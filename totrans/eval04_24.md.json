["```py\n( task: str = None ) \u2192 Evaluator\n```", "```py\n>>> from evaluate import evaluator\n>>> # Sentiment analysis evaluator\n>>> evaluator(\"sentiment-analysis\")\n```", "```py\n( task: str default_metric_name: str = None )\n```", "```py\n( data: typing.Union[str, datasets.arrow_dataset.Dataset] columns_names: typing.Dict[str, str] )\n```", "```py\n( metric: EvaluationModule metric_inputs: typing.Dict strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 random_state: typing.Optional[int] = None )\n```", "```py\n( data subset = None split = None ) \u2192 split\n```", "```py\n( data: typing.Union[str, datasets.arrow_dataset.Dataset] subset: str = None split: str = None ) \u2192 data (Dataset)\n```", "```py\n( *args **kwargs )\n```", "```py\n( data: Dataset input_column: str label_column: str *args **kwargs ) \u2192 dict\n```", "```py\n( metric: typing.Union[str, evaluate.module.EvaluationModule] )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] tokenizer: typing.Union[ForwardRef('PreTrainedTokenizerBase'), ForwardRef('FeatureExtractionMixin')] = None feature_extractor: typing.Union[ForwardRef('PreTrainedTokenizerBase'), ForwardRef('FeatureExtractionMixin')] = None device: int = None )\n```", "```py\n( task = 'image-classification' default_metric_name = None )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None feature_extractor: typing.Union[str, ForwardRef('FeatureExtractionMixin'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'image' label_column: str = 'label' label_mapping: typing.Union[typing.Dict[str, numbers.Number], NoneType] = None )\n```", "```py\n>>> from evaluate import evaluator\n>>> from datasets import load_dataset\n>>> task_evaluator = evaluator(\"image-classification\")\n>>> data = load_dataset(\"beans\", split=\"test[:40]\")\n>>> results = task_evaluator.compute(\n>>>     model_or_pipeline=\"nateraw/vit-base-beans\",\n>>>     data=data,\n>>>     label_column=\"labels\",\n>>>     metric=\"accuracy\",\n>>>     label_mapping={'angular_leaf_spot': 0, 'bean_rust': 1, 'healthy': 2},\n>>>     strategy=\"bootstrap\"\n>>> )\n```", "```py\n( task = 'question-answering' default_metric_name = None )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None question_column: str = 'question' context_column: str = 'context' id_column: str = 'id' label_column: str = 'answers' squad_v2_format: typing.Optional[bool] = None )\n```", "```py\n>>> from evaluate import evaluator\n>>> from datasets import load_dataset\n>>> task_evaluator = evaluator(\"question-answering\")\n>>> data = load_dataset(\"squad\", split=\"validation[:2]\")\n>>> results = task_evaluator.compute(\n>>>     model_or_pipeline=\"sshleifer/tiny-distilbert-base-cased-distilled-squad\",\n>>>     data=data,\n>>>     metric=\"squad\",\n>>> )\n```", "```py\n>>> from evaluate import evaluator\n>>> from datasets import load_dataset\n>>> task_evaluator = evaluator(\"question-answering\")\n>>> data = load_dataset(\"squad_v2\", split=\"validation[:2]\")\n>>> results = task_evaluator.compute(\n>>>     model_or_pipeline=\"mrm8488/bert-tiny-finetuned-squadv2\",\n>>>     data=data,\n>>>     metric=\"squad_v2\",\n>>>     squad_v2_format=True,\n>>> )\n```", "```py\n( task = 'text-classification' default_metric_name = None )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None feature_extractor: typing.Union[str, ForwardRef('FeatureExtractionMixin'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' second_input_column: typing.Optional[str] = None label_column: str = 'label' label_mapping: typing.Union[typing.Dict[str, numbers.Number], NoneType] = None )\n```", "```py\n>>> from evaluate import evaluator\n>>> from datasets import load_dataset\n>>> task_evaluator = evaluator(\"text-classification\")\n>>> data = load_dataset(\"imdb\", split=\"test[:2]\")\n>>> results = task_evaluator.compute(\n>>>     model_or_pipeline=\"huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli\",\n>>>     data=data,\n>>>     metric=\"accuracy\",\n>>>     label_mapping={\"LABEL_0\": 0.0, \"LABEL_1\": 1.0},\n>>>     strategy=\"bootstrap\",\n>>>     n_resamples=10,\n>>>     random_state=0\n>>> )\n```", "```py\n( task = 'token-classification' default_metric_name = None )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: str = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: typing.Optional[int] = None random_state: typing.Optional[int] = None input_column: str = 'tokens' label_column: str = 'ner_tags' join_by: typing.Optional[str] = ' ' )\n```", "```py\n>>> from evaluate import evaluator\n>>> from datasets import load_dataset\n>>> task_evaluator = evaluator(\"token-classification\")\n>>> data = load_dataset(\"conll2003\", split=\"validation[:2]\")\n>>> results = task_evaluator.compute(\n>>>     model_or_pipeline=\"elastic/distilbert-base-uncased-finetuned-conll03-english\",\n>>>     data=data,\n>>>     metric=\"seqeval\",\n>>> )\n```", "```py\ndataset = Dataset.from_dict(\n    mapping={\n        \"tokens\": [[\"New\", \"York\", \"is\", \"a\", \"city\", \"and\", \"Felix\", \"a\", \"person\", \".\"]],\n        \"ner_tags\": [[1, 2, 0, 0, 0, 0, 3, 0, 0, 0]],\n    },\n    features=Features({\n        \"tokens\": Sequence(feature=Value(dtype=\"string\")),\n        \"ner_tags\": Sequence(feature=ClassLabel(names=[\"O\", \"B-LOC\", \"I-LOC\", \"B-PER\", \"I-PER\"])),\n        }),\n)\n```", "```py\ndataset = Dataset.from_dict(\n    mapping={\n        \"tokens\": [[\"New York is a city and Felix a person.\"]],\n        \"starts\": [[0, 23]],\n        \"ends\": [[7, 27]],\n        \"ner_tags\": [[\"LOC\", \"PER\"]],\n    },\n    features=Features({\n        \"tokens\": Value(dtype=\"string\"),\n        \"starts\": Sequence(feature=Value(dtype=\"int32\")),\n        \"ends\": Sequence(feature=Value(dtype=\"int32\")),\n        \"ner_tags\": Sequence(feature=Value(dtype=\"string\")),\n    }),\n)\n```", "```py\n( task = 'text-generation' default_metric_name = None predictions_prefix: str = 'generated' )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None feature_extractor: typing.Union[str, ForwardRef('FeatureExtractionMixin'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' label_column: str = 'label' label_mapping: typing.Union[typing.Dict[str, numbers.Number], NoneType] = None )\n```", "```py\n( task = 'text2text-generation' default_metric_name = None )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' label_column: str = 'label' generation_kwargs: dict = None )\n```", "```py\n( task = 'summarization' default_metric_name = None )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' label_column: str = 'label' generation_kwargs: dict = None )\n```", "```py\n( task = 'translation' default_metric_name = None )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'text' label_column: str = 'label' generation_kwargs: dict = None )\n```", "```py\n( task = 'automatic-speech-recognition' default_metric_name = None )\n```", "```py\n( model_or_pipeline: typing.Union[str, ForwardRef('Pipeline'), typing.Callable, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')] = None data: typing.Union[str, datasets.arrow_dataset.Dataset] = None subset: typing.Optional[str] = None split: typing.Optional[str] = None metric: typing.Union[str, evaluate.module.EvaluationModule] = None tokenizer: typing.Union[str, ForwardRef('PreTrainedTokenizer'), NoneType] = None strategy: typing.Literal['simple', 'bootstrap'] = 'simple' confidence_level: float = 0.95 n_resamples: int = 9999 device: int = None random_state: typing.Optional[int] = None input_column: str = 'path' label_column: str = 'sentence' generation_kwargs: dict = None )\n```", "```py\n>>> from evaluate import evaluator\n>>> from datasets import load_dataset\n>>> task_evaluator = evaluator(\"automatic-speech-recognition\")\n>>> data = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"en\", split=\"validation[:40]\")\n>>> results = task_evaluator.compute(\n>>>     model_or_pipeline=\"https://huggingface.co/openai/whisper-tiny.en\",\n>>>     data=data,\n>>>     input_column=\"path\",\n>>>     label_column=\"sentence\",\n>>>     metric=\"wer\",\n>>> )\n```"]