# 存储库限制和建议

> 原始文本：[https://huggingface.co/docs/hub/repositories-recommendations](https://huggingface.co/docs/hub/repositories-recommendations)

在处理大量数据时，您需要注意一些限制。由于流式传输数据所需的时间，上传/推送在过程结束时失败或遇到降级体验，无论是在hf.co上还是在本地工作时，都会非常恼人。

## 推荐

我们收集了一些关于构建存储库的提示和建议。如果您正在寻找更多实用的提示，请查看[此指南](https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#tips-and-tricks-for-large-uploads)，了解如何使用Python库上传大量数据。

| 特征 | 推荐 | 提示 |
| --- | --- | --- |
| 存储库大小 | - | 对于大型存储库（TB级别的数据）请与我们联系 |
| 每个存储库的文件数 | <100k | 将数据合并到较少的文件中 |
| 每个文件夹的条目数 | <10k | 在存储库中使用子目录 |
| 文件大小 | <5GB | 将数据拆分为分块文件 |
| 提交大小 | <100个文件* | 在多个提交中上传文件 |
| 每个存储库的提交数 | - | 每个提交上传多个文件和/或压缩历史记录 |

**在直接使用`git` CLI时不相关*

请阅读下一节以更好地了解这些限制以及如何处理它们。

## 解释

当我们说“大型上传”时，我们在谈论什么，以及它们的相关限制是什么？大型上传可以非常多样化，从具有少量大文件（例如模型权重）的存储库到具有数千个小文件（例如图像数据集）的存储库。

在幕后，Hub使用Git对数据进行版本控制，这对您在存储库中可以做什么有结构上的影响。如果您的存储库超过了前一节提到的一些数字，**我们强烈建议您查看[`git-sizer`](https://github.com/github/git-sizer)**，它有关于影响您体验的不同因素的非常详细的文档。以下是需要考虑的因素的TL;DR：

+   **存储库大小**：您计划上传的数据的总大小。Hub存储库大小没有硬性限制。但是，如果您计划上传数百GB甚至TB级别的数据，我们会感激如果您提前告诉我们，这样我们在过程中有任何问题时可以更好地帮助您。您可以通过[datasets@huggingface.co](mailto:datasets@huggingface.co)或[我们的Discord](http://hf.co/join/discord)与我们联系。

+   **文件数量**：

    +   为了获得最佳体验，我们建议将文件总数保持在100k以下。如果文件更多，请尝试将数据合并到较少的文件中。例如，json文件可以合并为单个jsonl文件，或者大型数据集可以导出为Parquet文件或[WebDataset](https://github.com/webdataset/webdataset)格式。

    +   每个文件夹中的文件数不能超过10k个文件。一个简单的解决方案是创建一个使用子目录的存储库结构。例如，一个从`000/`到`999/`的包含最多1000个文件的1k个文件夹的存储库已经足够。

+   **文件大小**：在上传大文件（例如模型权重）的情况下，我们强烈建议将它们**分成每个约5GB的块**。这样做有几个原因：

    +   上传和下载较小的文件对您和其他用户都更容易。在流式传输数据时，连接问题总是可能发生，较小的文件可以避免在出现错误时从头开始恢复。

    +   文件是使用CloudFront提供给用户的。根据我们的经验，大文件不会被此服务缓存，导致下载速度较慢。在所有情况下，单个LFS文件的大小不会超过50GB。即单个文件大小的硬限制为50GB。

+   **提交次数**：在存储库历史记录中，总提交次数没有硬性限制。然而，根据我们的经验，在几千次提交后，Hub上的用户体验开始下降。我们不断努力改进服务，但人们必须始终记住，git存储库并不是用来作为具有大量写入的数据库。如果您的存储库历史记录变得非常庞大，总是可以将所有提交压缩以使用`huggingface_hub`的[`super_squash_history`](https://huggingface.co/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfApi.super_squash_history)重新开始。请注意，这是一个不可逆转的操作。

+   **每次提交的操作数量**：再次强调，这里没有硬性限制。当提交上传到Hub时，每个git操作（添加或删除）都会被服务器检查。当一次提交了一百个LFS文件时，每个文件都会被单独检查以确保已正确上传。通过HTTP推送数据时，请求会设置一个60秒的超时，意味着如果过程花费更多时间，就会出现错误。然而，在极少数情况下，即使客户端端设置了超时，过程仍可能在服务器端完成。可以通过在Hub上浏览存储库来手动检查这一点。为了防止超时，我们建议每次提交添加大约50-100个文件。
