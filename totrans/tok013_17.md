# 后处理器

> 原始文本：[https://huggingface.co/docs/tokenizers/api/post-processors](https://huggingface.co/docs/tokenizers/api/post-processors)

PythonRustNode

## BertProcessing

### `class tokenizers.processors.BertProcessing`

```py
( sep cls )
```

参数

+   `sep` (`Tuple[str, int]`) — 包含SEP标记的字符串表示和其ID的元组

+   `cls` (`Tuple[str, int]`) — 包含CLS标记的字符串表示和其ID的元组

这个后处理器负责添加Bert模型所需的特殊标记：

+   一个SEP标记

+   一个CLS标记

## ByteLevel

### `class tokenizers.processors.ByteLevel`

```py
( trim_offsets = True )
```

参数

+   `trim_offsets` (`bool`) — 是否修剪生成的偏移量中的空格。

这个后处理器负责修剪偏移量。

默认情况下，ByteLevel BPE可能会在生成的标记中包含空格。如果您不希望偏移量包含这些空格，则必须使用此PostProcessor。

## RobertaProcessing

### `class tokenizers.processors.RobertaProcessing`

```py
( sep cls trim_offsets = True add_prefix_space = True )
```

参数

+   `sep` (`Tuple[str, int]`) — 包含SEP标记的字符串表示和其ID的元组

+   `cls` (`Tuple[str, int]`) — 包含CLS标记的字符串表示和其ID的元组

+   `trim_offsets` (`bool`, *可选*, 默认为`True`) — 是否修剪生成的偏移量中的空格。

+   `add_prefix_space` (`bool`, *可选*, 默认为`True`) — 在预分词期间是否启用了add_prefix_space选项。这很重要，因为它定义了如何修剪偏移量。

这个后处理器负责添加Roberta模型所需的特殊标记：

+   一个SEP标记

+   一个CLS标记

它还负责修剪偏移量。默认情况下，ByteLevel BPE可能会在生成的标记中包含空格。如果您不希望偏移量包含这些空格，则应该使用`trim_offsets=True`初始化此PostProcessor

## TemplateProcessing

### `class tokenizers.processors.TemplateProcessing`

```py
( single pair special_tokens )
```

参数

+   `single` (`Template`) — 用于单个序列的模板

+   `pair` (`Template`) — 当两个序列都指定时使用的模板

+   `special_tokens` (`Tokens`) — 每个序列中使用的特殊标记列表

提供了一种指定模板以便将特殊标记添加到每个输入序列中的方法。

让我们以`BERT`分词器为例。它使用两个特殊标记，用于分隔每个序列。`[CLS]`始终用于第一个序列的开头，`[SEP]`被添加到第一个序列和双序列的末尾。最终结果如下：

+   单个序列：`[CLS] 你好 [SEP]`

+   双序列：`[CLS] 我的名字是安东尼 [SEP] 我的名字是什么？ [SEP]`

具有以下类型ID：

```py
[CLS]   ...   [SEP]   ...   [SEP]
0      0      0      1      1
```

您可以使用TemplateProcessing来实现这种行为：

```py
TemplateProcessing(
    single="[CLS] $0 [SEP]",
    pair="[CLS] $A [SEP] $B:1 [SEP]:1",
    special_tokens=[("[CLS]", 1), ("[SEP]", 0)],
)
```

在这个例子中，每个输入序列都使用`$`构造进行标识。这个标识符让我们可以指定每个输入序列和要使用的type_id。当没有指定时，它使用默认值。以下是指定的不同方式： 

+   指定序列，默认`type_id == 0`：`$A` 或 `$B`

+   指定*type_id*，默认`sequence == A`：`$0`，`$1`，`$2`，…

+   同时指定：`$A:0`，`$B:1`，…

相同的结构用于特殊标记：`<identifier>(:<type_id>)?`。

**警告**：您必须确保提供正确的标记/ID，因为这些将被添加到编码中，不会再进行进一步检查。如果给定的ID在使用此*PostProcessor*的*Tokenizer*中对应于完全不同的内容，可能会导致意外结果。

类型：

模板（`str`或`List`）：

+   如果提供了一个`str`，则空格被用作标记之间的分隔符

+   如果提供了一个`List[str]`，则是一个标记列表

Tokens (`List[Union[Tuple[int, str], Tuple[str, int], dict]]`):

+   一个包含标记及其关联ID的元组，顺序任意

+   一个包含以下键的字典：

    +   “id”: `str` => 模板中指定的特殊标记ID

    +   “ids”: `List[int]` => 相关的ID

    +   “tokens”：`List[str]` => 相关的标记

    给定的字典期望提供的`ids`和`tokens`列表具有相同的长度。
