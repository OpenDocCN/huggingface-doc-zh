["```py\n>>> from transformers import pipeline\n\n>>> transcriber = pipeline(task=\"automatic-speech-recognition\")\n```", "```py\n>>> transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}\n```", "```py\n>>> transcriber = pipeline(model=\"openai/whisper-large-v2\")\n>>> transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n```", "```py\ntranscriber(\n    [\n        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\",\n        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\",\n    ]\n)\n```", "```py\ntranscriber = pipeline(model=\"openai/whisper-large-v2\", my_parameter=1)\n\nout = transcriber(...)  # This will use `my_parameter=1`.\nout = transcriber(..., my_parameter=2)  # This will override and use `my_parameter=2`.\nout = transcriber(...)  # This will go back to using `my_parameter=1`.\n```", "```py\ntranscriber = pipeline(model=\"openai/whisper-large-v2\", device=0)\n```", "```py\npip install --upgrade accelerate\n```", "```py\ntranscriber = pipeline(model=\"openai/whisper-large-v2\", device_map=\"auto\")\n```", "```py\ntranscriber = pipeline(model=\"openai/whisper-large-v2\", device=0, batch_size=2)\naudio_filenames = [f\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/{i}.flac\" for i in range(1, 5)]\ntexts = transcriber(audio_filenames)\n```", "```py\n>>> transcriber = pipeline(model=\"openai/whisper-large-v2\", return_timestamps=True)\n>>> transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.', 'chunks': [{'timestamp': (0.0, 11.88), 'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its'}, {'timestamp': (11.88, 12.38), 'text': ' creed.'}]}\n```", "```py\n>>> transcriber = pipeline(model=\"openai/whisper-large-v2\", chunk_length_s=30, return_timestamps=True)\n>>> transcriber(\"https://huggingface.co/datasets/sanchit-gandhi/librispeech_long/resolve/main/audio.wav\")\n{'text': \" Chapter 16\\. I might have told you of the beginning of this liaison in a few lines, but I wanted you to see every step by which we came.  I, too, agree to whatever Marguerite wished, Marguerite to be unable to live apart from me. It was the day after the evening...\n```", "```py\ndef data():\n    for i in range(1000):\n        yield f\"My example {i}\"\n\npipe = pipeline(model=\"gpt2\", device=0)\ngenerated_characters = 0\nfor out in pipe(data()):\n    generated_characters += len(out[0][\"generated_text\"])\n```", "```py\n# KeyDataset is a util that will just output the item we're interested in.\nfrom transformers.pipelines.pt_utils import KeyDataset\nfrom datasets import load_dataset\n\npipe = pipeline(model=\"hf-internal-testing/tiny-random-wav2vec2\", device=0)\ndataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:10]\")\n\nfor out in pipe(KeyDataset(dataset, \"audio\")):\n    print(out)\n```", "```py\n>>> from transformers import pipeline\n\n>>> vision_classifier = pipeline(model=\"google/vit-base-patch16-224\")\n>>> preds = vision_classifier(\n...     images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n... )\n>>> preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n>>> preds\n[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]\n```", "```py\n>>> from transformers import pipeline\n\n>>> # This model is a `zero-shot-classification` model.\n>>> # It will classify text, except you are free to choose any label you might imagine\n>>> classifier = pipeline(model=\"facebook/bart-large-mnli\")\n>>> classifier(\n...     \"I have a problem with my iphone that needs to be resolved asap!!\",\n...     candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n... )\n{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}\n```", "```py\n>>> from transformers import pipeline\n\n>>> vqa = pipeline(model=\"impira/layoutlm-document-qa\")\n>>> vqa(\n...     image=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\",\n...     question=\"What is the invoice number?\",\n... )\n[{'score': 0.42515, 'answer': 'us-001', 'start': 16, 'end': 16}]\n```", "```py\nsudo apt install -y tesseract-ocr\npip install pytesseract\n```", "```py\n# pip install accelerate\nimport torch\nfrom transformers import pipeline\n\npipe = pipeline(model=\"facebook/opt-1.3b\", torch_dtype=torch.bfloat16, device_map=\"auto\")\noutput = pipe(\"This is a cool example!\", do_sample=True, top_p=0.95)\n```", "```py\n# pip install accelerate bitsandbytes\nimport torch\nfrom transformers import pipeline\n\npipe = pipeline(model=\"facebook/opt-1.3b\", device_map=\"auto\", model_kwargs={\"load_in_8bit\": True})\noutput = pipe(\"This is a cool example!\", do_sample=True, top_p=0.95)\n```"]