["```py\n( )\n```", "```py\n( adapter_names: Union )\n```", "```py\n( text_encoder: Optional = None )\n```", "```py\n( text_encoder: Optional = None )\n```", "```py\n( fuse_unet: bool = True fuse_text_encoder: bool = True lora_scale: float = 1.0 safe_fusing: bool = False adapter_names: Optional = None )\n```", "```py\nfrom diffusers import DiffusionPipeline\nimport torch\n\npipeline = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16\n).to(\"cuda\")\npipeline.load_lora_weights(\"nerijs/pixel-art-xl\", weight_name=\"pixel-art-xl.safetensors\", adapter_name=\"pixel\")\npipeline.fuse_lora(lora_scale=0.7)\n```", "```py\n( )\n```", "```py\nfrom diffusers import DiffusionPipeline\n\npipeline = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\",\n).to(\"cuda\")\npipeline.load_lora_weights(\"CiroN2022/toy-face\", weight_name=\"toy_face_sdxl.safetensors\", adapter_name=\"toy\")\npipeline.get_active_adapters()\n```", "```py\n( )\n```", "```py\n( state_dict network_alphas text_encoder prefix = None lora_scale = 1.0 low_cpu_mem_usage = None adapter_name = None _pipeline = None )\n```", "```py\n( state_dict network_alphas transformer low_cpu_mem_usage = None adapter_name = None _pipeline = None )\n```", "```py\n( state_dict network_alphas unet low_cpu_mem_usage = None adapter_name = None _pipeline = None )\n```", "```py\n( pretrained_model_name_or_path_or_dict: Union adapter_name = None **kwargs )\n```", "```py\n( pretrained_model_name_or_path_or_dict: Union **kwargs )\n```", "```py\n( save_directory: Union unet_lora_layers: Dict = None text_encoder_lora_layers: Dict = None transformer_lora_layers: Dict = None is_main_process: bool = True weight_name: str = None save_function: Callable = None safe_serialization: bool = True )\n```", "```py\n( adapter_names: Union text_encoder: Optional = None text_encoder_weights: List = None )\n```", "```py\n( adapter_names: List device: Union )\n```", "```py\n( unfuse_unet: bool = True unfuse_text_encoder: bool = True )\n```", "```py\n( )\n```", "```py\n>>> # Assuming `pipeline` is already loaded with the LoRA parameters.\n>>> pipeline.unload_lora_weights()\n>>> ...\n```", "```py\n( )\n```", "```py\n( pretrained_model_name_or_path_or_dict: Union adapter_name: Optional = None **kwargs )\n```"]