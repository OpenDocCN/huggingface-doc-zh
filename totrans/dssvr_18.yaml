- en: ClickHouse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/datasets-server/clickhouse](https://huggingface.co/docs/datasets-server/clickhouse)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: '[ClickHouse](https://clickhouse.com/docs/en/intro) is a fast and efficient
    column-oriented database for analytical workloads, making it easy to analyze Hub-hosted
    datasets with SQL. To get started quickly, use [`clickhouse-local`](https://clickhouse.com/docs/en/operations/utilities/clickhouse-local)
    to run SQL queries from the command line and avoid the need to fully install ClickHouse.'
  prefs: []
  type: TYPE_NORMAL
- en: Check this [blog](https://clickhouse.com/blog/query-analyze-hugging-face-datasets-with-clickhouse)
    for more details about how to analyze datasets on the Hub with ClickHouse.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, download and install `clickhouse-local`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For this example, you’ll analyze the [maharshipandya/spotify-tracks-dataset](https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset)
    which contains information about Spotify tracks. Datasets on the Hub are stored
    as Parquet files and you can access it with the [`/parquet`](parquet) endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Aggregate functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now you can begin to analyze the dataset. Use the `-q` argument to specify the
    query to execute, and the [`url`](https://clickhouse.com/docs/en/sql-reference/table-functions/url)
    function to create a table from the data in the Parquet file.
  prefs: []
  type: TYPE_NORMAL
- en: You should set `enable_url_encoding` to 0 to ensure the escape characters in
    the URL are preserved as intended, and `max_https_get_redirects` to 1 to redirect
    to the path of the Parquet file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by identifying the most popular artists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'ClickHouse also provides functions for visualizing your queries. For example,
    you can use the [`bar`](https://clickhouse.com/docs/en/sql-reference/functions/other-functions#bar)
    function to create a bar chart of the danceability of songs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: To get a deeper understanding about a dataset, ClickHouse provides statistical
    analysis functions for determining how your data is correlated, calculating statistical
    hypothesis tests, and more. Take a look at ClickHouse’s [List of Aggregate Functions](https://clickhouse.com/docs/en/sql-reference/aggregate-functions/reference)
    for a complete list of available aggregate functions.
  prefs: []
  type: TYPE_NORMAL
- en: User-defined function (UDFs)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A user-defined function (UDF) allows you to reuse custom logic. Many Hub datasets
    are often sharded into more than one Parquet file, so it can be easier and more
    efficient to create a UDF to list and query all the Parquet files of a given dataset
    from just the dataset name.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, you’ll need to run `clickhouse-local` in console mode so
    the UDF persists between queries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember to set `enable_url_encoding` to 0 and `max_https_get_redirects` to
    1 to redirect to the path of the Parquet files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s create a function to return a list of Parquet files from the [`blog_authorship_corpus`](https://huggingface.co/datasets/blog_authorship_corpus):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can make this even easier by creating another function that calls `hugging_paths`
    and outputs all the files based on the dataset name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now use the `hf` function to query any dataset by passing the dataset name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
