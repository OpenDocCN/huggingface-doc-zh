["```py\n( state_dim = 17 act_dim = 4 hidden_size = 128 max_ep_len = 4096 action_tanh = True vocab_size = 1 n_positions = 1024 n_layer = 3 n_head = 1 n_inner = None activation_function = 'relu' resid_pdrop = 0.1 embd_pdrop = 0.1 attn_pdrop = 0.1 layer_norm_epsilon = 1e-05 initializer_range = 0.02 scale_attn_weights = True use_cache = True bos_token_id = 50256 eos_token_id = 50256 scale_attn_by_inverse_layer_idx = False reorder_and_upcast_attn = False **kwargs )\n```", "```py\n>>> from transformers import DecisionTransformerConfig, DecisionTransformerModel\n\n>>> # Initializing a DecisionTransformer configuration\n>>> configuration = DecisionTransformerConfig()\n\n>>> # Initializing a model (with random weights) from the configuration\n>>> model = DecisionTransformerModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None past_key_values: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None encoder_hidden_states: Optional = None encoder_attention_mask: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )\n```", "```py\n( config )\n```", "```py\n( states: Optional = None actions: Optional = None rewards: Optional = None returns_to_go: Optional = None timesteps: Optional = None attention_mask: Optional = None output_hidden_states: Optional = None output_attentions: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.decision_transformer.modeling_decision_transformer.DecisionTransformerOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import DecisionTransformerModel\n>>> import torch\n\n>>> model = DecisionTransformerModel.from_pretrained(\"edbeeching/decision-transformer-gym-hopper-medium\")\n>>> # evaluation\n>>> model = model.to(device)\n>>> model.eval()\n\n>>> env = gym.make(\"Hopper-v3\")\n>>> state_dim = env.observation_space.shape[0]\n>>> act_dim = env.action_space.shape[0]\n\n>>> state = env.reset()\n>>> states = torch.from_numpy(state).reshape(1, 1, state_dim).to(device=device, dtype=torch.float32)\n>>> actions = torch.zeros((1, 1, act_dim), device=device, dtype=torch.float32)\n>>> rewards = torch.zeros(1, 1, device=device, dtype=torch.float32)\n>>> target_return = torch.tensor(TARGET_RETURN, dtype=torch.float32).reshape(1, 1)\n>>> timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n>>> attention_mask = torch.zeros(1, 1, device=device, dtype=torch.float32)\n\n>>> # forward pass\n>>> with torch.no_grad():\n...     state_preds, action_preds, return_preds = model(\n...         states=states,\n...         actions=actions,\n...         rewards=rewards,\n...         returns_to_go=target_return,\n...         timesteps=timesteps,\n...         attention_mask=attention_mask,\n...         return_dict=False,\n...     )\n```"]