["```py\n>>> from transformers import DecisionTransformerConfig, DecisionTransformerModel\n\n>>> # Initializing a DecisionTransformer configuration\n>>> configuration = DecisionTransformerConfig()\n\n>>> # Initializing a model (with random weights) from the configuration\n>>> model = DecisionTransformerModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import DecisionTransformerModel\n>>> import torch\n\n>>> model = DecisionTransformerModel.from_pretrained(\"edbeeching/decision-transformer-gym-hopper-medium\")\n>>> # evaluation\n>>> model = model.to(device)\n>>> model.eval()\n\n>>> env = gym.make(\"Hopper-v3\")\n>>> state_dim = env.observation_space.shape[0]\n>>> act_dim = env.action_space.shape[0]\n\n>>> state = env.reset()\n>>> states = torch.from_numpy(state).reshape(1, 1, state_dim).to(device=device, dtype=torch.float32)\n>>> actions = torch.zeros((1, 1, act_dim), device=device, dtype=torch.float32)\n>>> rewards = torch.zeros(1, 1, device=device, dtype=torch.float32)\n>>> target_return = torch.tensor(TARGET_RETURN, dtype=torch.float32).reshape(1, 1)\n>>> timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n>>> attention_mask = torch.zeros(1, 1, device=device, dtype=torch.float32)\n\n>>> # forward pass\n>>> with torch.no_grad():\n...     state_preds, action_preds, return_preds = model(\n...         states=states,\n...         actions=actions,\n...         rewards=rewards,\n...         returns_to_go=target_return,\n...         timesteps=timesteps,\n...         attention_mask=attention_mask,\n...         return_dict=False,\n...     )\n```"]