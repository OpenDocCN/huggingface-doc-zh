# 哲学

> 原文链接：[https://huggingface.co/docs/diffusers/conceptual/philosophy](https://huggingface.co/docs/diffusers/conceptual/philosophy)

🧨 Diffusers提供了跨多种模态的**最先进**的预训练扩散模型。它的目的是作为一个**模块化工具箱**，用于推理和训练。

我们致力于构建一个经得起时间考验的库，因此非常认真对待API设计。

简而言之，Diffusers被构建为PyTorch的自然扩展。因此，我们的大多数设计选择都基于[PyTorch的设计原则](https://pytorch.org/docs/stable/community/design.html#pytorch-design-philosophy)。让我们来看看最重要的几点：

## 可用性优于性能

+   虽然Diffusers具有许多内置的性能增强功能（请参阅[内存和速度](https://huggingface.co/docs/diffusers/optimization/fp16)），但模型始终以最高精度和最低优化加载。因此，默认情况下，如果用户没有另行定义，扩散管道始终在CPU上以float32精度实例化。这确保了在不同平台和加速器上的可用性，并意味着运行库不需要复杂的安装。

+   Diffusers旨在成为一个轻量级的包，因此具有非常少的必需依赖项，但有许多软依赖项可以提高性能（例如`accelerate`、`safetensors`、`onnx`等）。我们努力使库尽可能轻量，以便可以将其作为其他包的依赖项添加而无需太多担忧。

+   Diffusers更喜欢简单、易于理解的代码，而不是紧凑、神奇的代码。这意味着不希望使用诸如lambda函数和高级PyTorch运算符等简写代码语法。

## 简单胜于容易

正如PyTorch所述，“显式优于隐式”和“简单优于复杂”。这种设计哲学体现在库的多个部分中：

+   我们遵循PyTorch的API，使用[`DiffusionPipeline.to`](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.to)等方法，让用户处理设备管理。

+   更喜欢提供简洁的错误消息，而不是悄悄地纠正错误的输入。Diffusers旨在教导用户，而不是使库尽可能易于使用。

+   暴露复杂的模型与调度逻辑，而不是在内部神奇地处理。调度器/采样器与扩散模型分开，彼此之间的依赖性最小。这迫使用户编写展开的去噪循环。然而，这种分离使得调试更容易，并且让用户更容易控制适应去噪过程或切换扩散模型或调度器。

+   扩散管道的单独训练组件，例如文本编码器、unet和变分自动编码器，每个都有自己的模型类。这迫使用户处理不同模型组件之间的交互，而序列化格式将模型组件分开存储在不同文件中。然而，这使得调试和定制更容易。由于Diffusers能够分离扩散管道的单个组件，DreamBooth或文本反演训练非常简单。

## 易于调整、友好的贡献者优于抽象

对于图书馆的大部分部分，Diffusers采用了[Transformers库](https://github.com/huggingface/transformers)的一个重要设计原则，即更喜欢复制粘贴的代码而不是仓促的抽象。这个设计原则非常有主见，与流行的设计原则如[不要重复自己（DRY）](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself)形成鲜明对比。简而言之，就像Transformers为建模文件所做的那样，Diffusers更喜欢保持极低的抽象水平和非常自包含的管道和调度器代码。函数、长代码块，甚至类可以在多个文件之间复制，起初可能看起来像是一个糟糕、懒散的设计选择，使得图书馆难以维护。**然而**，这种设计已经被证明对Transformers非常成功，并且对于社区驱动的开源机器学习库来说是非常合理的，因为：

+   机器学习是一个快速发展的领域，范式、模型架构和算法都在迅速变化，因此很难定义持久的代码抽象。

+   机器学习从业者喜欢能够快速调整现有代码进行构思和研究，因此更喜欢自包含的代码而不是包含许多抽象的代码。

+   开源库依赖于社区贡献，因此必须构建一个易于贡献的库。代码越抽象，依赖越多，阅读越困难，贡献也越困难。贡献者简单地停止对非常抽象的库进行贡献，因为他们担心破坏重要功能。如果对库的贡献不会破坏其他基本代码，不仅对潜在的新贡献者更具吸引力，而且更容易审查和同时贡献多个部分。

在Hugging Face，我们称这种设计为**单文件政策**，这意味着某个类的几乎所有代码应该写在一个单独的自包含文件中。要了解更多关于这种哲学的信息，您可以查看[这篇博客文章](https://huggingface.co/blog/transformers-design-philosophy)。

在Diffusers中，我们对管道和调度器都遵循这一哲学，但对扩散模型只部分遵循。我们不完全遵循这种设计的原因是因为几乎所有扩散管道，如[DDPM](https://huggingface.co/docs/diffusers/api/pipelines/ddpm)、[稳定扩散](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview#stable-diffusion-pipelines)、[unCLIP（DALL·E 2）](https://huggingface.co/docs/diffusers/api/pipelines/unclip)和[Imagen](https://imagen.research.google/)都依赖于相同的扩散模型，即[UNet](https://huggingface.co/docs/diffusers/api/models/unet2d-cond)。

很好，现在你应该大致了解为什么🧨 Diffusers被设计成这样了🤗。我们试图在整个库中一致应用这些设计原则。然而，也有一些对这一理念的小例外或一些不幸的设计选择。如果您对设计有反馈，我们会❤️直接在GitHub上听取意见（https://github.com/huggingface/diffusers/issues/new?assignees=&labels=&template=feedback.md&title=）。

## 详细的设计哲学

现在，让我们稍微深入了解设计哲学的细节。Diffusers基本上由三个主要类组成：[管道](https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines)、[模型](https://github.com/huggingface/diffusers/tree/main/src/diffusers/models)和[调度器](https://github.com/huggingface/diffusers/tree/main/src/diffusers/schedulers)。让我们更详细地讨论每个类的设计决策。

### 管道

管道被设计为易于使用（因此不完全遵循[*简单胜过容易*](#简单胜过容易) 100%），不是功能完备的，并且应该宽松地被视为如何使用[模型](#模型)和[调度器](#调度器)进行推断的示例。

遵循以下设计原则：

+   管道遵循单文件策略。所有管道都可以在src/diffusers/pipelines的各个目录下找到。一个管道文件夹对应一个扩散论文/项目/发布。多个管道文件可以收集在一个管道文件夹中，就像对于[`src/diffusers/pipelines/stable-diffusion`](https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines/stable_diffusion)所做的那样。如果管道共享类似功能，可以利用[#从机制复制](https://github.com/huggingface/diffusers/blob/125d783076e5bd9785beb05367a2d2566843a271/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py#L251)。

+   所有管道都继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。

+   每个管道由不同的模型和调度器组件组成，这些组件在[`model_index.json`文件](https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/model_index.json)中有文档记录，可以在管道的属性下以相同的名称访问，并且可以通过[`DiffusionPipeline.components`](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.components)函数在管道之间共享。

+   每个管道应该可以通过[`DiffusionPipeline.from_pretrained`](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained)函数加载。

+   管道应该**仅**用于推断。

+   管道应该非常易读，自解释，并且易于调整。

+   管道应该被设计为相互构建，并且易于集成到更高级别的API中。

+   管道**不**旨在成为功能完备的用户界面。对于未来完整的用户界面，应该更多地查看[InvokeAI](https://github.com/invoke-ai/InvokeAI)，[Diffuzers](https://github.com/abhishekkrthakur/diffuzers)和[lama-cleaner](https://github.com/Sanster/lama-cleaner)。

+   每个管道应该只有一种通过`__call__`方法运行的方式。`__call__`参数的命名应该在所有管道中共享。

+   管道应该以其所打算解决的任务命名。

+   在几乎所有情况下，新颖的扩散管道应该在新的管道文件夹/文件中实现。

### 模型

模型被设计为可配置的工具箱，是[PyTorch的Module类](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)的自然扩展。它们只部分遵循**单文件策略**。

遵循以下设计原则：

+   模型对应于**一种模型架构**。*例如* [UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)类用于所有期望2D图像输入并受一些上下文影响的UNet变体。

+   所有模型都可以在[`src/diffusers/models`](https://github.com/huggingface/diffusers/tree/main/src/diffusers/models)中找到，每个模型架构应该在其文件中定义，例如[`unet_2d_condition.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/unet_2d_condition.py)，[`transformer_2d.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/transformer_2d.py)，等等...

+   模型**不**遵循单文件政策，应该利用较小的模型构建模块，例如[`attention.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention.py)、[`resnet.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/resnet.py)、[`embeddings.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/embeddings.py)等等... **注意**：这与Transformers的建模文件形成鲜明对比，表明模型实际上并没有遵循单文件政策。

+   模型意图公开复杂性，就像PyTorch的`Module`类一样，并提供清晰的错误消息。

+   所有模型都继承自`ModelMixin`和`ConfigMixin`。

+   当不需要进行重大代码更改时，模型可以针对性能进行优化，保持向后兼容性，并提供显著的内存或计算增益。

+   模型应默认具有最高精度和最低性能设置。

+   要集成新的模型检查点，其一般架构可以归类为Diffusers中已存在的架构，现有的模型架构应该被调整以使其与新检查点配合工作。只有当模型架构根本不同的情况下才应该创建新文件。

+   模型应设计为易于扩展以适应未来的变化。这可以通过限制公共函数参数、配置参数和“预见”未来变化来实现，例如最好添加`string`“…type”参数，可以轻松扩展到新的未来类型，而不是布尔`is_..._type`参数。只需对现有架构进行最少的更改，使新模型检查点能够正常工作。

+   模型设计是在保持代码可读性和简洁性以及支持许多模型检查点之间进行艰难权衡。在建模代码的大部分部分，类应该适应新的模型检查点，但也有一些例外情况，最好添加新的类以确保代码长期保持简洁和可读性，例如[UNet blocks](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/unet_2d_blocks.py)和[Attention processors](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)。

### 调度器

调度器负责引导推理的去噪过程，同时为训练定义噪声计划。它们被设计为具有可加载配置文件的单独类，并严格遵循“单文件政策”。

遵循以下设计原则：

+   所有调度器都位于[`src/diffusers/schedulers`](https://github.com/huggingface/diffusers/tree/main/src/diffusers/schedulers)中。

+   调度器**不**允许从大型utils文件中导入，并应保持非常自包含。

+   一个调度器Python文件对应一个调度算法（可能在论文中定义）。

+   如果调度器共享类似的功能，我们可以利用`#Copied from`机制。

+   所有调度器都继承自`SchedulerMixin`和`ConfigMixin`。

+   调度器可以通过[`ConfigMixin.from_config`](https://huggingface.co/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config)方法轻松替换，详细说明见[此处](../using-diffusers/schedulers.md)。

+   每个调度器都必须有一个`set_num_inference_steps`和一个`step`函数。在每次去噪过程之前必须调用`set_num_inference_steps(...)`，即在调用`step(...)`之前。

+   每个调度器通过一个`timesteps`属性公开要“循环遍历”的时间步，这是模型将被调用的时间步数组。

+   `step(...)`函数接受一个预测的模型输出和“当前”样本（x_t），并返回“上一个”，稍微去噪的样本（x_t-1）。

+   鉴于扩散调度器的复杂性，`step`函数不会暴露所有复杂性，可能有点像一个“黑匣子”。

+   在几乎所有情况下，新的调度程序应该在一个新的调度文件中实现。
