# 概述

> 原文链接：[https://huggingface.co/docs/diffusers/optimization/opt_overview](https://huggingface.co/docs/diffusers/optimization/opt_overview)

生成高质量的输出在计算上是密集的，特别是在每个迭代步骤中，您从嘈杂的输出转换为较少嘈杂的输出。🤗 Diffuser的目标之一是使这项技术普遍可用，这包括在消费者和专用硬件上实现快速推理。

本节将涵盖一些技巧和窍门 - 如半精度权重和切片注意力 - 用于优化推理速度和减少内存消耗。您还将学习如何使用[`torch.compile`](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html)或[ONNX Runtime](https://onnxruntime.ai/docs/)加快PyTorch代码的运行速度，并使用[xFormers](https://facebookresearch.github.io/xformers/)实现内存高效的注意力。还有关于在特定硬件上运行推理的指南，如苹果Silicon，以及英特尔或Habana处理器。
