["```py\n>>> import torch\n>>> import requests\n>>> from PIL import Image\n\n>>> from diffusers import StableDiffusionDepth2ImgPipeline\n\n>>> pipe = StableDiffusionDepth2ImgPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-2-depth\",\n...     torch_dtype=torch.float16,\n... )\n>>> pipe.to(\"cuda\")\n\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> init_image = Image.open(requests.get(url, stream=True).raw)\n>>> prompt = \"two tigers\"\n>>> n_propmt = \"bad, deformed, ugly, bad anotomy\"\n>>> image = pipe(prompt=prompt, image=init_image, negative_prompt=n_propmt, strength=0.7).images[0]\n```", "```py\n>>> import torch\n>>> from diffusers import StableDiffusionPipeline\n\n>>> pipe = StableDiffusionPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\",\n...     torch_dtype=torch.float16,\n...     use_safetensors=True,\n... )\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> pipe.enable_attention_slicing()\n>>> image = pipe(prompt).images[0]\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```", "```py\nfrom diffusers import StableDiffusionPipeline\nimport torch\n\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n\npipe.load_textual_inversion(\"sd-concepts-library/cat-toy\")\n\nprompt = \"A <cat-toy> backpack\"\n\nimage = pipe(prompt, num_inference_steps=50).images[0]\nimage.save(\"cat-backpack.png\")\n```", "```py\nfrom diffusers import StableDiffusionPipeline\nimport torch\n\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n\npipe.load_textual_inversion(\"./charturnerv2.pt\", token=\"charturnerv2\")\n\nprompt = \"charturnerv2, multiple views of the same character in the same outfit, a character turnaround of a woman wearing a black jacket and red shirt, best quality, intricate details.\"\n\nimage = pipe(prompt, num_inference_steps=50).images[0]\nimage.save(\"character.png\")\n```"]