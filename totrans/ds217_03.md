# å¿«é€Ÿå…¥é—¨

> åŽŸæ–‡ï¼š[https://huggingface.co/docs/datasets/quickstart](https://huggingface.co/docs/datasets/quickstart)

è¿™ä¸ªå¿«é€Ÿå…¥é—¨æŒ‡å—é€‚ç”¨äºŽå‡†å¤‡æ·±å…¥ä»£ç å¹¶æŸ¥çœ‹å¦‚ä½•å°†ðŸ¤—æ•°æ®é›†é›†æˆåˆ°æ¨¡åž‹è®­ç»ƒå·¥ä½œæµç¨‹ä¸­çš„å¼€å‘äººå‘˜ã€‚å¦‚æžœæ‚¨æ˜¯åˆå­¦è€…ï¼Œæˆ‘ä»¬å»ºè®®ä»Žæˆ‘ä»¬çš„[æ•™ç¨‹](./tutorial)å¼€å§‹ï¼Œé‚£é‡Œæ‚¨å°†å¾—åˆ°æ›´å…¨é¢çš„ä»‹ç»ã€‚

æ¯ä¸ªæ•°æ®é›†éƒ½æ˜¯ç‹¬ç‰¹çš„ï¼Œæ ¹æ®ä»»åŠ¡çš„ä¸åŒï¼Œä¸€äº›æ•°æ®é›†å¯èƒ½éœ€è¦é¢å¤–çš„æ­¥éª¤æ¥å‡†å¤‡è®­ç»ƒã€‚ä½†æ‚¨å§‹ç»ˆå¯ä»¥ä½¿ç”¨ðŸ¤— æ•°æ®é›†å·¥å…·æ¥åŠ è½½å’Œå¤„ç†æ•°æ®é›†ã€‚å¼€å§‹çš„æœ€å¿«æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä»Ž[Hugging Face Hub](https://huggingface.co/datasets)åŠ è½½çŽ°æœ‰æ•°æ®é›†ã€‚æœ‰æˆåƒä¸Šä¸‡ä¸ªæ•°æ®é›†å¯ä¾›é€‰æ‹©ï¼Œæ¶µç›–è®¸å¤šä»»åŠ¡ã€‚é€‰æ‹©æ‚¨æƒ³è¦å¤„ç†çš„æ•°æ®é›†ç±»åž‹ï¼Œç„¶åŽè®©æˆ‘ä»¬å¼€å§‹å§ï¼

[éŸ³é¢‘

å¯¹éŸ³é¢‘æ•°æ®é›†è¿›è¡Œé‡é‡‡æ ·ï¼Œå¹¶ä¸ºæ¨¡åž‹å‡†å¤‡å¥½ä»¥åˆ†ç±»è¯´è¯è€…æ­£åœ¨è¯¢é—®çš„é“¶è¡Œé—®é¢˜ç±»åž‹ã€‚](#audio) [è§†è§‰

å¯¹å›¾åƒæ•°æ®é›†åº”ç”¨æ•°æ®å¢žå¼ºï¼Œå¹¶ä¸ºæ¨¡åž‹å‡†å¤‡å¥½ä»¥è¯Šæ–­è±†ç±»æ¤ç‰©ç–¾ç—…ã€‚](#vision) [NLP

å¯¹æ•°æ®é›†è¿›è¡Œæ ‡è®°åŒ–å¤„ç†ï¼Œå¹¶ä¸ºæ¨¡åž‹å‡†å¤‡å¥½ä»¥ç¡®å®šä¸€å¯¹å¥å­æ˜¯å¦å…·æœ‰ç›¸åŒçš„å«ä¹‰ã€‚](#nlp)

æŸ¥çœ‹ [Hugging Face è¯¾ç¨‹](https://huggingface.co/course/chapter5/1?fw=pt) çš„ç¬¬ 5 ç« ï¼Œäº†è§£æ›´å¤šå…³äºŽåŠ è½½è¿œç¨‹æˆ–æœ¬åœ°æ•°æ®é›†ã€æ¸…ç†æ•°æ®é›†çš„å·¥å…·ä»¥åŠåˆ›å»ºè‡ªå·±çš„æ•°æ®é›†ç­‰å…¶ä»–é‡è¦ä¸»é¢˜ã€‚

é¦–å…ˆå®‰è£…ðŸ¤— æ•°æ®é›†ï¼š

```py
pip install datasets
```

ðŸ¤— æ•°æ®é›†è¿˜æ”¯æŒéŸ³é¢‘å’Œå›¾åƒæ•°æ®æ ¼å¼ï¼š

+   è¦å¤„ç†éŸ³é¢‘æ•°æ®é›†ï¼Œè¯·å®‰è£… [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio) åŠŸèƒ½ï¼š

    ```py
    pip install datasets[audio]
    ```

+   è¦å¤„ç†å›¾åƒæ•°æ®é›†ï¼Œè¯·å®‰è£… [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image) åŠŸèƒ½ï¼š

    ```py
    pip install datasets[vision]
    ```

é™¤äº†ðŸ¤— æ•°æ®é›†ä¹‹å¤–ï¼Œç¡®ä¿æ‚¨å–œæ¬¢çš„æœºå™¨å­¦ä¹ æ¡†æž¶å·²å®‰è£…ï¼š

Pytorchéšè— Pytorch å†…å®¹

```py
pip install torch
```

TensorFlowéšè— TensorFlow å†…å®¹

```py
pip install tensorflow
```

## éŸ³é¢‘

éŸ³é¢‘æ•°æ®é›†çš„åŠ è½½æ–¹å¼ä¸Žæ–‡æœ¬æ•°æ®é›†ç›¸åŒã€‚ä½†æ˜¯ï¼ŒéŸ³é¢‘æ•°æ®é›†çš„é¢„å¤„ç†æ–¹å¼ç•¥æœ‰ä¸åŒã€‚æ‚¨å°†éœ€è¦ä¸€ä¸ª [ç‰¹å¾æå–å™¨](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor) è€Œä¸æ˜¯æ ‡è®°åŒ–å™¨ã€‚éŸ³é¢‘è¾“å…¥å¯èƒ½è¿˜éœ€è¦é‡æ–°é‡‡æ ·å…¶é‡‡æ ·çŽ‡ä»¥åŒ¹é…æ‚¨æ­£åœ¨ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡åž‹çš„é‡‡æ ·çŽ‡ã€‚åœ¨è¿™ä¸ªå¿«é€Ÿå…¥é—¨ä¸­ï¼Œæ‚¨å°†å‡†å¤‡[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) æ•°æ®é›†ï¼Œç”¨äºŽè®­ç»ƒæ¨¡åž‹å¹¶å¯¹å®¢æˆ·é‡åˆ°çš„é“¶è¡Œé—®é¢˜è¿›è¡Œåˆ†ç±»ã€‚

**1**. é€šè¿‡å‘ [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset) å‡½æ•°æä¾›æ•°æ®é›†åç§°ã€æ•°æ®é›†é…ç½®ï¼ˆå¹¶éžæ‰€æœ‰æ•°æ®é›†éƒ½æœ‰é…ç½®ï¼‰å’Œæ•°æ®é›†æ‹†åˆ†æ¥åŠ è½½ MInDS-14 æ•°æ®é›†ï¼š

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
```

**2**. æŽ¥ä¸‹æ¥ï¼ŒåŠ è½½é¢„è®­ç»ƒçš„ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) æ¨¡åž‹åŠå…¶å¯¹åº”çš„ç‰¹å¾æå–å™¨ï¼Œæ¥è‡ª [ðŸ¤— Transformers](https://huggingface.co/transformers/) åº“ã€‚åœ¨åŠ è½½æ¨¡åž‹åŽçœ‹åˆ°ä¸€äº›æƒé‡æœªåˆå§‹åŒ–çš„è­¦å‘Šæ˜¯æ­£å¸¸çš„ã€‚è¿™æ˜¯é¢„æœŸçš„ï¼Œå› ä¸ºæ‚¨æ­£åœ¨åŠ è½½æ­¤æ¨¡åž‹æ£€æŸ¥ç‚¹ä»¥ç”¨äºŽå¦ä¸€ä¸ªä»»åŠ¡çš„è®­ç»ƒã€‚

```py
>>> from transformers import AutoModelForAudioClassification, AutoFeatureExtractor

>>> model = AutoModelForAudioClassification.from_pretrained("facebook/wav2vec2-base")
>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")
```

**3**. [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) æ•°æ®é›†å¡ç‰‡æ˜¾ç¤ºé‡‡æ ·çŽ‡ä¸º 8kHzï¼Œä½† Wav2Vec2 æ¨¡åž‹æ˜¯åœ¨ 16kHZ é‡‡æ ·çŽ‡ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„ã€‚æ‚¨éœ€è¦ä½¿ç”¨ [cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column) å‡½æ•°å’Œ [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio) åŠŸèƒ½å¯¹ `audio` åˆ—è¿›è¡Œä¸Šé‡‡æ ·ï¼Œä»¥åŒ¹é…æ¨¡åž‹çš„é‡‡æ ·çŽ‡ã€‚

```py
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
>>> dataset[0]["audio"]
{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,
         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
 'sampling_rate': 16000}
```

**4**. åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œä½¿ç”¨ç‰¹å¾æå–å™¨é¢„å¤„ç†éŸ³é¢‘`array`ï¼Œå¹¶å°†åºåˆ—æˆªæ–­å’Œå¡«å……ä¸ºæ•´æ´çš„çŸ©å½¢å¼ é‡ã€‚æœ€é‡è¦çš„æ˜¯è¦è®°ä½åœ¨ç‰¹å¾æå–å™¨ä¸­è°ƒç”¨éŸ³é¢‘`array`ï¼Œå› ä¸º`array` - å®žé™…è¯­éŸ³ä¿¡å· - æ˜¯æ¨¡åž‹è¾“å…¥ã€‚

ä¸€æ—¦æ‚¨æœ‰ä¸€ä¸ªé¢„å¤„ç†å‡½æ•°ï¼Œä½¿ç”¨[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)å‡½æ•°ï¼Œé€šè¿‡å°†å‡½æ•°åº”ç”¨äºŽæ•°æ®é›†ä¸­çš„ç¤ºä¾‹æ‰¹æ¬¡æ¥åŠ å¿«å¤„ç†é€Ÿåº¦ã€‚

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays,
...         sampling_rate=16000,
...         padding=True,
...         max_length=100000,
...         truncation=True,
...     )
...     return inputs

>>> dataset = dataset.map(preprocess_function, batched=True)
```

**5**. ä½¿ç”¨[rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)å‡½æ•°å°†`intent_class`åˆ—é‡å‘½åä¸º`labels`ï¼Œè¿™æ˜¯[Wav2Vec2ForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)ä¸­é¢„æœŸçš„è¾“å…¥åç§°ï¼š

```py
>>> dataset = dataset.rename_column("intent_class", "labels")
```

**6**. æ ¹æ®æ‚¨æ­£åœ¨ä½¿ç”¨çš„æœºå™¨å­¦ä¹ æ¡†æž¶è®¾ç½®æ•°æ®é›†æ ¼å¼ã€‚

PytorchHide Pytorch content

ä½¿ç”¨[set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format)å‡½æ•°å°†æ•°æ®é›†æ ¼å¼è®¾ç½®ä¸º`torch`ï¼Œå¹¶æŒ‡å®šè¦æ ¼å¼åŒ–çš„åˆ—ã€‚æ­¤å‡½æ•°ä¼šå®žæ—¶åº”ç”¨æ ¼å¼ã€‚è½¬æ¢ä¸ºPyTorchå¼ é‡åŽï¼Œå°†æ•°æ®é›†åŒ…è£…åœ¨[`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader)ä¸­ï¼š

```py
>>> from torch.utils.data import DataLoader

>>> dataset.set_format(type="torch", columns=["input_values", "labels"])
>>> dataloader = DataLoader(dataset, batch_size=4)
```

TensorFlowHide TensorFlow content

ä½¿ç”¨ðŸ¤— Transformersçš„[prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)æ–¹æ³•æ¥å‡†å¤‡æ•°æ®é›†ä»¥ä¸ŽTensorFlowå…¼å®¹ï¼Œå¹¶å‡†å¤‡å¥½è®­ç»ƒ/å¾®è°ƒæ¨¡åž‹ï¼Œå› ä¸ºå®ƒå°†HuggingFace [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)åŒ…è£…ä¸º`tf.data.Dataset`ï¼Œå…·æœ‰æ•´ç†å’Œæ‰¹å¤„ç†åŠŸèƒ½ï¼Œå› æ­¤å¯ä»¥ç›´æŽ¥å°†å…¶ä¼ é€’ç»™Kerasæ–¹æ³•ï¼Œå¦‚`fit()`ï¼Œæ— éœ€è¿›ä¸€æ­¥ä¿®æ”¹ã€‚

```py
>>> import tensorflow as tf

>>> tf_dataset = model.prepare_tf_dataset(
...     dataset,
...     batch_size=4,
...     shuffle=True,
... )
```

**7**. ä½¿ç”¨æ‚¨çš„æœºå™¨å­¦ä¹ æ¡†æž¶å¼€å§‹è®­ç»ƒï¼æŸ¥çœ‹ðŸ¤— Transformersçš„[éŸ³é¢‘åˆ†ç±»æŒ‡å—](https://huggingface.co/docs/transformers/tasks/audio_classification) ï¼Œäº†è§£å¦‚ä½•åœ¨éŸ³é¢‘æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡åž‹çš„ç«¯åˆ°ç«¯ç¤ºä¾‹ã€‚

## è§†è§‰

å›¾åƒæ•°æ®é›†çš„åŠ è½½æ–¹å¼ä¸Žæ–‡æœ¬æ•°æ®é›†ç›¸åŒã€‚ä½†æ˜¯ï¼Œæ‚¨éœ€è¦ä¸€ä¸ª[ç‰¹å¾æå–å™¨](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)æ¥é¢„å¤„ç†æ•°æ®é›†ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªåˆ†è¯å™¨ã€‚åœ¨è®¡ç®—æœºè§†è§‰ä¸­å¯¹å›¾åƒåº”ç”¨æ•°æ®å¢žå¼ºæ˜¯å¸¸è§çš„ï¼Œä»¥ä½¿æ¨¡åž‹æ›´å…·æŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›ã€‚æ‚¨å¯ä»¥è‡ªç”±é€‰æ‹©ä»»ä½•æ•°æ®å¢žå¼ºåº“ï¼Œç„¶åŽå¯ä»¥ä½¿ç”¨ðŸ¤— Datasetsåº”ç”¨å¢žå¼ºã€‚åœ¨è¿™ä¸ªå¿«é€Ÿå…¥é—¨ä¸­ï¼Œæ‚¨å°†åŠ è½½[Beans](https://huggingface.co/datasets/beans)æ•°æ®é›†ï¼Œå¹¶å‡†å¤‡å¥½è®©æ¨¡åž‹è®­ç»ƒå¹¶ä»Žå¶ç‰‡å›¾åƒä¸­è¯†åˆ«ç–¾ç—…ã€‚

**1**. é€šè¿‡æä¾›æ•°æ®é›†åç§°å’Œæ•°æ®é›†æ‹†åˆ†ï¼Œä½¿ç”¨[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)å‡½æ•°åŠ è½½Beansæ•°æ®é›†ï¼š

```py
>>> from datasets import load_dataset, Image

>>> dataset = load_dataset("beans", split="train")
```

**2**. çŽ°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•åº“ï¼ˆ[Albumentations](https://albumentations.ai/)ã€[imgaug](https://imgaug.readthedocs.io/en/latest/)ã€[Kornia](https://kornia.readthedocs.io/en/latest/)ï¼‰æ·»åŠ ä¸€äº›æ•°æ®å¢žå¼ºã€‚åœ¨è¿™é‡Œï¼Œæ‚¨å°†ä½¿ç”¨[torchvision](https://pytorch.org/vision/stable/transforms.html)éšæœºæ›´æ”¹å›¾åƒçš„é¢œè‰²å±žæ€§ï¼š

```py
>>> from torchvision.transforms import Compose, ColorJitter, ToTensor

>>> jitter = Compose(
...     [ColorJitter(brightness=0.5, hue=0.5), ToTensor()]
... )
```

**3**. åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå°†æ‚¨çš„è½¬æ¢åº”ç”¨äºŽæ•°æ®é›†å¹¶ç”Ÿæˆæ¨¡åž‹è¾“å…¥ï¼š`pixel_values`ã€‚

```py
>>> def transforms(examples):
...     examples["pixel_values"] = [jitter(image.convert("RGB")) for image in examples["image"]]
...     return examples
```

**4**. ä½¿ç”¨[with_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_transform)å‡½æ•°å®žæ—¶åº”ç”¨æ•°æ®å¢žå¼ºï¼š

```py
>>> dataset = dataset.with_transform(transforms)
```

**5**. æ ¹æ®æ‚¨æ­£åœ¨ä½¿ç”¨çš„æœºå™¨å­¦ä¹ æ¡†æž¶è®¾ç½®æ•°æ®é›†æ ¼å¼ã€‚

PytorchHide Pytorch content

å°†æ•°æ®é›†åŒ…è£…åœ¨[`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader)ä¸­ã€‚æ‚¨è¿˜éœ€è¦åˆ›å»ºä¸€ä¸ªæ•´ç†å‡½æ•°ï¼Œå°†æ ·æœ¬æ•´ç†æˆæ‰¹æ¬¡ï¼š

```py
>>> from torch.utils.data import DataLoader

>>> def collate_fn(examples):
...     images = []
...     labels = []
...     for example in examples:
...         images.append((example["pixel_values"]))
...         labels.append(example["labels"])
...         
...     pixel_values = torch.stack(images)
...     labels = torch.tensor(labels)
...     return {"pixel_values": pixel_values, "labels": labels}
>>> dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=4)
```

TensorFlowHide TensorFlow content

ä½¿ç”¨ðŸ¤— Transformersä¸­çš„[prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)æ–¹æ³•æ¥å‡†å¤‡æ•°æ®é›†ä»¥ä¸ŽTensorFlowå…¼å®¹ï¼Œå¹¶å‡†å¤‡å¥½è®­ç»ƒ/å¾®è°ƒæ¨¡åž‹ï¼Œå› ä¸ºå®ƒå°†HuggingFaceçš„[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)åŒ…è£…ä¸ºä¸€ä¸ªå¸¦æœ‰æ•´ç†å’Œæ‰¹å¤„ç†çš„`tf.data.Dataset`ï¼Œå› æ­¤å¯ä»¥ç›´æŽ¥å°†å…¶ä¼ é€’ç»™Kerasæ–¹æ³•ï¼Œå¦‚`fit()`ï¼Œè€Œæ— éœ€è¿›ä¸€æ­¥ä¿®æ”¹ã€‚

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…`albumentations`å’Œ`cv2`çš„æœ€æ–°ç‰ˆæœ¬ï¼š

```py
pip install -U albumentations opencv-python
```

```py
>>> import albumentations
>>> import numpy as np

>>> transform = albumentations.Compose([
...     albumentations.RandomCrop(width=256, height=256),
...     albumentations.HorizontalFlip(p=0.5),
...     albumentations.RandomBrightnessContrast(p=0.2),
... ])

>>> def transforms(examples):
...     examples["pixel_values"] = [
...         transform(image=np.array(image))["image"] for image in examples["image"]
...     ]
...     return examples

>>> dataset.set_transform(transforms)
>>> tf_dataset = model.prepare_tf_dataset(
...     dataset,
...     batch_size=4,
...     shuffle=True,
... )
```

**6**. ä½¿ç”¨æ‚¨çš„æœºå™¨å­¦ä¹ æ¡†æž¶å¼€å§‹è®­ç»ƒï¼æŸ¥çœ‹ðŸ¤— Transformersçš„[å›¾åƒåˆ†ç±»æŒ‡å—](https://huggingface.co/docs/transformers/tasks/image_classification) ï¼Œäº†è§£å¦‚ä½•åœ¨å›¾åƒæ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡åž‹çš„ç«¯åˆ°ç«¯ç¤ºä¾‹ã€‚

## NLP

æ–‡æœ¬éœ€è¦é€šè¿‡[åˆ†è¯å™¨](https://huggingface.co/docs/transformers/main_classes/tokenizer)åˆ†è¯ä¸ºå•ç‹¬çš„æ ‡è®°ã€‚åœ¨å¿«é€Ÿå…¥é—¨ä¸­ï¼Œæ‚¨å°†åŠ è½½[Microsoft Research Paraphrase Corpus (MRPC)](https://huggingface.co/datasets/glue/viewer/mrpc)è®­ç»ƒæ•°æ®é›†ï¼Œä»¥è®­ç»ƒæ¨¡åž‹æ¥ç¡®å®šä¸€å¯¹å¥å­æ˜¯å¦è¡¨ç¤ºç›¸åŒçš„å«ä¹‰ã€‚

**1**. é€šè¿‡å‘[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)å‡½æ•°æä¾›æ•°æ®é›†åç§°ã€æ•°æ®é›†é…ç½®ï¼ˆå¹¶éžæ‰€æœ‰æ•°æ®é›†éƒ½æœ‰é…ç½®ï¼‰å’Œæ•°æ®é›†æ‹†åˆ†æ¥åŠ è½½MRPCæ•°æ®é›†ï¼š

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("glue", "mrpc", split="train")
```

**2**. æŽ¥ä¸‹æ¥ï¼Œä»Ž[ðŸ¤— Transformers](https://huggingface.co/transformers/)åº“ä¸­åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„[BERT](https://huggingface.co/bert-base-uncased)æ¨¡åž‹åŠå…¶å¯¹åº”çš„åˆ†è¯å™¨ã€‚åœ¨åŠ è½½æ¨¡åž‹åŽçœ‹åˆ°ä¸€äº›æƒé‡æœªåˆå§‹åŒ–çš„è­¦å‘Šæ˜¯æ­£å¸¸çš„ã€‚è¿™æ˜¯å› ä¸ºæ‚¨æ­£åœ¨åŠ è½½æ­¤æ¨¡åž‹æ£€æŸ¥ç‚¹ä»¥ä¾¿ç”¨äºŽå¦ä¸€ä¸ªä»»åŠ¡çš„è®­ç»ƒã€‚

```py
>>> from transformers import AutoModelForSequenceClassification, AutoTokenizer

>>> model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased") **3**. Create a function to tokenize the dataset, and you should also truncate and pad the text into tidy rectangular tensors. The tokenizer generates three new columns in the dataset: `input_ids`, `token_type_ids`, and an `attention_mask`. These are the model inputs. Use the [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map) function to speed up processing by applying your tokenization function to batches of examples in the dataset:  

```

>>> def encode(examples):

...     return tokenizer(examples["sentence1"], examples["sentence2"], truncation=True, padding="max_length")

>>> dataset = dataset.map(encode, batched=True)

>>> dataset[0]

{'sentence1': 'AmroziæŒ‡æŽ§ä»–çš„å…„å¼Ÿï¼Œç§°å…¶ä¸ºâ€œè¯äººâ€ï¼Œæ•…æ„æ­ªæ›²è¯æ®ã€‚',

'sentence2': 'AmroziæŒ‡ç§°ä»–çš„å…„å¼Ÿä¸ºâ€œè¯äººâ€ï¼ŒæŒ‡æŽ§ä»–æ•…æ„æ­ªæ›²è¯æ®ã€‚',

'label': 1,

'idx': 0,

'input_ids': array([  101,  7277,  2180,  5303,  4806,  1117,  1711,   117,  2292, 1119,  1270,   107,  1103,  7737,   107,   117,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102, 11336,  6732, 3384,  1106,  1140,  1112,  1178,   107,  1103,  7737,   107, 117,  7277,  2180,  5303,  4806,  1117,  1711,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102]),

'token_type_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),

'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}

```py

**4**. Rename the `label` column to `labels`, which is the expected input name in [BertForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification):

```

>>> dataset = dataset.map(lambda examples: {"labels": examples["label"]}, batched=True)

```py

**5**. Set the dataset format according to the machine learning framework youâ€™re using.

   Pytorch  Hide Pytorch content  

Use the [set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format) function to set the dataset format to `torch` and specify the columns you want to format. This function applies formatting on-the-fly. After converting to PyTorch tensors, wrap the dataset in [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader):

```

>>> import torch

>>> dataset.set_format(type="torch", columns=["input_ids", "token_type_ids", "attention_mask", "labels"])

>>> dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)

```py

   TensorFlow  Hide TensorFlow content  

Use the [prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) method from ðŸ¤— Transformers to prepare the dataset to be compatible with
TensorFlow, and ready to train/fine-tune a model, as it wraps a HuggingFace [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset) as a `tf.data.Dataset`
with collation and batching, so one can pass it directly to Keras methods like `fit()` without further modification.

```

>>> import tensorflow as tf

>>> tf_dataset = model.prepare_tf_dataset(

...     dataset,

...     batch_size=4,

...     shuffle=True,

... )

```py

**6**. Start training with your machine learning framework! Check out the ðŸ¤— Transformers [text classification guide](https://huggingface.co/docs/transformers/tasks/sequence_classification) for an end-to-end example of how to train a model on a text dataset.

##   Whatâ€™s next?

This completes the ðŸ¤— Datasets quickstart! You can load any text, audio, or image dataset with a single function and get it ready for your model to train on.

For your next steps, take a look at our [How-to guides](./how_to) and learn how to do more specific things like loading different dataset formats, aligning labels, and streaming large datasets. If youâ€™re interested in learning more about ðŸ¤— Datasets core concepts, grab a cup of coffee and read our [Conceptual Guides](./about_arrow)!

```
