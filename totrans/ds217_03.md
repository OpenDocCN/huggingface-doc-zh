# 快速入门

> 原文：[https://huggingface.co/docs/datasets/quickstart](https://huggingface.co/docs/datasets/quickstart)

这个快速入门指南适用于准备深入代码并查看如何将🤗数据集集成到模型训练工作流程中的开发人员。如果您是初学者，我们建议从我们的[教程](./tutorial)开始，那里您将得到更全面的介绍。

每个数据集都是独特的，根据任务的不同，一些数据集可能需要额外的步骤来准备训练。但您始终可以使用🤗 数据集工具来加载和处理数据集。开始的最快最简单的方法是从[Hugging Face Hub](https://huggingface.co/datasets)加载现有数据集。有成千上万个数据集可供选择，涵盖许多任务。选择您想要处理的数据集类型，然后让我们开始吧！

[音频

对音频数据集进行重采样，并为模型准备好以分类说话者正在询问的银行问题类型。](#audio) [视觉

对图像数据集应用数据增强，并为模型准备好以诊断豆类植物疾病。](#vision) [NLP

对数据集进行标记化处理，并为模型准备好以确定一对句子是否具有相同的含义。](#nlp)

查看 [Hugging Face 课程](https://huggingface.co/course/chapter5/1?fw=pt) 的第 5 章，了解更多关于加载远程或本地数据集、清理数据集的工具以及创建自己的数据集等其他重要主题。

首先安装🤗 数据集：

```py
pip install datasets
```

🤗 数据集还支持音频和图像数据格式：

+   要处理音频数据集，请安装 [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio) 功能：

    ```py
    pip install datasets[audio]
    ```

+   要处理图像数据集，请安装 [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image) 功能：

    ```py
    pip install datasets[vision]
    ```

除了🤗 数据集之外，确保您喜欢的机器学习框架已安装：

Pytorch隐藏 Pytorch 内容

```py
pip install torch
```

TensorFlow隐藏 TensorFlow 内容

```py
pip install tensorflow
```

## 音频

音频数据集的加载方式与文本数据集相同。但是，音频数据集的预处理方式略有不同。您将需要一个 [特征提取器](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor) 而不是标记化器。音频输入可能还需要重新采样其采样率以匹配您正在使用的预训练模型的采样率。在这个快速入门中，您将准备[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) 数据集，用于训练模型并对客户遇到的银行问题进行分类。

**1**. 通过向 [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset) 函数提供数据集名称、数据集配置（并非所有数据集都有配置）和数据集拆分来加载 MInDS-14 数据集：

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
```

**2**. 接下来，加载预训练的 [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) 模型及其对应的特征提取器，来自 [🤗 Transformers](https://huggingface.co/transformers/) 库。在加载模型后看到一些权重未初始化的警告是正常的。这是预期的，因为您正在加载此模型检查点以用于另一个任务的训练。

```py
>>> from transformers import AutoModelForAudioClassification, AutoFeatureExtractor

>>> model = AutoModelForAudioClassification.from_pretrained("facebook/wav2vec2-base")
>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")
```

**3**. [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) 数据集卡片显示采样率为 8kHz，但 Wav2Vec2 模型是在 16kHZ 采样率上进行预训练的。您需要使用 [cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column) 函数和 [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio) 功能对 `audio` 列进行上采样，以匹配模型的采样率。

```py
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
>>> dataset[0]["audio"]
{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,
         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
 'sampling_rate': 16000}
```

**4**. 创建一个函数，使用特征提取器预处理音频`array`，并将序列截断和填充为整洁的矩形张量。最重要的是要记住在特征提取器中调用音频`array`，因为`array` - 实际语音信号 - 是模型输入。

一旦您有一个预处理函数，使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)函数，通过将函数应用于数据集中的示例批次来加快处理速度。

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays,
...         sampling_rate=16000,
...         padding=True,
...         max_length=100000,
...         truncation=True,
...     )
...     return inputs

>>> dataset = dataset.map(preprocess_function, batched=True)
```

**5**. 使用[rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)函数将`intent_class`列重命名为`labels`，这是[Wav2Vec2ForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)中预期的输入名称：

```py
>>> dataset = dataset.rename_column("intent_class", "labels")
```

**6**. 根据您正在使用的机器学习框架设置数据集格式。

PytorchHide Pytorch content

使用[set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format)函数将数据集格式设置为`torch`，并指定要格式化的列。此函数会实时应用格式。转换为PyTorch张量后，将数据集包装在[`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader)中：

```py
>>> from torch.utils.data import DataLoader

>>> dataset.set_format(type="torch", columns=["input_values", "labels"])
>>> dataloader = DataLoader(dataset, batch_size=4)
```

TensorFlowHide TensorFlow content

使用🤗 Transformers的[prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)方法来准备数据集以与TensorFlow兼容，并准备好训练/微调模型，因为它将HuggingFace [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)包装为`tf.data.Dataset`，具有整理和批处理功能，因此可以直接将其传递给Keras方法，如`fit()`，无需进一步修改。

```py
>>> import tensorflow as tf

>>> tf_dataset = model.prepare_tf_dataset(
...     dataset,
...     batch_size=4,
...     shuffle=True,
... )
```

**7**. 使用您的机器学习框架开始训练！查看🤗 Transformers的[音频分类指南](https://huggingface.co/docs/transformers/tasks/audio_classification) ，了解如何在音频数据集上训练模型的端到端示例。

## 视觉

图像数据集的加载方式与文本数据集相同。但是，您需要一个[特征提取器](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)来预处理数据集，而不是一个分词器。在计算机视觉中对图像应用数据增强是常见的，以使模型更具抗过拟合能力。您可以自由选择任何数据增强库，然后可以使用🤗 Datasets应用增强。在这个快速入门中，您将加载[Beans](https://huggingface.co/datasets/beans)数据集，并准备好让模型训练并从叶片图像中识别疾病。

**1**. 通过提供数据集名称和数据集拆分，使用[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)函数加载Beans数据集：

```py
>>> from datasets import load_dataset, Image

>>> dataset = load_dataset("beans", split="train")
```

**2**. 现在您可以使用任何库（[Albumentations](https://albumentations.ai/)、[imgaug](https://imgaug.readthedocs.io/en/latest/)、[Kornia](https://kornia.readthedocs.io/en/latest/)）添加一些数据增强。在这里，您将使用[torchvision](https://pytorch.org/vision/stable/transforms.html)随机更改图像的颜色属性：

```py
>>> from torchvision.transforms import Compose, ColorJitter, ToTensor

>>> jitter = Compose(
...     [ColorJitter(brightness=0.5, hue=0.5), ToTensor()]
... )
```

**3**. 创建一个函数，将您的转换应用于数据集并生成模型输入：`pixel_values`。

```py
>>> def transforms(examples):
...     examples["pixel_values"] = [jitter(image.convert("RGB")) for image in examples["image"]]
...     return examples
```

**4**. 使用[with_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_transform)函数实时应用数据增强：

```py
>>> dataset = dataset.with_transform(transforms)
```

**5**. 根据您正在使用的机器学习框架设置数据集格式。

PytorchHide Pytorch content

将数据集包装在[`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader)中。您还需要创建一个整理函数，将样本整理成批次：

```py
>>> from torch.utils.data import DataLoader

>>> def collate_fn(examples):
...     images = []
...     labels = []
...     for example in examples:
...         images.append((example["pixel_values"]))
...         labels.append(example["labels"])
...         
...     pixel_values = torch.stack(images)
...     labels = torch.tensor(labels)
...     return {"pixel_values": pixel_values, "labels": labels}
>>> dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=4)
```

TensorFlowHide TensorFlow content

使用🤗 Transformers中的[prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)方法来准备数据集以与TensorFlow兼容，并准备好训练/微调模型，因为它将HuggingFace的[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)包装为一个带有整理和批处理的`tf.data.Dataset`，因此可以直接将其传递给Keras方法，如`fit()`，而无需进一步修改。

在开始之前，请确保已安装`albumentations`和`cv2`的最新版本：

```py
pip install -U albumentations opencv-python
```

```py
>>> import albumentations
>>> import numpy as np

>>> transform = albumentations.Compose([
...     albumentations.RandomCrop(width=256, height=256),
...     albumentations.HorizontalFlip(p=0.5),
...     albumentations.RandomBrightnessContrast(p=0.2),
... ])

>>> def transforms(examples):
...     examples["pixel_values"] = [
...         transform(image=np.array(image))["image"] for image in examples["image"]
...     ]
...     return examples

>>> dataset.set_transform(transforms)
>>> tf_dataset = model.prepare_tf_dataset(
...     dataset,
...     batch_size=4,
...     shuffle=True,
... )
```

**6**. 使用您的机器学习框架开始训练！查看🤗 Transformers的[图像分类指南](https://huggingface.co/docs/transformers/tasks/image_classification) ，了解如何在图像数据集上训练模型的端到端示例。

## NLP

文本需要通过[分词器](https://huggingface.co/docs/transformers/main_classes/tokenizer)分词为单独的标记。在快速入门中，您将加载[Microsoft Research Paraphrase Corpus (MRPC)](https://huggingface.co/datasets/glue/viewer/mrpc)训练数据集，以训练模型来确定一对句子是否表示相同的含义。

**1**. 通过向[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)函数提供数据集名称、数据集配置（并非所有数据集都有配置）和数据集拆分来加载MRPC数据集：

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("glue", "mrpc", split="train")
```

**2**. 接下来，从[🤗 Transformers](https://huggingface.co/transformers/)库中加载一个预训练的[BERT](https://huggingface.co/bert-base-uncased)模型及其对应的分词器。在加载模型后看到一些权重未初始化的警告是正常的。这是因为您正在加载此模型检查点以便用于另一个任务的训练。

```py
>>> from transformers import AutoModelForSequenceClassification, AutoTokenizer

>>> model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased") **3**. Create a function to tokenize the dataset, and you should also truncate and pad the text into tidy rectangular tensors. The tokenizer generates three new columns in the dataset: `input_ids`, `token_type_ids`, and an `attention_mask`. These are the model inputs. Use the [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map) function to speed up processing by applying your tokenization function to batches of examples in the dataset:  

```

>>> def encode(examples):

...     return tokenizer(examples["sentence1"], examples["sentence2"], truncation=True, padding="max_length")

>>> dataset = dataset.map(encode, batched=True)

>>> dataset[0]

{'sentence1': 'Amrozi指控他的兄弟，称其为“证人”，故意歪曲证据。',

'sentence2': 'Amrozi指称他的兄弟为“证人”，指控他故意歪曲证据。',

'label': 1,

'idx': 0,

'input_ids': array([  101,  7277,  2180,  5303,  4806,  1117,  1711,   117,  2292, 1119,  1270,   107,  1103,  7737,   107,   117,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102, 11336,  6732, 3384,  1106,  1140,  1112,  1178,   107,  1103,  7737,   107, 117,  7277,  2180,  5303,  4806,  1117,  1711,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102]),

'token_type_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),

'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}

```py

**4**. Rename the `label` column to `labels`, which is the expected input name in [BertForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification):

```

>>> dataset = dataset.map(lambda examples: {"labels": examples["label"]}, batched=True)

```py

**5**. Set the dataset format according to the machine learning framework you’re using.

   Pytorch  Hide Pytorch content  

Use the [set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format) function to set the dataset format to `torch` and specify the columns you want to format. This function applies formatting on-the-fly. After converting to PyTorch tensors, wrap the dataset in [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader):

```

>>> import torch

>>> dataset.set_format(type="torch", columns=["input_ids", "token_type_ids", "attention_mask", "labels"])

>>> dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)

```py

   TensorFlow  Hide TensorFlow content  

Use the [prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset) method from 🤗 Transformers to prepare the dataset to be compatible with
TensorFlow, and ready to train/fine-tune a model, as it wraps a HuggingFace [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset) as a `tf.data.Dataset`
with collation and batching, so one can pass it directly to Keras methods like `fit()` without further modification.

```

>>> import tensorflow as tf

>>> tf_dataset = model.prepare_tf_dataset(

...     dataset,

...     batch_size=4,

...     shuffle=True,

... )

```py

**6**. Start training with your machine learning framework! Check out the 🤗 Transformers [text classification guide](https://huggingface.co/docs/transformers/tasks/sequence_classification) for an end-to-end example of how to train a model on a text dataset.

##   What’s next?

This completes the 🤗 Datasets quickstart! You can load any text, audio, or image dataset with a single function and get it ready for your model to train on.

For your next steps, take a look at our [How-to guides](./how_to) and learn how to do more specific things like loading different dataset formats, aligning labels, and streaming large datasets. If you’re interested in learning more about 🤗 Datasets core concepts, grab a cup of coffee and read our [Conceptual Guides](./about_arrow)!

```
