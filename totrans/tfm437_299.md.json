["```py\n( hidden_size = 768 num_hidden_layers = 12 num_attention_heads = 12 intermediate_size = 3072 hidden_act = 'gelu' hidden_dropout_prob = 0.0 attention_probs_dropout_prob = 0.0 initializer_range = 0.02 layer_norm_eps = 1e-06 image_size = 224 patch_size = 16 num_channels = 3 qkv_bias = True **kwargs )\n```", "```py\n>>> from transformers import ViTMSNModel, ViTMSNConfig\n\n>>> # Initializing a ViT MSN vit-msn-base style configuration\n>>> configuration = ViTConfig()\n\n>>> # Initializing a model from the vit-msn-base style configuration\n>>> model = ViTMSNModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( config: ViTMSNConfig use_mask_token: bool = False )\n```", "```py\n( pixel_values: Optional = None bool_masked_pos: Optional = None head_mask: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None interpolate_pos_encoding: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.BaseModelOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, ViTMSNModel\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"facebook/vit-msn-small\")\n>>> model = ViTMSNModel.from_pretrained(\"facebook/vit-msn-small\")\n>>> inputs = image_processor(images=image, return_tensors=\"pt\")\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n( config: ViTMSNConfig )\n```", "```py\n( pixel_values: Optional = None head_mask: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None interpolate_pos_encoding: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.ImageClassifierOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, ViTMSNForImageClassification\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n\n>>> torch.manual_seed(2)\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"facebook/vit-msn-small\")\n>>> model = ViTMSNForImageClassification.from_pretrained(\"facebook/vit-msn-small\")\n\n>>> inputs = image_processor(images=image, return_tensors=\"pt\")\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n>>> # model predicts one of the 1000 ImageNet classes\n>>> predicted_label = logits.argmax(-1).item()\n>>> print(model.config.id2label[predicted_label])\nKerry blue terrier\n```"]