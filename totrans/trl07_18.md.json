["```py\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\ntrainer = IterativeSFTTrainer(\n    model,\n    tokenizer\n)\n\n```", "```py\n\ninputs = {\n    \"input_ids\": input_ids,\n    \"attention_mask\": attention_mask\n}\n\ntrainer.step(**inputs)\n\n```", "```py\n\ninputs = {\n    \"texts\": texts\n}\n\ntrainer.step(**inputs)\n\n```", "```py\n( model: PreTrainedModel = None args: TrainingArguments = None tokenizer: PreTrainedTokenizerBase = None optimizers: Tuple = (None, None) data_collator: Optional = None eval_dataset: Union = None max_length: Optional = None truncation_mode: Optional = 'keep_end' preprocess_logits_for_metrics: Optional = None compute_metrics: Optional = None optimize_device_cache: Optional = False )\n```", "```py\n( input_ids: Optional = None attention_mask: Optional = None labels: Optional = None texts: Optional = None texts_labels: Optional = None ) \u2192 export const metadata = 'undefined';dict[str, Any]\n```"]