["```py\n>>> from transformers import SplinterModel, SplinterConfig\n\n>>> # Initializing a Splinter tau/splinter-base style configuration\n>>> configuration = SplinterConfig()\n\n>>> # Initializing a model from the tau/splinter-base style configuration\n>>> model = SplinterModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import AutoTokenizer, SplinterModel\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"tau/splinter-base\")\n>>> model = SplinterModel.from_pretrained(\"tau/splinter-base\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, SplinterForQuestionAnswering\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"tau/splinter-base\")\n>>> model = SplinterForQuestionAnswering.from_pretrained(\"tau/splinter-base\")\n\n>>> question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n\n>>> inputs = tokenizer(question, text, return_tensors=\"pt\")\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> answer_start_index = outputs.start_logits.argmax()\n>>> answer_end_index = outputs.end_logits.argmax()\n\n>>> predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n\n>>> # target is \"nice puppet\"\n>>> target_start_index = torch.tensor([14])\n>>> target_end_index = torch.tensor([15])\n\n>>> outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)\n>>> loss = outputs.loss\n```"]