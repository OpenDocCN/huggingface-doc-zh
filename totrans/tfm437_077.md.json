["```py\npip install optuna/sigopt/wandb/ray[tune] \n```", "```py\n>>> def sigopt_hp_space(trial):\n...     return [\n...         {\"bounds\": {\"min\": 1e-6, \"max\": 1e-4}, \"name\": \"learning_rate\", \"type\": \"double\"},\n...         {\n...             \"categorical_values\": [\"16\", \"32\", \"64\", \"128\"],\n...             \"name\": \"per_device_train_batch_size\",\n...             \"type\": \"categorical\",\n...         },\n...     ]\n```", "```py\n>>> def optuna_hp_space(trial):\n...     return {\n...         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n...         \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64, 128]),\n...     }\n```", "```py\n>>> best_trials = trainer.hyperparameter_search(\n...     direction=[\"minimize\", \"maximize\"],\n...     backend=\"optuna\",\n...     hp_space=optuna_hp_space,\n...     n_trials=20,\n...     compute_objective=compute_objective,\n... )\n```", "```py\n>>> def ray_hp_space(trial):\n...     return {\n...         \"learning_rate\": tune.loguniform(1e-6, 1e-4),\n...         \"per_device_train_batch_size\": tune.choice([16, 32, 64, 128]),\n...     }\n```", "```py\n>>> def wandb_hp_space(trial):\n...     return {\n...         \"method\": \"random\",\n...         \"metric\": {\"name\": \"objective\", \"goal\": \"minimize\"},\n...         \"parameters\": {\n...             \"learning_rate\": {\"distribution\": \"uniform\", \"min\": 1e-6, \"max\": 1e-4},\n...             \"per_device_train_batch_size\": {\"values\": [16, 32, 64, 128]},\n...         },\n...     }\n```", "```py\n>>> def model_init(trial):\n...     return AutoModelForSequenceClassification.from_pretrained(\n...         model_args.model_name_or_path,\n...         from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n...         config=config,\n...         cache_dir=model_args.cache_dir,\n...         revision=model_args.model_revision,\n...         token=True if model_args.use_auth_token else None,\n...     )\n```", "```py\n>>> trainer = Trainer(\n...     model=None,\n...     args=training_args,\n...     train_dataset=small_train_dataset,\n...     eval_dataset=small_eval_dataset,\n...     compute_metrics=compute_metrics,\n...     tokenizer=tokenizer,\n...     model_init=model_init,\n...     data_collator=data_collator,\n... )\n```", "```py\n>>> best_trial = trainer.hyperparameter_search(\n...     direction=\"maximize\",\n...     backend=\"optuna\",\n...     hp_space=optuna_hp_space,\n...     n_trials=20,\n...     compute_objective=compute_objective,\n... )\n```"]