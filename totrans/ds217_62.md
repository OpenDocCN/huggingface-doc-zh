# åŠ è½½æ–¹æ³•

> åŸæ–‡é“¾æ¥ï¼š[`huggingface.co/docs/datasets/package_reference/loading_methods`](https://huggingface.co/docs/datasets/package_reference/loading_methods)

åˆ—å‡ºå’ŒåŠ è½½æ•°æ®é›†å’ŒæŒ‡æ ‡çš„æ–¹æ³•ï¼š

## æ•°æ®é›†

#### `datasets.list_datasets`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/inspect.py#L52)

```py
( with_community_datasets = True with_details = False )
```

å‚æ•°

+   `with_community_datasets` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” åŒ…æ‹¬ç¤¾åŒºæä¾›çš„æ•°æ®é›†ã€‚

+   `with_details` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” è¿”å›æ•°æ®é›†çš„å®Œæ•´è¯¦æƒ…è€Œä¸ä»…ä»…æ˜¯ç®€çŸ­åç§°ã€‚

åˆ—å‡º HF Hub ä¸Šæ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†è„šæœ¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from datasets import list_datasets
>>> list_datasets()
['acronym_identification',
 'ade_corpus_v2',
 'adversarial_qa',
 'aeslc',
 'afrikaans_ner_corpus',
 'ag_news',
 ...
]
```

#### `datasets.load_dataset`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/load.py#L2276)

```py
( path: str name: Optional = None data_dir: Optional = None data_files: Union = None split: Union = None cache_dir: Optional = None features: Optional = None download_config: Optional = None download_mode: Union = None verification_mode: Union = None ignore_verifications = 'deprecated' keep_in_memory: Optional = None save_infos: bool = False revision: Union = None token: Union = None use_auth_token = 'deprecated' task = 'deprecated' streaming: bool = False num_proc: Optional = None storage_options: Optional = None trust_remote_code: bool = None **config_kwargs ) â†’ export const metadata = 'undefined';Dataset or DatasetDict
```

å‚æ•°

+   `path` (`str`) â€” æ•°æ®é›†çš„è·¯å¾„æˆ–åç§°ã€‚æ ¹æ®`path`ï¼Œä½¿ç”¨çš„æ•°æ®é›†æ„å»ºå™¨æ¥è‡ªé€šç”¨æ•°æ®é›†è„šæœ¬ï¼ˆJSONã€CSVã€Parquetã€æ–‡æœ¬ç­‰ï¼‰æˆ–æ•°æ®é›†ç›®å½•å†…çš„æ•°æ®é›†è„šæœ¬ï¼ˆä¸€ä¸ª Python æ–‡ä»¶ï¼‰ã€‚

    å¯¹äºæœ¬åœ°æ•°æ®é›†ï¼š

    +   å¦‚æœ`path`æ˜¯æœ¬åœ°ç›®å½•ï¼ˆä»…åŒ…å«æ•°æ®æ–‡ä»¶ï¼‰-> æ ¹æ®ç›®å½•å†…å®¹åŠ è½½é€šç”¨æ•°æ®é›†æ„å»ºå™¨ï¼ˆcsvã€jsonã€æ–‡æœ¬ç­‰ï¼‰ä¾‹å¦‚`'./path/to/directory/with/my/csv/data'`ã€‚

    +   å¦‚æœ`path`æ˜¯æœ¬åœ°æ•°æ®é›†è„šæœ¬æˆ–åŒ…å«æœ¬åœ°æ•°æ®é›†è„šæœ¬çš„ç›®å½•ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰-> ä»æ•°æ®é›†è„šæœ¬åŠ è½½æ•°æ®é›†æ„å»ºå™¨ ä¾‹å¦‚`'./dataset/squad'`æˆ–`'./dataset/squad/squad.py'`ã€‚

    å¯¹äº HF Hub ä¸Šçš„æ•°æ®é›†ï¼ˆä½¿ç”¨`huggingface_hub.list_datasets`åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†ï¼‰

    +   å¦‚æœ`path`æ˜¯ HF Hub ä¸Šçš„æ•°æ®é›†å­˜å‚¨åº“ï¼ˆä»…åŒ…å«æ•°æ®æ–‡ä»¶ï¼‰-> æ ¹æ®å­˜å‚¨åº“å†…å®¹åŠ è½½é€šç”¨æ•°æ®é›†æ„å»ºå™¨ï¼ˆcsvã€æ–‡æœ¬ç­‰ï¼‰ä¾‹å¦‚`'username/dataset_name'`ï¼ŒHF Hub ä¸ŠåŒ…å«æ‚¨æ•°æ®æ–‡ä»¶çš„æ•°æ®é›†å­˜å‚¨åº“ã€‚

    +   å¦‚æœ`path`æ˜¯ HF Hub ä¸Šå¸¦æœ‰æ•°æ®é›†è„šæœ¬çš„æ•°æ®é›†å­˜å‚¨åº“ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰-> ä»æ•°æ®é›†å­˜å‚¨åº“ä¸­çš„æ•°æ®é›†è„šæœ¬åŠ è½½æ•°æ®é›†æ„å»ºå™¨ ä¾‹å¦‚`glue`ã€`squad`ã€`'username/dataset_name'`ï¼ŒHF Hub ä¸ŠåŒ…å«æ•°æ®é›†è„šæœ¬`'dataset_name.py'`çš„æ•°æ®é›†å­˜å‚¨åº“ã€‚

+   `name` (`str`, *optional*) â€” å®šä¹‰æ•°æ®é›†é…ç½®çš„åç§°ã€‚

+   `data_dir` (`str`, *optional*) â€” å®šä¹‰æ•°æ®é›†é…ç½®çš„`data_dir`ã€‚å¦‚æœä¸ºé€šç”¨æ„å»ºå™¨ï¼ˆcsvã€æ–‡æœ¬ç­‰ï¼‰æˆ– Hub æ•°æ®é›†æŒ‡å®šäº†`data_files`ä¸”ä¸º`None`ï¼Œåˆ™è¡Œä¸ºç­‰åŒäºå°†`os.path.join(data_dir, **)`ä½œä¸º`data_files`ä¼ é€’ä»¥å¼•ç”¨ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚

+   `data_files` (`str` æˆ– `Sequence` æˆ– `Mapping`, *optional*) â€” æºæ•°æ®æ–‡ä»¶çš„è·¯å¾„ã€‚

+   `split` (`Split` æˆ– `str`) â€” è¦åŠ è½½çš„æ•°æ®æ‹†åˆ†ã€‚å¦‚æœä¸º`None`ï¼Œå°†è¿”å›åŒ…å«æ‰€æœ‰æ‹†åˆ†çš„`dict`ï¼ˆé€šå¸¸ä¸º`datasets.Split.TRAIN`å’Œ`datasets.Split.TEST`ï¼‰ã€‚å¦‚æœç»™å®šï¼Œå°†è¿”å›å•ä¸ªæ•°æ®é›†ã€‚å¯ä»¥åƒåœ¨ tensorflow-datasets ä¸­ä¸€æ ·ç»„åˆå’ŒæŒ‡å®šæ‹†åˆ†ã€‚

+   `cache_dir` (`str`, *optional*) â€” è¯»å–/å†™å…¥æ•°æ®çš„ç›®å½•ã€‚é»˜è®¤ä¸º`"~/.cache/huggingface/datasets"`ã€‚

+   `features` (`Features`, *optional*) â€” è®¾ç½®æ­¤æ•°æ®é›†ä½¿ç”¨çš„ç‰¹å¾ç±»å‹ã€‚

+   `download_config` (DownloadConfig, *optional*) â€” ç‰¹å®šçš„ä¸‹è½½é…ç½®å‚æ•°ã€‚

+   `download_mode` (DownloadMode æˆ– `str`, é»˜è®¤ä¸º`REUSE_DATASET_IF_EXISTS`) â€” ä¸‹è½½/ç”Ÿæˆæ¨¡å¼ã€‚

+   `verification_mode` (VerificationMode æˆ– `str`, é»˜è®¤ä¸º`BASIC_CHECKS`) â€” ç¡®å®šå¯¹ä¸‹è½½/å¤„ç†çš„æ•°æ®é›†ä¿¡æ¯è¿è¡Œçš„æ£€æŸ¥ï¼ˆæ ¡éªŒå’Œ/å¤§å°/æ‹†åˆ†ç­‰ï¼‰çš„éªŒè¯æ¨¡å¼ã€‚

    æ·»åŠ äº 2.9.1

+   `ignore_verifications`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” å¿½ç•¥ä¸‹è½½/å¤„ç†çš„æ•°æ®é›†ä¿¡æ¯çš„éªŒè¯ï¼ˆæ ¡éªŒå’Œ/å¤§å°/æ‹†åˆ†/...ï¼‰ã€‚

    2.9.1 ä¸­å·²å¼ƒç”¨

    `ignore_verifications`åœ¨ç‰ˆæœ¬ 2.9.1 ä¸­å·²å¼ƒç”¨ï¼Œå¹¶å°†åœ¨ 3.0.0 ä¸­åˆ é™¤ã€‚è¯·æ”¹ç”¨`verification_mode`ã€‚

+   `keep_in_memory`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`None`ï¼‰â€” æ˜¯å¦å°†æ•°æ®é›†ä¿å­˜åœ¨å†…å­˜ä¸­ã€‚å¦‚æœä¸º`None`ï¼Œåˆ™é™¤éé€šè¿‡å°†`datasets.config.IN_MEMORY_MAX_SIZE`è®¾ç½®ä¸ºéé›¶æ¥æ˜ç¡®å¯ç”¨ï¼Œå¦åˆ™æ•°æ®é›†ä¸ä¼šä¿å­˜åœ¨å†…å­˜ä¸­ã€‚åœ¨ improve performance éƒ¨åˆ†ä¸­æŸ¥çœ‹æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

+   `save_infos`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” ä¿å­˜æ•°æ®é›†ä¿¡æ¯ï¼ˆæ ¡éªŒå’Œ/å¤§å°/æ‹†åˆ†/...ï¼‰ã€‚

+   `revision`ï¼ˆVersion æˆ–`str`ï¼Œ*å¯é€‰*ï¼‰â€” è¦åŠ è½½çš„æ•°æ®é›†è„šæœ¬çš„ç‰ˆæœ¬ã€‚ç”±äºæ•°æ®é›†åœ¨ Datasets Hub ä¸Šæœ‰è‡ªå·±çš„ git å­˜å‚¨åº“ï¼Œé»˜è®¤ç‰ˆæœ¬â€œmainâ€å¯¹åº”äºå®ƒä»¬çš„â€œmainâ€åˆ†æ”¯ã€‚æ‚¨å¯ä»¥é€šè¿‡ä½¿ç”¨æ•°æ®é›†å­˜å‚¨åº“çš„æäº¤ SHA æˆ– git æ ‡ç­¾æŒ‡å®šä¸é»˜è®¤â€œmainâ€ä¸åŒçš„ç‰ˆæœ¬ã€‚

+   `token`ï¼ˆ`str`æˆ–`bool`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œ Datasets Hub ä¸Šè¿œç¨‹æ–‡ä»¶çš„ Bearer ä»¤ç‰Œçš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º`True`æˆ–æœªæŒ‡å®šï¼Œåˆ™å°†ä»`"~/.huggingface"`è·å–ä»¤ç‰Œã€‚

+   `use_auth_token`ï¼ˆ`str`æˆ–`bool`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œ Datasets Hub ä¸Šè¿œç¨‹æ–‡ä»¶çš„ Bearer ä»¤ç‰Œçš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º`True`æˆ–æœªæŒ‡å®šï¼Œåˆ™å°†ä»`"~/.huggingface"`è·å–ä»¤ç‰Œã€‚

    2.14.0 ä¸­å·²å¼ƒç”¨

    `use_auth_token`å·²åœ¨ç‰ˆæœ¬ 2.14.0 ä¸­å¼ƒç”¨ï¼Œæ”¹ç”¨`token`ï¼Œå¹¶å°†åœ¨ 3.0.0 ä¸­åˆ é™¤ã€‚

+   `task`ï¼ˆ`str`ï¼‰â€” åœ¨è®­ç»ƒå’Œè¯„ä¼°æœŸé—´ä¸ºæ•°æ®é›†å‡†å¤‡çš„ä»»åŠ¡ã€‚å°†æ•°æ®é›†çš„ Features è½¬æ¢ä¸º`datasets.tasks`ä¸­è¯¦ç»†è¯´æ˜çš„æ ‡å‡†åŒ–åˆ—åå’Œç±»å‹ã€‚

    2.13.0 ä¸­å·²å¼ƒç”¨

    `task`åœ¨ç‰ˆæœ¬ 2.13.0 ä¸­å·²å¼ƒç”¨ï¼Œå¹¶å°†åœ¨ 3.0.0 ä¸­åˆ é™¤ã€‚

+   `streaming`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™ä¸ä¸‹è½½æ•°æ®æ–‡ä»¶ã€‚ç›¸åï¼Œå®ƒåœ¨è¿­ä»£æ•°æ®é›†æ—¶é€æ­¥æµå¼ä¼ è¾“æ•°æ®ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå°†è¿”å› IterableDataset æˆ– IterableDatasetDictã€‚

    è¯·æ³¨æ„ï¼Œæµå¼ä¼ è¾“é€‚ç”¨äºæ”¯æŒåƒ txtã€csvã€jsonl ç­‰å¯ä»¥è¿­ä»£çš„æ•°æ®æ ¼å¼çš„æ•°æ®é›†ã€‚ä¾‹å¦‚ï¼ŒJson æ–‡ä»¶å¯èƒ½ä¼šå®Œå…¨ä¸‹è½½ã€‚è¿˜æ”¯æŒä»è¿œç¨‹ zip æˆ– gzip æ–‡ä»¶è¿›è¡Œæµå¼ä¼ è¾“ï¼Œä½†ä¸æ”¯æŒå…¶ä»–å‹ç¼©æ ¼å¼ï¼Œå¦‚ rar å’Œ xzã€‚tgz æ ¼å¼ä¸å…è®¸æµå¼ä¼ è¾“ã€‚

+   `num_proc`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`None`ï¼‰â€” ä¸‹è½½å’Œæœ¬åœ°ç”Ÿæˆæ•°æ®é›†æ—¶çš„è¿›ç¨‹æ•°ã€‚é»˜è®¤æƒ…å†µä¸‹ç¦ç”¨å¤šè¿›ç¨‹ã€‚

    2.7.0 ä¸­æ·»åŠ 

+   `storage_options`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`None`ï¼‰â€” **å®éªŒæ€§**ã€‚è¦ä¼ é€’ç»™æ•°æ®é›†æ–‡ä»¶ç³»ç»Ÿåç«¯çš„é”®/å€¼å¯¹ï¼Œå¦‚æœæœ‰çš„è¯ã€‚

    2.11.0 ä¸­æ·»åŠ 

+   `trust_remote_code`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦å…è®¸ä½¿ç”¨æ•°æ®é›†è„šæœ¬åœ¨ Hub ä¸Šå®šä¹‰æ•°æ®é›†ã€‚æ­¤é€‰é¡¹åº”ä»…å¯¹æ‚¨ä¿¡ä»»çš„å­˜å‚¨åº“è®¾ç½®ä¸º`True`ï¼Œå¹¶ä¸”æ‚¨å·²é˜…è¯»äº†ä»£ç ï¼Œå› ä¸ºå®ƒå°†åœ¨æœ¬åœ°æœºå™¨ä¸Šæ‰§è¡Œ Hub ä¸Šå­˜åœ¨çš„ä»£ç ã€‚

    `trust_remote_code`å°†åœ¨ä¸‹ä¸€ä¸ªä¸»è¦ç‰ˆæœ¬ä¸­é»˜è®¤ä¸º Falseã€‚

    2.16.0 ä¸­æ·»åŠ 

+   *`*config_kwargs`ï¼ˆé¢å¤–çš„å…³é”®å­—å‚æ•°ï¼‰â€” è¦ä¼ é€’ç»™`BuilderConfig`å¹¶åœ¨ DatasetBuilder ä¸­ä½¿ç”¨çš„å…³é”®å­—å‚æ•°ã€‚

è¿”å›

Dataset æˆ– DatasetDict

+   å¦‚æœ`split`ä¸æ˜¯`None`ï¼šè¯·æ±‚çš„æ•°æ®é›†ï¼Œ

+   å¦‚æœ`split`ä¸º`None`ï¼Œåˆ™è¿”å›ä¸€ä¸ªåŒ…å«æ¯ä¸ªæ‹†åˆ†çš„ DatasetDictã€‚

æˆ– IterableDataset æˆ– IterableDatasetDictï¼šå¦‚æœ`streaming=True`

+   å¦‚æœ`split`ä¸æ˜¯`None`ï¼Œåˆ™è¯·æ±‚æ•°æ®é›†ã€‚

+   å¦‚æœ`split`ä¸º`None`ï¼Œåˆ™è¿”å›ä¸€ä¸ª`~datasets.streaming.IterableDatasetDict`ï¼Œå…¶ä¸­åŒ…å«æ¯ä¸ªæ‹†åˆ†ã€‚

ä» Hugging Face Hub åŠ è½½æ•°æ®é›†ï¼Œæˆ–è€…åŠ è½½æœ¬åœ°æ•°æ®é›†ã€‚

æ‚¨å¯ä»¥åœ¨[Hub](https://huggingface.co/datasets)ä¸Šæ‰¾åˆ°æ•°æ®é›†åˆ—è¡¨ï¼Œæˆ–ä½¿ç”¨`huggingface_hub.list_datasets`ã€‚

æ•°æ®é›†æ˜¯ä¸€ä¸ªåŒ…å«ä»¥ä¸‹å†…å®¹çš„ç›®å½•ï¼š

+   ä¸€äº›é€šç”¨æ ¼å¼çš„æ•°æ®æ–‡ä»¶ï¼ˆJSONã€CSVã€Parquetã€æ–‡æœ¬ç­‰ï¼‰ã€‚

+   ä»¥åŠå¯é€‰çš„æ•°æ®é›†è„šæœ¬ï¼Œå¦‚æœéœ€è¦ä¸€äº›ä»£ç æ¥è¯»å–æ•°æ®æ–‡ä»¶ã€‚è¿™ç”¨äºåŠ è½½ä»»ä½•ç±»å‹çš„æ ¼å¼æˆ–ç»“æ„ã€‚

è¯·æ³¨æ„ï¼Œæ•°æ®é›†è„šæœ¬ä¹Ÿå¯ä»¥ä»ä»»ä½•åœ°æ–¹ä¸‹è½½å’Œè¯»å–æ•°æ®æ–‡ä»¶ - å¦‚æœæ‚¨çš„æ•°æ®æ–‡ä»¶å·²ç»å­˜åœ¨åœ¨çº¿ã€‚

æ­¤å‡½æ•°åœ¨åå°æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

1.  å¦‚æœåº“ä¸­å°šæœªç¼“å­˜æ•°æ®é›†è„šæœ¬ï¼Œåˆ™ä»`path`ä¸‹è½½å¹¶å¯¼å…¥æ•°æ®é›†è„šæœ¬ã€‚

    å¦‚æœæ•°æ®é›†æ²¡æœ‰æ•°æ®é›†è„šæœ¬ï¼Œåˆ™ä¼šå¯¼å…¥ä¸€ä¸ªé€šç”¨æ•°æ®é›†è„šæœ¬ï¼ˆJSONã€CSVã€Parquetã€æ–‡æœ¬ç­‰ï¼‰ã€‚

    æ•°æ®é›†è„šæœ¬æ˜¯å®šä¹‰æ•°æ®é›†æ„å»ºå™¨çš„å°å‹ Python è„šæœ¬ã€‚å®ƒä»¬å®šä¹‰äº†æ•°æ®é›†çš„å¼•ç”¨ã€ä¿¡æ¯å’Œæ ¼å¼ï¼ŒåŒ…å«äº†åŸå§‹æ•°æ®æ–‡ä»¶çš„è·¯å¾„æˆ– URL ä»¥åŠä»åŸå§‹æ•°æ®æ–‡ä»¶åŠ è½½ç¤ºä¾‹çš„ä»£ç ã€‚

    æ‚¨å¯ä»¥åœ¨ Datasets [Hub](https://huggingface.co/datasets)ä¸­æ‰¾åˆ°å®Œæ•´çš„æ•°æ®é›†åˆ—è¡¨ã€‚

1.  è¿è¡Œæ•°æ®é›†è„šæœ¬ï¼Œè¯¥è„šæœ¬å°†ï¼š

    +   ä»åŸå§‹ URL ä¸‹è½½æ•°æ®é›†æ–‡ä»¶ï¼ˆå‚è§è„šæœ¬ï¼‰ï¼Œå¦‚æœæœ¬åœ°å°šæœªå¯ç”¨æˆ–å·²ç¼“å­˜ã€‚

    +   ä¸ºç¼“å­˜å¤„ç†å¹¶ç¼“å­˜æ•°æ®é›†ä¸­çš„ç±»å‹åŒ– Arrow è¡¨ã€‚

        Arrow è¡¨æ˜¯ä»»æ„é•¿çš„ã€å¸¦ç±»å‹çš„è¡¨ï¼Œå¯ä»¥å­˜å‚¨åµŒå¥—å¯¹è±¡ï¼Œå¹¶ä¸”å¯ä»¥æ˜ å°„åˆ° numpy/pandas/python é€šç”¨ç±»å‹ã€‚å®ƒä»¬å¯ä»¥ç›´æ¥ä»ç£ç›˜è®¿é—®ï¼ŒåŠ è½½åˆ° RAM ä¸­ï¼Œç”šè‡³é€šè¿‡ç½‘ç»œæµå¼ä¼ è¾“ã€‚

1.  è¿”å›ä»`split`ä¸­è¯·æ±‚çš„æ‹†åˆ†æ„å»ºçš„æ•°æ®é›†ï¼ˆé»˜è®¤ï¼šå…¨éƒ¨ï¼‰ã€‚

è¿˜å…è®¸ä»æœ¬åœ°ç›®å½•æˆ– Hugging Face Hub ä¸Šçš„æ•°æ®é›†å­˜å‚¨åº“åŠ è½½æ•°æ®é›†ï¼Œè€Œæ— éœ€æ•°æ®é›†è„šæœ¬ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒä¼šè‡ªåŠ¨ä»ç›®å½•æˆ–æ•°æ®é›†å­˜å‚¨åº“ä¸­åŠ è½½æ‰€æœ‰æ•°æ®æ–‡ä»¶ã€‚

ç¤ºä¾‹ï¼š

ä» Hugging Face Hub åŠ è½½æ•°æ®é›†ï¼š

```py
>>> from datasets import load_dataset
>>> ds = load_dataset('rotten_tomatoes', split='train')

# Map data files to splits
>>> data_files = {'train': 'train.csv', 'test': 'test.csv'}
>>> ds = load_dataset('namespace/your_dataset_name', data_files=data_files)
```

åŠ è½½æœ¬åœ°æ•°æ®é›†ï¼š

```py
# Load a CSV file
>>> from datasets import load_dataset
>>> ds = load_dataset('csv', data_files='path/to/local/my_dataset.csv')

# Load a JSON file
>>> from datasets import load_dataset
>>> ds = load_dataset('json', data_files='path/to/local/my_dataset.json')

# Load from a local loading script
>>> from datasets import load_dataset
>>> ds = load_dataset('path/to/local/loading_script/loading_script.py', split='train')
```

åŠ è½½ä¸€ä¸ª IterableDatasetï¼š

```py
>>> from datasets import load_dataset
>>> ds = load_dataset('rotten_tomatoes', split='train', streaming=True)
```

ä½¿ç”¨`ImageFolder`æ•°æ®é›†æ„å»ºå™¨åŠ è½½å›¾åƒæ•°æ®é›†ï¼š

```py
>>> from datasets import load_dataset
>>> ds = load_dataset('imagefolder', data_dir='/path/to/images', split='train')
```

#### `datasets.load_from_disk`

[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/load.py#L2600)

```py
( dataset_path: str fs = 'deprecated' keep_in_memory: Optional = None storage_options: Optional = None ) â†’ export const metadata = 'undefined';Dataset or DatasetDict
```

å‚æ•°

+   `dataset_path`ï¼ˆ`str`ï¼‰â€”æ•°æ®é›†å°†ä»ä¸­åŠ è½½çš„ Dataset æˆ– DatasetDict ç›®å½•çš„è·¯å¾„ï¼ˆä¾‹å¦‚`"dataset/train"`ï¼‰æˆ–è¿œç¨‹ URIï¼ˆä¾‹å¦‚`"s3://my-bucket/dataset/train"`ï¼‰ã€‚

+   `fs`ï¼ˆ`~filesystems.S3FileSystem`æˆ–`fsspec.spec.AbstractFileSystem`ï¼Œ*å¯é€‰*ï¼‰â€”ç”¨äºä»è¿œç¨‹æ–‡ä»¶ç³»ç»Ÿä¸‹è½½æ–‡ä»¶çš„è¿œç¨‹æ–‡ä»¶ç³»ç»Ÿçš„å®ä¾‹ã€‚

    åœ¨ 2.9.0 ä¸­å¼ƒç”¨

    `fs`åœ¨ 2.9.0 ç‰ˆæœ¬ä¸­å·²å¼ƒç”¨ï¼Œå¹¶å°†åœ¨ 3.0.0 ä¸­ç§»é™¤ã€‚è¯·æ”¹ç”¨`storage_options`ï¼Œä¾‹å¦‚`storage_options=fs.storage_options`ã€‚

+   `keep_in_memory`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`None`ï¼‰â€”æ˜¯å¦å°†æ•°æ®é›†å¤åˆ¶åˆ°å†…å­˜ä¸­ã€‚å¦‚æœä¸º`None`ï¼Œé™¤éé€šè¿‡å°†`datasets.config.IN_MEMORY_MAX_SIZE`è®¾ç½®ä¸ºéé›¶æ¥æ˜ç¡®å¯ç”¨ï¼Œå¦åˆ™æ•°æ®é›†ä¸ä¼šè¢«å¤åˆ¶åˆ°å†…å­˜ä¸­ã€‚åœ¨ improve performance éƒ¨åˆ†ä¸­æŸ¥çœ‹æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

+   `storage_options`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼‰â€”è¦ä¼ é€’ç»™æ–‡ä»¶ç³»ç»Ÿåç«¯çš„é”®/å€¼å¯¹ï¼Œå¦‚æœæœ‰çš„è¯ã€‚

    2.9.0 ç‰ˆæœ¬ä¸­æ·»åŠ 

è¿”å›

Dataset æˆ– DatasetDict

+   å¦‚æœ`dataset_path`æ˜¯æ•°æ®é›†ç›®å½•çš„è·¯å¾„ï¼Œåˆ™è¿”å›è¯·æ±‚çš„æ•°æ®é›†ã€‚

+   å¦‚æœ`dataset_path`æ˜¯æ•°æ®é›†å­—å…¸ç›®å½•çš„è·¯å¾„ï¼Œåˆ™è¿”å›ä¸€ä¸ªåŒ…å«æ¯ä¸ªæ‹†åˆ†çš„ DatasetDictã€‚

åŠ è½½å…ˆå‰ä½¿ç”¨ save_to_disk()ä¿å­˜çš„æ•°æ®é›†ï¼Œä»æ•°æ®é›†ç›®å½•ä¸­åŠ è½½ï¼Œæˆ–è€…ä½¿ç”¨`fsspec.spec.AbstractFileSystem`çš„ä»»ä½•å®ç°ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from datasets import load_from_disk
>>> ds = load_from_disk('path/to/dataset/directory')
```

#### `datasets.load_dataset_builder`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/load.py#L2089)

```py
( path: str name: Optional = None data_dir: Optional = None data_files: Union = None cache_dir: Optional = None features: Optional = None download_config: Optional = None download_mode: Union = None revision: Union = None token: Union = None use_auth_token = 'deprecated' storage_options: Optional = None trust_remote_code: Optional = None _require_default_config_name = True **config_kwargs )
```

å‚æ•°

+   `path` (`str`) â€” æ•°æ®é›†çš„è·¯å¾„æˆ–åç§°ã€‚æ ¹æ®`path`ï¼Œæ‰€ä½¿ç”¨çš„æ•°æ®é›†æ„å»ºå™¨æ¥è‡ªé€šç”¨æ•°æ®é›†è„šæœ¬ï¼ˆJSONã€CSVã€Parquetã€æ–‡æœ¬ç­‰ï¼‰æˆ–æ•°æ®é›†ç›®å½•ä¸­çš„æ•°æ®é›†è„šæœ¬ï¼ˆpython æ–‡ä»¶ï¼‰ã€‚

    å¯¹äºæœ¬åœ°æ•°æ®é›†ï¼š

    +   å¦‚æœ`path`æ˜¯æœ¬åœ°ç›®å½•ï¼ˆä»…åŒ…å«æ•°æ®æ–‡ä»¶ï¼‰-> æ ¹æ®ç›®å½•å†…å®¹åŠ è½½é€šç”¨æ•°æ®é›†æ„å»ºå™¨ï¼ˆcsvã€jsonã€æ–‡æœ¬ç­‰ï¼‰ï¼Œä¾‹å¦‚`'./path/to/directory/with/my/csv/data'`ã€‚

    +   å¦‚æœ`path`æ˜¯æœ¬åœ°æ•°æ®é›†è„šæœ¬æˆ–åŒ…å«æœ¬åœ°æ•°æ®é›†è„šæœ¬çš„ç›®å½•ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰-> ä»æ•°æ®é›†è„šæœ¬åŠ è½½æ•°æ®é›†æ„å»ºå™¨ï¼Œä¾‹å¦‚`'./dataset/squad'`æˆ–`'./dataset/squad/squad.py'`ã€‚

    å¯¹äº Hugging Face Hub ä¸Šçš„æ•°æ®é›†ï¼ˆä½¿ç”¨`huggingface_hub.list_datasets`åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†ï¼‰

    +   å¦‚æœ`path`æ˜¯ HF Hub ä¸Šçš„æ•°æ®é›†å­˜å‚¨åº“ï¼ˆä»…åŒ…å«æ•°æ®æ–‡ä»¶ï¼‰-> æ ¹æ®å­˜å‚¨åº“å†…å®¹åŠ è½½é€šç”¨æ•°æ®é›†æ„å»ºå™¨ï¼ˆcsvã€æ–‡æœ¬ç­‰ï¼‰ï¼Œä¾‹å¦‚`'username/dataset_name'`ï¼ŒåŒ…å«æ‚¨çš„æ•°æ®æ–‡ä»¶çš„ HF Hub ä¸Šçš„æ•°æ®é›†å­˜å‚¨åº“ã€‚

    +   å¦‚æœ`path`æ˜¯ HF Hub ä¸Šå¸¦æœ‰æ•°æ®é›†è„šæœ¬çš„æ•°æ®é›†å­˜å‚¨åº“ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰-> ä»æ•°æ®é›†å­˜å‚¨åº“ä¸­çš„æ•°æ®é›†è„šæœ¬åŠ è½½æ•°æ®é›†æ„å»ºå™¨ï¼Œä¾‹å¦‚`glue`ã€`squad`ã€`'username/dataset_name'`ï¼ŒåŒ…å«æ•°æ®é›†è„šæœ¬`'dataset_name.py'`çš„ HF Hub ä¸Šçš„æ•°æ®é›†å­˜å‚¨åº“ã€‚

+   `name` (`str`, *å¯é€‰*) â€” å®šä¹‰æ•°æ®é›†é…ç½®çš„åç§°ã€‚

+   `data_dir` (`str`, *å¯é€‰*) â€” å®šä¹‰æ•°æ®é›†é…ç½®çš„`data_dir`ã€‚å¦‚æœä¸ºé€šç”¨æ„å»ºå™¨ï¼ˆcsvã€æ–‡æœ¬ç­‰ï¼‰æˆ– Hub æ•°æ®é›†æŒ‡å®šäº†`data_dir`ï¼Œå¹¶ä¸”`data_files`ä¸º`None`ï¼Œåˆ™è¡Œä¸ºç­‰åŒäºå°†`os.path.join(data_dir, **)`ä½œä¸º`data_files`ä¼ é€’ï¼Œä»¥å¼•ç”¨ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚

+   `data_files` (`str`æˆ–`Sequence`æˆ–`Mapping`ï¼Œ*å¯é€‰*) â€” æºæ•°æ®æ–‡ä»¶çš„è·¯å¾„ã€‚

+   `cache_dir` (`str`, *å¯é€‰*) â€” è¯»å–/å†™å…¥æ•°æ®çš„ç›®å½•ã€‚é»˜è®¤ä¸º`"~/.cache/huggingface/datasets"`ã€‚

+   `features`ï¼ˆFeaturesï¼Œ*å¯é€‰*ï¼‰ â€” è®¾ç½®ç”¨äºæ­¤æ•°æ®é›†çš„ç‰¹å¾ç±»å‹ã€‚

+   `download_config`ï¼ˆDownloadConfigï¼Œ*å¯é€‰*ï¼‰ â€” ç‰¹å®šçš„ä¸‹è½½é…ç½®å‚æ•°ã€‚

+   `download_mode`ï¼ˆDownloadMode æˆ–`str`ï¼Œé»˜è®¤ä¸º`REUSE_DATASET_IF_EXISTS`ï¼‰ â€” ä¸‹è½½/ç”Ÿæˆæ¨¡å¼ã€‚

+   `revision`ï¼ˆVersion æˆ–`str`ï¼Œ*å¯é€‰*ï¼‰ â€” è¦åŠ è½½çš„æ•°æ®é›†è„šæœ¬çš„ç‰ˆæœ¬ã€‚ç”±äºæ•°æ®é›†åœ¨ Datasets Hub ä¸Šæœ‰è‡ªå·±çš„ git å­˜å‚¨åº“ï¼Œé»˜è®¤ç‰ˆæœ¬â€œmainâ€å¯¹åº”äºå®ƒä»¬çš„â€œmainâ€åˆ†æ”¯ã€‚æ‚¨å¯ä»¥é€šè¿‡ä½¿ç”¨æ•°æ®é›†å­˜å‚¨åº“çš„æäº¤ SHA æˆ– git æ ‡ç­¾æŒ‡å®šä¸é»˜è®¤â€œmainâ€ä¸åŒçš„ç‰ˆæœ¬ã€‚

+   `token` (`str`æˆ–`bool`ï¼Œ*å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶åœ¨ Datasets Hub ä¸Šçš„ Bearer ä»¤ç‰Œçš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º`True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œåˆ™å°†ä»`"~/.huggingface"`è·å–ä»¤ç‰Œã€‚

+   `use_auth_token` (`str` æˆ– `bool`, *å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶åœ¨æ•°æ®é›† Hub ä¸Šçš„ Bearer ä»¤ç‰Œçš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä» `"~/.huggingface"` è·å–ä»¤ç‰Œã€‚

    åœ¨ 2.14.0 ä¸­å·²å¼ƒç”¨

    `use_auth_token` åœ¨ 2.14.0 ä¸­å·²å¼ƒç”¨ï¼Œæ¨èä½¿ç”¨ `token`ï¼Œå¹¶å°†åœ¨ 3.0.0 ä¸­ç§»é™¤ã€‚

+   `storage_options` (`dict`, *å¯é€‰*, é»˜è®¤ä¸º `None`) â€” **å®éªŒæ€§**ã€‚è¦ä¼ é€’ç»™æ•°æ®é›†æ–‡ä»¶ç³»ç»Ÿåç«¯çš„é”®/å€¼å¯¹ï¼Œå¦‚æœæœ‰çš„è¯ã€‚

    åœ¨ 2.11.0 ä¸­æ·»åŠ 

+   `trust_remote_code` (`bool`, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å…è®¸åœ¨ Hub ä¸Šä½¿ç”¨æ•°æ®é›†è„šæœ¬å®šä¹‰æ•°æ®é›†ã€‚æ­¤é€‰é¡¹åº”ä»…åœ¨æ‚¨ä¿¡ä»»çš„å­˜å‚¨åº“ä¸­è®¾ç½®ä¸º `True`ï¼Œå¹¶ä¸”æ‚¨å·²é˜…è¯»äº†ä»£ç ï¼Œå› ä¸ºå®ƒå°†åœ¨æœ¬åœ°æœºå™¨ä¸Šæ‰§è¡Œ Hub ä¸Šå­˜åœ¨çš„ä»£ç ã€‚

    `trust_remote_code` å°†åœ¨ä¸‹ä¸€ä¸ªä¸»è¦ç‰ˆæœ¬ä¸­é»˜è®¤ä¸º Falseã€‚

    åœ¨ 2.16.0 ä¸­æ·»åŠ 

+   *`*config_kwargs` (é¢å¤–çš„å…³é”®å­—å‚æ•°) â€” è¦ä¼ é€’ç»™ BuilderConfig å¹¶åœ¨ DatasetBuilder ä¸­ä½¿ç”¨çš„å…³é”®å­—å‚æ•°ã€‚

ä» Hugging Face Hub åŠ è½½æ•°æ®é›†æ„å»ºå™¨ï¼Œæˆ–æœ¬åœ°æ•°æ®é›†ã€‚æ•°æ®é›†æ„å»ºå™¨å¯ç”¨äºæ£€æŸ¥æ„å»ºæ•°æ®é›†æ‰€éœ€çš„ä¸€èˆ¬ä¿¡æ¯ï¼ˆç¼“å­˜ç›®å½•ã€é…ç½®ã€æ•°æ®é›†ä¿¡æ¯ç­‰ï¼‰ï¼Œè€Œæ— éœ€ä¸‹è½½æ•°æ®é›†æœ¬èº«ã€‚

æ‚¨å¯ä»¥åœ¨ [Hub](https://huggingface.co/datasets) ä¸Šæ‰¾åˆ°æ•°æ®é›†åˆ—è¡¨ï¼Œæˆ–ä½¿ç”¨ `huggingface_hub.list_datasets`ã€‚

æ•°æ®é›†æ˜¯åŒ…å«ä»¥ä¸‹å†…å®¹çš„ç›®å½•ï¼š

+   ä¸€äº›é€šç”¨æ ¼å¼çš„æ•°æ®æ–‡ä»¶ï¼ˆJSONã€CSVã€Parquetã€æ–‡æœ¬ç­‰ï¼‰

+   ä»¥åŠå¯é€‰çš„æ•°æ®é›†è„šæœ¬ï¼Œå¦‚æœéœ€è¦ä¸€äº›ä»£ç æ¥è¯»å–æ•°æ®æ–‡ä»¶ã€‚è¿™ç”¨äºåŠ è½½ä»»ä½•æ ¼å¼æˆ–ç»“æ„ã€‚

è¯·æ³¨æ„ï¼Œæ•°æ®é›†è„šæœ¬ä¹Ÿå¯ä»¥ä»ä»»ä½•åœ°æ–¹ä¸‹è½½å’Œè¯»å–æ•°æ®æ–‡ä»¶ - å¦‚æœæ‚¨çš„æ•°æ®æ–‡ä»¶å·²ç»å­˜åœ¨åœ¨çº¿ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from datasets import load_dataset_builder
>>> ds_builder = load_dataset_builder('rotten_tomatoes')
>>> ds_builder.info.features
{'label': ClassLabel(num_classes=2, names=['neg', 'pos'], id=None),
 'text': Value(dtype='string', id=None)}
```

#### `datasets.get_dataset_config_names`

[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/inspect.py#L291)

```py
( path: str revision: Union = None download_config: Optional = None download_mode: Union = None dynamic_modules_path: Optional = None data_files: Union = None **download_kwargs )
```

å‚æ•°

+   `path` (`str`) â€” åŒ…å«æ•°æ®é›†æ„å»ºå™¨çš„æ•°æ®é›†å¤„ç†è„šæœ¬çš„è·¯å¾„ã€‚å¯ä»¥æ˜¯ï¼š

    +   ç”¨äºå¤„ç†è„šæœ¬çš„æœ¬åœ°è·¯å¾„æˆ–åŒ…å«è„šæœ¬çš„ç›®å½•çš„æœ¬åœ°è·¯å¾„ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰ï¼Œä¾‹å¦‚ `'./dataset/squad'` æˆ– `'./dataset/squad/squad.py'`

    +   åœ¨ Hugging Face Hub ä¸Šçš„æ•°æ®é›†æ ‡è¯†ç¬¦ï¼ˆä½¿ç”¨ datasets.list_datasets() åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†å’Œ IDï¼‰ä¾‹å¦‚ `'squad'`ã€`'glue'` æˆ– `'openai/webtext'`

+   `revision` (`Union[str, datasets.Version]`, *å¯é€‰*) â€” å¦‚æœæŒ‡å®šï¼Œæ•°æ®é›†æ¨¡å—å°†ä»æ­¤ç‰ˆæœ¬çš„æ•°æ®é›†å­˜å‚¨åº“åŠ è½½ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼š

    +   å®ƒè®¾ç½®ä¸ºæœ¬åœ°ç‰ˆæœ¬çš„åº“ã€‚

    +   å¦‚æœåœ¨æœ¬åœ°ç‰ˆæœ¬çš„åº“ä¸­ä¸å¯ç”¨ï¼Œå®ƒè¿˜å°†å°è¯•ä»ä¸»åˆ†æ”¯åŠ è½½ã€‚æŒ‡å®šä¸æœ¬åœ°ç‰ˆæœ¬çš„åº“ä¸åŒçš„ç‰ˆæœ¬å¯èƒ½ä¼šå¯¼è‡´å…¼å®¹æ€§é—®é¢˜ã€‚

+   `download_config` (DownloadConfig, *å¯é€‰*) â€” ç‰¹å®šçš„ä¸‹è½½é…ç½®å‚æ•°ã€‚

+   `download_mode` (DownloadMode æˆ– `str`, é»˜è®¤ä¸º `REUSE_DATASET_IF_EXISTS`) â€” ä¸‹è½½/ç”Ÿæˆæ¨¡å¼ã€‚

+   `dynamic_modules_path` (`str`, é»˜è®¤ä¸º `~/.cache/huggingface/modules/datasets_modules`) â€” åŠ¨æ€æ¨¡å—ä¿å­˜çš„å¯é€‰è·¯å¾„ã€‚å®ƒå¿…é¡»å·²ç»ä½¿ç”¨ `init_dynamic_modules` è¿›è¡Œåˆå§‹åŒ–ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ•°æ®é›†å’ŒæŒ‡æ ‡å­˜å‚¨åœ¨ `datasets_modules` æ¨¡å—å†…ã€‚

+   `data_files` (`Union[Dict, List, str]`, *å¯é€‰*) â€” å®šä¹‰æ•°æ®é›†é…ç½®çš„ data_filesã€‚

+   *`*download_kwargs`ï¼ˆé¢å¤–çš„å…³é”®å­—å‚æ•°ï¼‰ â€” ç”¨äºè¦†ç›–æä¾›çš„ `download_config` ä¸­å±æ€§çš„ DownloadConfig çš„å¯é€‰å±æ€§ï¼Œä¾‹å¦‚ `token`ã€‚

è·å–ç‰¹å®šæ•°æ®é›†çš„å¯ç”¨é…ç½®åç§°åˆ—è¡¨ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from datasets import get_dataset_config_names
>>> get_dataset_config_names("glue")
['cola',
 'sst2',
 'mrpc',
 'qqp',
 'stsb',
 'mnli',
 'mnli_mismatched',
 'mnli_matched',
 'qnli',
 'rte',
 'wnli',
 'ax']
```

#### `datasets.get_dataset_infos`

[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/inspect.py#L205)

```py
( path: str data_files: Union = None download_config: Optional = None download_mode: Union = None revision: Union = None token: Union = None use_auth_token = 'deprecated' **config_kwargs )
```

å‚æ•°

+   `path` (`str`) â€” æ•°æ®é›†å¤„ç†è„šæœ¬çš„è·¯å¾„ä¸æ•°æ®é›†æ„å»ºå™¨ã€‚å¯ä»¥æ˜¯ï¼š

    +   æœ¬åœ°å¤„ç†è„šæœ¬çš„è·¯å¾„æˆ–åŒ…å«è„šæœ¬çš„ç›®å½•ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰ï¼Œä¾‹å¦‚ `'./dataset/squad'` æˆ– `'./dataset/squad/squad.py'`

    +   Hugging Face Hub ä¸Šçš„æ•°æ®é›†æ ‡è¯†ç¬¦ï¼ˆä½¿ç”¨ datasets.list_datasets() åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†å’Œæ ‡è¯†ç¬¦ï¼‰ï¼Œä¾‹å¦‚ `'squad'`ã€`'glue'` æˆ– `'openai/webtext'`

+   `revision` (`Union[str, datasets.Version]`, *optional*) â€” å¦‚æœæŒ‡å®šï¼Œæ•°æ®é›†æ¨¡å—å°†ä»è¯¥ç‰ˆæœ¬çš„æ•°æ®é›†å­˜å‚¨åº“ä¸­åŠ è½½ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼š

    +   å®ƒè®¾ç½®ä¸ºåº“çš„æœ¬åœ°ç‰ˆæœ¬ã€‚

    +   å¦‚æœåœ¨åº“çš„æœ¬åœ°ç‰ˆæœ¬ä¸­ä¸å¯ç”¨ï¼Œå®ƒè¿˜ä¼šå°è¯•ä»ä¸»åˆ†æ”¯åŠ è½½ã€‚æŒ‡å®šä¸åº“çš„æœ¬åœ°ç‰ˆæœ¬ä¸åŒçš„ç‰ˆæœ¬å¯èƒ½ä¼šå¯¼è‡´å…¼å®¹æ€§é—®é¢˜ã€‚

+   `download_config` (DownloadConfig, *optional*) â€” å…·ä½“çš„ä¸‹è½½é…ç½®å‚æ•°ã€‚

+   `download_mode` (DownloadMode æˆ– `str`ï¼Œé»˜è®¤ä¸º `REUSE_DATASET_IF_EXISTS`) â€” ä¸‹è½½/ç”Ÿæˆæ¨¡å¼ã€‚

+   `data_files` (`Union[Dict, List, str]`, *optional*) â€” å®šä¹‰æ•°æ®é›†é…ç½®çš„æ•°æ®æ–‡ä»¶ã€‚

+   `token` (`str` æˆ– `bool`, *optional*) â€” ç”¨ä½œæ•°æ®é›†ä¸­è¿œç¨‹æ–‡ä»¶çš„ Bearer token çš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä» `"~/.huggingface"` è·å–ä»¤ç‰Œã€‚

+   `use_auth_token` (`str` æˆ– `bool`, *optional*) â€” ç”¨ä½œæ•°æ®é›†ä¸­è¿œç¨‹æ–‡ä»¶çš„ Bearer token çš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä» `"~/.huggingface"` è·å–ä»¤ç‰Œã€‚

    åœ¨ 2.14.0 ä¸­å·²å¼ƒç”¨

    `use_auth_token` åœ¨ 2.14.0 ç‰ˆæœ¬ä¸­å·²å¼ƒç”¨ï¼Œå°†åœ¨ 3.0.0 ä¸­ç§»é™¤ã€‚

+   *`*config_kwargs`ï¼ˆé¢å¤–çš„å…³é”®å­—å‚æ•°ï¼‰ â€” ç”¨äºè¦†ç›–æä¾›çš„å±æ€§çš„æ„å»ºå™¨ç±»çš„å¯é€‰å±æ€§ã€‚

è·å–å…³äºæ•°æ®é›†çš„å…ƒä¿¡æ¯ï¼Œè¿”å›ä¸€ä¸ªå°†é…ç½®åç§°æ˜ å°„åˆ° DatasetInfoDict çš„å­—å…¸ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from datasets import get_dataset_infos
>>> get_dataset_infos('rotten_tomatoes')
{'default': DatasetInfo(description="Movie Review Dataset.
 is a dataset of containing 5,331 positive and 5,331 negative processed
ences from Rotten Tomatoes movie reviews...), ...}
```

#### `datasets.get_dataset_split_names`

[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/inspect.py#L507)

```py
( path: str config_name: Optional = None data_files: Union = None download_config: Optional = None download_mode: Union = None revision: Union = None token: Union = None use_auth_token = 'deprecated' **config_kwargs )
```

å‚æ•°

+   `path` (`str`) â€” æ•°æ®é›†å¤„ç†è„šæœ¬çš„è·¯å¾„ä¸æ•°æ®é›†æ„å»ºå™¨ã€‚å¯ä»¥æ˜¯ï¼š

    +   æœ¬åœ°å¤„ç†è„šæœ¬çš„è·¯å¾„æˆ–åŒ…å«è„šæœ¬çš„ç›®å½•ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰ï¼Œä¾‹å¦‚ `'./dataset/squad'` æˆ– `'./dataset/squad/squad.py'`

    +   Hugging Face Hub ä¸Šçš„æ•°æ®é›†æ ‡è¯†ç¬¦ï¼ˆä½¿ç”¨ datasets.list_datasets() åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†å’Œæ ‡è¯†ç¬¦ï¼‰ï¼Œä¾‹å¦‚ `'squad'`ã€`'glue'` æˆ– `'openai/webtext'`

+   `config_name` (`str`, *optional*) â€” å®šä¹‰æ•°æ®é›†é…ç½®çš„åç§°ã€‚

+   `data_files` (`str` æˆ– `Sequence` æˆ– `Mapping`, *optional*) â€” æºæ•°æ®æ–‡ä»¶çš„è·¯å¾„ã€‚

+   `download_config` (DownloadConfig, *optional*) â€” å…·ä½“çš„ä¸‹è½½é…ç½®å‚æ•°ã€‚

+   `download_mode` (DownloadMode æˆ– `str`ï¼Œé»˜è®¤ä¸º `REUSE_DATASET_IF_EXISTS`) â€” ä¸‹è½½/ç”Ÿæˆæ¨¡å¼ã€‚

+   `revision` (Version æˆ– `str`, *optional*) â€” è¦åŠ è½½çš„æ•°æ®é›†è„šæœ¬çš„ç‰ˆæœ¬ã€‚ç”±äºæ•°æ®é›†åœ¨æ•°æ®é›† Hub ä¸Šæœ‰è‡ªå·±çš„ git å­˜å‚¨åº“ï¼Œé»˜è®¤ç‰ˆæœ¬â€œmainâ€å¯¹åº”äºå®ƒä»¬çš„â€œmainâ€åˆ†æ”¯ã€‚æ‚¨å¯ä»¥é€šè¿‡ä½¿ç”¨æ•°æ®é›†å­˜å‚¨åº“çš„æäº¤ SHA æˆ– git æ ‡ç­¾æŒ‡å®šä¸é»˜è®¤â€œmainâ€ä¸åŒçš„ç‰ˆæœ¬ã€‚

+   `token` (`str` æˆ– `bool`, *optional*) â€” ç”¨ä½œæ•°æ®é›†ä¸­è¿œç¨‹æ–‡ä»¶çš„ Bearer ä»¤ç‰Œçš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä» `"~/.huggingface"` è·å–ä»¤ç‰Œã€‚

+   `use_auth_token` (`str` æˆ– `bool`, *optional*) â€” ç”¨ä½œæ•°æ®é›†ä¸­è¿œç¨‹æ–‡ä»¶çš„ Bearer ä»¤ç‰Œçš„å¯é€‰å­—ç¬¦ä¸²æˆ–å¸ƒå°”å€¼ã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä» `"~/.huggingface"` è·å–ä»¤ç‰Œã€‚

    åœ¨ 2.14.0 ä¸­å·²å¼ƒç”¨

    `use_auth_token` åœ¨ç‰ˆæœ¬ 2.14.0 ä¸­å·²å¼ƒç”¨ï¼Œæ¨èä½¿ç”¨ `token`ï¼Œå¹¶å°†åœ¨ 3.0.0 ä¸­ç§»é™¤ã€‚

+   *`*config_kwargs` (é¢å¤–çš„å…³é”®å­—å‚æ•°) â€” ç”¨äºæ„å»ºå™¨ç±»çš„å¯é€‰å±æ€§ï¼Œå¦‚æœæä¾›äº†è¿™äº›å±æ€§ï¼Œåˆ™ä¼šè¦†ç›–è¿™äº›å±æ€§ã€‚

è·å–ç‰¹å®šé…ç½®å’Œæ•°æ®é›†çš„å¯ç”¨æ‹†åˆ†åˆ—è¡¨ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from datasets import get_dataset_split_names
>>> get_dataset_split_names('rotten_tomatoes')
['train', 'validation', 'test']
```

#### `datasets.inspect_dataset`

[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/inspect.py#L124)

```py
( path: str local_path: str download_config: Optional = None **download_kwargs )
```

å‚æ•°

+   `path` (`str`) â€” æ•°æ®é›†å¤„ç†è„šæœ¬çš„è·¯å¾„ï¼Œä¸æ•°æ®é›†æ„å»ºå™¨ä¸€èµ·ã€‚å¯ä»¥æ˜¯ï¼š

    +   å¤„ç†è„šæœ¬çš„æœ¬åœ°è·¯å¾„æˆ–åŒ…å«è„šæœ¬çš„ç›®å½•çš„æœ¬åœ°è·¯å¾„ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰ï¼Œä¾‹å¦‚ `'./dataset/squad'` æˆ– `'./dataset/squad/squad.py'`ã€‚

    +   Hugging Face Hub ä¸Šçš„æ•°æ®é›†æ ‡è¯†ç¬¦ï¼ˆä½¿ç”¨ list_datasets() åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†å’Œ IDï¼‰ä¾‹å¦‚ `'squad'`, `'glue'` æˆ– `'openai/webtext'`ã€‚

+   `local_path` (`str`) â€” å°†æ•°æ®é›†è„šæœ¬å¤åˆ¶åˆ°çš„æœ¬åœ°æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚

+   `download_config` (DownloadConfig, *optional*) â€” å…·ä½“çš„ä¸‹è½½é…ç½®å‚æ•°ã€‚

+   *`*download_kwargs` (é¢å¤–çš„å…³é”®å­—å‚æ•°) â€” ç”¨äº DownloadConfig çš„å¯é€‰å‚æ•°ï¼Œå¦‚æœæä¾›äº†è¿™äº›å‚æ•°ï¼Œåˆ™ä¼šè¦†ç›– `download_config` çš„å±æ€§ã€‚

é€šè¿‡å°†æ•°æ®é›†è„šæœ¬å¤åˆ¶åˆ°æœ¬åœ°é©±åŠ¨å™¨ä¸Šçš„æœ¬åœ°è·¯å¾„æ¥å…è®¸æ£€æŸ¥/ä¿®æ”¹æ•°æ®é›†è„šæœ¬ã€‚

## æŒ‡æ ‡

æŒ‡æ ‡åœ¨ ğŸ¤— Datasets ä¸­å·²å¼ƒç”¨ã€‚è¦äº†è§£æœ‰å…³å¦‚ä½•ä½¿ç”¨æŒ‡æ ‡çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹åº“ ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index)! é™¤äº†æŒ‡æ ‡ä¹‹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥æ‰¾åˆ°æ›´å¤šç”¨äºè¯„ä¼°æ¨¡å‹å’Œæ•°æ®é›†çš„å·¥å…·ã€‚

#### `datasets.list_metrics`

[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/inspect.py#L85)

```py
( with_community_metrics = True with_details = False )
```

å‚æ•°

+   `with_community_metrics` (`bool`, optional, default `True`) â€” åŒ…æ‹¬ç¤¾åŒºæä¾›çš„æŒ‡æ ‡ã€‚

+   `with_details` (`bool`, optional, default `False`) â€” è¿”å›æŒ‡æ ‡çš„å®Œæ•´è¯¦æƒ…è€Œä¸ä»…ä»…æ˜¯ç®€ç§°ã€‚

åˆ—å‡ºåœ¨ Hugging Face Hub ä¸Šå¯ç”¨çš„æ‰€æœ‰æŒ‡æ ‡è„šæœ¬ã€‚

åœ¨ 2.5.0 ä¸­å·²å¼ƒç”¨

è¯·æ”¹ç”¨ *evaluate.list_evaluation_modules*ï¼Œæ¥è‡ªæ–°åº“ ğŸ¤— Evaluate: [`huggingface.co/docs/evaluate`](https://huggingface.co/docs/evaluate)

ç¤ºä¾‹ï¼š

```py
>>> from datasets import list_metrics
>>> list_metrics()
['accuracy',
 'bertscore',
 'bleu',
 'bleurt',
 'cer',
 'chrf',
 ...
]
```

#### `datasets.load_metric`

[< source >](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/load.py#L1992)

```py
( path: str config_name: Optional = None process_id: int = 0 num_process: int = 1 cache_dir: Optional = None experiment_id: Optional = None keep_in_memory: bool = False download_config: Optional = None download_mode: Union = None revision: Union = None trust_remote_code: Optional = None **metric_init_kwargs )
```

å‚æ•°

+   `path` (`str`) â€” åŒ…å«æŒ‡æ ‡æ„å»ºå™¨çš„æŒ‡æ ‡å¤„ç†è„šæœ¬çš„è·¯å¾„ã€‚å¯ä»¥æ˜¯ï¼š

    +   å¤„ç†è„šæœ¬çš„æœ¬åœ°è·¯å¾„æˆ–åŒ…å«è„šæœ¬çš„ç›®å½•çš„æœ¬åœ°è·¯å¾„ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰ï¼Œä¾‹å¦‚ `'./metrics/rouge'` æˆ– `'./metrics/rogue/rouge.py'`

    +   HuggingFace æ•°æ®é›†å­˜å‚¨åº“ä¸­çš„æŒ‡æ ‡æ ‡è¯†ç¬¦ï¼ˆä½¿ç”¨ `datasets.list_metrics()` åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æŒ‡æ ‡ï¼‰ä¾‹å¦‚ `'rouge'` æˆ– `'bleu'`

+   `config_name` (`str`, optional) â€” ä¸ºæŒ‡æ ‡é€‰æ‹©ä¸€ä¸ªé…ç½®ï¼ˆä¾‹å¦‚ï¼ŒGLUE æŒ‡æ ‡ä¸ºæ¯ä¸ªå­é›†éƒ½æœ‰ä¸€ä¸ªé…ç½®ï¼‰

+   `process_id`ï¼ˆ`int`ï¼Œå¯é€‰ï¼‰ â€” ç”¨äºåˆ†å¸ƒå¼è¯„ä¼°ï¼šè¿›ç¨‹çš„ id

+   `num_process`ï¼ˆ`int`ï¼Œå¯é€‰ï¼‰ â€” ç”¨äºåˆ†å¸ƒå¼è¯„ä¼°ï¼šè¿›ç¨‹çš„æ€»æ•°

+   `cache_dir`ï¼ˆå¯é€‰ strï¼‰ â€” ç”¨äºå­˜å‚¨ä¸´æ—¶é¢„æµ‹å’Œå‚è€ƒçš„è·¯å¾„ï¼ˆé»˜è®¤ä¸º*~/.cache/huggingface/metrics/*ï¼‰

+   `experiment_id`ï¼ˆ`str`ï¼‰ â€” ç‰¹å®šçš„å®éªŒ idã€‚å¦‚æœå‡ ä¸ªåˆ†å¸ƒå¼è¯„ä¼°å…±äº«ç›¸åŒçš„æ–‡ä»¶ç³»ç»Ÿï¼Œåˆ™ä¼šä½¿ç”¨æ­¤é€‰é¡¹ã€‚è¿™å¯¹äºåœ¨åˆ†å¸ƒå¼è®¾ç½®ä¸­è®¡ç®—æŒ‡æ ‡å¾ˆæœ‰ç”¨ï¼ˆç‰¹åˆ«æ˜¯åƒ F1 è¿™æ ·çš„éåŠ æ³•æŒ‡æ ‡ï¼‰ã€‚

+   `keep_in_memory`ï¼ˆboolï¼‰ â€” æ˜¯å¦å°†ä¸´æ—¶ç»“æœå­˜å‚¨åœ¨å†…å­˜ä¸­ï¼ˆé»˜è®¤ä¸º Falseï¼‰

+   `download_config`ï¼ˆå¯é€‰`datasets.DownloadConfig` â€” ç‰¹å®šçš„ä¸‹è½½é…ç½®å‚æ•°ã€‚

+   `download_mode`ï¼ˆDownloadMode æˆ–`str`ï¼Œé»˜è®¤ä¸º`REUSE_DATASET_IF_EXISTS`ï¼‰ â€” ä¸‹è½½/ç”Ÿæˆæ¨¡å¼ã€‚

+   `revision`ï¼ˆå¯é€‰`Union[str, datasets.Version]`ï¼‰ â€” å¦‚æœæŒ‡å®šï¼Œæ¨¡å—å°†ä»æ•°æ®é›†å­˜å‚¨åº“ä¸­åŠ è½½æ­¤ç‰ˆæœ¬ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒè®¾ç½®ä¸ºåº“çš„æœ¬åœ°ç‰ˆæœ¬ã€‚æŒ‡å®šä¸æœ¬åœ°åº“ç‰ˆæœ¬ä¸åŒçš„ç‰ˆæœ¬å¯èƒ½ä¼šå¯¼è‡´å…¼å®¹æ€§é—®é¢˜ã€‚

+   `trust_remote_code`ï¼ˆ*bool*ï¼Œé»˜è®¤ä¸º*True*ï¼‰ â€” æ˜¯å¦å…è®¸ä½¿ç”¨æ•°æ®é›†è„šæœ¬åœ¨ Hub ä¸Šå®šä¹‰æ•°æ®é›†ã€‚æ­¤é€‰é¡¹åº”ä»…å¯¹æ‚¨ä¿¡ä»»çš„å­˜å‚¨åº“è®¾ç½®ä¸º*True*ï¼Œå¹¶ä¸”æ‚¨å·²ç»é˜…è¯»äº†ä»£ç ï¼Œå› ä¸ºå®ƒå°†åœ¨æœ¬åœ°æœºå™¨ä¸Šæ‰§è¡Œ Hub ä¸Šå­˜åœ¨çš„ä»£ç ã€‚

    *trust_remote_code* åœ¨ä¸‹ä¸€ä¸ªä¸»è¦ç‰ˆæœ¬ä¸­é»˜è®¤ä¸º Falseã€‚

    åœ¨ 2.16.0 ä¸­æ·»åŠ 

åŠ è½½ä¸€ä¸ª*datasets.Metric*ã€‚

åœ¨ 2.5.0 ä¸­å¼ƒç”¨

è¯·æ”¹ç”¨*evaluate.load*ï¼Œä»æ–°åº“ğŸ¤— Evaluateï¼š[`huggingface.co/docs/evaluate`](https://huggingface.co/docs/evaluate)

ç¤ºä¾‹ï¼š

```py
>>> from datasets import load_metric
>>> accuracy = load_metric('accuracy')
>>> accuracy.compute(references=[1, 0], predictions=[1, 1])
{'accuracy': 0.5}
```

#### `datasets.inspect_metric`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/inspect.py#L161)

```py
( path: str local_path: str download_config: Optional = None **download_kwargs )
```

å‚æ•°

+   `path`ï¼ˆ`str`ï¼‰ â€” åŒ…å«æ•°æ®é›†æ„å»ºå™¨çš„æ•°æ®é›†å¤„ç†è„šæœ¬çš„è·¯å¾„ã€‚å¯ä»¥æ˜¯ï¼š

    +   å¤„ç†è„šæœ¬çš„æœ¬åœ°è·¯å¾„æˆ–åŒ…å«è„šæœ¬çš„ç›®å½•ï¼ˆå¦‚æœè„šæœ¬ä¸ç›®å½•åŒåï¼‰ï¼Œä¾‹å¦‚`'./dataset/squad'`æˆ–`'./dataset/squad/squad.py'`

    +   Hugging Face Hub ä¸Šçš„æ•°æ®é›†æ ‡è¯†ç¬¦ï¼ˆä½¿ç”¨`datasets.list_datasets()`åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†å’Œ idï¼‰ä¾‹å¦‚`'squad'`ï¼Œ`'glue'`æˆ–`'openai/webtext'`

+   `local_path`ï¼ˆ`str`ï¼‰ â€” ç”¨äºå°†æ•°æ®é›†è„šæœ¬å¤åˆ¶åˆ°çš„æœ¬åœ°æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚

+   `download_config`ï¼ˆå¯é€‰`datasets.DownloadConfig`ï¼‰ â€” ç‰¹å®šçš„ä¸‹è½½é…ç½®å‚æ•°ã€‚

+   *`*download_kwargs`ï¼ˆé¢å¤–çš„å…³é”®å­—å‚æ•°ï¼‰ â€” å¯é€‰å±æ€§ï¼Œç”¨äºè¦†ç›– download_config ä¸­çš„å±æ€§ã€‚

é€šè¿‡å°†æŒ‡æ ‡è„šæœ¬å¤åˆ¶åˆ°æœ¬åœ°é©±åŠ¨å™¨ä¸Šçš„ local_path æ¥å…è®¸æ£€æŸ¥/ä¿®æ”¹æŒ‡æ ‡è„šæœ¬ã€‚

åœ¨ 2.5.0 ä¸­å¼ƒç”¨

è¯·æ”¹ç”¨*evaluate.inspect_evaluation_module*ï¼Œä»æ–°åº“ğŸ¤— Evaluate æ›¿ä»£ï¼š[`huggingface.co/docs/evaluate`](https://huggingface.co/docs/evaluate)

## ä»æ–‡ä»¶

ç”¨äºåŠ è½½æ•°æ®æ–‡ä»¶çš„é…ç½®ã€‚åœ¨åŠ è½½æœ¬åœ°æ–‡ä»¶æˆ–æ•°æ®é›†å­˜å‚¨åº“æ—¶ä½¿ç”¨ï¼š

+   æœ¬åœ°æ–‡ä»¶ï¼š`load_dataset("parquet", data_dir="path/to/data/dir")`

+   æ•°æ®é›†å­˜å‚¨åº“ï¼š`load_dataset("allenai/c4")`

æ‚¨å¯ä»¥ä¼ é€’å‚æ•°ç»™`load_dataset`ä»¥é…ç½®æ•°æ®åŠ è½½ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥æŒ‡å®š`sep`å‚æ•°æ¥å®šä¹‰ç”¨äºåŠ è½½æ•°æ®çš„ CsvConfigï¼š

```py
load_dataset("csv", data_dir="path/to/data/dir", sep="\t")
```

### æ–‡æœ¬

### `class datasets.packaged_modules.text.TextConfig`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/text/text.py#L17)

```py
( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None encoding: str = 'utf-8' errors: dataclasses.InitVar[typing.Optional[str]] = 'deprecated' encoding_errors: Optional = None chunksize: int = 10485760 keep_linebreaks: bool = False sample_by: str = 'line' )
```

æ–‡æœ¬æ–‡ä»¶çš„ BuilderConfigã€‚

### `class datasets.packaged_modules.text.Text`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/text/text.py#L39)

```py
( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )
```

### CSV

### `class datasets.packaged_modules.csv.CsvConfig`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/csv/csv.py#L23)

```py
( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None sep: str = ',' delimiter: Optional = None header: Union = 'infer' names: Optional = None column_names: Optional = None index_col: Union = None usecols: Union = None prefix: Optional = None mangle_dupe_cols: bool = True engine: Optional = None converters: Dict = None true_values: Optional = None false_values: Optional = None skipinitialspace: bool = False skiprows: Union = None nrows: Optional = None na_values: Union = None keep_default_na: bool = True na_filter: bool = True verbose: bool = False skip_blank_lines: bool = True thousands: Optional = None decimal: str = '.' lineterminator: Optional = None quotechar: str = '"' quoting: int = 0 escapechar: Optional = None comment: Optional = None encoding: Optional = None dialect: Optional = None error_bad_lines: bool = True warn_bad_lines: bool = True skipfooter: int = 0 doublequote: bool = True memory_map: bool = False float_precision: Optional = None chunksize: int = 10000 features: Optional = None encoding_errors: Optional = 'strict' on_bad_lines: Literal = 'error' date_format: Optional = None )
```

CSV çš„ BuilderConfigã€‚

### `class datasets.packaged_modules.csv.Csv`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/csv/csv.py#L137)

```py
( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )
```

### JSON

### `class datasets.packaged_modules.json.JsonConfig`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/json/json.py#L18)

```py
( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None encoding: str = 'utf-8' encoding_errors: Optional = None field: Optional = None use_threads: bool = True block_size: Optional = None chunksize: int = 10485760 newlines_in_values: Optional = None )
```

JSON çš„ BuilderConfigã€‚

### `class datasets.packaged_modules.json.Json`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/json/json.py#L32)

```py
( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )
```

### Parquet

### `class datasets.packaged_modules.parquet.ParquetConfig`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/parquet/parquet.py#L15)

```py
( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None batch_size: int = 10000 columns: Optional = None features: Optional = None )
```

Parquet çš„ BuilderConfigã€‚

### `class datasets.packaged_modules.parquet.Parquet`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/parquet/parquet.py#L24)

```py
( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )
```

### Arrow

### `class datasets.packaged_modules.arrow.ArrowConfig`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/arrow/arrow.py#L14)

```py
( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None )
```

Arrow çš„ BuilderConfigã€‚

### `class datasets.packaged_modules.arrow.Arrow`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/arrow/arrow.py#L21)

```py
( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )
```

### SQL

### `class datasets.packaged_modules.sql.SqlConfig`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/sql/sql.py#L23)

```py
( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None sql: Union = None con: Union = None index_col: Union = None coerce_float: bool = True params: Union = None parse_dates: Union = None columns: Optional = None chunksize: Optional = 10000 features: Optional = None )
```

SQL çš„ BuilderConfigã€‚

### `class datasets.packaged_modules.sql.Sql`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/sql/sql.py#L90)

```py
( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )
```

### å›¾åƒ

### `class datasets.packaged_modules.imagefolder.ImageFolderConfig`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/imagefolder/imagefolder.py#L12)

```py
( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None drop_labels: bool = None drop_metadata: bool = None )
```

ImageFolder çš„ BuilderConfigã€‚

### `class datasets.packaged_modules.imagefolder.ImageFolder`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/imagefolder/imagefolder.py#L19)

```py
( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )
```

### éŸ³é¢‘

### `class datasets.packaged_modules.audiofolder.AudioFolderConfig`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/audiofolder/audiofolder.py#L12)

```py
( name: str = 'default' version: Union = 0.0.0 data_dir: Optional = None data_files: Union = None description: Optional = None features: Optional = None drop_labels: bool = None drop_metadata: bool = None )
```

éŸ³é¢‘æ–‡ä»¶å¤¹çš„ Builder é…ç½®ã€‚

### `class datasets.packaged_modules.audiofolder.AudioFolder`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/audiofolder/audiofolder.py#L19)

```py
( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )
```

### WebDataset

### `class datasets.packaged_modules.webdataset.WebDataset`

[<æ¥æº>](https://github.com/huggingface/datasets/blob/2.17.0/src/datasets/packaged_modules/webdataset/webdataset.py#L15)

```py
( cache_dir: Optional = None dataset_name: Optional = None config_name: Optional = None hash: Optional = None base_path: Optional = None info: Optional = None features: Optional = None token: Union = None use_auth_token = 'deprecated' repo_id: Optional = None data_files: Union = None data_dir: Optional = None storage_options: Optional = None writer_batch_size: Optional = None name = 'deprecated' **config_kwargs )
```
