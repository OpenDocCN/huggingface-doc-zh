- en: Launchers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/accelerate/package_reference/launchers](https://huggingface.co/docs/accelerate/package_reference/launchers)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/accelerate/v0.27.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/entry/start.6e0fb178.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/scheduler.69131cc3.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/singletons.ac467c20.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/paths.b2f3aeca.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/entry/app.67e11fc0.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/index.e1f30d73.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/nodes/0.bfeed9f0.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/nodes/23.0ed0fe20.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/Tip.22e79575.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/Docstring.ae1a1e2d.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/Heading.0aab6758.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/CodeBlock.30cef355.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/ExampleCodeBlock.e7a3d5fe.js">
  prefs: []
  type: TYPE_NORMAL
- en: Functions for launching training on distributed processes.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `accelerate.notebook_launcher`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/launchers.py#L37)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`function` (`Callable`) — The training function to execute. If it accepts arguments,
    the first argument should be the index of the process run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args` (`Tuple`) — Tuple of arguments to pass to the function (it will receive
    `*args`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_processes` (`int`, *optional*) — The number of processes to use for training.
    Will default to 8 in Colab/Kaggle if a TPU is available, to the number of GPUs
    available otherwise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mixed_precision` (`str`, *optional*, defaults to `"no"`) — If `fp16` or `bf16`,
    will use mixed precision training on multi-GPU.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_port` (`str`, *optional*, defaults to `"29500"`) — The port to use to
    communicate between processes when launching a multi-GPU training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`master_addr` (`str`, *optional*, defaults to `"127.0.0.1"`) — The address
    to use for communication between processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`node_rank` (`int`, *optional*, defaults to 0) — The rank of the current node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_nodes` (`int`, *optional*, defaults to 1) — The number of nodes to use
    for training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launches a training function, using several processes or multiple nodes if it’s
    possible in the current environment (TPU with multiple cores for instance).
  prefs: []
  type: TYPE_NORMAL
- en: To use this function absolutely zero calls to a CUDA device must be made in
    the notebook session before calling. If any have been made, you will need to restart
    the notebook and make sure no cells use any CUDA capability.
  prefs: []
  type: TYPE_NORMAL
- en: Setting `ACCELERATE_DEBUG_MODE="1"` in your environment will run a test before
    truly launching to ensure that none of those calls have been made.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#### `accelerate.debug_launcher`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/launchers.py#L224)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`function` (`Callable`) — The training function to execute.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`args` (`Tuple`) — Tuple of arguments to pass to the function (it will receive
    `*args`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_processes` (`int`, *optional*, defaults to 2) — The number of processes
    to use for training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launches a training function using several processes on CPU for debugging purposes.
  prefs: []
  type: TYPE_NORMAL
- en: This function is provided for internal testing and debugging, but it’s not intended
    for real trainings. It will only use the CPU.
  prefs: []
  type: TYPE_NORMAL
