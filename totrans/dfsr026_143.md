# DiT

> 原始文本：[`huggingface.co/docs/diffusers/api/pipelines/dit`](https://huggingface.co/docs/diffusers/api/pipelines/dit)

[具有变压器的可扩展扩散模型](https://huggingface.co/papers/2212.09748)（DiT）由 William Peebles 和 Saining Xie 撰写。

论文摘要为：

*我们探索了一类基于变压器架构的扩散模型。我们训练了图像的潜在扩散模型，用一个在潜在补丁上操作的变压器替换了常用的 U-Net 骨干。我们通过 Gflops 测量的前向传递复杂性的角度分析了我们的扩散变压器（DiTs）的可扩展性。我们发现具有更高 Gflops 的 DiTs - 通过增加变压器深度/宽度或增加输入令牌数量 - 一贯具有较低的 FID。除了具有良好的可扩展性属性外，我们最大的 DiT-XL/2 模型在类条件 ImageNet 512x512 和 256x256 基准上表现优于所有先前的扩散模型，实现了 256x256 基准的最新 FID 为 2.27。*

原始代码库可以在[facebookresearch/dit](https://github.com/facebookresearch/dit)找到。

确保查看调度器指南以了解如何探索调度器速度和质量之间的权衡，并查看跨管道重用组件部分以了解如何有效地将相同组件加载到多个管道中。

## DiTPipeline

### `class diffusers.DiTPipeline`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L31)

```py
( transformer: Transformer2DModel vae: AutoencoderKL scheduler: KarrasDiffusionSchedulers id2label: Optional = None )
```

参数

+   `transformer`（Transformer2DModel） - 一个条件化的`Transformer2DModel`类，用于去噪编码图像潜在。

+   `vae`（AutoencoderKL） - 变分自动编码器（VAE）模型，用于对图像进行编码和解码到和从潜在表示。

+   `scheduler`（DDIMScheduler） - 与`transformer`结合使用以去噪编码图像潜在的调度器。

基于变压器骨干而不是 UNet 的图像生成管道。

这个模型继承自 DiffusionPipeline。查看超类文档以了解为所有管道实现的通用方法（下载、保存、在特定设备上运行等）。

#### `__call__`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L92)

```py
( class_labels: List guidance_scale: float = 4.0 generator: Union = None num_inference_steps: int = 50 output_type: Optional = 'pil' return_dict: bool = True ) → export const metadata = 'undefined';ImagePipelineOutput or tuple
```

参数

+   `class_labels`（List[int]） - 要生成图像的 ImageNet 类标签列表。

+   `guidance_scale`（`float`，*可选*，默认为 4.0） - 更高的引导比例值鼓励模型生成与文本`prompt`紧密相关的图像，但以较低的图像质量为代价。当`guidance_scale > 1`时启用引导比例。

+   `generator`（`torch.Generator`，*可选*） - 用于使生成具有确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。

+   `num_inference_steps`（`int`，*可选*，默认为 250） - 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。

+   `output_type`（`str`，*可选*，默认为`"pil"`） - 生成图像的输出格式。选择`PIL.Image`或`np.array`之间。

+   `return_dict`（`bool`，*可选*，默认为`True`） - 是否返回 ImagePipelineOutput 而不是普通元组。

返回

ImagePipelineOutput 或`tuple`

如果`return_dict`为`True`，则返回 ImagePipelineOutput，否则返回一个元组，其中第一个元素是包含生成图像的列表

用于生成的管道的调用函数。

示例：

```py
>>> from diffusers import DiTPipeline, DPMSolverMultistepScheduler
>>> import torch

>>> pipe = DiTPipeline.from_pretrained("facebook/DiT-XL-2-256", torch_dtype=torch.float16)
>>> pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
>>> pipe = pipe.to("cuda")

>>> # pick words from Imagenet class labels
>>> pipe.labels  # to print all available words

>>> # pick words that exist in ImageNet
>>> words = ["white shark", "umbrella"]

>>> class_ids = pipe.get_label_ids(words)

>>> generator = torch.manual_seed(33)
>>> output = pipe(class_labels=class_ids, num_inference_steps=25, generator=generator)

>>> image = output.images[0]  # label 'white shark'
```

#### `get_label_ids`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L67)

```py
( label: Union ) → export const metadata = 'undefined';list of int
```

参数

+   `label` (`str`或`str`的`dict`) — 要映射到类别 ID 的标签字符串。

返回

`int`的`列表`

要由管道处理的类别 ID。

将 ImageNet 中的标签字符串映射到相应的类别 ID。

## ImagePipelineOutput

### `class diffusers.ImagePipelineOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L116)

```py
( images: Union )
```

参数

+   `images` (`List[PIL.Image.Image]`或`np.ndarray`) — 长度为`batch_size`的去噪 PIL 图像列表或形状为`(batch_size, height, width, num_channels)`的 NumPy 数组。

用于图像管道的输出类。
