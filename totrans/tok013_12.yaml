- en: Encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/tokenizers/api/encoding](https://huggingface.co/docs/tokenizers/api/encoding)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/start-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/vendor-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/paths-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/pages/__layout.svelte-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/pages/api/encoding.mdx-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/Tip-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/Docstring-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/IconCopyLink-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/TokenizersLanguageContent-hf-doc-builder.js">PythonRustNode
  prefs: []
  type: TYPE_NORMAL
- en: Encoding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class tokenizers.Encoding`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)
    represents the output of a [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer).
  prefs: []
  type: TYPE_NORMAL
- en: property attention_mask
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  prefs: []
  type: TYPE_NORMAL
- en: The attention mask
  prefs: []
  type: TYPE_NORMAL
- en: The attention mask
  prefs: []
  type: TYPE_NORMAL
- en: This indicates to the LM which tokens should be attended to, and which should
    not. This is especially important when batching sequences, where we need to applying
    padding.
  prefs: []
  type: TYPE_NORMAL
- en: property ids
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  prefs: []
  type: TYPE_NORMAL
- en: The list of IDs
  prefs: []
  type: TYPE_NORMAL
- en: The generated IDs
  prefs: []
  type: TYPE_NORMAL
- en: The IDs are the main input to a Language Model. They are the token indices,
    the numerical representations that a LM understands.
  prefs: []
  type: TYPE_NORMAL
- en: property n_sequences
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`int`'
  prefs: []
  type: TYPE_NORMAL
- en: The number of sequences in this [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)
  prefs: []
  type: TYPE_NORMAL
- en: The number of sequences represented
  prefs: []
  type: TYPE_NORMAL
- en: property offsets
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: A `List` of `Tuple[int, int]`
  prefs: []
  type: TYPE_NORMAL
- en: The list of offsets
  prefs: []
  type: TYPE_NORMAL
- en: The offsets associated to each token
  prefs: []
  type: TYPE_NORMAL
- en: These offsets let’s you slice the input string, and thus retrieve the original
    part that led to producing the corresponding token.
  prefs: []
  type: TYPE_NORMAL
- en: property overflowing
  prefs: []
  type: TYPE_NORMAL
- en: A `List` of overflowing [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)
  prefs: []
  type: TYPE_NORMAL
- en: When using truncation, the [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)
    takes care of splitting the output into as many pieces as required to match the
    specified maximum length. This field lets you retrieve all the subsequent pieces.
  prefs: []
  type: TYPE_NORMAL
- en: When you use pairs of sequences, the overflowing pieces will contain enough
    variations to cover all the possible combinations, while respecting the provided
    maximum length.
  prefs: []
  type: TYPE_NORMAL
- en: property sequence_ids
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: A `List` of `Optional[int]`
  prefs: []
  type: TYPE_NORMAL
- en: A list of optional sequence index.
  prefs: []
  type: TYPE_NORMAL
- en: The generated sequence indices.
  prefs: []
  type: TYPE_NORMAL
- en: They represent the index of the input sequence associated to each token. The
    sequence id can be None if the token is not related to any input sequence, like
    for example with special tokens.
  prefs: []
  type: TYPE_NORMAL
- en: property special_tokens_mask
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  prefs: []
  type: TYPE_NORMAL
- en: The special tokens mask
  prefs: []
  type: TYPE_NORMAL
- en: The special token mask
  prefs: []
  type: TYPE_NORMAL
- en: This indicates which tokens are special tokens, and which are not.
  prefs: []
  type: TYPE_NORMAL
- en: property tokens
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`List[str]`'
  prefs: []
  type: TYPE_NORMAL
- en: The list of tokens
  prefs: []
  type: TYPE_NORMAL
- en: The generated tokens
  prefs: []
  type: TYPE_NORMAL
- en: They are the string representation of the IDs.
  prefs: []
  type: TYPE_NORMAL
- en: property type_ids
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  prefs: []
  type: TYPE_NORMAL
- en: The list of type ids
  prefs: []
  type: TYPE_NORMAL
- en: The generated type IDs
  prefs: []
  type: TYPE_NORMAL
- en: Generally used for tasks like sequence classification or question answering,
    these tokens let the LM know which input sequence corresponds to each tokens.
  prefs: []
  type: TYPE_NORMAL
- en: property word_ids
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: A `List` of `Optional[int]`
  prefs: []
  type: TYPE_NORMAL
- en: A list of optional word index.
  prefs: []
  type: TYPE_NORMAL
- en: The generated word indices.
  prefs: []
  type: TYPE_NORMAL
- en: They represent the index of the word associated to each token. When the input
    is pre-tokenized, they correspond to the ID of the given input label, otherwise
    they correspond to the words indices as defined by the [PreTokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/pre-tokenizers#tokenizers.pre_tokenizers.PreTokenizer)
    that was used.
  prefs: []
  type: TYPE_NORMAL
- en: For special tokens and such (any token that was generated from something that
    was not part of the input), the output is `None`
  prefs: []
  type: TYPE_NORMAL
- en: property words
  prefs: []
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: A `List` of `Optional[int]`
  prefs: []
  type: TYPE_NORMAL
- en: A list of optional word index.
  prefs: []
  type: TYPE_NORMAL
- en: The generated word indices.
  prefs: []
  type: TYPE_NORMAL
- en: This is deprecated and will be removed in a future version. Please use `~tokenizers.Encoding.word_ids`
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: They represent the index of the word associated to each token. When the input
    is pre-tokenized, they correspond to the ID of the given input label, otherwise
    they correspond to the words indices as defined by the [PreTokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/pre-tokenizers#tokenizers.pre_tokenizers.PreTokenizer)
    that was used.
  prefs: []
  type: TYPE_NORMAL
- en: For special tokens and such (any token that was generated from something that
    was not part of the input), the output is `None`
  prefs: []
  type: TYPE_NORMAL
- en: '#### `char_to_token`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`char_pos` (`int`) — The position of a char in the input string'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sequence_index` (`int`, defaults to `0`) — The index of the sequence that
    contains the target char'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`int`'
  prefs: []
  type: TYPE_NORMAL
- en: The index of the token that contains this char in the encoded sequence
  prefs: []
  type: TYPE_NORMAL
- en: Get the token that contains the char at the given position in the input sequence.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `char_to_word`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`char_pos` (`int`) — The position of a char in the input string'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sequence_index` (`int`, defaults to `0`) — The index of the sequence that
    contains the target char'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`int`'
  prefs: []
  type: TYPE_NORMAL
- en: The index of the word that contains this char in the input sequence
  prefs: []
  type: TYPE_NORMAL
- en: Get the word that contains the char at the given position in the input sequence.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `merge`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`encodings` (A `List` of [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding))
    — The list of encodings that should be merged in one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`growing_offsets` (`bool`, defaults to `True`) — Whether the offsets should
    accumulate while merging'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)'
  prefs: []
  type: TYPE_NORMAL
- en: The resulting Encoding
  prefs: []
  type: TYPE_NORMAL
- en: Merge the list of encodings into one final [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)
  prefs: []
  type: TYPE_NORMAL
- en: '#### `pad`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`length` (`int`) — The desired length'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'direction — (`str`, defaults to `right`): The expected padding direction. Can
    be either `right` or `left`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`pad_id` (`int`, defaults to `0`) — The ID corresponding to the padding token'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pad_type_id` (`int`, defaults to `0`) — The type ID corresponding to the padding
    token'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pad_token` (`str`, defaults to *[PAD]*) — The pad token to use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pad the [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)
    at the given length
  prefs: []
  type: TYPE_NORMAL
- en: '#### `set_sequence_id`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Set the given sequence index
  prefs: []
  type: TYPE_NORMAL
- en: Set the given sequence index for the whole range of tokens contained in this
    [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding).
  prefs: []
  type: TYPE_NORMAL
- en: '#### `token_to_chars`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`token_index` (`int`) — The index of a token in the encoded sequence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Tuple[int, int]`'
  prefs: []
  type: TYPE_NORMAL
- en: The token offsets `(first, last + 1)`
  prefs: []
  type: TYPE_NORMAL
- en: Get the offsets of the token at the given index.
  prefs: []
  type: TYPE_NORMAL
- en: The returned offsets are related to the input sequence that contains the token.
    In order to determine in which input sequence it belongs, you must call `~tokenizers.Encoding.token_to_sequence()`.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `token_to_sequence`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`token_index` (`int`) — The index of a token in the encoded sequence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`int`'
  prefs: []
  type: TYPE_NORMAL
- en: The sequence id of the given token
  prefs: []
  type: TYPE_NORMAL
- en: Get the index of the sequence represented by the given token.
  prefs: []
  type: TYPE_NORMAL
- en: In the general use case, this method returns `0` for a single sequence or the
    first sequence of a pair, and `1` for the second sequence of a pair
  prefs: []
  type: TYPE_NORMAL
- en: '#### `token_to_word`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`token_index` (`int`) — The index of a token in the encoded sequence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`int`'
  prefs: []
  type: TYPE_NORMAL
- en: The index of the word in the relevant input sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Get the index of the word that contains the token in one of the input sequences.
  prefs: []
  type: TYPE_NORMAL
- en: The returned word index is related to the input sequence that contains the token.
    In order to determine in which input sequence it belongs, you must call `~tokenizers.Encoding.token_to_sequence()`.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `truncate`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`max_length` (`int`) — The desired length'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stride` (`int`, defaults to `0`) — The length of previous content to be included
    in each overflowing piece'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`direction` (`str`, defaults to `right`) — Truncate direction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Truncate the [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)
    at the given length
  prefs: []
  type: TYPE_NORMAL
- en: If this [Encoding](/docs/tokenizers/v0.13.4.rc2/en/api/encoding#tokenizers.Encoding)
    represents multiple sequences, when truncating this information is lost. It will
    be considered as representing a single sequence.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `word_to_chars`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`word_index` (`int`) — The index of a word in one of the input sequences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sequence_index` (`int`, defaults to `0`) — The index of the sequence that
    contains the target word'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Tuple[int, int]`'
  prefs: []
  type: TYPE_NORMAL
- en: The range of characters (span) `(first, last + 1)`
  prefs: []
  type: TYPE_NORMAL
- en: Get the offsets of the word at the given index in one of the input sequences.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `word_to_tokens`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`word_index` (`int`) — The index of a word in one of the input sequences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sequence_index` (`int`, defaults to `0`) — The index of the sequence that
    contains the target word'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`Tuple[int, int]`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The range of tokens: `(first, last + 1)`'
  prefs: []
  type: TYPE_NORMAL
- en: Get the encoded tokens corresponding to the word at the given index in one of
    the input sequences.
  prefs: []
  type: TYPE_NORMAL
