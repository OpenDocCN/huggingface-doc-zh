- en: Encode Inputs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/tokenizers/api/encode-inputs](https://huggingface.co/docs/tokenizers/api/encode-inputs)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/start-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/vendor-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/paths-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/pages/__layout.svelte-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/pages/api/encode-inputs.mdx-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/IconCopyLink-hf-doc-builder.js">
    <link rel="modulepreload" href="/docs/tokenizers/v0.13.4.rc2/en/_app/chunks/TokenizersLanguageContent-hf-doc-builder.js">PythonRustNode
  prefs: []
  type: TYPE_NORMAL
- en: These types represent all the different kinds of input that a [Tokenizer](/docs/tokenizers/v0.13.4.rc2/en/api/tokenizer#tokenizers.Tokenizer)
    accepts when using `encode_batch()`.
  prefs: []
  type: TYPE_NORMAL
- en: TextEncodeInput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`tokenizers.TextEncodeInput`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Represents a textual input for encoding. Can be either:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A single sequence: [TextInputSequence](/docs/tokenizers/api/input-sequences#tokenizers.TextInputSequence)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A pair of sequences:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Tuple of [TextInputSequence](/docs/tokenizers/api/input-sequences#tokenizers.TextInputSequence)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Or a List of [TextInputSequence](/docs/tokenizers/api/input-sequences#tokenizers.TextInputSequence)
    of size 2
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: alias of `Union[str, Tuple[str, str], List[str]]`.
  prefs: []
  type: TYPE_NORMAL
- en: PreTokenizedEncodeInput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`tokenizers.PreTokenizedEncodeInput`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Represents a pre-tokenized input for encoding. Can be either:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A single sequence: [PreTokenizedInputSequence](/docs/tokenizers/api/input-sequences#tokenizers.PreTokenizedInputSequence)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A pair of sequences:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Tuple of [PreTokenizedInputSequence](/docs/tokenizers/api/input-sequences#tokenizers.PreTokenizedInputSequence)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Or a List of [PreTokenizedInputSequence](/docs/tokenizers/api/input-sequences#tokenizers.PreTokenizedInputSequence)
    of size 2
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: alias of `Union[List[str], Tuple[str], Tuple[Union[List[str], Tuple[str]], Union[List[str],
    Tuple[str]]], List[Union[List[str], Tuple[str]]]]`.
  prefs: []
  type: TYPE_NORMAL
- en: EncodeInput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`tokenizers.EncodeInput`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Represents all the possible types of input for encoding. Can be:'
  prefs: []
  type: TYPE_NORMAL
- en: 'When `is_pretokenized=False`: [TextEncodeInput](#tokenizers.TextEncodeInput)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When `is_pretokenized=True`: [PreTokenizedEncodeInput](#tokenizers.PreTokenizedEncodeInput)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: alias of `Union[str, Tuple[str, str], List[str], Tuple[str], Tuple[Union[List[str],
    Tuple[str]], Union[List[str], Tuple[str]]], List[Union[List[str], Tuple[str]]]]`.
  prefs: []
  type: TYPE_NORMAL
