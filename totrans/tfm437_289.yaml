- en: Table Transformer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Table Transformer
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/table-transformer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/table-transformer)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/table-transformer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/table-transformer)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The Table Transformer model was proposed in [PubTables-1M: Towards comprehensive
    table extraction from unstructured documents](https://arxiv.org/abs/2110.00061)
    by Brandon Smock, Rohith Pesala, Robin Abraham. The authors introduce a new dataset,
    PubTables-1M, to benchmark progress in table extraction from unstructured documents,
    as well as table structure recognition and functional analysis. The authors train
    2 [DETR](detr) models, one for table detection and one for table structure recognition,
    dubbed Table Transformers.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'Table Transformer 模型是由 Brandon Smock、Rohith Pesala 和 Robin Abraham 在 [PubTables-1M:
    Towards comprehensive table extraction from unstructured documents](https://arxiv.org/abs/2110.00061)
    中提出的。作者引入了一个新数据集 PubTables-1M，用于评估从非结构化文档中提取表格、表结构识别和功能分析的进展。作者训练了两个 [DETR](detr)
    模型，一个用于表检测，一个用于表结构识别，被称为 Table Transformers。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Recently, significant progress has been made applying machine learning to
    the problem of table structure inference and extraction from unstructured documents.
    However, one of the greatest challenges remains the creation of datasets with
    complete, unambiguous ground truth at scale. To address this, we develop a new,
    more comprehensive dataset for table extraction, called PubTables-1M. PubTables-1M
    contains nearly one million tables from scientific articles, supports multiple
    input modalities, and contains detailed header and location information for table
    structures, making it useful for a wide variety of modeling approaches. It also
    addresses a significant source of ground truth inconsistency observed in prior
    datasets called oversegmentation, using a novel canonicalization procedure. We
    demonstrate that these improvements lead to a significant increase in training
    performance and a more reliable estimate of model performance at evaluation for
    table structure recognition. Further, we show that transformer-based object detection
    models trained on PubTables-1M produce excellent results for all three tasks of
    detection, structure recognition, and functional analysis without the need for
    any special customization for these tasks.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*最近，在将机器学习应用于从非结构化文档中推断和提取表结构方面取得了重大进展。然而，最大的挑战之一仍然是在规模上创建具有完整、明确的地面真实数据集。为了解决这个问题，我们开发了一个新的更全面的表提取数据集，名为
    PubTables-1M。PubTables-1M 包含来自科学文章的近一百万张表，支持多种输入模态，并包含详细的表头和位置信息，对于各种建模方法都很有用。它还通过一种新颖的规范化过程解决了先前数据集中观察到的地面真实不一致的重要来源，称为过分分割。我们展示这些改进导致训练性能显著提高，并在表结构识别的评估中获得更可靠的模型性能估计。此外，我们展示基于
    PubTables-1M 训练的基于 transformer 的目标检测模型在检测、结构识别和功能分析的三个任务中产生出色的结果，而无需为这些任务进行任何特殊定制。*'
- en: '![drawing](../Images/6a4207f7463ce853c0112742e980bd1d.png) Table detection
    and table structure recognition clarified. Taken from the [original paper](https://arxiv.org/abs/2110.00061).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![图示](../Images/6a4207f7463ce853c0112742e980bd1d.png) 表检测和表结构识别的澄清。摘自[原始论文](https://arxiv.org/abs/2110.00061)。'
- en: The authors released 2 models, one for [table detection](https://huggingface.co/microsoft/table-transformer-detection)
    in documents, one for [table structure recognition](https://huggingface.co/microsoft/table-transformer-structure-recognition)
    (the task of recognizing the individual rows, columns etc. in a table).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作者发布了两个模型，一个用于[文档中的表检测](https://huggingface.co/microsoft/table-transformer-detection)，一个用于[表结构识别](https://huggingface.co/microsoft/table-transformer-structure-recognition)（识别表中的各行、列等任务）。
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/microsoft/table-transformer).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由 [nielsr](https://huggingface.co/nielsr) 贡献。原始代码可以在这里找到 [链接](https://github.com/microsoft/table-transformer)。
- en: Resources
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: Object Detection
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测
- en: A demo notebook for the Table Transformer can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Table%20Transformer).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以在这里找到 Table Transformer 的演示笔记本 [链接](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Table%20Transformer)。
- en: It turns out padding of images is quite important for detection. An interesting
    Github thread with replies from the authors can be found [here](https://github.com/microsoft/table-transformer/issues/68).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原来图像的填充对于检测非常重要。可以在这里找到一个有趣的 Github 主题，其中包含作者的回复 [链接](https://github.com/microsoft/table-transformer/issues/68)。
- en: TableTransformerConfig
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TableTransformerConfig
- en: '### `class transformers.TableTransformerConfig`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TableTransformerConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/table_transformer/configuration_table_transformer.py#L36)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/table_transformer/configuration_table_transformer.py#L36)'
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`use_timm_backbone` (`bool`, *optional*, defaults to `True`) — Whether or not
    to use the `timm` library for the backbone. If set to `False`, will use the `AutoBackbone`
    API.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_timm_backbone` (`bool`，*可选*，默认为 `True`) — 是否使用 `timm` 库作为骨干。如果设置为 `False`，将使用
    `AutoBackbone` API。'
- en: '`backbone_config` (`PretrainedConfig` or `dict`, *optional*) — The configuration
    of the backbone model. Only used in case `use_timm_backbone` is set to `False`
    in which case it will default to `ResNetConfig()`.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_config` (`PretrainedConfig` 或 `dict`，*可选*) — 骨干模型的配置。仅在设置 `use_timm_backbone`
    为 `False` 时使用，此时默认为 `ResNetConfig()`。'
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`，*可选*，默认为 3) — 输入通道数。'
- en: '`num_queries` (`int`, *optional*, defaults to 100) — Number of object queries,
    i.e. detection slots. This is the maximal number of objects [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel)
    can detect in a single image. For COCO, we recommend 100 queries.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_queries` (`int`, *optional*, 默认为 100) — 对象查询的数量，即检测槽位。这是 [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel)
    在单个图像中可以检测到的对象的最大数量。对于 COCO，我们建议使用 100 个查询。'
- en: '`d_model` (`int`, *optional*, defaults to 256) — Dimension of the layers.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_model` (`int`, *optional*, 默认为 256) — 层的维度。'
- en: '`encoder_layers` (`int`, *optional*, defaults to 6) — Number of encoder layers.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layers` (`int`, *optional*, 默认为 6) — 编码器层的数量。'
- en: '`decoder_layers` (`int`, *optional*, defaults to 6) — Number of decoder layers.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers` (`int`, *optional*, 默认为 6) — 解码器层的数量。'
- en: '`encoder_attention_heads` (`int`, *optional*, defaults to 8) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_heads` (`int`, *optional*, 默认为 8) — Transformer 编码器中每个注意力层的注意力头数。'
- en: '`decoder_attention_heads` (`int`, *optional*, defaults to 8) — Number of attention
    heads for each attention layer in the Transformer decoder.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_heads` (`int`, *optional*, 默认为 8) — Transformer 解码器中每个注意力层的注意力头数。'
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 2048) — Dimension of the
    “intermediate” (often named feed-forward) layer in decoder.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ffn_dim` (`int`, *optional*, 默认为 2048) — 解码器中“中间”（通常称为前馈）层的维度。'
- en: '`encoder_ffn_dim` (`int`, *optional*, defaults to 2048) — Dimension of the
    “intermediate” (often named feed-forward) layer in decoder.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_ffn_dim` (`int`, *optional*, 默认为 2048) — 解码器中“中间”（通常称为前馈）层的维度。'
- en: '`activation_function` (`str` or `function`, *optional*, defaults to `"relu"`)
    — The non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_function` (`str` 或 `function`, *optional*, 默认为 `"relu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持
    `"gelu"`, `"relu"`, `"silu"` 和 `"gelu_new"`。'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, 默认为 0.1) — 嵌入、编码器和池化器中所有全连接层的丢失概率。'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for the attention probabilities.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout` (`float`, *optional*, 默认为 0.0) — 注意力概率的丢失比率。'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for activations inside the fully connected layer.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout` (`float`, *optional*, 默认为 0.0) — 全连接层内激活的丢失比率。'
- en: '`init_std` (`float`, *optional*, defaults to 0.02) — The standard deviation
    of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_std` (`float`, *optional*, 默认为 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`init_xavier_std` (`float`, *optional*, defaults to 1) — The scaling factor
    used for the Xavier initialization gain in the HM Attention map module.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_xavier_std` (`float`, *optional*, 默认为 1) — 用于 HM Attention map 模块中的 Xavier
    初始化增益的缩放因子。'
- en: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.0) — The LayerDrop
    probability for the encoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layerdrop` (`float`, *optional*, 默认为 0.0) — 编码器的 LayerDrop 概率。更多细节请参阅
    [LayerDrop 论文](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.0) — The LayerDrop
    probability for the decoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layerdrop` (`float`, *optional*, 默认为 0.0) — 解码器的 LayerDrop 概率。更多细节请参阅
    [LayerDrop 论文](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`auxiliary_loss` (`bool`, *optional*, defaults to `False`) — Whether auxiliary
    decoding losses (loss at each decoder layer) are to be used.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auxiliary_loss` (`bool`, *optional*, 默认为 `False`) — 是否使用辅助解码损失（每个解码器层的损失）。'
- en: '`position_embedding_type` (`str`, *optional*, defaults to `"sine"`) — Type
    of position embeddings to be used on top of the image features. One of `"sine"`
    or `"learned"`.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_embedding_type` (`str`, *optional*, 默认为 `"sine"`) — 在图像特征之上使用的位置嵌入的类型。可以是
    `"sine"` 或 `"learned"` 中的一个。'
- en: '`backbone` (`str`, *optional*, defaults to `"resnet50"`) — Name of convolutional
    backbone to use in case `use_timm_backbone` = `True`. Supports any convolutional
    backbone from the timm package. For a list of all available models, see [this
    page](https://rwightman.github.io/pytorch-image-models/#load-a-pretrained-model).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone` (`str`, *optional*, 默认为 `"resnet50"`) — 在 `use_timm_backbone` =
    `True` 时要使用的卷积主干的名称。支持来自 timm 包的任何卷积主干。有关所有可用模型的列表，请参阅 [此页面](https://rwightman.github.io/pytorch-image-models/#load-a-pretrained-model)。'
- en: '`use_pretrained_backbone` (`bool`, *optional*, defaults to `True`) — Whether
    to use pretrained weights for the backbone. Only supported when `use_timm_backbone`
    = `True`.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_pretrained_backbone` (`bool`, *optional*, 默认为 `True`) — 是否使用主干的预训练权重。仅在
    `use_timm_backbone` = `True` 时支持。'
- en: '`dilation` (`bool`, *optional*, defaults to `False`) — Whether to replace stride
    with dilation in the last convolutional block (DC5). Only supported when `use_timm_backbone`
    = `True`.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dilation` (`bool`, *optional*, 默认为 `False`) — 是否在最后的卷积块（DC5）中用膨胀替代步幅。仅在 `use_timm_backbone`
    = `True` 时支持。'
- en: '`class_cost` (`float`, *optional*, defaults to 1) — Relative weight of the
    classification error in the Hungarian matching cost.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_cost` (`float`, *optional*, 默认为 1) — 匈牙利匹配成本中分类错误的相对权重。'
- en: '`bbox_cost` (`float`, *optional*, defaults to 5) — Relative weight of the L1
    error of the bounding box coordinates in the Hungarian matching cost.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox_cost` (`float`, *optional*, 默认为 5) — 匈牙利匹配成本中边界框坐标的 L1 误差的相对权重。'
- en: '`giou_cost` (`float`, *optional*, defaults to 2) — Relative weight of the generalized
    IoU loss of the bounding box in the Hungarian matching cost.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`giou_cost` (`float`, *optional*, 默认为 2) — 匈牙利匹配成本中边界框广义 IoU 损失的相对权重。'
- en: '`mask_loss_coefficient` (`float`, *optional*, defaults to 1) — Relative weight
    of the Focal loss in the panoptic segmentation loss.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dice_loss_coefficient` (`float`, *optional*, defaults to 1) — Relative weight
    of the DICE/F-1 loss in the panoptic segmentation loss.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bbox_loss_coefficient` (`float`, *optional*, defaults to 5) — Relative weight
    of the L1 bounding box loss in the object detection loss.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`giou_loss_coefficient` (`float`, *optional*, defaults to 2) — Relative weight
    of the generalized IoU loss in the object detection loss.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eos_coefficient` (`float`, *optional*, defaults to 0.1) — Relative classification
    weight of the ‘no-object’ class in the object detection loss.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the configuration class to store the configuration of a [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel).
    It is used to instantiate a Table Transformer model according to the specified
    arguments, defining the model architecture. Instantiating a configuration with
    the defaults will yield a similar configuration to that of the Table Transformer
    [microsoft/table-transformer-detection](https://huggingface.co/microsoft/table-transformer-detection)
    architecture.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: TableTransformerModel
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TableTransformerModel`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/table_transformer/modeling_table_transformer.py#L1190)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bare Table Transformer Model (consisting of a backbone and encoder-decoder
    Transformer) outputting raw hidden-states without any specific head on top.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/table_transformer/modeling_table_transformer.py#L1232)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Padding will be ignored by default should you provide
    it.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pixel values can be obtained using [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor).
    See [DetrImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`pixel_mask` (`torch.FloatTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`,
    *optional*) — Not used by default. Can be used to mask object queries.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`,
    *可选*) — 默认情况下不使用。可用于屏蔽对象查询。'
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *可选*) — 元组包括(`last_hidden_state`,
    *可选*: `hidden_states`, *可选*: `attentions`) `last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*可选*) 是编码器最后一层的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing the flattened feature
    map (output of the backbone + projection layer), you can choose to directly pass
    a flattened representation of an image.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *可选*) — 可选地，您可以选择直接传递图像的扁平化表示，而不是传递扁平化特征图（骨干网络输出+投影层的输出）。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — Optionally, instead of initializing the queries with
    a tensor of zeros, you can choose to directly pass an embedded representation.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *可选*) — 可选地，您可以选择直接传递嵌入表示，而不是用零张量初始化查询。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.table_transformer.modeling_table_transformer.TableTransformerModelOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.table_transformer.modeling_table_transformer.TableTransformerModelOutput`
    或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.table_transformer.modeling_table_transformer.TableTransformerModelOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig))
    and inputs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.table_transformer.modeling_table_transformer.TableTransformerModelOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)）和输入的不同元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — 模型解码器最后一层的隐藏状态序列。'
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 元组`torch.FloatTensor`（一个用于嵌入输出，一个用于每层输出）的形状为`(batch_size, sequence_length, hidden_size)`。解码器每层输出的隐藏状态加上初始嵌入输出。'
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights of the decoder, after the
    attention softmax, used to compute the weighted average in the self-attention
    heads.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 元组`torch.FloatTensor`（每层一个）的形状为`(batch_size, num_heads, sequence_length, sequence_length)`。解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。'
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 元组`torch.FloatTensor`（每层一个）的形状为`(batch_size, num_heads, sequence_length, sequence_length)`。解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *可选*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights of the encoder, after the
    attention softmax, used to compute the weighted average in the self-attention
    heads.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`intermediate_hidden_states` (`torch.FloatTensor` of shape `(config.decoder_layers,
    batch_size, sequence_length, hidden_size)`, *optional*, returned when `config.auxiliary_loss=True`)
    — Intermediate decoder activations, i.e. the output of each decoder layer, each
    of them gone through a layernorm.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel)
    forward method, overrides the `__call__` special method.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: TableTransformerForObjectDetection
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TableTransformerForObjectDetection`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/table_transformer/modeling_table_transformer.py#L1359)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table Transformer Model (consisting of a backbone and encoder-decoder Transformer)
    with object detection heads on top, for tasks such as COCO detection.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/table_transformer/modeling_table_transformer.py#L1393)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Padding will be ignored by default should you provide
    it.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pixel values can be obtained using [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor).
    See [DetrImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`pixel_mask` (`torch.FloatTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`,
    *optional*) — Not used by default. Can be used to mask object queries.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`,
    *optional*) — 默认情况下不使用。可用于屏蔽对象查询。'
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — 元组包括（`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`）`last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*可选*是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing the flattened feature
    map (output of the backbone + projection layer), you can choose to directly pass
    a flattened representation of an image.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选，可以选择直接传递图像的扁平化表示，而不是传递骨干网络+投影层的扁平化特征图。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — Optionally, instead of initializing the queries with
    a tensor of zeros, you can choose to directly pass an embedded representation.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — 可选，可以选择直接传递嵌入表示，而不是用零张量初始化查询。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`labels` (`List[Dict]` of len `(batch_size,)`, *optional*) — Labels for computing
    the bipartite matching loss. List of dicts, each dictionary containing at least
    the following 2 keys: ‘class_labels’ and ‘boxes’ (the class labels and bounding
    boxes of an image in the batch respectively). The class labels themselves should
    be a `torch.LongTensor` of len `(number of bounding boxes in the image,)` and
    the boxes a `torch.FloatTensor` of shape `(number of bounding boxes in the image,
    4)`.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`List[Dict]` of len `(batch_size,)`, *optional*) — 用于计算二分匹配损失的标签。字典列表，每个字典至少包含以下2个键：''class_labels''和''boxes''（分别是批次中图像的类标签和边界框）。类标签本身应该是长度为`(图像中边界框的数量,)`的`torch.LongTensor`，而边界框应该是形状为`(图像中边界框的数量,
    4)`的`torch.FloatTensor`。'
- en: Returns
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.table_transformer.modeling_table_transformer.TableTransformerObjectDetectionOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.table_transformer.modeling_table_transformer.TableTransformerObjectDetectionOutput`
    或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.table_transformer.modeling_table_transformer.TableTransformerObjectDetectionOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig))
    and inputs.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.table_transformer.modeling_table_transformer.TableTransformerObjectDetectionOutput`或一个`torch.FloatTensor`的元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（[TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    are provided)) — Total loss as a linear combination of a negative log-likehood
    (cross-entropy) for class prediction and a bounding box loss. The latter is defined
    as a linear combination of the L1 loss and the generalized scale-invariant IoU
    loss.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) —
    作为负对数似然（交叉熵）和边界框损失的线性组合的总损失。后者被定义为L1损失和广义比例不变IoU损失的线性组合。'
- en: '`loss_dict` (`Dict`, *optional*) — A dictionary containing the individual losses.
    Useful for logging.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss_dict` (`Dict`, *optional*) — 包含各个损失的字典。用于记录。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, num_queries, num_classes
    + 1)`) — Classification logits (including no-object) for all queries.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, num_queries, num_classes
    + 1)`) — 包括无对象在内的所有查询的分类logits。'
- en: '`pred_boxes` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`)
    — Normalized boxes coordinates for all queries, represented as (center_x, center_y,
    width, height). These values are normalized in [0, 1], relative to the size of
    each individual image in the batch (disregarding possible padding). You can use
    `~TableTransformerImageProcessor.post_process_object_detection` to retrieve the
    unnormalized bounding boxes.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pred_boxes` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`)
    — 所有查询的归一化框坐标，表示为（中心_x，中心_y，宽度，高度）。这些值在[0, 1]范围内归一化，相对于批次中每个单独图像的大小（忽略可能的填充）。您可以使用`~TableTransformerImageProcessor.post_process_object_detection`来检索未归一化的边界框。'
- en: '`auxiliary_outputs` (`list[Dict]`, *optional*) — Optional, only returned when
    auxilary losses are activated (i.e. `config.auxiliary_loss` is set to `True`)
    and labels are provided. It is a list of dictionaries containing the two above
    keys (`logits` and `pred_boxes`) for each decoder layer.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auxiliary_outputs` (`list[Dict]`, *optional*) — 可选，仅在激活辅助损失（即`config.auxiliary_loss`设置为`True`）并提供标签时返回。它是一个字典列表，包含每个解码器层的上述两个键（`logits`和`pred_boxes`）。'
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the decoder of the model.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`，*optional*) — 模型解码器最后一层的隐藏状态序列。'
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`，*optional*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — `torch.FloatTensor`元组（嵌入输出和每层输出各一个），形状为`(batch_size, sequence_length, hidden_size)`。解码器在每层输出的隐藏状态加上初始嵌入输出。'
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights of the decoder, after the
    attention softmax, used to compute the weighted average in the self-attention
    heads.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`，*optional*，当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — `torch.FloatTensor`元组（每层一个），形状为`(batch_size, num_heads, sequence_length, sequence_length)`。解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。'
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`，*optional*，当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — `torch.FloatTensor`元组（每层一个），形状为`(batch_size, num_heads, sequence_length, sequence_length)`。解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`，*optional*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`，*optional*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — `torch.FloatTensor`元组（嵌入输出和每层输出各一个），形状为`(batch_size, sequence_length, hidden_size)`。编码器在每层输出的隐藏状态加上初始嵌入输出。'
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights of the encoder, after the
    attention softmax, used to compute the weighted average in the self-attention
    heads.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — `torch.FloatTensor`元组（每层一个），形状为`(batch_size, num_heads, sequence_length, sequence_length)`。编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。'
- en: The [TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)
    forward method, overrides the `__call__` special method.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此函数内调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
