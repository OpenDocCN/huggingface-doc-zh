- en: Quick tour
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¿«é€Ÿå¯¼è§ˆ
- en: 'Original text: [https://huggingface.co/docs/accelerate/quicktour](https://huggingface.co/docs/accelerate/quicktour)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/accelerate/quicktour](https://huggingface.co/docs/accelerate/quicktour)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This guide aims to help you get started with ğŸ¤— Accelerate quickly. It covers
    the essential steps you need to take to enable distributed training, as well as
    the adjustments that you need to make in some common scenarios.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—æ—¨åœ¨å¸®åŠ©æ‚¨å¿«é€Ÿå…¥é—¨ğŸ¤— Accelerateã€‚å®ƒæ¶µç›–äº†å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ‰€éœ€çš„åŸºæœ¬æ­¥éª¤ï¼Œä»¥åŠåœ¨ä¸€äº›å¸¸è§æƒ…å†µä¸‹éœ€è¦è¿›è¡Œçš„è°ƒæ•´ã€‚
- en: 'To help you navigate, the guide is split into two sections:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¸®åŠ©æ‚¨å¯¼èˆªï¼ŒæŒ‡å—åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š
- en: '[Getting Started with ğŸ¤— Accelerate](#getting-started-with--accelerate): start
    here to learn how to modify your script to enable distributed training with ğŸ¤—
    Accelerate'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Getting Started with ğŸ¤— Accelerate](#getting-started-with--accelerate)ï¼šä»è¿™é‡Œå¼€å§‹å­¦ä¹ å¦‚ä½•ä¿®æ”¹æ‚¨çš„è„šæœ¬ä»¥å¯ç”¨ğŸ¤—
    Accelerateçš„åˆ†å¸ƒå¼è®­ç»ƒ'
- en: '[Common adaptations to the base case](#common-adaptations-to-the-base-case):
    check out this section for common deviations from the baseline scenario and what
    adjustments may need to be made to support them.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[åŸºæœ¬æƒ…å†µä¸‹çš„å¸¸è§é€‚åº”](#common-adaptations-to-the-base-case)ï¼šæŸ¥çœ‹æ­¤éƒ¨åˆ†ä»¥äº†è§£ä¸åŸºçº¿æƒ…å†µçš„å¸¸è§åå·®ä»¥åŠå¯èƒ½éœ€è¦è¿›è¡Œçš„è°ƒæ•´ã€‚'
- en: Getting started with ğŸ¤— Accelerate
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¼€å§‹ä½¿ç”¨ğŸ¤— Accelerate
- en: Enable distributed training in your script
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨æ‚¨çš„è„šæœ¬ä¸­å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
- en: 'To use ğŸ¤— Accelerate in your own training script, you have to modify four things:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åœ¨è‡ªå·±çš„è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨ğŸ¤— Accelerateï¼Œæ‚¨éœ€è¦ä¿®æ”¹å››ä¸ªå†…å®¹ï¼š
- en: Import the [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    main class and instantiate one in an `accelerator` object.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¼å…¥[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)ä¸»ç±»å¹¶åœ¨`accelerator`å¯¹è±¡ä¸­å®ä¾‹åŒ–ä¸€ä¸ªã€‚
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Add this at the beginning of your training script as it will initialize everything
    necessary for distributed training. You donâ€™t need to indicate the kind of environment
    you are in (a single machine with a GPU, a machine with several GPUs, or several
    machines with multiple GPUs or a TPU), the library will detect this automatically.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤æ·»åŠ åˆ°æ‚¨çš„è®­ç»ƒè„šæœ¬å¼€å¤´ï¼Œå› ä¸ºå®ƒå°†åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒæ‰€éœ€çš„ä¸€åˆ‡ã€‚æ‚¨æ— éœ€æŒ‡ç¤ºæ‚¨æ‰€å¤„çš„ç¯å¢ƒç±»å‹ï¼ˆå…·æœ‰GPUçš„å•å°æœºå™¨ï¼Œå…·æœ‰å¤šä¸ªGPUçš„æœºå™¨ï¼Œæˆ–å…·æœ‰å¤šä¸ªGPUæˆ–TPUçš„å¤šå°æœºå™¨ï¼‰ï¼Œåº“å°†è‡ªåŠ¨æ£€æµ‹åˆ°è¿™ä¸€ç‚¹ã€‚
- en: Remove the `.to(device)` or `.cuda()` calls for your model and input data.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ é™¤æ¨¡å‹å’Œè¾“å…¥æ•°æ®çš„`.to(device)`æˆ–`.cuda()`è°ƒç”¨ã€‚
- en: 'The `accelerator` object will handle placing these objects on the right device
    for you. If you choose to leave those `.to(device)` calls, make sure to use the
    device provided by the `accelerator` object: `accelerator.device`.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '`accelerator`å¯¹è±¡å°†ä¸ºæ‚¨å¤„ç†å°†è¿™äº›å¯¹è±¡æ”¾ç½®åœ¨æ­£ç¡®è®¾å¤‡ä¸Šã€‚å¦‚æœé€‰æ‹©ä¿ç•™é‚£äº›`.to(device)`è°ƒç”¨ï¼Œè¯·ç¡®ä¿ä½¿ç”¨`accelerator`å¯¹è±¡æä¾›çš„è®¾å¤‡ï¼š`accelerator.device`ã€‚'
- en: You can fully deactivate the automatic device placement by passing along `device_placement=False`
    when initializing the [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator).
    However, if you place your objects manually on the proper device, be careful to
    create your optimizer after putting your model on `accelerator.device` or your
    training will fail on TPU.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡åœ¨åˆå§‹åŒ–[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)æ—¶ä¼ é€’`device_placement=False`æ¥å®Œå…¨åœç”¨è‡ªåŠ¨è®¾å¤‡æ”¾ç½®ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨æ‰‹åŠ¨å°†å¯¹è±¡æ”¾ç½®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼Œè¯·æ³¨æ„åœ¨å°†æ¨¡å‹æ”¾ç½®åœ¨`accelerator.device`ä¸Šåå†åˆ›å»ºä¼˜åŒ–å™¨ï¼Œå¦åˆ™æ‚¨çš„TPUè®­ç»ƒå°†å¤±è´¥ã€‚
- en: 'Pass all PyTorch objects relevant to training (optimizer, model, dataloader(s),
    learning rate scheduler) to the [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    method as soon as these objects are created, before starting your actual training
    loop:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰ä¸è®­ç»ƒç›¸å…³çš„PyTorchå¯¹è±¡ï¼ˆä¼˜åŒ–å™¨ï¼Œæ¨¡å‹ï¼Œæ•°æ®åŠ è½½å™¨ï¼Œå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼‰åœ¨åˆ›å»ºè¿™äº›å¯¹è±¡åç«‹å³ä¼ é€’ç»™[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)æ–¹æ³•ï¼Œç„¶åå†å¼€å§‹å®é™…çš„è®­ç»ƒå¾ªç¯ï¼š
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Important notes**:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**é‡è¦æç¤º**ï¼š'
- en: You should always pass the the learning rate scheduler to [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare),
    however if the scheduler should *not* be stepped at each optimization step, pass
    `step_with_optimizer=False` to the [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    init.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨åº”è¯¥å§‹ç»ˆå°†å­¦ä¹ ç‡è°ƒåº¦å™¨ä¼ é€’ç»™[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)ï¼Œä½†æ˜¯å¦‚æœè°ƒåº¦å™¨åœ¨æ¯æ¬¡ä¼˜åŒ–æ­¥éª¤æ—¶*ä¸*åº”è¯¥è¢«æ­¥è¿›ï¼Œè¯·åœ¨[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)åˆå§‹åŒ–æ—¶ä¼ é€’`step_with_optimizer=False`ã€‚
- en: While you can send your dataloader to [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    on its own (and there are cases for doing so, such as distributed inference),
    itâ€™s best to send it to [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    together with the model and optimizer.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è™½ç„¶æ‚¨å¯ä»¥å°†æ‚¨çš„æ•°æ®åŠ è½½å™¨å•ç‹¬å‘é€åˆ°[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)ï¼ˆå¹¶ä¸”æœ‰æ—¶éœ€è¦è¿™æ ·åšï¼Œæ¯”å¦‚åˆ†å¸ƒå¼æ¨ç†ï¼‰ï¼Œä½†æœ€å¥½å°†å…¶ä¸æ¨¡å‹å’Œä¼˜åŒ–å™¨ä¸€èµ·å‘é€åˆ°[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)ã€‚
- en: If you wish to run distributed evaluation, send your validation dataloader to
    [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    as well. There are some nuances to distributed validation, check the [Distributed
    evaluation](#add-distributed-evaluation) section of the guide.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å¸Œæœ›è¿è¡Œåˆ†å¸ƒå¼è¯„ä¼°ï¼Œè¯·å°†æ‚¨çš„éªŒè¯æ•°æ®åŠ è½½å™¨ä¹Ÿå‘é€åˆ°[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)ã€‚åˆ†å¸ƒå¼è¯„ä¼°æœ‰ä¸€äº›ç»†å¾®å·®åˆ«ï¼Œè¯·æŸ¥çœ‹æŒ‡å—ä¸­çš„[Distributed
    evaluation](#add-distributed-evaluation)éƒ¨åˆ†ã€‚
- en: Any instruction using your training dataloader length (for instance if you want
    to log the number of total training steps) should go after the call to [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare).
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»»ä½•ä½¿ç”¨æ‚¨çš„è®­ç»ƒæ•°æ®åŠ è½½å™¨é•¿åº¦çš„æŒ‡ä»¤ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³è®°å½•æ€»è®­ç»ƒæ­¥æ•°ï¼‰åº”è¯¥åœ¨è°ƒç”¨[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)ä¹‹åè¿›è¡Œã€‚
- en: Passing `DataLoader` objects to the [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    method ensures that your dataloader will be sharded across all GPUs/TPU cores
    available so that each one sees a different portion of the training dataset. In
    other words, if there are 8 processes and a dataset of 64 items, each process
    will see 8 of these items per iteration. Also, the random states of all processes
    will be synchronized at the beginning of each iteration through your dataloader,
    to make sure the data is shuffled the same way (if you decided to use `shuffle=True`
    or any kind of random sampler).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å°† `DataLoader` å¯¹è±¡ä¼ é€’ç»™ [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    æ–¹æ³•å¯ç¡®ä¿æ‚¨çš„æ•°æ®åŠ è½½å™¨å°†åœ¨æ‰€æœ‰å¯ç”¨çš„GPU/TPUæ ¸å¿ƒä¸Šè¿›è¡Œåˆ†ç‰‡ï¼Œä»¥ä¾¿æ¯ä¸ªæ ¸å¿ƒçœ‹åˆ°è®­ç»ƒæ•°æ®é›†çš„ä¸åŒéƒ¨åˆ†ã€‚æ¢å¥è¯è¯´ï¼Œå¦‚æœæœ‰ 8 ä¸ªè¿›ç¨‹å’Œä¸€ä¸ªåŒ…å« 64 ä¸ªé¡¹ç›®çš„æ•°æ®é›†ï¼Œæ¯ä¸ªè¿›ç¨‹å°†åœ¨æ¯æ¬¡è¿­ä»£ä¸­çœ‹åˆ°å…¶ä¸­çš„
    8 ä¸ªé¡¹ç›®ã€‚æ­¤å¤–ï¼Œæ‰€æœ‰è¿›ç¨‹çš„éšæœºçŠ¶æ€å°†åœ¨æ¯æ¬¡è¿­ä»£å¼€å§‹æ—¶é€šè¿‡æ‚¨çš„æ•°æ®åŠ è½½å™¨è¿›è¡ŒåŒæ­¥ï¼Œä»¥ç¡®ä¿æ•°æ®ä»¥ç›¸åŒçš„æ–¹å¼æ´—ç‰Œï¼ˆå¦‚æœæ‚¨å†³å®šä½¿ç”¨ `shuffle=True`
    æˆ–ä»»ä½•ç±»å‹çš„éšæœºé‡‡æ ·å™¨ï¼‰ã€‚
- en: 'The actual batch size for your training will be the number of devices used
    multiplied by the batch size you set in your script. For instance, training on
    4 GPUs with a batch size of 16 set when creating the training dataloader will
    train at an actual batch size of 64 (4 * 16). If you want the batch size remain
    the same regardless of how many GPUs the script is run on, you can use the option
    `split_batches=True` when creating and initializing [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator).
    Your training dataloader may change length when going through this method: if
    you run on X GPUs, it will have its length divided by X (since your actual batch
    size will be multiplied by X), unless you set `split_batches=True`.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨çš„è®­ç»ƒå®é™…æ‰¹é‡å¤§å°å°†æ˜¯ä½¿ç”¨çš„è®¾å¤‡æ•°é‡ä¹˜ä»¥è„šæœ¬ä¸­è®¾ç½®çš„æ‰¹é‡å¤§å°ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨æ‰¹é‡å¤§å°ä¸º 16 åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨æ—¶åœ¨ 4 ä¸ªGPUä¸Šè®­ç»ƒå°†ä»¥å®é™…æ‰¹é‡å¤§å°
    64ï¼ˆ4 * 16ï¼‰è¿›è¡Œè®­ç»ƒã€‚å¦‚æœå¸Œæœ›æ— è®ºè„šæœ¬åœ¨å¤šå°‘ä¸ªGPUä¸Šè¿è¡Œï¼Œæ‰¹é‡å¤§å°ä¿æŒä¸å˜ï¼Œå¯ä»¥åœ¨åˆ›å»ºå’Œåˆå§‹åŒ– [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    æ—¶ä½¿ç”¨é€‰é¡¹ `split_batches=True`ã€‚é€šè¿‡æ­¤æ–¹æ³•è¿›è¡Œè®­ç»ƒæ•°æ®åŠ è½½å™¨å¯èƒ½ä¼šæ”¹å˜é•¿åº¦ï¼šå¦‚æœåœ¨ X ä¸ªGPUä¸Šè¿è¡Œï¼Œå®ƒçš„é•¿åº¦å°†è¢« X æ•´é™¤ï¼ˆå› ä¸ºå®é™…æ‰¹é‡å¤§å°å°†ä¹˜ä»¥
    Xï¼‰ï¼Œé™¤éè®¾ç½® `split_batches=True`ã€‚
- en: Replace the `loss.backward()` line with `accelerator.backward(loss)`.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°† `loss.backward()` è¡Œæ›¿æ¢ä¸º `accelerator.backward(loss)`ã€‚
- en: And youâ€™re all set! With all these changes, your script will run on your local
    machine as well as on multiple GPUs or a TPU! You can either use your favorite
    tool to launch the distributed training, or you can use the ğŸ¤— Accelerate launcher.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ç½®å®Œæˆï¼é€šè¿‡æ‰€æœ‰è¿™äº›æ›´æ”¹ï¼Œæ‚¨çš„è„šæœ¬å°†åœ¨æœ¬åœ°æœºå™¨ä¸Šä»¥åŠå¤šä¸ªGPUæˆ–TPUä¸Šè¿è¡Œï¼æ‚¨å¯ä»¥ä½¿ç”¨æ‚¨å–œæ¬¢çš„å·¥å…·å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒï¼Œæˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ ğŸ¤— Accelerate
    å¯åŠ¨å™¨ã€‚
- en: Add distributed evaluation
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ·»åŠ åˆ†å¸ƒå¼è¯„ä¼°
- en: You can perform regular evaluation in your training script if you leave your
    validation dataloader out of the [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    method. In this case, you will need to put the input data on the `accelerator.device`
    manually.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå°†éªŒè¯æ•°æ®åŠ è½½å™¨æ’é™¤åœ¨ [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    æ–¹æ³•ä¹‹å¤–ï¼Œæ‚¨å¯ä»¥åœ¨è®­ç»ƒè„šæœ¬ä¸­æ‰§è¡Œå®šæœŸè¯„ä¼°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦æ‰‹åŠ¨å°†è¾“å…¥æ•°æ®æ”¾åœ¨ `accelerator.device` ä¸Šã€‚
- en: 'To perform distributed evaluation, send along your validation dataloader to
    the [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    method:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ‰§è¡Œåˆ†å¸ƒå¼è¯„ä¼°ï¼Œè¯·å°†éªŒè¯æ•°æ®åŠ è½½å™¨å‘é€åˆ° [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    æ–¹æ³•ä¸­ï¼š
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Same as with your training dataloader, each device will only see part of the
    evaluation data should you run your script on multiple devices. This means you
    will need to group your predictions together which you can do with the [gather_for_metrics()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather_for_metrics)
    method.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è®­ç»ƒæ•°æ®åŠ è½½å™¨ä¸€æ ·ï¼Œå¦‚æœåœ¨å¤šä¸ªè®¾å¤‡ä¸Šè¿è¡Œè„šæœ¬ï¼Œåˆ™æ¯ä¸ªè®¾å¤‡åªä¼šçœ‹åˆ°è¯„ä¼°æ•°æ®çš„ä¸€éƒ¨åˆ†ã€‚è¿™æ„å‘³ç€æ‚¨éœ€è¦å°†é¢„æµ‹ç»“æœç»„åˆåœ¨ä¸€èµ·ï¼Œå¯ä»¥ä½¿ç”¨ [gather_for_metrics()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather_for_metrics)
    æ–¹æ³•æ¥å®ç°ã€‚
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Similar to the training dataloader, passing your validation dataloader through
    [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    may change it: if you run on X GPUs, it will have its length divided by X (since
    your actual batch size will be multiplied by X), unless you set `split_batches=True`.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è®­ç»ƒæ•°æ®åŠ è½½å™¨ç±»ä¼¼ï¼Œé€šè¿‡ [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    ä¼ é€’éªŒè¯æ•°æ®åŠ è½½å™¨å¯èƒ½ä¼šæ”¹å˜å®ƒï¼šå¦‚æœåœ¨ X ä¸ªGPUä¸Šè¿è¡Œï¼Œå®ƒçš„é•¿åº¦å°†è¢« X æ•´é™¤ï¼ˆå› ä¸ºå®é™…æ‰¹é‡å¤§å°å°†ä¹˜ä»¥ Xï¼‰ï¼Œé™¤éè®¾ç½® `split_batches=True`ã€‚
- en: Some data at the end of the dataset may be duplicated so the batch can be divided
    equally among all workers. As a result, metrics should be calculated through the
    [gather_for_metrics()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather_for_metrics)
    method to automatically remove the duplicated data while gathering and provide
    a more accurate metric.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†æœ«å°¾çš„ä¸€äº›æ•°æ®å¯èƒ½ä¼šé‡å¤ï¼Œä»¥ä¾¿æ‰¹æ¬¡å¯ä»¥åœ¨æ‰€æœ‰å·¥ä½œè¿›ç¨‹ä¹‹é—´å¹³å‡åˆ†é…ã€‚å› æ­¤ï¼Œåº”é€šè¿‡ [gather_for_metrics()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather_for_metrics)
    æ–¹æ³•è®¡ç®—æŒ‡æ ‡ï¼Œä»¥åœ¨æ”¶é›†æ•°æ®æ—¶è‡ªåŠ¨åˆ é™¤é‡å¤æ•°æ®ï¼Œå¹¶æä¾›æ›´å‡†ç¡®çš„æŒ‡æ ‡ã€‚
- en: If for some reason you donâ€™t wish to have this automatically done, [gather()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather)
    can be used instead to gather the data across all processes and this can manually
    be done instead.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå‡ºäºæŸç§åŸå› æ‚¨ä¸å¸Œæœ›è‡ªåŠ¨æ‰§è¡Œæ­¤æ“ä½œï¼Œå¯ä»¥ä½¿ç”¨ [gather()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather)
    æ¥ä»£æ›¿ï¼Œä»¥æ”¶é›†æ‰€æœ‰è¿›ç¨‹ä¸­çš„æ•°æ®ï¼Œè¿™å¯ä»¥æ‰‹åŠ¨å®Œæˆã€‚
- en: The [gather()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather)
    and [gather_for_metrics()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather_for_metrics)
    methods require the tensors to be all the same size on each process. If you have
    tensors of different sizes on each process (for instance when dynamically padding
    to the maximum length in a batch), you should use the [pad_across_processes()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.pad_across_processes)
    method to pad you tensor to the biggest size across processes.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[gather()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather)å’Œ[gather_for_metrics()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather_for_metrics)æ–¹æ³•è¦æ±‚æ¯ä¸ªè¿›ç¨‹ä¸Šçš„å¼ é‡å¤§å°ç›¸åŒã€‚å¦‚æœæ¯ä¸ªè¿›ç¨‹ä¸Šçš„å¼ é‡å¤§å°ä¸åŒï¼ˆä¾‹å¦‚åœ¨æ‰¹å¤„ç†ä¸­åŠ¨æ€å¡«å……åˆ°æœ€å¤§é•¿åº¦æ—¶ï¼‰ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨[pad_across_processes()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.pad_across_processes)æ–¹æ³•å°†æ‚¨çš„å¼ é‡å¡«å……åˆ°è·¨è¿›ç¨‹çš„æœ€å¤§å¤§å°ã€‚'
- en: Launch your distributed script
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¯åŠ¨æ‚¨çš„åˆ†å¸ƒå¼è„šæœ¬
- en: You can use the regular commands to launch your distributed training (like `torch.distributed.run`
    for PyTorch) - they are fully compatible with ğŸ¤— Accelerate.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä½¿ç”¨å¸¸è§„å‘½ä»¤æ¥å¯åŠ¨æ‚¨çš„åˆ†å¸ƒå¼è®­ç»ƒï¼ˆä¾‹å¦‚PyTorchçš„`torch.distributed.run`ï¼‰-å®ƒä»¬ä¸ğŸ¤— Accelerateå®Œå…¨å…¼å®¹ã€‚
- en: 'Alternatively, ğŸ¤— Accelerate provides a CLI tool that unifies all launchers,
    so you only have to remember one command. \ To use it, run a quick configuration
    setup first on your machine and answer the questions:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å¦å¤–ï¼ŒğŸ¤— Accelerateæä¾›äº†ä¸€ä¸ªCLIå·¥å…·ï¼Œç»Ÿä¸€äº†æ‰€æœ‰å¯åŠ¨å™¨ï¼Œå› æ­¤æ‚¨åªéœ€è®°ä½ä¸€ä¸ªå‘½ä»¤ã€‚è¦ä½¿ç”¨å®ƒï¼Œåœ¨æ‚¨çš„æœºå™¨ä¸Šé¦–å…ˆè¿è¡Œå¿«é€Ÿé…ç½®è®¾ç½®å¹¶å›ç­”é—®é¢˜ï¼š
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'At the end of the setup, a *default_config.yaml* file will be saved in your
    cache folder for ğŸ¤— Accelerate. That cache folder is (with decreasing order of
    priority):'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®¾ç½®ç»“æŸæ—¶ï¼Œå°†åœ¨æ‚¨çš„ç¼“å­˜æ–‡ä»¶å¤¹ä¸­ä¿å­˜ä¸€ä¸ª*default_config.yaml*æ–‡ä»¶ä¾›ğŸ¤— Accelerateä½¿ç”¨ã€‚è¯¥ç¼“å­˜æ–‡ä»¶å¤¹ä¸ºï¼ˆæŒ‰ä¼˜å…ˆçº§é€’å‡çš„é¡ºåºï¼‰ï¼š
- en: The content of your environment variable `HF_HOME` suffixed with *accelerate*.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨çš„ç¯å¢ƒå˜é‡`HF_HOME`çš„å†…å®¹åç¼€ä¸º*accelerate*ã€‚
- en: If it does not exist, the content of your environment variable `XDG_CACHE_HOME`
    suffixed with *huggingface/accelerate*.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™å°†æ‚¨çš„ç¯å¢ƒå˜é‡`XDG_CACHE_HOME`çš„å†…å®¹åç¼€ä¸º*huggingface/accelerate*ã€‚
- en: If this does not exist either, the folder *~/.cache/huggingface/accelerate*.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœè¿™ä¹Ÿä¸å­˜åœ¨ï¼Œåˆ™æ–‡ä»¶å¤¹*~/.cache/huggingface/accelerate*ã€‚
- en: 'By specifying the `--config_file` flag you can specify an alternative location
    of the configuration file. Once the configuration setup is complete, you can test
    your setup by running:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æŒ‡å®š`--config_file`æ ‡å¿—ï¼Œæ‚¨å¯ä»¥æŒ‡å®šé…ç½®æ–‡ä»¶çš„æ›¿ä»£ä½ç½®ã€‚ä¸€æ—¦é…ç½®è®¾ç½®å®Œæˆï¼Œæ‚¨å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥æµ‹è¯•æ‚¨çš„è®¾ç½®ï¼š
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This will launch a short script that will test the distributed environment.
    If it runs without issues, you are ready for the next step!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†å¯åŠ¨ä¸€ä¸ªç®€çŸ­çš„è„šæœ¬ï¼Œæµ‹è¯•åˆ†å¸ƒå¼ç¯å¢ƒã€‚å¦‚æœæ²¡æœ‰é—®é¢˜è¿è¡Œï¼Œæ‚¨å·²ç»å‡†å¤‡å¥½è¿›è¡Œä¸‹ä¸€æ­¥äº†ï¼
- en: 'Note that if you specified a location for the config file in the previous step,
    you need to pass it here as well:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå¦‚æœåœ¨ä¸Šä¸€æ­¥ä¸­æŒ‡å®šäº†é…ç½®æ–‡ä»¶çš„ä½ç½®ï¼Œåˆ™éœ€è¦åœ¨æ­¤å¤„ä¼ é€’å®ƒï¼š
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now that this is done, you can run your script with the following command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è¿™æ ·åšåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œæ‚¨çš„è„šæœ¬ï¼š
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you stored the config file in a non-default location, you can indicate it
    to the launcher like this:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å°†é…ç½®æ–‡ä»¶å­˜å‚¨åœ¨éé»˜è®¤ä½ç½®ï¼Œå¯ä»¥åƒè¿™æ ·å‘å¯åŠ¨å™¨æŒ‡ç¤ºå®ƒï¼š
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You can override any of the arguments determined by your config file. To see
    the complete list of parameters that you can pass in, run `accelerate launch -h`.
    (And further niche argument help by passing in partial commands, such as `accelerate
    launch --multi_gpu -h` for all `multi_gpu` args)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥è¦†ç›–ç”±é…ç½®æ–‡ä»¶ç¡®å®šçš„ä»»ä½•å‚æ•°ã€‚è¦æŸ¥çœ‹å¯ä»¥ä¼ é€’çš„å®Œæ•´å‚æ•°åˆ—è¡¨ï¼Œè¯·è¿è¡Œ`accelerate launch -h`ã€‚ï¼ˆé€šè¿‡ä¼ é€’éƒ¨åˆ†å‘½ä»¤ï¼Œä¾‹å¦‚`accelerate
    launch --multi_gpu -h`ï¼Œå¯ä»¥è·å–æ›´å¤šå…³äºç‰¹å®šå‚æ•°çš„å¸®åŠ©ï¼‰
- en: Check out the [Launch tutorial](basic_tutorials/launch) for more information
    about launching your scripts.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[å¯åŠ¨æ•™ç¨‹](basic_tutorials/launch)ä»¥è·å–æœ‰å…³å¯åŠ¨æ‚¨çš„è„šæœ¬çš„æ›´å¤šä¿¡æ¯ã€‚
- en: Common modifications of the base case
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŸºæœ¬æƒ…å†µçš„å¸¸è§ä¿®æ”¹
- en: The previous section covers the minimal essential steps to move a training script
    into a distributed setup with ğŸ¤— Accelerate. Here we describe common modifications/deviations
    from the base case scenario and the adjustments you need to make to accommodate
    for them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å‰ä¸€èŠ‚æ¶µç›–äº†å°†è®­ç»ƒè„šæœ¬ç§»è‡³å…·æœ‰ğŸ¤— Accelerateçš„åˆ†å¸ƒå¼è®¾ç½®çš„æœ€å°åŸºæœ¬æ­¥éª¤ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æè¿°äº†ä¸åŸºæœ¬æƒ…å†µåœºæ™¯çš„å¸¸è§ä¿®æ”¹/åå·®ä»¥åŠæ‚¨éœ€è¦è¿›è¡Œçš„è°ƒæ•´ã€‚
- en: Launch distributed training from a notebook
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»ç¬”è®°æœ¬å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ
- en: Accelerate has a [notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)
    to help you launch your training function from a notebook. This launcher supports
    launching a training with TPUs on Colab or Kaggle, as well as training on several
    GPUs and machines (if the machine on which you are running your notebook has them).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Accelerateæœ‰ä¸€ä¸ª[notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)ï¼Œå¯ä»¥å¸®åŠ©æ‚¨ä»ç¬”è®°æœ¬å¯åŠ¨è®­ç»ƒå‡½æ•°ã€‚è¯¥å¯åŠ¨å™¨æ”¯æŒåœ¨Colabæˆ–Kaggleä¸Šä½¿ç”¨TPUè¿›è¡Œè®­ç»ƒï¼Œä»¥åŠåœ¨å¤šä¸ªGPUå’Œæœºå™¨ä¸Šè¿›è¡Œè®­ç»ƒï¼ˆå¦‚æœè¿è¡Œç¬”è®°æœ¬çš„æœºå™¨å…·æœ‰è¿™äº›è®¾å¤‡ï¼‰ã€‚
- en: 'Define a function responsible for your whole training and/or evaluation in
    a cell of the notebook, then execute a cell with the following code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬”è®°æœ¬çš„ä¸€ä¸ªå•å…ƒæ ¼ä¸­å®šä¹‰ä¸€ä¸ªè´Ÿè´£æ•´ä¸ªè®­ç»ƒå’Œ/æˆ–è¯„ä¼°çš„å‡½æ•°ï¼Œç„¶åæ‰§è¡Œä»¥ä¸‹ä»£ç çš„å•å…ƒæ ¼ï¼š
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Your [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    object should only be defined inside the training function. This is because the
    initialization should be done inside the launcher only.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨çš„[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)å¯¹è±¡åº”è¯¥åªåœ¨è®­ç»ƒå‡½æ•°å†…éƒ¨å®šä¹‰ã€‚è¿™æ˜¯å› ä¸ºåˆå§‹åŒ–åº”è¯¥åªåœ¨å¯åŠ¨å™¨å†…éƒ¨å®Œæˆã€‚
- en: Check out the [Notebook Launcher tutorial](basic_tutorials/notebook) for more
    information about training on TPUs.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[ç¬”è®°æœ¬å¯åŠ¨å™¨æ•™ç¨‹](basic_tutorials/notebook)ä»¥è·å–æœ‰å…³åœ¨TPUä¸Šè¿›è¡Œè®­ç»ƒçš„æ›´å¤šä¿¡æ¯ã€‚
- en: Specifics of training on TPU
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨TPUä¸Šè®­ç»ƒçš„å…·ä½“æƒ…å†µ
- en: If you want to launch your script on TPUs, there are a few caveats you should
    be aware of. Behind the scenes, the TPUs will create a graph of all the operations
    happening in your training step (forward pass, backward pass and optimizer step).
    This is why your first step of training will always be very long as building and
    compiling this graph for optimizations takes some time.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³åœ¨TPUä¸Šè¿è¡Œæ‚¨çš„è„šæœ¬ï¼Œæ‚¨åº”è¯¥æ³¨æ„ä¸€äº›æ³¨æ„äº‹é¡¹ã€‚åœ¨å¹•åï¼ŒTPUå°†åˆ›å»ºä¸€ä¸ªå›¾ï¼Œæ˜¾ç¤ºè®­ç»ƒæ­¥éª¤ä¸­å‘ç”Ÿçš„æ‰€æœ‰æ“ä½œï¼ˆå‰å‘ä¼ é€’ã€åå‘ä¼ é€’å’Œä¼˜åŒ–å™¨æ­¥éª¤ï¼‰ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ‚¨çš„è®­ç»ƒçš„ç¬¬ä¸€æ­¥æ€»æ˜¯éå¸¸é•¿çš„åŸå› ï¼Œå› ä¸ºæ„å»ºå’Œç¼–è¯‘æ­¤å›¾ä»¥è¿›è¡Œä¼˜åŒ–éœ€è¦ä¸€äº›æ—¶é—´ã€‚
- en: 'The good news is that this compilation will be cached so the second step and
    all the following will be much faster. The bad news is that it only applies if
    all of your steps do exactly the same operations, which implies:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½æ¶ˆæ¯æ˜¯è¿™ä¸ªç¼–è¯‘å°†è¢«ç¼“å­˜ï¼Œå› æ­¤ç¬¬äºŒæ­¥å’Œæ‰€æœ‰åç»­æ­¥éª¤å°†ä¼šå¿«å¾—å¤šã€‚åæ¶ˆæ¯æ˜¯å®ƒä»…é€‚ç”¨äºæ‰€æœ‰æ­¥éª¤å®Œå…¨ç›¸åŒçš„æ“ä½œï¼Œè¿™æ„å‘³ç€ï¼š
- en: having all tensors of the same length in all your batches
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ‰€æœ‰æ‰¹æ¬¡ä¸­å…·æœ‰ç›¸åŒé•¿åº¦çš„æ‰€æœ‰å¼ é‡
- en: having static code (i.e., not a for loop of length that could change from step
    to step)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰é™æ€ä»£ç ï¼ˆå³ï¼Œä¸æ˜¯é•¿åº¦å¯èƒ½ä¼šåœ¨æ­¥éª¤ä¹‹é—´æ”¹å˜çš„forå¾ªç¯ï¼‰
- en: Having any of the things above change between two steps will trigger a new compilation
    which will, once again, take a lot of time. In practice, that means you must take
    special care to have all your tensors in your inputs of the same shape (so no
    dynamic padding for instance if you are in an NLP problem) and should not use
    layers with for loops that have different lengths depending on the inputs (such
    as an LSTM) or the training will be excruciatingly slow.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸¤ä¸ªæ­¥éª¤ä¹‹é—´ä»»ä½•ä¸Šè¿°äº‹ç‰©çš„æ”¹å˜éƒ½ä¼šè§¦å‘æ–°çš„ç¼–è¯‘ï¼Œè¿™å°†å†æ¬¡èŠ±è´¹å¤§é‡æ—¶é—´ã€‚å®é™…ä¸Šï¼Œè¿™æ„å‘³ç€æ‚¨å¿…é¡»ç‰¹åˆ«æ³¨æ„ç¡®ä¿æ‰€æœ‰è¾“å…¥å¼ é‡å…·æœ‰ç›¸åŒçš„å½¢çŠ¶ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœæ‚¨åœ¨å¤„ç†è‡ªç„¶è¯­è¨€å¤„ç†é—®é¢˜ï¼Œåˆ™ä¸èƒ½ä½¿ç”¨åŠ¨æ€å¡«å……ï¼‰ï¼Œå¹¶ä¸”ä¸åº”è¯¥ä½¿ç”¨å…·æœ‰ä¸åŒé•¿åº¦çš„è¾“å…¥çš„forå¾ªç¯çš„å±‚ï¼ˆä¾‹å¦‚LSTMï¼‰ï¼Œå¦åˆ™è®­ç»ƒå°†å˜å¾—éå¸¸ç¼“æ…¢ã€‚
- en: 'To introduce special behavior in your script for TPUs you can check the `distributed_type`
    of your `accelerator`:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åœ¨è„šæœ¬ä¸­ä¸ºTPUå¼•å…¥ç‰¹æ®Šè¡Œä¸ºï¼Œæ‚¨å¯ä»¥æ£€æŸ¥`accelerator`çš„`distributed_type`ï¼š
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The [NLP example](https://github.com/huggingface/accelerate/blob/main/examples/nlp_example.py)
    shows an example in a situation with dynamic padding.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[NLPç¤ºä¾‹](https://github.com/huggingface/accelerate/blob/main/examples/nlp_example.py)å±•ç¤ºäº†ä¸€ä¸ªå…·æœ‰åŠ¨æ€å¡«å……æƒ…å†µçš„ç¤ºä¾‹ã€‚'
- en: 'One last thing to pay close attention to: if your model has tied weights (such
    as language models which tie the weights of the embedding matrix with the weights
    of the decoder), moving this model to the TPU (either yourself or after you passed
    your model to [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare))
    will break the tying. You will need to retie the weights after. You can find an
    example of this in the [run_clm_no_trainer](https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_clm.py)
    script in the Transformers repository.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åè¦ç‰¹åˆ«æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼šå¦‚æœæ‚¨çš„æ¨¡å‹å…·æœ‰ç»‘å®šæƒé‡ï¼ˆä¾‹å¦‚å°†åµŒå…¥çŸ©é˜µçš„æƒé‡ä¸è§£ç å™¨çš„æƒé‡ç»‘å®šçš„è¯­è¨€æ¨¡å‹ï¼‰ï¼Œå°†æ­¤æ¨¡å‹ç§»åŠ¨åˆ°TPUï¼ˆæ— è®ºæ˜¯æ‚¨è‡ªå·±è¿˜æ˜¯åœ¨å°†æ¨¡å‹ä¼ é€’ç»™[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)ä¹‹åï¼‰å°†ä¼šç ´åè¿™ç§ç»‘å®šã€‚æ‚¨éœ€è¦åœ¨ä¹‹åé‡æ–°ç»‘å®šæƒé‡ã€‚æ‚¨å¯ä»¥åœ¨Transformerså­˜å‚¨åº“ä¸­çš„[run_clm_no_trainer](https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_clm.py)è„šæœ¬ä¸­æ‰¾åˆ°ä¸€ä¸ªç¤ºä¾‹ã€‚
- en: Check out the [TPU tutorial](concept_guides/training_tpu) for more information
    about training on TPUs.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[TPUæ•™ç¨‹](concept_guides/training_tpu)ä»¥è·å–æœ‰å…³åœ¨TPUä¸Šè®­ç»ƒçš„æ›´å¤šä¿¡æ¯ã€‚
- en: Execute a statement only on one processes
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»…åœ¨ä¸€ä¸ªè¿›ç¨‹ä¸Šæ‰§è¡Œè¯­å¥
- en: 'Some of your instructions only need to run for one process on a given server:
    for instance a data download or a log statement. To do this, wrap the statement
    in a test like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨çš„ä¸€äº›æŒ‡ä»¤åªéœ€è¦åœ¨ç»™å®šæœåŠ¡å™¨ä¸Šçš„ä¸€ä¸ªè¿›ç¨‹ä¸Šè¿è¡Œï¼šä¾‹å¦‚æ•°æ®ä¸‹è½½æˆ–æ—¥å¿—è¯­å¥ã€‚ä¸ºæ­¤ï¼Œè¯·å°†è¯­å¥åŒ…è£…åœ¨ç±»ä¼¼äºä»¥ä¸‹çš„æµ‹è¯•ä¸­ï¼š
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Another example is progress bars: to avoid having multiple progress bars in
    your output, you should only display one on the local main process:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªä¾‹å­æ˜¯è¿›åº¦æ¡ï¼šä¸ºäº†é¿å…åœ¨è¾“å‡ºä¸­æœ‰å¤šä¸ªè¿›åº¦æ¡ï¼Œæ‚¨åº”è¯¥ä»…åœ¨æœ¬åœ°ä¸»è¿›ç¨‹ä¸Šæ˜¾ç¤ºä¸€ä¸ªï¼š
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The *local* means per machine: if you are running your training on two servers
    with several GPUs, the instruction will be executed once on each of those servers.
    If you need to execute something only once for all processes (and not per machine)
    for instance, uploading the final model to the ğŸ¤— model hub, wrap it in a test
    like this:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*æœ¬åœ°*è¡¨ç¤ºæ¯å°æœºå™¨ï¼šå¦‚æœæ‚¨åœ¨ä¸¤å°å…·æœ‰å¤šä¸ªGPUçš„æœåŠ¡å™¨ä¸Šè¿è¡Œè®­ç»ƒï¼Œè¯¥æŒ‡ä»¤å°†åœ¨æ¯å°æœåŠ¡å™¨ä¸Šæ‰§è¡Œä¸€æ¬¡ã€‚å¦‚æœæ‚¨éœ€è¦ä¸ºæ‰€æœ‰è¿›ç¨‹æ‰§è¡Œä¸€æ¬¡ï¼ˆè€Œä¸æ˜¯æ¯å°æœºå™¨ï¼‰çš„æŸäº›æ“ä½œï¼Œä¾‹å¦‚å°†æœ€ç»ˆæ¨¡å‹ä¸Šä¼ åˆ°ğŸ¤—æ¨¡å‹ä¸­å¿ƒï¼Œè¯·å°†å…¶åŒ…è£…åœ¨ç±»ä¼¼äºä»¥ä¸‹çš„æµ‹è¯•ä¸­ï¼š'
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: For printing statements you only want executed once per machine, you can just
    replace the `print` function by `accelerator.print`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåªæƒ³åœ¨æ¯å°æœºå™¨ä¸Šæ‰§è¡Œä¸€æ¬¡çš„æ‰“å°è¯­å¥ï¼Œæ‚¨å¯ä»¥å°†`print`å‡½æ•°æ›¿æ¢ä¸º`accelerator.print`ã€‚
- en: Defer execution on multiple GPUs
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¨è¿Ÿåœ¨å¤šä¸ªGPUä¸Šæ‰§è¡Œ
- en: 'When you run your usual script, instructions are executed in order. Using ğŸ¤—
    Accelerate to deploy your script on several GPUs at the same time introduces a
    complication: while each process executes all instructions in order, some may
    be faster than others.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‚¨è¿è¡Œæ‚¨çš„å¸¸è§„è„šæœ¬æ—¶ï¼ŒæŒ‡ä»¤æ˜¯æŒ‰é¡ºåºæ‰§è¡Œçš„ã€‚ä½¿ç”¨ğŸ¤— Accelerateåœ¨å¤šä¸ªGPUä¸ŠåŒæ—¶éƒ¨ç½²æ‚¨çš„è„šæœ¬ä¼šå¼•å…¥ä¸€ä¸ªå¤æ‚æ€§ï¼šè™½ç„¶æ¯ä¸ªè¿›ç¨‹æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰æŒ‡ä»¤ï¼Œä½†æœ‰äº›å¯èƒ½æ¯”å…¶ä»–è¿›ç¨‹å¿«ã€‚
- en: 'You might need to wait for all processes to have reached a certain point before
    executing a given instruction. For instance, you shouldnâ€™t save a model before
    making sure every process is done with training. To do this, add the following
    line in your code:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰§è¡Œç‰¹å®šæŒ‡ä»¤ä¹‹å‰ï¼Œæ‚¨å¯èƒ½éœ€è¦ç­‰å¾…æ‰€æœ‰è¿›ç¨‹éƒ½è¾¾åˆ°æŸä¸ªç‰¹å®šç‚¹ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¡®ä¿æ¯ä¸ªè¿›ç¨‹éƒ½å®Œæˆè®­ç»ƒä¹‹å‰ï¼Œæ‚¨ä¸åº”è¯¥ä¿å­˜æ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œè¯·åœ¨æ‚¨çš„ä»£ç ä¸­æ·»åŠ ä»¥ä¸‹è¡Œï¼š
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This instruction will block all the processes that arrive first until all the
    other processes have reached that point (if you run your script on just one GPU
    or CPU, this wonâ€™t do anything).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æŒ‡ä»¤å°†é˜»æ­¢æ‰€æœ‰æœ€å…ˆåˆ°è¾¾çš„è¿›ç¨‹ï¼Œç›´åˆ°æ‰€æœ‰å…¶ä»–è¿›ç¨‹éƒ½è¾¾åˆ°è¯¥ç‚¹ï¼ˆå¦‚æœæ‚¨åªåœ¨ä¸€ä¸ªGPUæˆ–CPUä¸Šè¿è¡Œè„šæœ¬ï¼Œåˆ™ä¸ä¼šæ‰§è¡Œä»»ä½•æ“ä½œï¼‰ã€‚
- en: Save/load a model in a distributed setup
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨åˆ†å¸ƒå¼è®¾ç½®ä¸­ä¿å­˜/åŠ è½½æ¨¡å‹
- en: 'Saving the model you trained might need a bit of adjustment: first you should
    wait for all processes to reach that point in the script as shown above, and then,
    you should unwrap your model before saving it. This is because when going through
    the [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)
    method, your model may have been placed inside a bigger model, which deals with
    the distributed training. This in turn means that saving your model state dictionary
    without taking any precaution will take that potential extra layer into account,
    and you will end up with weights you canâ€™t load back in your base model. The [save_model()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_model)
    method will help you to achieve that. It will unwrap your model and save the model
    state dictionary.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿å­˜è®­ç»ƒè¿‡çš„æ¨¡å‹å¯èƒ½éœ€è¦ä¸€äº›è°ƒæ•´ï¼šé¦–å…ˆï¼Œæ‚¨åº”è¯¥ç­‰å¾…æ‰€æœ‰è¿›ç¨‹è¾¾åˆ°è„šæœ¬ä¸­æ˜¾ç¤ºçš„é‚£ä¸€ç‚¹ï¼Œç„¶åï¼Œæ‚¨åº”è¯¥åœ¨ä¿å­˜ä¹‹å‰å–æ¶ˆåŒ…è£…æ¨¡å‹ã€‚è¿™æ˜¯å› ä¸ºå½“é€šè¿‡[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)æ–¹æ³•æ—¶ï¼Œæ‚¨çš„æ¨¡å‹å¯èƒ½å·²æ”¾ç½®åœ¨ä¸€ä¸ªæ›´å¤§çš„æ¨¡å‹ä¸­ï¼Œè¯¥æ¨¡å‹å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒã€‚è¿™åè¿‡æ¥æ„å‘³ç€ï¼Œä¿å­˜æ¨¡å‹çŠ¶æ€å­—å…¸è€Œä¸é‡‡å–ä»»ä½•é¢„é˜²æªæ–½å°†è€ƒè™‘åˆ°è¯¥æ½œåœ¨çš„é¢å¤–å±‚ï¼Œå¹¶ä¸”æ‚¨æœ€ç»ˆå°†å¾—åˆ°æ— æ³•åœ¨åŸºæœ¬æ¨¡å‹ä¸­åŠ è½½å›çš„æƒé‡ã€‚[save_model()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_model)æ–¹æ³•å°†å¸®åŠ©æ‚¨å®ç°è¿™ä¸€ç‚¹ã€‚å®ƒå°†å–æ¶ˆåŒ…è£…æ‚¨çš„æ¨¡å‹å¹¶ä¿å­˜æ¨¡å‹çŠ¶æ€å­—å…¸ã€‚
- en: 'Here is an example:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªä¾‹å­ï¼š
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The [save_model()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_model)
    method can also save a model into sharded checkpoints or with safetensors format:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: save_model()æ–¹æ³•è¿˜å¯ä»¥å°†æ¨¡å‹ä¿å­˜ä¸ºåˆ†ç‰‡æ£€æŸ¥ç‚¹æˆ–ä½¿ç”¨safetensorsæ ¼å¼ï¼š
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If your script contains logic to load a checkpoint, we also recommend you load
    your weights in the unwrapped model (this is only useful if you use the load function
    after making your model go through [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)).
    Here is an example:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨çš„è„šæœ¬åŒ…å«åŠ è½½æ£€æŸ¥ç‚¹çš„é€»è¾‘ï¼Œæˆ‘ä»¬è¿˜å»ºè®®æ‚¨åœ¨æœªåŒ…è£…çš„æ¨¡å‹ä¸­åŠ è½½æƒé‡ï¼ˆä»…åœ¨ä½¿æ¨¡å‹é€šè¿‡[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)å‡½æ•°åä½¿ç”¨åŠ è½½å‡½æ•°æ—¶æ‰æœ‰ç”¨ï¼‰ã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªä¾‹å­ï¼š
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note that since all the model parameters are references to tensors, this will
    load your weights inside `model`.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œç”±äºæ‰€æœ‰æ¨¡å‹å‚æ•°éƒ½æ˜¯å¯¹å¼ é‡çš„å¼•ç”¨ï¼Œè¿™å°†åœ¨`model`å†…åŠ è½½æ‚¨çš„æƒé‡ã€‚
- en: 'If you want to load a sharded checkpoint or a checkpoint with safetensors format
    into the model with a specific `device`, we recommend you to load it with [load_checkpoint_in_model()](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.load_checkpoint_in_model)
    function. Hereâ€™s an example:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³å°†åˆ†ç‰‡æ£€æŸ¥ç‚¹æˆ–å¸¦æœ‰safetensorsæ ¼å¼çš„æ£€æŸ¥ç‚¹åŠ è½½åˆ°å…·æœ‰ç‰¹å®š`device`çš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ä½¿ç”¨[load_checkpoint_in_model()](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.load_checkpoint_in_model)å‡½æ•°åŠ è½½ã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªä¾‹å­ï¼š
- en: '[PRE18]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Save/load entire states
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¿å­˜/åŠ è½½æ•´ä¸ªçŠ¶æ€
- en: When training your model, you may want to save the current state of the model,
    optimizer, random generators, and potentially learning rate schedulers to be restored
    in the *same script*. You can use [save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)
    and [load_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.load_state)
    respectively to do so.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæ‚¨å¯èƒ½å¸Œæœ›ä¿å­˜æ¨¡å‹çš„å½“å‰çŠ¶æ€ã€ä¼˜åŒ–å™¨ã€éšæœºç”Ÿæˆå™¨ä»¥åŠå¯èƒ½çš„å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œä»¥ä¾¿åœ¨*åŒä¸€è„šæœ¬*ä¸­æ¢å¤ã€‚æ‚¨å¯ä»¥åˆ†åˆ«ä½¿ç”¨[save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)å’Œ[load_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.load_state)æ¥å®ç°ã€‚
- en: To further customize where and how states saved through [save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)
    the [ProjectConfiguration](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.utils.ProjectConfiguration)
    class can be used. For example if `automatic_checkpoint_naming` is enabled each
    saved checkpoint will be located then at `Accelerator.project_dir/checkpoints/checkpoint_{checkpoint_number}`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è¿›ä¸€æ­¥è‡ªå®šä¹‰é€šè¿‡[save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)ä¿å­˜çš„çŠ¶æ€çš„ä½ç½®å’Œæ–¹å¼ï¼Œå¯ä»¥ä½¿ç”¨[ProjectConfiguration](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.utils.ProjectConfiguration)ç±»ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå¯ç”¨äº†`automatic_checkpoint_naming`ï¼Œæ¯ä¸ªä¿å­˜çš„æ£€æŸ¥ç‚¹å°†ä½äº`Accelerator.project_dir/checkpoints/checkpoint_{checkpoint_number}`ã€‚
- en: If you have registered any other stateful items to be stored through [register_for_checkpointing()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.register_for_checkpointing)
    they will also be saved and/or loaded.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å·²ç»é€šè¿‡[register_for_checkpointing()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.register_for_checkpointing)æ³¨å†Œäº†å…¶ä»–éœ€è¦å­˜å‚¨çš„æœ‰çŠ¶æ€é¡¹ç›®ï¼Œå®ƒä»¬ä¹Ÿå°†è¢«ä¿å­˜å’Œ/æˆ–åŠ è½½ã€‚
- en: Every object passed to [register_for_checkpointing()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.register_for_checkpointing)
    must have a `load_state_dict` and `state_dict` function to be stored
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡[register_for_checkpointing()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.register_for_checkpointing)ä¼ é€’çš„æ¯ä¸ªå¯¹è±¡å¿…é¡»å…·æœ‰`load_state_dict`å’Œ`state_dict`å‡½æ•°æ‰èƒ½è¢«å­˜å‚¨
- en: Use gradient clipping
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¢¯åº¦è£å‰ª
- en: If you are using gradient clipping in your script, you should replace the calls
    to `torch.nn.utils.clip_grad_norm_` or `torch.nn.utils.clip_grad_value_` with
    [clip*grad_norm*()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.clip_grad_norm_)
    and [clip*grad_value*()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.clip_grad_value_)
    respectively.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨åœ¨è„šæœ¬ä¸­ä½¿ç”¨æ¢¯åº¦è£å‰ªï¼Œåº”è¯¥å°†å¯¹`torch.nn.utils.clip_grad_norm_`æˆ–`torch.nn.utils.clip_grad_value_`çš„è°ƒç”¨æ›¿æ¢ä¸º[clip*grad_norm*()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.clip_grad_norm_)å’Œ[clip*grad_value*()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.clip_grad_value_)ã€‚
- en: Train with mixed precision
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ··åˆç²¾åº¦è¿›è¡Œè®­ç»ƒ
- en: 'If you are running your training in Mixed Precision with ğŸ¤— Accelerate, you
    will get the best result with your loss being computed inside your model (like
    in Transformer models for instance). Every computation outside of the model will
    be executed in full precision (which is generally what you want for loss computation,
    especially if it involves a softmax). However, you might want to put your loss
    computation inside the [autocast()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.autocast)
    context manager:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨åœ¨ğŸ¤— Accelerateä¸­ä»¥æ··åˆç²¾åº¦è¿è¡Œè®­ç»ƒï¼Œåˆ™æœ€å¥½çš„ç»“æœæ˜¯åœ¨æ¨¡å‹å†…è®¡ç®—æŸå¤±ï¼ˆä¾‹å¦‚åœ¨Transformeræ¨¡å‹ä¸­ï¼‰ã€‚æ¨¡å‹å¤–çš„æ¯ä¸ªè®¡ç®—å°†ä»¥å®Œæ•´ç²¾åº¦æ‰§è¡Œï¼ˆè¿™é€šå¸¸æ˜¯æŸå¤±è®¡ç®—æ‰€éœ€çš„ï¼Œç‰¹åˆ«æ˜¯å¦‚æœæ¶‰åŠsoftmaxï¼‰ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯èƒ½å¸Œæœ›å°†æŸå¤±è®¡ç®—æ”¾åœ¨[autocast()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.autocast)ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­ï¼š
- en: '[PRE19]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Another caveat with Mixed Precision training is that the gradient will skip
    a few updates at the beginning and sometimes during training: because of the dynamic
    loss scaling strategy, there are points during training where the gradients have
    overflown, and the loss scaling factor is reduced to avoid this happening again
    at the next step.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æ··åˆç²¾åº¦è®­ç»ƒçš„å¦ä¸€ä¸ªæ³¨æ„äº‹é¡¹æ˜¯ï¼Œæ¢¯åº¦åœ¨å¼€å§‹æ—¶ä¼šè·³è¿‡å‡ æ¬¡æ›´æ–°ï¼Œæœ‰æ—¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¹Ÿä¼šè·³è¿‡ï¼šç”±äºåŠ¨æ€æŸå¤±ç¼©æ”¾ç­–ç•¥ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­å­˜åœ¨æ¢¯åº¦æº¢å‡ºçš„ç‚¹ï¼ŒæŸå¤±ç¼©æ”¾å› å­ä¼šå‡å°ï¼Œä»¥é¿å…åœ¨ä¸‹ä¸€æ­¥å†æ¬¡å‘ç”Ÿè¿™ç§æƒ…å†µã€‚
- en: 'This means that you may update your learning rate scheduler when there was
    no update, which is fine in general, but may have an impact when you have very
    little training data, or if the first learning rate values of your scheduler are
    very important. In this case, you can skip the learning rate scheduler updates
    when the optimizer step was not done like this:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€å½“æ²¡æœ‰æ›´æ–°æ—¶ï¼Œæ‚¨å¯ä»¥æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿™åœ¨ä¸€èˆ¬æƒ…å†µä¸‹æ˜¯å¯ä»¥çš„ï¼Œä½†åœ¨è®­ç»ƒæ•°æ®å¾ˆå°‘æˆ–è€…è°ƒåº¦å™¨çš„ç¬¬ä¸€ä¸ªå­¦ä¹ ç‡å€¼éå¸¸é‡è¦æ—¶å¯èƒ½ä¼šäº§ç”Ÿå½±å“ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥è·³è¿‡å­¦ä¹ ç‡è°ƒåº¦å™¨çš„æ›´æ–°ï¼Œå°±åƒè¿™æ ·ï¼š
- en: '[PRE20]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Use gradient accumulation
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
- en: 'To perform gradient accumulation use [accumulate()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.accumulate)
    and specify a `gradient_accumulation_steps`. This will also automatically ensure
    the gradients are synced or unsynced when on multi-device training, check if the
    step should actually be performed, and auto-scale the loss:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ‰§è¡Œæ¢¯åº¦ç´¯ç§¯ï¼Œè¯·ä½¿ç”¨[accumulate()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.accumulate)å¹¶æŒ‡å®š`gradient_accumulation_steps`ã€‚è¿™ä¹Ÿä¼šè‡ªåŠ¨ç¡®ä¿åœ¨å¤šè®¾å¤‡è®­ç»ƒæ—¶æ¢¯åº¦æ˜¯åŒæ­¥çš„æˆ–å¼‚æ­¥çš„ï¼Œæ£€æŸ¥æ­¥éª¤æ˜¯å¦å®é™…æ‰§è¡Œï¼Œå¹¶è‡ªåŠ¨ç¼©æ”¾æŸå¤±ï¼š
- en: '[PRE21]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
