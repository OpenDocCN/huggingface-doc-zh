["```py\nimport { AutoProcessor, read_audio } from '@xenova/transformers';\n\nlet processor = await AutoProcessor.from_pretrained('openai/whisper-tiny.en');\nlet audio = await read_audio('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac', 16000);\nlet { input_features } = await processor(audio);\n// Tensor {\n//   data: Float32Array(240000) [0.4752984642982483, 0.5597258806228638, 0.56434166431427, ...],\n//   dims: [1, 80, 3000],\n//   type: 'float32',\n//   size: 240000,\n// }\n```", "```py\nlet processor = await AutoProcessor.from_pretrained('openai/whisper-tiny.en');\n```", "```py\nlet processor = await AutoProcessor.from_pretrained('Xenova/clip-vit-base-patch16');\nlet image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');\nlet image_inputs = await processor(image);\n// {\n//   \"pixel_values\": {\n//     \"dims\": [ 1, 3, 224, 224 ],\n//     \"type\": \"float32\",\n//     \"data\": Float32Array [ -1.558687686920166, -1.558687686920166, -1.5440893173217773, ... ],\n//     \"size\": 150528\n//   },\n//   \"original_sizes\": [\n//     [ 533, 800 ]\n//   ],\n//   \"reshaped_input_sizes\": [\n//     [ 224, 224 ]\n//   ]\n// }\n```"]