["```py\n( num_train_timesteps: int = 1000 beta_start: float = 0.0001 beta_end: float = 0.02 beta_schedule: str = 'linear' trained_betas: Optional = None solver_order: int = 2 prediction_type: str = 'epsilon' thresholding: bool = False dynamic_thresholding_ratio: float = 0.995 sample_max_value: float = 1.0 algorithm_type: str = 'deis' solver_type: str = 'logrho' lower_order_final: bool = True use_karras_sigmas: Optional = False timestep_spacing: str = 'linspace' steps_offset: int = 0 )\n```", "```py\n( model_output: FloatTensor *args sample: FloatTensor = None **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( model_output: FloatTensor *args sample: FloatTensor = None **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( model_output_list: List *args sample: FloatTensor = None **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( model_output_list: List *args sample: FloatTensor = None **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( sample: FloatTensor *args **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( num_inference_steps: int device: Union = None )\n```", "```py\n( model_output: FloatTensor timestep: int sample: FloatTensor return_dict: bool = True ) \u2192 export const metadata = 'undefined';SchedulerOutput or tuple\n```", "```py\n( prev_sample: FloatTensor )\n```"]