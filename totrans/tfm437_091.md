# 拉取请求上的检查

> 原始文本：[`huggingface.co/docs/transformers/v4.37.2/en/pr_checks`](https://huggingface.co/docs/transformers/v4.37.2/en/pr_checks)

当您在🤗 Transformers 上打开拉取请求时，将运行相当多的检查，以确保您添加的补丁不会破坏任何现有内容。这些检查有四种类型：

+   常规测试

+   文档构建

+   代码和文档样式

+   一般存储库一致性

在这份文档中，我们将尝试解释这些各种检查是什么，以及背后的原因，以及如果其中一个在您的 PR 上失败时如何在本地调试它们。

请注意，理想情况下，它们要求您进行开发安装：

```py
pip install transformers[dev]
```

或者进行可编辑安装：

```py
pip install -e .[dev]
```

在 Transformers 存储库内。由于 Transformers 的可选依赖项数量大大增加，您可能无法获得所有依赖项。如果开发安装失败，请确保安装您正在使用的深度学习框架（PyTorch、TensorFlow 和/或 Flax），然后执行以下操作：

```py
pip install transformers[quality]
```

或者进行可编辑安装：

```py
pip install -e .[quality]
```

## 测试

所有以`ci/circleci: run_tests_`开头的作业都运行 Transformers 测试套件的部分。这些作业中的每一个都专注于库的某个部分在特定环境中运行：例如，`ci/circleci: run_tests_pipelines_tf`在仅安装 TensorFlow 的环境中运行 pipelines 测试。

请注意，为了避免在测试的模块中没有真正更改时运行测试，每次只运行测试套件的一部分：运行一个实用程序来确定库中的差异在 PR 之前和之后（GitHub 在“文件更改”选项卡中显示给您的内容），并选择受该差异影响的测试。该实用程序可以在本地运行：

```py
python utils/tests_fetcher.py
```

从 Transformers 存储库的根目录开始。它将：

1.  检查差异中的每个文件，看看更改是在代码中还是仅在注释或文档字符串中。只保留具有真实代码更改的文件。

1.  构建一个内部映射，为库源代码的每个文件提供递归影响的所有文件列表。如果模块 B 导入模块 A，则模块 A 被认为影响模块 B。对于递归影响，我们需要一个从模块 A 到模块 B 的模块链，其中每个模块导入前一个模块。

1.  将此映射应用于第 1 步中收集的文件，这给出了 PR 影响的模型文件列表。

1.  将这些文件映射到它们对应的测试文件，并获取要运行的测试列表。

在本地执行脚本时，您应该得到步骤 1、3 和 4 的结果打印出来，从而知道运行哪些测试。该脚本还将创建一个名为`test_list.txt`的文件，其中包含要运行的测试列表，您可以使用以下命令在本地运行它们：

```py
python -m pytest -n 8 --dist=loadfile -rA -s $(cat test_list.txt)
```

以防有任何遗漏，完整的测试套件也会每天运行。

## 文档构建

`build_pr_documentation`作业构建并生成文档预览，以确保一切在合并您的 PR 后看起来都没问题。机器人将在您的 PR 中添加一个预览文档的链接。您对 PR 所做的任何更改都会自动更新到预览中。如果文档构建失败，请点击失败作业旁边的**详细信息**，查看出了什么问题。通常，错误可能只是`toctree`中缺少文件。

如果您有兴趣在本地构建或预览文档，请查看文档文件夹中的[`README.md`](https://github.com/huggingface/transformers/tree/main/docs)。

## 代码和文档样式

对所有源文件、示例和测试应用代码格式化，使用`black`和`ruff`。我们还有一个自定义工具负责格式化文档字符串和`rst`文件（`utils/style_doc.py`），以及 Transformers `__init__.py`文件中执行的延迟导入顺序（`utils/custom_init_isort.py`）。所有这些都可以通过执行来启动

```py
make style
```

CI 检查这些已应用于`ci/circleci: check_code_quality`检查中。它还运行`ruff`，它将基本查看您的代码，并在找到未定义的变量或未使用的变量时发出投诉。要在本地运行该检查，请使用

```py
make quality
```

这可能需要很长时间，因此要仅对当前分支中修改的文件运行相同的操作，请运行

```py
make fixup
```

这个最后的命令也将运行所有额外的检查，以确保存储库的一致性。让我们来看看它们。

## 存储库的一致性

这将汇总所有测试，以确保您的 PR 使存储库保持良好状态，并由`ci/circleci: check_repository_consistency`检查执行。您可以通过执行以下操作在本地运行该检查：

```py
make repo-consistency
```

这些检查包括：

+   所有添加到 init 中的对象都有文档记录（由`utils/check_repo.py`执行）

+   所有`__init__.py`文件在其两个部分中具有相同的内容（由`utils/check_inits.py`执行）

+   所有被识别为从另一个模块复制的代码与原始代码一致（由`utils/check_copies.py`执行）

+   所有配置类在其 docstrings 中至少提到一个有效的检查点（由`utils/check_config_docstrings.py`执行）

+   所有配置类只包含在相应建模文件中使用的属性（由`utils/check_config_attributes.py`执行）

+   README 和文档索引的翻译与主 README 中的模型列表相同（由`utils/check_copies.py`执行）

+   文档中的自动生成表是最新的（由`utils/check_table.py`执行）

+   即使没有安装所有可选依赖项，库中仍有所有对象可用（由`utils/check_dummies.py`执行）

+   所有 docstrings 都正确记录了对象签名中的参数（由`utils/check_docstrings.py`执行）

如果此检查失败，前两项需要手动修复，最后四项可以通过运行以下命令自动修复

```py
make fix-copies
```

额外的检查涉及添加新模型的 PR，主要是：

+   所有添加的模型都在 Auto-mapping 中（由`utils/check_repo.py`执行）

+   所有模型都经过适当的测试（由`utils/check_repo.py`执行）

### 检查副本

由于 Transformers 库在模型代码方面非常有主见，每个模型应该完全在单个文件中实现，而不依赖于其他模型，因此我们添加了一个机制，检查给定模型的层的代码副本是否与原始代码保持一致。这样，当有 bug 修复时，我们可以看到所有其他受影响的模型，并选择将修改传递下去或打破副本。

如果一个文件是另一个文件的完全副本，您应该在`utils/check_copies.py`的常量`FULL_COPIES`中注册它。

这个机制依赖于形式为`# Copied from xxx`的注释。`xxx`应包含被复制的类或函数的完整路径，该类或函数被复制在下面。例如，`RobertaSelfOutput`是`BertSelfOutput`类的直接副本，因此您可以在[这里](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L289)看到它有一个注释：

```py
# Copied from transformers.models.bert.modeling_bert.BertSelfOutput
```

请注意，您可以将此应用于整个类，也可以将其应用于从中复制的相关方法。例如，在[这里](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L598)中，您可以看到`RobertaPreTrainedModel._init_weights`是从`BertPreTrainedModel`中的相同方法复制的，并带有注释：

```py
# Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights
```

有时副本完全相同，除了名称：例如，在`RobertaAttention`中，我们使用`RobertaSelfAttention`而不是`BertSelfAttention`，但除此之外，代码完全相同。这就是为什么`# Copied from`支持简单的字符串替换，语法如下：`Copied from xxx with foo->bar`。这意味着代码被复制，所有`foo`的实例都被替换为`bar`。您可以在`RobertaAttention`中看到它是如何使用的[这里](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L304C1-L304C86)。

```py
# Copied from transformers.models.bert.modeling_bert.BertAttention with Bert->Roberta
```

请注意箭头周围不应该有任何空格（除非该空格是要替换的模式的一部分）。

您可以添加几个用逗号分隔的模式。例如，在这里`CamemberForMaskedLM`是`RobertaForMaskedLM`的直接副本，有两个替换：`Roberta`替换为`Camembert`和`ROBERTA`替换为`CAMEMBERT`。您可以在[这里](https://github.com/huggingface/transformers/blob/15082a9dc6950ecae63a0d3e5060b2fc7f15050a/src/transformers/models/camembert/modeling_camembert.py#L929)看到这是如何完成的，带有注释：

```py
# Copied from transformers.models.roberta.modeling_roberta.RobertaForMaskedLM with Roberta->Camembert, ROBERTA->CAMEMBERT
```

如果顺序很重要（因为其中一个替换可能与先前的替换冲突），则替换从左到右执行。

如果替换改变了格式（例如，如果您用一个非常长的名称替换一个短名称），则在应用自动格式化程序后会检查副本。

当模式只是相同替换的不同大小写形式（具有大写和小写变体）时，另一种方法就是添加选项`all-casing`。[这里](https://github.com/huggingface/transformers/blob/15082a9dc6950ecae63a0d3e5060b2fc7f15050a/src/transformers/models/mobilebert/modeling_mobilebert.py#L1237)是`MobileBertForSequenceClassification`中的一个示例，带有注释：

```py
# Copied from transformers.models.bert.modeling_bert.BertForSequenceClassification with Bert->MobileBert all-casing
```

在这种情况下，代码是通过替换`BertForSequenceClassification`复制的：

+   `Bert`替换为`MobileBert`（例如，在 init 中使用`MobileBertModel`时）

+   `bert`替换为`mobilebert`（例如在定义`self.mobilebert`时）

+   `BERT`替换为`MOBILEBERT`（在常量`MOBILEBERT_INPUTS_DOCSTRING`中）
