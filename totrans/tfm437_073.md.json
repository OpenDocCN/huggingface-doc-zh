["```py\npip install oneccl_bind_pt=={pytorch_version} -f https://developer.intel.com/ipex-whl-stable-cpu\n```", "```py\noneccl_bindings_for_pytorch_path=$(python -c \"from oneccl_bindings_for_pytorch import cwd; print(cwd)\")\nsource $oneccl_bindings_for_pytorch_path/env/setvars.sh\n```", "```py\ntorch_ccl_path=$(python -c \"import torch; import torch_ccl; import os;  print(os.path.abspath(os.path.dirname(torch_ccl.__file__)))\")\nsource $torch_ccl_path/env/setvars.sh\n```", "```py\n export CCL_WORKER_COUNT=1\n export MASTER_ADDR=127.0.0.1\n mpirun -n 2 -genv OMP_NUM_THREADS=23 \\\n python3 run_qa.py \\\n --model_name_or_path bert-large-uncased \\\n --dataset_name squad \\\n --do_train \\\n --do_eval \\\n --per_device_train_batch_size 12  \\\n --learning_rate 3e-5  \\\n --num_train_epochs 2  \\\n --max_seq_length 384 \\\n --doc_stride 128  \\\n --output_dir /tmp/debug_squad/ \\\n --no_cuda \\\n --ddp_backend ccl \\\n --use_ipex\n```", "```py\n cat hostfile\n xxx.xxx.xxx.xxx #node0 ip\n xxx.xxx.xxx.xxx #node1 ip\n```", "```py\n export CCL_WORKER_COUNT=1\n export MASTER_ADDR=xxx.xxx.xxx.xxx #node0 ip\n mpirun -f hostfile -n 4 -ppn 2 \\\n -genv OMP_NUM_THREADS=23 \\\n python3 run_qa.py \\\n --model_name_or_path bert-large-uncased \\\n --dataset_name squad \\\n --do_train \\\n --do_eval \\\n --per_device_train_batch_size 12  \\\n --learning_rate 3e-5  \\\n --num_train_epochs 2  \\\n --max_seq_length 384 \\\n --doc_stride 128  \\\n --output_dir /tmp/debug_squad/ \\\n --no_cuda \\\n --ddp_backend ccl \\\n --use_ipex \\\n --bf16\n```", "```py\nFROM intel/ai-workflows:torch-2.0.1-huggingface-multinode-py3.9\n\nWORKDIR /workspace\n\n# Download and extract the transformers code\nARG HF_TRANSFORMERS_VER=\"4.35.2\"\nRUN mkdir transformers && \\\n    curl -sSL --retry 5 https://github.com/huggingface/transformers/archive/refs/tags/v${HF_TRANSFORMERS_VER}.tar.gz | tar -C transformers --strip-components=1 -xzf -\n```", "```py\napiVersion: \"kubeflow.org/v1\"\nkind: PyTorchJob\nmetadata:\n  name: transformers-pytorchjob\n  namespace: kubeflow\nspec:\n  elasticPolicy:\n    rdzvBackend: c10d\n    minReplicas: 1\n    maxReplicas: 4\n    maxRestarts: 10\n  pytorchReplicaSpecs:\n    Worker:\n      replicas: 4  # The number of worker pods\n      restartPolicy: OnFailure\n      template:\n        spec:\n          containers:\n            - name: pytorch\n              image: <image name>:<tag>  # Specify the docker image to use for the worker pods\n              imagePullPolicy: IfNotPresent\n              command:\n                - torchrun\n                - /workspace/transformers/examples/pytorch/question-answering/run_qa.py\n                - --model_name_or_path\n                - \"bert-large-uncased\"\n                - --dataset_name\n                - \"squad\"\n                - --do_train\n                - --do_eval\n                - --per_device_train_batch_size\n                - \"12\"\n                - --learning_rate\n                - \"3e-5\"\n                - --num_train_epochs\n                - \"2\"\n                - --max_seq_length\n                - \"384\"\n                - --doc_stride\n                - \"128\"\n                - --output_dir\n                - \"/tmp/pvc-mount/output\"\n                - --no_cuda\n                - --ddp_backend\n                - \"ccl\"\n                - --use_ipex\n                - --bf16  # Specify --bf16 if your hardware supports bfloat16\n              env:\n              - name: LD_PRELOAD\n                value: \"/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9:/usr/local/lib/libiomp5.so\"\n              - name: TRANSFORMERS_CACHE\n                value: \"/tmp/pvc-mount/transformers_cache\"\n              - name: HF_DATASETS_CACHE\n                value: \"/tmp/pvc-mount/hf_datasets_cache\"\n              - name: LOGLEVEL\n                value: \"INFO\"\n              - name: CCL_WORKER_COUNT\n                value: \"1\"\n              - name: OMP_NUM_THREADS  # Can be tuned for optimal performance\n-                value: \"56\"\n              resources:\n                limits:\n                  cpu: 200  # Update the CPU and memory limit values based on your nodes\n                  memory: 128Gi\n                requests:\n                  cpu: 200  # Update the CPU and memory request values based on your nodes\n                  memory: 128Gi\n              volumeMounts:\n              - name: pvc-volume\n                mountPath: /tmp/pvc-mount\n              - mountPath: /dev/shm\n                name: dshm\n          restartPolicy: Never\n          nodeSelector:  #  Optionally use the node selector to specify what types of nodes to use for the workers\n            node-type: spr\n          volumes:\n          - name: pvc-volume\n            persistentVolumeClaim:\n              claimName: transformers-pvc\n          - name: dshm\n            emptyDir:\n              medium: Memory\n```", "```py\nkubectl create -f pytorchjob.yaml\n```", "```py\nNAME                                                     READY   STATUS                  RESTARTS          AGE\n...\ntransformers-pytorchjob-worker-0                         1/1     Running                 0                 7m37s\ntransformers-pytorchjob-worker-1                         1/1     Running                 0                 7m37s\ntransformers-pytorchjob-worker-2                         1/1     Running                 0                 7m37s\ntransformers-pytorchjob-worker-3                         1/1     Running                 0                 7m37s\n...\n```", "```py\nkubectl logs -n kubeflow transformers-pytorchjob-worker-0 -f\n```"]