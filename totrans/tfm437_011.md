# ä½¿ç”¨ğŸ¤— Accelerate è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/accelerate`](https://huggingface.co/docs/transformers/v4.37.2/en/accelerate)

éšç€æ¨¡å‹å˜å¾—æ›´å¤§ï¼Œå¹¶è¡Œæ€§å·²ç»æˆä¸ºåœ¨æœ‰é™ç¡¬ä»¶ä¸Šè®­ç»ƒæ›´å¤§æ¨¡å‹å¹¶é€šè¿‡å‡ ä¸ªæ•°é‡çº§åŠ é€Ÿè®­ç»ƒé€Ÿåº¦çš„ç­–ç•¥ã€‚åœ¨ Hugging Faceï¼Œæˆ‘ä»¬åˆ›å»ºäº†[ğŸ¤— Accelerate](https://huggingface.co/docs/accelerate)åº“ï¼Œä»¥å¸®åŠ©ç”¨æˆ·è½»æ¾åœ°åœ¨ä»»ä½•ç±»å‹çš„åˆ†å¸ƒå¼è®¾ç½®ä¸Šè®­ç»ƒğŸ¤— Transformers æ¨¡å‹ï¼Œæ— è®ºæ˜¯åœ¨ä¸€å°æœºå™¨ä¸Šçš„å¤šä¸ª GPU è¿˜æ˜¯è·¨å¤šå°æœºå™¨çš„å¤šä¸ª GPUã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œäº†è§£å¦‚ä½•è‡ªå®šä¹‰æ‚¨çš„æœ¬åœ° PyTorch è®­ç»ƒå¾ªç¯ä»¥åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è¿›è¡Œè®­ç»ƒã€‚

## è®¾ç½®

é€šè¿‡å®‰è£…ğŸ¤— Accelerate å¼€å§‹ï¼š

```py
pip install accelerate
```

ç„¶åå¯¼å…¥å¹¶åˆ›å»ºä¸€ä¸ª[Accelerator](https://huggingface.co/docs/accelerate/v0.26.1/en/package_reference/accelerator#accelerate.Accelerator)å¯¹è±¡ã€‚[Accelerator](https://huggingface.co/docs/accelerate/v0.26.1/en/package_reference/accelerator#accelerate.Accelerator)å°†è‡ªåŠ¨æ£€æµ‹æ‚¨çš„åˆ†å¸ƒå¼è®¾ç½®ç±»å‹ï¼Œå¹¶åˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„ç»„ä»¶è¿›è¡Œè®­ç»ƒã€‚æ‚¨ä¸éœ€è¦æ˜ç¡®å°†æ¨¡å‹æ”¾åœ¨è®¾å¤‡ä¸Šã€‚

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
```

## å‡†å¤‡åŠ é€Ÿ

ä¸‹ä¸€æ­¥æ˜¯å°†æ‰€æœ‰ç›¸å…³çš„è®­ç»ƒå¯¹è±¡ä¼ é€’ç»™[prepare](https://huggingface.co/docs/accelerate/v0.26.1/en/package_reference/accelerator#accelerate.Accelerator.prepare)æ–¹æ³•ã€‚è¿™åŒ…æ‹¬æ‚¨çš„è®­ç»ƒå’Œè¯„ä¼° DataLoadersï¼Œä¸€ä¸ªæ¨¡å‹å’Œä¸€ä¸ªä¼˜åŒ–å™¨ï¼š

```py
>>> train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
...     train_dataloader, eval_dataloader, model, optimizer
... )
```

## å‘å

æœ€åä¸€ä¸ªè¡¥å……æ˜¯ç”¨ğŸ¤— Accelerate çš„[backward](https://huggingface.co/docs/accelerate/v0.26.1/en/package_reference/accelerator#accelerate.Accelerator.backward)æ–¹æ³•æ›¿æ¢è®­ç»ƒå¾ªç¯ä¸­å…¸å‹çš„`loss.backward()`ï¼š

```py
>>> for epoch in range(num_epochs):
...     for batch in train_dataloader:
...         outputs = model(**batch)
...         loss = outputs.loss
...         accelerator.backward(loss)

...         optimizer.step()
...         lr_scheduler.step()
...         optimizer.zero_grad()
...         progress_bar.update(1)
```

å¦‚ä¸‹é¢çš„ä»£ç æ‰€ç¤ºï¼Œæ‚¨åªéœ€è¦å‘è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ å››è¡Œé¢å¤–çš„ä»£ç å³å¯å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒï¼

```py
+ from accelerate import Accelerator
  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler

+ accelerator = Accelerator()

  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
  optimizer = AdamW(model.parameters(), lr=3e-5)

- device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
- model.to(device)

+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
+     train_dataloader, eval_dataloader, model, optimizer
+ )

  num_epochs = 3
  num_training_steps = num_epochs * len(train_dataloader)
  lr_scheduler = get_scheduler(
      "linear",
      optimizer=optimizer,
      num_warmup_steps=0,
      num_training_steps=num_training_steps
  )

  progress_bar = tqdm(range(num_training_steps))

  model.train()
  for epoch in range(num_epochs):
      for batch in train_dataloader:
-         batch = {k: v.to(device) for k, v in batch.items()}
          outputs = model(**batch)
          loss = outputs.loss
-         loss.backward()
+         accelerator.backward(loss)

          optimizer.step()
          lr_scheduler.step()
          optimizer.zero_grad()
          progress_bar.update(1)
```

## è®­ç»ƒ

æ·»åŠ äº†ç›¸å…³ä»£ç è¡Œåï¼Œå¯ä»¥åœ¨è„šæœ¬æˆ–ç±»ä¼¼ Colaboratory çš„ç¬”è®°æœ¬ä¸­å¯åŠ¨è®­ç»ƒã€‚

### ä½¿ç”¨è„šæœ¬è¿›è¡Œè®­ç»ƒ

å¦‚æœæ‚¨ä»è„šæœ¬ä¸­è¿è¡Œè®­ç»ƒï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥åˆ›å»ºå¹¶ä¿å­˜é…ç½®æ–‡ä»¶ï¼š

```py
accelerate config
```

ç„¶åå¯åŠ¨æ‚¨çš„è®­ç»ƒï¼š

```py
accelerate launch train.py
```

### ä½¿ç”¨ç¬”è®°æœ¬è¿›è¡Œè®­ç»ƒ

ğŸ¤— Accelerate ä¹Ÿå¯ä»¥åœ¨ç¬”è®°æœ¬ä¸­è¿è¡Œï¼Œå¦‚æœæ‚¨è®¡åˆ’ä½¿ç”¨ Colaboratory çš„ TPUã€‚å°†è´Ÿè´£è®­ç»ƒçš„æ‰€æœ‰ä»£ç åŒ…è£…åœ¨ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™[notebook_launcher](https://huggingface.co/docs/accelerate/v0.26.1/en/package_reference/launchers#accelerate.notebook_launcher)ï¼š

```py
>>> from accelerate import notebook_launcher

>>> notebook_launcher(training_function)
```

æœ‰å…³ğŸ¤— Accelerate åŠå…¶ä¸°å¯ŒåŠŸèƒ½çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ[æ–‡æ¡£](https://huggingface.co/docs/accelerate)ã€‚
