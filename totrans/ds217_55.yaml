- en: Dataset features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/datasets/about_dataset_features](https://huggingface.co/docs/datasets/about_dataset_features)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: '[Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    defines the internal structure of a dataset. It is used to specify the underlying
    serialization format. Whatâ€™s more interesting to you though is that [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    contains high-level information about everything from the column names and types,
    to the [ClassLabel](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel).
    You can think of [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    as the backbone of a dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    format is simple: `dict[column_name, column_type]`. It is a dictionary of column
    name and column type pairs. The column type provides a wide range of options for
    describing the type of data you have.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Letâ€™s have a look at the features of the MRPC dataset from the GLUE benchmark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The [Value](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Value)
    feature tells ðŸ¤— Datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: The `idx` data type is `int32`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `sentence1` and `sentence2` data types are `string`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ðŸ¤— Datasets supports many other data types such as `bool`, `float32` and `binary`
    to name just a few.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to [Value](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Value)
    for a full list of supported data types.
  prefs: []
  type: TYPE_NORMAL
- en: The [ClassLabel](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel)
    feature informs ðŸ¤— Datasets the `label` column contains two classes. The classes
    are labeled `not_equivalent` and `equivalent`. Labels are stored as integers in
    the dataset. When you retrieve the labels, [ClassLabel.int2str()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel.int2str)
    and [ClassLabel.str2int()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel.str2int)
    carries out the conversion from integer value to label name, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: If your data type contains a list of objects, then you want to use the [Sequence](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Sequence)
    feature. Remember the SQuAD dataset?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `answers` field is constructed using the [Sequence](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Sequence)
    feature because it contains two subfields, `text` and `answer_start`, which are
    lists of `string` and `int32`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: See the [flatten](./process#flatten) section to learn how you can extract the
    nested subfields as their own independent columns.
  prefs: []
  type: TYPE_NORMAL
- en: The array feature type is useful for creating arrays of various sizes. You can
    create arrays with two dimensions using [Array2D](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Array2D),
    and even arrays with five dimensions using [Array5D](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Array5D).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The array type also allows the first dimension of the array to be dynamic. This
    is useful for handling sequences with variable lengths such as sentences, without
    having to pad or truncate the input to a uniform shape.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Audio feature
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Audio datasets have a column with type [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio),
    which contains three important fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`array`: the decoded audio data represented as a 1-dimensional array.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`path`: the path to the downloaded audio file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sampling_rate`: the sampling rate of the audio data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When you load an audio dataset and call the audio column, the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature automatically decodes and resamples the audio file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Index into an audio dataset using the row index first and then the `audio` column
    - `dataset[0]["audio"]` - to avoid decoding and resampling all the audio files
    in the dataset. Otherwise, this can be a slow and time-consuming process if you
    have a large dataset.
  prefs: []
  type: TYPE_NORMAL
- en: With `decode=False`, the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    type simply gives you the path or the bytes of the audio file, without decoding
    it into an `array`,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Image feature
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Image datasets have a column with type [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image),
    which loads `PIL.Image` objects from images stored as bytes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'When you load an image dataset and call the image column, the [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)
    feature automatically decodes the image file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Index into an image dataset using the row index first and then the `image` column
    - `dataset[0]["image"]` - to avoid decoding all the image files in the dataset.
    Otherwise, this can be a slow and time-consuming process if you have a large dataset.
  prefs: []
  type: TYPE_NORMAL
- en: With `decode=False`, the [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)
    type simply gives you the path or the bytes of the image file, without decoding
    it into an `PIL.Image`,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Depending on the dataset, you may get the path to the local downloaded image,
    or the content of the image as bytes if the dataset is not made of individual
    files.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also define a dataset of images from numpy arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: And in this case the numpy arrays are encoded into PNG (or TIFF if the pixels
    values precision is important).
  prefs: []
  type: TYPE_NORMAL
- en: 'For multi-channels arrays like RGB or RGBA, only uint8 is supported. If you
    use a larger precision, you get a warning and the array is downcasted to uint8.
    For gray-scale images you can use the integer or float precision you want as long
    as it is compatible with `Pillow`. A warning is shown if your image integer or
    float precision is too high, and in this case the array is downcated: an int64
    array is downcasted to int32, and a float64 array is downcasted to float32.'
  prefs: []
  type: TYPE_NORMAL
