# 图像处理器

> 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/image_processor](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/image_processor)

图像处理器负责为视觉模型准备输入特征并后处理它们的输出。这包括诸如调整大小、归一化和转换为PyTorch、TensorFlow、Flax和Numpy张量等转换。它还可能包括模型特定的后处理，如将对数转换为分割掩模。

## ImageProcessingMixin

### `class transformers.ImageProcessingMixin`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L68)

```py
( **kwargs )
```

这是一个用于为顺序和图像特征提取器提供保存/加载功能的图像处理器mixin。

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L95)

```py
( pretrained_model_name_or_path: Union cache_dir: Union = None force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str`或`os.PathLike`) — 这可以是：

    +   一个字符串，预训练的图像处理器的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。

    +   一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained)方法保存的图像处理器文件，例如，`./my_model_directory/`。

    +   一个保存的图像处理器JSON *文件*的路径或URL，例如，`./my_model_directory/preprocessor_config.json`。

+   `cache_dir` (`str`或`os.PathLike`, *可选*) — 预下载的预训练模型图像处理器应该缓存在其中的目录路径，如果不使用标准缓存。

+   `force_download` (`bool`, *可选*, 默认为`False`) — 是否强制（重新）下载图像处理器文件并覆盖缓存版本（如果存在）。

+   `resume_download` (`bool`, *可选*, 默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，尝试恢复下载。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理在每个请求中使用。

+   `token` (`str`或`bool`, *可选*) — 用作远程文件的HTTP bearer授权的令牌。如果为`True`或未指定，将使用运行`huggingface-cli login`时生成的令牌（存储在`~/.huggingface`中）。

+   `revision` (`str`, *可选*, 默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。

从图像处理器实例化一个类型的[ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)。

示例：

```py
# We can't instantiate directly the base class *ImageProcessingMixin* so let's show the examples on a
# derived class: *CLIPImageProcessor*
image_processor = CLIPImageProcessor.from_pretrained(
    "openai/clip-vit-base-patch32"
)  # Download image_processing_config from huggingface.co and cache.
image_processor = CLIPImageProcessor.from_pretrained(
    "./test/saved_model/"
)  # E.g. image processor (or model) was saved using *save_pretrained('./test/saved_model/')*
image_processor = CLIPImageProcessor.from_pretrained("./test/saved_model/preprocessor_config.json")
image_processor = CLIPImageProcessor.from_pretrained(
    "openai/clip-vit-base-patch32", do_normalize=False, foo=False
)
assert image_processor.do_normalize is False
image_processor, unused_kwargs = CLIPImageProcessor.from_pretrained(
    "openai/clip-vit-base-patch32", do_normalize=False, foo=False, return_unused_kwargs=True
)
assert image_processor.do_normalize is False
assert unused_kwargs == {"foo": False}
```

#### `save_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L210)

```py
( save_directory: Union push_to_hub: bool = False **kwargs )
```

参数

+   `save_directory` (`str`或`os.PathLike`) — 将保存图像处理器JSON文件的目录（如果不存在，将创建）。

+   `push_to_hub` (`bool`, *可选*, 默认为`False`) — 是否在保存后将模型推送到Hugging Face模型中心。您可以使用`repo_id`指定要推送到的存储库（将默认为您的命名空间中的`save_directory`名称）。

+   `kwargs` (`Dict[str, Any]`, *可选*) — 传递给[push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)方法的额外关键字参数。

将图像处理器对象保存到目录`save_directory`，以便可以使用[from_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.from_pretrained)类方法重新加载。

## BatchFeature

### `class transformers.BatchFeature`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L61)

```py
( data: Optional = None tensor_type: Union = None )
```

参数

+   `data`（`dict`，*可选*）- 由**call**/pad方法返回的列表/数组/张量的字典（'input_values'，'attention_mask'等）。

+   `tensor_type`（`Union[None, str, TensorType]`，*可选*）- 您可以在此处给出一个tensor_type，以在初始化时将整数列表转换为PyTorch/TensorFlow/Numpy张量。

保存[pad()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor.pad)和特定特征提取器`__call__`方法的输出。

这个类是从一个Python字典派生而来的，可以作为一个字典使用。

#### `convert_to_tensors`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L164)

```py
( tensor_type: Union = None )
```

参数

+   `tensor_type`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）- 要使用的张量类型。如果是`str`，应该是枚举[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)的值之一。如果是`None`，则不进行修改。

将内部内容转换为张量。

#### `to`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L195)

```py
( *args **kwargs ) → export const metadata = 'undefined';BatchFeature
```

参数

+   `args`（`Tuple`）- 将传递给张量的`to(...)`函数。

+   `kwargs`（`Dict`，*可选*）- 将传递给张量的`to(...)`函数。

返回

[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)

修改后的相同实例。

通过调用`v.to(*args, **kwargs)`将所有值发送到设备（仅适用于PyTorch）。这应该支持在不同的`dtypes`中进行转换，并将`BatchFeature`发送到不同的`device`。

## BaseImageProcessor

### `class transformers.image_processing_utils.BaseImageProcessor`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L546)

```py
( **kwargs )
```

#### `center_crop`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L626)

```py
( image: ndarray size: Dict data_format: Union = None input_data_format: Union = None **kwargs )
```

参数

+   `image`（`np.ndarray`）- 要居中裁剪的图像。

+   `size`（`Dict[str, int]`）- 输出图像的大小。

+   `data_format`（`str`或`ChannelDimension`，*可选*）- 输出图像的通道维度格式。如果未设置，则使用输入图像的通道维度格式。可以是以下之一：

    +   `"channels_first"`或`ChannelDimension.FIRST`：图像以(num_channels, height, width)格式。

    +   `"channels_last"`或`ChannelDimension.LAST`：图像以(height, width, num_channels)格式。

+   `input_data_format`（`ChannelDimension`或`str`，*可选*）- 输入图像的通道维度格式。如果未设置，则从输入图像推断通道维度格式。可以是以下之一：

    +   `"channels_first"`或`ChannelDimension.FIRST`：图像以(num_channels, height, width)格式。

    +   `"channels_last"`或`ChannelDimension.LAST`：图像以(height, width, num_channels)格式。

将图像居中裁剪到`(size["height"], size["width"])`。如果输入尺寸沿任何边小于`crop_size`，则图像将填充为0，然后居中裁剪。

#### `normalize`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L589)

```py
( image: ndarray mean: Union std: Union data_format: Union = None input_data_format: Union = None **kwargs ) → export const metadata = 'undefined';np.ndarray
```

参数

+   `image`（`np.ndarray`）- 要归一化的图像。

+   `mean`（`float`或`Iterable[float]`）- 用于归一化的图像均值。

+   `std`（`float`或`Iterable[float]`）- 用于归一化的图像标准差。

+   `data_format` (`str` 或 `ChannelDimension`，*可选*) — 输出图像的通道维度格式。如果未设置，则使用输入图像的通道维度格式。可以是以下之一：

    +   `"channels_first"` 或 `ChannelDimension.FIRST`：图像以 (通道数, 高度, 宽度) 格式。

    +   `"channels_last"` 或 `ChannelDimension.LAST`：图像以 (高度, 宽度, 通道数) 格式。

+   `input_data_format` (`ChannelDimension` 或 `str`，*可选*) — 输入图像的通道维度格式。如果未设置，则从输入图像中推断通道维度格式。可以是以下之一：

    +   `"channels_first"` 或 `ChannelDimension.FIRST`：图像以 (通道数, 高度, 宽度) 格式。

    +   `"channels_last"` 或 `ChannelDimension.LAST`：图像以 (高度, 宽度, 通道数) 格式。

返回值

`np.ndarray`

归一化后的图像。

归一化图像。图像 = (图像 - 图像均值) / 图像标准差。

#### `重新缩放`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L557)

```py
( image: ndarray scale: float data_format: Union = None input_data_format: Union = None **kwargs ) → export const metadata = 'undefined';np.ndarray
```

参数

+   `image` (`np.ndarray`) — 要重新缩放的图像。

+   `scale` (`float`) — 用于重新缩放像素值的缩放因子。

+   `data_format` (`str` 或 `ChannelDimension`，*可选*) — 输出图像的通道维度格式。如果未设置，则使用输入图像的通道维度格式。可以是以下之一：

    +   `"channels_first"` 或 `ChannelDimension.FIRST`：图像以 (通道数, 高度, 宽度) 格式。

    +   `"channels_last"` 或 `ChannelDimension.LAST`：图像以 (高度, 宽度, 通道数) 格式。

+   `input_data_format` (`ChannelDimension` 或 `str`，*可选*) — 输入图像的通道维度格式。如果未设置，则从输入图像中推断通道维度格式。可以是以下之一：

    +   `"channels_first"` 或 `ChannelDimension.FIRST`：图像以 (通道数, 高度, 宽度) 格式。

    +   `"channels_last"` 或 `ChannelDimension.LAST`：图像以 (高度, 宽度, 通道数) 格式。

返回值

`np.ndarray`

重新缩放后的图像。

通过缩放因子重新缩放图像。图像 = 图像 * 缩放因子。
