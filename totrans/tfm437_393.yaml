- en: Utilities for Tokenizers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分词器实用程序
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/internal/tokenization_utils](https://huggingface.co/docs/transformers/v4.37.2/en/internal/tokenization_utils)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/internal/tokenization_utils](https://huggingface.co/docs/transformers/v4.37.2/en/internal/tokenization_utils)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This page lists all the utility functions used by the tokenizers, mainly the
    class [PreTrainedTokenizerBase](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase)
    that implements the common methods between [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    and [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    and the mixin [SpecialTokensMixin](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.SpecialTokensMixin).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 此页面列出了分词器使用的所有实用函数，主要是实现 [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    和 [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    之间的常见方法的类 [PreTrainedTokenizerBase](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase)
    和混合 [SpecialTokensMixin](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.SpecialTokensMixin)。
- en: Most of those are only useful if you are studying the code of the tokenizers
    in the library.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，这些只有在研究库中的分词器代码时才有用。
- en: PreTrainedTokenizerBase
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PreTrainedTokenizerBase
- en: '### `class transformers.PreTrainedTokenizerBase`'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.PreTrainedTokenizerBase`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L1543)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L1543)'
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model_max_length` (`int`, *optional*) — The maximum length (in number of tokens)
    for the inputs to the transformer model. When the tokenizer is loaded with [from_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained),
    this will be set to the value stored for the associated model in `max_model_input_sizes`
    (see above). If no value is provided, will default to VERY_LARGE_INTEGER (`int(1e30)`).'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_max_length` (`int`, *可选*) — 输入到变换器模型的最大长度（以标记数计）。当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained)
    加载分词器时，此值将设置为存储在 `max_model_input_sizes` 中关联模型的值（参见上文）。如果未提供值，将默认为 VERY_LARGE_INTEGER
    (`int(1e30)`).'
- en: '`padding_side` (`str`, *optional*) — The side on which the model should have
    padding applied. Should be selected between [‘right’, ‘left’]. Default value is
    picked from the class attribute of the same name.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_side` (`str`, *可选*) — 模型应该应用填充的一侧。应在 [''right'', ''left''] 中选择。默认值从同名类属性中选择。'
- en: '`truncation_side` (`str`, *optional*) — The side on which the model should
    have truncation applied. Should be selected between [‘right’, ‘left’]. Default
    value is picked from the class attribute of the same name.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation_side` (`str`, *可选*) — 模型应该应用截断的一侧。应在 [''right'', ''left''] 中选择。默认值从同名类属性中选择。'
- en: '`chat_template` (`str`, *optional*) — A Jinja template string that will be
    used to format lists of chat messages. See [https://huggingface.co/docs/transformers/chat_templating](https://huggingface.co/docs/transformers/chat_templating)
    for a full description.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chat_template` (`str`, *可选*) — 用于格式化聊天消息列表的 Jinja 模板字符串。查看 [https://huggingface.co/docs/transformers/chat_templating](https://huggingface.co/docs/transformers/chat_templating)
    获取完整描述。'
- en: '`model_input_names` (`List[string]`, *optional*) — The list of inputs accepted
    by the forward pass of the model (like `"token_type_ids"` or `"attention_mask"`).
    Default value is picked from the class attribute of the same name.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_input_names` (`List[string]`, *可选*) — 模型前向传递接受的输入列表（如 `"token_type_ids"`
    或 `"attention_mask"`）。默认值从同名类属性中选择。'
- en: '`bos_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing the beginning of a sentence. Will be associated to `self.bos_token`
    and `self.bos_token_id`.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str` 或 `tokenizers.AddedToken`, *可选*) — 代表句子开头的特殊标记。将与 `self.bos_token`
    和 `self.bos_token_id` 相关联。'
- en: '`eos_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing the end of a sentence. Will be associated to `self.eos_token` and
    `self.eos_token_id`.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token` (`str` 或 `tokenizers.AddedToken`, *可选*) — 代表句子结尾的特殊标记。将与 `self.eos_token`
    和 `self.eos_token_id` 相关联。'
- en: '`unk_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing an out-of-vocabulary token. Will be associated to `self.unk_token`
    and `self.unk_token_id`.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str` 或 `tokenizers.AddedToken`, *可选*) — 代表一个未知词的特殊标记。将与 `self.unk_token`
    和 `self.unk_token_id` 相关联。'
- en: '`sep_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    separating two different sentences in the same input (used by BERT for instance).
    Will be associated to `self.sep_token` and `self.sep_token_id`.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str` 或 `tokenizers.AddedToken`, *可选*) — 用于在同一输入中分隔两个不同句子的特殊标记（例如，BERT
    使用）。将与 `self.sep_token` 和 `self.sep_token_id` 相关联。'
- en: '`pad_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    used to make arrays of tokens the same size for batching purpose. Will then be
    ignored by attention mechanisms or loss computation. Will be associated to `self.pad_token`
    and `self.pad_token_id`.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str` 或 `tokenizers.AddedToken`, *可选*) — 用于使标记数组大小相同以进行批处理的特殊标记。然后将被注意机制或损失计算忽略。将与
    `self.pad_token` 和 `self.pad_token_id` 相关联。'
- en: '`cls_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing the class of the input (used by BERT for instance). Will be associated
    to `self.cls_token` and `self.cls_token_id`.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str` 或 `tokenizers.AddedToken`, *可选*) — 代表输入类别的特殊标记（例如，BERT 使用）。将与
    `self.cls_token` 和 `self.cls_token_id` 相关联。'
- en: '`mask_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing a masked token (used by masked-language modeling pretraining objectives,
    like BERT). Will be associated to `self.mask_token` and `self.mask_token_id`.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str` 或 `tokenizers.AddedToken`, *可选*) — 代表一个被屏蔽的标记的特殊标记（用于掩码语言建模预训练目标，如
    BERT）。将与 `self.mask_token` 和 `self.mask_token_id` 相关联。'
- en: '`additional_special_tokens` (tuple or list of `str` or `tokenizers.AddedToken`,
    *optional*) — A tuple or a list of additional special tokens. Add them here to
    ensure they are skipped when decoding with `skip_special_tokens` is set to True.
    If they are not part of the vocabulary, they will be added at the end of the vocabulary.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`additional_special_tokens`（元组或`str`或`tokenizers.AddedToken`的列表，*可选*） — 附加特殊标记的元组或列表。在此处添加它们以确保在`skip_special_tokens`设置为True时解码时跳过它们。如果它们不是词汇的一部分，它们将被添加到词汇的末尾。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*, defaults to `True`) — Whether
    or not the model should cleanup the spaces that were added when splitting the
    input text during the tokenization process.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces` (`bool`, *可选*，默认为`True`) — 模型是否应清除在分词过程中拆分输入文本时添加的空格。'
- en: '`split_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the special tokens should be split during the tokenization process. The
    default behavior is to not split special tokens. This means that if `<s>` is the
    `bos_token`, then `tokenizer.tokenize("<s>") = [''<s>`]. Otherwise, if `split_special_tokens=True`,
    then `tokenizer.tokenize("<s>")` will be give `[''<'', ''s'', ''>'']`. This argument
    is only supported for `slow` tokenizers for the moment.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`split_special_tokens` (`bool`, *可选*，默认为`False`) — 特殊标记是否应在分词过程中拆分。默认行为是不拆分特殊标记。这意味着如果`<s>`是`bos_token`，那么`tokenizer.tokenize("<s>")
    = [''<s>`]`。否则，如果`split_special_tokens=True`，那么`tokenizer.tokenize("<s>")`将给出`[''<'',
    ''s'', ''>'']`。目前仅支持`slow`分词器支持此参数。'
- en: Base class for [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    and [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)和[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)的基类。'
- en: Handles shared (mostly boiler plate) methods for those two classes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这两个类的共享（大部分是样板）方法。
- en: Class attributes (overridden by derived classes)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 类属性（由派生类覆盖）
- en: '`vocab_files_names` (`Dict[str, str]`) — A dictionary with, as keys, the `__init__`
    keyword name of each vocabulary file required by the model, and as associated
    values, the filename for saving the associated file (string).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_files_names` (`Dict[str, str]`) — 一个字典，其中键是模型所需的每个词汇文件的`__init__`关键字名称，关联值是用于保存关联文件的文件名（字符串）。'
- en: '`pretrained_vocab_files_map` (`Dict[str, Dict[str, str]]`) — A dictionary of
    dictionaries, with the high-level keys being the `__init__` keyword name of each
    vocabulary file required by the model, the low-level being the `short-cut-names`
    of the pretrained models with, as associated values, the `url` to the associated
    pretrained vocabulary file.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_vocab_files_map` (`Dict[str, Dict[str, str]]`) — 一个字典的字典，高级键是模型所需的每个词汇文件的`__init__`关键字名称，低级键是预训练模型的`short-cut-names`，关联值是关联预训练词汇文件的`url`。'
- en: '`max_model_input_sizes` (`Dict[str, Optional[int]]`) — A dictionary with, as
    keys, the `short-cut-names` of the pretrained models, and as associated values,
    the maximum length of the sequence inputs of this model, or `None` if the model
    has no maximum input size.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_model_input_sizes` (`Dict[str, Optional[int]]`) — 一个字典，其中键是预训练模型的`short-cut-names`，关联值是该模型的序列输入的最大长度，如果模型没有最大输入大小，则为`None`。'
- en: '`pretrained_init_configuration` (`Dict[str, Dict[str, Any]]`) — A dictionary
    with, as keys, the `short-cut-names` of the pretrained models, and as associated
    values, a dictionary of specific arguments to pass to the `__init__` method of
    the tokenizer class for this pretrained model when loading the tokenizer with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained)
    method.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_init_configuration` (`Dict[str, Dict[str, Any]]`) — 预训练模型的`short-cut-names`作为键，关联值是一个字典，其中包含加载预训练模型时传递给tokenizer类的`__init__`方法的特定参数。'
- en: '`model_input_names` (`List[str]`) — A list of inputs expected in the forward
    pass of the model.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_input_names` (`List[str]`) — 模型前向传递中预期的输入列表。'
- en: '`padding_side` (`str`) — The default value for the side on which the model
    should have padding applied. Should be `''right''` or `''left''`.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_side` (`str`) — 模型应该应用填充的默认位置。应为`''right''`或`''left''`。'
- en: '`truncation_side` (`str`) — The default value for the side on which the model
    should have truncation applied. Should be `''right''` or `''left''`.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation_side` (`str`) — 模型应该应用截断的默认位置。应为`''right''`或`''left''`。'
- en: '#### `__call__`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2729)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2729)'
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]`, `List[List[str]]`, *optional*) — The sequence or
    batch of sequences to be encoded. Each sequence can be a string or a list of strings
    (pretokenized string). If the sequences are provided as list of strings (pretokenized),
    you must set `is_split_into_words=True` (to lift the ambiguity with a batch of
    sequences).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`, `List[str]`, `List[List[str]]`, *optional*) — 要编码的序列或批量序列。每个序列可以是字符串或字符串列表（预先分词的字符串）。如果提供的序列是字符串列表（预先分词的），必须设置`is_split_into_words=True`（以消除与批量序列的歧义）。'
- en: '`text_pair` (`str`, `List[str]`, `List[List[str]]`, *optional*) — The sequence
    or batch of sequences to be encoded. Each sequence can be a string or a list of
    strings (pretokenized string). If the sequences are provided as list of strings
    (pretokenized), you must set `is_split_into_words=True` (to lift the ambiguity
    with a batch of sequences).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair` (`str`, `List[str]`, `List[List[str]]`, *optional*) — 要编码的序列或批量序列。每个序列可以是字符串或字符串列表（预先分词的字符串）。如果提供的序列是字符串列表（预先分词的），必须设置`is_split_into_words=True`（以消除与批量序列的歧义）。'
- en: '`text_target` (`str`, `List[str]`, `List[List[str]]`, *optional*) — The sequence
    or batch of sequences to be encoded as target texts. Each sequence can be a string
    or a list of strings (pretokenized string). If the sequences are provided as list
    of strings (pretokenized), you must set `is_split_into_words=True` (to lift the
    ambiguity with a batch of sequences).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_target`（`str`，`List[str]`，`List[List[str]]`，*可选*）— 要编码为目标文本的序列或批次。每个序列可以是字符串或字符串列表（预分词字符串）。如果将序列提供为字符串列表（预分词），必须设置`is_split_into_words=True`（以消除与批次序列的歧义）。'
- en: '`text_pair_target` (`str`, `List[str]`, `List[List[str]]`, *optional*) — The
    sequence or batch of sequences to be encoded as target texts. Each sequence can
    be a string or a list of strings (pretokenized string). If the sequences are provided
    as list of strings (pretokenized), you must set `is_split_into_words=True` (to
    lift the ambiguity with a batch of sequences).'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair_target`（`str`，`List[str]`，`List[List[str]]`，*可选*）— 要编码为目标文本的序列或批次。每个序列可以是字符串或字符串列表（预分词字符串）。如果将序列提供为字符串列表（预分词），必须设置`is_split_into_words=True`（以消除与批次序列的歧义）。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to add special tokens when encoding the sequences. This will use the underlying
    `PretrainedTokenizerBase.build_inputs_with_special_tokens` function, which defines
    which tokens are automatically added to the input ids. This is usefull if you
    want to add `bos` or `eos` tokens automatically.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens`（`bool`，*可选*，默认为`True`）— 在编码序列时是否添加特殊标记。这将使用底层的`PretrainedTokenizerBase.build_inputs_with_special_tokens`函数，该函数定义了自动添加到输入id的标记。如果要自动添加`bos`或`eos`标记，则这很有用。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`，`str`或[PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为`False`）—
    激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`或`''longest''`：填充到批次中最长的序列（如果只提供单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 使用参数`max_length`指定的最大长度进行填充，或者使用模型的最大可接受输入长度（如果未提供该参数）。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`或`''do_not_pad''`（默认）：无填充（即，可以输出长度不同的序列批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`bool`，`str`或[TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy)，*可选*，默认为`False`）—
    激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`或`''longest_first''`：使用参数`max_length`指定的最大长度进行截断，或者使用模型的最大可接受输入长度（如果未提供该参数）。这将逐标记截断，如果提供了一对序列（或一批对序列），则从较长序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`: 使用参数`max_length`指定的最大长度进行截断，或者使用模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则仅截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`: 使用参数`max_length`指定的最大长度进行截断，或者使用模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则仅截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`或`''do_not_truncate''`（默认）：无截断（即，可以输出长度大于模型最大可接受输入大小的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*）— 由截断/填充参数之一使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为`None`，则将使用预定义的模型最大长度（如果截断/填充参数中需要最大长度）。如果模型没有特定的最大输入长度（如XLNet），则将禁用截断/填充到最大长度。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride`（`int`，*可选*，默认为0）— 如果与`max_length`一起设置为一个数字，则当`return_overflowing_tokens=True`时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。此参数的值定义了重叠标记的数量。'
- en: '`is_split_into_words` (`bool`, *optional*, defaults to `False`) — Whether or
    not the input is already pre-tokenized (e.g., split into words). If set to `True`,
    the tokenizer assumes the input is already split into words (for instance, by
    splitting it on whitespace) which it will tokenize. This is useful for NER or
    token classification.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_split_into_words` (`bool`, *optional*, defaults to `False`) — 输入是否已经预分词化（例如，已经分成单词）。如果设置为`True`，分词器会假定输入已经分成单词（例如，通过在空格上分割），然后对其进行分词。这对于NER或令牌分类很有用。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. Requires `padding` to be activated. This is
    especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute
    capability `>= 7.5` (Volta).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *optional*) — 如果设置，将填充序列到提供的值的倍数。需要激活`padding`。这对于启用具有计算能力`>=
    7.5`（Volta）的NVIDIA硬件上的Tensor Cores的使用特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — 如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回Numpy `np.ndarray`对象。'
- en: '`return_token_type_ids` (`bool`, *optional*) — Whether to return token type
    IDs. If left to the default, will return the token type IDs according to the specific
    tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_token_type_ids` (`bool`, *optional*) — 是否返回令牌类型ID。如果保持默认设置，将根据特定分词器的默认值返回令牌类型ID，由`return_outputs`属性定义。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是token类型ID？](../glossary#token-type-ids)'
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask` (`bool`, *optional*) — 是否返回注意力掩码。如果保持默认设置，将根据特定分词器的默认值返回注意力掩码，由`return_outputs`属性定义。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`return_overflowing_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return overflowing token sequences. If a pair of sequences of input
    ids (or a batch of pairs) is provided with `truncation_strategy = longest_first`
    or `True`, an error is raised instead of returning overflowing tokens.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_overflowing_tokens` (`bool`, *optional*, defaults to `False`) — 是否返回溢出的令牌序列。如果提供了一对输入ID序列（或一批对）并且`truncation_strategy
    = longest_first`或`True`，则会引发错误，而不是返回溢出的令牌。'
- en: '`return_special_tokens_mask` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return special tokens mask information.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_special_tokens_mask` (`bool`, *optional*, defaults to `False`) — 是否返回特殊令牌掩码信息。'
- en: '`return_offsets_mapping` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return `(char_start, char_end)` for each token.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_offsets_mapping` (`bool`, *optional*, defaults to `False`) — 是否返回每个令牌的`(char_start,
    char_end)`。'
- en: This is only available on fast tokenizers inheriting from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast),
    if using Python’s tokenizer, this method will raise `NotImplementedError`.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这仅适用于继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)的快速分词器，如果使用Python的分词器，此方法将引发`NotImplementedError`。
- en: '`return_length` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return the lengths of the encoded inputs.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_length` (`bool`, *optional*, defaults to `False`) — 是否返回编码输入的长度。'
- en: '`verbose` (`bool`, *optional*, defaults to `True`) — Whether or not to print
    more information and warnings. **kwargs — passed to the `self.tokenize()` method'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose` (`bool`, *optional*, defaults to `True`) — 是否打印更多信息和警告。**kwargs —
    传递给`self.tokenize()`方法'
- en: Returns
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
- en: 'A [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)
    with the following fields:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 具有以下字段的[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)：
- en: '`input_ids` — List of token ids to be fed to a model.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` — 要馈送给模型的令牌ID列表。'
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`token_type_ids` — List of token type ids to be fed to a model (when `return_token_type_ids=True`
    or if *“token_type_ids”* is in `self.model_input_names`).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` — 要馈送给模型的令牌类型ID列表（当`return_token_type_ids=True`或*“token_type_ids”*在`self.model_input_names`中时）。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是token类型ID？](../glossary#token-type-ids)'
- en: '`attention_mask` — List of indices specifying which tokens should be attended
    to by the model (when `return_attention_mask=True` or if *“attention_mask”* is
    in `self.model_input_names`).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` — 指定模型应该关注的令牌的索引列表（当`return_attention_mask=True`或*“attention_mask”*在`self.model_input_names`中时）。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`overflowing_tokens` — List of overflowing tokens sequences (when a `max_length`
    is specified and `return_overflowing_tokens=True`).'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overflowing_tokens` — 溢出的令牌序列列表（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`num_truncated_tokens` — Number of tokens truncated (when a `max_length` is
    specified and `return_overflowing_tokens=True`).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_truncated_tokens` — 被截断的令牌数量（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`special_tokens_mask` — List of 0s and 1s, with 1 specifying added special
    tokens and 0 specifying regular sequence tokens (when `add_special_tokens=True`
    and `return_special_tokens_mask=True`).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens_mask` — 0和1的列表，其中1指定添加的特殊令牌，0指定常规序列令牌（当`add_special_tokens=True`和`return_special_tokens_mask=True`时）。'
- en: '`length` — The length of the inputs (when `return_length=True`)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length` — 输入的长度（当`return_length=True`时）'
- en: Main method to tokenize and prepare for the model one or several sequence(s)
    or one or several pair(s) of sequences.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化和为模型准备一个或多个序列或一个或多个序列对的主要方法。
- en: '#### `apply_chat_template`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `apply_chat_template`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L1678)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L1678)'
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`conversation` (Union[List[Dict[str, str]], “Conversation”]) — A Conversation
    object or list of dicts with “role” and “content” keys, representing the chat
    history so far.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conversation`（Union[List[Dict[str, str]], “Conversation”） — 一个Conversation对象或包含“role”和“content”键的字典列表，表示到目前为止的聊天历史。'
- en: '`chat_template` (str, *optional*) — A Jinja template to use for this conversion.
    If this is not passed, the model’s default chat template will be used instead.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chat_template`（str，*可选*） — 用于此转换的Jinja模板。如果未传递此参数，则将使用模型的默认聊天模板。'
- en: '`add_generation_prompt` (bool, *optional*) — Whether to end the prompt with
    the token(s) that indicate the start of an assistant message. This is useful when
    you want to generate a response from the model. Note that this argument will be
    passed to the chat template, and so it must be supported in the template for this
    argument to have any effect.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_generation_prompt`（bool，*可选*） — 是否以指示助手消息开始的标记结束提示。当您想要从模型生成响应时，这很有用。请注意，此参数将传递给聊天模板，因此必须在模板中支持此参数才能产生任何效果。'
- en: '`tokenize` (`bool`, defaults to `True`) — Whether to tokenize the output. If
    `False`, the output will be a string.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenize`（`bool`，默认为`True`） — 是否对输出进行标记化。如果为`False`，输出将是一个字符串。'
- en: '`padding` (`bool`, defaults to `False`) — Whether to pad sequences to the maximum
    length. Has no effect if tokenize is `False`.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`，默认为`False`） — 是否将序列填充到最大长度。如果tokenize为`False`，则无效。'
- en: '`truncation` (`bool`, defaults to `False`) — Whether to truncate sequences
    at the maximum length. Has no effect if tokenize is `False`.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`bool`，默认为`False`） — 是否在最大长度处截断序列。如果tokenize为`False`，则无效。'
- en: '`max_length` (`int`, *optional*) — Maximum length (in tokens) to use for padding
    or truncation. Has no effect if tokenize is `False`. If not specified, the tokenizer’s
    `max_length` attribute will be used as a default.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*） — 用于填充或截断的最大长度（以标记为单位）。如果未指定，则将使用分词器的`max_length`属性作为默认值。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors of a particular framework. Has no effect
    if tokenize is `False`. Acceptable values are:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）
    — 如果设置，将返回特定框架的张量。如果tokenize为`False`，则无效。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.Tensor` objects.'
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`：返回TensorFlow `tf.Tensor`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`：返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return NumPy `np.ndarray` objects.'
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`：返回NumPy `np.ndarray`对象。'
- en: '`''jax''`: Return JAX `jnp.ndarray` objects. **tokenizer_kwargs — Additional
    kwargs to pass to the tokenizer.'
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''jax''`：返回JAX `jnp.ndarray`对象。**tokenizer_kwargs — 传递给分词器的额外kwargs。'
- en: Returns
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: A list of token ids representing the tokenized chat so far, including control
    tokens. This output is ready to pass to the model, either directly or via methods
    like `generate()`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 表示到目前为止标记化聊天的标记id列表，包括控制标记。此输出已准备好直接传递给模型，或通过`generate()`等方法传递。
- en: Converts a Conversation object or a list of dictionaries with `"role"` and `"content"`
    keys to a list of token ids. This method is intended for use with chat models,
    and will read the tokenizer’s chat_template attribute to determine the format
    and control tokens to use when converting. When chat_template is None, it will
    fall back to the default_chat_template specified at the class level.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 将Conversation对象或包含“role”和“content”键的字典列表转换为标记id列表。此方法旨在与聊天模型一起使用，并将读取分词器的chat_template属性以确定在转换时要使用的格式和控制标记。当chat_template为None时，将退回到在类级别指定的default_chat_template。
- en: '#### `as_target_tokenizer`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `as_target_tokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3860)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3860)'
- en: '[PRE3]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Temporarily sets the tokenizer for encoding the targets. Useful for tokenizer
    associated to sequence-to-sequence models that need a slightly different processing
    for the labels.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 临时设置用于编码目标的分词器。对于需要为标签进行稍微不同处理的序列到序列模型相关的分词器非常有用。
- en: '#### `batch_decode`'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3692)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3692)'
- en: '[PRE4]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sequences` (`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`)
    — List of tokenized input ids. Can be obtained using the `__call__` method.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequences` (`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`)
    — 标记化输入id的列表。可以使用`__call__`方法获得。'
- en: '`skip_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove special tokens in the decoding.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens`（`bool`，*可选*，默认为`False`） — 是否删除解码中的特殊标记。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*) — Whether or not to clean
    up the tokenization spaces. If `None`, will default to `self.clean_up_tokenization_spaces`.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces`（`bool`，*可选*） — 是否清除分词空格。如果为`None`，将默认为`self.clean_up_tokenization_spaces`。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    underlying model specific decode method.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 将传递给底层模型特定的解码方法。'
- en: Returns
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[str]`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[str]`'
- en: The list of decoded sentences.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 解码的句子列表。
- en: Convert a list of lists of token ids into a list of strings by calling decode.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 将标记id列表的列表转换为字符串列表，通过调用解码。
- en: '#### `batch_encode_plus`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_encode_plus`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3026)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3026)'
- en: '[PRE5]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`batch_text_or_text_pairs` (`List[str]`, `List[Tuple[str, str]]`, `List[List[str]]`,
    `List[Tuple[List[str], List[str]]]`, and for not-fast tokenizers, also `List[List[int]]`,
    `List[Tuple[List[int], List[int]]]`) — Batch of sequences or pair of sequences
    to be encoded. This can be a list of string/string-sequences/int-sequences or
    a list of pair of string/string-sequences/int-sequence (see details in `encode_plus`).'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_text_or_text_pairs`（`List[str]`，`List[Tuple[str, str]]`，`List[List[str]]`，`List[Tuple[List[str],
    List[str]]`，以及对于非快速分词器，还有`List[List[int]]`，`List[Tuple[List[int], List[int]]`）
    - 要编码的序列或序列对批次。这可以是字符串/字符串序列/整数序列列表或字符串/字符串序列/整数序列对列表（请参阅`encode_plus`中的详细信息）。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to add special tokens when encoding the sequences. This will use the underlying
    `PretrainedTokenizerBase.build_inputs_with_special_tokens` function, which defines
    which tokens are automatically added to the input ids. This is usefull if you
    want to add `bos` or `eos` tokens automatically.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens`（`bool`，*可选*，默认为`True`） - 在编码序列时是否添加特殊标记。这将使用底层的`PretrainedTokenizerBase.build_inputs_with_special_tokens`函数，该函数定义了自动添加到输入id的标记。如果要自动添加`bos`或`eos`标记，则这很有用。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`，`str`或[PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为`False`）
    - 激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`或`''longest''`：填充到批次中最长的序列（如果只提供了单个序列，则不进行填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 使用参数`max_length`指定的最大长度进行填充，或者如果未提供该参数，则使用模型的最大可接受输入长度。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`或`''do_not_pad''`（默认）：不进行填充（即，可以输出长度不同的序列批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`bool`，`str`或[TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy)，*可选*，默认为`False`）
    - 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`或`''longest_first''`: 使用参数`max_length`指定的最大长度进行截断，或者如果未提供该参数，则使用模型的最大可接受输入长度。这将逐个标记地截断，如果提供了一对序列（或一批序列），则从该对中最长的序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`：使用参数`max_length`指定的最大长度进行截断，或者如果未提供该参数，则使用模型的最大可接受输入长度。如果提供了一对序列（或一批序列），则仅截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`：使用参数`max_length`指定的最大长度进行截断，或者如果未提供该参数，则使用模型的最大可接受输入长度。如果提供了一对序列（或一批序列），则仅截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`或`''do_not_truncate''`（默认）：不进行截断（即，可以输出长度大于模型最大可接受输入大小的序列批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*） - 控制截断/填充参数使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为`None`，则如果截断/填充参数中的一个需要最大长度，则将使用预定义的模型最大长度。如果模型没有特定的最大输入长度（如XLNet），则将停用截断/填充到最大长度。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride`（`int`，*可选*，默认为0） - 如果与`max_length`一起设置为一个数字，则当`return_overflowing_tokens=True`时返回的溢出标记将包含从截断序列末尾返回的一些标记，以提供截断和溢出序列之间的一些重叠。此参数的值定义了重叠标记的数量。'
- en: '`is_split_into_words` (`bool`, *optional*, defaults to `False`) — Whether or
    not the input is already pre-tokenized (e.g., split into words). If set to `True`,
    the tokenizer assumes the input is already split into words (for instance, by
    splitting it on whitespace) which it will tokenize. This is useful for NER or
    token classification.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_split_into_words`（`bool`，*可选*，默认为`False`） - 输入是否已经预分词（例如，已经分成单词）。如果设置为`True`，则分词器会假定输入已经分成单词（例如，通过在空格上分割），然后对其进行分词。这对于NER或标记分类很有用。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. Requires `padding` to be activated. This is
    especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute
    capability `>= 7.5` (Volta).'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of`（`int`，*可选*） — 如果设置，将序列填充到提供的值的倍数。需要激活`padding`。这对于在具有计算能力`>=
    7.5`（Volta）的NVIDIA硬件上启用Tensor Cores特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）
    — 如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`：返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`：返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`：返回Numpy `np.ndarray`对象。'
- en: '`return_token_type_ids` (`bool`, *optional*) — Whether to return token type
    IDs. If left to the default, will return the token type IDs according to the specific
    tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_token_type_ids`（`bool`，*可选*） — 是否返回标记类型ID。如果保持默认设置，将根据特定分词器的默认值返回标记类型ID，由`return_outputs`属性定义。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是token type IDs？](../glossary#token-type-ids)'
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask`（`bool`，*可选*） — 是否返回注意力掩码。如果保持默认设置，将根据特定分词器的默认值返回注意力掩码，由`return_outputs`属性定义。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是attention masks？](../glossary#attention-mask)'
- en: '`return_overflowing_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return overflowing token sequences. If a pair of sequences of input
    ids (or a batch of pairs) is provided with `truncation_strategy = longest_first`
    or `True`, an error is raised instead of returning overflowing tokens.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_overflowing_tokens`（`bool`，*可选*，默认为`False`） — 是否返回溢出的标记序列。如果提供了一对输入id序列（或一批对）并且`truncation_strategy
    = longest_first`或`True`，则会引发错误，而不是返回溢出的标记。'
- en: '`return_special_tokens_mask` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return special tokens mask information.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_special_tokens_mask`（`bool`，*可选*，默认为`False`） — 是否返回特殊标记掩码信息。'
- en: '`return_offsets_mapping` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return `(char_start, char_end)` for each token.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_offsets_mapping`（`bool`，*可选*，默认为`False`） — 是否返回每个标记的`(char_start, char_end)`。'
- en: This is only available on fast tokenizers inheriting from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast),
    if using Python’s tokenizer, this method will raise `NotImplementedError`.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 仅适用于继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)的快速分词器，如果使用Python的分词器，此方法将引发`NotImplementedError`。
- en: '`return_length` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return the lengths of the encoded inputs.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_length`（`bool`，*可选*，默认为`False`） — 是否返回编码输入的长度。'
- en: '`verbose` (`bool`, *optional*, defaults to `True`) — Whether or not to print
    more information and warnings. **kwargs — passed to the `self.tokenize()` method'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose`（`bool`，*可选*，默认为`True`） — 是否打印更多信息和警告。**kwargs — 传递给`self.tokenize()`方法'
- en: Returns
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
- en: 'A [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)
    with the following fields:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 具有以下字段的[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)：
- en: '`input_ids` — List of token ids to be fed to a model.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` — 要提供给模型的标记id列表。'
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`token_type_ids` — List of token type ids to be fed to a model (when `return_token_type_ids=True`
    or if *“token_type_ids”* is in `self.model_input_names`).'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` — 要提供给模型的标记类型id列表（当`return_token_type_ids=True`或*“token_type_ids”*在`self.model_input_names`中时）。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是token type IDs？](../glossary#token-type-ids)'
- en: '`attention_mask` — List of indices specifying which tokens should be attended
    to by the model (when `return_attention_mask=True` or if *“attention_mask”* is
    in `self.model_input_names`).'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` — 指定哪些标记应该被模型关注的索引列表（当`return_attention_mask=True`或*“attention_mask”*在`self.model_input_names`中时）。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是attention masks？](../glossary#attention-mask)'
- en: '`overflowing_tokens` — List of overflowing tokens sequences (when a `max_length`
    is specified and `return_overflowing_tokens=True`).'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overflowing_tokens` — 溢出标记序列的列表（当指定`max_length`和`return_overflowing_tokens=True`时）。'
- en: '`num_truncated_tokens` — Number of tokens truncated (when a `max_length` is
    specified and `return_overflowing_tokens=True`).'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_truncated_tokens` — 截断的标记数量（当指定`max_length`和`return_overflowing_tokens=True`时）。'
- en: '`special_tokens_mask` — List of 0s and 1s, with 1 specifying added special
    tokens and 0 specifying regular sequence tokens (when `add_special_tokens=True`
    and `return_special_tokens_mask=True`).'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens_mask` — 0和1的列表，其中1指定添加的特殊标记，0指定常规序列标记（当`add_special_tokens=True`和`return_special_tokens_mask=True`时）。'
- en: '`length` — The length of the inputs (when `return_length=True`)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length` — 输入的长度（当`return_length=True`时）'
- en: Tokenize and prepare for the model a list of sequences or a list of pairs of
    sequences.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 对一组序列或一组序列对进行标记化和准备模型。
- en: This method is deprecated, `__call__` should be used instead.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法已弃用，应改用`__call__`。
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3322)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3322)'
- en: '[PRE6]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — The first tokenized sequence.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`） — 第一个标记化序列。'
- en: '`token_ids_1` (`List[int]`, *optional*) — The second tokenized sequence.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）—第二个标记化序列。'
- en: Returns
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: The model input with special tokens.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 带有特殊标记的模型输入。
- en: Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 通过连接和添加特殊标记，从序列或序列对构建用于序列分类任务的模型输入。
- en: This implementation does not add special tokens and this method should be overridden
    in a subclass.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现不添加特殊标记，应该在子类中重写此方法。
- en: '#### `clean_up_tokenization`'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `clean_up_tokenization`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3803)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3803)'
- en: '[PRE7]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`out_string` (`str`) — The text to clean up.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`out_string`（`str`）—要清理的文本。'
- en: Returns
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The cleaned-up string.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 清理后的字符串。
- en: Clean up a list of simple English tokenization artifacts like spaces before
    punctuations and abbreviated forms.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 清理一系列简单的英语分词工件，如标点符号前的空格和缩写形式。
- en: '#### `convert_tokens_to_string`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `convert_tokens_to_string`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3679)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3679)'
- en: '[PRE8]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`tokens` (`List[str]`) — The token to join in a string.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokens`（`List[str]`）—要连接的标记。'
- en: Returns
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The joined tokens.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 连接的标记。
- en: Converts a sequence of tokens in a single string. The most simple way to do
    it is `" ".join(tokens)` but we often want to remove sub-word tokenization artifacts
    at the same time.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 将一系列标记转换为单个字符串。最简单的方法是`" ".join(tokens)`，但我们经常希望同时删除子词标记化工件。
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3302)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3302)'
- en: '[PRE9]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — The first tokenized sequence.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）—第一个标记化序列。'
- en: '`token_ids_1` (`List[int]`, *optional*) — The second tokenized sequence.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）—第二个标记化序列。'
- en: Returns
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: The token type ids.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 标记类型ID。
- en: Create the token type IDs corresponding to the sequences passed. [What are token
    type IDs?](../glossary#token-type-ids)
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 创建与传递的序列相对应的标记类型ID。[什么是标记类型ID？](../glossary#token-type-ids)
- en: Should be overridden in a subclass if the model has a special way of building
    those.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型有特殊的构建方式，则应在子类中重写。
- en: '#### `decode`'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3726)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3726)'
- en: '[PRE10]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids` (`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`)
    — List of tokenized input ids. Can be obtained using the `__call__` method.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids`（`Union[int]`，`List[int]`，`np.ndarray`，`torch.Tensor`，`tf.Tensor`）—标记化输入ID的列表。可以使用`__call__`方法获得。'
- en: '`skip_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove special tokens in the decoding.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens`（`bool`，*可选*，默认为`False`）—是否在解码中删除特殊标记。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*) — Whether or not to clean
    up the tokenization spaces. If `None`, will default to `self.clean_up_tokenization_spaces`.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces`（`bool`，*可选*）—是否清理分词空格。如果为`None`，将默认为`self.clean_up_tokenization_spaces`。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    underlying model specific decode method.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）—将传递给底层模型特定的解码方法。'
- en: Returns
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The decoded sentence.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 解码后的句子。
- en: Converts a sequence of ids in a string, using the tokenizer and vocabulary with
    options to remove special tokens and clean up tokenization spaces.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 将ID序列转换为字符串，使用分词器和词汇表，并提供选项以删除特殊标记和清理分词空格。
- en: Similar to doing `self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于执行`self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`。
- en: '#### `encode`'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2537)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2537)'
- en: '[PRE11]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]` or `List[int]`) — The first sequence to be encoded.
    This can be a string, a list of strings (tokenized string using the `tokenize`
    method) or a list of integers (tokenized string ids using the `convert_tokens_to_ids`
    method).'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`（`str`，`List[str]`或`List[int]`）—要编码的第一个序列。这可以是一个字符串，一个字符串列表（使用`tokenize`方法标记化的字符串）或一个整数列表（使用`convert_tokens_to_ids`方法标记化的字符串ID）。'
- en: '`text_pair` (`str`, `List[str]` or `List[int]`, *optional*) — Optional second
    sequence to be encoded. This can be a string, a list of strings (tokenized string
    using the `tokenize` method) or a list of integers (tokenized string ids using
    the `convert_tokens_to_ids` method).'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair`（`str`，`List[str]`或`List[int]`，*可选*）—要编码的可选第二序列。这可以是一个字符串，一个字符串列表（使用`tokenize`方法标记化的字符串）或一个整数列表（使用`convert_tokens_to_ids`方法标记化的字符串ID）。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to add special tokens when encoding the sequences. This will use the underlying
    `PretrainedTokenizerBase.build_inputs_with_special_tokens` function, which defines
    which tokens are automatically added to the input ids. This is usefull if you
    want to add `bos` or `eos` tokens automatically.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens`（`bool`，*可选*，默认为`True`）—在编码序列时是否添加特殊标记。这将使用底层的`PretrainedTokenizerBase.build_inputs_with_special_tokens`函数，该函数定义了哪些标记会自动添加到输入ID中。如果要自动添加`bos`或`eos`标记，则这很有用。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`，`str`或[PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为`False`）—激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`: 填充到批次中最长的序列（如果只提供了单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 填充到由参数 `max_length` 指定的最大长度，或者如果未提供该参数，则填充到模型可接受的最大输入长度。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）：不填充（即可以输出具有不同长度的序列的批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`, `str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, 默认为 `False`) — 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`: 截断到由参数 `max_length` 指定的最大长度，或者如果未提供该参数，则截断到模型可接受的最大输入长度。如果提供了一对序列（或一批序列对），则将逐标记截断，从序列对中最长的序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`: 截断到由参数 `max_length` 指定的最大长度，或者如果未提供该参数，则截断到模型可接受的最大输入长度。如果提供了一对序列（或一批序列对），则只会截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`: 截断到由参数 `max_length` 指定的最大长度，或者如果未提供该参数，则截断到模型可接受的最大输入长度。如果提供了一对序列（或一批序列对），则只会截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''`（默认）：不截断（即可以输出长度大于模型最大可接受输入大小的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *optional*) — 控制截断/填充参数使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为 `None`，则将使用预定义的模型最大长度（如果截断/填充参数需要最大长度）。如果模型没有特定的最大输入长度（如 XLNet），则将禁用截断/填充到最大长度。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride` (`int`, *optional*, defaults to 0) — 如果设置为一个数字，并且与 `max_length` 一起使用，当
    `return_overflowing_tokens=True` 时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。该参数的值定义了重叠标记的数量。'
- en: '`is_split_into_words` (`bool`, *optional*, defaults to `False`) — Whether or
    not the input is already pre-tokenized (e.g., split into words). If set to `True`,
    the tokenizer assumes the input is already split into words (for instance, by
    splitting it on whitespace) which it will tokenize. This is useful for NER or
    token classification.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_split_into_words` (`bool`, *optional*, 默认为 `False`) — 输入是否已经预分词化（例如，已经分成单词）。如果设置为
    `True`，则分词器假定输入已经分成单词（例如，通过在空格上分割），它将对其进行分词。这对于 NER 或标记分类很有用。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. Requires `padding` to be activated. This is
    especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute
    capability `>= 7.5` (Volta).'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *optional*) — 如果设置，将序列填充到提供的值的倍数。需要激活 `padding`。这对于启用具有计算能力
    `>= 7.5`（Volta）的 NVIDIA 硬件上的 Tensor Cores 特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — 如果设置，将返回张量而不是 Python 整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回 TensorFlow `tf.constant` 对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回 PyTorch `torch.Tensor` 对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回 Numpy `np.ndarray` 对象。'
- en: '**kwargs — Passed along to the `.tokenize()` method.'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**kwargs — 传递给 `.tokenize()` 方法。'
- en: Returns
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`, `torch.Tensor`, `tf.Tensor` or `np.ndarray`'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`, `torch.Tensor`, `tf.Tensor` 或 `np.ndarray`'
- en: The tokenized ids of the text.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 文本的标记化 id。
- en: Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 将字符串转换为 id（整数）序列，使用分词器和词汇表。
- en: Same as doing `self.convert_tokens_to_ids(self.tokenize(text))`.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 与执行 `self.convert_tokens_to_ids(self.tokenize(text))` 相同。
- en: '#### `encode_plus`'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_plus`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2930)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2930)'
- en: '[PRE12]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]` or `List[int]` (the latter only for not-fast tokenizers))
    — The first sequence to be encoded. This can be a string, a list of strings (tokenized
    string using the `tokenize` method) or a list of integers (tokenized string ids
    using the `convert_tokens_to_ids` method).'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`, `List[str]` 或 `List[int]`（仅用于非快速分词器）） — 要编码的第一个序列。可以是一个字符串，一个字符串列表（使用
    `tokenize` 方法进行分词），或一个整数列表（使用 `convert_tokens_to_ids` 方法进行分词）。'
- en: '`text_pair` (`str`, `List[str]` or `List[int]`, *optional*) — Optional second
    sequence to be encoded. This can be a string, a list of strings (tokenized string
    using the `tokenize` method) or a list of integers (tokenized string ids using
    the `convert_tokens_to_ids` method).'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair` (`str`, `List[str]` 或 `List[int]`, *可选*) — 要编码的可选第二个序列。可以是一个字符串，一个字符串列表（使用
    `tokenize` 方法进行分词），或一个整数列表（使用 `convert_tokens_to_ids` 方法进行分词）。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to add special tokens when encoding the sequences. This will use the underlying
    `PretrainedTokenizerBase.build_inputs_with_special_tokens` function, which defines
    which tokens are automatically added to the input ids. This is usefull if you
    want to add `bos` or `eos` tokens automatically.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens` (`bool`, *可选*, 默认为 `True`) — 在编码序列时是否添加特殊标记。这将使用底层的 `PretrainedTokenizerBase.build_inputs_with_special_tokens`
    函数，该函数定义了自动添加到输入标识的标记。如果要自动添加 `bos` 或 `eos` 标记，则这很有用。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding` (`bool`, `str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *可选*, 默认为 `False`) — 激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`：填充到批次中最长的序列（如果只提供了单个序列，则不进行填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`：填充到指定的最大长度（使用参数 `max_length`）或模型可接受的最大输入长度（如果未提供该参数）。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）：不进行填充（即，可以输出长度不同的序列批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`, `str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *可选*, 默认为 `False`) — 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`：截断到指定的最大长度（使用参数 `max_length`）或模型可接受的最大输入长度（如果未提供该参数）。这将逐个标记进行截断，如果提供了一对序列（或一批对序列），则从最长序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`：截断到指定的最大长度（使用参数 `max_length`）或模型可接受的最大输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则仅截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`：截断到指定的最大长度（使用参数 `max_length`）或模型可接受的最大输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则仅截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''`（默认）：不进行截断（即，可以输出长度大于模型最大可接受输入大小的序列批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *可选*) — 由截断/填充参数之一使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为 `None`，则将使用预定义的模型最大长度（如果截断/填充参数需要最大长度）。如果模型没有特定的最大输入长度（如 XLNet），则将禁用截断/填充到最大长度。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride` (`int`, *可选*, 默认为 0) — 如果与 `max_length` 一起设置为一个数字，则当 `return_overflowing_tokens=True`
    时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。该参数的值定义了重叠标记的数量。'
- en: '`is_split_into_words` (`bool`, *optional*, defaults to `False`) — Whether or
    not the input is already pre-tokenized (e.g., split into words). If set to `True`,
    the tokenizer assumes the input is already split into words (for instance, by
    splitting it on whitespace) which it will tokenize. This is useful for NER or
    token classification.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_split_into_words` (`bool`, *optional*, 默认为`False`) — 输入是否已经预分词化（例如，已分割为单词）。如果设置为`True`，分词器会假定输入已经分割为单词（例如，通过在空格上分割），然后对其进行分词。这对于NER或标记分类很有用。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. Requires `padding` to be activated. This is
    especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute
    capability `>= 7.5` (Volta).'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *optional*) — 如果设置，将序列填充到提供的值的倍数。需要激活`padding`。这对于启用具有计算能力`>=
    7.5`（Volta）的NVIDIA硬件上的Tensor Cores特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — 如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回Numpy `np.ndarray`对象。'
- en: '`return_token_type_ids` (`bool`, *optional*) — Whether to return token type
    IDs. If left to the default, will return the token type IDs according to the specific
    tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_token_type_ids` (`bool`, *optional*) — 是否返回标记类型ID。如果保持默认设置，将根据特定分词器的默认值返回标记类型ID，由`return_outputs`属性定义。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids)'
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask` (`bool`, *optional*) — 是否返回注意力掩码。如果保持默认设置，将根据特定分词器的默认值返回注意力掩码，由`return_outputs`属性定义。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`return_overflowing_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return overflowing token sequences. If a pair of sequences of input
    ids (or a batch of pairs) is provided with `truncation_strategy = longest_first`
    or `True`, an error is raised instead of returning overflowing tokens.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_overflowing_tokens` (`bool`, *optional*, defaults to `False`) — 是否返回溢出的标记序列。如果提供一对输入id序列（或一批对）并且`truncation_strategy
    = longest_first`或`True`，则会引发错误而不是返回溢出的标记。'
- en: '`return_special_tokens_mask` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return special tokens mask information.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_special_tokens_mask` (`bool`, *optional*, 默认为`False`) — 是否返回特殊标记掩码信息。'
- en: '`return_offsets_mapping` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return `(char_start, char_end)` for each token.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_offsets_mapping` (`bool`, *optional*, 默认为`False`) — 是否返回每个标记的`(char_start,
    char_end)`。'
- en: This is only available on fast tokenizers inheriting from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast),
    if using Python’s tokenizer, this method will raise `NotImplementedError`.
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这仅适用于继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)的快速分词器，如果使用Python的分词器，此方法将引发`NotImplementedError`。
- en: '`return_length` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return the lengths of the encoded inputs.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_length` (`bool`, *optional*, 默认为`False`) — 是否返回编码输入的长度。'
- en: '`verbose` (`bool`, *optional*, defaults to `True`) — Whether or not to print
    more information and warnings. **kwargs — passed to the `self.tokenize()` method'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose` (`bool`, *optional*, 默认为`True`) — 是否打印更多信息和警告。**kwargs — 传递给`self.tokenize()`方法'
- en: Returns
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
- en: 'A [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)
    with the following fields:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 具有以下字段的[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)：
- en: '`input_ids` — List of token ids to be fed to a model.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` — 要提供给模型的标记id列表。'
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`token_type_ids` — List of token type ids to be fed to a model (when `return_token_type_ids=True`
    or if *“token_type_ids”* is in `self.model_input_names`).'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` — 要提供给模型的标记类型id列表（当`return_token_type_ids=True`或*“token_type_ids”*在`self.model_input_names`中时）。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids)'
- en: '`attention_mask` — List of indices specifying which tokens should be attended
    to by the model (when `return_attention_mask=True` or if *“attention_mask”* is
    in `self.model_input_names`).'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` — 指定哪些标记应该被模型关注的索引列表（当`return_attention_mask=True`或*“attention_mask”*在`self.model_input_names`中时）。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`overflowing_tokens` — List of overflowing tokens sequences (when a `max_length`
    is specified and `return_overflowing_tokens=True`).'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overflowing_tokens` — 溢出标记序列的列表（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`num_truncated_tokens` — Number of tokens truncated (when a `max_length` is
    specified and `return_overflowing_tokens=True`).'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_truncated_tokens` — 截断的标记数（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`special_tokens_mask` — List of 0s and 1s, with 1 specifying added special
    tokens and 0 specifying regular sequence tokens (when `add_special_tokens=True`
    and `return_special_tokens_mask=True`).'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens_mask` — 由0和1组成的列表，其中1指定添加的特殊标记，0指定常规序列标记（当`add_special_tokens=True`和`return_special_tokens_mask=True`时）。'
- en: '`length` — The length of the inputs (when `return_length=True`)'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length` — 输入的长度（当`return_length=True`时）'
- en: Tokenize and prepare for the model a sequence or a pair of sequences.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 对一个序列或一对序列进行标记化和准备模型。
- en: This method is deprecated, `__call__` should be used instead.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法已弃用，应改用 `__call__`。
- en: '#### `from_pretrained`'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L1803)'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L1803)'
- en: '[PRE13]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：'
- en: A string, the *model id* of a predefined tokenizer hosted inside a model repo
    on huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预定义tokenizer的*模型id*，托管在huggingface.co模型仓库中。有效的模型id可以位于根级别，如 `bert-base-uncased`，也可以位于用户或组织名称下，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing vocabulary files required by the tokenizer,
    for instance saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含了tokenizer所需的词汇文件，例如使用[save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)方法保存的文件，例如
    `./my_model_directory/`。
- en: (`Deprecated`, not applicable to all derived classes) A path or url to a single
    saved vocabulary file (if and only if the tokenizer only requires a single vocabulary
    file like Bert or XLNet), e.g., `./my_model_directory/vocab.txt`.
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: （已弃用，不适用于所有派生类）一个单个保存的词汇文件的路径或url（仅当tokenizer只需要一个词汇文件时，如Bert或XLNet），例如 `./my_model_directory/vocab.txt`。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded predefined tokenizer vocabulary files should be cached if the standard
    cache should not be used.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载的预定义tokenizer词汇文件应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download the vocabulary files and override the cached versions
    if they exist.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载词汇文件并覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Attempt to resume the download if such
    a file exists.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，则尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如 `{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理将在每个请求中使用。'
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`).'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 *bool*, *optional*) — 用作远程文件HTTP bearer授权的token。如果为 `True`，将使用运行
    `huggingface-cli login` 时生成的token（存储在 `~/.huggingface` 中）。'
- en: '`local_files_only` (`bool`, *optional*, defaults to `False`) — Whether or not
    to only rely on local files and not to attempt to download any files.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only` (`bool`, *optional*, 默认为 `False`) — 是否仅依赖本地文件，不尝试下载任何文件。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以
    `revision` 可以是git允许的任何标识符。'
- en: '`subfolder` (`str`, *optional*) — In case the relevant files are located inside
    a subfolder of the model repo on huggingface.co (e.g. for facebook/rag-token-base),
    specify it here.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder` (`str`, *optional*) — 如果相关文件位于huggingface.co模型仓库的子文件夹中（例如facebook/rag-token-base），请在此处指定。'
- en: '`inputs` (additional positional arguments, *optional*) — Will be passed along
    to the Tokenizer `__init__` method.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs`（额外的位置参数，*optional*） — 将传递给Tokenizer `__init__`方法。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    Tokenizer `__init__` method. Can be used to set special tokens like `bos_token`,
    `eos_token`, `unk_token`, `sep_token`, `pad_token`, `cls_token`, `mask_token`,
    `additional_special_tokens`. See parameters in the `__init__` for more details.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*optional*） — 将传递给Tokenizer `__init__`方法。可以用于设置特殊token，如
    `bos_token`、`eos_token`、`unk_token`、`sep_token`、`pad_token`、`cls_token`、`mask_token`、`additional_special_tokens`。有关更多详细信息，请参阅`__init__`中的参数。'
- en: Instantiate a [PreTrainedTokenizerBase](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase)
    (or a derived class) from a predefined tokenizer.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 从预定义tokenizer实例化一个[PreTrainedTokenizerBase](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase)（或派生类）。
- en: Passing `token=True` is required when you want to use a private model.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想使用私有模型时，需要传递 `token=True`。
- en: 'Examples:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE14]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#### `get_special_tokens_mask`'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_special_tokens_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3772)'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3772)'
- en: '[PRE15]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of ids of the first sequence.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) — 第一个序列的id列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — List of ids of the second sequence.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *optional*) — 第二个序列的id列表。'
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`already_has_special_tokens` (`bool`, *optional*, 默认为 `False`) — token列表是否已经包含了模型所需的特殊token。'
- en: Returns
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: A list of integers in the range [0, 1]
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 一个整数列表，范围为 [0, 1]
- en: 1 for a special token, 0 for a sequence token.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 1 代表特殊token，0 代表序列token。
- en: Retrieves sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    or `encode_plus` methods.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 从没有添加特殊标记的标记列表中检索序列id。当使用tokenizer的`prepare_for_model`或`encode_plus`方法添加特殊标记时，会调用此方法。
- en: '#### `get_vocab`'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_vocab`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L1666)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L1666)'
- en: '[PRE16]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Returns
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict[str, int]`'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict[str, int]`'
- en: The vocabulary.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇表。
- en: Returns the vocabulary as a dictionary of token to index.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 将词汇表作为标记到索引的字典返回。
- en: '`tokenizer.get_vocab()[token]` is equivalent to `tokenizer.convert_tokens_to_ids(token)`
    when `token` is in the vocab.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 当`token`在词汇表中时，`tokenizer.get_vocab()[token]`等同于`tokenizer.convert_tokens_to_ids(token)`。
- en: '#### `pad`'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `pad`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3129)'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3129)'
- en: '[PRE17]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`encoded_inputs` ([BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding),
    list of [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding),
    `Dict[str, List[int]]`, `Dict[str, List[List[int]]` or `List[Dict[str, List[int]]]`)
    — Tokenized inputs. Can represent one input ([BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)
    or `Dict[str, List[int]]`) or a batch of tokenized inputs (list of [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding),
    *Dict[str, List[List[int]]]* or *List[Dict[str, List[int]]]*) so you can use this
    method during preprocessing as well as in a PyTorch Dataloader collate function.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoded_inputs`（[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)，[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)列表，`Dict[str,
    List[int]]`，`Dict[str, List[List[int]]`或`List[Dict[str, List[int]]]`） — 标记化输入。可以表示一个输入（[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)或`Dict[str,
    List[int]]`）或一批标记化输入（[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)列表，*Dict[str,
    List[List[int]]]*或*List[Dict[str, List[int]]]*)，因此您可以在预处理期间以及在PyTorch Dataloader收集函数中使用此方法。'
- en: Instead of `List[int]` you can have tensors (numpy arrays, PyTorch tensors or
    TensorFlow tensors), see the note above for the return type.
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以使用张量（numpy数组，PyTorch张量或TensorFlow张量）代替`List[int]`，请参考上面的返回类型说明。
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `True`) — Select a strategy to pad the returned sequences
    (according to the model’s padding side and padding index) among:'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`，`str`或[PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为`True`）
    — 选择一种策略来填充返回的序列（根据模型的填充方向和填充索引），包括：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`或`''longest''`：填充到批量中最长的序列（如果只提供单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 填充到指定的最大长度，使用参数`max_length`或者如果未提供该参数，则填充到模型的最大可接受输入长度。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-355
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`或`''do_not_pad''`（默认）：无填充（即可以输出具有不同长度序列的批次）。'
- en: '`max_length` (`int`, *optional*) — Maximum length of the returned list and
    optionally padding length (see above).'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*） — 返回列表的最大长度和可选的填充长度（参见上文）。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of`（`int`，*可选*） — 如果设置，将填充序列到提供的值的倍数。'
- en: This is especially useful to enable the use of Tensor Cores on NVIDIA hardware
    with compute capability `>= 7.5` (Volta).
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这对于启用具有计算能力`>= 7.5`（Volta）的NVIDIA硬件上的Tensor Cores特别有用。
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask`（`bool`，*可选*） — 是否返回注意力蒙版。如果保持默认值，将根据特定tokenizer的默认值返回注意力蒙版，由`return_outputs`属性定义。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[注意力蒙版是什么？](../glossary#attention-mask)'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）
    — 如果设置，将返回张量而不是Python整数列表。可接受的值包括：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`：返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`：返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-364
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`：返回Numpy `np.ndarray`对象。'
- en: '`verbose` (`bool`, *optional*, defaults to `True`) — Whether or not to print
    more information and warnings.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose`（`bool`，*可选*，默认为`True`） — 是否打印更多信息和警告。'
- en: Pad a single encoded input or a batch of encoded inputs up to predefined length
    or to the max sequence length in the batch.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 将单个编码输入或批量编码输入填充到预定义长度或批量中的最大序列长度。
- en: Padding side (left/right) padding token ids are defined at the tokenizer level
    (with `self.padding_side`, `self.pad_token_id` and `self.pad_token_type_id`).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 填充方向（左/右）填充标记id在tokenizer级别定义（使用`self.padding_side`，`self.pad_token_id`和`self.pad_token_type_id`）。
- en: Please note that with a fast tokenizer, using the `__call__` method is faster
    than using a method to encode the text followed by a call to the `pad` method
    to get a padded encoding.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，使用快速tokenizer时，使用`__call__`方法比使用编码文本的方法再调用`pad`方法更快。
- en: If the `encoded_inputs` passed are dictionary of numpy arrays, PyTorch tensors
    or TensorFlow tensors, the result will use the same type unless you provide a
    different tensor type with `return_tensors`. In the case of PyTorch tensors, you
    will lose the specific device of your tensors however.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 如果传递的 `encoded_inputs` 是 numpy 数组、PyTorch 张量或 TensorFlow 张量的字典，则结果将使用相同的类型，除非您使用
    `return_tensors` 提供不同的张量类型。对于 PyTorch 张量，您将丢失张量的特定设备。
- en: '#### `prepare_for_model`'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `prepare_for_model`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3342)'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3342)'
- en: '[PRE18]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`ids` (`List[int]`) — Tokenized input ids of the first sequence. Can be obtained
    from a string by chaining the `tokenize` and `convert_tokens_to_ids` methods.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ids`（`List[int]`） — 第一个序列的标记化输入 id。可以通过链接 `tokenize` 和 `convert_tokens_to_ids`
    方法从字符串中获取。'
- en: '`pair_ids` (`List[int]`, *optional*) — Tokenized input ids of the second sequence.
    Can be obtained from a string by chaining the `tokenize` and `convert_tokens_to_ids`
    methods.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pair_ids`（`List[int]`，*可选*） — 第二个序列的标记化输入 id。可以通过链接 `tokenize` 和 `convert_tokens_to_ids`
    方法从字符串中获取。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to add special tokens when encoding the sequences. This will use the underlying
    `PretrainedTokenizerBase.build_inputs_with_special_tokens` function, which defines
    which tokens are automatically added to the input ids. This is usefull if you
    want to add `bos` or `eos` tokens automatically.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens`（`bool`，*可选*，默认为 `True`） — 在编码序列时是否添加特殊标记。这将使用底层的 `PretrainedTokenizerBase.build_inputs_with_special_tokens`
    函数，该函数定义了自动添加到输入 id 的标记。如果要自动添加 `bos` 或 `eos` 标记，这很有用。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`、`str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为
    `False`） — 激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-378
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`：填充到批次中最长的序列（如果只提供单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-379
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`：填充到指定的最大长度，该长度由参数 `max_length` 指定，或者填充到模型可接受的最大输入长度（如果未提供该参数）。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-380
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）：不填充（即，可以输出具有不同长度的序列批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`bool`、`str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy)，*可选*，默认为
    `False`） — 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-382
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`：截断到指定的最大长度，该长度由参数 `max_length` 指定，或者截断到模型可接受的最大输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则将逐标记截断，从一对序列中最长的序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-383
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`：截断到指定的最大长度，该长度由参数 `max_length` 指定，或者截断到模型可接受的最大输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则只会截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-384
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`：截断到指定的最大长度，该长度由参数 `max_length` 指定，或者截断到模型可接受的最大输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则只会截断第二个序列。 '
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-385
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''`（默认）：不截断（即，可以输出长度大于模型最大可接受输入大小的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*） — 由截断/填充参数之一使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为 `None`，则将使用预定义的模型最大长度，如果截断/填充参数中需要最大长度。如果模型没有特定的最大输入长度（如 XLNet），则将禁用截断/填充到最大长度。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride`（`int`，*可选*，默认为 0） — 如果与 `max_length` 一起设置为一个数字，则当 `return_overflowing_tokens=True`
    时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。该参数的值定义了重叠标记的数量。'
- en: '`is_split_into_words` (`bool`, *optional*, defaults to `False`) — Whether or
    not the input is already pre-tokenized (e.g., split into words). If set to `True`,
    the tokenizer assumes the input is already split into words (for instance, by
    splitting it on whitespace) which it will tokenize. This is useful for NER or
    token classification.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_split_into_words` (`bool`, *可选*, 默认为 `False`) — 输入是否已经预分词（例如，已经分成单词）。如果设置为`True`，分词器会假定输入已经分成单词（例如，通过在空格上分割），然后对其进行分词。这对于NER或标记分类很有用。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. Requires `padding` to be activated. This is
    especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute
    capability `>= 7.5` (Volta).'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *可选*) — 如果设置，将序列填充到提供的值的倍数。需要激活`padding`。这对于在具有计算能力`>=
    7.5`（Volta）的NVIDIA硬件上启用Tensor Cores特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *可选*) — 如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-392
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-393
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-394
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回Numpy `np.ndarray`对象。'
- en: '`return_token_type_ids` (`bool`, *optional*) — Whether to return token type
    IDs. If left to the default, will return the token type IDs according to the specific
    tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_token_type_ids` (`bool`, *可选*) — 是否返回token type IDs。如果保持默认设置，将根据特定分词器的默认设置返回token
    type IDs，由`return_outputs`属性定义。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是token type IDs？
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask` (`bool`, *可选*) — 是否返回attention mask。如果保持默认设置，将根据特定分词器的默认设置返回attention
    mask，由`return_outputs`属性定义。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是attention masks？
- en: '`return_overflowing_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return overflowing token sequences. If a pair of sequences of input
    ids (or a batch of pairs) is provided with `truncation_strategy = longest_first`
    or `True`, an error is raised instead of returning overflowing tokens.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_overflowing_tokens` (`bool`, *可选*, 默认为 `False`) — 是否返回溢出的token序列。如果提供一对输入IDs序列（或一批对）并且`truncation_strategy
    = longest_first`或`True`，则会引发错误而不是返回溢出的tokens。'
- en: '`return_special_tokens_mask` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return special tokens mask information.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_special_tokens_mask` (`bool`, *可选*, 默认为 `False`) — 是否返回特殊token的mask信息。'
- en: '`return_offsets_mapping` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return `(char_start, char_end)` for each token.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_offsets_mapping` (`bool`, *可选*, 默认为 `False`) — 是否返回每个token的`(char_start,
    char_end)`。'
- en: This is only available on fast tokenizers inheriting from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast),
    if using Python’s tokenizer, this method will raise `NotImplementedError`.
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这仅适用于继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)的快速分词器，如果使用Python的分词器，此方法将引发`NotImplementedError`。
- en: '`return_length` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return the lengths of the encoded inputs.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_length` (`bool`, *可选*, 默认为 `False`) — 是否返回编码输入的长度。'
- en: '`verbose` (`bool`, *optional*, defaults to `True`) — Whether or not to print
    more information and warnings. **kwargs — passed to the `self.tokenize()` method'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose` (`bool`, *可选*, 默认为 `True`) — 是否打印更多信息和警告。**kwargs — 传递给`self.tokenize()`方法'
- en: Returns
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
- en: 'A [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)
    with the following fields:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 一个带有以下字段的[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)：
- en: '`input_ids` — List of token ids to be fed to a model.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` — 要提供给模型的token ids列表。'
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是输入IDs？
- en: '`token_type_ids` — List of token type ids to be fed to a model (when `return_token_type_ids=True`
    or if *“token_type_ids”* is in `self.model_input_names`).'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` — 要提供给模型的token type ids列表（当`return_token_type_ids=True`或*“token_type_ids”*在`self.model_input_names`中）。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是token type IDs？
- en: '`attention_mask` — List of indices specifying which tokens should be attended
    to by the model (when `return_attention_mask=True` or if *“attention_mask”* is
    in `self.model_input_names`).'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` — 指定哪些token应该被模型关注的索引列表（当`return_attention_mask=True`或*“attention_mask”*在`self.model_input_names`中）。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是attention masks？
- en: '`overflowing_tokens` — List of overflowing tokens sequences (when a `max_length`
    is specified and `return_overflowing_tokens=True`).'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overflowing_tokens` — 溢出token序列的列表（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`num_truncated_tokens` — Number of tokens truncated (when a `max_length` is
    specified and `return_overflowing_tokens=True`).'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_truncated_tokens` — 被截断的token数量（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`special_tokens_mask` — List of 0s and 1s, with 1 specifying added special
    tokens and 0 specifying regular sequence tokens (when `add_special_tokens=True`
    and `return_special_tokens_mask=True`).'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens_mask` — 由0和1组成的列表，其中1指定添加的特殊token，0指定常规序列token（当`add_special_tokens=True`并且`return_special_tokens_mask=True`时）。'
- en: '`length` — The length of the inputs (when `return_length=True`)'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length` — 输入的长度（当`return_length=True`时）'
- en: Prepares a sequence of input id, or a pair of sequences of inputs ids so that
    it can be used by the model. It adds special tokens, truncates sequences if overflowing
    while taking into account the special tokens and manages a moving window (with
    user defined stride) for overflowing tokens. Please Note, for *pair_ids* different
    than `None` and *truncation_strategy = longest_first* or `True`, it is not possible
    to return overflowing tokens. Such a combination of arguments will raise an error.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 准备输入 id 的序列，或一对输入 id 的序列，以便模型使用。它添加特殊标记，如果溢出则截断序列，同时考虑特殊标记，并管理一个移动窗口（带有用户定义的步幅）以处理溢出的标记。请注意，对于
    *pair_ids* 不等于 `None` 且 *truncation_strategy = longest_first* 或 `True`，不可能返回溢出的标记。这样的参数组合将引发错误。
- en: '#### `prepare_seq2seq_batch`'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `prepare_seq2seq_batch`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3903)'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3903)'
- en: '[PRE19]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`src_texts` (`List[str]`) — List of documents to summarize or source language
    texts.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`src_texts` (`List[str]`) — 要总结的文档或源语言文本的列表。'
- en: '`tgt_texts` (`list`, *optional*) — List of summaries or target language texts.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tgt_texts` (`list`, *可选*) — 摘要或目标语言文本的列表。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length for encoder
    inputs (documents to summarize or source language texts) If left unset or set
    to `None`, this will use the predefined model maximum length if a maximum length
    is required by one of the truncation/padding parameters. If the model has no specific
    maximum input length (like XLNet) truncation/padding to a maximum length will
    be deactivated.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *可选*) — 控制编码器输入（要总结的文档或源语言文本）的最大长度。如果未设置或设置为 `None`，并且截断/填充参数中需要最大长度，则将使用预定义的模型最大长度。如果模型没有特定的最大输入长度（如
    XLNet），则将禁用截断/填充到最大长度。'
- en: '`max_target_length` (`int`, *optional*) — Controls the maximum length of decoder
    inputs (target language texts or summaries) If left unset or set to `None`, this
    will use the max_length value.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_target_length` (`int`, *可选*) — 控制解码器输入（目标语言文本或摘要）的最大长度。如果未设置或设置为 `None`，将使用
    max_length 值。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding` (`bool`, `str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *可选*, 默认为 `False`) — 激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-428
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`: 填充到批次中最长的序列（如果只提供了单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-429
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 填充到由参数 `max_length` 指定的最大长度，或者如果未提供该参数，则填充到模型可接受的最大输入长度。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-430
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''` (默认): 不填充（即，可以输出长度不同的序列批次）。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *可选*) — 如果设置，将返回张量而不是 Python 整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-432
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回 TensorFlow `tf.constant` 对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-433
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回 PyTorch `torch.Tensor` 对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-434
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回 Numpy `np.ndarray` 对象。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `True`) — Activates and controls truncation. Accepts the
    following values:'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`, `str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *可选*, 默认为 `True`) — 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-436
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`: 截断到由参数 `max_length` 指定的最大长度，或者如果未提供该参数，则截断到模型可接受的最大输入长度。如果提供了一对序列（或一批对），则将逐标记截断，从一对序列中最长的序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-437
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`: 截断到由参数 `max_length` 指定的最大长度，或者如果未提供该参数，则截断到模型可接受的最大输入长度。如果提供了一对序列（或一批对），则仅截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-438
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`: 截断到由参数 `max_length` 指定的最大长度，或者如果未提供该参数，则截断到模型可接受的最大输入长度。如果提供了一对序列（或一批对），则仅截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).
    **kwargs — Additional keyword arguments passed along to `self.__call__`.'
  id: totrans-439
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''` (默认): 不截断（即，可以输出长度大于模型最大可接受输入大小的序列）。**kwargs
    — 传递给 `self.__call__` 的额外关键字参数。'
- en: Returns
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
- en: 'A [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)
    with the following fields:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 具有以下字段的[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)：
- en: '`input_ids` — List of token ids to be fed to the encoder.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` — 要馈送给编码器的标记id列表。'
- en: '`attention_mask` — List of indices specifying which tokens should be attended
    to by the model.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` — 指定模型应关注的哪些标记的索引列表。'
- en: '`labels` — List of token ids for tgt_texts.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` — tgt_texts的标记id列表。'
- en: The full set of keys `[input_ids, attention_mask, labels]`, will only be returned
    if tgt_texts is passed. Otherwise, input_ids, attention_mask will be the only
    keys.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 仅当传递了tgt_texts时，将返回完整的键集`[input_ids, attention_mask, labels]`。否则，`input_ids`，`attention_mask`将是唯一的键。
- en: Prepare model inputs for translation. For best performance, translate one sentence
    at a time.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 为翻译准备模型输入。为了获得最佳性能，请一次翻译一句话。
- en: '#### `push_to_hub`'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `push_to_hub`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)'
- en: '[PRE20]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`repo_id` (`str`) — The name of the repository you want to push your tokenizer
    to. It should contain your organization name when pushing to a given organization.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_id`（`str`）— 要将分词器推送到的存储库的名称。在推送到给定组织时，它应包含您的组织名称。'
- en: '`use_temp_dir` (`bool`, *optional*) — Whether or not to use a temporary directory
    to store the files saved before they are pushed to the Hub. Will default to `True`
    if there is no directory named like `repo_id`, `False` otherwise.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_temp_dir`（`bool`，*可选*）— 是否使用临时目录存储保存之前的文件，然后将它们推送到Hub。如果没有名为`repo_id`的目录，则默认为`True`，否则为`False`。'
- en: '`commit_message` (`str`, *optional*) — Message to commit while pushing. Will
    default to `"Upload tokenizer"`.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_message`（`str`，*可选*）— 推送时要提交的消息。默认为`"Upload tokenizer"`。'
- en: '`private` (`bool`, *optional*) — Whether or not the repository created should
    be private.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`private`（`bool`，*可选*）— 创建的存储库是否应为私有。'
- en: '`token` (`bool` or `str`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`). Will default to `True` if `repo_url` is not
    specified.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`（`bool`或`str`，*可选*）— 用作远程文件HTTP令牌的令牌。如果为`True`，将使用运行`huggingface-cli
    login`时生成的令牌（存储在`~/.huggingface`中）。如果未指定`repo_url`，则默认为`True`。'
- en: '`max_shard_size` (`int` or `str`, *optional*, defaults to `"5GB"`) — Only applicable
    for models. The maximum size for a checkpoint before being sharded. Checkpoints
    shard will then be each of size lower than this size. If expressed as a string,
    needs to be digits followed by a unit (like `"5MB"`). We default it to `"5GB"`
    so that users can easily load models on free-tier Google Colab instances without
    any CPU OOM issues.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_shard_size`（`int`或`str`，*可选*，默认为`"5GB"`）— 仅适用于模型。在被分片之前的检查点的最大大小。然后，检查点将分片为每个大小低于此大小的大小。如果表示为字符串，需要是数字后跟一个单位（如`"5MB"`）。我们将其默认设置为`"5GB"`，以便用户可以在免费的Google
    Colab实例上轻松加载模型，而不会出现CPU OOM问题。'
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) — Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_pr`（`bool`，*可选*，默认为`False`）— 是否创建具有上传文件的PR或直接提交。'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) — Whether or
    not to convert the model weights in safetensors format for safer serialization.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization`（`bool`，*可选*，默认为`True`）— 是否将模型权重转换为safetensors格式以进行更安全的序列化。'
- en: '`revision` (`str`, *optional*) — Branch to push the uploaded files to.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*）— 要将上传的文件推送到的分支。'
- en: '`commit_description` (`str`, *optional*) — The description of the commit that
    will be created'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_description`（`str`，*可选*）— 将创建的提交的描述'
- en: '`tags` (`List[str]`, *optional*) — List of tags to push on the Hub.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags`（`List[str]`，*可选*）— 要推送到Hub的标签列表。'
- en: Upload the tokenizer files to the 🤗 Model Hub.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 将分词器文件上传到🤗模型Hub。
- en: 'Examples:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE21]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '#### `register_for_auto_class`'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register_for_auto_class`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3877)'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3877)'
- en: '[PRE22]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`auto_class` (`str` or `type`, *optional*, defaults to `"AutoTokenizer"`) —
    The auto class to register this new tokenizer with.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto_class`（`str`或`type`，*可选*，默认为`"AutoTokenizer"`）— 要将此新分词器注册到的自动类。'
- en: Register this class with a given auto class. This should only be used for custom
    tokenizers as the ones in the library are already mapped with `AutoTokenizer`.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 使用给定的自动类注册此类。这应仅用于自定义分词器，因为库中的分词器已经与`AutoTokenizer`映射。
- en: This API is experimental and may have some slight breaking changes in the next
    releases.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 此API是实验性的，可能在下一个版本中有一些轻微的破坏性更改。
- en: '#### `save_pretrained`'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2302)'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2302)'
- en: '[PRE23]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — The path to a directory where the
    tokenizer will be saved.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory`（`str`或`os.PathLike`）— 分词器将被保存的目录路径。'
- en: '`legacy_format` (`bool`, *optional*) — Only applicable for a fast tokenizer.
    If unset (default), will save the tokenizer in the unified JSON format as well
    as in legacy format if it exists, i.e. with tokenizer specific vocabulary and
    a separate added_tokens files.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`legacy_format`（`bool`，*可选*）— 仅适用于快速分词器。如果未设置（默认），将以统一的JSON格式保存分词器，以及以传统格式保存（如果存在），即具有特定于分词器的词汇表和单独的added_tokens文件。'
- en: If `False`, will only save the tokenizer in the unified JSON format. This format
    is incompatible with “slow” tokenizers (not powered by the *tokenizers* library),
    so the tokenizer will not be able to be loaded in the corresponding “slow” tokenizer.
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果为`False`，则只会以统一的JSON格式保存分词器。该格式与“慢速”分词器（不由*tokenizers*库提供支持）不兼容，因此无法在相应的“慢速”分词器中加载分词器。
- en: If `True`, will save the tokenizer in legacy format. If the “slow” tokenizer
    doesn’t exits, a value error is raised.
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果为`True`，将以传统格式保存分词器。如果“slow”分词器不存在，则会引发值错误。
- en: '`filename_prefix` (`str`, *optional*) — A prefix to add to the names of the
    files saved by the tokenizer.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filename_prefix` (`str`, *可选*) — 要添加到分词器保存的文件名称前缀。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *可选*, 默认为`False`) — 保存后是否将模型推送到Hugging Face模型中心。您可以使用`repo_id`指定要推送到的存储库（将默认为您的命名空间中的`save_directory`名称）。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *可选*) — 传递给[push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)方法的额外关键字参数。'
- en: Returns
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: A tuple of `str`
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`str`元组
- en: The files saved.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 保存的文件。
- en: Save the full tokenizer state.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 保存完整的分词器状态。
- en: This method make sure the full tokenizer can then be re-loaded using the `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`
    class method..
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法确保完整的分词器可以使用`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`类方法重新加载。
- en: Warning,None This won’t save modifications you may have applied to the tokenizer
    after the instantiation (for instance, modifying `tokenizer.do_lower_case` after
    creation).
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 警告，无。这不会保存您在实例化后对分词器应用的修改（例如，在创建后修改`tokenizer.do_lower_case`）。
- en: '#### `save_vocabulary`'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_vocabulary`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2499)'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2499)'
- en: '[PRE24]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str`) — The directory in which to save the vocabulary.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str`) — 保存词汇表的目录。'
- en: '`filename_prefix` (`str`, *optional*) — An optional prefix to add to the named
    of the saved files.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filename_prefix` (`str`, *可选*) — 要添加到保存文件名称的可选前缀。'
- en: Returns
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Tuple(str)`'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '`Tuple(str)`'
- en: Paths to the files saved.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 保存的文件路径。
- en: Save only the vocabulary of the tokenizer (vocabulary + added tokens).
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 仅保存分词器的词汇表（词汇表+添加的标记）。
- en: This method won’t save the configuration and special token mappings of the tokenizer.
    Use `_save_pretrained()` to save the whole state of the tokenizer.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法不会保存分词器的配置和特殊标记映射。使用`_save_pretrained()`保存分词器的整个状态。
- en: '#### `tokenize`'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tokenize`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2517)'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2517)'
- en: '[PRE25]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — The sequence to be encoded.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 要编码的序列。'
- en: '`pair` (`str`, *optional*) — A second sequence to be encoded with the first.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pair` (`str`, *可选*) — 要与第一个序列一起编码的第二个序列。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether or
    not to add the special tokens associated with the corresponding model.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens` (`bool`, *可选*, 默认为`False`) — 是否添加与相应模型相关的特殊标记。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    underlying model specific encode method. See details in [`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外关键字参数，*可选*） — 将传递给底层模型特定的编码方法。详细信息请参见[`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)'
- en: Returns
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[str]`'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[str]`'
- en: The list of tokens.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 标记列表。
- en: Converts a string into a sequence of tokens, replacing unknown tokens with the
    `unk_token`.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 将字符串转换为标记序列，用`unk_token`替换未知标记。
- en: '#### `truncate_sequences`'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `truncate_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3478)'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3478)'
- en: '[PRE26]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`ids` (`List[int]`) — Tokenized input ids of the first sequence. Can be obtained
    from a string by chaining the `tokenize` and `convert_tokens_to_ids` methods.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ids` (`List[int]`) — 第一个序列的标记化输入id。可以通过链接`tokenize`和`convert_tokens_to_ids`方法从字符串中获取。'
- en: '`pair_ids` (`List[int]`, *optional*) — Tokenized input ids of the second sequence.
    Can be obtained from a string by chaining the `tokenize` and `convert_tokens_to_ids`
    methods.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pair_ids` (`List[int]`, *可选*) — 第二个序列的标记化输入id。可以通过链接`tokenize`和`convert_tokens_to_ids`方法从字符串中获取。'
- en: '`num_tokens_to_remove` (`int`, *optional*, defaults to 0) — Number of tokens
    to remove using the truncation strategy.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_tokens_to_remove` (`int`, *可选*, 默认为0) — 使用截断策略要移除的标记数。'
- en: '`truncation_strategy` (`str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — The strategy to follow for truncation. Can
    be:'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation_strategy` (`str`或[TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *可选*, 默认为`False`) — 截断的策略。可以是：'
- en: '`''longest_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will truncate token by token, removing a token from the
    longest sequence in the pair if a pair of sequences (or a batch of pairs) is provided.'
  id: totrans-521
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''longest_first''`: 截断到指定的最大长度（使用参数`max_length`）或模型的最大可接受输入长度（如果未提供该参数）。这将逐个标记截断，如果提供了一对序列（或一批序列），则从一对序列中最长的序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-522
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`: 截断到指定的最大长度（使用参数`max_length`）或模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对序列（或一批序列），则仅截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-523
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`：根据参数`max_length`指定的最大长度截断，或者根据模型的最大可接受输入长度截断。如果未提供该参数，则仅截断一对序列中的第二个序列（或一批序列对）。'
- en: '`''do_not_truncate''` (default): No truncation (i.e., can output batch with
    sequence lengths greater than the model maximum admissible input size).'
  id: totrans-524
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''do_not_truncate''`（默认）：不截断（即，可以输出长度大于模型最大可接受输入大小的批次）。'
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a positive number,
    the overflowing tokens returned will contain some tokens from the main sequence
    returned. The value of this argument defines the number of additional tokens.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride`（`int`，*可选*，默认为0）— 如果设置为正数，返回的溢出标记将包含来自返回的主序列的一些标记。该参数的值定义了额外标记的数量。'
- en: Returns
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Tuple[List[int], List[int], List[int]]`'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '`Tuple[List[int], List[int], List[int]]`'
- en: 'The truncated `ids`, the truncated `pair_ids` and the list of overflowing tokens.
    Note: The *longest_first* strategy returns empty list of overflowing tokens if
    a pair of sequences (or a batch of pairs) is provided.'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 被截断的`ids`，被截断的`pair_ids`和溢出标记的列表。注意：如果提供了一对序列（或一批序列对），则*longest_first*策略返回空的溢出标记列表。
- en: Truncates a sequence pair in-place following the strategy.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 根据策略就地截断一个序列对。
- en: SpecialTokensMixin
  id: totrans-530
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpecialTokensMixin
- en: '### `class transformers.SpecialTokensMixin`'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpecialTokensMixin`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L795)'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L795)'
- en: '[PRE27]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`bos_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing the beginning of a sentence.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表句子开头的特殊标记。'
- en: '`eos_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing the end of a sentence.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表句子结尾的特殊标记。'
- en: '`unk_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing an out-of-vocabulary token.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表一个未知词的特殊标记。'
- en: '`sep_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    separating two different sentences in the same input (used by BERT for instance).'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表同一输入中两个不同句子之间的特殊标记（例如BERT使用）。'
- en: '`pad_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    used to make arrays of tokens the same size for batching purpose. Will then be
    ignored by attention mechanisms or loss computation.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token`（`str`或`tokenizers.AddedToken`，*可选*）— 用于使标记数组大小相同以进行批处理的特殊标记。然后将被注意机制或损失计算忽略。'
- en: '`cls_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing the class of the input (used by BERT for instance).'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表输入类别的特殊标记（例如BERT使用）。'
- en: '`mask_token` (`str` or `tokenizers.AddedToken`, *optional*) — A special token
    representing a masked token (used by masked-language modeling pretraining objectives,
    like BERT).'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token`（`str`或`tokenizers.AddedToken`，*可选*）— 代表被屏蔽的标记的特殊标记（例如BERT使用）。'
- en: '`additional_special_tokens` (tuple or list of `str` or `tokenizers.AddedToken`,
    *optional*) — A tuple or a list of additional tokens, which will be marked as
    `special`, meaning that they will be skipped when decoding if `skip_special_tokens`
    is set to `True`.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`additional_special_tokens`（元组或`str`或`tokenizers.AddedToken`的列表，*可选*）— 一组额外的标记，将被标记为`special`，这意味着如果`skip_special_tokens`设置为`True`，在解码时将被跳过。'
- en: A mixin derived by [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    and [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    to handle specific behaviors related to special tokens. In particular, this class
    hold the attributes which can be used to directly access these special tokens
    in a model-independent manner and allow to set and update the special tokens.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 由[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)和[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)派生的mixin，用于处理与特殊标记相关的特定行为。特别是，这个类保存了可以用于以与模型无关的方式直接访问这些特殊标记的属性，并允许设置和更新特殊标记。
- en: '#### `add_special_tokens`'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L873)'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L873)'
- en: '[PRE28]'
  id: totrans-546
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`special_tokens_dict` (dictionary *str* to *str* or `tokenizers.AddedToken`)
    — Keys should be in the list of predefined special attributes: [`bos_token`, `eos_token`,
    `unk_token`, `sep_token`, `pad_token`, `cls_token`, `mask_token`, `additional_special_tokens`].'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens_dict`（字典*str*到*str*或`tokenizers.AddedToken`）— 键应该在预定义特殊属性列表中：[`bos_token`、`eos_token`、`unk_token`、`sep_token`、`pad_token`、`cls_token`、`mask_token`、`additional_special_tokens`]。'
- en: Tokens are only added if they are not already in the vocabulary (tested by checking
    if the tokenizer assign the index of the `unk_token` to them).
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 仅当它们不在词汇表中时才会添加标记（通过检查分词器是否将`unk_token`的索引分配给它们进行测试）。
- en: '`replace_additional_special_tokens` (`bool`, *optional*,, defaults to `True`)
    — If `True`, the existing list of additional special tokens will be replaced by
    the list provided in `special_tokens_dict`. Otherwise, `self._additional_special_tokens`
    is just extended. In the former case, the tokens will NOT be removed from the
    tokenizer’s full vocabulary - they are only being flagged as non-special tokens.
    Remember, this only affects which tokens are skipped during decoding, not the
    `added_tokens_encoder` and `added_tokens_decoder`. This means that the previous
    `additional_special_tokens` are still added tokens, and will not be split by the
    model.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`replace_additional_special_tokens`（`bool`，*可选*，默认为`True`） - 如果为`True`，则现有的额外特殊标记列表将被`special_tokens_dict`中提供的列表替换。否则，`self._additional_special_tokens`只是被扩展。在前一种情况下，这些标记不会从标记器的完整词汇表中删除
    - 它们只被标记为非特殊标记。请记住，这只影响解码时跳过哪些标记，而不影响`added_tokens_encoder`和`added_tokens_decoder`。这意味着以前的`additional_special_tokens`仍然是添加的标记，并且不会被模型分割。'
- en: Returns
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: Number of tokens added to the vocabulary.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 将特殊标记添加到词汇表中的数量。
- en: Add a dictionary of special tokens (eos, pad, cls, etc.) to the encoder and
    link them to class attributes. If special tokens are NOT in the vocabulary, they
    are added to it (indexed starting from the last index of the current vocabulary).
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 将特殊标记的字典（eos、pad、cls等）添加到编码器中，并将它们链接到类属性。如果特殊标记不在词汇表中，则将它们添加到词汇表中（从当前词汇表的最后索引开始索引）。
- en: When adding new tokens to the vocabulary, you should make sure to also resize
    the token embedding matrix of the model so that its embedding matrix matches the
    tokenizer.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 在向词汇表中添加新标记时，您应确保还调整模型的标记嵌入矩阵，以使其嵌入矩阵与标记器匹配。
- en: In order to do that, please use the [resize_token_embeddings()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.resize_token_embeddings)
    method.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，请使用[resize_token_embeddings()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.resize_token_embeddings)方法。
- en: 'Using `add_special_tokens` will ensure your special tokens can be used in several
    ways:'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`add_special_tokens`将确保您的特殊标记可以以多种方式使用：
- en: Special tokens can be skipped when decoding using `skip_special_tokens = True`.
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在解码时可以跳过特殊标记，使用`skip_special_tokens = True`。
- en: Special tokens are carefully handled by the tokenizer (they are never split),
    similar to `AddedTokens`.
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特殊标记由标记器仔细处理（它们永远不会被分割），类似于`AddedTokens`。
- en: You can easily refer to special tokens using tokenizer class attributes like
    `tokenizer.cls_token`. This makes it easy to develop model-agnostic training and
    fine-tuning scripts.
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用标记器类属性轻松引用特殊标记，如`tokenizer.cls_token`。这使得开发与模型无关的训练和微调脚本变得容易。
- en: When possible, special tokens are already registered for provided pretrained
    models (for instance [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    `cls_token` is already registered to be :obj*’[CLS]’* and XLM’s one is also registered
    to be `'</s>'`).
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 在可能的情况下，为提供的预训练模型已经注册了特殊标记（例如[BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    `cls_token`已经注册为：obj*’[CLS]’*，XLM的一个也已经注册为`'</s>'`）。
- en: 'Examples:'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE29]'
  id: totrans-563
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '#### `add_tokens`'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L975)'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L975)'
- en: '[PRE30]'
  id: totrans-566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`new_tokens` (`str`, `tokenizers.AddedToken` or a list of *str* or `tokenizers.AddedToken`)
    — Tokens are only added if they are not already in the vocabulary. `tokenizers.AddedToken`
    wraps a string token to let you personalize its behavior: whether this token should
    only match against a single word, whether this token should strip all potential
    whitespaces on the left side, whether this token should strip all potential whitespaces
    on the right side, etc.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`new_tokens`（`str`，`tokenizers.AddedToken`或*str*或`tokenizers.AddedToken`的列表）
    - 仅当这些标记尚未在词汇表中时才会添加。`tokenizers.AddedToken`包装了一个字符串标记，让您可以个性化其行为：这个标记是否只匹配一个单词，这个标记是否应该去除左侧的所有潜在空格，这个标记是否应该去除右侧的所有潜在空格等。'
- en: '`special_tokens` (`bool`, *optional*, defaults to `False`) — Can be used to
    specify if the token is a special token. This mostly change the normalization
    behavior (special tokens like CLS or [MASK] are usually not lower-cased for instance).'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens`（`bool`，*可选*，默认为`False`） - 可用于指定标记是否为特殊标记。这主要会改变标准化行为（例如，特殊标记如CLS或[MASK]通常不会被小写）。'
- en: See details for `tokenizers.AddedToken` in HuggingFace tokenizers library.
  id: totrans-570
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请参阅HuggingFace tokenizers库中的`tokenizers.AddedToken`的详细信息。
- en: Returns
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`int`'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`'
- en: Number of tokens added to the vocabulary.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 将特殊标记添加到词汇表中的数量。
- en: Add a list of new tokens to the tokenizer class. If the new tokens are not in
    the vocabulary, they are added to it with indices starting from length of the
    current vocabulary and and will be isolated before the tokenization algorithm
    is applied. Added tokens and tokens from the vocabulary of the tokenization algorithm
    are therefore not treated in the same way.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 向标记器类添加一组新标记。如果新标记不在词汇表中，则将它们添加到词汇表中，索引从当前词汇表的长度开始，并且在应用标记化算法之前将被隔离。因此，标记化算法的添加标记和词汇表中的标记不会以相同的方式处理。
- en: Note, when adding new tokens to the vocabulary, you should make sure to also
    resize the token embedding matrix of the model so that its embedding matrix matches
    the tokenizer.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，向词汇表中添加新标记时，您应确保还调整模型的标记嵌入矩阵，以使其嵌入矩阵与标记器匹配。
- en: In order to do that, please use the [resize_token_embeddings()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.resize_token_embeddings)
    method.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，请使用[resize_token_embeddings()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.resize_token_embeddings)方法。
- en: 'Examples:'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE31]'
  id: totrans-578
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '#### `sanitize_special_tokens`'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `sanitize_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L865)'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L865)'
- en: '[PRE32]'
  id: totrans-581
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `sanitize_special_tokens` is now deprecated kept for backward compatibility
    and will be removed in transformers v5.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: '`sanitize_special_tokens` 现在已弃用，仅用于向后兼容，并将在 transformers v5 中移除。'
- en: Enums and namedtuples
  id: totrans-583
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 枚举和命名元组
- en: '### `class transformers.tokenization_utils_base.TruncationStrategy`'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.tokenization_utils_base.TruncationStrategy`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L138)'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L138)'
- en: '[PRE33]'
  id: totrans-586
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Possible values for the `truncation` argument in [PreTrainedTokenizerBase.**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__).
    Useful for tab-completion in an IDE.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [PreTrainedTokenizerBase.**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    中 `truncation` 参数的可能取值。在 IDE 中用于制表完成。
- en: '### `class transformers.CharSpan`'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.CharSpan`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L150)'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L150)'
- en: '[PRE34]'
  id: totrans-590
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Parameters
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`start` (`int`) — Index of the first character in the original string.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start` (`int`) — 原始字符串中第一个字符的索引。'
- en: '`end` (`int`) — Index of the character following the last character in the
    original string.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`end` (`int`) — 原始字符串中最后一个字符后面的字符的索引。'
- en: Character span in the original string.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 原始字符串中的字符范围。
- en: '### `class transformers.TokenSpan`'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TokenSpan`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L163)'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L163)'
- en: '[PRE35]'
  id: totrans-597
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`start` (`int`) — Index of the first token in the span.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start` (`int`) — span 中第一个标记的索引。'
- en: '`end` (`int`) — Index of the token following the last token in the span.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`end` (`int`) — span 中最后一个标记后面的标记的索引。'
- en: Token span in an encoded string (list of tokens).
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 编码字符串中的标记范围（标记列表）。
