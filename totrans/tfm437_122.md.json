["```py\n( *args **kwargs )\n```", "```py\n( args processor_dict: Dict **kwargs ) \u2192 export const metadata = 'undefined';~processing_utils.ProcessingMixin\n```", "```py\n( pretrained_model_name_or_path: Union cache_dir: Union = None force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' **kwargs )\n```", "```py\n( pretrained_model_name_or_path: Union **kwargs ) \u2192 export const metadata = 'undefined';Tuple[Dict, Dict]\n```", "```py\n( repo_id: str use_temp_dir: Optional = None commit_message: Optional = None private: Optional = None token: Union = None max_shard_size: Union = '5GB' create_pr: bool = False safe_serialization: bool = True revision: str = None commit_description: str = None tags: Optional = None **deprecated_kwargs )\n```", "```py\nfrom transformers import AutoProcessor\n\nprocessor = AutoProcessor.from_pretrained(\"bert-base-cased\")\n\n# Push the processor to your namespace with the name \"my-finetuned-bert\".\nprocessor.push_to_hub(\"my-finetuned-bert\")\n\n# Push the processor to an organization with the name \"my-finetuned-bert\".\nprocessor.push_to_hub(\"huggingface/my-finetuned-bert\")\n```", "```py\n( auto_class = 'AutoProcessor' )\n```", "```py\n( save_directory push_to_hub: bool = False **kwargs )\n```", "```py\n( ) \u2192 export const metadata = 'undefined';Dict[str, Any]\n```", "```py\n( json_file_path: Union )\n```", "```py\n( ) \u2192 export const metadata = 'undefined';str\n```", "```py\n( )\n```", "```py\n( data_dir )\n```", "```py\n( tensor_dict )\n```", "```py\n( )\n```", "```py\n( data_dir )\n```", "```py\n( data_dir )\n```", "```py\n( example )\n```", "```py\n( guid: str text_a: str text_b: Optional = None label: Optional = None )\n```", "```py\n( )\n```", "```py\n( input_ids: List attention_mask: Optional = None token_type_ids: Optional = None label: Union = None )\n```", "```py\n( )\n```", "```py\n( examples: Union tokenizer: PreTrainedTokenizer max_length: Optional = None task = None label_list = None output_mode = None )\n```", "```py\n( )\n```", "```py\n( data_dir filename = None )\n```", "```py\n( dataset evaluate = False )\n```", "```py\n>>> import tensorflow_datasets as tfds\n\n>>> dataset = tfds.load(\"squad\")\n\n>>> training_examples = get_examples_from_dataset(dataset, evaluate=False)\n>>> evaluation_examples = get_examples_from_dataset(dataset, evaluate=True)\n```", "```py\n( data_dir filename = None )\n```", "```py\n( examples tokenizer max_seq_length doc_stride max_query_length is_training padding_strategy = 'max_length' return_dataset = False threads = 1 tqdm_enabled = True )\n```", "```py\nprocessor = SquadV2Processor()\nexamples = processor.get_dev_examples(data_dir)\n\nfeatures = squad_convert_examples_to_features(\n    examples=examples,\n    tokenizer=tokenizer,\n    max_seq_length=args.max_seq_length,\n    doc_stride=args.doc_stride,\n    max_query_length=args.max_query_length,\n    is_training=not evaluate,\n)\n```", "```py\n# Loading a V2 processor\nprocessor = SquadV2Processor()\nexamples = processor.get_dev_examples(squad_v2_data_dir)\n\n# Loading a V1 processor\nprocessor = SquadV1Processor()\nexamples = processor.get_dev_examples(squad_v1_data_dir)\n\nfeatures = squad_convert_examples_to_features(\n    examples=examples,\n    tokenizer=tokenizer,\n    max_seq_length=max_seq_length,\n    doc_stride=args.doc_stride,\n    max_query_length=max_query_length,\n    is_training=not evaluate,\n)\n```", "```py\n# tensorflow_datasets only handle Squad V1.\ntfds_examples = tfds.load(\"squad\")\nexamples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)\n\nfeatures = squad_convert_examples_to_features(\n    examples=examples,\n    tokenizer=tokenizer,\n    max_seq_length=max_seq_length,\n    doc_stride=args.doc_stride,\n    max_query_length=max_query_length,\n    is_training=not evaluate,\n)\n```"]