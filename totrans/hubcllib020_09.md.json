["```py\n>>> pip install -U \"huggingface_hub[cli]\"\n```", "```py\n>>> huggingface-cli --help\nusage: huggingface-cli <command> [<args>]\n\npositional arguments:\n  {env,login,whoami,logout,repo,upload,download,lfs-enable-largefiles,lfs-multipart-upload,scan-cache,delete-cache}\n                        huggingface-cli command helpers\n    env                 Print information about the environment.\n    login               Log in using a token from huggingface.co/settings/tokens\n    whoami              Find out which huggingface.co account you are logged in as.\n    logout              Log out\n    repo                {create} Commands to interact with your huggingface.co repos.\n    upload              Upload a file or a folder to a repo on the Hub\n    download            Download files from the Hub\n    lfs-enable-largefiles\n                        Configure your repository to enable upload of files > 5GB.\n    scan-cache          Scan cache directory.\n    delete-cache        Delete revisions from the cache directory.\n\noptions:\n  -h, --help            show this help message and exit\n```", "```py\n>>> huggingface-cli login\n```", "```py\n_|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n_|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n_|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n_|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n_|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\nTo login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\nToken: \nAdd token as git credential? (Y/n) \nToken is valid (permission: write).\nYour token has been saved in your configured git credential helpers (store).\nYour token has been saved to /home/wauplin/.cache/huggingface/token\nLogin successful\n```", "```py\n# Or using an environment variable\n>>> huggingface-cli login --token $HUGGINGFACE_TOKEN --add-to-git-credential \nToken is valid (permission: write).\nYour token has been saved in your configured git credential helpers (store).\nYour token has been saved to /home/wauplin/.cache/huggingface/token\nLogin successful\n```", "```py\nhuggingface-cli whoami                                                                     \nWauplin\norgs:  huggingface,eu-test,OAuthTesters,hf-accelerate,HFSmolCluster\n```", "```py\nhuggingface-cli download --help\n```", "```py\n>>> huggingface-cli download gpt2 config.json\ndownloading https://huggingface.co/gpt2/resolve/main/config.json to /home/wauplin/.cache/huggingface/hub/tmpwrq8dm5o\n(\u2026)ingface.co/gpt2/resolve/main/config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 665/665 [00:00<00:00, 2.49MB/s]\n/home/wauplin/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10/config.json\n```", "```py\n>>> huggingface-cli download HuggingFaceH4/zephyr-7b-beta\nFetching 23 files:   0%|                                                | 0/23 [00:00<?, ?it/s]\n...\n...\n/home/wauplin/.cache/huggingface/hub/models--HuggingFaceH4--zephyr-7b-beta/snapshots/3bac358730f8806e5c3dc7c7e19eb36e045bf720\n```", "```py\n>>> huggingface-cli download gpt2 config.json model.safetensors\nFetching 2 files:   0%|                                                                        | 0/2 [00:00<?, ?it/s]\ndownloading https://huggingface.co/gpt2/resolve/11c5a3d5811f50298f278a704980280950aedb10/model.safetensors to /home/wauplin/.cache/huggingface/hub/tmpdachpl3o\n(\u2026)8f278a7049802950aedb10/model.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8.09k/8.09k [00:00<00:00, 40.5MB/s]\nFetching 2 files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00<00:00,  3.76it/s]\n/home/wauplin/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10\n```", "```py\n>>> huggingface-cli download stabilityai/stable-diffusion-xl-base-1.0 --include \"*.safetensors\" --exclude \"*.fp16.*\"*\nFetching 8 files:   0%|                                                                         | 0/8 [00:00<?, ?it/s]\n...\n...\nFetching 8 files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 (...)\n/home/wauplin/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0/snapshots/462165984030d82259a11f4367a4eed129e94a7b\n```", "```py\n# https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k\n>>> huggingface-cli download HuggingFaceH4/ultrachat_200k --repo-type dataset\n\n# https://huggingface.co/spaces/HuggingFaceH4/zephyr-chat\n>>> huggingface-cli download HuggingFaceH4/zephyr-chat --repo-type space\n\n...\n```", "```py\n>>> huggingface-cli download bigcode/the-stack --repo-type dataset --revision v1.1\n...\n```", "```py\n>>> huggingface-cli download adept/fuyu-8b model-00001-of-00002.safetensors --local-dir .\n...\n./model-00001-of-00002.safetensors\n```", "```py\n>>> huggingface-cli download adept/fuyu-8b --cache-dir ./path/to/cache\n...\n./path/to/cache/models--adept--fuyu-8b/snapshots/ddcacbcf5fdf9cc59ff01f6be6d6662624d9c745\n```", "```py\n>>> huggingface-cli download gpt2 config.json --token=hf_****\n/home/wauplin/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10/config.json\n```", "```py\n>>> huggingface-cli download gpt2 --quiet\n/home/wauplin/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10\n```", "```py\n>>> huggingface-cli upload --help\n```", "```py\n# Usage:  huggingface-cli upload [repo_id] [local_path] [path_in_repo]\n```", "```py\n>>> huggingface-cli upload my-cool-model . .\nhttps://huggingface.co/Wauplin/my-cool-model/tree/main/\n```", "```py\n>>> huggingface-cli upload my-cool-model ./models .\nhttps://huggingface.co/Wauplin/my-cool-model/tree/main/\n```", "```py\n>>> huggingface-cli upload my-cool-model ./path/to/curated/data /data/train\nhttps://huggingface.co/Wauplin/my-cool-model/tree/main/data/train\n```", "```py\n>>> huggingface-cli upload Wauplin/my-cool-model ./models/model.safetensors\nhttps://huggingface.co/Wauplin/my-cool-model/blob/main/model.safetensors\n```", "```py\n>>> huggingface-cli upload Wauplin/my-cool-model ./models/model.safetensors /vae/model.safetensors\nhttps://huggingface.co/Wauplin/my-cool-model/blob/main/vae/model.safetensors\n```", "```py\n# Sync local Space with Hub (upload new files except from logs/, delete removed files)\n>>> huggingface-cli upload Wauplin/space-example --repo-type=space --exclude=\"/logs/*\" --delete=\"*\" --commit-message=\"Sync local Space with Hub\"\n...\n```", "```py\n>>> huggingface-cli upload Wauplin/my-cool-dataset ./data /train --repo-type=dataset\n...\n```", "```py\n>>> huggingface-cli upload MyCoolOrganization/my-cool-model . .\nhttps://huggingface.co/MyCoolOrganization/my-cool-model/tree/main/\n```", "```py\n# Upload files to a PR\n>>> huggingface-cli upload bigcode/the-stack . . --repo-type dataset --revision refs/pr/104\n...\n```", "```py\n# Create a PR and upload the files to it\n>>> huggingface-cli upload bigcode/the-stack . . --repo-type dataset --revision refs/pr/104\nhttps://huggingface.co/datasets/bigcode/the-stack/blob/refs%2Fpr%2F104/\n```", "```py\n# Upload new logs every 10 minutes\nhuggingface-cli upload training-model logs/ --every=10\n```", "```py\n>>> huggingface-cli upload Wauplin/my-cool-model ./models . --commit-message=\"Epoch 34/50\" --commit-description=\"Val accuracy: 68%. Check tensorboard for more details.\"\n...\nhttps://huggingface.co/Wauplin/my-cool-model/tree/main\n```", "```py\n>>> huggingface-cli upload Wauplin/my-cool-model ./models . --token=hf_****\n...\nhttps://huggingface.co/Wauplin/my-cool-model/tree/main\n```", "```py\n>>> huggingface-cli upload Wauplin/my-cool-model ./models . --quiet\nhttps://huggingface.co/Wauplin/my-cool-model/tree/main\n```", "```py\n>>> huggingface-cli scan-cache\nREPO ID                     REPO TYPE SIZE ON DISK NB FILES LAST_ACCESSED LAST_MODIFIED REFS                LOCAL PATH\n--------------------------- --------- ------------ -------- ------------- ------------- ------------------- -------------------------------------------------------------------------\nglue                        dataset         116.3K       15 4 days ago    4 days ago    2.4.0, main, 1.17.0 /home/wauplin/.cache/huggingface/hub/datasets--glue\ngoogle/fleurs               dataset          64.9M        6 1 week ago    1 week ago    refs/pr/1, main     /home/wauplin/.cache/huggingface/hub/datasets--google--fleurs\nJean-Baptiste/camembert-ner model           441.0M        7 2 weeks ago   16 hours ago  main                /home/wauplin/.cache/huggingface/hub/models--Jean-Baptiste--camembert-ner\nbert-base-cased             model             1.9G       13 1 week ago    2 years ago                       /home/wauplin/.cache/huggingface/hub/models--bert-base-cased\nt5-base                     model            10.1K        3 3 months ago  3 months ago  main                /home/wauplin/.cache/huggingface/hub/models--t5-base\nt5-small                    model           970.7M       11 3 days ago    3 days ago    refs/pr/1, main     /home/wauplin/.cache/huggingface/hub/models--t5-small\n\nDone in 0.0s. Scanned 6 repo(s) for a total of 3.4G.\nGot 1 warning(s) while scanning. Use -vvv to print details.\n```", "```py\n>>> huggingface-cli env\n\nCopy-and-paste the text below in your GitHub issue.\n\n- huggingface_hub version: 0.19.0.dev0\n- Platform: Linux-6.2.0-36-generic-x86_64-with-glibc2.35\n- Python version: 3.10.12\n- Running in iPython ?: No\n- Running in notebook ?: No\n- Running in Google Colab ?: No\n- Token path ?: /home/wauplin/.cache/huggingface/token\n- Has saved token ?: True\n- Who am I ?: Wauplin\n- Configured git credential helpers: store\n- FastAI: N/A\n- Tensorflow: 2.11.0\n- Torch: 1.12.1\n- Jinja2: 3.1.2\n- Graphviz: 0.20.1\n- Pydot: 1.4.2\n- Pillow: 9.2.0\n- hf_transfer: 0.1.3\n- gradio: 4.0.2\n- tensorboard: 2.6\n- numpy: 1.23.2\n- pydantic: 2.4.2\n- aiohttp: 3.8.4\n- ENDPOINT: https://huggingface.co\n- HF_HUB_CACHE: /home/wauplin/.cache/huggingface/hub\n- HF_ASSETS_CACHE: /home/wauplin/.cache/huggingface/assets\n- HF_TOKEN_PATH: /home/wauplin/.cache/huggingface/token\n- HF_HUB_OFFLINE: False\n- HF_HUB_DISABLE_TELEMETRY: False\n- HF_HUB_DISABLE_PROGRESS_BARS: None\n- HF_HUB_DISABLE_SYMLINKS_WARNING: False\n- HF_HUB_DISABLE_EXPERIMENTAL_WARNING: False\n- HF_HUB_DISABLE_IMPLICIT_TOKEN: False\n- HF_HUB_ENABLE_HF_TRANSFER: False\n- HF_HUB_ETAG_TIMEOUT: 10\n- HF_HUB_DOWNLOAD_TIMEOUT: 10\n```"]