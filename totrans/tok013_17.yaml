- en: Post-processors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 后处理器
- en: 'Original text: [https://huggingface.co/docs/tokenizers/api/post-processors](https://huggingface.co/docs/tokenizers/api/post-processors)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/tokenizers/api/post-processors](https://huggingface.co/docs/tokenizers/api/post-processors)
- en: PythonRustNode
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: PythonRustNode
- en: BertProcessing
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BertProcessing
- en: '### `class tokenizers.processors.BertProcessing`'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.processors.BertProcessing`'
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sep` (`Tuple[str, int]`) — A tuple with the string representation of the SEP
    token, and its id'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep` (`Tuple[str, int]`) — 包含SEP标记的字符串表示和其ID的元组'
- en: '`cls` (`Tuple[str, int]`) — A tuple with the string representation of the CLS
    token, and its id'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls` (`Tuple[str, int]`) — 包含CLS标记的字符串表示和其ID的元组'
- en: 'This post-processor takes care of adding the special tokens needed by a Bert
    model:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这个后处理器负责添加Bert模型所需的特殊标记：
- en: a SEP token
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个SEP标记
- en: a CLS token
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个CLS标记
- en: ByteLevel
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ByteLevel
- en: '### `class tokenizers.processors.ByteLevel`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.processors.ByteLevel`'
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`trim_offsets` (`bool`) — Whether to trim the whitespaces from the produced
    offsets.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trim_offsets` (`bool`) — 是否修剪生成的偏移量中的空格。'
- en: This post-processor takes care of trimming the offsets.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个后处理器负责修剪偏移量。
- en: By default, the ByteLevel BPE might include whitespaces in the produced tokens.
    If you don’t want the offsets to include these whitespaces, then this PostProcessor
    must be used.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，ByteLevel BPE可能会在生成的标记中包含空格。如果您不希望偏移量包含这些空格，则必须使用此PostProcessor。
- en: RobertaProcessing
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RobertaProcessing
- en: '### `class tokenizers.processors.RobertaProcessing`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.processors.RobertaProcessing`'
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sep` (`Tuple[str, int]`) — A tuple with the string representation of the SEP
    token, and its id'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep` (`Tuple[str, int]`) — 包含SEP标记的字符串表示和其ID的元组'
- en: '`cls` (`Tuple[str, int]`) — A tuple with the string representation of the CLS
    token, and its id'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls` (`Tuple[str, int]`) — 包含CLS标记的字符串表示和其ID的元组'
- en: '`trim_offsets` (`bool`, *optional*, defaults to `True`) — Whether to trim the
    whitespaces from the produced offsets.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trim_offsets` (`bool`, *可选*, 默认为`True`) — 是否修剪生成的偏移量中的空格。'
- en: '`add_prefix_space` (`bool`, *optional*, defaults to `True`) — Whether the add_prefix_space
    option was enabled during pre-tokenization. This is relevant because it defines
    the way the offsets are trimmed out.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_prefix_space` (`bool`, *可选*, 默认为`True`) — 在预分词期间是否启用了add_prefix_space选项。这很重要，因为它定义了如何修剪偏移量。'
- en: 'This post-processor takes care of adding the special tokens needed by a Roberta
    model:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这个后处理器负责添加Roberta模型所需的特殊标记：
- en: a SEP token
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个SEP标记
- en: a CLS token
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个CLS标记
- en: It also takes care of trimming the offsets. By default, the ByteLevel BPE might
    include whitespaces in the produced tokens. If you don’t want the offsets to include
    these whitespaces, then this PostProcessor should be initialized with `trim_offsets=True`
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 它还负责修剪偏移量。默认情况下，ByteLevel BPE可能会在生成的标记中包含空格。如果您不希望偏移量包含这些空格，则应该使用`trim_offsets=True`初始化此PostProcessor
- en: TemplateProcessing
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TemplateProcessing
- en: '### `class tokenizers.processors.TemplateProcessing`'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class tokenizers.processors.TemplateProcessing`'
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`single` (`Template`) — The template used for single sequences'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`single` (`Template`) — 用于单个序列的模板'
- en: '`pair` (`Template`) — The template used when both sequences are specified'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pair` (`Template`) — 当两个序列都指定时使用的模板'
- en: '`special_tokens` (`Tokens`) — The list of special tokens used in each sequences'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens` (`Tokens`) — 每个序列中使用的特殊标记列表'
- en: Provides a way to specify templates in order to add the special tokens to each
    input sequence as relevant.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了一种指定模板以便将特殊标记添加到每个输入序列中的方法。
- en: 'Let’s take `BERT` tokenizer as an example. It uses two special tokens, used
    to delimitate each sequence. `[CLS]` is always used at the beginning of the first
    sequence, and `[SEP]` is added at the end of both the first, and the pair sequences.
    The final result looks like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以`BERT`分词器为例。它使用两个特殊标记，用于分隔每个序列。`[CLS]`始终用于第一个序列的开头，`[SEP]`被添加到第一个序列和双序列的末尾。最终结果如下：
- en: 'Single sequence: `[CLS] Hello there [SEP]`'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个序列：`[CLS] 你好 [SEP]`
- en: 'Pair sequences: `[CLS] My name is Anthony [SEP] What is my name? [SEP]`'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双序列：`[CLS] 我的名字是安东尼 [SEP] 我的名字是什么？ [SEP]`
- en: 'With the type ids as following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 具有以下类型ID：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can achieve such behavior using a TemplateProcessing:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用TemplateProcessing来实现这种行为：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this example, each input sequence is identified using a `$` construct. This
    identifier lets us specify each input sequence, and the type_id to use. When nothing
    is specified, it uses the default values. Here are the different ways to specify
    it:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '在这个例子中，每个输入序列都使用`$`构造进行标识。这个标识符让我们可以指定每个输入序列和要使用的type_id。当没有指定时，它使用默认值。以下是指定的不同方式： '
- en: 'Specifying the sequence, with default `type_id == 0`: `$A` or `$B`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定序列，默认`type_id == 0`：`$A` 或 `$B`
- en: 'Specifying the *type_id* with default `sequence == A`: `$0`, `$1`, `$2`, …'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定*type_id*，默认`sequence == A`：`$0`，`$1`，`$2`，…
- en: 'Specifying both: `$A:0`, `$B:1`, …'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时指定：`$A:0`，`$B:1`，…
- en: 'The same construct is used for special tokens: `<identifier>(:<type_id>)?`.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的结构用于特殊标记：`<identifier>(:<type_id>)?`。
- en: '**Warning**: You must ensure that you are giving the correct tokens/ids as
    these will be added to the Encoding without any further check. If the given ids
    correspond to something totally different in a *Tokenizer* using this *PostProcessor*,
    it might lead to unexpected results.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**：您必须确保提供正确的标记/ID，因为这些将被添加到编码中，不会再进行进一步检查。如果给定的ID在使用此*PostProcessor*的*Tokenizer*中对应于完全不同的内容，可能会导致意外结果。'
- en: 'Types:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 类型：
- en: 'Template (`str` or `List`):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 模板（`str`或`List`）：
- en: If a `str` is provided, the whitespace is used as delimiter between tokens
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了一个`str`，则空格被用作标记之间的分隔符
- en: If a `List[str]` is provided, a list of tokens
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了一个`List[str]`，则是一个标记列表
- en: 'Tokens (`List[Union[Tuple[int, str], Tuple[str, int], dict]]`):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 'Tokens (`List[Union[Tuple[int, str], Tuple[str, int], dict]]`):'
- en: A `Tuple` with both a token and its associated ID, in any order
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含标记及其关联ID的元组，顺序任意
- en: 'A `dict` with the following keys:'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含以下键的字典：
- en: '“id”: `str` => The special token id, as specified in the Template'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '“id”: `str` => 模板中指定的特殊标记ID'
- en: '“ids”: `List[int]` => The associated IDs'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '“ids”: `List[int]` => 相关的ID'
- en: '“tokens”: `List[str]` => The associated tokens'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “tokens”：`List[str]` => 相关的标记
- en: The given dict expects the provided `ids` and `tokens` lists to have the same
    length.
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 给定的字典期望提供的“ids”和“tokens”列表具有相同的长度。
