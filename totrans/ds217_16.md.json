["```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"lhoestq/demo1\")\n```", "```py\n>>> dataset = load_dataset(\n...   \"lhoestq/custom_squad\",\n...   revision=\"main\"  # tag name, or branch name, or commit hash\n... )\n```", "```py\n>>> data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\"}\n>>> dataset = load_dataset(\"namespace/your_dataset_name\", data_files=data_files)\n```", "```py\n>>> from datasets import load_dataset\n\n# load files that match the grep pattern\n>>> c4_subset = load_dataset(\"allenai/c4\", data_files=\"en/c4-train.0000*-of-01024.json.gz\")\n\n# load dataset from the en directory on the Hub\n>>> c4_subset = load_dataset(\"allenai/c4\", data_dir=\"en\")\n```", "```py\n>>> data_files = {\"validation\": \"en/c4-validation.*.json.gz\"}\n>>> c4_validation = load_dataset(\"allenai/c4\", data_files=data_files, split=\"validation\")\n```", "```py\n>>> dataset = load_dataset(\"path/to/local/loading_script/loading_script.py\", split=\"train\", trust_remote_code=True)\n>>> dataset = load_dataset(\"path/to/local/loading_script\", split=\"train\", trust_remote_code=True)  # equivalent because the file has the same name as the directory\n```", "```py\ngit clone https://huggingface.co/datasets/eli5\n```", "```py\n>>> from datasets import load_dataset\n>>> eli5 = load_dataset(\"path/to/local/eli5\")\n```", "```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"csv\", data_files=\"my_file.csv\")\n```", "```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"json\", data_files=\"my_file.json\")\n```", "```py\n{\"a\": 1, \"b\": 2.0, \"c\": \"foo\", \"d\": false}\n{\"a\": 4, \"b\": -5.5, \"c\": null, \"d\": true}\n```", "```py\n{\"version\": \"0.1.0\",\n \"data\": [{\"a\": 1, \"b\": 2.0, \"c\": \"foo\", \"d\": false},\n          {\"a\": 4, \"b\": -5.5, \"c\": null, \"d\": true}]\n}\n\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"json\", data_files=\"my_file.json\", field=\"data\")\n```", "```py\n>>> base_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/\"\n>>> dataset = load_dataset(\"json\", data_files={\"train\": base_url + \"train-v1.1.json\", \"validation\": base_url + \"dev-v1.1.json\"}, field=\"data\")\n```", "```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"parquet\", data_files={'train': 'train.parquet', 'test': 'test.parquet'})\n```", "```py\n>>> base_url = \"https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20200501.en/1.0.0/\"\n>>> data_files = {\"train\": base_url + \"wikipedia-train.parquet\"}\n>>> wiki = load_dataset(\"parquet\", data_files=data_files, split=\"train\")\n```", "```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"arrow\", data_files={'train': 'train.arrow', 'test': 'test.arrow'})\n```", "```py\n>>> base_url = \"https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20200501.en/1.0.0/\"\n>>> data_files = {\"train\": base_url + \"wikipedia-train.arrow\"}\n>>> wiki = load_dataset(\"arrow\", data_files=data_files, split=\"train\")\n```", "```py\n>>> from datasets import Dataset\n>>> dataset = Dataset.from_file(\"data.arrow\")\n```", "```py\n>>> from datasets import Dataset\n# load entire table\n>>> dataset = Dataset.from_sql(\"data_table_name\", con=\"sqlite:///sqlite_file.db\")\n# load from query\n>>> dataset = Dataset.from_sql(\"SELECT text FROM table WHERE length(text) > 100 LIMIT 10\", con=\"sqlite:///sqlite_file.db\")\n```", "```py\n>>> from datasets import load_dataset\n>>>\n>>> path = \"path/to/train/*.tar\"\n>>> dataset = load_dataset(\"webdataset\", data_files={\"train\": path}, split=\"train\", streaming=True)\n```", "```py\n>>> from datasets import load_dataset\n>>>\n>>> base_url = \"https://huggingface.co/datasets/lhoestq/small-publaynet-wds/resolve/main/publaynet-train-{i:06d}.tar\"\n>>> urls = [base_url.format(i=i) for i in range(4)]\n>>> dataset = load_dataset(\"webdataset\", data_files={\"train\": urls}, split=\"train\", streaming=True)\n```", "```py\nfrom datasets import load_dataset\n\nimagenet = load_dataset(\"imagenet-1k\", num_proc=8)\nml_librispeech_spanish = load_dataset(\"facebook/multilingual_librispeech\", \"spanish\", num_proc=8)\n```", "```py\n>>> from datasets import Dataset\n>>> my_dict = {\"a\": [1, 2, 3]}\n>>> dataset = Dataset.from_dict(my_dict)\n```", "```py\n>>> from datasets import Dataset\n>>> my_list = [{\"a\": 1}, {\"a\": 2}, {\"a\": 3}]\n>>> dataset = Dataset.from_list(my_list)\n```", "```py\n>>> from datasets import Dataset\n>>> def my_gen():\n...     for i in range(1, 4):\n...         yield {\"a\": i}\n...\n>>> dataset = Dataset.from_generator(my_gen)\n```", "```py\n>>> def gen(shards):\n...     for shard in shards:\n...         with open(shard) as f:\n...             for line in f:\n...                 yield {\"line\": line}\n...\n>>> shards = [f\"data{i}.txt\" for i in range(32)]\n>>> ds = IterableDataset.from_generator(gen, gen_kwargs={\"shards\": shards})\n>>> ds = ds.shuffle(seed=42, buffer_size=10_000)  # shuffles the shards order + uses a shuffle buffer\n>>> from torch.utils.data import DataLoader\n>>> dataloader = DataLoader(ds.with_format(\"torch\"), num_workers=4)  # give each worker a subset of 32/4=8 shards\n```", "```py\n>>> from datasets import Dataset\n>>> import pandas as pd\n>>> df = pd.DataFrame({\"a\": [1, 2, 3]})\n>>> dataset = Dataset.from_pandas(df)\n```", "```py\n>>> train_test_ds = datasets.load_dataset(\"bookcorpus\", split=\"train+test\") Select specific rows of the `train` split:  \n\n```", "```py\n>>> train_10pct_ds = datasets.load_dataset(\"bookcorpus\", split=\"train[:10%]\") Select a combination of percentages from each split:  \n\n```", "```py\n>>> val_ds = datasets.load_dataset(\"bookcorpus\", split=[f\"train[{k}%:{k+10}%]\" for k in range(0, 100, 10)])\n>>> train_ds = datasets.load_dataset(\"bookcorpus\", split=[f\"train[:{k}%]+train[{k+10}%:]\" for k in range(0, 100, 10)])    Percent slicing and rounding The default behavior is to round the boundaries to the nearest integer for datasets where the requested slice boundaries do not divide evenly by 100\\. As shown below, some slices may contain more examples than others. For instance, if the following train split includes 999 records, then:  \n\n```", "```py\n\nIf you want equal sized splits, use `pct1_dropremainder` rounding instead. This treats the specified percentage boundaries as multiples of 1%.\n\n```", "```py\n\n`pct1_dropremainder` rounding may truncate the last examples in a dataset if the number of examples in your dataset don\u2019t divide evenly by 100.\n\n##   Troubleshooting\n\nSometimes, you may get unexpected results when you load a dataset. Two of the most common issues you may encounter are manually downloading a dataset and specifying features of a dataset.\n\n###   Manual download\n\nCertain datasets require you to manually download the dataset files due to licensing incompatibility or if the files are hidden behind a login page. This causes [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset) to throw an `AssertionError`. But \ud83e\udd17 Datasets provides detailed instructions for downloading the missing files. After you\u2019ve downloaded the files, use the `data_dir` argument to specify the path to the files you just downloaded.\n\nFor example, if you try to download a configuration from the [MATINF](https://huggingface.co/datasets/matinf) dataset:\n\n```", "```py\n\nIf you\u2019ve already downloaded a dataset from the *Hub with a loading script* to your computer, then you need to pass an absolute path to the `data_dir` or `data_files` parameter to load that dataset. Otherwise, if you pass a relative path, [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset) will load the directory from the repository on the Hub instead of the local directory.\n\n###   Specify features\n\nWhen you create a dataset from local files, the [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features) are automatically inferred by [Apache Arrow](https://arrow.apache.org/docs/). However, the dataset\u2019s features may not always align with your expectations, or you may want to define the features yourself. The following example shows how you can add custom labels with the [ClassLabel](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel) feature.\n\nStart by defining your own labels with the [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features) class:\n\n```", "```py\n\nNext, specify the `features` parameter in [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset) with the features you just created:\n\n```", "```py\n\nNow when you look at your dataset features, you can see it uses the custom labels you defined:\n\n```", "```py\n\n##   Metrics\n\nMetrics is deprecated in \ud83e\udd17 Datasets. To learn more about how to use metrics, take a look at the library \ud83e\udd17 [Evaluate](https://huggingface.co/docs/evaluate/index)! In addition to metrics, you can find more tools for evaluating models and datasets.\n\nWhen the metric you want to use is not supported by \ud83e\udd17 Datasets, you can write and use your own metric script. Load your metric by providing the path to your local metric loading script:\n\n```", "```py\n\nSee the [Metrics](./how_to_metrics#custom-metric-loading-script) guide for more details on how to write your own metric loading script.\n\n###   Load configurations\n\nIt is possible for a metric to have different configurations. The configurations are stored in the `config_name` parameter in [MetricInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.MetricInfo) attribute. When you load a metric, provide the configuration name as shown in the following:\n\n```", "```py\n\n###   Distributed setup\n\nWhen working in a distributed or parallel processing environment, loading and computing a metric can be tricky because these processes are executed in parallel on separate subsets of the data. \ud83e\udd17 Datasets supports distributed usage with a few additional arguments when you load a metric.\n\nFor example, imagine you are training and evaluating on eight parallel processes. Here\u2019s how you would load a metric in this distributed setting:\n\n1.  Define the total number of processes with the `num_process` argument.\n\n2.  Set the process `rank` as an integer between zero and `num_process - 1`.\n\n3.  Load your metric with [load_metric()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_metric) with these arguments:\n\n```", "```py\n\nOnce you\u2019ve loaded a metric for distributed usage, you can compute the metric as usual. Behind the scenes, [Metric.compute()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Metric.compute) gathers all the predictions and references from the nodes, and computes the final metric.\n\nIn some instances, you may be simultaneously running multiple independent distributed evaluations on the same server and files. To avoid any conflicts, it is important to provide an `experiment_id` to distinguish the separate evaluations:\n\n```", "```py\n\n```", "```py\n\n```", "```py\n\n```"]