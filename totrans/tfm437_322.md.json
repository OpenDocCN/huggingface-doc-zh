["```py\nimport torch\nfrom transformers import VitsTokenizer, VitsModel, set_seed\n\ntokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\nmodel = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n\ninputs = tokenizer(text=\"Hello - my dog is cute\", return_tensors=\"pt\")\n\nset_seed(555)  # make deterministic\n\nwith torch.no_grad():\n   outputs = model(**inputs)\n\nwaveform = outputs.waveform[0]\n```", "```py\nimport scipy\n\nscipy.io.wavfile.write(\"techno.wav\", rate=model.config.sampling_rate, data=waveform)\n```", "```py\nfrom IPython.display import Audio\n\nAudio(waveform, rate=model.config.sampling_rate)\n```", "```py\nfrom transformers import VitsTokenizer\n\ntokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\nprint(tokenizer.is_uroman)\n```", "```py\ngit clone https://github.com/isi-nlp/uroman.git\ncd uroman\nexport UROMAN=$(pwd)\n```", "```py\nimport torch\nfrom transformers import VitsTokenizer, VitsModel, set_seed\nimport os\nimport subprocess\n\ntokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-kor\")\nmodel = VitsModel.from_pretrained(\"facebook/mms-tts-kor\")\n\ndef uromanize(input_string, uroman_path):\n    \"\"\"Convert non-Roman strings to Roman using the `uroman` perl package.\"\"\"\n    script_path = os.path.join(uroman_path, \"bin\", \"uroman.pl\")\n\n    command = [\"perl\", script_path]\n\n    process = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    # Execute the perl command\n    stdout, stderr = process.communicate(input=input_string.encode())\n\n    if process.returncode != 0:\n        raise ValueError(f\"Error {process.returncode}: {stderr.decode()}\")\n\n    # Return the output as a string and skip the new-line character at the end\n    return stdout.decode()[:-1]\n\ntext = \"\uc774\ubd10 \ubb34\uc2a8 \uc77c\uc774\uc57c\"\nuromaized_text = uromanize(text, uroman_path=os.environ[\"UROMAN\"])\n\ninputs = tokenizer(text=uromaized_text, return_tensors=\"pt\")\n\nset_seed(555)  # make deterministic\nwith torch.no_grad():\n   outputs = model(inputs[\"input_ids\"])\n\nwaveform = outputs.waveform[0]\n```", "```py\n( vocab_size = 38 hidden_size = 192 num_hidden_layers = 6 num_attention_heads = 2 window_size = 4 use_bias = True ffn_dim = 768 layerdrop = 0.1 ffn_kernel_size = 3 flow_size = 192 spectrogram_bins = 513 hidden_act = 'relu' hidden_dropout = 0.1 attention_dropout = 0.1 activation_dropout = 0.1 initializer_range = 0.02 layer_norm_eps = 1e-05 use_stochastic_duration_prediction = True num_speakers = 1 speaker_embedding_size = 0 upsample_initial_channel = 512 upsample_rates = [8, 8, 2, 2] upsample_kernel_sizes = [16, 16, 4, 4] resblock_kernel_sizes = [3, 7, 11] resblock_dilation_sizes = [[1, 3, 5], [1, 3, 5], [1, 3, 5]] leaky_relu_slope = 0.1 depth_separable_channels = 2 depth_separable_num_layers = 3 duration_predictor_flow_bins = 10 duration_predictor_tail_bound = 5.0 duration_predictor_kernel_size = 3 duration_predictor_dropout = 0.5 duration_predictor_num_flows = 4 duration_predictor_filter_channels = 256 prior_encoder_num_flows = 4 prior_encoder_num_wavenet_layers = 4 posterior_encoder_num_wavenet_layers = 16 wavenet_kernel_size = 5 wavenet_dilation_rate = 1 wavenet_dropout = 0.0 speaking_rate = 1.0 noise_scale = 0.667 noise_scale_duration = 0.8 sampling_rate = 16000 **kwargs )\n```", "```py\n>>> from transformers import VitsModel, VitsConfig\n\n>>> # Initializing a \"facebook/mms-tts-eng\" style configuration\n>>> configuration = VitsConfig()\n\n>>> # Initializing a model (with random weights) from the \"facebook/mms-tts-eng\" style configuration\n>>> model = VitsModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( vocab_file pad_token = '<pad>' unk_token = '<unk>' language = None add_blank = True normalize = True phonemize = True is_uroman = False **kwargs )\n```", "```py\n( text: Union = None text_pair: Union = None text_target: Union = None text_pair_target: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 is_split_into_words: bool = False pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs ) \u2192 export const metadata = 'undefined';BatchEncoding\n```", "```py\n( save_directory: str filename_prefix: Optional = None )\n```", "```py\n( config: VitsConfig )\n```", "```py\n( input_ids: Optional = None attention_mask: Optional = None speaker_id: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None labels: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.vits.modeling_vits.VitsModelOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import VitsTokenizer, VitsModel, set_seed\n>>> import torch\n\n>>> tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n>>> model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n\n>>> inputs = tokenizer(text=\"Hello - my dog is cute\", return_tensors=\"pt\")\n\n>>> set_seed(555)  # make deterministic\n\n>>> with torch.no_grad():\n...     outputs = model(inputs[\"input_ids\"])\n>>> outputs.waveform.shape\ntorch.Size([1, 45824])\n```"]