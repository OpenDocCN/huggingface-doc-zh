["```py\nimport torch\nfrom transformers import VitsTokenizer, VitsModel, set_seed\n\ntokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\nmodel = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n\ninputs = tokenizer(text=\"Hello - my dog is cute\", return_tensors=\"pt\")\n\nset_seed(555)  # make deterministic\n\nwith torch.no_grad():\n   outputs = model(**inputs)\n\nwaveform = outputs.waveform[0]\n```", "```py\nimport scipy\n\nscipy.io.wavfile.write(\"techno.wav\", rate=model.config.sampling_rate, data=waveform)\n```", "```py\nfrom IPython.display import Audio\n\nAudio(waveform, rate=model.config.sampling_rate)\n```", "```py\nfrom transformers import VitsTokenizer\n\ntokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\nprint(tokenizer.is_uroman)\n```", "```py\ngit clone https://github.com/isi-nlp/uroman.git\ncd uroman\nexport UROMAN=$(pwd)\n```", "```py\nimport torch\nfrom transformers import VitsTokenizer, VitsModel, set_seed\nimport os\nimport subprocess\n\ntokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-kor\")\nmodel = VitsModel.from_pretrained(\"facebook/mms-tts-kor\")\n\ndef uromanize(input_string, uroman_path):\n    \"\"\"Convert non-Roman strings to Roman using the `uroman` perl package.\"\"\"\n    script_path = os.path.join(uroman_path, \"bin\", \"uroman.pl\")\n\n    command = [\"perl\", script_path]\n\n    process = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    # Execute the perl command\n    stdout, stderr = process.communicate(input=input_string.encode())\n\n    if process.returncode != 0:\n        raise ValueError(f\"Error {process.returncode}: {stderr.decode()}\")\n\n    # Return the output as a string and skip the new-line character at the end\n    return stdout.decode()[:-1]\n\ntext = \"\uc774\ubd10 \ubb34\uc2a8 \uc77c\uc774\uc57c\"\nuromaized_text = uromanize(text, uroman_path=os.environ[\"UROMAN\"])\n\ninputs = tokenizer(text=uromaized_text, return_tensors=\"pt\")\n\nset_seed(555)  # make deterministic\nwith torch.no_grad():\n   outputs = model(inputs[\"input_ids\"])\n\nwaveform = outputs.waveform[0]\n```", "```py\n>>> from transformers import VitsModel, VitsConfig\n\n>>> # Initializing a \"facebook/mms-tts-eng\" style configuration\n>>> configuration = VitsConfig()\n\n>>> # Initializing a model (with random weights) from the \"facebook/mms-tts-eng\" style configuration\n>>> model = VitsModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import VitsTokenizer, VitsModel, set_seed\n>>> import torch\n\n>>> tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n>>> model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n\n>>> inputs = tokenizer(text=\"Hello - my dog is cute\", return_tensors=\"pt\")\n\n>>> set_seed(555)  # make deterministic\n\n>>> with torch.no_grad():\n...     outputs = model(inputs[\"input_ids\"])\n>>> outputs.waveform.shape\ntorch.Size([1, 45824])\n```"]