- en: LXMERT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LXMERT
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/lxmert](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/lxmert)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/lxmert](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/lxmert)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The LXMERT model was proposed in [LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490) by Hao Tan & Mohit Bansal.
    It is a series of bidirectional transformer encoders (one for the vision modality,
    one for the language modality, and then one to fuse both modalities) pretrained
    using a combination of masked language modeling, visual-language text alignment,
    ROI-feature regression, masked visual-attribute modeling, masked visual-object
    modeling, and visual-question answering objectives. The pretraining consists of
    multiple multi-modal datasets: MSCOCO, Visual-Genome + Visual-Genome Question
    Answering, VQA 2.0, and GQA.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'LXMERT模型是由Hao Tan和Mohit Bansal在[LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490)中提出的。它是一系列双向Transformer编码器（一个用于视觉模态，一个用于语言模态，然后一个用于融合两种模态），使用一种组合的方法进行预训练，包括遮蔽语言建模、视觉-语言文本对齐、ROI特征回归、遮蔽视觉属性建模、遮蔽视觉对象建模和视觉问题回答目标。预训练包括多个多模态数据集：MSCOCO、Visual-Genome
    + Visual-Genome Question Answering、VQA 2.0和GQA。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要如下：
- en: '*Vision-and-language reasoning requires an understanding of visual concepts,
    language semantics, and, most importantly, the alignment and relationships between
    these two modalities. We thus propose the LXMERT (Learning Cross-Modality Encoder
    Representations from Transformers) framework to learn these vision-and-language
    connections. In LXMERT, we build a large-scale Transformer model that consists
    of three encoders: an object relationship encoder, a language encoder, and a cross-modality
    encoder. Next, to endow our model with the capability of connecting vision and
    language semantics, we pre-train the model with large amounts of image-and-sentence
    pairs, via five diverse representative pretraining tasks: masked language modeling,
    masked object prediction (feature regression and label classification), cross-modality
    matching, and image question answering. These tasks help in learning both intra-modality
    and cross-modality relationships. After fine-tuning from our pretrained parameters,
    our model achieves the state-of-the-art results on two visual question answering
    datasets (i.e., VQA and GQA). We also show the generalizability of our pretrained
    cross-modality model by adapting it to a challenging visual-reasoning task, NLVR,
    and improve the previous best result by 22% absolute (54% to 76%). Lastly, we
    demonstrate detailed ablation studies to prove that both our novel model components
    and pretraining strategies significantly contribute to our strong results; and
    also present several attention visualizations for the different encoders*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*视觉与语言推理需要理解视觉概念、语言语义，最重要的是理解这两种模态之间的对齐和关系。因此，我们提出了LXMERT（Learning Cross-Modality
    Encoder Representations from Transformers）框架来学习这些视觉与语言的连接。在LXMERT中，我们构建了一个大规模的Transformer模型，包括三个编码器：对象关系编码器、语言编码器和跨模态编码器。接下来，为了赋予我们的模型连接视觉和语言语义的能力，我们使用大量的图像和句子对进行预训练，通过五种不同的代表性预训练任务：遮蔽语言建模、遮蔽对象预测（特征回归和标签分类）、跨模态匹配和图像问题回答。这些任务有助于学习模态内部和模态间的关系。在从我们的预训练参数微调后，我们的模型在两个视觉问题回答数据集（即VQA和GQA）上取得了最先进的结果。我们还展示了我们预训练的跨模态模型的泛化能力，通过将其适应具有挑战性的视觉推理任务NLVR，将先前的最佳结果提高了22%绝对值（从54%到76%）。最后，我们进行了详细的消融研究，证明了我们的新颖模型组件和预训练策略对我们强大结果的显著贡献；并展示了不同编码器的几个注意力可视化*'
- en: This model was contributed by [eltoto1219](https://huggingface.co/eltoto1219).
    The original code can be found [here](https://github.com/airsplay/lxmert).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[eltoto1219](https://huggingface.co/eltoto1219)贡献。原始代码可在[此处](https://github.com/airsplay/lxmert)找到。
- en: Usage tips
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: Bounding boxes are not necessary to be used in the visual feature embeddings,
    any kind of visual-spacial features will work.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在视觉特征嵌入中不必使用边界框，任何类型的视觉空间特征都可以使用。
- en: Both the language hidden states and the visual hidden states that LXMERT outputs
    are passed through the cross-modality layer, so they contain information from
    both modalities. To access a modality that only attends to itself, select the
    vision/language hidden states from the first input in the tuple.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LXMERT输出的语言隐藏状态和视觉隐藏状态都经过了跨模态层，因此它们包含来自两种模态的信息。要访问仅关注自身的模态，请从元组中的第一个输入中选择视觉/语言隐藏状态。
- en: The bidirectional cross-modality encoder attention only returns attention values
    when the language modality is used as the input and the vision modality is used
    as the context vector. Further, while the cross-modality encoder contains self-attention
    for each respective modality and cross-attention, only the cross attention is
    returned and both self attention outputs are disregarded.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双向跨模态编码器注意力仅在语言模态用作输入且视觉模态用作上下文向量时返回注意力值。此外，虽然跨模态编码器包含每个相应模态的自注意力和交叉注意力，但只返回交叉注意力，两个自注意力输出都被忽略。
- en: Resources
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: '[Question answering task guide](../tasks/question_answering)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[问答任务指南](../tasks/question_answering)'
- en: LxmertConfig
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LxmertConfig
- en: '### `class transformers.LxmertConfig`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LxmertConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/configuration_lxmert.py#L29)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/configuration_lxmert.py#L29)'
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 30522) — Vocabulary size of the
    LXMERT model. Defines the number of different tokens that can be represented by
    the `inputs_ids` passed when calling [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    or [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, defaults to 30522) — LXMERT 模型的词汇表大小。定义了在调用
    [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    或 [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)
    时可以由 `inputs_ids` 表示的不同标记数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 768) — 编码器层和池化器层的维度。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Transformer 编码器中每个注意力层的注意力头数量。'
- en: '`num_qa_labels` (`int`, *optional*, defaults to 9500) — This represents the
    total number of different question answering (QA) labels there are. If using more
    than one dataset with QA, the user will need to account for the total number of
    labels that all of the datasets have in total.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_qa_labels` (`int`, *optional*, defaults to 9500) — 这表示不同的问题回答（QA）标签的总数。如果使用多个具有
    QA 的数据集，用户需要考虑所有数据集总共拥有的标签数量。'
- en: '`num_object_labels` (`int`, *optional*, defaults to 1600) — This represents
    the total number of semantically unique objects that lxmert will be able to classify
    a pooled-object feature as belonging too.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_object_labels` (`int`, *optional*, defaults to 1600) — 这表示 LXMERT 将能够将池化对象特征分类为所属的语义唯一对象的总数。'
- en: '`num_attr_labels` (`int`, *optional*, defaults to 400) — This represents the
    total number of semantically unique attributes that lxmert will be able to classify
    a pooled-object feature as possessing.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attr_labels` (`int`, *optional*, defaults to 400) — 这表示 LXMERT 将能够将池化对象特征分类为具有的语义唯一属性的总数。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimensionality
    of the “intermediate” (often named feed-forward) layer in the Transformer encoder.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Transformer 编码器中“中间”（通常称为前馈）层的维度。'
- en: '`hidden_act` (`str` or `Callable`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `Callable`, *optional*, defaults to `"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持
    `"gelu"`, `"relu"`, `"silu"` 和 `"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probability for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — 嵌入层、编码器和池化器中所有全连接层的丢失概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — The
    dropout ratio for the attention probabilities.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — 注意力概率的丢失比率。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — 该模型可能会与的最大序列长度。通常将其设置为较大的值以防万一（例如，512、1024
    或 2048）。'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) — The vocabulary size
    of the *token_type_ids* passed into [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size` (`int`, *optional*, defaults to 2) — 传递给 [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel)
    的 *token_type_ids* 的词汇表大小。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — 层归一化层使用的 epsilon。'
- en: '`l_layers` (`int`, *optional*, defaults to 9) — Number of hidden layers in
    the Transformer language encoder.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`l_layers` (`int`, *optional*, defaults to 9) — Transformer 语言编码器中的隐藏层数量。'
- en: '`x_layers` (`int`, *optional*, defaults to 5) — Number of hidden layers in
    the Transformer cross modality encoder.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_layers` (`int`, *optional*, defaults to 5) — Transformer 跨模态编码器中的隐藏层数量。'
- en: '`r_layers` (`int`, *optional*, defaults to 5) — Number of hidden layers in
    the Transformer visual encoder.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`r_layers` (`int`, *optional*, defaults to 5) — Transformer 视觉编码器中的隐藏层数量。'
- en: '`visual_feat_dim` (`int`, *optional*, defaults to 2048) — This represents the
    last dimension of the pooled-object features used as input for the model, representing
    the size of each object feature itself.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_feat_dim` (`int`, *optional*, defaults to 2048) — 这表示用作模型输入的池化对象特征的最后维度，表示每个对象特征本身的大小。'
- en: '`visual_pos_dim` (`int`, *optional*, defaults to 4) — This represents the number
    of spacial features that are mixed into the visual features. The default is set
    to 4 because most commonly this will represent the location of a bounding box.
    i.e., (x, y, width, height)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_pos_dim` (`int`, *optional*, defaults to 4) — 这表示混合到视觉特征中的空间特征的数量。默认设置为
    4，因为通常这将表示边界框的位置。即 (x, y, 宽度, 高度)'
- en: '`visual_loss_normalizer` (`float`, *optional*, defaults to 6.67) — This represents
    the scaling factor in which each visual loss is multiplied by if during pretraining,
    one decided to train with multiple vision-based loss objectives.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_loss_normalizer` (`float`, *optional*, defaults to 6.67) — 这表示如果在预训练期间决定使用多个基于视觉的损失目标进行训练，则每个视觉损失将乘以的缩放因子。'
- en: '`task_matched` (`bool`, *optional*, defaults to `True`) — This task is used
    for sentence-image matching. If the sentence correctly describes the image the
    label will be 1\. If the sentence does not correctly describe the image, the label
    will be 0.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task_matched` (`bool`, *optional*, defaults to `True`) — 该任务用于句子-图像匹配。如果句子正确描述图像，则标签为
    1。如果句子未正确描述图像，则标签为 0。'
- en: '`task_mask_lm` (`bool`, *optional*, defaults to `True`) — Whether or not to
    add masked language modeling (as used in pretraining models such as BERT) to the
    loss objective.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task_mask_lm` (`bool`, *optional*, defaults to `True`) — 是否添加掩码语言建模（如BERT中使用的）到损失目标中。'
- en: '`task_obj_predict` (`bool`, *optional*, defaults to `True`) — Whether or not
    to add object prediction, attribute prediction and feature regression to the loss
    objective.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task_obj_predict` (`bool`, *optional*, defaults to `True`) — 是否添加对象预测、属性预测和特征回归到损失目标中。'
- en: '`task_qa` (`bool`, *optional*, defaults to `True`) — Whether or not to add
    the question-answering loss to the objective'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task_qa` (`bool`, *optional*, defaults to `True`) — 是否将问答损失添加到目标中。'
- en: '`visual_obj_loss` (`bool`, *optional*, defaults to `True`) — Whether or not
    to calculate the object-prediction loss objective'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_obj_loss` (`bool`, *optional*, defaults to `True`) — 是否计算对象预测损失目标'
- en: '`visual_attr_loss` (`bool`, *optional*, defaults to `True`) — Whether or not
    to calculate the attribute-prediction loss objective'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attr_loss` (`bool`, *optional*, defaults to `True`) — 是否计算属性预测损失目标'
- en: '`visual_feat_loss` (`bool`, *optional*, defaults to `True`) — Whether or not
    to calculate the feature-regression loss objective'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_feat_loss` (`bool`, *optional*, defaults to `True`) — 是否计算特征回归损失目标'
- en: This is the configuration class to store the configuration of a [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    or a [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel).
    It is used to instantiate a LXMERT model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the Lxmert [unc-nlp/lxmert-base-uncased](https://huggingface.co/unc-nlp/lxmert-base-uncased)
    architecture.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)或[TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)配置的配置类。它用于根据指定的参数实例化一个LXMERT模型，定义模型架构。使用默认值实例化配置将产生与Lxmert
    [unc-nlp/lxmert-base-uncased](https://huggingface.co/unc-nlp/lxmert-base-uncased)架构类似的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: LxmertTokenizer
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LxmertTokenizer
- en: '### `class transformers.LxmertTokenizer`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LxmertTokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L67)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L67)'
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — File containing the vocabulary.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 包含词汇表的文件。'
- en: '`do_lower_case` (`bool`, *optional*, defaults to `True`) — Whether or not to
    lowercase the input when tokenizing.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_lower_case` (`bool`, *optional*, defaults to `True`) — 在标记化时是否将输入转换为小写。'
- en: '`do_basic_tokenize` (`bool`, *optional*, defaults to `True`) — Whether or not
    to do basic tokenization before WordPiece.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_basic_tokenize` (`bool`, *optional*, defaults to `True`) — 在WordPiece之前是否进行基本标记化。'
- en: '`never_split` (`Iterable`, *optional*) — Collection of tokens which will never
    be split during tokenization. Only has an effect when `do_basic_tokenize=True`'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`never_split` (`Iterable`, *optional*) — 在标记化期间永远不会拆分的标记集合。仅在`do_basic_tokenize=True`时有效。'
- en: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) — 未知标记。词汇表中不存在的标记无法转换为ID，而是设置为此标记。'
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — 分隔符标记，用于从多个序列构建序列，例如用于序列分类的两个序列或用于文本和问题的问题回答。它还用作使用特殊标记构建的序列的最后一个标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) — 用于填充的标记，例如在批处理不同长度的序列时使用。'
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — 用于进行序列分类（对整个序列进行分类而不是对每个标记进行分类）时使用的分类器标记。它是使用特殊标记构建的序列的第一个标记。'
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — 用于屏蔽值的标记。这是在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。'
- en: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) — Whether
    or not to tokenize Chinese characters.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) — 是否对中文字符进行标记化。'
- en: This should likely be deactivated for Japanese (see this [issue](https://github.com/huggingface/transformers/issues/328)).
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可能应该在日语中停用（请参阅此[问题](https://github.com/huggingface/transformers/issues/328)）。
- en: '`strip_accents` (`bool`, *optional*) — Whether or not to strip all accents.
    If this option is not specified, then it will be determined by the value for `lowercase`
    (as in the original Lxmert).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strip_accents` (`bool`, *optional*) — 是否去除所有重音符号。如果未指定此选项，则将由`lowercase`的值确定（与原始Lxmert中相同）。'
- en: Construct a Lxmert tokenizer. Based on WordPiece.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个Lxmert标记器。基于WordPiece。
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此标记器继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L200)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L200)'
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs to which the special tokens will
    be added.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) — 将添加特殊标记的ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *可选*) — 第二个序列对的可选ID列表。'
- en: Returns
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '`List[int]`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 带有适当特殊标记的[输入ID](../glossary#input-ids)列表。
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. A Lxmert sequence has the following
    format:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过连接和添加特殊标记构建用于序列分类任务的序列或序列对的模型输入。Lxmert序列的格式如下：
- en: 'single sequence: `[CLS] X [SEP]`'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个序列：`[CLS] X [SEP]`
- en: 'pair of sequences: `[CLS] A [SEP] B [SEP]`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列对：`[CLS] A [SEP] B [SEP]`
- en: '#### `convert_tokens_to_string`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`convert_tokens_to_string`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L195)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L195)'
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Converts a sequence of tokens (string) in a single string.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将一系列标记（字符串）转换为单个字符串。
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L253)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L253)'
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) — ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *可选*) — 第二个序列对的可选ID列表。'
- en: Returns
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '`List[int]`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [token type IDs](../glossary#token-type-ids) according to the given
    sequence(s).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 根据给定序列的[标记类型ID](../glossary#token-type-ids)列表。
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. A Lxmert sequence
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 从传递的两个序列创建用于序列对分类任务的掩码。一个Lxmert序列
- en: 'pair mask has the following format:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 序列对掩码的格式如下：
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If `token_ids_1` is `None`, this method only returns the first portion of the
    mask (0s).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`token_ids_1`为`None`，则此方法仅返回掩码的第一部分（0）。
- en: '#### `get_special_tokens_mask`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_special_tokens_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L225)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert.py#L225)'
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) — ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *可选*) — 第二个序列对的可选ID列表。'
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`already_has_special_tokens` (`bool`, *可选*, 默认为 `False`) — 标记列表是否已经使用特殊标记格式化。'
- en: Returns
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '`List[int]`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一个整数列表，范围为[0, 1]：1表示特殊标记，0表示序列标记。
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 从没有添加特殊标记的标记列表中检索序列ID。在使用标记器的`prepare_for_model`方法添加特殊标记时调用此方法。
- en: LxmertTokenizerFast
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LxmertTokenizerFast
- en: '### `class transformers.LxmertTokenizerFast`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LxmertTokenizerFast`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert_fast.py#L48)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert_fast.py#L48)'
- en: '[PRE7]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — File containing the vocabulary.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 包含词汇表的文件。'
- en: '`do_lower_case` (`bool`, *optional*, defaults to `True`) — Whether or not to
    lowercase the input when tokenizing.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_lower_case` (`bool`, *可选*, 默认为 `True`) — 在标记化时是否将输入转换为小写。'
- en: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *可选*, 默认为 `"[UNK]"`) — 未知标记。词汇表中没有的标记无法转换为ID，而是设置为此标记。'
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str`, *可选*, 默认为 `"[SEP]"`) — 分隔符标记，在构建多个序列的序列时使用，例如用于序列分类的两个序列或用于文本和问题的问题回答。它也用作使用特殊标记构建的序列的最后一个标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *可选*, 默认为 `"[PAD]"`) — 用于填充的标记，例如在批处理不同长度的序列时使用。'
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str`, *可选*, 默认为 `"[CLS]"`) — 用于进行序列分类（对整个序列进行分类而不是每个标记的分类）时使用的分类器标记。当使用特殊标记构建序列时，它是序列的第一个标记。'
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str`, *可选*, 默认为 `"[MASK]"`) — 用于屏蔽值的标记。这是在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。'
- en: '`clean_text` (`bool`, *optional*, defaults to `True`) — Whether or not to clean
    the text before tokenization by removing any control characters and replacing
    all whitespaces by the classic one.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_text` (`bool`, *可选*, 默认为 `True`) — 是否在分词之前清理文本，通过删除所有控制字符并将所有空格替换为经典空格。'
- en: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) — Whether
    or not to tokenize Chinese characters. This should likely be deactivated for Japanese
    (see [this issue](https://github.com/huggingface/transformers/issues/328)).'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenize_chinese_chars` (`bool`, *可选*, 默认为 `True`) — 是否对中文字符进行分词。这可能应该在日语中停用（参见[此问题](https://github.com/huggingface/transformers/issues/328)）。'
- en: '`strip_accents` (`bool`, *optional*) — Whether or not to strip all accents.
    If this option is not specified, then it will be determined by the value for `lowercase`
    (as in the original Lxmert).'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strip_accents` (`bool`, *可选*) — 是否去除所有重音符号。如果未指定此选项，则将由`lowercase`的值确定（与原始Lxmert中一样）。'
- en: '`wordpieces_prefix` (`str`, *optional*, defaults to `"##"`) — The prefix for
    subwords.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wordpieces_prefix` (`str`, *可选*, 默认为 `"##"`) — 用于子词的前缀。'
- en: Construct a “fast” Lxmert tokenizer (backed by HuggingFace’s *tokenizers* library).
    Based on WordPiece.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个“快速”Lxmert 分词器（由HuggingFace的 *tokenizers* 库支持）。基于 WordPiece。
- en: This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分词器继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)，其中包含大部分主要方法。用户应该参考这个超类以获取有关这些方法的更多信息。
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert_fast.py#L136)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert_fast.py#L136)'
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs to which the special tokens will
    be added.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) — 将添加特殊标记的ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`，*可选*) — 序列对的可选第二个ID列表。'
- en: Returns
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 带有适当特殊标记的[输入ID](../glossary#input-ids)列表。
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. A Lxmert sequence has the following
    format:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 通过连接和添加特殊标记，为序列分类任务从序列或序列对构建模型输入。一个 Lxmert 序列的格式如下：
- en: 'single sequence: `[CLS] X [SEP]`'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个序列：`[CLS] X [SEP]`
- en: 'pair of sequences: `[CLS] A [SEP] B [SEP]`'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列对：`[CLS] A [SEP] B [SEP]`
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert_fast.py#L160)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/tokenization_lxmert_fast.py#L160)'
- en: '[PRE9]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) — ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`，*可选*) — 序列对的可选第二个ID列表。'
- en: Returns
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [token type IDs](../glossary#token-type-ids) according to the given
    sequence(s).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 根据给定序列的[标记类型ID](../glossary#token-type-ids)列表。
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. A Lxmert sequence
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 从传递的两个序列创建一个用于序列对分类任务的掩码。一个 Lxmert 序列
- en: 'pair mask has the following format:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 序列掩码的格式如下：
- en: '[PRE10]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If `token_ids_1` is `None`, this method only returns the first portion of the
    mask (0s).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`token_ids_1`为`None`，则此方法仅返回掩码的第一部分（0）。
- en: Lxmert specific outputs
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lxmert 特定输出
- en: '### `class transformers.models.lxmert.modeling_lxmert.LxmertModelOutput`'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.models.lxmert.modeling_lxmert.LxmertModelOutput`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L59)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L59)'
- en: '[PRE11]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`language_output` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the language encoder.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_output` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, hidden_size)`)
    — 语言编码器最后一层的隐藏状态序列。'
- en: '`vision_output` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the visual encoder.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_output` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, hidden_size)`)
    — 视觉编码器最后一层的隐藏状态序列。'
- en: '`pooled_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state of the first token of the sequence (classification,
    CLS, token) further processed by a Linear layer and a Tanh activation function.
    The Linear'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_output` (`torch.FloatTensor`，形状为 `(batch_size, hidden_size)`) — 序列第一个标记（分类，CLS，标记）的最后一层隐藏状态，进一步通过线性层和
    Tanh 激活函数处理。线性'
- en: '`language_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为 `(batch_size, sequence_length, hidden_size)` 的`torch.FloatTensor`元组（一个用于输入特征
    + 一个用于每个跨模态层的输出）。'
- en: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当`output_hidden_states=True`被传递或者`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于输入特征，一个用于每个跨模态层的输出）。'
- en: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当`output_attentions=True`被传递或者`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个层一个）。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`vision_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当`output_attentions=True`被传递或者`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个层一个）。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`cross_encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_attentions=True` is passed or when `config.output_attentions=True`)
    — Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当`output_attentions=True`被传递或者`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个层一个）。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: 'Lxmert’s outputs that contain the last hidden states, pooled outputs, and attention
    probabilities for the language, visual, and, cross-modality encoders. (note: the
    visual encoder in Lxmert is referred to as the “relation-ship” encoder”)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Lxmert的输出包含语言、视觉和跨模态编码器的最后隐藏状态、汇总输出和注意力概率。（注意：在Lxmert中，视觉编码器被称为“关系-ship”编码器）
- en: '### `class transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L145)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L145)'
- en: '[PRE12]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`loss` (*optional*, returned when `labels` is provided, `torch.FloatTensor`
    of shape `(1,)`) — Total loss as the sum of the masked language modeling loss
    and the next sequence prediction (classification) loss.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (*optional*, 当提供`labels`时返回，形状为`(1,)`的`torch.FloatTensor`) — 总损失，作为掩码语言建模损失和下一个序列预测（分类）损失的总和。'
- en: '`prediction_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    config.vocab_size)`) — Prediction scores of the language modeling head (scores
    for each vocabulary token before SoftMax).'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    config.vocab_size)`) — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`cross_relationship_score` (`torch.FloatTensor` of shape `(batch_size, 2)`)
    — Prediction scores of the textual matching objective (classification) head (scores
    of True/False continuation before SoftMax).'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_relationship_score` (`torch.FloatTensor`，形状为`(batch_size, 2)`) — 文本匹配目标（分类）头的预测分数（SoftMax之前的True/False继续分数）。'
- en: '`question_answering_score` (`torch.FloatTensor` of shape `(batch_size, n_qa_answers)`)
    — Prediction scores of question answering objective (classification).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question_answering_score` (`torch.FloatTensor`，形状为`(batch_size, n_qa_answers)`)
    — 问答目标（分类）的预测分数。'
- en: '`language_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当`output_hidden_states=True`被传递或者`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于输入特征，一个用于每个跨模态层的输出）。'
- en: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当`output_hidden_states=True`被传递或者`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于输入特征，一个用于每个跨模态层的输出）。'
- en: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当`output_attentions=True`被传递或者`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每个层一个）。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`vision_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`cross_encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_attentions=True` is passed or when `config.output_attentions=True`)
    — Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: Output type of [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)的输出类型。'
- en: '### `class transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput`'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L105)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L105)'
- en: '[PRE13]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`loss` (*optional*, returned when `labels` is provided, `torch.FloatTensor`
    of shape `(1,)`) — Total loss as the sum of the masked language modeling loss
    and the next sequence prediction (classification) loss.k.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（*可选*，当提供`labels`时返回，形状为`(1,)`的`torch.FloatTensor`）— 总损失，作为掩码语言建模损失和下一个序列预测（分类）损失的总和。'
- en: '`question_answering_score` (`torch.FloatTensor` of shape `(batch_size, n_qa_answers)`,
    *optional*) — Prediction scores of question answering objective (classification).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question_answering_score`（形状为`(batch_size, n_qa_answers)`的`torch.FloatTensor`，*可选*）—
    问题回答目标（分类）的预测分数。'
- en: '`language_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`vision_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`cross_encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_attentions=True` is passed or when `config.output_attentions=True`)
    — Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: Output type of [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering)的输出类型。'
- en: '### `class transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L60)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L60)'
- en: '[PRE14]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`language_output` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    — Sequence of hidden-states at the output of the last layer of the language encoder.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_output`（形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`）—
    语言编码器最后一层的隐藏状态序列。'
- en: '`vision_output` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    — Sequence of hidden-states at the output of the last layer of the visual encoder.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_output` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    — 视觉编码器最后一层的隐藏状态序列。'
- en: '`pooled_output` (`tf.Tensor` of shape `(batch_size, hidden_size)`) — Last layer
    hidden-state of the first token of the sequence (classification, CLS, token) further
    processed by a Linear layer and a Tanh activation function. The Linear'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_output` (`tf.Tensor` of shape `(batch_size, hidden_size)`) — 序列第一个标记的最后一层隐藏状态（分类，CLS，标记），经过线性层和Tanh激活函数进一步处理的隐藏状态。'
- en: '`language_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for input features + one for the output of each cross-modality layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于输入特征 + 一个用于每个跨模态层的输出）。'
- en: '`vision_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for input features + one for the output of each cross-modality layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于输入特征 + 一个用于每个跨模态层的输出）。'
- en: '`language_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`vision_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`cross_encoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions` (`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: 'Lxmert’s outputs that contain the last hidden states, pooled outputs, and attention
    probabilities for the language, visual, and, cross-modality encoders. (note: the
    visual encoder in Lxmert is referred to as the “relation-ship” encoder”)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Lxmert的输出包含语言、视觉和跨模态编码器的最后隐藏状态、汇聚输出和注意力概率。（注意：在Lxmert中，视觉编码器被称为“关系-ship”编码器）
- en: '### `class transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput`'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L106)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L106)'
- en: '[PRE15]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`loss` (*optional*, returned when `labels` is provided, `tf.Tensor` of shape
    `(1,)`) — Total loss as the sum of the masked language modeling loss and the next
    sequence prediction (classification) loss.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（*可选*，在提供`labels`时返回，`tf.Tensor` of shape `(1,)`） — 总损失，作为掩码语言建模损失和下一个序列预测（分类）损失的总和。'
- en: '`prediction_logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`cross_relationship_score` (`tf.Tensor` of shape `(batch_size, 2)`) — Prediction
    scores of the textual matching objective (classification) head (scores of True/False
    continuation before SoftMax).'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_relationship_score` (`tf.Tensor` of shape `(batch_size, 2)`) — 文本匹配目标（分类）头的预测分数（SoftMax之前的True/False连续性分数）。'
- en: '`question_answering_score` (`tf.Tensor` of shape `(batch_size, n_qa_answers)`)
    — Prediction scores of question answering objective (classification).'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question_answering_score` (`tf.Tensor` of shape `(batch_size, n_qa_answers)`)
    — 问答目标（分类）的预测分数。'
- en: '`language_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for input features + one for the output of each cross-modality layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于输入特征 + 一个用于每个跨模态层的输出）。'
- en: '`vision_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for input features + one for the output of each cross-modality layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于输入特征 + 一个用于每个跨模态层的输出）。'
- en: '`language_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions` (`tuple(tf.Tensor)`, *可选的*, 当传递`output_attentions=True`或者当`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。在自注意力头中用于计算加权平均值的注意力权重。'
- en: '`vision_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions` (`tuple(tf.Tensor)`, *可选的*, 当传递`output_attentions=True`或者当`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。在自注意力头中用于计算加权平均值的注意力权重。'
- en: '`cross_encoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions` (`tuple(tf.Tensor)`, *可选的*, 当传递`output_attentions=True`或者当`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。在自注意力头中用于计算加权平均值的注意力权重。'
- en: Output type of [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)的输出类型。'
- en: PytorchHide Pytorch content
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch内容
- en: LxmertModel
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LxmertModel
- en: '### `class transformers.LxmertModel`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LxmertModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L879)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L879)'
- en: '[PRE16]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare Lxmert Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Lxmert模型变换器输出原始隐藏状态，没有特定的头部。
- en: 'The LXMERT model was proposed in [LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490) by Hao Tan and Mohit Bansal.
    It’s a vision and language transformer model, pretrained on a variety of multi-modal
    datasets comprising of GQA, VQAv2.0, MSCOCO captions, and Visual genome, using
    a combination of masked language modeling, region of interest feature regression,
    cross entropy loss for question answering attribute prediction, and object tag
    prediction.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 'LXMERT模型是由Hao Tan和Mohit Bansal在[LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490)中提出的。这是一个视觉和语言变换器模型，预训练于包括GQA、VQAv2.0、MSCOCO标题和Visual
    genome在内的各种多模态数据集，使用掩码语言建模、感兴趣区域特征回归、交叉熵损失用于问题回答属性预测和对象标签预测。'
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有信息。
- en: '#### `forward`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L898)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L898)'
- en: '[PRE17]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`) — 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。查看[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)获取详细信息。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`visual_feats` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_feat_dim)`) — This input represents visual features. They ROI pooled object
    features from bounding boxes using a faster-RCNN model)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_feats` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_feat_dim)`) — 此输入表示视觉特征。它们是使用 faster-RCNN 模型从边界框中 ROI 池化的对象特征）'
- en: These are currently not provided by the transformers library.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前 transformers 库中没有提供这些。
- en: '`visual_pos` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_pos_dim)`) — This input represents spacial features corresponding to their
    relative (via index) visual features. The pre-trained LXMERT model expects these
    spacial features to be normalized bounding boxes on a scale of 0 to'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_pos` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_pos_dim)`) — 此输入表示与它们的相对（通过索引）视觉特征对应的空间特征。预训练的 LXMERT 模型期望这些空间特征是在 0 到'
- en: These are currently not provided by the transformers library.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前 transformers 库中没有提供这些。
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 避免在填充标记索引上执行注意力的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示未被屏蔽的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示被屏蔽的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 避免在填充标记索引上执行注意力的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示未被屏蔽的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示被屏蔽的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 段落标记索引，用于指示输入的第一部分和第二部分。索引在 `[0, 1]` 中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于 *句子 A* 标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型 ID？](../glossary#token-type-ids)'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将 `input_ids`
    索引转换为相关向量，这将很有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的
    `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回一个 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是一个普通的元组。'
- en: Returns
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.models.lxmert.modeling_lxmert.LxmertModelOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.models.lxmert.modeling_lxmert.LxmertModelOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertModelOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.models.lxmert.modeling_lxmert.LxmertModelOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    and inputs.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.models.lxmert.modeling_lxmert.LxmertModelOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertModelOutput)
    或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False`
    时）包含根据配置（[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)）和输入而异的各种元素。
- en: '`language_output` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the language encoder.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_output` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — 语言编码器最后一层的隐藏状态序列。'
- en: '`vision_output` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the visual encoder.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_output` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — 视觉编码器最后一层的隐藏状态序列。'
- en: '`pooled_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state of the first token of the sequence (classification,
    CLS, token) further processed by a Linear layer and a Tanh activation function.
    The Linear'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — 序列第一个标记（分类，CLS，标记）的最后一层隐藏状态，进一步由线性层和 Tanh 激活函数处理。线性'
- en: '`language_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于输入特征，一个用于每个交叉模态层的输出）。'
- en: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于输入特征，一个用于每个交叉模态层的输出）。'
- en: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。在自注意力头中用于计算加权平均值的注意力权重softmax后。'
- en: '`vision_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。在自注意力头中用于计算加权平均值的注意力权重softmax后。'
- en: '`cross_encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_attentions=True` is passed or when `config.output_attentions=True`)
    — Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。在自注意力头中用于计算加权平均值的注意力权重softmax后。'
- en: The [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    forward method, overrides the `__call__` special method.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '[LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE18]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: LxmertForPreTraining
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LxmertForPreTraining
- en: '### `class transformers.LxmertForPreTraining`'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LxmertForPreTraining`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L1017)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L1017)'
- en: '[PRE19]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: Lxmert Model with a specified pretraining head on top.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 具有指定预训练头的Lxmert模型。
- en: 'The LXMERT model was proposed in [LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490) by Hao Tan and Mohit Bansal.
    It’s a vision and language transformer model, pretrained on a variety of multi-modal
    datasets comprising of GQA, VQAv2.0, MSCOCO captions, and Visual genome, using
    a combination of masked language modeling, region of interest feature regression,
    cross entropy loss for question answering attribute prediction, and object tag
    prediction.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 'LXMERT模型是由Hao Tan和Mohit Bansal在[LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490)中提出的。它是一个视觉和语言变换器模型，预训练于包括GQA、VQAv2.0、MSCOCO标题和Visual
    genome在内的各种多模态数据集，使用掩码语言建模、感兴趣区域特征回归、交叉熵损失用于问题回答属性预测和对象标签预测的组合。'
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L1150)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L1150)'
- en: '[PRE20]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    输入序列标记在词汇表中的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参阅 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入 ID？](../glossary#input-ids)'
- en: '`visual_feats` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_feat_dim)`) — This input represents visual features. They ROI pooled object
    features from bounding boxes using a faster-RCNN model)'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_feats` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_feat_dim)`) — 这个输入表示视觉特征。它们是通过 faster-RCNN 模型从边界框中ROI池化的对象特征。'
- en: These are currently not provided by the transformers library.
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前这些由 transformers 库不提供。
- en: '`visual_pos` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_pos_dim)`) — This input represents spacial features corresponding to their
    relative (via index) visual features. The pre-trained LXMERT model expects these
    spacial features to be normalized bounding boxes on a scale of 0 to'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_pos` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_pos_dim)`) — 这个输入表示与它们的相对（通过索引）视觉特征对应的空间特征。预训练的 LXMERT 模型期望这些空间特征是在 0 到
    1 的范围内归一化的边界框。'
- en: These are currently not provided by the transformers library.
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前这些由 transformers 库不提供。
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *可选*) — 避免在填充标记索引上执行注意力的掩码。掩码值选择在 `[0, 1]`：'
- en: 1 for tokens that are `not masked`,
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 代表未被 `masked` 的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 代表被 `masked` 的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *可选*) — 避免在填充标记索引上执行注意力的掩码。掩码值选择在 `[0, 1]`：'
- en: 1 for tokens that are `not masked`,
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 代表未被 `masked` 的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 代表被 `masked` 的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *可选*) — 段标记索引，用于指示输入的第一部分和第二部分。索引选择在 `[0, 1]`：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于 *句子 A* 标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型 ID？](../glossary#token-type-ids)'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *可选*) — 可选地，您可以选择直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将 `input_ids`
    索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将很有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的 `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的 `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通的元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should be in
    `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-100` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *可选*)
    — 用于计算掩码语言建模损失的标签。索引应在 `[-100, 0, ..., config.vocab_size]`（参见 `input_ids` 文档字符串）。索引设置为
    `-100` 的标记将被忽略（被 `masked`），损失仅计算具有标签在 `[0, ..., config.vocab_size]` 中的标记。'
- en: '`obj_labels` (`Dict[Str -- Tuple[Torch.FloatTensor, Torch.FloatTensor]]`, *optional*):
    each key is named after each one of the visual losses and each element of the
    tuple is of the shape `(batch_size, num_features)` and `(batch_size, num_features,
    visual_feature_dim)` for each the label id and the label score respectively'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`obj_labels` (`Dict[Str -- Tuple[Torch.FloatTensor, Torch.FloatTensor]]`, *可选*):
    每个键以视觉损失中的每一个命名，元组的每个元素的形状分别为 `(batch_size, num_features)` 和 `(batch_size, num_features,
    visual_feature_dim)`，用于标签 ID 和标签分数'
- en: '`matched_label` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) —
    Labels for computing the whether or not the text input matches the image (classification)
    loss. Input should be a sequence pair (see `input_ids` docstring) Indices should
    be in `[0, 1]`:'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matched_label`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*） - 用于计算文本输入是否与图像匹配（分类）损失的标签。输入应为一个序列对（参见`input_ids`文档字符串）。索引应在`[0,
    1]`中：'
- en: 0 indicates that the sentence does not match the image,
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示句子与图像不匹配，
- en: 1 indicates that the sentence does match the image.
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示句子与图像匹配。
- en: '`ans` (`Torch.Tensor` of shape `(batch_size)`, *optional*) — a one hot representation
    hof the correct answer *optional*'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ans`（形状为`(batch_size)`的`Torch.Tensor`，*可选*） - 正确答案的独热表示*可选*'
- en: Returns
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    and inputs.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertForPreTrainingOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包括根据配置（[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)）和输入的不同元素。
- en: '`loss` (*optional*, returned when `labels` is provided, `torch.FloatTensor`
    of shape `(1,)`) — Total loss as the sum of the masked language modeling loss
    and the next sequence prediction (classification) loss.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（*可选*，当提供`labels`时返回，形状为`(1,)`的`torch.FloatTensor`） - 作为掩码语言建模损失和下一个序列预测（分类）损失之和的总损失。'
- en: '`prediction_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    config.vocab_size)`) — Prediction scores of the language modeling head (scores
    for each vocabulary token before SoftMax).'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`torch.FloatTensor`）
    - 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`cross_relationship_score` (`torch.FloatTensor` of shape `(batch_size, 2)`)
    — Prediction scores of the textual matching objective (classification) head (scores
    of True/False continuation before SoftMax).'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_relationship_score`（形状为`(batch_size, 2)`的`torch.FloatTensor`） - 文本匹配目标（分类）头的预测分数（SoftMax之前的True/False继续分数）。'
- en: '`question_answering_score` (`torch.FloatTensor` of shape `(batch_size, n_qa_answers)`)
    — Prediction scores of question answering objective (classification).'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question_answering_score`（形状为`(batch_size, n_qa_answers)`的`torch.FloatTensor`）
    - 问题回答目标（分类）的预测分数。'
- en: '`language_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    - 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于输入特征+一个用于每个跨模态层的输出）。'
- en: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    - 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于输入特征+一个用于每个跨模态层的输出）。'
- en: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    - 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`vision_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    - 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`cross_encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_attentions=True` is passed or when `config.output_attentions=True`)
    — Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    - 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: The [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)
    forward method, overrides the `__call__` special method.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '[LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)的前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: LxmertForQuestionAnswering
  id: totrans-327
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LxmertForQuestionAnswering
- en: '### `class transformers.LxmertForQuestionAnswering`'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LxmertForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L1285)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L1285)'
- en: '[PRE21]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig））—模型配置类，包含模型的所有参数。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: Lxmert Model with a visual-answering head on top for downstream QA tasks
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 带有视觉回答头的Lxmert模型，用于下游QA任务
- en: 'The LXMERT model was proposed in [LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490) by Hao Tan and Mohit Bansal.
    It’s a vision and language transformer model, pretrained on a variety of multi-modal
    datasets comprising of GQA, VQAv2.0, MSCOCO captions, and Visual genome, using
    a combination of masked language modeling, region of interest feature regression,
    cross entropy loss for question answering attribute prediction, and object tag
    prediction.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 'LXMERT模型是由Hao Tan和Mohit Bansal在[LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490)中提出的。这是一个视觉和语言变换器模型，预训练于各种多模态数据集，包括GQA、VQAv2.0、MSCOCO字幕和Visual
    genome，使用掩码语言建模、感兴趣区域特征回归、交叉熵损失用于问题回答属性预测和对象标签预测的组合。'
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档，了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有信息。
- en: '#### `forward`'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L1381)'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_lxmert.py#L1381)'
- en: '[PRE22]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）—输入序列标记在词汇表中的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`visual_feats` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_feat_dim)`) — This input represents visual features. They ROI pooled object
    features from bounding boxes using a faster-RCNN model)'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_feats`（形状为`(batch_size, num_visual_features, visual_feat_dim)`的`torch.FloatTensor`）—这个输入表示视觉特征。它们是使用faster-RCNN模型从边界框中ROI池化的对象特征）'
- en: These are currently not provided by the transformers library.
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些目前不是由transformers库提供的。
- en: '`visual_pos` (`torch.FloatTensor` of shape `(batch_size, num_visual_features,
    visual_pos_dim)`) — This input represents spacial features corresponding to their
    relative (via index) visual features. The pre-trained LXMERT model expects these
    spacial features to be normalized bounding boxes on a scale of 0 to'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_pos`（形状为`(batch_size, num_visual_features, visual_pos_dim)`的`torch.FloatTensor`）—这个输入表示与它们的相对（通过索引）视觉特征对应的空间特征。预训练的LXMERT模型期望这些空间特征是在0到1的范围内的归一化边界框'
- en: These are currently not provided by the transformers library.
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些目前不是由transformers库提供的。
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）—避免在填充标记索引上执行注意力的掩码。选择的掩码值在`[0,
    1]`范围内：'
- en: 1 for tokens that are `not masked`,
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示“未屏蔽”的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示“屏蔽”的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`visual_attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`，*可选*）—避免在填充标记索引上执行注意力的掩码。选择的掩码值在`[0,
    1]`范围内：'
- en: 1 for tokens that are `not masked`,
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示“未屏蔽”的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对于被 `masked` 的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 段落标记索引，用于指示输入的第一部分和第二部分。索引在 `[0, 1]` 中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-357
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应 *句子 A* 标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-358
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应 *句子 B* 标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型 ID？](../glossary#token-type-ids)'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，可以直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将 `input_ids`
    索引转换为相关向量，这将非常有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的
    `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: '`labels` (`Torch.Tensor` of shape `(batch_size)`, *optional*) — A one-hot representation
    of the correct answer'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`Torch.Tensor` of shape `(batch_size)`, *optional*) — 正确答案的独热表示'
- en: Returns
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    and inputs.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_lxmert.LxmertForQuestionAnsweringOutput)
    或一个 `torch.FloatTensor` 元组（如果传递 `return_dict=False` 或 `config.return_dict=False`）包含根据配置（[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)）和输入的不同元素。
- en: '`loss` (*optional*, returned when `labels` is provided, `torch.FloatTensor`
    of shape `(1,)`) — Total loss as the sum of the masked language modeling loss
    and the next sequence prediction (classification) loss.k.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (*optional*, 当提供 `labels` 时返回，形状为 `(1,)` 的 `torch.FloatTensor`) — 作为掩码语言建模损失和下一个序列预测（分类）损失之和的总损失。'
- en: '`question_answering_score` (`torch.FloatTensor` of shape `(batch_size, n_qa_answers)`,
    *optional*) — Prediction scores of question answering objective (classification).'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question_answering_score` (`torch.FloatTensor` of shape `(batch_size, n_qa_answers)`,
    *optional*) — 问题回答目标（分类）的预测分数。'
- en: '`language_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递 `output_hidden_states=True`
    或 `config.output_hidden_states=True` 时返回) — 形状为 `(batch_size, sequence_length,
    hidden_size)` 的 `torch.FloatTensor` 元组（一个用于输入特征 + 一个用于每个跨模态层的输出）。'
- en: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for input features + one for the output of
    each cross-modality layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递 `output_hidden_states=True`
    或 `config.output_hidden_states=True` 时返回) — 形状为 `(batch_size, sequence_length,
    hidden_size)` 的 `torch.FloatTensor` 元组（一个用于输入特征 + 一个用于每个跨模态层的输出）。'
- en: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递 `output_attentions=True`
    或 `config.output_attentions=True` 时返回) — 形状为 `(batch_size, num_heads, sequence_length,
    sequence_length)` 的 `torch.FloatTensor` 元组（每个层一个）。注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`vision_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递 `output_attentions=True`
    或 `config.output_attentions=True` 时返回) — 形状为 `(batch_size, num_heads, sequence_length,
    sequence_length)` 的 `torch.FloatTensor` 元组（每个层一个）。注意力 softmax 后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`cross_encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_attentions=True` is passed or when `config.output_attentions=True`)
    — Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`. Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    - 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: The [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '[LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 例子：
- en: '[PRE23]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: TensorFlowHide TensorFlow content
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏TensorFlow内容
- en: TFLxmertModel
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFLxmertModel
- en: '### `class transformers.TFLxmertModel`'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFLxmertModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L1093)'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L1093)'
- en: '[PRE24]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)）
    - 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare Lxmert Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Lxmert模型变换器，输出原始隐藏状态而没有特定的头部。
- en: 'The LXMERT model was proposed in [LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490) by Hao Tan and Mohit Bansal.
    It’s a vision and language transformer model, pre-trained on a variety of multi-modal
    datasets comprising of GQA, VQAv2.0, MCSCOCO captions, and Visual genome, using
    a combination of masked language modeling, region of interest feature regression,
    cross entropy loss for question answering attribute prediction, and object tag
    prediction.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 'LXMERT模型是由Hao Tan和Mohit Bansal在[LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490)中提出的。这是一个视觉和语言变换器模型，预训练于各种多模态数据集，包括GQA、VQAv2.0、MCSCOCO字幕和Visual
    genome，使用掩码语言建模、感兴趣区域特征回归、交叉熵损失用于问题回答属性预测和对象标签预测。'
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)子类。将其用作常规的TF
    2.0 Keras模型，并参考TF 2.0文档以获取与一般用法和行为相关的所有信息。
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers`中的TensorFlow模型和层接受两种格式的输入：'
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有输入作为关键字参数（类似于PyTorch模型），或者
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有输入作为列表、元组或字典放在第一个位置参数中。
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should “just work” for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 支持第二种格式的原因是，当将输入传递给模型和层时，Keras方法更喜欢这种格式。由于有了这种支持，当使用`model.fit()`等方法时，应该可以正常工作
    - 只需以`model.fit()`支持的任何格式传递输入和标签即可！但是，如果您想在Keras方法之外使用第二种格式，比如在使用Keras`Functional`API创建自己的层或模型时，有三种可能性可以用来收集所有输入张量放在第一个位置参数中：
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个只包含`input_ids`的单个张量，没有其他内容：`model(input_ids)`
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个长度不定的列表，其中包含一个或多个按照文档字符串中给定顺序的输入张量：`model([input_ids, attention_mask])`或`model([input_ids,
    attention_mask, token_type_ids])`
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '一个与文档字符串中给定的输入名称相关联的包含一个或多个输入张量的字典：`model({"input_ids": input_ids, "token_type_ids":
    token_type_ids})`'
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you don’t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当使用[子类化](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)创建模型和层时，您无需担心这些问题，因为您可以像对待任何其他Python函数一样传递输入！
- en: '#### `call`'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L1102)'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L1102)'
- en: '[PRE25]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`np.ndarray` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`np.ndarray` 或 `tf.Tensor`，形状为 `(batch_size, sequence_length)`)
    — 输入序列标记在词汇表中的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参见 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    和 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是输入ID？
- en: '`visual_feats` (`tf.Tensor` of shape `(batch_size, num_visual_features, visual_feat_dim)`)
    — This input represents visual features. They ROI pooled object features from
    bounding boxes using a faster-RCNN model)'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_feats` (`tf.Tensor`，形状为 `(batch_size, num_visual_features, visual_feat_dim)`)
    — 此输入表示视觉特征。它们是使用 faster-RCNN 模型从边界框中 ROI 池化的对象特征。'
- en: These are currently not provided by the transformers library.
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些目前不由 transformers 库提供。
- en: '`visual_pos` (`tf.Tensor` of shape `(batch_size, num_visual_features, visual_feat_dim)`)
    — This input represents spacial features corresponding to their relative (via
    index) visual features. The pre-trained LXMERT model expects these spacial features
    to be normalized bounding boxes on a scale of 0 to'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_pos` (`tf.Tensor`，形状为 `(batch_size, num_visual_features, visual_feat_dim)`)
    — 此输入表示与它们的相对（通过索引）视觉特征对应的空间特征。预训练的 LXMERT 模型期望这些空间特征是在 0 到 之间的归一化边界框'
- en: These are currently not provided by the transformers library.
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些目前不由 transformers 库提供。
- en: '`attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`tf.Tensor`，形状为 `(batch_size, sequence_length)`，*可选*) — 避免在填充标记索引上执行注意力的掩码。掩码值选在
    `[0, 1]`：'
- en: 1 for tokens that are `not masked`,
  id: totrans-409
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 用于未被掩码的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 用于被掩码的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是注意力掩码？
- en: '`visual_attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — MMask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask` (`tf.Tensor`，形状为 `(batch_size, sequence_length)`，*可选*)
    — 避免在填充标记索引上执行注意力的掩码。掩码值选在 `[0, 1]`：'
- en: 1 for tokens that are `not masked`,
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 用于未被掩码的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 用于被掩码的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是注意力掩码？
- en: '`token_type_ids` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Segment token indices to indicate first and second portions of the inputs. Indices
    are selected in `[0, 1]`:'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`tf.Tensor`，形状为 `(batch_size, sequence_length)`，*可选*) — 段标记索引，指示输入的第一部分和第二部分。索引选在
    `[0, 1]`：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于 *句子 A* 的标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 的标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 什么是标记类型ID？
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) — Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`tf.Tensor`，形状为 `(batch_size, sequence_length, hidden_size)`，*可选*)
    — 可选地，您可以选择直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将 `input_ids` 索引转换为相关向量，而不是模型内部的嵌入查找矩阵，则这很有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail. This argument can be used only in eager mode, in graph mode the value
    in the config will be used instead.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的 `attentions`。此参数仅在急切模式下使用，在图模式下将使用配置中的值。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail. This argument can be used only in eager mode, in graph mode the value
    in the config will be used instead.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的 `hidden_states`。此参数仅在急切模式下使用，在图模式下将使用配置中的值。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple. This argument can be used in eager mode, in graph mode
    the value will always be set to True.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。此参数可以在急切模式下使用，在图模式下该值将始终设置为 True。'
- en: '`training` (`bool`, *optional*, defaults to `False`) — Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`training` (`bool`，*可选*，默认为 `False`) — 是否在训练模式下使用模型（一些模块，如 dropout 模块，在训练和评估之间有不同的行为）。'
- en: Returns
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput 或 `tuple(tf.Tensor)`
- en: A [transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    and inputs.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModelOutput)或一个`tf.Tensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)）和输入的不同元素。
- en: '`language_output` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    — Sequence of hidden-states at the output of the last layer of the language encoder.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_output` (`tf.Tensor`，形状为`(batch_size, sequence_length, hidden_size)`)
    — 语言编码器最后一层的隐藏状态序列。'
- en: '`vision_output` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    — Sequence of hidden-states at the output of the last layer of the visual encoder.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_output` (`tf.Tensor`，形状为`(batch_size, sequence_length, hidden_size)`)
    — 视觉编码器最后一层的隐藏状态序列。'
- en: '`pooled_output` (`tf.Tensor` of shape `(batch_size, hidden_size)`) — Last layer
    hidden-state of the first token of the sequence (classification, CLS, token) further
    processed by a Linear layer and a Tanh activation function. The Linear'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_output` (`tf.Tensor`，形状为`(batch_size, hidden_size)`) — 序列第一个标记的最后一层隐藏状态（分类，CLS，标记），经过线性层和Tanh激活函数进一步处理。线性'
- en: '`language_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for input features + one for the output of each cross-modality layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于输入特征，一个用于每个跨模态层的输出）。'
- en: '`vision_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for input features + one for the output of each cross-modality layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于输入特征，一个用于每个跨模态层的输出）。'
- en: '`language_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组。在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`vision_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组。在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: '`cross_encoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组。在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。'
- en: The [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)
    forward method, overrides the `__call__` special method.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)的前向方法覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE26]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: TFLxmertForPreTraining
  id: totrans-440
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFLxmertForPreTraining
- en: '### `class transformers.TFLxmertForPreTraining`'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFLxmertForPreTraining`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L1400)'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L1400)'
- en: '[PRE27]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: Lxmert Model with a `language modeling` head on top.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部带有`语言建模`头的Lxmert模型。
- en: 'The LXMERT model was proposed in [LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490) by Hao Tan and Mohit Bansal.
    It’s a vision and language transformer model, pre-trained on a variety of multi-modal
    datasets comprising of GQA, VQAv2.0, MCSCOCO captions, and Visual genome, using
    a combination of masked language modeling, region of interest feature regression,
    cross entropy loss for question answering attribute prediction, and object tag
    prediction.'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 'LXMERT模型是由Hao Tan和Mohit Bansal在[LXMERT: Learning Cross-Modality Encoder Representations
    from Transformers](https://arxiv.org/abs/1908.07490)中提出的。这是一个视觉和语言变换器模型，使用遮蔽语言建模、感兴趣区域特征回归、交叉熵损失用于问题回答属性预测和对象标签预测，预先在各种多模态数据集上进行了预训练，包括GQA、VQAv2.0、MCSCOCO标题和Visual
    genome。'
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型还是一个[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)子类。将其用作常规的TF
    2.0 Keras模型，并参考TF 2.0文档以获取有关一般用法和行为的所有相关信息。
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers`中的TensorFlow模型和层接受两种格式的输入：'
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有输入作为关键字参数（类似于PyTorch模型），或
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有输入作为列表、元组或字典放在第一个位置参数中。
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should “just work” for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 支持第二种格式的原因是，Keras方法在将输入传递给模型和层时更喜欢这种格式。由于有了这种支持，当使用`model.fit()`等方法时，应该可以“正常工作”
    - 只需以`model.fit()`支持的任何格式传递您的输入和标签！但是，如果您想在Keras方法之外使用第二种格式，例如在使用Keras`Functional`
    API创建自己的层或模型时，有三种可能性可用于在第一个位置参数中收集所有输入张量：
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个仅包含`input_ids`的单个张量，没有其他内容：`model(input_ids)`
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按照文档字符串中给定的顺序，一个长度可变的列表，包含一个或多个输入张量：`model([input_ids, attention_mask])`或`model([input_ids,
    attention_mask, token_type_ids])`
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '一个包含一个或多个与文档字符串中给定的输入名称相关联的输入张量的字典：`model({"input_ids": input_ids, "token_type_ids":
    token_type_ids})`'
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you don’t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在使用[子类化](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)创建模型和层时，您无需担心任何这些，因为您可以像对待任何其他Python函数一样传递输入！
- en: '#### `call`'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L1501)'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/lxmert/modeling_tf_lxmert.py#L1501)'
- en: '[PRE28]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`np.ndarray` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`np.ndarray`或`tf.Tensor`）- 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)和[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是input IDs？](../glossary#input-ids)'
- en: '`visual_feats` (`tf.Tensor` of shape `(batch_size, num_visual_features, visual_feat_dim)`)
    — This input represents visual features. They ROI pooled object features from
    bounding boxes using a faster-RCNN model)'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_feats`（形状为`(batch_size, num_visual_features, visual_feat_dim)`的`tf.Tensor`）-
    此输入表示视觉特征。它们是使用faster-RCNN模型从边界框中ROI池化的对象特征。'
- en: These are currently not provided by the transformers library.
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前transformers库中没有提供这些。
- en: '`visual_pos` (`tf.Tensor` of shape `(batch_size, num_visual_features, visual_feat_dim)`)
    — This input represents spacial features corresponding to their relative (via
    index) visual features. The pre-trained LXMERT model expects these spacial features
    to be normalized bounding boxes on a scale of 0 to'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_pos`（形状为`(batch_size, num_visual_features, visual_feat_dim)`的`tf.Tensor`）-
    此输入表示与它们的相对（通过索引）视觉特征对应的空间特征。预训练的LXMERT模型期望这些空间特征是在0到1的范围内的归一化边界框。'
- en: These are currently not provided by the transformers library.
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前transformers库中没有提供这些。
- en: '`attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`tf.Tensor`，*可选*）- 用于避免在填充标记索引上执行注意力的掩码。选择在`[0,
    1]`中的掩码值：'
- en: 1 for tokens that are `not masked`,
  id: totrans-469
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被“masked”（掩盖）的标记，值为1，
- en: 0 for tokens that are `masked`.
  id: totrans-470
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被“masked”（掩盖）的标记，值为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是attention masks？](../glossary#attention-mask)'
- en: '`visual_attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — MMask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 避免在填充令牌索引上执行注意力的MMask。在`[0, 1]`中选择的掩码值：'
- en: 1 for tokens that are `not masked`,
  id: totrans-473
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被`masked`的令牌，
- en: 0 for tokens that are `masked`.
  id: totrans-474
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`masked`的令牌。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Segment token indices to indicate first and second portions of the inputs. Indices
    are selected in `[0, 1]`:'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — 段令牌索引，指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-477
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*令牌，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-478
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于*句子B*令牌。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是令牌类型ID？](../glossary#token-type-ids)'
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) — Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) — 可选地，您可以选择直接传递嵌入表示而不是传递`input_ids`。如果您希望更多地控制如何将`input_ids`索引转换为相关向量，而不是模型的内部嵌入查找矩阵，则这很有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail. This argument can be used only in eager mode, in graph mode the value
    in the config will be used instead.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。此参数仅在急切模式下可用，在图模式下将使用配置中的值。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail. This argument can be used only in eager mode, in graph mode the value
    in the config will be used instead.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。此参数仅在急切模式下可用，在图模式下将使用配置中的值。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple. This argument can be used in eager mode, in graph mode
    the value will always be set to True.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。此参数可在急切模式下使用，在图模式下该值将始终设置为True。'
- en: '`training` (`bool`, *optional*, defaults to `False`) — Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`training` (`bool`, *optional*, 默认为`False`) — 是否在训练模式下使用模型（某些模块如丢弃模块在训练和评估之间有不同的行为）。'
- en: '`masked_lm_labels` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should be in
    `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-100` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`masked_lm_labels` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — 用于计算掩码语言建模损失的标签。索引应在`[-100, 0, ..., config.vocab_size]`内（请参阅`input_ids`文档字符串）。索引设置为`-100`的令牌将被忽略（掩码），仅对具有标签在`[0,
    ..., config.vocab_size]`中的令牌计算损失'
- en: '`obj_labels` (`Dict[Str -- Tuple[tf.Tensor, tf.Tensor]]`, *optional*, defaults
    to `None`): each key is named after each one of the visual losses and each element
    of the tuple is of the shape `(batch_size, num_features)` and `(batch_size, num_features,
    visual_feature_dim)` for each the label id and the label score respectively'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`obj_labels` (`Dict[Str -- Tuple[tf.Tensor, tf.Tensor]]`, *optional*, 默认为`None`):
    每个键都以视觉损失中的每个元素命名，元组的每个元素的形状分别为`(batch_size, num_features)`和`(batch_size, num_features,
    visual_feature_dim)`，用于标签id和标签分数'
- en: '`matched_label` (`tf.Tensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the whether or not the text input matches the image (classification)
    loss. Input should be a sequence pair (see `input_ids` docstring) Indices should
    be in `[0, 1]`:'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matched_label` (`tf.Tensor` of shape `(batch_size,)`, *optional*) — 用于计算文本输入是否与图像（分类）损失匹配的标签。输入应为一个序列对（请参阅`input_ids`文档字符串）索引应在`[0,
    1]`内：'
- en: 0 indicates that the sentence does not match the image,
  id: totrans-488
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示句子与图像不匹配，
- en: 1 indicates that the sentence does match the image.
  id: totrans-489
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示句子与图像匹配。
- en: '`ans` (`tf.Tensor` of shape `(batch_size)`, *optional*, defaults to `None`)
    — a one hot representation hof the correct answer *optional*'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ans` (`tf.Tensor` of shape `(batch_size)`, *optional*, 默认为`None`) — 正确答案的独热表示*可选*'
- en: Returns
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput)或`tuple(tf.Tensor)`'
- en: A [transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig))
    and inputs.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTrainingOutput)或一个`tf.Tensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包括根据配置（[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)）和输入的不同元素。
- en: '`loss` (*optional*, returned when `labels` is provided, `tf.Tensor` of shape
    `(1,)`) — Total loss as the sum of the masked language modeling loss and the next
    sequence prediction (classification) loss.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (*optional*, 当提供`labels`时返回，形状为`(1,)`) — 总损失，作为掩码语言建模损失和下一个序列预测（分类）损失的总和。'
- en: '`prediction_logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_logits` (`tf.Tensor`，形状为`(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`cross_relationship_score` (`tf.Tensor` of shape `(batch_size, 2)`) — Prediction
    scores of the textual matching objective (classification) head (scores of True/False
    continuation before SoftMax).'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_relationship_score` (`tf.Tensor`，形状为`(batch_size, 2)`) — 文本匹配目标（分类）头的预测分数（SoftMax之前的True/False连续性分数）。'
- en: '`question_answering_score` (`tf.Tensor` of shape `(batch_size, n_qa_answers)`)
    — Prediction scores of question answering objective (classification).'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question_answering_score` (`tf.Tensor`，形状为`(batch_size, n_qa_answers)`) —
    问答目标（分类）的预测分数。'
- en: '`language_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for input features + one for the output of each cross-modality layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于输入特征，一个用于每个跨模态层的输出）。'
- en: '`vision_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for input features + one for the output of each cross-modality layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_hidden_states` (`tuple(tf.Tensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于输入特征，一个用于每个跨模态层的输出）。'
- en: '`language_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language_attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组。在自注意力头中用于计算加权平均的注意力权重softmax之后。'
- en: '`vision_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision_attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组。在自注意力头中用于计算加权平均的注意力权重softmax之后。'
- en: '`cross_encoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
    Attentions weights after the attention softmax, used to compute the weighted average
    in the self-attention heads.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_encoder_attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组。在自注意力头中用于计算加权平均的注意力权重softmax之后。'
- en: The [TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining)
    forward method, overrides the `__call__` special method.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在此之后调用`Module`实例，而不是这个函数，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
