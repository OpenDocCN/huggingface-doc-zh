["```py\npip install -q transformers datasets\n```", "```py\npip install 'git+https://github.com/facebookresearch/detectron2.git'\npip install torchvision\n```", "```py\nsudo apt install tesseract-ocr\npip install -q pytesseract\n```", "```py\n>>> from huggingface_hub import notebook_login\n\n>>> notebook_login()\n```", "```py\n>>> model_checkpoint = \"microsoft/layoutlmv2-base-uncased\"\n>>> batch_size = 4\n```", "```py\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"nielsr/docvqa_1200_examples\")\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'image', 'query', 'answers', 'words', 'bounding_boxes', 'answer'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['id', 'image', 'query', 'answers', 'words', 'bounding_boxes', 'answer'],\n        num_rows: 200\n    })\n})\n```", "```py\n>>> dataset[\"train\"].features\n```", "```py\n>>> updated_dataset = dataset.map(lambda example: {\"question\": example[\"query\"][\"en\"]}, remove_columns=[\"query\"])\n>>> updated_dataset = updated_dataset.map(\n...     lambda example: {\"answer\": example[\"answers\"][0]}, remove_columns=[\"answer\", \"answers\"]\n... )\n```", "```py\n>>> updated_dataset = updated_dataset.filter(lambda x: len(x[\"words\"]) + len(x[\"question\"].split()) < 512)\n```", "```py\n>>> updated_dataset = updated_dataset.remove_columns(\"words\")\n>>> updated_dataset = updated_dataset.remove_columns(\"bounding_boxes\")\n```", "```py\n>>> updated_dataset[\"train\"][11][\"image\"]\n```", "```py\n>>> from transformers import AutoProcessor\n\n>>> processor = AutoProcessor.from_pretrained(model_checkpoint)\n```", "```py\n>>> image_processor = processor.image_processor\n\n>>> def get_ocr_words_and_boxes(examples):\n...     images = [image.convert(\"RGB\") for image in examples[\"image\"]]\n...     encoded_inputs = image_processor(images)\n\n...     examples[\"image\"] = encoded_inputs.pixel_values\n...     examples[\"words\"] = encoded_inputs.words\n...     examples[\"boxes\"] = encoded_inputs.boxes\n\n...     return examples\n```", "```py\n>>> dataset_with_ocr = updated_dataset.map(get_ocr_words_and_boxes, batched=True, batch_size=2)\n```", "```py\n>>> tokenizer = processor.tokenizer\n```", "```py\n>>> def subfinder(words_list, answer_list):\n...     matches = []\n...     start_indices = []\n...     end_indices = []\n...     for idx, i in enumerate(range(len(words_list))):\n...         if words_list[i] == answer_list[0] and words_list[i : i + len(answer_list)] == answer_list:\n...             matches.append(answer_list)\n...             start_indices.append(idx)\n...             end_indices.append(idx + len(answer_list) - 1)\n...     if matches:\n...         return matches[0], start_indices[0], end_indices[0]\n...     else:\n...         return None, 0, 0\n```", "```py\n>>> example = dataset_with_ocr[\"train\"][1]\n>>> words = [word.lower() for word in example[\"words\"]]\n>>> match, word_idx_start, word_idx_end = subfinder(words, example[\"answer\"].lower().split())\n>>> print(\"Question: \", example[\"question\"])\n>>> print(\"Words:\", words)\n>>> print(\"Answer: \", example[\"answer\"])\n>>> print(\"start_index\", word_idx_start)\n>>> print(\"end_index\", word_idx_end)\nQuestion:  Who is in  cc in this letter?\nWords: ['wie', 'baw', 'brown', '&', 'williamson', 'tobacco', 'corporation', 'research', '&', 'development', 'internal', 'correspondence', 'to:', 'r.', 'h.', 'honeycutt', 'ce:', 't.f.', 'riehl', 'from:', '.', 'c.j.', 'cook', 'date:', 'may', '8,', '1995', 'subject:', 'review', 'of', 'existing', 'brainstorming', 'ideas/483', 'the', 'major', 'function', 'of', 'the', 'product', 'innovation', 'graup', 'is', 'to', 'develop', 'marketable', 'nove!', 'products', 'that', 'would', 'be', 'profitable', 'to', 'manufacture', 'and', 'sell.', 'novel', 'is', 'defined', 'as:', 'of', 'a', 'new', 'kind,', 'or', 'different', 'from', 'anything', 'seen', 'or', 'known', 'before.', 'innovation', 'is', 'defined', 'as:', 'something', 'new', 'or', 'different', 'introduced;', 'act', 'of', 'innovating;', 'introduction', 'of', 'new', 'things', 'or', 'methods.', 'the', 'products', 'may', 'incorporate', 'the', 'latest', 'technologies,', 'materials', 'and', 'know-how', 'available', 'to', 'give', 'then', 'a', 'unique', 'taste', 'or', 'look.', 'the', 'first', 'task', 'of', 'the', 'product', 'innovation', 'group', 'was', 'to', 'assemble,', 'review', 'and', 'categorize', 'a', 'list', 'of', 'existing', 'brainstorming', 'ideas.', 'ideas', 'were', 'grouped', 'into', 'two', 'major', 'categories', 'labeled', 'appearance', 'and', 'taste/aroma.', 'these', 'categories', 'are', 'used', 'for', 'novel', 'products', 'that', 'may', 'differ', 'from', 'a', 'visual', 'and/or', 'taste/aroma', 'point', 'of', 'view', 'compared', 'to', 'canventional', 'cigarettes.', 'other', 'categories', 'include', 'a', 'combination', 'of', 'the', 'above,', 'filters,', 'packaging', 'and', 'brand', 'extensions.', 'appearance', 'this', 'category', 'is', 'used', 'for', 'novel', 'cigarette', 'constructions', 'that', 'yield', 'visually', 'different', 'products', 'with', 'minimal', 'changes', 'in', 'smoke', 'chemistry', 'two', 'cigarettes', 'in', 'cne.', 'emulti-plug', 'te', 'build', 'yaur', 'awn', 'cigarette.', 'eswitchable', 'menthol', 'or', 'non', 'menthol', 'cigarette.', '*cigarettes', 'with', 'interspaced', 'perforations', 'to', 'enable', 'smoker', 'to', 'separate', 'unburned', 'section', 'for', 'future', 'smoking.', '\u00abshort', 'cigarette,', 'tobacco', 'section', '30', 'mm.', '\u00abextremely', 'fast', 'buming', 'cigarette.', '\u00abnovel', 'cigarette', 'constructions', 'that', 'permit', 'a', 'significant', 'reduction', 'iretobacco', 'weight', 'while', 'maintaining', 'smoking', 'mechanics', 'and', 'visual', 'characteristics.', 'higher', 'basis', 'weight', 'paper:', 'potential', 'reduction', 'in', 'tobacco', 'weight.', '\u00abmore', 'rigid', 'tobacco', 'column;', 'stiffing', 'agent', 'for', 'tobacco;', 'e.g.', 'starch', '*colored', 'tow', 'and', 'cigarette', 'papers;', 'seasonal', 'promotions,', 'e.g.', 'pastel', 'colored', 'cigarettes', 'for', 'easter', 'or', 'in', 'an', 'ebony', 'and', 'ivory', 'brand', 'containing', 'a', 'mixture', 'of', 'all', 'black', '(black', 'paper', 'and', 'tow)', 'and', 'ail', 'white', 'cigarettes.', '499150498']\nAnswer:  T.F. Riehl\nstart_index 17\nend_index 18\n```", "```py\n>>> encoding = tokenizer(example[\"question\"], example[\"words\"], example[\"boxes\"])\n>>> tokenizer.decode(encoding[\"input_ids\"])\n[CLS] who is in cc in this letter? [SEP] wie baw brown & williamson tobacco corporation research & development ...\n```", "```py\n>>> def encode_dataset(examples, max_length=512):\n...     questions = examples[\"question\"]\n...     words = examples[\"words\"]\n...     boxes = examples[\"boxes\"]\n...     answers = examples[\"answer\"]\n\n...     # encode the batch of examples and initialize the start_positions and end_positions\n...     encoding = tokenizer(questions, words, boxes, max_length=max_length, padding=\"max_length\", truncation=True)\n...     start_positions = []\n...     end_positions = []\n\n...     # loop through the examples in the batch\n...     for i in range(len(questions)):\n...         cls_index = encoding[\"input_ids\"][i].index(tokenizer.cls_token_id)\n\n...         # find the position of the answer in example's words\n...         words_example = [word.lower() for word in words[i]]\n...         answer = answers[i]\n...         match, word_idx_start, word_idx_end = subfinder(words_example, answer.lower().split())\n\n...         if match:\n...             # if match is found, use `token_type_ids` to find where words start in the encoding\n...             token_type_ids = encoding[\"token_type_ids\"][i]\n...             token_start_index = 0\n...             while token_type_ids[token_start_index] != 1:\n...                 token_start_index += 1\n\n...             token_end_index = len(encoding[\"input_ids\"][i]) - 1\n...             while token_type_ids[token_end_index] != 1:\n...                 token_end_index -= 1\n\n...             word_ids = encoding.word_ids(i)[token_start_index : token_end_index + 1]\n...             start_position = cls_index\n...             end_position = cls_index\n\n...             # loop over word_ids and increase `token_start_index` until it matches the answer position in words\n...             # once it matches, save the `token_start_index` as the `start_position` of the answer in the encoding\n...             for id in word_ids:\n...                 if id == word_idx_start:\n...                     start_position = token_start_index\n...                 else:\n...                     token_start_index += 1\n\n...             # similarly loop over `word_ids` starting from the end to find the `end_position` of the answer\n...             for id in word_ids[::-1]:\n...                 if id == word_idx_end:\n...                     end_position = token_end_index\n...                 else:\n...                     token_end_index -= 1\n\n...             start_positions.append(start_position)\n...             end_positions.append(end_position)\n\n...         else:\n...             start_positions.append(cls_index)\n...             end_positions.append(cls_index)\n\n...     encoding[\"image\"] = examples[\"image\"]\n...     encoding[\"start_positions\"] = start_positions\n...     encoding[\"end_positions\"] = end_positions\n\n...     return encoding\n```", "```py\n>>> encoded_train_dataset = dataset_with_ocr[\"train\"].map(\n...     encode_dataset, batched=True, batch_size=2, remove_columns=dataset_with_ocr[\"train\"].column_names\n... )\n>>> encoded_test_dataset = dataset_with_ocr[\"test\"].map(\n...     encode_dataset, batched=True, batch_size=2, remove_columns=dataset_with_ocr[\"test\"].column_names\n... )\n```", "```py\n>>> encoded_train_dataset.features\n{'image': Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='uint8', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None),\n 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n 'bbox': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n 'start_positions': Value(dtype='int64', id=None),\n 'end_positions': Value(dtype='int64', id=None)}\n```", "```py\n>>> from transformers import AutoModelForDocumentQuestionAnswering\n\n>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained(model_checkpoint)\n```", "```py\n>>> from transformers import TrainingArguments\n\n>>> # REPLACE THIS WITH YOUR REPO ID\n>>> repo_id = \"MariaK/layoutlmv2-base-uncased_finetuned_docvqa\"\n\n>>> training_args = TrainingArguments(\n...     output_dir=repo_id,\n...     per_device_train_batch_size=4,\n...     num_train_epochs=20,\n...     save_steps=200,\n...     logging_steps=50,\n...     evaluation_strategy=\"steps\",\n...     learning_rate=5e-5,\n...     save_total_limit=2,\n...     remove_unused_columns=False,\n...     push_to_hub=True,\n... )\n```", "```py\n>>> from transformers import DefaultDataCollator\n\n>>> data_collator = DefaultDataCollator()\n```", "```py\n>>> from transformers import Trainer\n\n>>> trainer = Trainer(\n...     model=model,\n...     args=training_args,\n...     data_collator=data_collator,\n...     train_dataset=encoded_train_dataset,\n...     eval_dataset=encoded_test_dataset,\n...     tokenizer=processor,\n... )\n\n>>> trainer.train()\n```", "```py\n>>> trainer.create_model_card()\n>>> trainer.push_to_hub()\n```", "```py\n>>> example = dataset[\"test\"][2]\n>>> question = example[\"query\"][\"en\"]\n>>> image = example[\"image\"]\n>>> print(question)\n>>> print(example[\"answers\"])\n'Who is \u2018presiding\u2019 TRRF GENERAL SESSION (PART 1)?'\n['TRRF Vice President', 'lee a. waller']\n```", "```py\n>>> from transformers import pipeline\n\n>>> qa_pipeline = pipeline(\"document-question-answering\", model=\"MariaK/layoutlmv2-base-uncased_finetuned_docvqa\")\n>>> qa_pipeline(image, question)\n[{'score': 0.9949808120727539,\n  'answer': 'Lee A. Waller',\n  'start': 55,\n  'end': 57}]\n```", "```py\n>>> import torch\n>>> from transformers import AutoProcessor\n>>> from transformers import AutoModelForDocumentQuestionAnswering\n\n>>> processor = AutoProcessor.from_pretrained(\"MariaK/layoutlmv2-base-uncased_finetuned_docvqa\")\n>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained(\"MariaK/layoutlmv2-base-uncased_finetuned_docvqa\")\n\n>>> with torch.no_grad():\n...     encoding = processor(image.convert(\"RGB\"), question, return_tensors=\"pt\")\n...     outputs = model(**encoding)\n...     start_logits = outputs.start_logits\n...     end_logits = outputs.end_logits\n...     predicted_start_idx = start_logits.argmax(-1).item()\n...     predicted_end_idx = end_logits.argmax(-1).item()\n\n>>> processor.tokenizer.decode(encoding.input_ids.squeeze()[predicted_start_idx : predicted_end_idx + 1])\n'lee a. waller'\n```"]