- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/optimum-neuron/guides/overview](https://huggingface.co/docs/optimum-neuron/guides/overview)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the ðŸ¤— Optimum Neuron how-to guides!
  prefs: []
  type: TYPE_NORMAL
- en: 'These guides tackle more advanced topics and will show you how to easily get
    the best from AWS Trainium / Inferentia:'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to setup AWS Trainium instance](./setup_aws_instance)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Training and Deployment using Amazon Sagemaker](./sagemaker)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Neuron model cache](./cache_system)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to fine-tune a Transformers model with AWS Trainium](./fine_tune)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Distributed training with AWS Neuron](./distributed_training.mdx)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Export a model to Inferentia](./export_model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Neuron Model Inference](./models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Inference pipelines with AWS Neuron (Inf2/Trn1)](./pipelines)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
