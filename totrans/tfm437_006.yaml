- en: Pipelines for inference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于推断的管道
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/pipeline_tutorial](https://huggingface.co/docs/transformers/v4.37.2/en/pipeline_tutorial)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/pipeline_tutorial](https://huggingface.co/docs/transformers/v4.37.2/en/pipeline_tutorial)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'The [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    makes it simple to use any model from the [Hub](https://huggingface.co/models)
    for inference on any language, computer vision, speech, and multimodal tasks.
    Even if you don’t have experience with a specific modality or aren’t familiar
    with the underlying code behind the models, you can still use them for inference
    with the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)!
    This tutorial will teach you to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)使得在任何语言、计算机视觉、语音和多模态任务上使用Hub中的任何模型进行推断变得简单。即使您没有使用特定模态的经验或不熟悉模型背后的代码，您仍然可以使用[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)进行推断！本教程将教您：'
- en: Use a [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for inference.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于推断的[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)。
- en: Use a specific tokenizer or model.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用特定的分词器或模型。
- en: Use a [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for audio, vision, and multimodal tasks.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为音频、视觉和多模态任务使用[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)。
- en: Take a look at the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    documentation for a complete list of supported tasks and available parameters.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)文档，了解支持的任务和可用参数的完整列表。
- en: Pipeline usage
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道用法
- en: While each task has an associated [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline),
    it is simpler to use the general [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    abstraction which contains all the task-specific pipelines. The [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    automatically loads a default model and a preprocessing class capable of inference
    for your task. Let’s take the example of using the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for automatic speech recognition (ASR), or speech-to-text.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然每个任务都有一个相关的[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)，但使用包含所有特定任务管道的通用[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)抽象更简单。[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)会自动加载默认模型和适用于您任务的推断预处理类。让我们以使用[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)进行自动语音识别（ASR）或语音转文本为例。
- en: 'Start by creating a [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    and specify the inference task:'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先创建一个[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)，并指定推断任务：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Pass your input to the [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline).
    In the case of speech recognition, this is an audio input file:'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的输入传递给[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)。在语音识别的情况下，这是一个音频输入文件：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Not the result you had in mind? Check out some of the [most downloaded automatic
    speech recognition models](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=trending)
    on the Hub to see if you can get a better transcription.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 不是您想要的结果？查看Hub上一些[最受欢迎的自动语音识别模型](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=trending)，看看是否可以获得更好的转录。
- en: Let’s try the [Whisper large-v2](https://huggingface.co/openai/whisper-large)
    model from OpenAI. Whisper was released 2 years later than Wav2Vec2, and was trained
    on close to 10x more data. As such, it beats Wav2Vec2 on most downstream benchmarks.
    It also has the added benefit of predicting punctuation and casing, neither of
    which are possible with
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试来自OpenAI的[Whisper large-v2](https://huggingface.co/openai/whisper-large)模型。Whisper比Wav2Vec2晚发布了2年，训练数据接近10倍。因此，它在大多数下游基准测试中击败了Wav2Vec2。它还具有预测标点和大小写的附加好处，而这两者在Wav2Vec2中都不可能。
- en: Wav2Vec2.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Wav2Vec2。
- en: 'Let’s give it a try here to see how it performs:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里尝试一下，看看它的表现如何：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now this result looks more accurate! For a deep-dive comparison on Wav2Vec2
    vs Whisper, refer to the [Audio Transformers Course](https://huggingface.co/learn/audio-course/chapter5/asr_models).
    We really encourage you to check out the Hub for models in different languages,
    models specialized in your field, and more. You can check out and compare model
    results directly from your browser on the Hub to see if it fits or handles corner
    cases better than other ones. And if you don’t find a model for your use case,
    you can always start [training](training) your own!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这个结果看起来更准确了！要深入比较Wav2Vec2和Whisper，请参考[音频变换器课程](https://huggingface.co/learn/audio-course/chapter5/asr_models)。我们真的鼓励您查看Hub中不同语言的模型、专门针对您领域的模型等。您可以直接从Hub在浏览器上查看和比较模型结果，看看它是否比其他模型更适合或更好地处理边缘情况。如果您找不到适用于您用例的模型，您始终可以开始[训练](training)您自己的模型！
- en: 'If you have several inputs, you can pass your input as a list:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有多个输入，可以将输入作为列表传递：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Pipelines are great for experimentation as switching from one model to another
    is trivial; however, there are some ways to optimize them for larger workloads
    than experimentation. See the following guides that dive into iterating over whole
    datasets or using pipelines in a webserver: of the docs:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 管道对于实验很有用，因为从一个模型切换到另一个模型很简单；然而，有一些方法可以优化它们以处理比实验更大的工作量。查看以下指南，深入探讨如何迭代整个数据集或在web服务器中使用管道：文档中的：
- en: '[Using pipelines on a dataset](#using-pipelines-on-a-dataset)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在数据集上使用管道](#using-pipelines-on-a-dataset)'
- en: '[Using pipelines for a webserver](./pipeline_webserver)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在web服务器上使用管道](./pipeline_webserver)'
- en: Parameters
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数
- en: '[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    supports many parameters; some are task specific, and some are general to all
    pipelines. In general, you can specify parameters anywhere you want:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)支持许多参数；一些是任务特定的，一些是所有管道通用的。一般来说，您可以在任何地方指定参数：'
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s check out 3 important ones:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看3个重要的参数：
- en: Device
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设备
- en: If you use `device=n`, the pipeline automatically puts the model on the specified
    device. This will work regardless of whether you are using PyTorch or Tensorflow.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用`device=n`，管道会自动将模型放在指定的设备上。无论您使用PyTorch还是Tensorflow，这都可以工作。
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If the model is too large for a single GPU and you are using PyTorch, you can
    set `device_map="auto"` to automatically determine how to load and store the model
    weights. Using the `device_map` argument requires the 🤗 [Accelerate](https://huggingface.co/docs/accelerate)
    package:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型对单个GPU来说太大，并且您使用的是PyTorch，您可以设置`device_map="auto"`来自动确定如何加载和存储模型权重。使用`device_map`参数需要
    🤗 [Accelerate](https://huggingface.co/docs/accelerate) 软件包：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following code automatically loads and stores model weights across devices:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码会自动在设备之间加载和存储模型权重：
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that if `device_map="auto"` is passed, there is no need to add the argument
    `device=device` when instantiating your `pipeline` as you may encounter some unexpected
    behavior!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果传递了`device_map="auto"`，在实例化您的`pipeline`时无需添加参数`device=device`，否则可能会遇到一些意外行为！
- en: Batch size
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 批处理大小
- en: By default, pipelines will not batch inference for reasons explained in detail
    [here](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching).
    The reason is that batching is not necessarily faster, and can actually be quite
    slower in some cases.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，管道不会批量推理，原因在[这里](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching)有详细解释。原因是批处理不一定更快，在某些情况下实际上可能会更慢。
- en: 'But if it works in your use case, you can use:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果在您的使用案例中有效，您可以使用：
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This runs the pipeline on the 4 provided audio files, but it will pass them
    in batches of 2 to the model (which is on a GPU, where batching is more likely
    to help) without requiring any further code from you. The output should always
    match what you would have received without batching. It is only meant as a way
    to help you get more speed out of a pipeline.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这会在提供的4个音频文件上运行管道，但会将它们分批传递给模型（模型在GPU上，批处理更有可能有所帮助），而无需您进一步编写任何代码。输出应始终与没有批处理时收到的结果相匹配。这只是一种帮助您从管道中获得更快速度的方法。
- en: Pipelines can also alleviate some of the complexities of batching because, for
    some pipelines, a single item (like a long audio file) needs to be chunked into
    multiple parts to be processed by a model. The pipeline performs this [*chunk
    batching*](./main_classes/pipelines#pipeline-chunk-batching) for you.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 管道还可以减轻一些批处理的复杂性，因为对于某些管道，单个项目（如长音频文件）需要被分成多个部分才能被模型处理。管道会为您执行这种[*块批处理*](./main_classes/pipelines#pipeline-chunk-batching)。
- en: Task specific parameters
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务特定参数
- en: 'All tasks provide task specific parameters which allow for additional flexibility
    and options to help you get your job done. For instance, the [transformers.AutomaticSpeechRecognitionPipeline.**call**()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline.__call__)
    method has a `return_timestamps` parameter which sounds promising for subtitling
    videos:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 所有任务都提供任务特定参数，这些参数允许额外的灵活性和选项，帮助您完成工作。例如，[transformers.AutomaticSpeechRecognitionPipeline.**call**()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline.__call__)方法有一个`return_timestamps`参数，对于为视频添加字幕听起来很有希望：
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As you can see, the model inferred the text and also outputted **when** the
    various sentences were pronounced.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，模型推断了文本，并且还输出了各个句子的发音时间。
- en: 'There are many parameters available for each task, so check out each task’s
    API reference to see what you can tinker with! For instance, the [AutomaticSpeechRecognitionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline)
    has a `chunk_length_s` parameter which is helpful for working on really long audio
    files (for example, subtitling entire movies or hour-long videos) that a model
    typically cannot handle on its own:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 每个任务都有许多可用的参数，因此请查看每个任务的API参考，看看您可以调整哪些参数！例如，[AutomaticSpeechRecognitionPipeline](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline)有一个`chunk_length_s`参数，对于处理非常长的音频文件（例如，为整部电影或长达一小时的视频添加字幕）非常有帮助，这是模型通常无法独立处理的：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you can’t find a parameter that would really help you out, feel free to [request
    it](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果找不到一个真正有帮助的参数，请随时[请求](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)！
- en: Using pipelines on a dataset
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在数据集上使用管道
- en: 'The pipeline can also run inference on a large dataset. The easiest way we
    recommend doing this is by using an iterator:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 管道还可以在大型数据集上运行推理。我们建议的最简单方法是使用迭代器：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The iterator `data()` yields each result, and the pipeline automatically recognizes
    the input is iterable and will start fetching the data while it continues to process
    it on the GPU (this uses [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)
    under the hood). This is important because you don’t have to allocate memory for
    the whole dataset and you can feed the GPU as fast as possible.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代器`data()`会产生每个结果，管道会自动识别输入是可迭代的，并在继续在GPU上处理数据的同时开始获取数据（这在底层使用[DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)）。这很重要，因为您不必为整个数据集分配内存，可以尽可能快地将数据馈送到GPU。
- en: Since batching could speed things up, it may be useful to try tuning the `batch_size`
    parameter here.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于批处理可能加快速度，尝试调整这里的`batch_size`参数可能会有用。
- en: 'The simplest way to iterate over a dataset is to just load one from 🤗 [Datasets](https://github.com/huggingface/datasets/):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代数据集的最简单方法就是从 🤗 [Datasets](https://github.com/huggingface/datasets/) 加载一个：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Using pipelines for a webserver
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在web服务器上使用管道
- en: Creating an inference engine is a complex topic which deserves it's own page.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 创建推理引擎是一个复杂的主题，值得有自己的页面。
- en: '[Link](./pipeline_webserver)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[链接](./pipeline_webserver)'
- en: Vision pipeline
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视觉管道
- en: Using a [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for vision tasks is practically identical.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对于视觉任务使用[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)几乎是相同的。
- en: Specify your task and pass your image to the classifier. The image can be a
    link, a local path or a base64-encoded image. For example, what species of cat
    is shown below?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 指定您的任务并将图像传递给分类器。图像可以是链接，本地路径或base64编码的图像。例如，下面显示了什么品种的猫？
- en: '![pipeline-cat-chonk](../Images/ed522d0b7df733cc4426cbf9141d11c3.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![pipeline-cat-chonk](../Images/ed522d0b7df733cc4426cbf9141d11c3.png)'
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Text pipeline
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本管道
- en: Using a [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for NLP tasks is practically identical.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于NLP任务使用[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)几乎是相同的。
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Multimodal pipeline
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多模态管道
- en: The [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    supports more than one modality. For example, a visual question answering (VQA)
    task combines text and image. Feel free to use any image link you like and a question
    you want to ask about the image. The image can be a URL or a local path to the
    image.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)支持多种模态。例如，视觉问答（VQA）任务结合了文本和图像。随意使用您喜欢的任何图像链接和您想要询问有关图像的问题。图像可以是URL或图像的本地路径。'
- en: 'For example, if you use this [invoice image](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您使用这个[发票图像](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png)：
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To run the example above you need to have [`pytesseract`](https://pypi.org/project/pytesseract/)
    installed in addition to 🤗 Transformers:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行上面的示例，您需要安装[`pytesseract`](https://pypi.org/project/pytesseract/)以及🤗 Transformers：
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Using pipeline on large models with 🤗 accelerate :'
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在大型模型上使用🤗加速器：
- en: You can easily run `pipeline` on large models using 🤗 `accelerate`! First make
    sure you have installed `accelerate` with `pip install accelerate`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以轻松地在大型模型上使用🤗`accelerate`运行`pipeline`！首先确保您已经安装了`accelerate`和`pip install
    accelerate`。
- en: First load your model using `device_map="auto"`! We will use `facebook/opt-1.3b`
    for our example.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先使用`device_map="auto"`加载您的模型！我们将在示例中使用`facebook/opt-1.3b`。
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: You can also pass 8-bit loaded models if you install `bitsandbytes` and add
    the argument `load_in_8bit=True`
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果安装了`bitsandbytes`并添加参数`load_in_8bit=True`，还可以传递8位加载的模型
- en: '[PRE18]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note that you can replace the checkpoint with any of the Hugging Face model
    that supports large model loading such as BLOOM!
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您可以用支持大型模型加载的任何Hugging Face模型替换检查点，例如BLOOM！
