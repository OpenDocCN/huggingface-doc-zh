["```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"kandinsky-community/kandinsky-2-2-decoder-inpaint\", torch_dtype=torch.float16\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n```", "```py\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n```", "```py\nprompt = \"a black cat with glowing eyes, cute, adorable, disney, pixar, highly detailed, 8k\"\nnegative_prompt = \"bad anatomy, deformed, ugly, disfigured\"\nimage = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]\nmake_image_grid([init_image, mask_image, image], rows=1, cols=3)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image\nfrom PIL import Image\n\npipeline = AutoPipelineForInpainting.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to('cuda')\n\nmask = load_image(\"https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png\")\nblurred_mask = pipeline.mask_processor.blur(mask, blur_factor=33)\nblurred_mask\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16, variant=\"fp16\"\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n\ngenerator = torch.Generator(\"cuda\").manual_seed(92)\nprompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\nimage = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]\nmake_image_grid([init_image, mask_image, image], rows=1, cols=3)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"diffusers/stable-diffusion-xl-1.0-inpainting-0.1\", torch_dtype=torch.float16, variant=\"fp16\"\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n\ngenerator = torch.Generator(\"cuda\").manual_seed(92)\nprompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\nimage = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]\nmake_image_grid([init_image, mask_image, image], rows=1, cols=3)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"kandinsky-community/kandinsky-2-2-decoder-inpaint\", torch_dtype=torch.float16\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n\ngenerator = torch.Generator(\"cuda\").manual_seed(92)\nprompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\nimage = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]\nmake_image_grid([init_image, mask_image, image], rows=1, cols=3)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\"\n).to(\"cuda\")\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n\ngenerator = torch.Generator(\"cuda\").manual_seed(92)\nprompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\nimage = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\"\n).to(\"cuda\")\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/road-mask.png\")\n\nimage = pipeline(prompt=\"road\", image=init_image, mask_image=mask_image).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nimport PIL\nimport numpy as np\nimport torch\n\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\ndevice = \"cuda\"\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\",\n    torch_dtype=torch.float16,\n)\npipeline = pipeline.to(device)\n\nimg_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\nmask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n\ninit_image = load_image(img_url).resize((512, 512))\nmask_image = load_image(mask_url).resize((512, 512))\n\nprompt = \"Face of a yellow cat, high resolution, sitting on a park bench\"\nrepainted_image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]\nrepainted_image.save(\"repainted_image.png\")\n\nunmasked_unchanged_image = pipeline.image_processor.apply_overlay(mask_image, init_image, repainted_image)\nunmasked_unchanged_image.save(\"force_unmasked_unchanged.png\")\nmake_image_grid([init_image, mask_image, repainted_image, unmasked_unchanged_image], rows=2, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16, variant=\"fp16\"\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n\nprompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\nimage = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.6).images[0]\nmake_image_grid([init_image, mask_image, image], rows=1, cols=3)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16, variant=\"fp16\"\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n\nprompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\nimage = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, guidance_scale=2.5).images[0]\nmake_image_grid([init_image, mask_image, image], rows=1, cols=3)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16, variant=\"fp16\"\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n\nprompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\nnegative_prompt = \"bad architecture, unstable, poor details, blurry\"\nimage = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]\nmake_image_grid([init_image, mask_image, image], rows=1, cols=3)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image\nfrom PIL import Image\n\ngenerator = torch.Generator(device='cuda').manual_seed(0)\npipeline = AutoPipelineForInpainting.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to('cuda')\n\nbase = load_image(\"https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore.png\")\nmask = load_image(\"https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png\")\n\nimage = pipeline(\"boat\", image=base, mask_image=mask, strength=0.75, generator=generator, padding_mask_crop=32).images[0]\nimage\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForText2Image, AutoPipelineForInpainting\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForText2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\ntext2image = pipeline(\"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\").images[0]\n```", "```py\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_text-chain-mask.png\")\n```", "```py\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"kandinsky-community/kandinsky-2-2-decoder-inpaint\", torch_dtype=torch.float16\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\nprompt = \"digital painting of a fantasy waterfall, cloudy\"\nimage = pipeline(prompt=prompt, image=text2image, mask_image=mask_image).images[0]\nmake_image_grid([text2image, mask_image, image], rows=1, cols=3)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting, AutoPipelineForImage2Image\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16, variant=\"fp16\"\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n\nprompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\nimage_inpainting = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]\n\n# resize image to 1024x1024 for SDXL\nimage_inpainting = image_inpainting.resize((1024, 1024))\n```", "```py\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\"\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\nimage = pipeline(prompt=prompt, image=image_inpainting, mask_image=mask_image, output_type=\"latent\").images[0]\n```", "```py\npipeline = AutoPipelineForImage2Image.from_pipe(pipeline)\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\nimage = pipeline(prompt=prompt, image=image).images[0]\nmake_image_grid([init_image, mask_image, image_inpainting, image], rows=2, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import make_image_grid\n\npipeline = AutoPipelineForInpainting.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16,\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\nimage = pipeline(prompt_embeds=prompt_embeds, # generated from Compel\n    negative_prompt_embeds=negative_prompt_embeds, # generated from Compel\n    image=init_image,\n    mask_image=mask_image\n).images[0]\nmake_image_grid([init_image, mask_image, image], rows=1, cols=3)\n```", "```py\nimport torch\nimport numpy as np\nfrom diffusers import ControlNetModel, StableDiffusionControlNetInpaintPipeline\nfrom diffusers.utils import load_image, make_image_grid\n\n# load ControlNet\ncontrolnet = ControlNetModel.from_pretrained(\"lllyasviel/control_v11p_sd15_inpaint\", torch_dtype=torch.float16, variant=\"fp16\")\n\n# pass ControlNet to the pipeline\npipeline = StableDiffusionControlNetInpaintPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\", controlnet=controlnet, torch_dtype=torch.float16, variant=\"fp16\"\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# load base and mask image\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\nmask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n\n# prepare control image\ndef make_inpaint_condition(init_image, mask_image):\n    init_image = np.array(init_image.convert(\"RGB\")).astype(np.float32) / 255.0\n    mask_image = np.array(mask_image.convert(\"L\")).astype(np.float32) / 255.0\n\n    assert init_image.shape[0:1] == mask_image.shape[0:1], \"image and image_mask must have the same image size\"\n    init_image[mask_image > 0.5] = -1.0  # set as masked pixel\n    init_image = np.expand_dims(init_image, 0).transpose(0, 3, 1, 2)\n    init_image = torch.from_numpy(init_image)\n    return init_image\n\ncontrol_image = make_inpaint_condition(init_image, mask_image)\n```", "```py\nprompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\nimage = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, control_image=control_image).images[0]\nmake_image_grid([init_image, mask_image, PIL.Image.fromarray(np.uint8(control_image[0][0])).convert('RGB'), image], rows=2, cols=2)\n```", "```py\nfrom diffusers import AutoPipelineForImage2Image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"nitrosocke/elden-ring-diffusion\", torch_dtype=torch.float16,\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\nprompt = \"elden ring style castle\" # include the token \"elden ring style\" in the prompt\nnegative_prompt = \"bad architecture, deformed, disfigured, poor details\"\n\nimage_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image).images[0]\nmake_image_grid([init_image, mask_image, image, image_elden_ring], rows=2, cols=2)\n```", "```py\n+ pipeline.enable_xformers_memory_efficient_attention()\n+ pipeline.enable_model_cpu_offload()\n```", "```py\npipeline.unet = torch.compile(pipeline.unet, mode=\"reduce-overhead\", fullgraph=True)\n```"]