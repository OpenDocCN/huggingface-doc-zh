- en: Image Processor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/image_processor](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/image_processor)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: An image processor is in charge of preparing input features for vision models
    and post processing their outputs. This includes transformations such as resizing,
    normalization, and conversion to PyTorch, TensorFlow, Flax and Numpy tensors.
    It may also include model specific post-processing such as converting logits to
    segmentation masks.
  prefs: []
  type: TYPE_NORMAL
- en: ImageProcessingMixin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.ImageProcessingMixin`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L68)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This is an image processor mixin used to provide saving/loading functionality
    for sequential and image feature extractors.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `from_pretrained`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L95)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a string, the *model id* of a pretrained image_processor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a path to a *directory* containing a image processor file saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a path or url to a saved image processor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model image processor should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force to (re-)download the image processor files and override the cached versions
    if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received file. Attempts to resume the download if such
    a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}.` The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token` (`str` or `bool`, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, or not specified, will use the token generated when
    running `huggingface-cli login` (stored in `~/.huggingface`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate a type of [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    from an image processor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#### `save_pretrained`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L210)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`save_directory` (`str` or `os.PathLike`) — Directory where the image processor
    JSON file will be saved (will be created if it does not exist).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save an image processor object to the directory `save_directory`, so that it
    can be re-loaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.from_pretrained)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: BatchFeature
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.BatchFeature`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L61)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`data` (`dict`, *optional*) — Dictionary of lists/arrays/tensors returned by
    the **call**/pad methods (‘input_values’, ‘attention_mask’, etc.).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tensor_type` (`Union[None, str, TensorType]`, *optional*) — You can give a
    tensor_type here to convert the lists of integers in PyTorch/TensorFlow/Numpy
    Tensors at initialization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Holds the output of the [pad()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor.pad)
    and feature extractor specific `__call__` methods.
  prefs: []
  type: TYPE_NORMAL
- en: This class is derived from a python dictionary and can be used as a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `convert_to_tensors`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L164)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`tensor_type` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — The type of tensors to use. If `str`, should be one of the values
    of the enum [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType).
    If `None`, no modification is done.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert the inner content to tensors.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `to`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/feature_extraction_utils.py#L195)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`args` (`Tuple`) — Will be passed to the `to(...)` function of the tensors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kwargs` (`Dict`, *optional*) — Will be passed to the `to(...)` function of
    the tensors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[BatchFeature](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.BatchFeature)'
  prefs: []
  type: TYPE_NORMAL
- en: The same instance after modification.
  prefs: []
  type: TYPE_NORMAL
- en: Send all values to device by calling `v.to(*args, **kwargs)` (PyTorch only).
    This should support casting in different `dtypes` and sending the `BatchFeature`
    to a different `device`.
  prefs: []
  type: TYPE_NORMAL
- en: BaseImageProcessor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.image_processing_utils.BaseImageProcessor`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L546)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '#### `center_crop`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L626)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`np.ndarray`) — Image to center crop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`size` (`Dict[str, int]`) — Size of the output image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data_format` (`str` or `ChannelDimension`, *optional*) — The channel dimension
    format for the output image. If unset, the channel dimension format of the input
    image is used. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Center crop an image to `(size["height"], size["width"])`. If the input size
    is smaller than `crop_size` along any edge, the image is padded with 0’s and then
    center cropped.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `normalize`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L589)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`np.ndarray`) — Image to normalize.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mean` (`float` or `Iterable[float]`) — Image mean to use for normalization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std` (`float` or `Iterable[float]`) — Image standard deviation to use for
    normalization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data_format` (`str` or `ChannelDimension`, *optional*) — The channel dimension
    format for the output image. If unset, the channel dimension format of the input
    image is used. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: The normalized image.
  prefs: []
  type: TYPE_NORMAL
- en: Normalize an image. image = (image - image_mean) / image_std.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `rescale`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L557)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`np.ndarray`) — Image to rescale.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scale` (`float`) — The scaling factor to rescale pixel values by.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data_format` (`str` or `ChannelDimension`, *optional*) — The channel dimension
    format for the output image. If unset, the channel dimension format of the input
    image is used. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: The rescaled image.
  prefs: []
  type: TYPE_NORMAL
- en: Rescale an image by a scale factor. image = image * scale.
  prefs: []
  type: TYPE_NORMAL
