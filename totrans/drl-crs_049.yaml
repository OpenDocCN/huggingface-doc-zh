- en: Hands-on
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®è·µ
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit3/hands-on](https://huggingface.co/learn/deep-rl-course/unit3/hands-on)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/learn/deep-rl-course/unit3/hands-on](https://huggingface.co/learn/deep-rl-course/unit3/hands-on)
- en: '[![Ask a Question](../Images/255e59f8542cbd6d3f1c72646b2fff13.png)](http://hf.co/join/discord)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit3/unit3.ipynb)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[![æé—®](../Images/255e59f8542cbd6d3f1c72646b2fff13.png)](http://hf.co/join/discord)
    [![åœ¨ Colab ä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit3/unit3.ipynb)'
- en: Now that youâ€™ve studied the theory behind Deep Q-Learning, **youâ€™re ready to
    train your Deep Q-Learning agent to play Atari Games**. Weâ€™ll start with Space
    Invaders, but youâ€™ll be able to use any Atari game you want ğŸ”¥
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²ç»å­¦ä¹ äº†æ·±åº¦ Q å­¦ä¹ èƒŒåçš„ç†è®ºï¼Œ**æ‚¨å·²ç»å‡†å¤‡å¥½è®­ç»ƒæ‚¨çš„æ·±åº¦ Q å­¦ä¹ ä»£ç†ç© Atari æ¸¸æˆ**ã€‚æˆ‘ä»¬å°†ä» Space Invaders å¼€å§‹ï¼Œä½†æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•æ‚¨æƒ³è¦çš„
    Atari æ¸¸æˆğŸ”¥
- en: '![Environments](../Images/bf441b005cda192d0dc86eb42475aeb3.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![ç¯å¢ƒ](../Images/bf441b005cda192d0dc86eb42475aeb3.png)'
- en: Weâ€™re using the [RL-Baselines-3 Zoo integration](https://github.com/DLR-RM/rl-baselines3-zoo),
    a vanilla version of Deep Q-Learning with no extensions such as Double-DQN, Dueling-DQN,
    or Prioritized Experience Replay.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯[RL-Baselines-3 Zoo é›†æˆ](https://github.com/DLR-RM/rl-baselines3-zoo)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ²¡æœ‰
    Double-DQNã€Dueling-DQN æˆ– Prioritized Experience Replay ç­‰æ‰©å±•çš„æ·±åº¦ Q å­¦ä¹ çš„åŸºæœ¬ç‰ˆæœ¬ã€‚
- en: 'Also, **if you want to learn to implement Deep Q-Learning by yourself after
    this hands-on**, you definitely should look at the CleanRL implementation: [https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py](https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œ**å¦‚æœæ‚¨æƒ³åœ¨æ­¤å®è·µä¹‹åè‡ªå·±å­¦ä¹ å®ç°æ·±åº¦ Q å­¦ä¹ **ï¼Œæ‚¨ç»å¯¹åº”è¯¥æŸ¥çœ‹ CleanRL å®ç°ï¼š[https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py](https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py)
- en: To validate this hands-on for the certification process, you need to push your
    trained model to the Hub and **get a result of >= 200**.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¦éªŒè¯æ­¤å®è·µä»¥è¿›è¡Œè®¤è¯è¿‡ç¨‹ï¼Œæ‚¨éœ€è¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ° Hub å¹¶**è·å¾— >= 200 çš„ç»“æœ**ã€‚
- en: To find your result, go to the leaderboard and find your model, **the result
    = mean_reward - std of reward**
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ‰¾åˆ°æ‚¨çš„ç»“æœï¼Œè¯·è½¬åˆ°æ’è¡Œæ¦œå¹¶æ‰¾åˆ°æ‚¨çš„æ¨¡å‹ï¼Œ**ç»“æœ = å¹³å‡å¥–åŠ± - å¥–åŠ±çš„æ ‡å‡†å·®**
- en: '**If you donâ€™t find your model, go to the bottom of the page and click on the
    refresh button.**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¦‚æœæ‰¾ä¸åˆ°æ‚¨çš„æ¨¡å‹ï¼Œè¯·è½¬åˆ°é¡µé¢åº•éƒ¨å¹¶ç‚¹å‡»åˆ·æ–°æŒ‰é’®ã€‚**'
- en: For more information about the certification process, check this section ğŸ‘‰ [https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³è®¤è¯è¿‡ç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ†ğŸ‘‰[https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)
- en: And you can check your progress here ğŸ‘‰ [https://huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course](https://huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨è¿™é‡Œæ£€æŸ¥æ‚¨çš„è¿›åº¦ğŸ‘‰[https://huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course](https://huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course)
- en: '**To start the hands-on click on Open In Colab button** ğŸ‘‡ :'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¦å¼€å§‹å®è·µï¼Œè¯·ç‚¹å‡»â€œåœ¨ Colab ä¸­æ‰“å¼€â€æŒ‰é’®**ğŸ‘‡ï¼š'
- en: '[![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit3/unit3.ipynb)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[![åœ¨ Colab ä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit3/unit3.ipynb)'
- en: 'Unit 3: Deep Q-Learning with Atari Games ğŸ‘¾ using RL Baselines3 Zoo'
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰å•å…ƒï¼šä½¿ç”¨ RL Baselines3 Zoo è¿›è¡Œ Atari æ¸¸æˆçš„æ·±åº¦ Q å­¦ä¹  ğŸ‘¾
- en: '![Unit 3 Thumbnail](../Images/e8420d1d9f22aa4095ae8b961c412a91.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![ç¬¬ä¸‰å•å…ƒç¼©ç•¥å›¾](../Images/e8420d1d9f22aa4095ae8b961c412a91.png)'
- en: In this hands-on, **youâ€™ll train a Deep Q-Learning agent** playing Space Invaders
    using [RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo), a training
    framework based on [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)
    that provides scripts for training, evaluating agents, tuning hyperparameters,
    plotting results and recording videos.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªå®è·µä¸­ï¼Œ**æ‚¨å°†è®­ç»ƒä¸€ä¸ªæ·±åº¦ Q å­¦ä¹ ä»£ç†**æ¥ç© Space Invadersï¼Œä½¿ç”¨çš„æ˜¯åŸºäº[Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)çš„è®­ç»ƒæ¡†æ¶[RL
    Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)ï¼Œè¯¥æ¡†æ¶æä¾›äº†ç”¨äºè®­ç»ƒã€è¯„ä¼°ä»£ç†ã€è°ƒæ•´è¶…å‚æ•°ã€ç»˜åˆ¶ç»“æœå’Œå½•åˆ¶è§†é¢‘çš„è„šæœ¬ã€‚
- en: Weâ€™re using the [RL-Baselines-3 Zoo integration, a vanilla version of Deep Q-Learning](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html)
    with no extensions such as Double-DQN, Dueling-DQN, and Prioritized Experience
    Replay.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯[RL-Baselines-3 Zoo é›†æˆï¼Œä¸€ä¸ªåŸºæœ¬ç‰ˆæœ¬çš„æ·±åº¦ Q å­¦ä¹ ](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html)ï¼Œæ²¡æœ‰
    Double-DQNã€Dueling-DQN å’Œ Prioritized Experience Replay ç­‰æ‰©å±•ã€‚
- en: 'ğŸ® Environments:'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'ğŸ® ç¯å¢ƒ:'
- en: '[SpacesInvadersNoFrameskip-v4](https://gymnasium.farama.org/environments/atari/space_invaders/)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SpacesInvadersNoFrameskip-v4](https://gymnasium.farama.org/environments/atari/space_invaders/)'
- en: You can see the difference between Space Invaders versions here ğŸ‘‰ [https://gymnasium.farama.org/environments/atari/space_invaders/#variants](https://gymnasium.farama.org/environments/atari/space_invaders/#variants)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹ Space Invaders ç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚ğŸ‘‰[https://gymnasium.farama.org/environments/atari/space_invaders/#variants](https://gymnasium.farama.org/environments/atari/space_invaders/#variants)
- en: 'ğŸ“š RL-Library:'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'ğŸ“š RL-Library:'
- en: '[RL-Baselines3-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RL-Baselines3-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)'
- en: Objectives of this hands-on ğŸ†
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¤å®è·µçš„ç›®æ ‡ ğŸ†
- en: 'At the end of the hands-on, you will:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®è·µç»“æŸæ—¶ï¼Œæ‚¨å°†ï¼š
- en: Be able to understand deeper **how RL Baselines3 Zoo works**.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: èƒ½å¤Ÿæ›´æ·±å…¥åœ°ç†è§£**RL Baselines3 Zoo çš„å·¥ä½œåŸç†**ã€‚
- en: Be able to **push your trained agent and the code to the Hub** with a nice video
    replay and an evaluation score ğŸ”¥.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: èƒ½å¤Ÿ**å°†è®­ç»ƒå¥½çš„ä»£ç†å’Œä»£ç æ¨é€åˆ° Hub**ï¼Œå¹¶é™„å¸¦ä¸€ä¸ªæ¼‚äº®çš„è§†é¢‘å›æ”¾å’Œè¯„ä¼°åˆ†æ•°ğŸ”¥ã€‚
- en: Prerequisites ğŸ—ï¸
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…ˆå†³æ¡ä»¶ ğŸ—ï¸
- en: 'Before diving into the hands-on, you need to:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ·±å…¥å®è·µä¹‹å‰ï¼Œæ‚¨éœ€è¦ï¼š
- en: ğŸ”² ğŸ“š **[Study Deep Q-Learning by reading Unit 3](https://huggingface.co/deep-rl-course/unit3/introduction)**
    ğŸ¤—
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”² ğŸ“š **[é€šè¿‡é˜…è¯»ç¬¬ä¸‰å•å…ƒå­¦ä¹ æ·±åº¦ Q å­¦ä¹ ](https://huggingface.co/deep-rl-course/unit3/introduction)**
    ğŸ¤—
- en: Weâ€™re constantly trying to improve our tutorials, so **if you find some issues
    in this hands-on**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸æ–­åŠªåŠ›æ”¹è¿›æˆ‘ä»¬çš„æ•™ç¨‹ï¼Œæ‰€ä»¥**å¦‚æœæ‚¨åœ¨è¿™ä¸ªå®è·µä¸­å‘ç°äº†ä¸€äº›é—®é¢˜**ï¼Œè¯·[åœ¨ Github Repo ä¸Šæå‡ºé—®é¢˜](https://github.com/huggingface/deep-rl-class/issues)ã€‚
- en: Letâ€™s train a Deep Q-Learning agent playing Atariâ€™ Space Invaders ğŸ‘¾ and upload
    it to the Hub.
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªç© Atari å¤ªç©ºä¾µç•¥è€…çš„æ·±åº¦ Q å­¦ä¹ æ™ºèƒ½ä½“ğŸ‘¾ å¹¶å°†å…¶ä¸Šä¼ åˆ° Hubã€‚
- en: We strongly recommend students **to use Google Colab for the hands-on exercises
    instead of running them on their personal computers**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼ºçƒˆå»ºè®®å­¦ç”Ÿ**ä½¿ç”¨ Google Colab è¿›è¡Œå®è·µç»ƒä¹ ï¼Œè€Œä¸æ˜¯åœ¨ä¸ªäººè®¡ç®—æœºä¸Šè¿è¡Œå®ƒä»¬**ã€‚
- en: By using Google Colab, **you can focus on learning and experimenting without
    worrying about the technical aspects of setting up your environments**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä½¿ç”¨ Google Colabï¼Œ**æ‚¨å¯ä»¥ä¸“æ³¨äºå­¦ä¹ å’Œå®éªŒï¼Œè€Œä¸å¿…æ‹…å¿ƒè®¾ç½®ç¯å¢ƒçš„æŠ€æœ¯ç»†èŠ‚**ã€‚
- en: To validate this hands-on for the certification process, you need to push your
    trained model to the Hub and **get a result of >= 200**.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†éªŒè¯è¿™ä¸ªå®è·µè¿‡ç¨‹çš„è®¤è¯ï¼Œæ‚¨éœ€è¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ° Hub å¹¶**è·å¾— >= 200 çš„ç»“æœ**ã€‚
- en: To find your result, go to the leaderboard and find your model, **the result
    = mean_reward - std of reward**
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ‰¾åˆ°æ‚¨çš„ç»“æœï¼Œè¯·è½¬åˆ°æ’è¡Œæ¦œå¹¶æ‰¾åˆ°æ‚¨çš„æ¨¡å‹ï¼Œ**ç»“æœ = å¹³å‡å¥–åŠ± - å¥–åŠ±çš„æ ‡å‡†å·®**
- en: For more information about the certification process, check this section ğŸ‘‰ [https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³è®¤è¯æµç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ†ğŸ‘‰ [https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)
- en: Set the GPU ğŸ’ª
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¾ç½® GPU ğŸ’ª
- en: To **accelerate the agentâ€™s training, weâ€™ll use a GPU**. To do that, go to `Runtime
    > Change Runtime type`
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†**åŠ é€Ÿæ™ºèƒ½ä½“çš„è®­ç»ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ GPU**ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œè½¬åˆ°`Runtime > Change Runtime type`
- en: '![GPU Step 1](../Images/5378127c314cdd92729aa31b7e11ca44.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![GPU æ­¥éª¤ 1](../Images/5378127c314cdd92729aa31b7e11ca44.png)'
- en: '`Hardware Accelerator > GPU`'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ç¡¬ä»¶åŠ é€Ÿå™¨ > GPU`'
- en: '![GPU Step 2](../Images/e0fec252447f98378386ccca8e57a80a.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![GPU æ­¥éª¤ 2](../Images/e0fec252447f98378386ccca8e57a80a.png)'
- en: Install RL-Baselines3 Zoo and its dependencies ğŸ“š
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®‰è£… RL-Baselines3 Zoo åŠå…¶ä¾èµ–é¡¹ğŸ“š
- en: 'If you see `ERROR: pip''s dependency resolver does not currently take into
    account all the packages that are installed.` **this is normal and itâ€™s not a
    critical error** thereâ€™s a conflict of version. But the packages we need are installed.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¦‚æœä½ çœ‹åˆ°`ERROR: pip''s dependency resolver does not currently take into account
    all the packages that are installed.` **è¿™æ˜¯æ­£å¸¸çš„ï¼Œä¸æ˜¯å…³é”®é”™è¯¯** è¿™æ˜¯ç‰ˆæœ¬å†²çªã€‚ä½†æˆ‘ä»¬éœ€è¦çš„åŒ…å·²ç»å®‰è£…å¥½äº†ã€‚'
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: IF AND ONLY IF THE VERSION ABOVE DOES NOT EXIST ANYMORE. UNCOMMENT AND INSTALL
    THE ONE BELOW
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸Šé¢çš„ç‰ˆæœ¬ä¸å†å­˜åœ¨ã€‚å–æ¶ˆæ³¨é‡Šå¹¶å®‰è£…ä¸‹é¢çš„ç‰ˆæœ¬
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To be able to use Atari games in Gymnasium we need to install atari package.
    And accept-rom-license to download the rom files (games files).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†èƒ½å¤Ÿåœ¨ Gymnasium ä¸­ä½¿ç”¨ Atari æ¸¸æˆï¼Œæˆ‘ä»¬éœ€è¦å®‰è£… atari åŒ…ã€‚å¹¶æ¥å— rom è®¸å¯è¯ä»¥ä¸‹è½½ rom æ–‡ä»¶ï¼ˆæ¸¸æˆæ–‡ä»¶ï¼‰ã€‚
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Create a virtual display ğŸ”½
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿæ˜¾ç¤ºğŸ”½
- en: During the hands-on, weâ€™ll need to generate a replay video. To do so, if you
    train it on a headless machine, **we need to have a virtual screen to be able
    to render the environment** (and thus record the frames).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®è·µè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆä¸€ä¸ªé‡æ’­è§†é¢‘ã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œå¦‚æœæ‚¨åœ¨æ— å¤´æœºå™¨ä¸Šè®­ç»ƒå®ƒï¼Œ**æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªè™šæ‹Ÿå±å¹•æ¥èƒ½å¤Ÿæ¸²æŸ“ç¯å¢ƒ**ï¼ˆä»è€Œè®°å½•å¸§ï¼‰ã€‚
- en: Hence the following cell will install the librairies and create and run a virtual
    screen ğŸ–¥
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä»¥ä¸‹å•å…ƒæ ¼å°†å®‰è£…åº“å¹¶åˆ›å»ºå¹¶è¿è¡Œä¸€ä¸ªè™šæ‹Ÿå±å¹•ğŸ–¥
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Train our Deep Q-Learning Agent to Play Space Invaders ğŸ‘¾
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒæˆ‘ä»¬çš„æ·±åº¦ Q å­¦ä¹ æ™ºèƒ½ä½“ç©å¤ªç©ºä¾µç•¥è€… ğŸ‘¾
- en: 'To train an agent with RL-Baselines3-Zoo, we just need to do two things:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨ RL-Baselines3-Zoo è®­ç»ƒä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œæˆ‘ä»¬åªéœ€è¦åšä¸¤ä»¶äº‹ï¼š
- en: Create a hyperparameter config file that will contain our training hyperparameters
    called `dqn.yml`.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªåŒ…å«æˆ‘ä»¬è®­ç»ƒè¶…å‚æ•°çš„è¶…å‚æ•°é…ç½®æ–‡ä»¶ï¼Œåä¸º`dqn.yml`ã€‚
- en: 'This is a template example:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæ¨¡æ¿ç¤ºä¾‹ï¼š
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here we see that:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°ï¼š
- en: We use the `Atari Wrapper` that preprocess the input (Frame reduction ,grayscale,
    stack 4 frames)
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨`Atari Wrapper`å¯¹è¾“å…¥è¿›è¡Œé¢„å¤„ç†ï¼ˆå¸§ç¼©å‡ï¼Œç°åº¦åŒ–ï¼Œå †å  4 å¸§ï¼‰
- en: We use `CnnPolicy`, since we use Convolutional layers to process the frames
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨`CnnPolicy`ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨å·ç§¯å±‚æ¥å¤„ç†å¸§
- en: We train it for 10 million `n_timesteps`
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸º 1000 ä¸‡ä¸ª`n_timesteps`è¿›è¡Œè®­ç»ƒ
- en: Memory (Experience Replay) size is 100000, aka the amount of experience steps
    you saved to train again your agent with.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…å­˜ï¼ˆç»éªŒé‡æ”¾ï¼‰å¤§å°ä¸º 100000ï¼Œå³æ‚¨ä¿å­˜çš„ç»éªŒæ­¥æ•°ï¼Œç”¨äºå†æ¬¡è®­ç»ƒæ‚¨çš„æ™ºèƒ½ä½“ã€‚
- en: 'ğŸ’¡ My advice is to **reduce the training timesteps to 1M,** which will take
    about 90 minutes on a P100\. `!nvidia-smi` will tell you what GPU youâ€™re using.
    At 10 million steps, this will take about 9 hours. I recommend running this on
    your local computer (or somewhere else). Just click on: `File>Download`.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡ æˆ‘çš„å»ºè®®æ˜¯**å°†è®­ç»ƒæ­¥éª¤å‡å°‘åˆ° 1M**ï¼Œè¿™å°†åœ¨ P100 ä¸ŠèŠ±è´¹çº¦ 90 åˆ†é’Ÿã€‚`!nvidia-smi`ä¼šå‘Šè¯‰æ‚¨æ­£åœ¨ä½¿ç”¨çš„ GPUã€‚åœ¨ 1000
    ä¸‡æ­¥éª¤ä¸­ï¼Œè¿™å°†èŠ±è´¹çº¦ 9 å°æ—¶ã€‚æˆ‘å»ºè®®åœ¨æ‚¨çš„æœ¬åœ°è®¡ç®—æœºä¸Šè¿è¡Œæ­¤æ“ä½œï¼ˆæˆ–å…¶ä»–åœ°æ–¹ï¼‰ã€‚åªéœ€ç‚¹å‡»ï¼š`File>Download`ã€‚
- en: 'In terms of hyperparameters optimization, my advice is to focus on these 3
    hyperparameters:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¶…å‚æ•°ä¼˜åŒ–æ–¹é¢ï¼Œæˆ‘çš„å»ºè®®æ˜¯ä¸“æ³¨äºè¿™ 3 ä¸ªè¶…å‚æ•°ï¼š
- en: '`learning_rate`'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate`'
- en: '`buffer_size (Experience Memory size)`'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`buffer_size (ç»éªŒè®°å¿†å¤§å°)`'
- en: '`batch_size`'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size`'
- en: 'As a good practice, you need to **check the documentation to understand what
    each hyperparameters does**: [https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€ä¸ªè‰¯å¥½çš„å®è·µï¼Œæ‚¨éœ€è¦**æŸ¥çœ‹æ–‡æ¡£ä»¥äº†è§£æ¯ä¸ªè¶…å‚æ•°çš„ä½œç”¨**ï¼š[https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters)
- en: We start the training and save the models on `logs` folder ğŸ“
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼€å§‹è®­ç»ƒå¹¶å°†æ¨¡å‹ä¿å­˜åœ¨`logs`æ–‡ä»¶å¤¹ğŸ“
- en: Define the algorithm after `--algo`, where we save the model after `-f` and
    where the hyperparameter config is after `-c`.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨`--algo`ä¹‹åå®šä¹‰ç®—æ³•ï¼Œåœ¨`-f`ä¹‹åä¿å­˜æ¨¡å‹ï¼Œåœ¨`-c`ä¹‹åæ˜¯è¶…å‚æ•°é…ç½®ã€‚
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Solution
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è§£å†³æ–¹æ¡ˆ
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Letâ€™s evaluate our agent ğŸ‘€
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¯„ä¼°æˆ‘ä»¬çš„æ™ºèƒ½ä½“ğŸ‘€
- en: RL-Baselines3-Zoo provides `enjoy.py`, a python script to evaluate our agent.
    In most RL libraries, we call the evaluation script `enjoy.py`.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RL-Baselines3-Zoo æä¾›äº†`enjoy.py`ï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°æˆ‘ä»¬æ™ºèƒ½ä½“çš„ Python è„šæœ¬ã€‚åœ¨å¤§å¤šæ•° RL åº“ä¸­ï¼Œæˆ‘ä»¬å°†è¯„ä¼°è„šæœ¬ç§°ä¸º`enjoy.py`ã€‚
- en: Letâ€™s evaluate it for 5000 timesteps ğŸ”¥
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¯¹å…¶è¿›è¡Œ 5000 ä¸ªæ—¶é—´æ­¥çš„è¯„ä¼°ğŸ”¥
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Solution
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è§£å†³æ–¹æ¡ˆ
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Publish our trained model on the Hub ğŸš€
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨ Hub ä¸Šå‘å¸ƒæˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹ğŸš€
- en: Now that we saw we got good results after the training, we can publish our trained
    model on the hub ğŸ¤— with one line of code.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çœ‹åˆ°è®­ç»ƒåè·å¾—äº†è‰¯å¥½çš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€è¡Œä»£ç å°†æˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹å‘å¸ƒåˆ° Hub ğŸ¤—ã€‚
- en: '![Space Invaders model](../Images/8ae15c5c6ac1a3242637770ca390f7e1.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![å¤ªç©ºä¾µç•¥è€…æ¨¡å‹](../Images/8ae15c5c6ac1a3242637770ca390f7e1.png)'
- en: By using `rl_zoo3.push_to_hub` **you evaluate, record a replay, generate a model
    card of your agent and push it to the hub**.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä½¿ç”¨`rl_zoo3.push_to_hub` **æ‚¨å¯ä»¥è¯„ä¼°ã€è®°å½•é‡æ’­ã€ç”Ÿæˆæ‚¨çš„ä»£ç†çš„æ¨¡å‹å¡å¹¶å°†å…¶æ¨é€åˆ°hub**ã€‚
- en: 'This way:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·ï¼š
- en: You can **showcase our work** ğŸ”¥
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥å±•ç¤ºæˆ‘ä»¬çš„å·¥ä½œğŸ”¥
- en: You can **visualize your agent playing** ğŸ‘€
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥**è§‚çœ‹æ‚¨çš„ä»£ç†ç©**ğŸ‘€
- en: You can **share with the community an agent that others can use** ğŸ’¾
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥**ä¸ç¤¾åŒºåˆ†äº«å…¶ä»–äººå¯ä»¥ä½¿ç”¨çš„ä»£ç†**ğŸ’¾
- en: You can **access a leaderboard ğŸ† to see how well your agent is performing compared
    to your classmates** ğŸ‘‰ [https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥**è®¿é—®æ’è¡Œæ¦œğŸ†ï¼ŒæŸ¥çœ‹æ‚¨çš„ä»£ç†ä¸åŒå­¦ç›¸æ¯”è¡¨ç°å¦‚ä½•**ğŸ‘‰ [https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)
- en: 'To be able to share your model with the community there are three more steps
    to follow:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: è¦èƒ½å¤Ÿä¸ç¤¾åŒºåˆ†äº«æ‚¨çš„æ¨¡å‹ï¼Œè¿˜æœ‰ä¸‰ä¸ªæ­¥éª¤è¦éµå¾ªï¼š
- en: 1ï¸âƒ£ (If itâ€™s not already done) create an account to HF â¡ [https://huggingface.co/join](https://huggingface.co/join)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰åˆ›å»ºä¸€ä¸ªHFè´¦æˆ· â¡ [https://huggingface.co/join](https://huggingface.co/join)
- en: 2ï¸âƒ£ Sign in and then, you need to store your authentication token from the Hugging
    Face website.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ç™»å½•ï¼Œç„¶åï¼Œæ‚¨éœ€è¦ä»Hugging Faceç½‘ç«™å­˜å‚¨æ‚¨çš„èº«ä»½éªŒè¯ä»¤ç‰Œã€‚
- en: Create a new token ([https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))
    **with write role**
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªæ–°çš„ä»¤ç‰Œï¼ˆ[https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)ï¼‰**å…·æœ‰å†™å…¥è§’è‰²**
- en: '![Create HF Token](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![åˆ›å»ºHFä»¤ç‰Œ](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
- en: Copy the token
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤åˆ¶ä»¤ç‰Œ
- en: Run the cell below and past the token
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼å¹¶ç²˜è´´ä»¤ç‰Œ
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If you donâ€™t want to use a Google Colab or a Jupyter Notebook, you need to
    use this command instead: `huggingface-cli login`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä¸æƒ³ä½¿ç”¨Google Colabæˆ–Jupyter Notebookï¼Œæ‚¨éœ€è¦ä½¿ç”¨è¿™ä¸ªå‘½ä»¤ï¼š`huggingface-cli login`
- en: 3ï¸âƒ£ Weâ€™re now ready to push our trained agent to the ğŸ¤— Hub ğŸ”¥
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 3ï¸âƒ£æˆ‘ä»¬ç°åœ¨å‡†å¤‡å°†æˆ‘ä»¬è®­ç»ƒçš„ä»£ç†æ¨é€åˆ°ğŸ¤— HubğŸ”¥
- en: Letâ€™s run push_to_hub.py file to upload our trained agent to the Hub.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿è¡Œpush_to_hub.pyæ–‡ä»¶å°†æˆ‘ä»¬è®­ç»ƒçš„ä»£ç†ä¸Šä¼ åˆ°Hubã€‚
- en: '`--repo-name` : The name of the repo'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`--repo-name`ï¼šå­˜å‚¨åº“çš„åç§°'
- en: '`-orga`: Your Hugging Face username'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`-orga`ï¼šæ‚¨çš„Hugging Faceç”¨æˆ·å'
- en: '`-f`: Where the trained model folder is (in our case `logs`)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`-f`ï¼šè®­ç»ƒæ¨¡å‹æ–‡ä»¶å¤¹æ‰€åœ¨ä½ç½®ï¼ˆåœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ä¸º`logs`ï¼‰'
- en: '![Select Id](../Images/6f04c3f40368af928c98d0979b5abbe5.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![é€‰æ‹©ID](../Images/6f04c3f40368af928c98d0979b5abbe5.png)'
- en: '[PRE12]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Solution
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è§£å†³æ–¹æ¡ˆ
- en: '[PRE13]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '###.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '###ã€‚'
- en: 'Congrats ğŸ¥³ youâ€™ve just trained and uploaded your first Deep Q-Learning agent
    using RL-Baselines-3 Zoo. The script above should have displayed a link to a model
    repository such as [https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4](https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4).
    When you go to this link, you can:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œğŸ¥³æ‚¨åˆšåˆšä½¿ç”¨RL-Baselines-3 Zooè®­ç»ƒå’Œä¸Šä¼ äº†æ‚¨çš„ç¬¬ä¸€ä¸ªDeep Q-Learningä»£ç†ã€‚ä¸Šé¢çš„è„šæœ¬åº”è¯¥æ˜¾ç¤ºäº†ä¸€ä¸ªæŒ‡å‘æ¨¡å‹å­˜å‚¨åº“çš„é“¾æ¥ï¼Œä¾‹å¦‚[https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4](https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4)ã€‚å½“æ‚¨è®¿é—®æ­¤é“¾æ¥æ—¶ï¼Œæ‚¨å¯ä»¥ï¼š
- en: See a **video preview of your agent** at the right.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å³ä¾§æŸ¥çœ‹**ä»£ç†çš„è§†é¢‘é¢„è§ˆ**ã€‚
- en: Click â€œFiles and versionsâ€ to see all the files in the repository.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‚¹å‡»â€œæ–‡ä»¶å’Œç‰ˆæœ¬â€æŸ¥çœ‹å­˜å‚¨åº“ä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚
- en: Click â€œUse in stable-baselines3â€ to get a code snippet that shows how to load
    the model.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‚¹å‡»â€œåœ¨stable-baselines3ä¸­ä½¿ç”¨â€è·å–æ˜¾ç¤ºå¦‚ä½•åŠ è½½æ¨¡å‹çš„ä»£ç ç‰‡æ®µã€‚
- en: A model card (`README.md` file) which gives a description of the model and the
    hyperparameters you used.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ¨¡å‹å¡ï¼ˆ`README.md`æ–‡ä»¶ï¼‰ï¼Œå…¶ä¸­åŒ…å«å¯¹æ¨¡å‹å’Œæ‚¨ä½¿ç”¨çš„è¶…å‚æ•°çš„æè¿°ã€‚
- en: Under the hood, the Hub uses git-based repositories (donâ€™t worry if you donâ€™t
    know what git is), which means you can update the model with new versions as you
    experiment and improve your agent.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¹•åï¼ŒHubä½¿ç”¨åŸºäºgitçš„å­˜å‚¨åº“ï¼ˆå¦‚æœæ‚¨ä¸çŸ¥é“gitæ˜¯ä»€ä¹ˆï¼Œä¸ç”¨æ‹…å¿ƒï¼‰ï¼Œè¿™æ„å‘³ç€æ‚¨å¯ä»¥éšç€å®éªŒå’Œæ”¹è¿›æ‚¨çš„ä»£ç†æ›´æ–°æ¨¡å‹çš„æ–°ç‰ˆæœ¬ã€‚
- en: '**Compare the results of your agents with your classmates** using the [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)
    ğŸ†'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ä¸åŒå­¦æ¯”è¾ƒæ‚¨çš„ä»£ç†çš„ç»“æœ**ğŸ†'
- en: Load a powerful trained model ğŸ”¥
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ è½½ä¸€ä¸ªå¼ºå¤§çš„è®­ç»ƒæ¨¡å‹ğŸ”¥
- en: The Stable-Baselines3 team uploaded **more than 150 trained Deep Reinforcement
    Learning agents on the Hub**.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stable-Baselines3å›¢é˜Ÿåœ¨Hubä¸Šä¸Šä¼ äº†**è¶…è¿‡150ä¸ªè®­ç»ƒæœ‰ç´ çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†**ã€‚
- en: 'You can find them here: ğŸ‘‰ [https://huggingface.co/sb3](https://huggingface.co/sb3)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°å®ƒä»¬ï¼šğŸ‘‰ [https://huggingface.co/sb3](https://huggingface.co/sb3)
- en: 'Some examples:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›ç¤ºä¾‹ï¼š
- en: 'Asteroids: [https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4](https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Asteroids: [https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4](https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4)'
- en: 'Beam Rider: [https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4](https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Beam Rider: [https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4](https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4)'
- en: 'Breakout: [https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4](https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Breakout: [https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4](https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4)'
- en: 'Road Runner: [https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4](https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Road Runner: [https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4](https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4)'
- en: 'Letâ€™s load an agent playing Beam Rider: [https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4](https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªç©Beam Riderçš„ä»£ç†ï¼š[https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4](https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4)
- en: We download the model using `rl_zoo3.load_from_hub`, and place it in a new folder
    that we can call `rl_trained`
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨`rl_zoo3.load_from_hub`ä¸‹è½½æ¨¡å‹ï¼Œå¹¶å°†å…¶æ”¾åœ¨ä¸€ä¸ªæ–°æ–‡ä»¶å¤¹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç§°ä¹‹ä¸º`rl_trained`
- en: '[PRE14]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Letâ€™s evaluate if for 5000 timesteps
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¯„ä¼°5000ä¸ªæ—¶é—´æ­¥é•¿
- en: '[PRE15]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Why not trying to train your own **Deep Q-Learning Agent playing BeamRiderNoFrameskip-v4?
    ğŸ†.**
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆä¸å°è¯•è®­ç»ƒæ‚¨è‡ªå·±çš„**Deep Q-Learningä»£ç†ç©BeamRiderNoFrameskip-v4ï¼ŸğŸ†ã€‚**
- en: If you want to try, check [https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4#hyperparameters](https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4#hyperparameters)
    **in the model card, you have the hyperparameters of the trained agent.**
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³å°è¯•ï¼Œè¯·æŸ¥çœ‹[https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4#hyperparameters](https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4#hyperparameters)
    **åœ¨æ¨¡å‹å¡ä¸­ï¼Œæ‚¨å¯ä»¥çœ‹åˆ°è®­ç»ƒä»£ç†çš„è¶…å‚æ•°ã€‚**
- en: But finding hyperparameters can be a daunting task. Fortunately, weâ€™ll see in
    the next Unit, how we can **use Optuna for optimizing the Hyperparameters ğŸ”¥.**
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æ‰¾åˆ°è¶…å‚æ•°å¯èƒ½æ˜¯ä¸€é¡¹è‰°å·¨çš„ä»»åŠ¡ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ä¸ªå•å…ƒä¸­çœ‹åˆ°å¦‚ä½•**ä½¿ç”¨Optunaæ¥ä¼˜åŒ–è¶…å‚æ•°ğŸ”¥ã€‚**
- en: Some additional challenges ğŸ†
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸€äº›é¢å¤–çš„æŒ‘æˆ˜ğŸ†
- en: The best way to learn **is to try things by your own**!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å­¦ä¹ çš„æœ€ä½³æ–¹å¼æ˜¯**è‡ªå·±å°è¯•**ï¼
- en: In the [Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)
    you will find your agents. Can you get to the top?
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ä¸­ï¼Œæ‚¨å°†æ‰¾åˆ°æ‚¨çš„ä»£ç†ã€‚æ‚¨èƒ½ç™»é¡¶å—ï¼Ÿ
- en: 'Hereâ€™s a list of environments you can try to train your agent with:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥å°è¯•è®­ç»ƒä»£ç†çš„ç¯å¢ƒåˆ—è¡¨ï¼š
- en: BeamRiderNoFrameskip-v4
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BeamRiderNoFrameskip-v4
- en: BreakoutNoFrameskip-v4
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BreakoutNoFrameskip-v4
- en: EnduroNoFrameskip-v4
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EnduroNoFrameskip-v4
- en: PongNoFrameskip-v4
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PongNoFrameskip-v4
- en: 'Also, **if you want to learn to implement Deep Q-Learning by yourself**, you
    definitely should look at CleanRL implementation: [https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py](https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œ**å¦‚æœæ‚¨æƒ³è‡ªå·±å­¦ä¹ å®ç°æ·±åº¦Qå­¦ä¹ **ï¼Œæ‚¨ç»å¯¹åº”è¯¥æŸ¥çœ‹CleanRLçš„å®ç°ï¼š[https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py](https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py)
- en: '![Environments](../Images/bf441b005cda192d0dc86eb42475aeb3.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![ç¯å¢ƒ](../Images/bf441b005cda192d0dc86eb42475aeb3.png)'
- en: '* * *'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Congrats on finishing this chapter!
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œæ‚¨å®Œæˆäº†æœ¬ç« ï¼
- en: If youâ€™re still feel confused with all these elementsâ€¦itâ€™s totally normal! **This
    was the same for me and for all people who studied RL.**
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä»ç„¶å¯¹æ‰€æœ‰è¿™äº›å…ƒç´ æ„Ÿåˆ°å›°æƒ‘...è¿™æ˜¯å®Œå…¨æ­£å¸¸çš„ï¼**å¯¹æˆ‘å’Œæ‰€æœ‰å­¦ä¹ RLçš„äººæ¥è¯´éƒ½æ˜¯å¦‚æ­¤ã€‚**
- en: Take time to really **grasp the material before continuing and try the additional
    challenges**. Itâ€™s important to master these elements and having a solid foundations.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»§ç»­ä¹‹å‰èŠ±æ—¶é—´çœŸæ­£**æŒæ¡ææ–™å¹¶å°è¯•é¢å¤–çš„æŒ‘æˆ˜**ã€‚æŒæ¡è¿™äº›å…ƒç´ å¹¶å»ºç«‹åšå®çš„åŸºç¡€éå¸¸é‡è¦ã€‚
- en: In the next unit, **weâ€™re going to learn about [Optuna](https://optuna.org/)**.
    One of the most critical task in Deep Reinforcement Learning is to find a good
    set of training hyperparameters. And Optuna is a library that helps you to automate
    the search.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€ä¸ªå•å…ƒä¸­ï¼Œ**æˆ‘ä»¬å°†å­¦ä¹ æœ‰å…³[Optuna](https://optuna.org/)çš„å†…å®¹**ã€‚åœ¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ‰¾åˆ°ä¸€ç»„è‰¯å¥½çš„è®­ç»ƒè¶…å‚æ•°æ˜¯æœ€å…³é”®çš„ä»»åŠ¡ä¹‹ä¸€ã€‚Optunaæ˜¯ä¸€ä¸ªå¸®åŠ©æ‚¨è‡ªåŠ¨åŒ–æœç´¢çš„åº“ã€‚
- en: This is a course built with you ğŸ‘·ğŸ¿â€â™€ï¸
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªä¸æ‚¨å…±åŒæ„å»ºçš„è¯¾ç¨‹ğŸ‘·ğŸ¿â€â™€ï¸
- en: Finally, we want to improve and update the course iteratively with your feedback.
    If you have some, please fill this form ğŸ‘‰ [https://forms.gle/3HgA7bEHwAmmLfwh9](https://forms.gle/3HgA7bEHwAmmLfwh9)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¸Œæœ›æ ¹æ®æ‚¨çš„åé¦ˆé€æ­¥æ”¹è¿›å’Œæ›´æ–°è¯¾ç¨‹ã€‚å¦‚æœæ‚¨æœ‰æ„è§ï¼Œè¯·å¡«å†™æ­¤è¡¨æ ¼ğŸ‘‰ [https://forms.gle/3HgA7bEHwAmmLfwh9](https://forms.gle/3HgA7bEHwAmmLfwh9)
- en: Weâ€™re constantly trying to improve our tutorials, so **if you find some issues
    in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸æ–­åŠªåŠ›æ”¹è¿›æˆ‘ä»¬çš„æ•™ç¨‹ï¼Œæ‰€ä»¥**å¦‚æœæ‚¨åœ¨æœ¬ç¬”è®°æœ¬ä¸­å‘ç°é—®é¢˜**ï¼Œè¯·[åœ¨Github Repoä¸Šæå‡ºé—®é¢˜](https://github.com/huggingface/deep-rl-class/issues)ã€‚
- en: See you on Bonus unit 2! ğŸ”¥
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨å¥–åŠ±å•å…ƒ2è§ï¼ğŸ”¥
- en: Keep Learning, Stay Awesome ğŸ¤—
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»§ç»­å­¦ä¹ ï¼Œä¿æŒç²¾å½©ğŸ¤—
