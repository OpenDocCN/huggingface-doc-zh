- en: DPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DPT
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/dpt](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/dpt)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/dpt](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/dpt)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The DPT model was proposed in [Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413)
    by René Ranftl, Alexey Bochkovskiy, Vladlen Koltun. DPT is a model that leverages
    the [Vision Transformer (ViT)](vit) as backbone for dense prediction tasks like
    semantic segmentation and depth estimation.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: DPT 模型由 René Ranftl、Alexey Bochkovskiy、Vladlen Koltun 在 [Vision Transformers
    for Dense Prediction](https://arxiv.org/abs/2103.13413) 中提出。DPT 是一个利用 [Vision
    Transformer (ViT)](vit) 作为密集预测任务（如语义分割和深度估计）的骨干的模型。
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*We introduce dense vision transformers, an architecture that leverages vision
    transformers in place of convolutional networks as a backbone for dense prediction
    tasks. We assemble tokens from various stages of the vision transformer into image-like
    representations at various resolutions and progressively combine them into full-resolution
    predictions using a convolutional decoder. The transformer backbone processes
    representations at a constant and relatively high resolution and has a global
    receptive field at every stage. These properties allow the dense vision transformer
    to provide finer-grained and more globally coherent predictions when compared
    to fully-convolutional networks. Our experiments show that this architecture yields
    substantial improvements on dense prediction tasks, especially when a large amount
    of training data is available. For monocular depth estimation, we observe an improvement
    of up to 28% in relative performance when compared to a state-of-the-art fully-convolutional
    network. When applied to semantic segmentation, dense vision transformers set
    a new state of the art on ADE20K with 49.02% mIoU. We further show that the architecture
    can be fine-tuned on smaller datasets such as NYUv2, KITTI, and Pascal Context
    where it also sets the new state of the art.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们介绍了密集视觉变换器，这是一种利用视觉变换器代替卷积网络作为密集预测任务骨干的架构。我们从视觉变换器的各个阶段汇集令牌，将它们组合成各种分辨率的图像表示，并逐渐将它们结合成使用卷积解码器进行全分辨率预测。变换器骨干以恒定且相对较高的分辨率处理表示，并在每个阶段具有全局感受野。这些特性使得密集视觉变换器在与完全卷积网络相比提供更精细和更全局一致的预测。我们的实验表明，这种架构在密集预测任务上取得了显著的改进，特别是当有大量训练数据可用时。对于单目深度估计，我们观察到与最先进的完全卷积网络相比，性能相对提高了高达
    28%。当应用于语义分割时，密集视觉变换器在 ADE20K 上取得了 49.02% mIoU 的新的最先进水平。我们进一步展示，该架构可以在较小的数据集（如
    NYUv2、KITTI 和 Pascal Context）上进行微调，也在这些数据集上取得了新的最先进水平。*'
- en: '![drawing](../Images/a0659410be29958ad5c55dce63aa3e01.png) DPT architecture.
    Taken from the [original paper](https://arxiv.org/abs/2103.13413).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![drawing](../Images/a0659410be29958ad5c55dce63aa3e01.png) DPT 架构。摘自[原始论文](https://arxiv.org/abs/2103.13413)。'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/isl-org/DPT).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由 [nielsr](https://huggingface.co/nielsr) 贡献。原始代码可在[此处](https://github.com/isl-org/DPT)找到。
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: 'DPT is compatible with the `AutoBackbone` class. This allows to use the DPT
    framework with various computer vision backbones available in the library, such
    as `VitDetBackbone` or `Dinov2Backbone`. One can create it as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: DPT 兼容 `AutoBackbone` 类。这允许使用库中提供的各种计算机视觉骨干（如 `VitDetBackbone` 或 `Dinov2Backbone`）与
    DPT 框架一起使用。可以按照以下方式创建它：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Resources
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with DPT.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是官方 Hugging Face 和社区（🌎 标志）资源列表，可帮助您开始使用 DPT。
- en: Demo notebooks for [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)
    can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/DPT).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)
    的演示笔记本可以在[这里](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/DPT)找到。'
- en: '[Semantic segmentation task guide](../tasks/semantic_segmentation)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义分割任务指南](../tasks/semantic_segmentation)'
- en: '[Monocular depth estimation task guide](../tasks/monocular_depth_estimation)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[单目深度估计任务指南](../tasks/monocular_depth_estimation)'
- en: If you’re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and we’ll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣提交资源以包含在此处，请随时提交拉取请求，我们将进行审查！资源应该展示一些新内容，而不是重复现有资源。
- en: DPTConfig
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DPTConfig
- en: '### `class transformers.DPTConfig`'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.DPTConfig` 类'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/configuration_dpt.py#L33)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/configuration_dpt.py#L33)'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *可选*, 默认为 768) — 编码器层和池化层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *可选*, 默认为 12) — Transformer 编码器中的隐藏层数。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *可选*, 默认为 12) — Transformer 编码器中每个注意力层的注意力头数。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimensionality
    of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *可选*, 默认为 3072) — Transformer 编码器中“中间”（即前馈）层的维度。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` 或 `function`, *可选*, 默认为 `"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持
    `"gelu"`, `"relu"`, `"selu"` 和 `"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.0) — The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.0) — 嵌入、编码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) — The
    dropout ratio for the attention probabilities.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.0) — 注意力概率的dropout比率。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — 层归一化层使用的epsilon。'
- en: '`image_size` (`int`, *optional*, defaults to 384) — The size (resolution) of
    each image.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_size` (`int`, *optional*, defaults to 384) — 每个图像的大小（分辨率）。'
- en: '`patch_size` (`int`, *optional*, defaults to 16) — The size (resolution) of
    each patch.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size` (`int`, *optional*, defaults to 16) — 每个补丁的大小（分辨率）。'
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *optional*, defaults to 3) — 输入通道数。'
- en: '`is_hybrid` (`bool`, *optional*, defaults to `False`) — Whether to use a hybrid
    backbone. Useful in the context of loading DPT-Hybrid models.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_hybrid` (`bool`, *optional*, defaults to `False`) — 是否使用混合主干。在加载DPT-Hybrid模型的情况下很有用。'
- en: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — Whether to add a bias
    to the queries, keys and values.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qkv_bias` (`bool`, *optional*, defaults to `True`) — 是否为查询、键和值添加偏置。'
- en: '`backbone_out_indices` (`List[int]`, *optional*, defaults to `[2, 5, 8, 11]`)
    — Indices of the intermediate hidden states to use from backbone.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_out_indices` (`List[int]`, *optional*, defaults to `[2, 5, 8, 11]`)
    — 要从主干使用的中间隐藏状态的索引。'
- en: '`readout_type` (`str`, *optional*, defaults to `"project"`) — The readout type
    to use when processing the readout token (CLS token) of the intermediate hidden
    states of the ViT backbone. Can be one of [`"ignore"`, `"add"`, `"project"`].'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`readout_type` (`str`, *optional*, defaults to `"project"`) — 处理ViT主干中间隐藏状态的读出标记（CLS标记）时要使用的读出类型。可以是[`"ignore"`,
    `"add"`, `"project"`]之一。'
- en: “ignore” simply ignores the CLS token.
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “ignore” 简单地忽略CLS标记。
- en: “add” passes the information from the CLS token to all other tokens by adding
    the representations.
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “add” 通过将CLS标记的信息添加到所有其他标记中传递表示。
- en: “project” passes information to the other tokens by concatenating the readout
    to all other tokens before projecting the representation to the original feature
    dimension D using a linear layer followed by a GELU non-linearity.
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “project” 通过将读出连接到所有其他标记，然后使用线性层将表示投影到原始特征维度D，接着使用GELU非线性传递信息给其他标记。
- en: '`reassemble_factors` (`List[int]`, *optional*, defaults to `[4, 2, 1, 0.5]`)
    — The up/downsampling factors of the reassemble layers.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reassemble_factors` (`List[int]`, *optional*, defaults to `[4, 2, 1, 0.5]`)
    — 重组层的上/下采样因子。'
- en: '`neck_hidden_sizes` (`List[str]`, *optional*, defaults to `[96, 192, 384, 768]`)
    — The hidden sizes to project to for the feature maps of the backbone.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`neck_hidden_sizes` (`List[str]`, *optional*, defaults to `[96, 192, 384, 768]`)
    — 要投影到主干特征图的隐藏大小。'
- en: '`fusion_hidden_size` (`int`, *optional*, defaults to 256) — The number of channels
    before fusion.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fusion_hidden_size` (`int`, *optional*, defaults to 256) — 融合前的通道数。'
- en: '`head_in_index` (`int`, *optional*, defaults to -1) — The index of the features
    to use in the heads.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_in_index` (`int`, *optional*, defaults to -1) — 在头部中要使用的特征的索引。'
- en: '`use_batch_norm_in_fusion_residual` (`bool`, *optional*, defaults to `False`)
    — Whether to use batch normalization in the pre-activate residual units of the
    fusion blocks.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_batch_norm_in_fusion_residual` (`bool`, *optional*, defaults to `False`)
    — 是否在融合块的预激活残差单元中使用批归一化。'
- en: '`use_bias_in_fusion_residual` (`bool`, *optional*, defaults to `True`) — Whether
    to use bias in the pre-activate residual units of the fusion blocks.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_bias_in_fusion_residual` (`bool`, *optional*, defaults to `True`) — 是否在融合块的预激活残差单元中使用偏置。'
- en: '`add_projection` (`bool`, *optional*, defaults to `False`) — Whether to add
    a projection layer before the depth estimation head.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_projection` (`bool`, *optional*, defaults to `False`) — 是否在深度估计头之前添加投影层。'
- en: '`use_auxiliary_head` (`bool`, *optional*, defaults to `True`) — Whether to
    use an auxiliary head during training.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_auxiliary_head` (`bool`, *optional*, defaults to `True`) — 训练时是否使用辅助头。'
- en: '`auxiliary_loss_weight` (`float`, *optional*, defaults to 0.4) — Weight of
    the cross-entropy loss of the auxiliary head.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auxiliary_loss_weight` (`float`, *optional*, defaults to 0.4) — 辅助头的交叉熵损失权重。'
- en: '`semantic_loss_ignore_index` (`int`, *optional*, defaults to 255) — The index
    that is ignored by the loss function of the semantic segmentation model.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`semantic_loss_ignore_index` (`int`, *optional*, defaults to 255) — 语义分割模型损失函数中被忽略的索引。'
- en: '`semantic_classifier_dropout` (`float`, *optional*, defaults to 0.1) — The
    dropout ratio for the semantic classification head.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`semantic_classifier_dropout` (`float`, *optional*, defaults to 0.1) — 语义分类头的dropout比率。'
- en: '`backbone_featmap_shape` (`List[int]`, *optional*, defaults to `[1, 1024, 24,
    24]`) — Used only for the `hybrid` embedding type. The shape of the feature maps
    of the backbone.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_featmap_shape` (`List[int]`, *optional*, defaults to `[1, 1024, 24,
    24]`) — 仅用于`hybrid`嵌入类型。主干特征图的形状。'
- en: '`neck_ignore_stages` (`List[int]`, *optional*, defaults to `[0, 1]`) — Used
    only for the `hybrid` embedding type. The stages of the readout layers to ignore.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`neck_ignore_stages` (`List[int]`, *optional*, defaults to `[0, 1]`) — 仅用于`hybrid`嵌入类型。要忽略的读出层阶段。'
- en: '`backbone_config` (`Union[Dict[str, Any], PretrainedConfig]`, *optional*) —
    The configuration of the backbone model. Only used in case `is_hybrid` is `True`
    or in case you want to leverage the `AutoBackbone` API.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_config` (`Union[Dict[str, Any], PretrainedConfig]`, *optional*) —
    主干模型的配置。仅在`is_hybrid`为`True`或者想要利用`AutoBackbone` API时使用。'
- en: This is the configuration class to store the configuration of a [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel).
    It is used to instantiate an DPT model according to the specified arguments, defining
    the model architecture. Instantiating a configuration with the defaults will yield
    a similar configuration to that of the DPT [Intel/dpt-large](https://huggingface.co/Intel/dpt-large)
    architecture.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这是配置类，用于存储[DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel)的配置。它用于根据指定的参数实例化一个DPT模型，定义模型架构。使用默认值实例化配置将产生类似于[DPT
    Intel/dpt-large](https://huggingface.co/Intel/dpt-large)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `to_dict`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `to_dict`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/configuration_dpt.py#L247)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/configuration_dpt.py#L247)'
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Serializes this instance to a Python dictionary. Override the default [to_dict()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.to_dict).
    Returns: `Dict[str, any]`: Dictionary of all the attributes that make up this
    configuration instance,'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将此实例序列化为Python字典。覆盖默认的[to_dict()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.to_dict)。返回：`Dict[str,
    any]`：构成此配置实例的所有属性的字典，
- en: DPTFeatureExtractor
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DPTFeatureExtractor
- en: '### `class transformers.DPTFeatureExtractor`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DPTFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/feature_extraction_dpt.py#L26)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/feature_extraction_dpt.py#L26)'
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `__call__`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Preprocess an image or a batch of images.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理图像或一批图像。
- en: '#### `post_process_semantic_segmentation`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_semantic_segmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/image_processing_dpt.py#L422)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/image_processing_dpt.py#L422)'
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` ([DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation))
    — Raw outputs of the model.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs`（[DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)）—
    模型的原始输出。'
- en: '`target_sizes` (`List[Tuple]` of length `batch_size`, *optional*) — List of
    tuples corresponding to the requested final size (height, width) of each prediction.
    If unset, predictions will not be resized.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes`（长度为`batch_size`的`List[Tuple]`，*可选*）— 对应于每个预测的请求最终大小（高度，宽度）的元组列表。如果未设置，预测将不会被调整大小。'
- en: Returns
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: semantic_segmentation
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割
- en: '`List[torch.Tensor]` of length `batch_size`, where each item is a semantic
    segmentation map of shape (height, width) corresponding to the target_sizes entry
    (if `target_sizes` is specified). Each entry of each `torch.Tensor` correspond
    to a semantic class id.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 长度为`batch_size`的`List[torch.Tensor]`，其中每个项目是形状为（高度，宽度）的语义分割地图，对应于`target_sizes`条目（如果指定了`target_sizes`）。每个`torch.Tensor`的每个条目对应于语义类别ID。
- en: Converts the output of [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)
    into semantic segmentation maps. Only supports PyTorch.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 将[DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)的输出转换为语义分割地图。仅支持PyTorch。
- en: DPTImageProcessor
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DPTImageProcessor
- en: '### `class transformers.DPTImageProcessor`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DPTImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/image_processing_dpt.py#L94)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/image_processing_dpt.py#L94)'
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Whether to resize the
    image’s (height, width) dimensions. Can be overidden by `do_resize` in `preprocess`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize`（`bool`，*可选*，默认为`True`）— 是否调整图像的（高度，宽度）尺寸。可以被`preprocess`中的`do_resize`覆盖。'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"height" -- 384, "width":
    384}`): Size of the image after resizing. Can be overidden by `size` in `preprocess`.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`（`Dict[str, int]` *可选*，默认为`{"height" -- 384, "width": 384}`）：调整大小后的图像尺寸。可以被`preprocess`中的`size`覆盖。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `Resampling.BICUBIC`)
    — Defines the resampling filter to use if resizing the image. Can be overidden
    by `resample` in `preprocess`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample`（`PILImageResampling`，*可选*，默认为`Resampling.BICUBIC`）— 如果调整图像大小，则定义要使用的重采样滤波器。可以被`preprocess`中的`resample`覆盖。'
- en: '`keep_aspect_ratio` (`bool`, *optional*, defaults to `False`) — If `True`,
    the image is resized to the largest possible size such that the aspect ratio is
    preserved. Can be overidden by `keep_aspect_ratio` in `preprocess`.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keep_aspect_ratio`（`bool`，*可选*，默认为`False`）— 如果为`True`，则将图像调整为保持纵横比的最大可能尺寸。可以被`preprocess`中的`keep_aspect_ratio`覆盖。'
- en: '`ensure_multiple_of` (`int`, *optional*, defaults to 1) — If `do_resize` is
    `True`, the image is resized to a size that is a multiple of this value. Can be
    overidden by `ensure_multiple_of` in `preprocess`.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ensure_multiple_of`（`int`，*可选*，默认为1）— 如果`do_resize`为`True`，则将图像调整为此值的倍数。可以被`preprocess`中的`ensure_multiple_of`覆盖。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to rescale
    the image by the specified scale `rescale_factor`. Can be overidden by `do_rescale`
    in `preprocess`.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale`（`bool`，*可选*，默认为`True`）— 是否按指定比例`rescale_factor`重新缩放图像。可以被`preprocess`中的`do_rescale`覆盖。'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) — Scale
    factor to use if rescaling the image. Can be overidden by `rescale_factor` in
    `preprocess`.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`int`或`float`，*optional*，默认为`1/255`) — 如果重新缩放图像，则使用的缩放因子。可以被`preprocess`中的`rescale_factor`覆盖。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) — Whether to normalize
    the image. Can be overridden by the `do_normalize` parameter in the `preprocess`
    method.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`，*optional*，默认为`True`) — 是否对图像进行归一化。可以被`preprocess`方法中的`do_normalize`参数覆盖。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_MEAN`)
    — Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float`或`List[float]`，*optional*，默认为`IMAGENET_STANDARD_MEAN`)
    — 如果对图像进行归一化，则使用的均值。这是一个浮点数或与图像通道数相同长度的浮点数列表。可以被`preprocess`方法中的`image_mean`参数覆盖。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_STD`)
    — Standard deviation to use if normalizing the image. This is a float or list
    of floats the length of the number of channels in the image. Can be overridden
    by the `image_std` parameter in the `preprocess` method.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float`或`List[float]`，*optional*，默认为`IMAGENET_STANDARD_STD`) —
    如果对图像进行归一化，则使用的标准差。这是一个浮点数或与图像通道数相同长度的浮点数列表。可以被`preprocess`方法中的`image_std`参数覆盖。'
- en: '`do_pad` (`bool`, *optional*, defaults to `False`) — Whether to apply center
    padding. This was introduced in the DINOv2 paper, which uses the model in combination
    with DPT.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad` (`bool`，*optional*，默认为`False`) — 是否应用中心填充。这在DINOv2论文中引入，该论文将该模型与DPT结合使用。'
- en: '`size_divisor` (`int`, *optional*) — If `do_pad` is `True`, pads the image
    dimensions to be divisible by this value. This was introduced in the DINOv2 paper,
    which uses the model in combination with DPT.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size_divisor` (`int`，*optional*) — 如果`do_pad`为`True`，则填充图像尺寸使其可被该值整除。这在DINOv2论文中引入，该论文将该模型与DPT结合使用。'
- en: Constructs a DPT image processor.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 构造一个DPT图像处理器。
- en: '#### `preprocess`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/image_processing_dpt.py#L267)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/image_processing_dpt.py#L267)'
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — Image to preprocess. Expects a single or batch of
    images with pixel values ranging from 0 to 255\. If passing in images with pixel
    values between 0 and 1, set `do_rescale=False`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) — 要预处理的图像。期望单个图像或批量图像，像素值范围为0到255。如果传入像素值在0到1之间的图像，请设置`do_rescale=False`。'
- en: '`do_resize` (`bool`, *optional*, defaults to `self.do_resize`) — Whether to
    resize the image.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`，*optional*，默认为`self.do_resize`) — 是否调整图像大小。'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) — Size of the
    image after reszing. If `keep_aspect_ratio` is `True`, the image is resized to
    the largest possible size such that the aspect ratio is preserved. If `ensure_multiple_of`
    is set, the image is resized to a size that is a multiple of this value.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) — 调整大小后的图像尺寸。如果`keep_aspect_ratio`为`True`，则将图像调整大小为保持纵横比的最大可能尺寸。如果设置了`ensure_multiple_of`，则将图像调整大小为该值的倍数。'
- en: '`keep_aspect_ratio` (`bool`, *optional*, defaults to `self.keep_aspect_ratio`)
    — Whether to keep the aspect ratio of the image. If False, the image will be resized
    to (size, size). If True, the image will be resized to keep the aspect ratio and
    the size will be the maximum possible.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keep_aspect_ratio` (`bool`，*optional*，默认为`self.keep_aspect_ratio`) — 是否保持图像的纵横比。如果为False，则将图像调整大小为（size，size）。如果为True，则将图像调整大小以保持纵横比，大小将是最大可能的。'
- en: '`ensure_multiple_of` (`int`, *optional*, defaults to `self.ensure_multiple_of`)
    — Ensure that the image size is a multiple of this value.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ensure_multiple_of` (`int`，*optional*，默认为`self.ensure_multiple_of`) — 确保图像大小是该值的倍数。'
- en: '`resample` (`int`, *optional*, defaults to `self.resample`) — Resampling filter
    to use if resizing the image. This can be one of the enum `PILImageResampling`,
    Only has an effect if `do_resize` is set to `True`.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`int`，*optional*，默认为`self.resample`) — 如果调整图像大小，则要使用的重采样滤波器。这可以是枚举`PILImageResampling`之一，仅在`do_resize`设置为`True`时有效。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) — Whether
    to rescale the image values between [0 - 1].'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`，*optional*，默认为`self.do_rescale`) — 是否将图像值重新缩放在[0 - 1]之间。'
- en: '`rescale_factor` (`float`, *optional*, defaults to `self.rescale_factor`) —
    Rescale factor to rescale the image by if `do_rescale` is set to `True`.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`float`，*optional*，默认为`self.rescale_factor`) — 如果`do_rescale`设置为`True`，则用于重新缩放图像的缩放因子。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) — Whether
    to normalize the image.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`，*optional*，默认为`self.do_normalize`) — 是否对图像进行归一化。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `self.image_mean`)
    — Image mean.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float`或`List[float]`，*optional*，默认为`self.image_mean`) — 图像均值。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `self.image_std`)
    — Image standard deviation.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float`或`List[float]`，*optional*，默认为`self.image_std`) — 图像标准差。'
- en: '`return_tensors` (`str` or `TensorType`, *optional*) — The type of tensors
    to return. Can be one of:'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str`或`TensorType`，*optional*) — 要返回的张量类型。可以是以下之一：'
- en: 'Unset: Return a list of `np.ndarray`.'
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：返回一个`np.ndarray`列表。
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW`或`''tf''`：返回类型为`tf.Tensor`的批处理。'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH`或`''pt''`：返回类型为`torch.Tensor`的批处理。'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY`或`''np''`：返回类型为`np.ndarray`的批处理。'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX`或`''jax''`：返回类型为`jax.numpy.ndarray`的批处理。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format` (`ChannelDimension`或`str`，*optional*，默认为`ChannelDimension.FIRST`)
    — 输出图像的通道维度格式。可以是以下之一：'
- en: '`ChannelDimension.FIRST`: image in (num_channels, height, width) format.'
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.FIRST`：图像以（num_channels，height，width）格式。'
- en: '`ChannelDimension.LAST`: image in (height, width, num_channels) format.'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.LAST`: 图像以（高度，宽度，通道数）格式。'
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format`（`ChannelDimension` 或 `str`，*可选*）— 输入图像的通道维度格式。如果未设置，将从输入图像中推断通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"` 或 `ChannelDimension.FIRST`: 图像以（通道数，高度，宽度）格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"` 或 `ChannelDimension.LAST`: 图像以（高度，宽度，通道数）格式。'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"` 或 `ChannelDimension.NONE`: 图像以（高度，宽度）格式。'
- en: Preprocess an image or batch of images.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 对图像或图像批次进行预处理。
- en: '#### `post_process_semantic_segmentation`'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_semantic_segmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/image_processing_dpt.py#L422)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/image_processing_dpt.py#L422)'
- en: '[PRE9]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` ([DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation))
    — Raw outputs of the model.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs`（[DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)）—
    模型的原始输出。'
- en: '`target_sizes` (`List[Tuple]` of length `batch_size`, *optional*) — List of
    tuples corresponding to the requested final size (height, width) of each prediction.
    If unset, predictions will not be resized.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes`（长度为`batch_size`的 `List[Tuple]`，*可选*）— 与每个预测的请求最终大小（高度，宽度）对应的元组列表。如果未设置，预测将不会被调整大小。'
- en: Returns
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: semantic_segmentation
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: semantic_segmentation
- en: '`List[torch.Tensor]` of length `batch_size`, where each item is a semantic
    segmentation map of shape (height, width) corresponding to the target_sizes entry
    (if `target_sizes` is specified). Each entry of each `torch.Tensor` correspond
    to a semantic class id.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 长度为`batch_size`的 `List[torch.Tensor]`，其中每个项目是形状为（高度，宽度）的语义分割地图，对应于 `target_sizes`
    条目（如果指定了 `target_sizes`）。每个 `torch.Tensor` 的每个条目对应于一个语义类别 id。
- en: Converts the output of [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)
    into semantic segmentation maps. Only supports PyTorch.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 将 [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)
    的输出转换为语义分割地图。仅支持 PyTorch。
- en: DPTModel
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DPTModel
- en: '### `class transformers.DPTModel`'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DPTModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L869)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L869)'
- en: '[PRE10]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: The bare DPT Model transformer outputting raw hidden-states without any specific
    head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的 DPT 模型变压器输出原始的隐藏状态，没有特定的头部。这个模型是 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    的子类。将其用作常规的 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L905)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L905)'
- en: '[PRE11]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DPTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（形状为`(batch_size, num_channels, height, width)`的 `torch.FloatTensor`）—
    像素值。可以使用 [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)
    获取像素值。有关详细信息，请参阅 [DPTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的 `torch.FloatTensor`，*可选*）—
    用于使自注意力模块的选定头部无效的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部为`未屏蔽`，
- en: 0 indicates the head is `masked`.
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部为`已屏蔽`。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的 `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的 `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是一个普通元组。'
- en: Returns
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.dpt.modeling_dpt.BaseModelOutputWithPoolingAndIntermediateActivations`
    or `tuple(torch.FloatTensor)`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.dpt.modeling_dpt.BaseModelOutputWithPoolingAndIntermediateActivations`
    或 `tuple(torch.FloatTensor)`'
- en: A `transformers.models.dpt.modeling_dpt.BaseModelOutputWithPoolingAndIntermediateActivations`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig))
    and inputs.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.dpt.modeling_dpt.BaseModelOutputWithPoolingAndIntermediateActivations`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)）和输入的各种元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — 模型最后一层的隐藏状态序列。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — 序列第一个标记（分类标记）的最后一层隐藏状态（经过用于辅助预训练任务的层进一步处理后）的输出。例如，对于BERT系列模型，这返回经过线性层和tanh激活函数处理后的分类标记。线性层权重是从预训练期间的下一个句子预测（分类）目标中训练的。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: '`intermediate_activations` (`tuple(torch.FloatTensor)`, *optional*) — Intermediate
    activations that can be used to compute hidden states of the model at various
    layers.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_activations` (`tuple(torch.FloatTensor)`，*可选*) — 可用于计算各层模型隐藏状态的中间激活。'
- en: The [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel)
    forward method, overrides the `__call__` special method.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE12]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: DPTForDepthEstimation
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DPTForDepthEstimation
- en: '### `class transformers.DPTForDepthEstimation`'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DPTForDepthEstimation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L1073)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L1073)'
- en: '[PRE13]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: DPT Model with a depth estimation head on top (consisting of 3 convolutional
    layers) e.g. for KITTI, NYUv2.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 带有深度估计头部的DPT模型（包含3个卷积层），例如用于KITTI、NYUv2。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L1098)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L1098)'
- en: '[PRE14]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DPTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — 像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获得。有关详细信息，请参阅[DPTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(num_heads,)`或`(num_layers, num_heads)`的`torch.FloatTensor`，*可选*）—
    用于使自注意力模块中的选定头部失效的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被屏蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被屏蔽。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请查看返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Ground truth depth estimation maps for computing the loss.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, height, width)`的`torch.LongTensor`，*可选*）— 用于计算损失的地面真实深度估计图。'
- en: Returns
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.DepthEstimatorOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.DepthEstimatorOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.DepthEstimatorOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.DepthEstimatorOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.DepthEstimatorOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.DepthEstimatorOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig))
    and inputs.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.DepthEstimatorOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.DepthEstimatorOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)）和输入的不同元素。'
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回）— 分类（或如果`config.num_labels==1`则为回归）损失。'
- en: '`predicted_depth` (`torch.FloatTensor` of shape `(batch_size, height, width)`)
    — Predicted depth for each pixel.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predicted_depth`（形状为`(batch_size, height, width)`的`torch.FloatTensor`）— 每个像素的预测深度。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, num_channels, height,
    width)`.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组（如果模型有嵌入层的输出一个，+
    每一层的输出一个）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态加上可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, patch_size, sequence_length)`.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, patch_size, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在自注意力头中用于计算加权平均值的注意力权重在注意力softmax之后。
- en: The [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)
    forward method, overrides the `__call__` special method.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)的前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE15]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: DPTForSemanticSegmentation
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DPTForSemanticSegmentation
- en: '### `class transformers.DPTForSemanticSegmentation`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DPTForSemanticSegmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L1259)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L1259)'
- en: '[PRE16]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: DPT Model with a semantic segmentation head on top e.g. for ADE20k, CityScapes.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语义分割头的DPT模型，例如ADE20k，CityScapes。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L1281)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/dpt/modeling_dpt.py#L1281)'
- en: '[PRE17]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [DPTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅[DPTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为`(num_heads,)`或`(num_layers, num_heads)`，*可选*)
    — 用于使自注意力模块的选定头部失效的掩码。掩码值选定在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮罩，
- en: 0 indicates the head is `masked`.
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮罩。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Ground truth semantic segmentation maps for computing the loss. Indices should
    be in `[0, ..., config.num_labels - 1]`. If `config.num_labels > 1`, a classification
    loss is computed (Cross-Entropy).'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`，形状为`(batch_size, height, width)`，*可选*) — 用于计算损失的地面真实语义分割地图。索引应在`[0,
    ..., config.num_labels - 1]`中。如果`config.num_labels > 1`，则计算分类损失（交叉熵）。'
- en: Returns
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.SemanticSegmenterOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SemanticSegmenterOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.SemanticSegmenterOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SemanticSegmenterOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.SemanticSegmenterOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SemanticSegmenterOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig))
    and inputs.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.SemanticSegmenterOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SemanticSegmenterOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`）包含各种元素，具体取决于配置（[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)）和输入。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回） — 分类（或回归，如果`config.num_labels==1`）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels, logits_height,
    logits_width)`) — Classification scores for each pixel.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为`(batch_size, config.num_labels, logits_height,
    logits_width)`) — 每个像素的分类分数。'
- en: <tip warning="{true}">The logits returned do not necessarily have the same size
    as the `pixel_values` passed as inputs. This is to avoid doing two interpolations
    and lose some quality when a user needs to resize the logits to the original image
    size as post-processing. You should always check your logits shape and resize
    as needed.</tip>
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <tip warning="{true}">返回的logits不一定与作为输入传递的`pixel_values`具有相同的大小。这是为了避免进行两次插值并在用户需要将logits调整为原始图像大小时丢失一些质量。您应该始终检查您的logits形状并根据需要调整大小。</tip>
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, patch_size, hidden_size)`.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, patch_size, hidden_size)`的`torch.FloatTensor`元组（如果模型具有嵌入层，则为嵌入的输出的一个+每层输出的一个）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出时的隐藏状态加上可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, patch_size, sequence_length)`.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, patch_size, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)
    forward method, overrides the `__call__` special method.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数中定义，但应该在此之后调用 `Module` 实例，而不是这个函数，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE18]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
