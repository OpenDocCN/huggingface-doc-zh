# 快速导览

> 原文链接：[https://huggingface.co/docs/accelerate/quicktour](https://huggingface.co/docs/accelerate/quicktour)

本指南旨在帮助您快速入门🤗 Accelerate。它涵盖了启用分布式训练所需的基本步骤，以及在一些常见情况下需要进行的调整。

为了帮助您导航，指南分为两个部分：

+   [Getting Started with 🤗 Accelerate](#getting-started-with--accelerate)：从这里开始学习如何修改您的脚本以启用🤗 Accelerate的分布式训练

+   [基本情况下的常见适应](#common-adaptations-to-the-base-case)：查看此部分以了解与基线情况的常见偏差以及可能需要进行的调整。

## 开始使用🤗 Accelerate

### 在您的脚本中启用分布式训练

要在自己的训练脚本中使用🤗 Accelerate，您需要修改四个内容：

1.  导入[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)主类并在`accelerator`对象中实例化一个。

```py
from accelerate import Accelerator

accelerator = Accelerator()
```

将此添加到您的训练脚本开头，因为它将初始化分布式训练所需的一切。您无需指示您所处的环境类型（具有GPU的单台机器，具有多个GPU的机器，或具有多个GPU或TPU的多台机器），库将自动检测到这一点。

1.  删除模型和输入数据的`.to(device)`或`.cuda()`调用。

`accelerator`对象将为您处理将这些对象放置在正确设备上。如果选择保留那些`.to(device)`调用，请确保使用`accelerator`对象提供的设备：`accelerator.device`。

您可以通过在初始化[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)时传递`device_placement=False`来完全停用自动设备放置。但是，如果您手动将对象放置在正确的设备上，请注意在将模型放置在`accelerator.device`上后再创建优化器，否则您的TPU训练将失败。

1.  将所有与训练相关的PyTorch对象（优化器，模型，数据加载器，学习率调度器）在创建这些对象后立即传递给[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)方法，然后再开始实际的训练循环：

```py
model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
    model, optimizer, train_dataloader, lr_scheduler
)
```

**重要提示**：

+   您应该始终将学习率调度器传递给[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)，但是如果调度器在每次优化步骤时*不*应该被步进，请在[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)初始化时传递`step_with_optimizer=False`。

+   虽然您可以将您的数据加载器单独发送到[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)（并且有时需要这样做，比如分布式推理），但最好将其与模型和优化器一起发送到[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)。

+   如果您希望运行分布式评估，请将您的验证数据加载器也发送到[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)。分布式评估有一些细微差别，请查看指南中的[Distributed evaluation](#add-distributed-evaluation)部分。

+   任何使用您的训练数据加载器长度的指令（例如，如果您想记录总训练步数）应该在调用[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)之后进行。

将 `DataLoader` 对象传递给 [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare) 方法可确保您的数据加载器将在所有可用的GPU/TPU核心上进行分片，以便每个核心看到训练数据集的不同部分。换句话说，如果有 8 个进程和一个包含 64 个项目的数据集，每个进程将在每次迭代中看到其中的 8 个项目。此外，所有进程的随机状态将在每次迭代开始时通过您的数据加载器进行同步，以确保数据以相同的方式洗牌（如果您决定使用 `shuffle=True` 或任何类型的随机采样器）。

您的训练实际批量大小将是使用的设备数量乘以脚本中设置的批量大小。例如，使用批量大小为 16 创建训练数据加载器时在 4 个GPU上训练将以实际批量大小 64（4 * 16）进行训练。如果希望无论脚本在多少个GPU上运行，批量大小保持不变，可以在创建和初始化 [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator) 时使用选项 `split_batches=True`。通过此方法进行训练数据加载器可能会改变长度：如果在 X 个GPU上运行，它的长度将被 X 整除（因为实际批量大小将乘以 X），除非设置 `split_batches=True`。

1.  将 `loss.backward()` 行替换为 `accelerator.backward(loss)`。

设置完成！通过所有这些更改，您的脚本将在本地机器上以及多个GPU或TPU上运行！您可以使用您喜欢的工具启动分布式训练，或者您可以使用 🤗 Accelerate 启动器。

### 添加分布式评估

如果将验证数据加载器排除在 [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare) 方法之外，您可以在训练脚本中执行定期评估。在这种情况下，您需要手动将输入数据放在 `accelerator.device` 上。

要执行分布式评估，请将验证数据加载器发送到 [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare) 方法中：

```py
validation_dataloader = accelerator.prepare(validation_dataloader)
```

与训练数据加载器一样，如果在多个设备上运行脚本，则每个设备只会看到评估数据的一部分。这意味着您需要将预测结果组合在一起，可以使用 [gather_for_metrics()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather_for_metrics) 方法来实现。

```py
for inputs, targets in validation_dataloader:
    predictions = model(inputs)
    # Gather all predictions and targets
    all_predictions, all_targets = accelerator.gather_for_metrics((predictions, targets))
    # Example of use with a *Datasets.Metric*
    metric.add_batch(all_predictions, all_targets)
```

与训练数据加载器类似，通过 [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare) 传递验证数据加载器可能会改变它：如果在 X 个GPU上运行，它的长度将被 X 整除（因为实际批量大小将乘以 X），除非设置 `split_batches=True`。

数据集末尾的一些数据可能会重复，以便批次可以在所有工作进程之间平均分配。因此，应通过 [gather_for_metrics()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather_for_metrics) 方法计算指标，以在收集数据时自动删除重复数据，并提供更准确的指标。

如果出于某种原因您不希望自动执行此操作，可以使用 [gather()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather) 来代替，以收集所有进程中的数据，这可以手动完成。

[gather()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather)和[gather_for_metrics()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather_for_metrics)方法要求每个进程上的张量大小相同。如果每个进程上的张量大小不同（例如在批处理中动态填充到最大长度时），您应该使用[pad_across_processes()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.pad_across_processes)方法将您的张量填充到跨进程的最大大小。

### 启动您的分布式脚本

您可以使用常规命令来启动您的分布式训练（例如PyTorch的`torch.distributed.run`）-它们与🤗 Accelerate完全兼容。

另外，🤗 Accelerate提供了一个CLI工具，统一了所有启动器，因此您只需记住一个命令。要使用它，在您的机器上首先运行快速配置设置并回答问题：

```py
accelerate config
```

在设置结束时，将在您的缓存文件夹中保存一个*default_config.yaml*文件供🤗 Accelerate使用。该缓存文件夹为（按优先级递减的顺序）：

+   您的环境变量`HF_HOME`的内容后缀为*accelerate*。

+   如果不存在，则将您的环境变量`XDG_CACHE_HOME`的内容后缀为*huggingface/accelerate*。

+   如果这也不存在，则文件夹*~/.cache/huggingface/accelerate*。

通过指定`--config_file`标志，您可以指定配置文件的替代位置。一旦配置设置完成，您可以通过运行以下命令来测试您的设置：

```py
accelerate test
```

这将启动一个简短的脚本，测试分布式环境。如果没有问题运行，您已经准备好进行下一步了！

请注意，如果在上一步中指定了配置文件的位置，则需要在此处传递它：

```py
accelerate test --config_file path_to_config.yaml
```

现在这样做后，您可以使用以下命令运行您的脚本：

```py
accelerate launch path_to_script.py --args_for_the_script
```

如果您将配置文件存储在非默认位置，可以像这样向启动器指示它：

```py
accelerate launch --config_file path_to_config.yaml path_to_script.py --args_for_the_script
```

您可以覆盖由配置文件确定的任何参数。要查看可以传递的完整参数列表，请运行`accelerate launch -h`。（通过传递部分命令，例如`accelerate launch --multi_gpu -h`，可以获取更多关于特定参数的帮助）

查看[启动教程](basic_tutorials/launch)以获取有关启动您的脚本的更多信息。

## 基本情况的常见修改

前一节涵盖了将训练脚本移至具有🤗 Accelerate的分布式设置的最小基本步骤。在这里，我们描述了与基本情况场景的常见修改/偏差以及您需要进行的调整。

### 从笔记本启动分布式训练

Accelerate有一个[notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)，可以帮助您从笔记本启动训练函数。该启动器支持在Colab或Kaggle上使用TPU进行训练，以及在多个GPU和机器上进行训练（如果运行笔记本的机器具有这些设备）。

在笔记本的一个单元格中定义一个负责整个训练和/或评估的函数，然后执行以下代码的单元格：

```py
from accelerate import notebook_launcher

notebook_launcher(training_function)
```

您的[Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)对象应该只在训练函数内部定义。这是因为初始化应该只在启动器内部完成。

查看[笔记本启动器教程](basic_tutorials/notebook)以获取有关在TPU上进行训练的更多信息。

### 在TPU上训练的具体情况

如果您想在TPU上运行您的脚本，您应该注意一些注意事项。在幕后，TPU将创建一个图，显示训练步骤中发生的所有操作（前向传递、反向传递和优化器步骤）。这就是为什么您的训练的第一步总是非常长的原因，因为构建和编译此图以进行优化需要一些时间。

好消息是这个编译将被缓存，因此第二步和所有后续步骤将会快得多。坏消息是它仅适用于所有步骤完全相同的操作，这意味着：

+   在所有批次中具有相同长度的所有张量

+   具有静态代码（即，不是长度可能会在步骤之间改变的for循环）

在两个步骤之间任何上述事物的改变都会触发新的编译，这将再次花费大量时间。实际上，这意味着您必须特别注意确保所有输入张量具有相同的形状（例如，如果您在处理自然语言处理问题，则不能使用动态填充），并且不应该使用具有不同长度的输入的for循环的层（例如LSTM），否则训练将变得非常缓慢。

要在脚本中为TPU引入特殊行为，您可以检查`accelerator`的`distributed_type`：

```py
from accelerate import DistributedType

if accelerator.distributed_type == DistributedType.TPU:
    # do something of static shape
else:
    # go crazy and be dynamic
```

[NLP示例](https://github.com/huggingface/accelerate/blob/main/examples/nlp_example.py)展示了一个具有动态填充情况的示例。

最后要特别注意的一点是：如果您的模型具有绑定权重（例如将嵌入矩阵的权重与解码器的权重绑定的语言模型），将此模型移动到TPU（无论是您自己还是在将模型传递给[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)之后）将会破坏这种绑定。您需要在之后重新绑定权重。您可以在Transformers存储库中的[run_clm_no_trainer](https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_clm.py)脚本中找到一个示例。

查看[TPU教程](concept_guides/training_tpu)以获取有关在TPU上训练的更多信息。

### 仅在一个进程上执行语句

您的一些指令只需要在给定服务器上的一个进程上运行：例如数据下载或日志语句。为此，请将语句包装在类似于以下的测试中：

```py
if accelerator.is_local_main_process:
    # Is executed once per server
```

另一个例子是进度条：为了避免在输出中有多个进度条，您应该仅在本地主进程上显示一个：

```py
from tqdm.auto import tqdm

progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)
```

*本地*表示每台机器：如果您在两台具有多个GPU的服务器上运行训练，该指令将在每台服务器上执行一次。如果您需要为所有进程执行一次（而不是每台机器）的某些操作，例如将最终模型上传到🤗模型中心，请将其包装在类似于以下的测试中：

```py
if accelerator.is_main_process:
    # Is executed once only
```

对于只想在每台机器上执行一次的打印语句，您可以将`print`函数替换为`accelerator.print`。

### 推迟在多个GPU上执行

当您运行您的常规脚本时，指令是按顺序执行的。使用🤗 Accelerate在多个GPU上同时部署您的脚本会引入一个复杂性：虽然每个进程按顺序执行所有指令，但有些可能比其他进程快。

在执行特定指令之前，您可能需要等待所有进程都达到某个特定点。例如，在确保每个进程都完成训练之前，您不应该保存模型。为此，请在您的代码中添加以下行：

```py
accelerator.wait_for_everyone()
```

此指令将阻止所有最先到达的进程，直到所有其他进程都达到该点（如果您只在一个GPU或CPU上运行脚本，则不会执行任何操作）。

### 在分布式设置中保存/加载模型

保存训练过的模型可能需要一些调整：首先，您应该等待所有进程达到脚本中显示的那一点，然后，您应该在保存之前取消包装模型。这是因为当通过[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)方法时，您的模型可能已放置在一个更大的模型中，该模型处理分布式训练。这反过来意味着，保存模型状态字典而不采取任何预防措施将考虑到该潜在的额外层，并且您最终将得到无法在基本模型中加载回的权重。[save_model()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_model)方法将帮助您实现这一点。它将取消包装您的模型并保存模型状态字典。

这里是一个例子：

```py
accelerator.wait_for_everyone()
accelerator.save_model(model, save_directory)
```

save_model()方法还可以将模型保存为分片检查点或使用safetensors格式：

```py
accelerator.wait_for_everyone()
accelerator.save_model(model, save_directory, max_shard_size="1GB", safe_serialization=True)
```

如果您的脚本包含加载检查点的逻辑，我们还建议您在未包装的模型中加载权重（仅在使模型通过[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)函数后使用加载函数时才有用）。这里是一个例子：

```py
unwrapped_model = accelerator.unwrap_model(model)
path_to_checkpoint = os.path.join(save_directory,"pytorch_model.bin")
unwrapped_model.load_state_dict(torch.load(path_to_checkpoint))
```

请注意，由于所有模型参数都是对张量的引用，这将在`model`内加载您的权重。

如果您想将分片检查点或带有safetensors格式的检查点加载到具有特定`device`的模型中，我们建议您使用[load_checkpoint_in_model()](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.load_checkpoint_in_model)函数加载。这里是一个例子：

```py
load_checkpoint_in_model(unwrapped_model, save_directory, device_map={"":device})
```

### 保存/加载整个状态

在训练模型时，您可能希望保存模型的当前状态、优化器、随机生成器以及可能的学习率调度器，以便在*同一脚本*中恢复。您可以分别使用[save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)和[load_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.load_state)来实现。

要进一步自定义通过[save_state()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.save_state)保存的状态的位置和方式，可以使用[ProjectConfiguration](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.utils.ProjectConfiguration)类。例如，如果启用了`automatic_checkpoint_naming`，每个保存的检查点将位于`Accelerator.project_dir/checkpoints/checkpoint_{checkpoint_number}`。

如果您已经通过[register_for_checkpointing()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.register_for_checkpointing)注册了其他需要存储的有状态项目，它们也将被保存和/或加载。

通过[register_for_checkpointing()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.register_for_checkpointing)传递的每个对象必须具有`load_state_dict`和`state_dict`函数才能被存储

### 使用梯度裁剪

如果您在脚本中使用梯度裁剪，应该将对`torch.nn.utils.clip_grad_norm_`或`torch.nn.utils.clip_grad_value_`的调用替换为[clip*grad_norm*()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.clip_grad_norm_)和[clip*grad_value*()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.clip_grad_value_)。

### 使用混合精度进行训练

如果您在🤗 Accelerate中以混合精度运行训练，则最好的结果是在模型内计算损失（例如在Transformer模型中）。模型外的每个计算将以完整精度执行（这通常是损失计算所需的，特别是如果涉及softmax）。但是，您可能希望将损失计算放在[autocast()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.autocast)上下文管理器中：

```py
with accelerator.autocast():
    loss = complex_loss_function(outputs, target):
```

混合精度训练的另一个注意事项是，梯度在开始时会跳过几次更新，有时在训练过程中也会跳过：由于动态损失缩放策略，训练过程中存在梯度溢出的点，损失缩放因子会减小，以避免在下一步再次发生这种情况。

这意味着当没有更新时，您可以更新学习率调度器，这在一般情况下是可以的，但在训练数据很少或者调度器的第一个学习率值非常重要时可能会产生影响。在这种情况下，您可以跳过学习率调度器的更新，就像这样：

```py
if not accelerator.optimizer_step_was_skipped:
    lr_scheduler.step()
```

### 使用梯度累积

要执行梯度累积，请使用[accumulate()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.accumulate)并指定`gradient_accumulation_steps`。这也会自动确保在多设备训练时梯度是同步的或异步的，检查步骤是否实际执行，并自动缩放损失：

```py
accelerator = Accelerator(gradient_accumulation_steps=2)
model, optimizer, training_dataloader = accelerator.prepare(model, optimizer, training_dataloader)

for input, label in training_dataloader:
    with accelerator.accumulate(model):
        predictions = model(input)
        loss = loss_function(predictions, label)
        accelerator.backward(loss)
        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()
```
