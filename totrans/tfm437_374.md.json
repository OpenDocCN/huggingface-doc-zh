["```py\nA chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.###Human: <image>\\n<prompt>###Assistant:\n```", "```py\nA chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.###Human: <image>\\n<prompt1>###Assistant: <answer1>###Human: <prompt2>###Assistant:\n```", "```py\n>>> from transformers import VipLlavaForConditionalGeneration, VipLlavaConfig, CLIPVisionConfig, LlamaConfig\n\n>>> # Initializing a CLIP-vision config\n>>> vision_config = CLIPVisionConfig()\n\n>>> # Initializing a Llama config\n>>> text_config = LlamaConfig()\n\n>>> # Initializing a VipLlava vipllava-7b style configuration\n>>> configuration = VipLlavaConfig(vision_config, text_config)\n\n>>> # Initializing a model from the vipllava-7b style configuration\n>>> model = VipLlavaForConditionalGeneration(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n>>> from transformers import AutoProcessor, VipLlavaForConditionalGeneration\n\n>>> model = VipLlavaForConditionalGeneration.from_pretrained(\"llava-hf/vip-llava-7b-hf\", device_map=\"auto\", torch_dtype=torch.float16)\n>>> processor = AutoProcessor.from_pretrained(\"llava-hf/vip-llava-7b-hf\")\n\n>>> prompt = \"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.###Human: <image>\\n{}###Assistant:\"\n>>> question = \"Can you please describe this image?\"\n>>> prompt = prompt.format(question)\n>>> url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/compel-neg.png\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n\n>>> inputs = processor(text=text, images=image, return_tensors=\"pt\").to(0, torch.float16)\n\n>>> # Generate\n>>> generate_ids = model.generate(**inputs, max_new_tokens=20)\n>>> processor.decode(generate_ids[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True)\nThe image features a brown and white cat sitting on a green surface, with a red ball in its\n```"]