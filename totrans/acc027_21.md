# 跟踪

> 原始文本：[https://huggingface.co/docs/accelerate/usage_guides/tracking](https://huggingface.co/docs/accelerate/usage_guides/tracking)

有大量的实验跟踪API可用，但是让它们在多进程环境中一起工作通常会很复杂。🤗 Accelerate提供了一个通用的跟踪API，可以用来通过`Accelerator.log()`记录脚本中的有用项目

## 集成跟踪器

目前`Accelerate`支持七种开箱即用的跟踪器：

+   TensorBoard

+   WandB

+   CometML

+   目标

+   MLFlow

+   ClearML

+   DVCLive

要使用其中任何一个，只需将所选类型传递给`Accelerate`中的`log_with`参数：

```py
from accelerate import Accelerator
from accelerate.utils import LoggerType

accelerator = Accelerator(log_with="all")  # For all available trackers in the environment
accelerator = Accelerator(log_with="wandb")
accelerator = Accelerator(log_with=["wandb", LoggerType.TENSORBOARD])
```

在实验开始时，应该使用`Accelerator.init_trackers()`来设置您的项目，并可能添加要记录的任何实验超参数：

```py
hps = {"num_iterations": 5, "learning_rate": 1e-2}
accelerator.init_trackers("my_project", config=hps)
```

当您准备记录任何数据时，应该使用`Accelerator.log()`。还可以传递一个`step`来将数据与训练循环中的特定步骤相关联。

```py
accelerator.log({"train_loss": 1.12, "valid_loss": 0.8}, step=1)
```

一旦训练完成，请确保运行`Accelerator.end_training()`，以便所有跟踪器可以运行其完成功能（如果有的话）。

```py
accelerator.end_training()
```

下面是一个完整的示例：

```py
from accelerate import Accelerator

accelerator = Accelerator(log_with="all")
config = {
    "num_iterations": 5,
    "learning_rate": 1e-2,
    "loss_function": str(my_loss_function),
}

accelerator.init_trackers("example_project", config=config)

my_model, my_optimizer, my_training_dataloader = accelerate.prepare(my_model, my_optimizer, my_training_dataloader)
device = accelerator.device
my_model.to(device)

for iteration in config["num_iterations"]:
    for step, batch in my_training_dataloader:
        my_optimizer.zero_grad()
        inputs, targets = batch
        inputs = inputs.to(device)
        targets = targets.to(device)
        outputs = my_model(inputs)
        loss = my_loss_function(outputs, targets)
        accelerator.backward(loss)
        my_optimizer.step()
        accelerator.log({"training_loss": loss}, step=step)
accelerator.end_training()
```

如果跟踪器需要一个目录来保存数据，比如`TensorBoard`，那么将目录路径传递给`project_dir`。当有其他配置需要与[ProjectConfiguration](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.utils.ProjectConfiguration)数据类结合时，`project_dir`参数非常有用。例如，您可以将TensorBoard数据保存到`project_dir`，其他所有内容可以记录在[`~utils.ProjectConfiguration`]的`logging_dir`参数中：

```py
accelerator = Accelerator(log_with="tensorboard", project_dir=".")

# use with ProjectConfiguration
config = ProjectConfiguration(project_dir=".", logging_dir="another/directory")
accelerator = Accelerator(log_with="tensorboard", project_config=config)
```

## 实现自定义跟踪器

要实现一个新的跟踪器以在`Accelerator`中使用，可以通过实现`GeneralTracker`类来创建一个新的跟踪器。每个跟踪器必须实现三个函数并具有三个属性：

+   `__init__`：

    +   应该存储一个`run_name`并初始化集成库的跟踪器API。

    +   如果跟踪器将数据存储在本地（例如TensorBoard），可以添加一个`logging_dir`参数。

+   `store_init_configuration`：

    +   应该接收一个`values`字典并将其存储为一次性实验配置

+   `log`：

    +   应该接收一个`values`字典和一个`step`，并将它们记录到运行中

+   `name`（`str`）:

    +   一个唯一的字符串名称，例如`"wandb"`用于wandb跟踪器。

    +   这将用于专门与此跟踪器交互

+   `requires_logging_directory`（`bool`）：

    +   这个特定跟踪器是否需要`logging_dir`，以及它是否使用一个。

+   `tracker`：

    +   这应该实现为一个`@property`函数

    +   应该返回库使用的内部跟踪机制，例如`wandb`的`run`对象。

如果记录器应该仅在主进程上执行，则每个方法还应该利用[state.PartialState](/docs/accelerate/v0.27.2/en/package_reference/state#accelerate.PartialState)类。

下面可以看到一个简短的示例，与Weights and Biases集成，仅包含相关信息并仅在主进程上记录：

```py
from accelerate.tracking import GeneralTracker, on_main_process
from typing import Optional

import wandb

class MyCustomTracker(GeneralTracker):
    name = "wandb"
    requires_logging_directory = False

 @on_main_process
    def __init__(self, run_name: str):
        self.run_name = run_name
        run = wandb.init(self.run_name)

 @property
    def tracker(self):
        return self.run.run

 @on_main_process
    def store_init_configuration(self, values: dict):
        wandb.config(values)

 @on_main_process
    def log(self, values: dict, step: Optional[int] = None):
        wandb.log(values, step=step)
```

当您准备构建您的`Accelerator`对象时，请将您的跟踪器的**实例**传递给`Accelerator.log_with`，以便自动与API一起使用：

```py
tracker = MyCustomTracker("some_run_name")
accelerator = Accelerator(log_with=tracker)
```

这些也可以与现有的跟踪器混合使用，包括`"all"`：

```py
tracker = MyCustomTracker("some_run_name")
accelerator = Accelerator(log_with=[tracker, "all"])
```

## 访问内部跟踪器

如果可能需要与跟踪器直接进行一些自定义交互，可以使用[Accelerator.get_tracker()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.get_tracker)方法快速访问一个。只需传递与跟踪器的`.name`属性对应的字符串，它将返回主进程上的该跟踪器。

这个示例展示了如何使用wandb：

```py
wandb_tracker = accelerator.get_tracker("wandb")
```

从那里，您可以像平常一样与`wandb`的`run`对象交互：

```py
wandb_run.log_artifact(some_artifact_to_log)
```

在 Accelerate 中构建的跟踪器将自动在正确的进程上执行，因此，如果一个跟踪器只应在主进程上运行，它将自动执行。

如果您想完全删除 Accelerate 的包装，可以通过以下方式实现相同的结果：

```py
wandb_tracker = accelerator.get_tracker("wandb", unwrap=True)
with accelerator.on_main_process:
    wandb_tracker.log_artifact(some_artifact_to_log)
```

## 当包装器无法工作

如果一个库的 API 不遵循严格的 `.log` 与 Neptune.AI 这样的整体字典，日志记录可以在一个 `if accelerator.is_main_process` 语句下手动完成。

```py
  from accelerate import Accelerator
+ import neptune.new as neptune

  accelerator = Accelerator()
+ run = neptune.init(...)

  my_model, my_optimizer, my_training_dataloader = accelerate.prepare(my_model, my_optimizer, my_training_dataloader)
  device = accelerator.device
  my_model.to(device)

  for iteration in config["num_iterations"]:
      for batch in my_training_dataloader:
          my_optimizer.zero_grad()
          inputs, targets = batch
          inputs = inputs.to(device)
          targets = targets.to(device)
          outputs = my_model(inputs)
          loss = my_loss_function(outputs, targets)
          total_loss += loss
          accelerator.backward(loss)
          my_optimizer.step()
+         if accelerator.is_main_process:
+             run["logs/training/batch/loss"].log(loss)
```
