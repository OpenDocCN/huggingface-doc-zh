# è·Ÿè¸ª

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/accelerate/usage_guides/tracking](https://huggingface.co/docs/accelerate/usage_guides/tracking)

æœ‰å¤§é‡çš„å®éªŒè·Ÿè¸ªAPIå¯ç”¨ï¼Œä½†æ˜¯è®©å®ƒä»¬åœ¨å¤šè¿›ç¨‹ç¯å¢ƒä¸­ä¸€èµ·å·¥ä½œé€šå¸¸ä¼šå¾ˆå¤æ‚ã€‚ğŸ¤— Accelerateæä¾›äº†ä¸€ä¸ªé€šç”¨çš„è·Ÿè¸ªAPIï¼Œå¯ä»¥ç”¨æ¥é€šè¿‡`Accelerator.log()`è®°å½•è„šæœ¬ä¸­çš„æœ‰ç”¨é¡¹ç›®

## é›†æˆè·Ÿè¸ªå™¨

ç›®å‰`Accelerate`æ”¯æŒä¸ƒç§å¼€ç®±å³ç”¨çš„è·Ÿè¸ªå™¨ï¼š

+   TensorBoard

+   WandB

+   CometML

+   ç›®æ ‡

+   MLFlow

+   ClearML

+   DVCLive

è¦ä½¿ç”¨å…¶ä¸­ä»»ä½•ä¸€ä¸ªï¼Œåªéœ€å°†æ‰€é€‰ç±»å‹ä¼ é€’ç»™`Accelerate`ä¸­çš„`log_with`å‚æ•°ï¼š

```py
from accelerate import Accelerator
from accelerate.utils import LoggerType

accelerator = Accelerator(log_with="all")  # For all available trackers in the environment
accelerator = Accelerator(log_with="wandb")
accelerator = Accelerator(log_with=["wandb", LoggerType.TENSORBOARD])
```

åœ¨å®éªŒå¼€å§‹æ—¶ï¼Œåº”è¯¥ä½¿ç”¨`Accelerator.init_trackers()`æ¥è®¾ç½®æ‚¨çš„é¡¹ç›®ï¼Œå¹¶å¯èƒ½æ·»åŠ è¦è®°å½•çš„ä»»ä½•å®éªŒè¶…å‚æ•°ï¼š

```py
hps = {"num_iterations": 5, "learning_rate": 1e-2}
accelerator.init_trackers("my_project", config=hps)
```

å½“æ‚¨å‡†å¤‡è®°å½•ä»»ä½•æ•°æ®æ—¶ï¼Œåº”è¯¥ä½¿ç”¨`Accelerator.log()`ã€‚è¿˜å¯ä»¥ä¼ é€’ä¸€ä¸ª`step`æ¥å°†æ•°æ®ä¸è®­ç»ƒå¾ªç¯ä¸­çš„ç‰¹å®šæ­¥éª¤ç›¸å…³è”ã€‚

```py
accelerator.log({"train_loss": 1.12, "valid_loss": 0.8}, step=1)
```

ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œè¯·ç¡®ä¿è¿è¡Œ`Accelerator.end_training()`ï¼Œä»¥ä¾¿æ‰€æœ‰è·Ÿè¸ªå™¨å¯ä»¥è¿è¡Œå…¶å®ŒæˆåŠŸèƒ½ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ã€‚

```py
accelerator.end_training()
```

ä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç¤ºä¾‹ï¼š

```py
from accelerate import Accelerator

accelerator = Accelerator(log_with="all")
config = {
    "num_iterations": 5,
    "learning_rate": 1e-2,
    "loss_function": str(my_loss_function),
}

accelerator.init_trackers("example_project", config=config)

my_model, my_optimizer, my_training_dataloader = accelerate.prepare(my_model, my_optimizer, my_training_dataloader)
device = accelerator.device
my_model.to(device)

for iteration in config["num_iterations"]:
    for step, batch in my_training_dataloader:
        my_optimizer.zero_grad()
        inputs, targets = batch
        inputs = inputs.to(device)
        targets = targets.to(device)
        outputs = my_model(inputs)
        loss = my_loss_function(outputs, targets)
        accelerator.backward(loss)
        my_optimizer.step()
        accelerator.log({"training_loss": loss}, step=step)
accelerator.end_training()
```

å¦‚æœè·Ÿè¸ªå™¨éœ€è¦ä¸€ä¸ªç›®å½•æ¥ä¿å­˜æ•°æ®ï¼Œæ¯”å¦‚`TensorBoard`ï¼Œé‚£ä¹ˆå°†ç›®å½•è·¯å¾„ä¼ é€’ç»™`project_dir`ã€‚å½“æœ‰å…¶ä»–é…ç½®éœ€è¦ä¸[ProjectConfiguration](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.utils.ProjectConfiguration)æ•°æ®ç±»ç»“åˆæ—¶ï¼Œ`project_dir`å‚æ•°éå¸¸æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥å°†TensorBoardæ•°æ®ä¿å­˜åˆ°`project_dir`ï¼Œå…¶ä»–æ‰€æœ‰å†…å®¹å¯ä»¥è®°å½•åœ¨[`~utils.ProjectConfiguration`]çš„`logging_dir`å‚æ•°ä¸­ï¼š

```py
accelerator = Accelerator(log_with="tensorboard", project_dir=".")

# use with ProjectConfiguration
config = ProjectConfiguration(project_dir=".", logging_dir="another/directory")
accelerator = Accelerator(log_with="tensorboard", project_config=config)
```

## å®ç°è‡ªå®šä¹‰è·Ÿè¸ªå™¨

è¦å®ç°ä¸€ä¸ªæ–°çš„è·Ÿè¸ªå™¨ä»¥åœ¨`Accelerator`ä¸­ä½¿ç”¨ï¼Œå¯ä»¥é€šè¿‡å®ç°`GeneralTracker`ç±»æ¥åˆ›å»ºä¸€ä¸ªæ–°çš„è·Ÿè¸ªå™¨ã€‚æ¯ä¸ªè·Ÿè¸ªå™¨å¿…é¡»å®ç°ä¸‰ä¸ªå‡½æ•°å¹¶å…·æœ‰ä¸‰ä¸ªå±æ€§ï¼š

+   `__init__`ï¼š

    +   åº”è¯¥å­˜å‚¨ä¸€ä¸ª`run_name`å¹¶åˆå§‹åŒ–é›†æˆåº“çš„è·Ÿè¸ªå™¨APIã€‚

    +   å¦‚æœè·Ÿè¸ªå™¨å°†æ•°æ®å­˜å‚¨åœ¨æœ¬åœ°ï¼ˆä¾‹å¦‚TensorBoardï¼‰ï¼Œå¯ä»¥æ·»åŠ ä¸€ä¸ª`logging_dir`å‚æ•°ã€‚

+   `store_init_configuration`ï¼š

    +   åº”è¯¥æ¥æ”¶ä¸€ä¸ª`values`å­—å…¸å¹¶å°†å…¶å­˜å‚¨ä¸ºä¸€æ¬¡æ€§å®éªŒé…ç½®

+   `log`ï¼š

    +   åº”è¯¥æ¥æ”¶ä¸€ä¸ª`values`å­—å…¸å’Œä¸€ä¸ª`step`ï¼Œå¹¶å°†å®ƒä»¬è®°å½•åˆ°è¿è¡Œä¸­

+   `name`ï¼ˆ`str`ï¼‰:

    +   ä¸€ä¸ªå”¯ä¸€çš„å­—ç¬¦ä¸²åç§°ï¼Œä¾‹å¦‚`"wandb"`ç”¨äºwandbè·Ÿè¸ªå™¨ã€‚

    +   è¿™å°†ç”¨äºä¸“é—¨ä¸æ­¤è·Ÿè¸ªå™¨äº¤äº’

+   `requires_logging_directory`ï¼ˆ`bool`ï¼‰ï¼š

    +   è¿™ä¸ªç‰¹å®šè·Ÿè¸ªå™¨æ˜¯å¦éœ€è¦`logging_dir`ï¼Œä»¥åŠå®ƒæ˜¯å¦ä½¿ç”¨ä¸€ä¸ªã€‚

+   `tracker`ï¼š

    +   è¿™åº”è¯¥å®ç°ä¸ºä¸€ä¸ª`@property`å‡½æ•°

    +   åº”è¯¥è¿”å›åº“ä½¿ç”¨çš„å†…éƒ¨è·Ÿè¸ªæœºåˆ¶ï¼Œä¾‹å¦‚`wandb`çš„`run`å¯¹è±¡ã€‚

å¦‚æœè®°å½•å™¨åº”è¯¥ä»…åœ¨ä¸»è¿›ç¨‹ä¸Šæ‰§è¡Œï¼Œåˆ™æ¯ä¸ªæ–¹æ³•è¿˜åº”è¯¥åˆ©ç”¨[state.PartialState](/docs/accelerate/v0.27.2/en/package_reference/state#accelerate.PartialState)ç±»ã€‚

ä¸‹é¢å¯ä»¥çœ‹åˆ°ä¸€ä¸ªç®€çŸ­çš„ç¤ºä¾‹ï¼Œä¸Weights and Biasesé›†æˆï¼Œä»…åŒ…å«ç›¸å…³ä¿¡æ¯å¹¶ä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®°å½•ï¼š

```py
from accelerate.tracking import GeneralTracker, on_main_process
from typing import Optional

import wandb

class MyCustomTracker(GeneralTracker):
    name = "wandb"
    requires_logging_directory = False

 @on_main_process
    def __init__(self, run_name: str):
        self.run_name = run_name
        run = wandb.init(self.run_name)

 @property
    def tracker(self):
        return self.run.run

 @on_main_process
    def store_init_configuration(self, values: dict):
        wandb.config(values)

 @on_main_process
    def log(self, values: dict, step: Optional[int] = None):
        wandb.log(values, step=step)
```

å½“æ‚¨å‡†å¤‡æ„å»ºæ‚¨çš„`Accelerator`å¯¹è±¡æ—¶ï¼Œè¯·å°†æ‚¨çš„è·Ÿè¸ªå™¨çš„**å®ä¾‹**ä¼ é€’ç»™`Accelerator.log_with`ï¼Œä»¥ä¾¿è‡ªåŠ¨ä¸APIä¸€èµ·ä½¿ç”¨ï¼š

```py
tracker = MyCustomTracker("some_run_name")
accelerator = Accelerator(log_with=tracker)
```

è¿™äº›ä¹Ÿå¯ä»¥ä¸ç°æœ‰çš„è·Ÿè¸ªå™¨æ··åˆä½¿ç”¨ï¼ŒåŒ…æ‹¬`"all"`ï¼š

```py
tracker = MyCustomTracker("some_run_name")
accelerator = Accelerator(log_with=[tracker, "all"])
```

## è®¿é—®å†…éƒ¨è·Ÿè¸ªå™¨

å¦‚æœå¯èƒ½éœ€è¦ä¸è·Ÿè¸ªå™¨ç›´æ¥è¿›è¡Œä¸€äº›è‡ªå®šä¹‰äº¤äº’ï¼Œå¯ä»¥ä½¿ç”¨[Accelerator.get_tracker()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.get_tracker)æ–¹æ³•å¿«é€Ÿè®¿é—®ä¸€ä¸ªã€‚åªéœ€ä¼ é€’ä¸è·Ÿè¸ªå™¨çš„`.name`å±æ€§å¯¹åº”çš„å­—ç¬¦ä¸²ï¼Œå®ƒå°†è¿”å›ä¸»è¿›ç¨‹ä¸Šçš„è¯¥è·Ÿè¸ªå™¨ã€‚

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨wandbï¼š

```py
wandb_tracker = accelerator.get_tracker("wandb")
```

ä»é‚£é‡Œï¼Œæ‚¨å¯ä»¥åƒå¹³å¸¸ä¸€æ ·ä¸`wandb`çš„`run`å¯¹è±¡äº¤äº’ï¼š

```py
wandb_run.log_artifact(some_artifact_to_log)
```

åœ¨ Accelerate ä¸­æ„å»ºçš„è·Ÿè¸ªå™¨å°†è‡ªåŠ¨åœ¨æ­£ç¡®çš„è¿›ç¨‹ä¸Šæ‰§è¡Œï¼Œå› æ­¤ï¼Œå¦‚æœä¸€ä¸ªè·Ÿè¸ªå™¨åªåº”åœ¨ä¸»è¿›ç¨‹ä¸Šè¿è¡Œï¼Œå®ƒå°†è‡ªåŠ¨æ‰§è¡Œã€‚

å¦‚æœæ‚¨æƒ³å®Œå…¨åˆ é™¤ Accelerate çš„åŒ…è£…ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°ç›¸åŒçš„ç»“æœï¼š

```py
wandb_tracker = accelerator.get_tracker("wandb", unwrap=True)
with accelerator.on_main_process:
    wandb_tracker.log_artifact(some_artifact_to_log)
```

## å½“åŒ…è£…å™¨æ— æ³•å·¥ä½œ

å¦‚æœä¸€ä¸ªåº“çš„ API ä¸éµå¾ªä¸¥æ ¼çš„ `.log` ä¸ Neptune.AI è¿™æ ·çš„æ•´ä½“å­—å…¸ï¼Œæ—¥å¿—è®°å½•å¯ä»¥åœ¨ä¸€ä¸ª `if accelerator.is_main_process` è¯­å¥ä¸‹æ‰‹åŠ¨å®Œæˆã€‚

```py
  from accelerate import Accelerator
+ import neptune.new as neptune

  accelerator = Accelerator()
+ run = neptune.init(...)

  my_model, my_optimizer, my_training_dataloader = accelerate.prepare(my_model, my_optimizer, my_training_dataloader)
  device = accelerator.device
  my_model.to(device)

  for iteration in config["num_iterations"]:
      for batch in my_training_dataloader:
          my_optimizer.zero_grad()
          inputs, targets = batch
          inputs = inputs.to(device)
          targets = targets.to(device)
          outputs = my_model(inputs)
          loss = my_loss_function(outputs, targets)
          total_loss += loss
          accelerator.backward(loss)
          my_optimizer.step()
+         if accelerator.is_main_process:
+             run["logs/training/batch/loss"].log(loss)
```
