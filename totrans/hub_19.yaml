- en: Widgets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/hub/models-widgets](https://huggingface.co/docs/hub/models-widgets)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Whatâ€™s a widget?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many model repos have a widget that allows anyone to run inferences directly
    in the browser!
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Named Entity Recognition](https://huggingface.co/spacy/en_core_web_sm?text=My+name+is+Sarah+and+I+live+in+London)
    using [spaCy](https://spacy.io/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Image Classification](https://huggingface.co/google/vit-base-patch16-224)
    using [ðŸ¤— Transformers](https://github.com/huggingface/transformers)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Text to Speech](https://huggingface.co/julien-c/ljspeech_tts_train_tacotron2_raw_phn_tacotron_g2p_en_no_space_train)
    using [ESPnet](https://github.com/espnet/espnet).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sentence Similarity](https://huggingface.co/osanseviero/full-sentence-distillroberta3)
    using [Sentence Transformers](https://github.com/UKPLab/sentence-transformers).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can try out all the widgets [here](https://huggingface-widgets.netlify.app/).
  prefs: []
  type: TYPE_NORMAL
- en: Enabling a widget
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A widget is automatically created for your model when you upload it to the Hub.
    To determine which pipeline and widget to display (`text-classification`, `token-classification`,
    `translation`, etc.), we analyze information in the repo, such as the metadata
    provided in the model card and configuration files. This information is mapped
    to a single `pipeline_tag`. We choose to expose **only one** widget per model
    for simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: 'For most use cases, we determine the model type from the tags. For example,
    if there is `tag: text-classification` in the [model card metadata](./model-cards),
    the inferred `pipeline_tag` will be `text-classification`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For some libraries, such as ðŸ¤— `Transformers`, the model type should be inferred
    automatically based from configuration files (`config.json`). The architecture
    can determine the type: for example, `AutoModelForTokenClassification` corresponds
    to `token-classification`. If youâ€™re interested in this, you can see pseudo-code
    in [this gist](https://gist.github.com/julien-c/857ba86a6c6a895ecd90e7f7cab48046).'
  prefs: []
  type: TYPE_NORMAL
- en: '**You can always manually override your pipeline type with `pipeline_tag: xxx`
    in your [model card metadata](./model-cards#model-card-metadata).** (You can also
    use the metadata GUI editor to do this).'
  prefs: []
  type: TYPE_NORMAL
- en: How can I control my modelâ€™s widget example input?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can specify the widget input in the model card metadata section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can provide more than one example input. In the examples dropdown menu of
    the widget, they will appear as `Example 1`, `Example 2`, etc. Optionally, you
    can supply `example_title` as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e667af198cffeb9b266712fc947a249.png) ![](../Images/b3e00f232523405c5b89a7cbb3c63c02.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Moreover, you can specify non-text example inputs in the model card metadata.
    Refer [here](./models-widgets-examples) for a complete list of sample input formats
    for all widget types. For vision & audio widget types, provide example inputs
    with `src` rather than `text`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, allow users to choose from two sample audio files for automatic
    speech recognition tasks by:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that you can also include example files in your model repository and use
    them as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'But even more convenient, if the file lives in the corresponding model repo,
    you can just use the filename or file path inside the repo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'or if it was nested inside the repo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We provide example inputs for some languages and most widget types in [default-widget-inputs.ts
    file](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/default-widget-inputs.ts).
    If some examples are missing, we welcome PRs from the community to add them!
  prefs: []
  type: TYPE_NORMAL
- en: Example outputs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As an extension to example inputs, for each widget example, you can also optionally
    describe the corresponding model output, directly in the `output` property.
  prefs: []
  type: TYPE_NORMAL
- en: This is useful when the model is not yet supported by the Inference API (for
    instance, the model library is not yet supported or the model is too large) so
    that the model page can still showcase how the model works and what results it
    gives.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, for an [automatic-speech-recognition](./models-widgets-examples#automatic-speech-recognition)
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/08c477c6d1dd4bb7c844c730f176c3e9.png) ![](../Images/c80148c8cad45a4510b41176888bfa95.png)'
  prefs: []
  type: TYPE_IMG
- en: The `output` property should be a YAML dictionary that represents the Inference
    API output.
  prefs: []
  type: TYPE_NORMAL
- en: For a model that outputs text, see the example above.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a model that outputs labels (like a [text-classification](./models-widgets-examples#text-classification)
    model for instance), output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/933ebdde720cfeda653c4dfa6dd91f56.png) ![](../Images/51974136749f2869e4b018133697ada9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, for a model that outputs an image, audio, or any other kind of asset,
    the output should include a `url` property linking to either a file name or path
    inside the repo or a remote URL. For example, for a text-to-image model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d1f98b52d0f98e0639af7b77624d07af.png) ![](../Images/5002ad2cf1d0dcdf434b887f68789704.png)'
  prefs: []
  type: TYPE_IMG
- en: We can also surface the example outputs in the Hugging Face UI, for instance,
    for a text-to-image model to display a gallery of cool image generations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0576121b8e46b63008259c4e8831cc52.png)'
  prefs: []
  type: TYPE_IMG
- en: What are all the possible task/widget types?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can find all the supported tasks in [pipelines.ts file](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/pipelines.ts).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some links to examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '`text-classification`, for instance [`roberta-large-mnli`](https://huggingface.co/roberta-large-mnli)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token-classification`, for instance [`dbmdz/bert-large-cased-finetuned-conll03-english`](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`question-answering`, for instance [`distilbert-base-uncased-distilled-squad`](https://huggingface.co/distilbert-base-uncased-distilled-squad)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`translation`, for instance [`t5-base`](https://huggingface.co/t5-base)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`summarization`, for instance [`facebook/bart-large-cnn`](https://huggingface.co/facebook/bart-large-cnn)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`conversational`, for instance [`facebook/blenderbot-400M-distill`](https://huggingface.co/facebook/blenderbot-400M-distill)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text-generation`, for instance [`gpt2`](https://huggingface.co/gpt2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fill-mask`, for instance [`distilroberta-base`](https://huggingface.co/distilroberta-base)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`zero-shot-classification` (implemented on top of a nli `text-classification`
    model), for instance [`facebook/bart-large-mnli`](https://huggingface.co/facebook/bart-large-mnli)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`table-question-answering`, for instance [`google/tapas-base-finetuned-wtq`](https://huggingface.co/google/tapas-base-finetuned-wtq)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sentence-similarity`, for instance [`osanseviero/full-sentence-distillroberta2`](/osanseviero/full-sentence-distillroberta2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can I control my modelâ€™s widget Inference API parameters?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generally, the Inference API for a model uses the default pipeline settings
    associated with each task. But if youâ€™d like to change the pipelineâ€™s default
    settings and specify additional inference parameters, you can configure the parameters
    directly through the model card metadata. Refer [here](https://huggingface.co/docs/api-inference/detailed_parameters)
    for some of the most commonly used parameters associated with each task.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if you want to specify an aggregation strategy for a NER task
    in the widget:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Or if youâ€™d like to change the temperature for a summarization task in the
    widget:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The Inference API allows you to send HTTP requests to models in the Hugging
    Face Hub, and itâ€™s 2x to 10x faster than the widgets! âš¡âš¡ Learn more about it by
    reading the [Inference API documentation](./models-inference). Finally, you can
    also deploy all those models to dedicated [Inference Endpoints](https://huggingface.co/docs/inference-endpoints).
  prefs: []
  type: TYPE_NORMAL
