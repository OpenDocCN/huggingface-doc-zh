- en: Widgets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小部件
- en: 'Original text: [https://huggingface.co/docs/hub/models-widgets](https://huggingface.co/docs/hub/models-widgets)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/hub/models-widgets](https://huggingface.co/docs/hub/models-widgets)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: What’s a widget?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是小部件？
- en: Many model repos have a widget that allows anyone to run inferences directly
    in the browser!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 许多模型存储库都有一个小部件，允许任何人直接在浏览器中运行推理！
- en: 'Here are some examples:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些示例：
- en: '[Named Entity Recognition](https://huggingface.co/spacy/en_core_web_sm?text=My+name+is+Sarah+and+I+live+in+London)
    using [spaCy](https://spacy.io/).'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[命名实体识别](https://huggingface.co/spacy/en_core_web_sm?text=My+name+is+Sarah+and+I+live+in+London)
    使用[spaCy](https://spacy.io/)。'
- en: '[Image Classification](https://huggingface.co/google/vit-base-patch16-224)
    using [🤗 Transformers](https://github.com/huggingface/transformers)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像分类](https://huggingface.co/google/vit-base-patch16-224) 使用[🤗 Transformers](https://github.com/huggingface/transformers)'
- en: '[Text to Speech](https://huggingface.co/julien-c/ljspeech_tts_train_tacotron2_raw_phn_tacotron_g2p_en_no_space_train)
    using [ESPnet](https://github.com/espnet/espnet).'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文本转语音](https://huggingface.co/julien-c/ljspeech_tts_train_tacotron2_raw_phn_tacotron_g2p_en_no_space_train)
    使用[ESPnet](https://github.com/espnet/espnet)。'
- en: '[Sentence Similarity](https://huggingface.co/osanseviero/full-sentence-distillroberta3)
    using [Sentence Transformers](https://github.com/UKPLab/sentence-transformers).'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[句子相似度](https://huggingface.co/osanseviero/full-sentence-distillroberta3) 使用[句子转换器](https://github.com/UKPLab/sentence-transformers)。'
- en: You can try out all the widgets [here](https://huggingface-widgets.netlify.app/).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[这里](https://huggingface-widgets.netlify.app/)尝试所有小部件。
- en: Enabling a widget
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用小部件
- en: A widget is automatically created for your model when you upload it to the Hub.
    To determine which pipeline and widget to display (`text-classification`, `token-classification`,
    `translation`, etc.), we analyze information in the repo, such as the metadata
    provided in the model card and configuration files. This information is mapped
    to a single `pipeline_tag`. We choose to expose **only one** widget per model
    for simplicity.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将模型上传到Hub时，将自动为您的模型创建一个小部件。为了确定显示哪个管道和小部件（`文本分类`，`标记分类`，`翻译`等），我们会分析存储库中提供的元数据和配置文件等信息。这些信息被映射到一个单一的`pipeline_tag`。为了简单起见，我们选择**仅显示一个**模型的小部件。
- en: 'For most use cases, we determine the model type from the tags. For example,
    if there is `tag: text-classification` in the [model card metadata](./model-cards),
    the inferred `pipeline_tag` will be `text-classification`.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '对于大多数用例，我们从标签中确定模型类型。例如，如果在[model卡片元数据](./model-cards)中有`tag: text-classification`，则推断的`pipeline_tag`将是`text-classification`。'
- en: 'For some libraries, such as 🤗 `Transformers`, the model type should be inferred
    automatically based from configuration files (`config.json`). The architecture
    can determine the type: for example, `AutoModelForTokenClassification` corresponds
    to `token-classification`. If you’re interested in this, you can see pseudo-code
    in [this gist](https://gist.github.com/julien-c/857ba86a6c6a895ecd90e7f7cab48046).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一些库，例如🤗`Transformers`，应根据配置文件（`config.json`）自动推断模型类型。架构可以确定类型：例如，`AutoModelForTokenClassification`对应于`token-classification`。如果您对此感兴趣，可以在[此代码片段](https://gist.github.com/julien-c/857ba86a6c6a895ecd90e7f7cab48046)中看到伪代码。
- en: '**You can always manually override your pipeline type with `pipeline_tag: xxx`
    in your [model card metadata](./model-cards#model-card-metadata).** (You can also
    use the metadata GUI editor to do this).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**您可以始终在您的[model卡片元数据](./model-cards#model-card-metadata)中手动覆盖您的管道类型，使用`pipeline_tag:
    xxx`。**（您也可以使用元数据GUI编辑器来执行此操作）。'
- en: How can I control my model’s widget example input?
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何控制我的模型的小部件示例输入？
- en: 'You can specify the widget input in the model card metadata section:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在模型卡片元数据部分指定小部件输入：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You can provide more than one example input. In the examples dropdown menu of
    the widget, they will appear as `Example 1`, `Example 2`, etc. Optionally, you
    can supply `example_title` as well.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以提供多个示例输入。在小部件的示例下拉菜单中，它们将显示为`示例1`，`示例2`等。也可以选择提供`example_title`。
- en: '![](../Images/2e667af198cffeb9b266712fc947a249.png) ![](../Images/b3e00f232523405c5b89a7cbb3c63c02.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e667af198cffeb9b266712fc947a249.png) ![](../Images/b3e00f232523405c5b89a7cbb3c63c02.png)'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Moreover, you can specify non-text example inputs in the model card metadata.
    Refer [here](./models-widgets-examples) for a complete list of sample input formats
    for all widget types. For vision & audio widget types, provide example inputs
    with `src` rather than `text`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可以在模型卡片元数据中指定非文本示例输入。请参考[此处](./models-widgets-examples)以获取所有小部件类型的示例输入格式的完整列表。对于视觉和音频小部件类型，请使用`src`而不是`text`提供示例输入。
- en: 'For example, allow users to choose from two sample audio files for automatic
    speech recognition tasks by:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，允许用户从两个示例音频文件中选择，用于自动语音识别任务：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that you can also include example files in your model repository and use
    them as:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您还可以在您的模型存储库中包含示例文件并将其用作：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'But even more convenient, if the file lives in the corresponding model repo,
    you can just use the filename or file path inside the repo:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但更方便的是，如果文件位于相应的模型存储库中，您可以直接使用文件名或存储库内的文件路径：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'or if it was nested inside the repo:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 或者如果它被嵌套在存储库中：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We provide example inputs for some languages and most widget types in [default-widget-inputs.ts
    file](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/default-widget-inputs.ts).
    If some examples are missing, we welcome PRs from the community to add them!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为一些语言和大多数小部件类型提供示例输入，[default-widget-inputs.ts文件](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/default-widget-inputs.ts)中有。如果缺少某些示例，我们欢迎社区提供PR来添加它们！
- en: Example outputs
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例输出
- en: As an extension to example inputs, for each widget example, you can also optionally
    describe the corresponding model output, directly in the `output` property.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例输入的扩展，对于每个小部件示例，您还可以选择在`output`属性中直接描述相应的模型输出。
- en: This is useful when the model is not yet supported by the Inference API (for
    instance, the model library is not yet supported or the model is too large) so
    that the model page can still showcase how the model works and what results it
    gives.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型尚未受到推理API的支持时（例如，模型库尚未受到支持或模型过大），这将非常有用，以便模型页面仍然可以展示模型的工作原理和结果。
- en: 'For instance, for an [automatic-speech-recognition](./models-widgets-examples#automatic-speech-recognition)
    model:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于[automatic-speech-recognition](./models-widgets-examples#automatic-speech-recognition)模型：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/08c477c6d1dd4bb7c844c730f176c3e9.png) ![](../Images/c80148c8cad45a4510b41176888bfa95.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08c477c6d1dd4bb7c844c730f176c3e9.png) ![](../Images/c80148c8cad45a4510b41176888bfa95.png)'
- en: The `output` property should be a YAML dictionary that represents the Inference
    API output.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`output`属性应该是一个表示推理API输出的YAML字典。'
- en: For a model that outputs text, see the example above.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输出文本的模型，请参阅上面的示例。
- en: 'For a model that outputs labels (like a [text-classification](./models-widgets-examples#text-classification)
    model for instance), output should look like this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输出标签的模型（例如[文本分类](./models-widgets-examples#text-classification)模型），输出应如下所示：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/933ebdde720cfeda653c4dfa6dd91f56.png) ![](../Images/51974136749f2869e4b018133697ada9.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/933ebdde720cfeda653c4dfa6dd91f56.png) ![](../Images/51974136749f2869e4b018133697ada9.png)'
- en: 'Finally, for a model that outputs an image, audio, or any other kind of asset,
    the output should include a `url` property linking to either a file name or path
    inside the repo or a remote URL. For example, for a text-to-image model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于输出图像、音频或任何其他类型资产的模型，输出应包括一个`url`属性，链接到存储库内的文件名或路径，或远程URL。例如，对于文本到图像模型：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/d1f98b52d0f98e0639af7b77624d07af.png) ![](../Images/5002ad2cf1d0dcdf434b887f68789704.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1f98b52d0f98e0639af7b77624d07af.png) ![](../Images/5002ad2cf1d0dcdf434b887f68789704.png)'
- en: We can also surface the example outputs in the Hugging Face UI, for instance,
    for a text-to-image model to display a gallery of cool image generations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在Hugging Face UI中展示示例输出，例如，对于文本到图像模型，以显示一个酷炫图像生成的画廊。
- en: '![](../Images/0576121b8e46b63008259c4e8831cc52.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0576121b8e46b63008259c4e8831cc52.png)'
- en: What are all the possible task/widget types?
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 所有可能的任务/小部件类型是什么？
- en: You can find all the supported tasks in [pipelines.ts file](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/pipelines.ts).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[pipelines.ts文件](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/pipelines.ts)中找到所有支持的任务。
- en: 'Here are some links to examples:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些示例链接：
- en: '`text-classification`, for instance [`roberta-large-mnli`](https://huggingface.co/roberta-large-mnli)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text-classification`，例如[`roberta-large-mnli`](https://huggingface.co/roberta-large-mnli)'
- en: '`token-classification`, for instance [`dbmdz/bert-large-cased-finetuned-conll03-english`](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token-classification`，例如[`dbmdz/bert-large-cased-finetuned-conll03-english`](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)'
- en: '`question-answering`, for instance [`distilbert-base-uncased-distilled-squad`](https://huggingface.co/distilbert-base-uncased-distilled-squad)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question-answering`，例如[`distilbert-base-uncased-distilled-squad`](https://huggingface.co/distilbert-base-uncased-distilled-squad)'
- en: '`translation`, for instance [`t5-base`](https://huggingface.co/t5-base)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`translation`，例如[`t5-base`](https://huggingface.co/t5-base)'
- en: '`summarization`, for instance [`facebook/bart-large-cnn`](https://huggingface.co/facebook/bart-large-cnn)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`summarization`，例如[`facebook/bart-large-cnn`](https://huggingface.co/facebook/bart-large-cnn)'
- en: '`conversational`, for instance [`facebook/blenderbot-400M-distill`](https://huggingface.co/facebook/blenderbot-400M-distill)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conversational`，例如[`facebook/blenderbot-400M-distill`](https://huggingface.co/facebook/blenderbot-400M-distill)'
- en: '`text-generation`, for instance [`gpt2`](https://huggingface.co/gpt2)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text-generation`，例如[`gpt2`](https://huggingface.co/gpt2)'
- en: '`fill-mask`, for instance [`distilroberta-base`](https://huggingface.co/distilroberta-base)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fill-mask`，例如[`distilroberta-base`](https://huggingface.co/distilroberta-base)'
- en: '`zero-shot-classification` (implemented on top of a nli `text-classification`
    model), for instance [`facebook/bart-large-mnli`](https://huggingface.co/facebook/bart-large-mnli)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zero-shot-classification`（建立在nli `text-classification`模型之上），例如[`facebook/bart-large-mnli`](https://huggingface.co/facebook/bart-large-mnli)'
- en: '`table-question-answering`, for instance [`google/tapas-base-finetuned-wtq`](https://huggingface.co/google/tapas-base-finetuned-wtq)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table-question-answering`，例如[`google/tapas-base-finetuned-wtq`](https://huggingface.co/google/tapas-base-finetuned-wtq)'
- en: '`sentence-similarity`, for instance [`osanseviero/full-sentence-distillroberta2`](/osanseviero/full-sentence-distillroberta2)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sentence-similarity`，例如[`osanseviero/full-sentence-distillroberta2`](/osanseviero/full-sentence-distillroberta2)'
- en: How can I control my model’s widget Inference API parameters?
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何控制我的模型小部件推理API参数？
- en: Generally, the Inference API for a model uses the default pipeline settings
    associated with each task. But if you’d like to change the pipeline’s default
    settings and specify additional inference parameters, you can configure the parameters
    directly through the model card metadata. Refer [here](https://huggingface.co/docs/api-inference/detailed_parameters)
    for some of the most commonly used parameters associated with each task.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，模型的推理API使用与每个任务相关的默认管道设置。但是，如果您想更改管道的默认设置并指定额外的推理参数，可以通过模型卡片元数据直接配置参数。有关与每个任务相关的一些常用参数，请参考[这里](https://huggingface.co/docs/api-inference/detailed_parameters)。
- en: 'For example, if you want to specify an aggregation strategy for a NER task
    in the widget:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您想为小部件中的NER任务指定聚合策略：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Or if you’d like to change the temperature for a summarization task in the
    widget:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您想在小部件中更改摘要任务的温度：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The Inference API allows you to send HTTP requests to models in the Hugging
    Face Hub, and it’s 2x to 10x faster than the widgets! ⚡⚡ Learn more about it by
    reading the [Inference API documentation](./models-inference). Finally, you can
    also deploy all those models to dedicated [Inference Endpoints](https://huggingface.co/docs/inference-endpoints).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 推理API允许您向Hugging Face Hub中的模型发送HTTP请求，比小部件快2倍到10倍！⚡⚡ 通过阅读[推理API文档](./models-inference)了解更多。最后，您还可以将所有这些模型部署到专用的[推理端点](https://huggingface.co/docs/inference-endpoints)。
