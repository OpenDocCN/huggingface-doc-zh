- en: DiffEdit
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DiffEdit
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/diffedit](https://huggingface.co/docs/diffusers/api/pipelines/diffedit)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/pipelines/diffedit](https://huggingface.co/docs/diffusers/api/pipelines/diffedit)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[DiffEdit: Diffusion-based semantic image editing with mask guidance](https://huggingface.co/papers/2210.11427)
    is by Guillaume Couairon, Jakob Verbeek, Holger Schwenk, and Matthieu Cord.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[DiffEdit：基于扩散的带蒙版指导的语义图像编辑](https://huggingface.co/papers/2210.11427)由Guillaume
    Couairon、Jakob Verbeek、Holger Schwenk和Matthieu Cord撰写。'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Image generation has recently seen tremendous advances, with diffusion models
    allowing to synthesize convincing images for a large variety of text prompts.
    In this article, we propose DiffEdit, a method to take advantage of text-conditioned
    diffusion models for the task of semantic image editing, where the goal is to
    edit an image based on a text query. Semantic image editing is an extension of
    image generation, with the additional constraint that the generated image should
    be as similar as possible to a given input image. Current editing methods based
    on diffusion models usually require to provide a mask, making the task much easier
    by treating it as a conditional inpainting task. In contrast, our main contribution
    is able to automatically generate a mask highlighting regions of the input image
    that need to be edited, by contrasting predictions of a diffusion model conditioned
    on different text prompts. Moreover, we rely on latent inference to preserve content
    in those regions of interest and show excellent synergies with mask-based diffusion.
    DiffEdit achieves state-of-the-art editing performance on ImageNet. In addition,
    we evaluate semantic image editing in more challenging settings, using images
    from the COCO dataset as well as text-based generated images.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*图像生成最近取得了巨大进展，扩散模型允许根据各种文本提示合成令人信服的图像。在本文中，我们提出了DiffEdit，一种利用文本条件扩散模型进行语义图像编辑任务的方法，其目标是根据文本查询编辑图像。语义图像编辑是图像生成的延伸，额外的约束是生成的图像应尽可能与给定的输入图像相似。基于扩散模型的当前编辑方法通常需要提供一个蒙版，通过将其视为条件修补任务，使任务变得更容易得多。相比之下，我们的主要贡献是能够自动生成一个蒙版，突出显示需要编辑的输入图像区域，通过对比受不同文本提示条件的扩散模型的预测。此外，我们依赖潜在推断来保留感兴趣区域的内容，并与基于蒙版的扩散表现出卓越的协同作用。DiffEdit在ImageNet上实现了最先进的编辑性能。此外，我们使用来自COCO数据集的图像以及基于文本生成的图像来评估更具挑战性的语义图像编辑。*'
- en: The original codebase can be found at [Xiang-cd/DiffEdit-stable-diffusion](https://github.com/Xiang-cd/DiffEdit-stable-diffusion),
    and you can try it out in this [demo](https://blog.problemsolversguild.com/technical/research/2022/11/02/DiffEdit-Implementation.html).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 原始代码库可以在[Xiang-cd/DiffEdit-stable-diffusion](https://github.com/Xiang-cd/DiffEdit-stable-diffusion)找到，您可以在此[演示](https://blog.problemsolversguild.com/technical/research/2022/11/02/DiffEdit-Implementation.html)中尝试。
- en: This pipeline was contributed by [clarencechen](https://github.com/clarencechen).
    ❤️
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这个流水线是由[clarencechen](https://github.com/clarencechen)贡献的。❤️
- en: Tips
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示
- en: The pipeline can generate masks that can be fed into other inpainting pipelines.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该流水线可以生成可供其他修补流水线使用的蒙版。
- en: In order to generate an image using this pipeline, both an image mask (source
    and target prompts can be manually specified or generated, and passed to [generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask))
    and a set of partially inverted latents (generated using [invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert))
    *must* be provided as arguments when calling the pipeline to generate the final
    edited image.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了使用这个流水线生成图像，必须在调用流水线生成最终编辑的图像时提供图像蒙版（源和目标提示可以手动指定或生成，并传递给[generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask))和一组部分反转的潜在变量（使用[invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)生成）*必须*作为参数提供。
- en: The function [generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)
    exposes two prompt arguments, `source_prompt` and `target_prompt` that let you
    control the locations of the semantic edits in the final image to be generated.
    Let’s say, you wanted to translate from “cat” to “dog”. In this case, the edit
    direction will be “cat -> dog”. To reflect this in the generated mask, you simply
    have to set the embeddings related to the phrases including “cat” to `source_prompt`
    and “dog” to `target_prompt`.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数[generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)公开了两个提示参数，`source_prompt`和`target_prompt`，让您控制最终生成的图像中语义编辑的位置。假设您想要从“cat”翻译为“dog”。在这种情况下，编辑方向将是“cat
    -> dog”。为了在生成的蒙版中反映这一点，您只需将与包含“cat”短语相关的嵌入设置为`source_prompt`，将“dog”设置为`target_prompt`。
- en: When generating partially inverted latents using `invert`, assign a caption
    or text embedding describing the overall image to the `prompt` argument to help
    guide the inverse latent sampling process. In most cases, the source concept is
    sufficiently descriptive to yield good results, but feel free to explore alternatives.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用`invert`生成部分反转潜在变量时，将描述整体图像的标题或文本嵌入分配给`prompt`参数，以帮助指导反向潜在抽样过程。在大多数情况下，源概念足够描述性，可以产生良好的结果，但请随时探索其他选择。
- en: When calling the pipeline to generate the final edited image, assign the source
    concept to `negative_prompt` and the target concept to `prompt`. Taking the above
    example, you simply have to set the embeddings related to the phrases including
    “cat” to `negative_prompt` and “dog” to `prompt`.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用流水线生成最终编辑的图像时，将源概念分配给`negative_prompt`，将目标概念分配给`prompt`。以上面的例子为例，您只需将与包含“cat”短语相关的嵌入设置为`negative_prompt`，将“dog”设置为`prompt`。
- en: 'If you wanted to reverse the direction in the example above, i.e., “dog ->
    cat”, then it’s recommended to:'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您想要在上面的示例中反转方向，即“dog -> cat”，那么建议：
- en: Swap the `source_prompt` and `target_prompt` in the arguments to `generate_mask`.
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用`generate_mask`时，交换参数中的`source_prompt`和`target_prompt`。
- en: Change the input prompt in [invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)
    to include “dog”.
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)
    中更改输入提示以包含“dog”。
- en: Swap the `prompt` and `negative_prompt` in the arguments to call the pipeline
    to generate the final edited image.
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用管道生成最终编辑图像的参数中交换`prompt`和`negative_prompt`。
- en: The source and target prompts, or their corresponding embeddings, can also be
    automatically generated. Please refer to the [DiffEdit](../../using-diffusers/diffedit)
    guide for more details.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源和目标提示，或它们对应的嵌入，也可以自动生成。请参考 [DiffEdit](../../using-diffusers/diffedit) 指南获取更多详细信息。
- en: StableDiffusionDiffEditPipeline
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionDiffEditPipeline
- en: '### `class diffusers.StableDiffusionDiffEditPipeline`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionDiffEditPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L238)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L238)'
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — 变分自动编码器（VAE）模型，用于将图像编码和解码为潜在表示。'
- en: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` ([CLIPTextModel](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTextModel))
    — 冻结文本编码器（[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)）。'
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — A `CLIPTokenizer` to tokenize text.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    — 一个`CLIPTokenizer`用于对文本进行标记化。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — A `UNet2DConditionModel` to denoise the encoded image latents.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 一个`UNet2DConditionModel`用于去噪编码图像潜在部分。'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — A scheduler to be used in combination with `unet` to denoise the encoded image
    latents.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    — 一个调度器，用于与`unet`结合使用，去噪编码图像潜在部分。'
- en: '`inverse_scheduler` ([DDIMInverseScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim_inverse#diffusers.DDIMInverseScheduler))
    — A scheduler to be used in combination with `unet` to fill in the unmasked part
    of the input latents.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inverse_scheduler` ([DDIMInverseScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim_inverse#diffusers.DDIMInverseScheduler))
    — 一个调度器，用于与`unet`结合使用，填充输入潜在部分的未遮罩部分。'
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) — Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model’s potential harms.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safety_checker` (`StableDiffusionSafetyChecker`) — 用于估计生成的图像是否可能被视为具有冒犯性或有害的分类模块。请参考
    [模型卡片](https://huggingface.co/runwayml/stable-diffusion-v1-5) 以获取有关模型潜在危害的更多详细信息。'
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    — 一个`CLIPImageProcessor`用于从生成的图像中提取特征；作为`安全检查器`的输入。'
- en: This is an experimental feature!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个实验性功能！
- en: Pipeline for text-guided image inpainting using Stable Diffusion and DiffEdit.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Stable Diffusion 和 DiffEdit 进行文本引导图像修补的管道。
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以获取所有管道实现的通用方法（下载、保存、在特定设备上运行等）。
- en: 'The pipeline also inherits the following loading and saving methods:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 该管道还继承以下加载和保存方法：
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    用于加载文本反演嵌入。'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.load_lora_weights)
    用于加载 LoRA 权重。'
- en: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    for saving LoRA weights'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[save_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.LoraLoaderMixin.save_lora_weights)
    用于保存 LoRA 权重。'
- en: '#### `generate_mask`'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate_mask`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L857)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L857)'
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`PIL.Image.Image`) — `Image` or tensor representing an image batch
    to be used for computing the mask.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`PIL.Image.Image`) — 代表要用于计算蒙版的图像批次的`Image`或张量。'
- en: '`target_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide semantic mask generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_prompt` (`str` 或 `List[str]`，*可选*) — 用于指导语义蒙版生成的提示或提示。如果未定义，则需要传递`prompt_embeds`。'
- en: '`target_negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or
    prompts to guide what to not include in image generation. If not defined, you
    need to pass `negative_prompt_embeds` instead. Ignored when not using guidance
    (`guidance_scale < 1`).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_negative_prompt` (`str` 或 `List[str]`, *optional*) — 指导图像生成中不包括的提示或提示。如果未定义，则需要传递`negative_prompt_embeds`。在不使用引导时被忽略（`guidance_scale
    < 1`）。'
- en: '`target_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text
    embeddings. Can be used to easily tweak text inputs (prompt weighting). If not
    provided, text embeddings are generated from the `prompt` input argument.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`prompt`输入参数生成文本嵌入。'
- en: '`target_negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负面文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`negative_prompt`输入参数生成`negative_prompt_embeds`。'
- en: '`source_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide semantic mask generation using DiffEdit. If not defined, you need to
    pass `source_prompt_embeds` or `source_image` instead.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source_prompt` (`str` 或 `List[str]`, *optional*) — 使用DiffEdit指导语义蒙版生成的提示或提示。如果未定义，则需要传递`source_prompt_embeds`或`source_image`。'
- en: '`source_negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or
    prompts to guide semantic mask generation away from using DiffEdit. If not defined,
    you need to pass `source_negative_prompt_embeds` or `source_image` instead.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source_negative_prompt` (`str` 或 `List[str]`, *optional*) — 指导语义蒙版生成远离DiffEdit的提示或提示。如果未定义，则需要传递`source_negative_prompt_embeds`或`source_image`。'
- en: '`source_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text
    embeddings to guide the semantic mask generation. Can be used to easily tweak
    text inputs (prompt weighting). If not provided, text embeddings are generated
    from `source_prompt` input argument.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source_prompt_embeds` (`torch.FloatTensor`, *optional*) — 用于指导语义蒙版生成的预生成文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`source_prompt`输入参数生成文本嵌入。'
- en: '`source_negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    text embeddings to negatively guide the semantic mask generation. Can be used
    to easily tweak text inputs (prompt weighting). If not provided, text embeddings
    are generated from `source_negative_prompt` input argument.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source_negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 用于负向指导语义蒙版生成的预生成文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`source_negative_prompt`输入参数生成文本嵌入。'
- en: '`num_maps_per_mask` (`int`, *optional*, defaults to 10) — The number of noise
    maps sampled to generate the semantic mask using DiffEdit.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_maps_per_mask` (`int`, *optional*, 默认为10) — 采样生成语义蒙版所需的噪声图数量，使用DiffEdit。'
- en: '`mask_encode_strength` (`float`, *optional*, defaults to 0.5) — The strength
    of the noise maps sampled to generate the semantic mask using DiffEdit. Must be
    between 0 and 1.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_encode_strength` (`float`, *optional*, 默认为0.5) — 用于生成语义蒙版的噪声图的强度，使用DiffEdit。必须在0和1之间。'
- en: '`mask_thresholding_ratio` (`float`, *optional*, defaults to 3.0) — The maximum
    multiple of the mean absolute difference used to clamp the semantic guidance map
    before mask binarization.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_thresholding_ratio` (`float`, *optional*, 默认为3.0) — 在进行蒙版二值化之前，用于夹紧语义引导图的平均绝对差的最大倍数。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, 默认为50) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, 默认为7.5) — 更高的引导比例值鼓励模型生成与文本`prompt`紧密相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *optional*) — 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, 默认为`"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间的一个。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the [AttnProcessor](/docs/diffusers/v0.26.3/en/api/attnprocessor#diffusers.models.attention_processor.AttnProcessor)
    as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给[AttnProcessor](/docs/diffusers/v0.26.3/en/api/attnprocessor#diffusers.models.attention_processor.AttnProcessor)中定义的`self.processor`的kwargs字典。'
- en: Returns
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[PIL.Image.Image]` or `np.array`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[PIL.Image.Image]` 或 `np.array`'
- en: When returning a `List[PIL.Image.Image]`, the list consists of a batch of single-channel
    binary images with dimensions `(height // self.vae_scale_factor, width // self.vae_scale_factor)`.
    If it’s `np.array`, the shape is `(batch_size, height // self.vae_scale_factor,
    width // self.vae_scale_factor)`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当返回`List[PIL.Image.Image]`时，列表由一批单通道二值图像组成，尺寸为`(height // self.vae_scale_factor,
    width // self.vae_scale_factor)`。如果是`np.array`，形状为`(batch_size, height // self.vae_scale_factor,
    width // self.vae_scale_factor)`。
- en: Generate a latent mask given a mask prompt, a target prompt, and an image.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 给定蒙版提示、目标提示和图像生成潜在蒙版。
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `invert`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `invert`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L1076)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L1076)'
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *optional*) — 指导图像生成的提示或提示。如果未定义，则需要传递`prompt_embeds`。'
- en: '`image` (`PIL.Image.Image`) — `Image` or tensor representing an image batch
    to produce the inverted latents guided by `prompt`.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`PIL.Image.Image`) — 代表要生成的反转潜变量的图像批次的`Image`或张量。'
- en: '`inpaint_strength` (`float`, *optional*, defaults to 0.8) — Indicates extent
    of the noising process to run latent inversion. Must be between 0 and 1\. When
    `inpaint_strength` is 1, the inversion process is run for the full number of iterations
    specified in `num_inference_steps`. `image` is used as a reference for the inversion
    process, and adding more noise increases `inpaint_strength`. If `inpaint_strength`
    is 0, no inpainting occurs.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inpaint_strength` (`float`, *optional*, defaults to 0.8) — 表示运行潜变量反转的噪声过程的程度。必须在0和1之间。当`inpaint_strength`为1时，反转过程将运行指定的`num_inference_steps`的全部迭代。`image`用作反转过程的参考，并增加更多噪声会增加`inpaint_strength`。如果`inpaint_strength`为0，则不进行修补。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, defaults to 50) — 降噪步数。更多的降噪步骤通常会导致更高质量的图像，但会降低推断速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — 更高的指导比例值鼓励模型生成与文本`prompt`紧密相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用指导比例。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) — 指导不包含在图像生成中的提示或提示。如果未定义，则需要传递`negative_prompt_embeds`。在不使用指导时被忽略（`guidance_scale
    < 1`）。'
- en: '`generator` (`torch.Generator`, *optional*) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`, *optional*) — 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，文本嵌入将从`prompt`输入参数生成。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，`negative_prompt_embeds`将从`negative_prompt`输入参数生成。'
- en: '`decode_latents` (`bool`, *optional*, defaults to `False`) — Whether or not
    to decode the inverted latents into a generated image. Setting this argument to
    `True` decodes all inverted latents for each timestep into a list of generated
    images.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decode_latents` (`bool`, *optional*, defaults to `False`) — 是否解码反转的潜变量为生成的图像。将此参数设置为`True`会将每个时间步的所有反转的潜变量解码为生成的图像列表。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, defaults to `"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a `~pipelines.stable_diffusion.DiffEditInversionPipelineOutput` instead
    of a plain tuple.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, defaults to `True`) — 是否返回`~pipelines.stable_diffusion.DiffEditInversionPipelineOutput`而不是普通元组。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *optional*) — 推断过程中每`callback_steps`步调用的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *optional*, defaults to 1) — 调用`callback`函数的频率。如果未指定，回调将在每一步调用。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the [AttnProcessor](/docs/diffusers/v0.26.3/en/api/attnprocessor#diffusers.models.attention_processor.AttnProcessor)
    as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给[AttnProcessor](/docs/diffusers/v0.26.3/en/api/attnprocessor#diffusers.models.attention_processor.AttnProcessor)中定义的`self.processor`的kwargs字典。'
- en: '`lambda_auto_corr` (`float`, *optional*, defaults to 20.0) — Lambda parameter
    to control auto correction.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lambda_auto_corr` (`float`, *optional*, defaults to 20.0) — 控制自动校正的Lambda参数。'
- en: '`lambda_kl` (`float`, *optional*, defaults to 20.0) — Lambda parameter to control
    Kullback-Leibler divergence output.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lambda_kl` (`float`, *optional*, defaults to 20.0) — 控制Kullback-Leibler散度输出的Lambda参数。'
- en: '`num_reg_steps` (`int`, *optional*, defaults to 0) — Number of regularization
    loss steps.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_reg_steps` (`int`, *optional*, defaults to 0) — 正则化损失步数。'
- en: '`num_auto_corr_rolls` (`int`, *optional*, defaults to 5) — Number of auto correction
    roll steps.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_auto_corr_rolls` (`int`, *optional*, defaults to 5) — 自动校正滚动步数。'
- en: Generate inverted latents given a prompt and image.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 给定提示和图像生成反转潜变量。
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `__call__`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L1314)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L1314)'
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts to guide
    image generation. If not defined, you need to pass `prompt_embeds`.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *optional*) — 用于指导图像生成的提示或提示。如果未定义，则需要传递`prompt_embeds`。'
- en: '`mask_image` (`PIL.Image.Image`) — `Image` or tensor representing an image
    batch to mask the generated image. White pixels in the mask are repainted, while
    black pixels are preserved. If `mask_image` is a PIL image, it is converted to
    a single channel (luminance) before use. If it’s a tensor, it should contain one
    color channel (L) instead of 3, so the expected shape would be `(B, 1, H, W)`.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_image` (`PIL.Image.Image`) — 代表要遮罩生成图像的图像批次的`Image`或张量。遮罩中的白色像素被重新绘制，而黑色像素被保留。如果`mask_image`是PIL图像，则在使用之前将其转换为单通道（亮度）。如果是张量，则应该包含一个颜色通道（L）而不是3个，因此预期形状将是`(B,
    1, H, W)`。'
- en: '`image_latents` (`PIL.Image.Image` or `torch.FloatTensor`) — Partially noised
    image latents from the inversion process to be used as inputs for image generation.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_latents` (`PIL.Image.Image` or `torch.FloatTensor`) — 部分噪声图像潜变量，用于图像生成的反演过程的输入。'
- en: '`inpaint_strength` (`float`, *optional*, defaults to 0.8) — Indicates extent
    to inpaint the masked area. Must be between 0 and 1\. When `inpaint_strength`
    is 1, the denoising process is run on the masked area for the full number of iterations
    specified in `num_inference_steps`. `image_latents` is used as a reference for
    the masked area, and adding more noise to a region increases `inpaint_strength`.
    If `inpaint_strength` is 0, no inpainting occurs.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inpaint_strength` (`float`, *optional*, defaults to 0.8) — 表示修复遮罩区域的程度。必须在0和1之间。当`inpaint_strength`为1时，对遮罩区域进行完整数量的迭代指定的`num_inference_steps`运行去噪过程。`image_latents`用作遮罩区域的参考，向区域添加更多噪声会增加`inpaint_strength`。如果`inpaint_strength`为0，则不进行修复。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, defaults to 50) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, defaults to 7.5) — 更高的引导比例值鼓励模型生成与文本`prompt`紧密相关的图像，但会降低图像质量。当`guidance_scale
    > 1`时启用引导比例。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) — 用于指导图像生成中不包括什么的提示或提示。如果未定义，则需要传递`negative_prompt_embeds`。在不使用引导时被忽略（`guidance_scale
    < 1`）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — 每个提示生成的图像数量。'
- en: '`eta` (`float`, *optional*, defaults to 0.0) — Corresponds to parameter eta
    (η) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *optional*, defaults to 0.0) — 对应于[DDIM](https://arxiv.org/abs/2010.02502)论文中的参数
    eta (η)。仅适用于[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，在其他调度程序中被忽略。'
- en: '`generator` (`torch.Generator`, *optional*) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`, *optional*) — 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) — 从高斯分布中采样的预生成噪声潜变量，用作图像生成的输入。可以用来使用不同提示微调相同的生成。如果未提供，则通过使用提供的随机`generator`进行采样生成潜变量张量。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs (prompt weighting). If not provided, text
    embeddings are generated from the `prompt` input argument.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`prompt`输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs (prompt weighting).
    If not provided, `negative_prompt_embeds` are generated from the `negative_prompt`
    input argument.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的负文本嵌入。可用于轻松调整文本输入（提示加权）。如果未提供，则从`negative_prompt`输入参数生成`negative_prompt_embeds`。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, defaults to `"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间的一个。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, defaults to `True`) — 是否返回一个[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)而不是一个普通的元组。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *optional*) — 一个函数，在推断过程中每 `callback_steps` 步调用一次。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *optional*, defaults to 1) — 指定 `callback` 函数被调用的频率。如果未指定，则在每一步都会调用回调函数。'
- en: '`cross_attention_kwargs` (`dict`, *optional*) — A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined in [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) — 如果指定，将传递给 [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)
    中定义的 `AttentionProcessor` 的 kwargs 字典。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *optional*) — 在计算提示嵌入时要跳过的 CLIP 层的数量。值为 1 表示将使用预最终层的输出来计算提示嵌入。'
- en: Returns
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    或 `tuple`'
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains “not-safe-for-work” (nsfw)
    content.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `return_dict` 为 `True`，则返回 [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)，否则返回一个
    `tuple`，其中第一个元素是生成的图像列表，第二个元素是一个指示相应生成图像是否包含“不安全内容”（nsfw）的 `bool` 列表。
- en: The call function to the pipeline for generation.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成的管道的调用函数。
- en: '[PRE6]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#### `disable_vae_slicing`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L383)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L383)'
- en: '[PRE7]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用切片式 VAE 解码。如果之前启用了 `enable_vae_slicing`，则此方法将回到一步计算解码。
- en: '#### `disable_vae_tiling`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L400)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L400)'
- en: '[PRE8]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用平铺式 VAE 解码。如果之前启用了 `enable_vae_tiling`，则此方法将回到一步计算解码。
- en: '#### `enable_vae_slicing`'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_slicing`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L375)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L375)'
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 启用切片式 VAE 解码。启用此选项时，VAE 将把输入张量切片以便在几个步骤中计算解码。这对于节省一些内存并允许更大的批量大小非常有用。
- en: '#### `enable_vae_tiling`'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_vae_tiling`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L391)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L391)'
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 启用平铺式 VAE 解码。启用此选项时，VAE 将把输入张量分割成多个瓦片，以便在几个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。
- en: '#### `encode_prompt`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L441)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py#L441)'
- en: '[PRE11]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`, *optional*) — prompt to be encoded device —
    (`torch.device`): torch device'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *optional*) — 要编码的提示设备 — (`torch.device`):
    torch 设备'
- en: '`num_images_per_prompt` (`int`) — number of images that should be generated
    per prompt'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) — 每个提示应生成的图像数量'
- en: '`do_classifier_free_guidance` (`bool`) — whether to use classifier free guidance
    or not'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) — 是否使用分类器自由指导'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` or `List[str]`, *optional*) — 不用来指导图像生成的提示或提示。如果未定义，则必须传递
    `negative_prompt_embeds`。当不使用指导时（即，如果 `guidance_scale` 小于 `1`，则忽略）。'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) — 预生成的文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，则将从
    `prompt` 输入参数生成文本嵌入。'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) — Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *可选*) — 预生成的负文本嵌入。可用于轻松调整文本输入，例如提示加权。如果未提供，将从`negative_prompt`输入参数生成`negative_prompt_embeds`。'
- en: '`lora_scale` (`float`, *optional*) — A LoRA scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *可选*) — 如果加载了LoRA层，则将应用于文本编码器的所有LoRA层的LoRA比例。'
- en: '`clip_skip` (`int`, *optional*) — Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *可选*) — 在计算提示嵌入时要跳过的CLIP层数。值为1意味着将使用前一层的输出来计算提示嵌入。'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示编码为文本编码器隐藏状态。
- en: StableDiffusionPipelineOutput
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionPipelineOutput
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
- en: '[PRE12]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) — List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`List[PIL.Image.Image]` 或 `np.ndarray`) — 长度为`batch_size`的去噪PIL图像列表或形状为`(batch_size,
    height, width, num_channels)`的NumPy数组。'
- en: '`nsfw_content_detected` (`List[bool]`) — List indicating whether the corresponding
    generated image contains “not-safe-for-work” (nsfw) content or `None` if safety
    checking could not be performed.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nsfw_content_detected` (`List[bool]`) — 列表，指示相应生成的图像是否包含“不安全内容”（nsfw）或如果无法执行安全检查，则为`None`。'
- en: Output class for Stable Diffusion pipelines.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散管道的输出类。
