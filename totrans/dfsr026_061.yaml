- en: Wuerstchen
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/wuerstchen](https://huggingface.co/docs/diffusers/training/wuerstchen)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The [Wuerstchen](https://hf.co/papers/2306.00637) model drastically reduces
    computational costs by compressing the latent space by 42x, without compromising
    image quality and accelerating inference. During training, Wuerstchen uses two
    models (VQGAN + autoencoder) to compress the latents, and then a third model (text-conditioned
    latent diffusion model) is conditioned on this highly compressed space to generate
    an image.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: To fit the prior model into GPU memory and to speedup training, try enabling
    `gradient_accumulation_steps`, `gradient_checkpointing`, and `mixed_precision`
    respectively.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: This guide explores the [train_text_to_image_prior.py](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_prior.py)
    script to help you become more familiar with it, and how you can adapt it for
    your own use-case.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'Before running the script, make sure you install the library from source:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then navigate to the example folder containing the training script and install
    the required dependencies for the script youâ€™re using:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ğŸ¤— Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. Itâ€™ll automatically configure your training setup based on your
    hardware and environment. Take a look at the ğŸ¤— Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialize an ğŸ¤— Accelerate environment:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To setup a default ğŸ¤— Accelerate environment without choosing any configurations:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or if your environment doesnâ€™t support an interactive shell, like a notebook,
    you can use:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: The following sections highlight parts of the training scripts that are important
    for understanding how to modify it, but it doesnâ€™t cover every aspect of the [script](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_prior.py)
    in detail. If youâ€™re interested in learning more, feel free to read through the
    scripts and let us know if you have any questions or concerns.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Script parameters
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The training scripts provides many parameters to help you customize your training
    run. All of the parameters and their descriptions are found in the [`parse_args()`](https://github.com/huggingface/diffusers/blob/6e68c71503682c8693cb5b06a4da4911dfd655ee/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L192)
    function. It provides default values for each parameter, such as the training
    batch size and learning rate, but you can also set your own values in the training
    command if youâ€™d like.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to speedup training with mixed precision using the fp16 format,
    add the `--mixed_precision` parameter to the training command:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Most of the parameters are identical to the parameters in the [Text-to-image](text2image#script-parameters)
    training guide, so letâ€™s dive right into the Wuerstchen training script!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Training script
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The training script is also similar to the [Text-to-image](text2image#training-script)
    training guide, but itâ€™s been modified to support Wuerstchen. This guide focuses
    on the code that is unique to the Wuerstchen training script.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The [`main()`](https://github.com/huggingface/diffusers/blob/6e68c71503682c8693cb5b06a4da4911dfd655ee/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L441)
    function starts by initializing the image encoder - an [EfficientNet](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/modeling_efficient_net_encoder.py)
    - in addition to the usual scheduler and tokenizer.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Youâ€™ll also load the `WuerstchenPrior` model for optimization.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, youâ€™ll apply some [transforms](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)
    to the images and [tokenize](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L637)
    the captions:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæ‚¨å°†å¯¹å›¾åƒåº”ç”¨ä¸€äº›[è½¬æ¢](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)ï¼Œå¹¶[æ ‡è®°åŒ–](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L637)æ ‡é¢˜ï¼š
- en: '[PRE8]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Finally, the [training loop](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)
    handles compressing the images to latent space with the `EfficientNetEncoder`,
    adding noise to the latents, and predicting the noise residual with the `WuerstchenPrior`
    model.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œ[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)å¤„ç†å°†å›¾åƒå‹ç¼©åˆ°æ½œåœ¨ç©ºé—´ä¸­ï¼Œä½¿ç”¨`EfficientNetEncoder`å‘æ½œåœ¨ç©ºé—´æ·»åŠ å™ªå£°ï¼Œå¹¶ä½¿ç”¨`WuerstchenPrior`æ¨¡å‹é¢„æµ‹å™ªå£°æ®‹å·®ã€‚
- en: '[PRE9]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If you want to learn more about how the training loop works, check out the [Understanding
    pipelines, models and schedulers](../using-diffusers/write_own_pipeline) tutorial
    which breaks down the basic pattern of the denoising process.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³äº†è§£è®­ç»ƒå¾ªç¯çš„å·¥ä½œåŸç†ï¼Œè¯·æŸ¥çœ‹[äº†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦å™¨](../using-diffusers/write_own_pipeline)æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹è¯¦ç»†ä»‹ç»äº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚
- en: Launch the script
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯åŠ¨è„šæœ¬
- en: Once youâ€™ve made all your changes or youâ€™re okay with the default configuration,
    youâ€™re ready to launch the training script! ğŸš€
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨å®Œæˆæ‰€æœ‰æ›´æ”¹æˆ–å¯¹é»˜è®¤é…ç½®æ»¡æ„ï¼Œæ‚¨å°±å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€
- en: Set the `DATASET_NAME` environment variable to the dataset name from the Hub.
    This guide uses the [PokÃ©mon BLIP captions](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)
    dataset, but you can create and train on your own datasets as well (see the [Create
    a dataset for training](create_dataset) guide).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å°†`DATASET_NAME`ç¯å¢ƒå˜é‡è®¾ç½®ä¸ºHubä¸­çš„æ•°æ®é›†åç§°ã€‚æœ¬æŒ‡å—ä½¿ç”¨[PokÃ©mon BLIP captions](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)æ•°æ®é›†ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥åˆ›å»ºå’Œè®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ï¼ˆè¯·å‚é˜…[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼‰ã€‚
- en: To monitor training progress with Weights & Biases, add the `--report_to=wandb`
    parameter to the training command. Youâ€™ll also need to add the `--validation_prompt`
    to the training command to keep track of results. This can be really useful for
    debugging the model and viewing intermediate results.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨Weights & Biasesç›‘æ§è®­ç»ƒè¿›åº¦ï¼Œè¯·åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--report_to=wandb`å‚æ•°ã€‚æ‚¨è¿˜éœ€è¦åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--validation_prompt`ä»¥è·Ÿè¸ªç»“æœã€‚è¿™å¯¹äºè°ƒè¯•æ¨¡å‹å’ŒæŸ¥çœ‹ä¸­é—´ç»“æœéå¸¸æœ‰ç”¨ã€‚
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once training is complete, you can use your newly trained model for inference!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ–°è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Next steps
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥
- en: 'Congratulations on training a Wuerstchen model! To learn more about how to
    use your new model, the following may be helpful:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥è´ºæ‚¨è®­ç»ƒäº†ä¸€ä¸ªWuerstchenæ¨¡å‹ï¼è¦äº†è§£å¦‚ä½•ä½¿ç”¨æ‚¨çš„æ–°æ¨¡å‹ï¼Œä»¥ä¸‹å†…å®¹å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼š
- en: Take a look at the [Wuerstchen](../api/pipelines/wuerstchen#text-to-image-generation)
    API documentation to learn more about how to use the pipeline for text-to-image
    generation and its limitations.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[Wuerstchen](../api/pipelines/wuerstchen#text-to-image-generation) APIæ–‡æ¡£ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ç®¡é“åŠå…¶é™åˆ¶ã€‚
