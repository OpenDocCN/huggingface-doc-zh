- en: DiffEdit
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DiffEdit
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/diffedit](https://huggingface.co/docs/diffusers/using-diffusers/diffedit)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/using-diffusers/diffedit](https://huggingface.co/docs/diffusers/using-diffusers/diffedit)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Image editing typically requires providing a mask of the area to be edited.
    DiffEdit automatically generates the mask for you based on a text query, making
    it easier overall to create a mask without image editing software. The DiffEdit
    algorithm works in three steps:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒç¼–è¾‘é€šå¸¸éœ€è¦æä¾›è¦ç¼–è¾‘çš„åŒºåŸŸçš„è’™ç‰ˆã€‚DiffEditæ ¹æ®æ–‡æœ¬æŸ¥è¯¢è‡ªåŠ¨ç”Ÿæˆè’™ç‰ˆï¼Œä»è€Œæ›´å®¹æ˜“åœ°åˆ›å»ºè’™ç‰ˆè€Œæ— éœ€å›¾åƒç¼–è¾‘è½¯ä»¶ã€‚DiffEditç®—æ³•åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼š
- en: the diffusion model denoises an image conditioned on some query text and reference
    text which produces different noise estimates for different areas of the image;
    the difference is used to infer a mask to identify which area of the image needs
    to be changed to match the query text
  id: totrans-4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰©æ•£æ¨¡å‹å¯¹å—æŸäº›æŸ¥è¯¢æ–‡æœ¬å’Œå‚è€ƒæ–‡æœ¬æ¡ä»¶çš„å›¾åƒè¿›è¡Œå»å™ªï¼Œä¸ºå›¾åƒçš„ä¸åŒåŒºåŸŸäº§ç”Ÿä¸åŒçš„å™ªå£°ä¼°è®¡ï¼›è¿™ç§å·®å¼‚ç”¨äºæ¨æ–­ä¸€ä¸ªè’™ç‰ˆï¼Œä»¥è¯†åˆ«éœ€è¦æ›´æ”¹ä»¥åŒ¹é…æŸ¥è¯¢æ–‡æœ¬çš„å›¾åƒåŒºåŸŸ
- en: the input image is encoded into latent space with DDIM
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¾“å…¥å›¾åƒä½¿ç”¨DDIMç¼–ç åˆ°æ½œç©ºé—´
- en: the latents are decoded with the diffusion model conditioned on the text query,
    using the mask as a guide such that pixels outside the mask remain the same as
    in the input image
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ½œå˜é‡é€šè¿‡æ‰©æ•£æ¨¡å‹è§£ç ï¼Œè¯¥æ¨¡å‹ä»¥æ–‡æœ¬æŸ¥è¯¢ä¸ºæ¡ä»¶ï¼Œä½¿ç”¨è’™ç‰ˆä½œä¸ºæŒ‡å¯¼ï¼Œä½¿è’™ç‰ˆå¤–çš„åƒç´ ä¿æŒä¸è¾“å…¥å›¾åƒç›¸åŒ
- en: This guide will show you how to use DiffEdit to edit images without manually
    creating a mask.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨DiffEditç¼–è¾‘å›¾åƒï¼Œè€Œæ— éœ€æ‰‹åŠ¨åˆ›å»ºè’™ç‰ˆã€‚
- en: 'Before you begin, make sure you have the following libraries installed:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹åº“ï¼š
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The [StableDiffusionDiffEditPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline)
    requires an image mask and a set of partially inverted latents. The image mask
    is generated from the [generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)
    function, and includes two parameters, `source_prompt` and `target_prompt`. These
    parameters determine what to edit in the image. For example, if you want to change
    a bowl of *fruits* to a bowl of *pears*, then:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[StableDiffusionDiffEditPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline)éœ€è¦ä¸€ä¸ªå›¾åƒè’™ç‰ˆå’Œä¸€ç»„éƒ¨åˆ†åè½¬çš„æ½œå˜é‡ã€‚å›¾åƒè’™ç‰ˆæ˜¯ä»[generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)å‡½æ•°ç”Ÿæˆçš„ï¼Œå¹¶åŒ…æ‹¬ä¸¤ä¸ªå‚æ•°ï¼Œ`source_prompt`å’Œ`target_prompt`ã€‚è¿™äº›å‚æ•°ç¡®å®šè¦åœ¨å›¾åƒä¸­è¿›è¡Œç¼–è¾‘çš„å†…å®¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³å°†ä¸€ä¸ªè£…æ»¡*æ°´æœ*çš„ç¢—æ›´æ”¹ä¸ºä¸€ä¸ªè£…æ»¡*æ¢¨*çš„ç¢—ï¼Œåˆ™ï¼š'
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The partially inverted latents are generated from the [invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)
    function, and it is generally a good idea to include a `prompt` or *caption* describing
    the image to help guide the inverse latent sampling process. The caption can often
    be your `source_prompt`, but feel free to experiment with other text descriptions!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: éƒ¨åˆ†åè½¬çš„æ½œå˜é‡æ˜¯é€šè¿‡[invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)å‡½æ•°ç”Ÿæˆçš„ï¼Œé€šå¸¸æœ€å¥½åŒ…å«ä¸€ä¸ªæè¿°å›¾åƒçš„`prompt`æˆ–*æ ‡é¢˜*ï¼Œä»¥å¸®åŠ©æŒ‡å¯¼åå‘æ½œå˜é‡é‡‡æ ·è¿‡ç¨‹ã€‚æ ‡é¢˜é€šå¸¸å¯ä»¥æ˜¯æ‚¨çš„`source_prompt`ï¼Œä½†ä¹Ÿå¯ä»¥å°è¯•å…¶ä»–æ–‡æœ¬æè¿°ï¼
- en: 'Letâ€™s load the pipeline, scheduler, inverse scheduler, and enable some optimizations
    to reduce memory usage:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½ç®¡é“ã€è°ƒåº¦å™¨ã€é€†è°ƒåº¦å™¨ï¼Œå¹¶å¯ç”¨ä¸€äº›ä¼˜åŒ–ä»¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼š
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Load the image to edit:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½è¦ç¼–è¾‘çš„å›¾åƒï¼š
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Use the [generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)
    function to generate the image mask. Youâ€™ll need to pass it the `source_prompt`
    and `target_prompt` to specify what to edit in the image:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)å‡½æ•°ç”Ÿæˆå›¾åƒè’™ç‰ˆã€‚æ‚¨éœ€è¦ä¼ é€’`source_prompt`å’Œ`target_prompt`ä»¥æŒ‡å®šè¦åœ¨å›¾åƒä¸­è¿›è¡Œç¼–è¾‘çš„å†…å®¹ï¼š
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, create the inverted latents and pass it a caption describing the image:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œåˆ›å»ºåè½¬çš„æ½œå˜é‡å¹¶ä¼ é€’ä¸€ä¸ªæè¿°å›¾åƒçš„æ ‡é¢˜ï¼š
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, pass the image mask and inverted latents to the pipeline. The `target_prompt`
    becomes the `prompt` now, and the `source_prompt` is used as the `negative_prompt`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå°†å›¾åƒè’™ç‰ˆå’Œåè½¬çš„æ½œå˜é‡ä¼ é€’ç»™ç®¡é“ã€‚`target_prompt`ç°åœ¨æˆä¸º`prompt`ï¼Œè€Œ`source_prompt`åˆ™ç”¨ä½œ`negative_prompt`ï¼š
- en: '[PRE6]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/66e8c6b1baf21e3ade0ec71d71f6eff6.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/66e8c6b1baf21e3ade0ec71d71f6eff6.png)'
- en: original image
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹å›¾åƒ
- en: '![](../Images/9cc02168a4ef69d9e1454293018a3a04.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9cc02168a4ef69d9e1454293018a3a04.png)'
- en: edited image
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–è¾‘åçš„å›¾åƒ
- en: Generate source and target embeddings
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”Ÿæˆæºå’Œç›®æ ‡åµŒå…¥
- en: The source and target embeddings can be automatically generated with the [Flan-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)
    model instead of creating them manually.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æºå’Œç›®æ ‡åµŒå…¥å¯ä»¥ä½¿ç”¨[Flan-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆï¼Œè€Œä¸æ˜¯æ‰‹åŠ¨åˆ›å»ºã€‚
- en: 'Load the Flan-T5 model and tokenizer from the ğŸ¤— Transformers library:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ğŸ¤— Transformersåº“åŠ è½½Flan-T5æ¨¡å‹å’Œåˆ†è¯å™¨ï¼š
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Provide some initial text to prompt the model to generate the source and target
    prompts.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æä¾›ä¸€äº›åˆå§‹æ–‡æœ¬ä»¥æç¤ºæ¨¡å‹ç”Ÿæˆæºå’Œç›®æ ‡æç¤ºã€‚
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, create a utility function to generate the prompts:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªå®ç”¨å‡½æ•°æ¥ç”Ÿæˆæç¤ºï¼š
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Check out the [generation strategy](https://huggingface.co/docs/transformers/main/en/generation_strategies)
    guide if youâ€™re interested in learning more about strategies for generating different
    quality text.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å¯¹ç”Ÿæˆä¸åŒè´¨é‡æ–‡æœ¬çš„ç­–ç•¥æ„Ÿå…´è¶£ï¼Œè¯·æŸ¥çœ‹[ç”Ÿæˆç­–ç•¥](https://huggingface.co/docs/transformers/main/en/generation_strategies)æŒ‡å—ã€‚
- en: 'Load the text encoder model used by the [StableDiffusionDiffEditPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline)
    to encode the text. Youâ€™ll use the text encoder to compute the text embeddings:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½ç”±[StableDiffusionDiffEditPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline)ä½¿ç”¨çš„æ–‡æœ¬ç¼–ç å™¨æ¨¡å‹ä»¥å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç ã€‚æ‚¨å°†ä½¿ç”¨æ–‡æœ¬ç¼–ç å™¨æ¥è®¡ç®—æ–‡æœ¬åµŒå…¥ï¼š
- en: '[PRE10]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, pass the embeddings to the [generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)
    and [invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)
    functions, and pipeline to generate the image:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå°†åµŒå…¥ä¼ é€’ç»™[generate_mask()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)å’Œ[invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)å‡½æ•°ï¼Œä»¥åŠç®¡é“æ¥ç”Ÿæˆå›¾åƒï¼š
- en: '[PRE11]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Generate a caption for inversion
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”Ÿæˆåè½¬çš„æ ‡é¢˜
- en: While you can use the `source_prompt` as a caption to help generate the partially
    inverted latents, you can also use the [BLIP](https://huggingface.co/docs/transformers/model_doc/blip)
    model to automatically generate a caption.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‚¨å¯ä»¥ä½¿ç”¨`source_prompt`ä½œä¸ºæ ‡é¢˜æ¥å¸®åŠ©ç”Ÿæˆéƒ¨åˆ†åè½¬çš„æ½œåœ¨å†…å®¹æ—¶ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨[BLIP](https://huggingface.co/docs/transformers/model_doc/blip)æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜ã€‚
- en: 'Load the BLIP model and processor from the ğŸ¤— Transformers library:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ğŸ¤— Transformersåº“ä¸­åŠ è½½BLIPæ¨¡å‹å’Œå¤„ç†å™¨ï¼š
- en: '[PRE12]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Create a utility function to generate a caption from the input image:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªå®ç”¨å‡½æ•°æ¥ä»è¾“å…¥å›¾åƒç”Ÿæˆæ ‡é¢˜ï¼š
- en: '[PRE13]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Load an input image and generate a caption for it using the `generate_caption`
    function:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½è¾“å…¥å›¾åƒå¹¶ä½¿ç”¨`generate_caption`å‡½æ•°ä¸ºå…¶ç”Ÿæˆæ ‡é¢˜ï¼š
- en: '[PRE14]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/66e8c6b1baf21e3ade0ec71d71f6eff6.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/66e8c6b1baf21e3ade0ec71d71f6eff6.png)'
- en: 'generated caption: "a photograph of a bowl of fruit on a table"'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„æ ‡é¢˜ï¼š"ä¸€å¼ æ”¾åœ¨æ¡Œå­ä¸Šçš„æ°´æœç¢—çš„ç…§ç‰‡"
- en: Now you can drop the caption into the [invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)
    function to generate the partially inverted latents!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å¯ä»¥å°†æ ‡é¢˜æ”¾å…¥[invert()](/docs/diffusers/v0.26.3/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)å‡½æ•°ä¸­ï¼Œä»¥ç”Ÿæˆéƒ¨åˆ†åè½¬çš„æ½œåœ¨å†…å®¹ï¼
