# 多任务提示调整

> 原文：[https://huggingface.co/docs/peft/package_reference/multitask_prompt_tuning](https://huggingface.co/docs/peft/package_reference/multitask_prompt_tuning)

[多任务提示调整](https://huggingface.co/papers/2303.02861) 将每个任务的软提示分解为单个可学习的可转移提示，而不是为每个任务单独设置提示。单个学习的提示可以通过乘法低秩更新适应每个任务。

该论文的摘要是：

*提示调整是一种基于学习提示向量对基础预训练模型进行调整的方法，已经成为一种有效地将大型语言模型有效地适应多个下游任务的有前途的方法。然而，现有方法通常是从头开始学习软提示向量，并且尚不清楚如何在多任务学习环境中利用提示向量中的丰富跨任务知识。我们提出了多任务提示调整（MPT），首先通过从多个任务特定源提示中提炼知识来学习单个可转移提示。然后，我们学习对这个共享提示进行乘法低秩更新，以有效地将其适应到每个下游目标任务。对23个NLP数据集的大量实验表明，我们提出的方法在某些情况下优于最先进的方法，包括在某些情况下优于完全微调基线，尽管只调整了0.035%的任务特定参数*。

## 多任务提示调整配置

### `class peft.MultitaskPromptTuningConfig`

[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/multitask_prompt_tuning/config.py#L36)

```py
( peft_type: Union = None auto_mapping: Optional = None base_model_name_or_path: Optional = None revision: Optional = None task_type: Union = None inference_mode: bool = False num_virtual_tokens: int = None token_dim: int = None num_transformer_submodules: Optional = None num_attention_heads: Optional = None num_layers: Optional = None prompt_tuning_init: Union = <MultitaskPromptTuningInit.RANDOM: 'RANDOM'> prompt_tuning_init_text: Optional = None tokenizer_name_or_path: Optional = None tokenizer_kwargs: Optional = None prompt_tuning_init_state_dict_path: Optional = None prompt_tuning_init_task: Optional = 0 num_ranks: Optional = 1 num_tasks: Optional = 1 )
```

## 多任务提示嵌入

### `class peft.tuners.MultitaskPromptEmbedding`

[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/multitask_prompt_tuning/model.py#L27)

```py
( config: MultitaskPromptTuningConfig word_embeddings )
```
