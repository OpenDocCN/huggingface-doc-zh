- en: LayoutLM
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LayoutLM
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlm](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlm)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlm](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlm)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: 'The LayoutLM model was proposed in the paper [LayoutLM: Pre-training of Text
    and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318)
    by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, and Ming Zhou. Itâ€™s
    a simple but effective pretraining method of text and layout for document image
    understanding and information extraction tasks, such as form understanding and
    receipt understanding. It obtains state-of-the-art results on several downstream
    tasks:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'LayoutLMæ¨¡å‹æ˜¯ç”±Yiheng Xuï¼ŒMinghao Liï¼ŒLei Cuiï¼ŒShaohan Huangï¼ŒFuru Weiå’ŒMing Zhouåœ¨è®ºæ–‡[LayoutLM:
    Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318)ä¸­æå‡ºçš„ã€‚è¿™æ˜¯ä¸€ç§ç®€å•ä½†æœ‰æ•ˆçš„æ–‡æœ¬å’Œå¸ƒå±€é¢„è®­ç»ƒæ–¹æ³•ï¼Œç”¨äºæ–‡æ¡£å›¾åƒç†è§£å’Œä¿¡æ¯æå–ä»»åŠ¡ï¼Œå¦‚è¡¨å•ç†è§£å’Œæ”¶æ®ç†è§£ã€‚å®ƒåœ¨å‡ ä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼š'
- en: 'form understanding: the [FUNSD](https://guillaumejaume.github.io/FUNSD/) dataset
    (a collection of 199 annotated forms comprising more than 30,000 words).'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¡¨å•ç†è§£ï¼š[FUNSD](https://guillaumejaume.github.io/FUNSD/)æ•°æ®é›†ï¼ˆåŒ…å«199ä¸ªå¸¦æœ‰è¶…è¿‡30,000ä¸ªå•è¯çš„æ³¨é‡Šè¡¨å•ï¼‰ã€‚
- en: 'receipt understanding: the [SROIE](https://rrc.cvc.uab.es/?ch=13) dataset (a
    collection of 626 receipts for training and 347 receipts for testing).'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ”¶æ®ç†è§£ï¼š[SROIE](https://rrc.cvc.uab.es/?ch=13)æ•°æ®é›†ï¼ˆåŒ…å«626å¼ æ”¶æ®ç”¨äºè®­ç»ƒå’Œ347å¼ æ”¶æ®ç”¨äºæµ‹è¯•ï¼‰ã€‚
- en: 'document image classification: the [RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)
    dataset (a collection of 400,000 images belonging to one of 16 classes).'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–‡æ¡£å›¾åƒåˆ†ç±»ï¼š[RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)æ•°æ®é›†ï¼ˆåŒ…å«400,000å¼ å›¾åƒï¼Œå±äº16ä¸ªç±»åˆ«ä¹‹ä¸€ï¼‰ã€‚
- en: 'The abstract from the paper is the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š
- en: '*Pre-training techniques have been verified successfully in a variety of NLP
    tasks in recent years. Despite the widespread use of pretraining models for NLP
    applications, they almost exclusively focus on text-level manipulation, while
    neglecting layout and style information that is vital for document image understanding.
    In this paper, we propose the LayoutLM to jointly model interactions between text
    and layout information across scanned document images, which is beneficial for
    a great number of real-world document image understanding tasks such as information
    extraction from scanned documents. Furthermore, we also leverage image features
    to incorporate wordsâ€™ visual information into LayoutLM. To the best of our knowledge,
    this is the first time that text and layout are jointly learned in a single framework
    for document-level pretraining. It achieves new state-of-the-art results in several
    downstream tasks, including form understanding (from 70.72 to 79.27), receipt
    understanding (from 94.02 to 95.24) and document image classification (from 93.07
    to 94.42).*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿‘å¹´æ¥ï¼Œé¢„è®­ç»ƒæŠ€æœ¯åœ¨å„ç§NLPä»»åŠ¡ä¸­å–å¾—äº†æˆåŠŸã€‚å°½ç®¡é¢„è®­ç»ƒæ¨¡å‹åœ¨NLPåº”ç”¨ä¸­è¢«å¹¿æ³›ä½¿ç”¨ï¼Œä½†å®ƒä»¬å‡ ä¹å®Œå…¨ä¸“æ³¨äºæ–‡æœ¬çº§åˆ«çš„æ“ä½œï¼Œè€Œå¿½ç•¥äº†å¯¹äºæ–‡æ¡£å›¾åƒç†è§£è‡³å…³é‡è¦çš„å¸ƒå±€å’Œæ ·å¼ä¿¡æ¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†LayoutLMï¼Œä»¥å…±åŒå»ºæ¨¡æ‰«ææ–‡æ¡£å›¾åƒä¸­æ–‡æœ¬å’Œå¸ƒå±€ä¿¡æ¯ä¹‹é—´çš„äº¤äº’ï¼Œè¿™å¯¹äºè®¸å¤šçœŸå®ä¸–ç•Œçš„æ–‡æ¡£å›¾åƒç†è§£ä»»åŠ¡ï¼ˆå¦‚ä»æ‰«ææ–‡æ¡£ä¸­æå–ä¿¡æ¯ï¼‰æ˜¯æœ‰ç›Šçš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜åˆ©ç”¨å›¾åƒç‰¹å¾å°†å•è¯çš„è§†è§‰ä¿¡æ¯æ•´åˆåˆ°LayoutLMä¸­ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯æ–‡æœ¬å’Œå¸ƒå±€é¦–æ¬¡åœ¨å•ä¸ªæ¡†æ¶ä¸­å…±åŒå­¦ä¹ ä»¥è¿›è¡Œæ–‡æ¡£çº§é¢„è®­ç»ƒã€‚å®ƒåœ¨å‡ ä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­å–å¾—äº†æœ€æ–°çš„æœ€å…ˆè¿›ç»“æœï¼ŒåŒ…æ‹¬è¡¨å•ç†è§£ï¼ˆä»70.72åˆ°79.27ï¼‰ã€æ”¶æ®ç†è§£ï¼ˆä»94.02åˆ°95.24ï¼‰å’Œæ–‡æ¡£å›¾åƒåˆ†ç±»ï¼ˆä»93.07åˆ°94.42ï¼‰ã€‚*'
- en: Usage tips
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æç¤º
- en: 'In addition to *input_ids*, [forward()](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel.forward)
    also expects the input `bbox`, which are the bounding boxes (i.e. 2D-positions)
    of the input tokens. These can be obtained using an external OCR engine such as
    Googleâ€™s [Tesseract](https://github.com/tesseract-ocr/tesseract) (thereâ€™s a [Python
    wrapper](https://pypi.org/project/pytesseract/) available). Each bounding box
    should be in (x0, y0, x1, y1) format, where (x0, y0) corresponds to the position
    of the upper left corner in the bounding box, and (x1, y1) represents the position
    of the lower right corner. Note that one first needs to normalize the bounding
    boxes to be on a 0-1000 scale. To normalize, you can use the following function:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤äº†*input_ids*ä¹‹å¤–ï¼Œ[forward()](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel.forward)è¿˜éœ€è¦è¾“å…¥`bbox`ï¼Œè¿™æ˜¯è¾“å…¥æ ‡è®°çš„è¾¹ç•Œæ¡†ï¼ˆå³2Dä½ç½®ï¼‰ã€‚è¿™äº›å¯ä»¥ä½¿ç”¨å¤–éƒ¨OCRå¼•æ“ï¼ˆå¦‚Googleçš„[Tesseract](https://github.com/tesseract-ocr/tesseract)ï¼‰è·å–ï¼ˆæœ‰ä¸€ä¸ª[PythonåŒ…è£…å™¨](https://pypi.org/project/pytesseract/)å¯ç”¨ï¼‰ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥é‡‡ç”¨ï¼ˆx0ï¼Œy0ï¼Œx1ï¼Œy1ï¼‰æ ¼å¼ï¼Œå…¶ä¸­ï¼ˆx0ï¼Œy0ï¼‰å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œï¼ˆx1ï¼Œy1ï¼‰è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚è¯·æ³¨æ„ï¼Œé¦–å…ˆéœ€è¦å°†è¾¹ç•Œæ¡†å½’ä¸€åŒ–ä¸º0-1000çš„æ¯”ä¾‹ã€‚è¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‡½æ•°ï¼š
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here, `width` and `height` correspond to the width and height of the original
    document in which the token occurs. Those can be obtained using the Python Image
    Library (PIL) library for example, as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ`width`å’Œ`height`å¯¹åº”äºæ ‡è®°å‡ºç°çš„åŸå§‹æ–‡æ¡£çš„å®½åº¦å’Œé«˜åº¦ã€‚å¯ä»¥ä½¿ç”¨Python Image Libraryï¼ˆPILï¼‰åº“æ¥è·å–è¿™äº›ï¼Œä¾‹å¦‚ï¼š
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Resources
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èµ„æº
- en: A list of official Hugging Face and community (indicated by ğŸŒ) resources to
    help you get started with LayoutLM. If youâ€™re interested in submitting a resource
    to be included here, please feel free to open a Pull Request and weâ€™ll review
    it! The resource should ideally demonstrate something new instead of duplicating
    an existing resource.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºåˆ—è¡¨ï¼Œå¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨LayoutLMã€‚å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€Pull Requestï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥ç†æƒ³åœ°å±•ç¤ºä¸€äº›æ–°ä¸œè¥¿ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚
- en: Document Question Answering
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æ¡£é—®ç­”
- en: A blog post on [fine-tuning LayoutLM for document-understanding using Keras
    & Hugging Face Transformers](https://www.philschmid.de/fine-tuning-layoutlm-keras).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ç¯‡å…³äº[ä½¿ç”¨Keraså’ŒHugging Face Transformerså¯¹LayoutLMè¿›è¡Œæ–‡æ¡£ç†è§£å¾®è°ƒçš„åšæ–‡](https://www.philschmid.de/fine-tuning-layoutlm-keras)ã€‚
- en: A blog post on how to [fine-tune LayoutLM for document-understanding using only
    Hugging Face Transformers](https://www.philschmid.de/fine-tuning-layoutlm).
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ç¯‡å…³äºå¦‚ä½•[ä»…ä½¿ç”¨Hugging Face Transformerså¯¹LayoutLMè¿›è¡Œæ–‡æ¡£ç†è§£å¾®è°ƒçš„åšæ–‡](https://www.philschmid.de/fine-tuning-layoutlm)ã€‚
- en: A notebook on how to [fine-tune LayoutLM on the FUNSD dataset with image embeddings](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Add_image_embeddings_to_LayoutLM.ipynb).
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…³äºå¦‚ä½•åœ¨ FUNSD æ•°æ®é›†ä¸Šä½¿ç”¨å›¾åƒåµŒå…¥æ¥[å¾®è°ƒ LayoutLM æ¨¡å‹çš„ç¬”è®°æœ¬](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Add_image_embeddings_to_LayoutLM.ipynb)ã€‚
- en: 'See also: [Document question answering task guide](../tasks/document_question_answering)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦è¯·å‚é˜…ï¼š[æ–‡æ¡£é—®ç­”ä»»åŠ¡æŒ‡å—](../tasks/document_question_answering)
- en: Text Classification
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åˆ†ç±»
- en: A notebook on how to [fine-tune LayoutLM for sequence classification on the
    RVL-CDIP dataset](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb).
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…³äºå¦‚ä½•åœ¨ RVL-CDIP æ•°æ®é›†ä¸Š[å¾®è°ƒ LayoutLM ç”¨äºåºåˆ—åˆ†ç±»çš„ç¬”è®°æœ¬](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb)ã€‚
- en: '[Text classification task guide](../tasks/sequence_classification)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ–‡æœ¬åˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/sequence_classification)'
- en: Token Classification
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡è®°åˆ†ç±»
- en: A notebook on how to [fine-tune LayoutLM for token classification on the FUNSD
    dataset](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb).
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…³äºå¦‚ä½•åœ¨ FUNSD æ•°æ®é›†ä¸Š[å¾®è°ƒ LayoutLM ç”¨äºæ ‡è®°åˆ†ç±»çš„ç¬”è®°æœ¬](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb)ã€‚
- en: '[Token classification task guide](../tasks/token_classification)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ ‡è®°åˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/token_classification)'
- en: '**Other resources**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**å…¶ä»–èµ„æº**'
- en: '[Masked language modeling task guide](../tasks/masked_language_modeling)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ©ç è¯­è¨€å»ºæ¨¡ä»»åŠ¡æŒ‡å—](../tasks/masked_language_modeling)'
- en: ğŸš€ Deploy
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸš€ éƒ¨ç½²
- en: A blog post on how to [Deploy LayoutLM with Hugging Face Inference Endpoints](https://www.philschmid.de/inference-endpoints-layoutlm).
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…³äºå¦‚ä½•[ä½¿ç”¨ Hugging Face æ¨ç†ç«¯ç‚¹éƒ¨ç½² LayoutLM](https://www.philschmid.de/inference-endpoints-layoutlm)çš„åšå®¢æ–‡ç« ã€‚
- en: LayoutLMConfig
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMConfig
- en: '### `class transformers.LayoutLMConfig`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/configuration_layoutlm.py#L36)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/configuration_layoutlm.py#L36)'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vocab_size` (`int`, *optional*, defaults to 30522) â€” Vocabulary size of the
    LayoutLM model. Defines the different tokens that can be represented by the *inputs_ids*
    passed to the forward method of [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, defaults to 30522) â€” LayoutLM æ¨¡å‹çš„è¯æ±‡è¡¨å¤§å°ã€‚å®šä¹‰äº†å¯ä»¥ç”±ä¼ é€’ç»™[LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)çš„`inputs_ids`è¡¨ç¤ºçš„ä¸åŒæ ‡è®°ã€‚'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) â€” Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 768) â€” ç¼–ç å™¨å±‚å’Œæ± åŒ–å™¨å±‚çš„ç»´åº¦ã€‚'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) â€” Number of hidden
    layers in the Transformer encoder.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, defaults to 12) â€” Transformer ç¼–ç å™¨ä¸­çš„éšè—å±‚æ•°é‡ã€‚'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) â€” Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, defaults to 12) â€” Transformer ç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) â€” Dimensionality
    of the â€œintermediateâ€ (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, defaults to 3072) â€” Transformer ç¼–ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆå³å‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) â€” The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) â€” ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ`"gelu"`ã€`"relu"`ã€`"silu"`å’Œ`"gelu_new"`ã€‚'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) â€” The dropout
    probability for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) â€” åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œæ± åŒ–å™¨ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„ä¸¢å¼ƒæ¦‚ç‡ã€‚'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) â€” The
    dropout ratio for the attention probabilities.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) â€” æ³¨æ„åŠ›æ¦‚ç‡çš„ä¸¢å¼ƒæ¯”ç‡ã€‚'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) â€” The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *optional*, defaults to 512) â€” æ­¤æ¨¡å‹å¯èƒ½ä½¿ç”¨çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚é€šå¸¸å°†å…¶è®¾ç½®ä¸ºè¾ƒå¤§çš„å€¼ä»¥é˜²ä¸‡ä¸€ï¼ˆä¾‹å¦‚ï¼Œ512ã€1024æˆ–2048ï¼‰ã€‚'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) â€” The vocabulary size
    of the `token_type_ids` passed into [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size` (`int`, *optional*, defaults to 2) â€” ä¼ é€’ç»™[LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)çš„`token_type_ids`çš„è¯æ±‡è¡¨å¤§å°ã€‚'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) â€” The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) â€” The epsilon used
    by the layer normalization layers.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) â€” å±‚å½’ä¸€åŒ–å±‚ä½¿ç”¨çš„ epsilonã€‚'
- en: '`pad_token_id` (`int`, *optional*, defaults to 0) â€” The value used to pad input_ids.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_id` (`int`, *optional*, defaults to 0) â€” ç”¨äºå¡«å……`input_ids`çš„å€¼ã€‚'
- en: '`position_embedding_type` (`str`, *optional*, defaults to `"absolute"`) â€” Type
    of position embedding. Choose one of `"absolute"`, `"relative_key"`, `"relative_key_query"`.
    For positional embeddings use `"absolute"`. For more information on `"relative_key"`,
    please refer to [Self-Attention with Relative Position Representations (Shaw et
    al.)](https://arxiv.org/abs/1803.02155). For more information on `"relative_key_query"`,
    please refer to *Method 4* in [Improve Transformer Models with Better Relative
    Position Embeddings (Huang et al.)](https://arxiv.org/abs/2009.13658).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_embedding_type` (`str`, *optional*, defaults to `"absolute"`) â€” ä½ç½®åµŒå…¥çš„ç±»å‹ã€‚é€‰æ‹©`"absolute"`ã€`"relative_key"`ã€`"relative_key_query"`ä¸­çš„ä¸€ä¸ªã€‚å¯¹äºä½ç½®åµŒå…¥ï¼Œè¯·ä½¿ç”¨`"absolute"`ã€‚æœ‰å…³`"relative_key"`çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ[å…·æœ‰ç›¸å¯¹ä½ç½®è¡¨ç¤ºçš„è‡ªæ³¨æ„åŠ›ï¼ˆShawç­‰äººï¼‰](https://arxiv.org/abs/1803.02155)ã€‚æœ‰å…³`"relative_key_query"`çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ[ä½¿ç”¨æ›´å¥½çš„ç›¸å¯¹ä½ç½®åµŒå…¥æ”¹è¿›Transformeræ¨¡å‹ï¼ˆHuangç­‰äººï¼‰]ä¸­çš„*æ–¹æ³•4*ï¼ˆhttps://arxiv.org/abs/2009.13658ï¼‰ã€‚'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” Whether or not the model
    should return the last key/values attentions (not used by all models). Only relevant
    if `config.is_decoder=True`.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” æ¨¡å‹æ˜¯å¦åº”è¿”å›æœ€åçš„é”®/å€¼æ³¨æ„åŠ›ï¼ˆå¹¶éæ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨ï¼‰ã€‚ä»…åœ¨`config.is_decoder=True`æ—¶ç›¸å…³ã€‚'
- en: '`max_2d_position_embeddings` (`int`, *optional*, defaults to 1024) â€” The maximum
    value that the 2D position embedding might ever used. Typically set this to something
    large just in case (e.g., 1024).'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_2d_position_embeddings` (`int`, *optional*, defaults to 1024) â€” 2Dä½ç½®åµŒå…¥å¯èƒ½ä½¿ç”¨çš„æœ€å¤§å€¼ã€‚é€šå¸¸å°†å…¶è®¾ç½®ä¸ºè¾ƒå¤§çš„å€¼ä»¥é˜²ä¸‡ä¸€ï¼ˆä¾‹å¦‚ï¼Œ1024ï¼‰ã€‚'
- en: This is the configuration class to store the configuration of a [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel).
    It is used to instantiate a LayoutLM model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the LayoutLM [microsoft/layoutlm-base-uncased](https://huggingface.co/microsoft/layoutlm-base-uncased)
    architecture.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯é…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨[LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)çš„é…ç½®ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–LayoutLMæ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äºLayoutLM
    [microsoft/layoutlm-base-uncased](https://huggingface.co/microsoft/layoutlm-base-uncased)æ¶æ„çš„é…ç½®ã€‚
- en: Configuration objects inherit from [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    and can be used to control the model outputs. Read the documentation from [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    for more information.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»æ¥è‡ª[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: 'Examples:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: LayoutLMTokenizer
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMTokenizer
- en: '### `class transformers.LayoutLMTokenizer`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMTokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L75)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L75)'
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vocab_file` (`str`) â€” File containing the vocabulary.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) â€” åŒ…å«è¯æ±‡è¡¨çš„æ–‡ä»¶ã€‚'
- en: '`do_lower_case` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    lowercase the input when tokenizing.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_lower_case` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦åœ¨æ ‡è®°åŒ–æ—¶å°†è¾“å…¥è½¬æ¢ä¸ºå°å†™ã€‚'
- en: '`do_basic_tokenize` (`bool`, *optional*, defaults to `True`) â€” Whether or not
    to do basic tokenization before WordPiece.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_basic_tokenize` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦åœ¨WordPieceä¹‹å‰è¿›è¡ŒåŸºæœ¬æ ‡è®°åŒ–ã€‚'
- en: '`never_split` (`Iterable`, *optional*) â€” Collection of tokens which will never
    be split during tokenization. Only has an effect when `do_basic_tokenize=True`'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`never_split` (`Iterable`, *optional*) â€” åœ¨æ ‡è®°åŒ–è¿‡ç¨‹ä¸­æ°¸è¿œä¸ä¼šè¢«æ‹†åˆ†çš„æ ‡è®°é›†åˆã€‚ä»…åœ¨`do_basic_tokenize=True`æ—¶ç”Ÿæ•ˆã€‚'
- en: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) â€” The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) â€” æœªçŸ¥æ ‡è®°ã€‚è¯æ±‡è¡¨ä¸­ä¸å­˜åœ¨çš„æ ‡è®°æ— æ³•è½¬æ¢ä¸ºIDï¼Œè€Œæ˜¯è®¾ç½®ä¸ºæ­¤æ ‡è®°ã€‚'
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) â€” The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) â€” åˆ†éš”ç¬¦æ ‡è®°ï¼Œåœ¨ä»å¤šä¸ªåºåˆ—æ„å»ºåºåˆ—æ—¶ä½¿ç”¨ï¼Œä¾‹å¦‚ç”¨äºåºåˆ—åˆ†ç±»çš„ä¸¤ä¸ªåºåˆ—æˆ–ç”¨äºæ–‡æœ¬å’Œé—®é¢˜çš„é—®é¢˜å›ç­”ã€‚å®ƒä¹Ÿç”¨ä½œä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ„å»ºçš„åºåˆ—çš„æœ€åä¸€ä¸ªæ ‡è®°ã€‚'
- en: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) â€” The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) â€” ç”¨äºå¡«å……çš„æ ‡è®°ï¼Œä¾‹å¦‚åœ¨æ‰¹å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä½¿ç”¨ã€‚'
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) â€” The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) â€” åˆ†ç±»å™¨æ ‡è®°ï¼Œç”¨äºè¿›è¡Œåºåˆ—åˆ†ç±»ï¼ˆå¯¹æ•´ä¸ªåºåˆ—è¿›è¡Œåˆ†ç±»ï¼Œè€Œä¸æ˜¯æ¯ä¸ªæ ‡è®°çš„åˆ†ç±»ï¼‰ã€‚åœ¨æ„å»ºå¸¦æœ‰ç‰¹æ®Šæ ‡è®°çš„åºåˆ—æ—¶ï¼Œå®ƒæ˜¯åºåˆ—çš„ç¬¬ä¸€ä¸ªæ ‡è®°ã€‚'
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) â€” The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) â€” ç”¨äºå±è”½å€¼çš„æ ‡è®°ã€‚è¿™æ˜¯åœ¨ä½¿ç”¨æ©ç è¯­è¨€å»ºæ¨¡è®­ç»ƒæ­¤æ¨¡å‹æ—¶ä½¿ç”¨çš„æ ‡è®°ã€‚è¿™æ˜¯æ¨¡å‹å°†å°è¯•é¢„æµ‹çš„æ ‡è®°ã€‚'
- en: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) â€” Whether
    or not to tokenize Chinese characters.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦å¯¹ä¸­æ–‡å­—ç¬¦è¿›è¡Œæ ‡è®°åŒ–ã€‚'
- en: This should likely be deactivated for Japanese (see this [issue](https://github.com/huggingface/transformers/issues/328)).
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºæ—¥è¯­ï¼Œè¿™å¯èƒ½åº”è¯¥è¢«åœç”¨ï¼ˆè¯·å‚é˜…æ­¤[é—®é¢˜](https://github.com/huggingface/transformers/issues/328)ï¼‰ã€‚
- en: '`strip_accents` (`bool`, *optional*) â€” Whether or not to strip all accents.
    If this option is not specified, then it will be determined by the value for `lowercase`
    (as in the original LayoutLM).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strip_accents` (`bool`, *optional*) â€” æ˜¯å¦å»é™¤æ‰€æœ‰é‡éŸ³ç¬¦å·ã€‚å¦‚æœæœªæŒ‡å®šæ­¤é€‰é¡¹ï¼Œåˆ™å°†ç”±`lowercase`çš„å€¼ç¡®å®šï¼ˆä¸åŸå§‹LayoutLMä¸­çš„æƒ…å†µç›¸åŒï¼‰ã€‚'
- en: Construct a LayoutLM tokenizer. Based on WordPiece.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªåŸºäºWordPieceçš„LayoutLMåˆ†è¯å™¨ã€‚
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤åˆ†è¯å™¨ç»§æ‰¿è‡ª[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)ï¼Œå…¶ä¸­åŒ…å«å¤§éƒ¨åˆ†ä¸»è¦æ–¹æ³•ã€‚ç”¨æˆ·åº”å‚è€ƒæ­¤è¶…ç±»ä»¥è·å–æœ‰å…³è¿™äº›æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ã€‚
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L208)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L208)'
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs to which the special tokens will
    be added.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) â€” å°†æ·»åŠ ç‰¹æ®Šæ ‡è®°çš„IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *å¯é€‰*) â€” åºåˆ—å¯¹çš„ç¬¬äºŒä¸ªIDåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ã€‚'
- en: Returns
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰é€‚å½“ç‰¹æ®Šæ ‡è®°çš„[input IDs](../glossary#input-ids)åˆ—è¡¨ã€‚
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. A LayoutLM sequence has the
    following format:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿æ¥å’Œæ·»åŠ ç‰¹æ®Šæ ‡è®°ï¼Œä»åºåˆ—æˆ–åºåˆ—å¯¹æ„å»ºç”¨äºåºåˆ—åˆ†ç±»ä»»åŠ¡çš„æ¨¡å‹è¾“å…¥ã€‚ä¸€ä¸ªLayoutLMåºåˆ—çš„æ ¼å¼å¦‚ä¸‹ï¼š
- en: 'single sequence: `[CLS] X [SEP]`'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•ä¸ªåºåˆ—ï¼š`[CLS] X [SEP]`
- en: 'pair of sequences: `[CLS] A [SEP] B [SEP]`'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åºåˆ—å¯¹ï¼š`[CLS] A [SEP] B [SEP]`
- en: '#### `convert_tokens_to_string`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `convert_tokens_to_string`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L203)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L203)'
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Converts a sequence of tokens (string) in a single string.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ä¸€ç³»åˆ—æ ‡è®°ï¼ˆå­—ç¬¦ä¸²ï¼‰è½¬æ¢ä¸ºå•ä¸ªå­—ç¬¦ä¸²ã€‚
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L261)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L261)'
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) â€” IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *å¯é€‰*) â€” åºåˆ—å¯¹çš„ç¬¬äºŒä¸ªIDåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ã€‚'
- en: Returns
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [token type IDs](../glossary#token-type-ids) according to the given
    sequence(s).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ç»™å®šåºåˆ—çš„[token type IDs](../glossary#token-type-ids)åˆ—è¡¨ã€‚
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. A LayoutLM sequence
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¼ é€’çš„ä¸¤ä¸ªåºåˆ—åˆ›å»ºä¸€ä¸ªç”¨äºåºåˆ—å¯¹åˆ†ç±»ä»»åŠ¡çš„æ©ç ã€‚ä¸€ä¸ªLayoutLMåºåˆ—
- en: 'pair mask has the following format:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: åºåˆ—æ©ç çš„æ ¼å¼å¦‚ä¸‹ï¼š
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If `token_ids_1` is `None`, this method only returns the first portion of the
    mask (0s).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ`token_ids_1`ä¸º`None`ï¼Œåˆ™æ­¤æ–¹æ³•ä»…è¿”å›æ©ç çš„ç¬¬ä¸€éƒ¨åˆ†ï¼ˆ0ï¼‰ã€‚
- en: '#### `get_special_tokens_mask`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_special_tokens_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L233)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm.py#L233)'
- en: '[PRE9]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) â€” IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *å¯é€‰*) â€” åºåˆ—å¯¹çš„ç¬¬äºŒä¸ªIDåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ã€‚'
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) â€” Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`already_has_special_tokens` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ ‡è®°åˆ—è¡¨æ˜¯å¦å·²ç»ä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ ¼å¼åŒ–ä¸ºæ¨¡å‹ã€‚'
- en: Returns
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ•´æ•°åˆ—è¡¨ï¼ŒèŒƒå›´ä¸º[0, 1]ï¼š1è¡¨ç¤ºç‰¹æ®Šæ ‡è®°ï¼Œ0è¡¨ç¤ºåºåˆ—æ ‡è®°ã€‚
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ²¡æœ‰æ·»åŠ ç‰¹æ®Šæ ‡è®°çš„æ ‡è®°åˆ—è¡¨ä¸­æ£€ç´¢åºåˆ—IDã€‚å½“ä½¿ç”¨åˆ†è¯å™¨çš„`prepare_for_model`æ–¹æ³•æ·»åŠ ç‰¹æ®Šæ ‡è®°æ—¶ï¼Œå°†è°ƒç”¨æ­¤æ–¹æ³•ã€‚
- en: LayoutLMTokenizerFast
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMTokenizerFast
- en: '### `class transformers.LayoutLMTokenizerFast`'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMTokenizerFast`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py#L62)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py#L62)'
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vocab_file` (`str`) â€” File containing the vocabulary.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) â€” åŒ…å«è¯æ±‡è¡¨çš„æ–‡ä»¶ã€‚'
- en: '`do_lower_case` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    lowercase the input when tokenizing.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_lower_case` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” åœ¨åˆ†è¯æ—¶æ˜¯å¦å°†è¾“å…¥è½¬æ¢ä¸ºå°å†™ã€‚'
- en: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) â€” The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"[UNK]"`) â€” æœªçŸ¥æ ‡è®°ã€‚è¯æ±‡è¡¨ä¸­æ²¡æœ‰çš„æ ‡è®°æ— æ³•è½¬æ¢ä¸ºIDï¼Œè€Œæ˜¯è®¾ç½®ä¸ºæ­¤æ ‡è®°ã€‚'
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) â€” The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"[SEP]"`) â€” åˆ†éš”ç¬¦æ ‡è®°ï¼Œåœ¨æ„å»ºæ¥è‡ªå¤šä¸ªåºåˆ—çš„åºåˆ—æ—¶ä½¿ç”¨ï¼Œä¾‹å¦‚ç”¨äºåºåˆ—åˆ†ç±»çš„ä¸¤ä¸ªåºåˆ—æˆ–ç”¨äºæ–‡æœ¬å’Œé—®é¢˜çš„é—®é¢˜å›ç­”ã€‚ä¹Ÿç”¨ä½œä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ„å»ºçš„åºåˆ—çš„æœ€åä¸€ä¸ªæ ‡è®°ã€‚'
- en: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) â€” The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"[PAD]"`) â€” ç”¨äºå¡«å……çš„æ ‡è®°ï¼Œä¾‹å¦‚åœ¨æ‰¹å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä½¿ç”¨ã€‚'
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) â€” The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"[CLS]"`) â€” åœ¨è¿›è¡Œåºåˆ—åˆ†ç±»ï¼ˆæ•´ä¸ªåºåˆ—è€Œä¸æ˜¯æ¯ä¸ªæ ‡è®°çš„åˆ†ç±»ï¼‰æ—¶ä½¿ç”¨çš„åˆ†ç±»å™¨æ ‡è®°ã€‚æ„å»ºæ—¶æ˜¯åºåˆ—çš„ç¬¬ä¸€ä¸ªæ ‡è®°ã€‚'
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) â€” The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) â€” ç”¨äºå±è”½å€¼çš„æ ‡è®°ã€‚è¿™æ˜¯åœ¨ä½¿ç”¨æ©ç è¯­è¨€å»ºæ¨¡è®­ç»ƒæ­¤æ¨¡å‹æ—¶ä½¿ç”¨çš„æ ‡è®°ã€‚è¿™æ˜¯æ¨¡å‹å°†å°è¯•é¢„æµ‹çš„æ ‡è®°ã€‚'
- en: '`clean_text` (`bool`, *optional*, defaults to `True`) â€” Whether or not to clean
    the text before tokenization by removing any control characters and replacing
    all whitespaces by the classic one.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_text` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦åœ¨æ ‡è®°åŒ–ä¹‹å‰æ¸…ç†æ–‡æœ¬ï¼Œé€šè¿‡åˆ é™¤ä»»ä½•æ§åˆ¶å­—ç¬¦å¹¶å°†æ‰€æœ‰ç©ºæ ¼æ›¿æ¢ä¸ºç»å…¸ç©ºæ ¼ã€‚'
- en: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) â€” Whether
    or not to tokenize Chinese characters. This should likely be deactivated for Japanese
    (see [this issue](https://github.com/huggingface/transformers/issues/328)).'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦å¯¹ä¸­æ–‡å­—ç¬¦è¿›è¡Œåˆ†è¯ã€‚å¯¹äºæ—¥è¯­ï¼Œè¿™å¯èƒ½åº”è¯¥è¢«ç¦ç”¨ï¼ˆå‚è§[æ­¤é—®é¢˜](https://github.com/huggingface/transformers/issues/328)ï¼‰ã€‚'
- en: '`strip_accents` (`bool`, *optional*) â€” Whether or not to strip all accents.
    If this option is not specified, then it will be determined by the value for `lowercase`
    (as in the original LayoutLM).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strip_accents` (`bool`, *optional*) â€” æ˜¯å¦å»é™¤æ‰€æœ‰é‡éŸ³ç¬¦å·ã€‚å¦‚æœæœªæŒ‡å®šæ­¤é€‰é¡¹ï¼Œåˆ™å°†ç”±`lowercase`çš„å€¼ç¡®å®šï¼ˆä¸åŸå§‹LayoutLMä¸­ç›¸åŒï¼‰ã€‚'
- en: '`wordpieces_prefix` (`str`, *optional*, defaults to `"##"`) â€” The prefix for
    subwords.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wordpieces_prefix` (`str`, *optional*, defaults to `"##"`) â€” å­è¯çš„å‰ç¼€ã€‚'
- en: Construct a â€œfastâ€ LayoutLM tokenizer (backed by HuggingFaceâ€™s *tokenizers*
    library). Based on WordPiece.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªâ€œå¿«é€Ÿâ€LayoutLMæ ‡è®°å™¨ï¼ˆç”±HuggingFaceçš„*tokenizers*åº“æ”¯æŒï¼‰ã€‚åŸºäºWordPieceã€‚
- en: This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ ‡è®°å™¨ç»§æ‰¿è‡ª[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)ï¼Œå…¶ä¸­åŒ…å«å¤§å¤šæ•°ä¸»è¦æ–¹æ³•ã€‚ç”¨æˆ·åº”å‚è€ƒæ­¤è¶…ç±»ä»¥è·å–æœ‰å…³è¿™äº›æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ã€‚
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py#L150)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py#L150)'
- en: '[PRE11]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs to which the special tokens will
    be added.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) â€” å°†æ·»åŠ ç‰¹æ®Šæ ‡è®°çš„IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *optional*) â€” åºåˆ—å¯¹çš„å¯é€‰ç¬¬äºŒä¸ªIDåˆ—è¡¨ã€‚'
- en: Returns
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å…·æœ‰é€‚å½“ç‰¹æ®Šæ ‡è®°çš„[input IDs](../glossary#input-ids)åˆ—è¡¨ã€‚
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. A LayoutLM sequence has the
    following format:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ä»åºåˆ—æˆ–åºåˆ—å¯¹æ„å»ºç”¨äºåºåˆ—åˆ†ç±»ä»»åŠ¡çš„æ¨¡å‹è¾“å…¥ï¼Œé€šè¿‡è¿æ¥å’Œæ·»åŠ ç‰¹æ®Šæ ‡è®°ã€‚ä¸€ä¸ªLayoutLMåºåˆ—å…·æœ‰ä»¥ä¸‹æ ¼å¼ï¼š
- en: 'single sequence: `[CLS] X [SEP]`'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•ä¸ªåºåˆ—ï¼š`[CLS] X [SEP]`
- en: 'pair of sequences: `[CLS] A [SEP] B [SEP]`'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åºåˆ—å¯¹ï¼š`[CLS] A [SEP] B [SEP]`
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py#L174)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py#L174)'
- en: '[PRE12]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`token_ids_0` (`List[int]`) â€” List of IDs.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) â€” IDåˆ—è¡¨ã€‚'
- en: '`token_ids_1` (`List[int]`, *optional*) â€” Optional second list of IDs for sequence
    pairs.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *optional*) â€” åºåˆ—å¯¹çš„å¯é€‰ç¬¬äºŒä¸ªIDåˆ—è¡¨ã€‚'
- en: Returns
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`List[int]`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [token type IDs](../glossary#token-type-ids) according to the given
    sequence(s).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ç»™å®šåºåˆ—çš„[token type IDs](../glossary#token-type-ids)åˆ—è¡¨ã€‚
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. A LayoutLM sequence
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¼ é€’çš„ä¸¤ä¸ªåºåˆ—åˆ›å»ºç”¨äºåºåˆ—å¯¹åˆ†ç±»ä»»åŠ¡çš„æ©ç ã€‚ä¸€ä¸ªLayoutLMåºåˆ—
- en: 'pair mask has the following format:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: åºåˆ—æ©ç å…·æœ‰ä»¥ä¸‹æ ¼å¼ï¼š
- en: '[PRE13]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: If `token_ids_1` is `None`, this method only returns the first portion of the
    mask (0s).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ`token_ids_1`ä¸º`None`ï¼Œåˆ™æ­¤æ–¹æ³•ä»…è¿”å›æ©ç çš„ç¬¬ä¸€éƒ¨åˆ†ï¼ˆ0sï¼‰ã€‚
- en: PytorchHide Pytorch content
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorchå†…å®¹
- en: LayoutLMModel
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMModel
- en: '### `class transformers.LayoutLMModel`'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L699)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L699)'
- en: '[PRE14]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: 'The bare LayoutLM Model transformer outputting raw hidden-states without any
    specific head on top. The LayoutLM model was proposed in [LayoutLM: Pre-training
    of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318)
    by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei and Ming Zhou.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 'è£¸çš„LayoutLMæ¨¡å‹å˜å‹å™¨è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚LayoutLMæ¨¡å‹ç”±Yiheng Xuã€Minghao Liã€Lei Cuiã€Shaohan
    Huangã€Furu Weiå’ŒMing Zhouåœ¨[LayoutLM: Pre-training of Text and Layout for Document
    Image Understanding](https://arxiv.org/abs/1912.13318)ä¸­æå‡ºã€‚'
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚
- en: '#### `forward`'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L729)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L729)'
- en: '[PRE15]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner. See [Overview](#Overview)
    for normalization.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_2d_position_embeddings-1]`ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0,
    x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0, y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚æœ‰å…³å½’ä¸€åŒ–ï¼Œè¯·å‚é˜…[æ¦‚è¿°](#Overview)ã€‚'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`: `1` for tokens that are NOT MASKED, `0` for MASKED
    tokens.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚é€‰æ‹©åœ¨`[0, 1]`èŒƒå›´å†…çš„æ©ç å€¼ï¼š`1`è¡¨ç¤ºæœªè¢«æ©ç›–çš„æ ‡è®°ï¼Œ`0`è¡¨ç¤ºè¢«æ©ç›–çš„æ ‡è®°ã€‚'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`: `0` corresponds to a *sentence A* token,
    `1` corresponds to a *sentence B* token'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” æ®µæ ‡è®°ç´¢å¼•ï¼ŒæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•é€‰æ‹©åœ¨`[0, 1]`ï¼š`0`å¯¹åº”äº*å¥å­A*æ ‡è®°ï¼Œ`1`å¯¹åº”äº*å¥å­B*æ ‡è®°'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹IDï¼Ÿ](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚é€‰æ‹©èŒƒå›´ä¸º`[0, config.max_position_embeddings - 1]`ã€‚'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`: `1` indicates the head is **not masked**, `0` indicates
    the head is **masked**.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚é€‰æ‹©çš„æ©ç å€¼åœ¨`[0, 1]`èŒƒå›´å†…ï¼š`1`è¡¨ç¤ºå¤´éƒ¨**æœªè¢«æ©ç›–**ï¼Œ`0`è¡¨ç¤ºå¤´éƒ¨**è¢«æ©ç›–**ã€‚'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†*input_ids*ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè¿™å°†éå¸¸æœ‰ç”¨ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” If set to `True`, the attentions
    tensors of all attention layers are returned. See `attentions` under returned
    tensors for more detail.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” If set to `True`, the hidden
    states of all layers are returned. See `hidden_states` under returned tensors
    for more detail.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” If set to `True`, the model will return
    a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œæ¨¡å‹å°†è¿”å›ä¸€ä¸ª[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚'
- en: Returns
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions)
    or `tuple(torch.FloatTensor)`'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions)æˆ–è€…ä¸€ä¸ª`torch.FloatTensor`çš„å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–è€…å½“`config.return_dict=False`æ—¶ï¼‰ï¼ŒåŒ…æ‹¬æ ¹æ®é…ç½®ï¼ˆ[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)ï¼‰å’Œè¾“å…¥è€Œå®šçš„å„ç§å…ƒç´ ã€‚
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼‰
    â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    â€” Last layer hidden-state of the first token of the sequence (classification token)
    after further processing through the layers used for the auxiliary pretraining
    task. E.g. for BERT-family of models, this returns the classification token after
    processing through a linear layer and a tanh activation function. The linear layer
    weights are trained from the next sentence prediction (classification) objective
    during pretraining.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, hidden_size)`çš„`torch.FloatTensor`ï¼‰ â€” åºåˆ—ä¸­ç¬¬ä¸€ä¸ªæ ‡è®°ï¼ˆåˆ†ç±»æ ‡è®°ï¼‰çš„æœ€åä¸€å±‚éšè—çŠ¶æ€ï¼ˆç»è¿‡ç”¨äºè¾…åŠ©é¢„è®­ç»ƒä»»åŠ¡çš„å±‚è¿›ä¸€æ­¥å¤„ç†åï¼‰ã€‚ä¾‹å¦‚ï¼Œå¯¹äºBERTç³»åˆ—æ¨¡å‹ï¼Œè¿™è¿”å›ç»è¿‡çº¿æ€§å±‚å’Œtanhæ¿€æ´»å‡½æ•°å¤„ç†åçš„åˆ†ç±»æ ‡è®°ã€‚çº¿æ€§å±‚çš„æƒé‡æ˜¯åœ¨é¢„è®­ç»ƒæœŸé—´ä»ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹ï¼ˆåˆ†ç±»ï¼‰ç›®æ ‡ä¸­è®­ç»ƒçš„ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–è€…å½“`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡ºä¸€ä¸ª
    + æ¯ä¸ªå±‚çš„è¾“å‡ºä¸€ä¸ªï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–è€…å½“`config.output_attentions=True`æ—¶è¿”å›ï¼‰
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„åŠ›softmaxä¹‹åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    and `config.add_cross_attention=True` is passed or when `config.output_attentions=True`)
    â€” Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`å’Œ`config.add_cross_attention=True`æˆ–è€…å½“`config.output_attentions=True`æ—¶è¿”å›ï¼‰
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and optionally if `config.is_encoder_decoder=True`
    2 additional tensors of shape `(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`ï¼ˆ`tuple(tuple(torch.FloatTensor))`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`use_cache=True`æˆ–è€…å½“`config.use_cache=True`æ—¶è¿”å›ï¼‰
    â€” é•¿åº¦ä¸º`config.n_layers`çš„`tuple(torch.FloatTensor)`å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰2ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`çš„å¼ é‡ï¼Œå¦‚æœ`config.is_encoder_decoder=True`è¿˜æœ‰é¢å¤–çš„2ä¸ªå½¢çŠ¶ä¸º`(batch_size,
    num_heads, encoder_sequence_length, embed_size_per_head)`çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and optionally if `config.is_encoder_decoder=True` in the cross-attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ä»¥åŠåœ¨äº¤å‰æ³¨æ„åŠ›å—ä¸­å¯é€‰åœ°å¦‚æœ`config.is_encoder_decoder=True`ï¼‰å¯ä»¥ç”¨æ¥åŠ é€Ÿé¡ºåºè§£ç çš„ï¼ˆè§`past_key_values`è¾“å…¥ï¼‰ã€‚
- en: The [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)
    forward method, overrides the `__call__` special method.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨è¿™ä¸ªå‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨ä¹‹åè°ƒç”¨`Module`å®ä¾‹è€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE16]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: LayoutLMForMaskedLM
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMForMaskedLM
- en: '### `class transformers.LayoutLMForMaskedLM`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMForMaskedLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L851)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L851)'
- en: '[PRE17]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)ï¼‰â€”
    æ¨¡å‹é…ç½®ç±»ï¼ŒåŒ…å«æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: 'LayoutLM Model with a `language modeling` head on top. The LayoutLM model was
    proposed in [LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318)
    by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei and Ming Zhou.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨é¡¶éƒ¨å¸¦æœ‰`è¯­è¨€å»ºæ¨¡`å¤´çš„LayoutLMæ¨¡å‹ã€‚LayoutLMæ¨¡å‹æ˜¯ç”±Yiheng Xuã€Minghao Liã€Lei Cuiã€Shaohan Huangã€Furu
    Weiå’ŒMing Zhouåœ¨[LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318)ä¸­æå‡ºçš„ã€‚'
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚
- en: '#### `forward`'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L873)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L873)'
- en: '[PRE18]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼‰â€” è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner. See [Overview](#Overview)
    for normalization.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, 4)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚åœ¨èŒƒå›´`[0,
    config.max_2d_position_embeddings-1]`ä¸­é€‰æ‹©ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0, x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0,
    y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚æœ‰å…³å½’ä¸€åŒ–ï¼Œè¯·å‚é˜…[æ¦‚è¿°](#æ¦‚è¿°)ã€‚'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`: `1` for tokens that are NOT MASKED, `0` for MASKED
    tokens.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºé¿å…åœ¨å¡«å……æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š`1`è¡¨ç¤ºæœªè¢«æ©ç çš„æ ‡è®°ï¼Œ`0`è¡¨ç¤ºè¢«æ©ç çš„æ ‡è®°ã€‚'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`: `0` corresponds to a *sentence A* token,
    `1` corresponds to a *sentence B* token'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    æ®µæ ‡è®°ç´¢å¼•ï¼Œç”¨äºæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š`0`å¯¹åº”äº*å¥å­A*çš„æ ‡è®°ï¼Œ`1`å¯¹åº”äº*å¥å­B*çš„æ ‡è®°'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯token type IDsï¼Ÿ
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚åœ¨èŒƒå›´`[0, config.max_position_embeddings - 1]`ä¸­é€‰æ‹©ã€‚'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`: `1` indicates the head is **not masked**, `0` indicates
    the head is **masked**.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š`1`è¡¨ç¤ºå¤´éƒ¨**æœªè¢«æ©ç **ï¼Œ`0`è¡¨ç¤ºå¤´éƒ¨**è¢«æ©ç **ã€‚'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€”
    å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†*input_ids*ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” If set to `True`, the attentions
    tensors of all attention layers are returned. See `attentions` under returned
    tensors for more detail.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›çš„å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” If set to `True`, the hidden
    states of all layers are returned. See `hidden_states` under returned tensors
    for more detail.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” If set to `True`, the model will return
    a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œæ¨¡å‹å°†è¿”å›ä¸€ä¸ª[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šå…ƒç»„ã€‚'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Labels for computing the masked language modeling loss. Indices should be in
    `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-100` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè®¡ç®—æ©ç è¯­è¨€å»ºæ¨¡æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[-100,
    0, ..., config.vocab_size]`å†…ï¼ˆå‚è§`input_ids`æ–‡æ¡£å­—ç¬¦ä¸²ï¼‰ã€‚ç´¢å¼•è®¾ç½®ä¸º`-100`çš„æ ‡è®°å°†è¢«å¿½ç•¥ï¼ˆæ©ç ï¼‰ï¼ŒæŸå¤±ä»…è®¡ç®—å…·æœ‰æ ‡ç­¾åœ¨`[0,
    ..., config.vocab_size]`å†…çš„æ ‡è®°ã€‚'
- en: Returns
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)ï¼‰å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Masked language modeling (MLM) loss.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`ï¼ˆå½¢çŠ¶ä¸º`(1,)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼‰â€” æ©ç è¯­è¨€å»ºæ¨¡ï¼ˆMLMï¼‰æŸå¤±ã€‚'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    â€” Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, config.vocab_size)`çš„`torch.FloatTensor`ï¼‰â€”
    è¯­è¨€å»ºæ¨¡å¤´éƒ¨çš„é¢„æµ‹åˆ†æ•°ï¼ˆSoftMaxä¹‹å‰æ¯ä¸ªè¯æ±‡æ ‡è®°çš„åˆ†æ•°ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡ºï¼Œå¦‚æœæ¨¡å‹æœ‰ä¸€ä¸ªåµŒå…¥å±‚ï¼Œ+
    ä¸€ä¸ªç”¨äºæ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€”
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    forward method, overrides the `__call__` special method.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE19]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: LayoutLMForSequenceClassification
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMForSequenceClassification
- en: '### `class transformers.LayoutLMForSequenceClassification`'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L976)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L976)'
- en: '[PRE20]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)ï¼‰â€”
    å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: LayoutLM Model with a sequence classification head on top (a linear layer on
    top of the pooled output) e.g. for document image classification tasks such as
    the [RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/) dataset.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: LayoutLM æ¨¡å‹åœ¨é¡¶éƒ¨ä½¿ç”¨åºåˆ—åˆ†ç±»å¤´éƒ¨ï¼ˆæ± åŒ–è¾“å‡ºçš„é¡¶éƒ¨çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºæ–‡æ¡£å›¾åƒåˆ†ç±»ä»»åŠ¡çš„[RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)æ•°æ®é›†ã€‚
- en: 'The LayoutLM model was proposed in [LayoutLM: Pre-training of Text and Layout
    for Document Image Understanding](https://arxiv.org/abs/1912.13318) by Yiheng
    Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei and Ming Zhou.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 'LayoutLMæ¨¡å‹ç”±Yiheng Xuã€Minghao Liã€Lei Cuiã€Shaohan Huangã€Furu Weiå’ŒMing Zhouåœ¨[LayoutLM:
    Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318)ä¸­æå‡ºã€‚'
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚
- en: '#### `forward`'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L997)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L997)'
- en: '[PRE21]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`ï¼ˆ`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼‰â€” è¯æ±‡è¡¨ä¸­è¾“å…¥åºåˆ—æ ‡è®°çš„ç´¢å¼•ã€‚'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)è·å–ç´¢å¼•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)å’Œ[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)ã€‚
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯è¾“å…¥IDï¼Ÿ
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner. See [Overview](#Overview)
    for normalization.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox`ï¼ˆ`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, 4)`ï¼Œ*å¯é€‰*ï¼‰â€” æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°çš„è¾¹ç•Œæ¡†ã€‚åœ¨èŒƒå›´`[0,
    config.max_2d_position_embeddings-1]`ä¸­é€‰æ‹©ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†åº”è¯¥æ˜¯(x0, y0, x1, y1)æ ¼å¼çš„å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œå…¶ä¸­(x0,
    y0)å¯¹åº”äºè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ä½ç½®ï¼Œ(x1, y1)è¡¨ç¤ºå³ä¸‹è§’çš„ä½ç½®ã€‚æœ‰å…³å½’ä¸€åŒ–ï¼Œè¯·å‚é˜…[æ¦‚è¿°](#Overview)ã€‚'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`: `1` for tokens that are NOT MASKED, `0` for MASKED
    tokens.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºé¿å…å¯¹å¡«å……æ ‡è®°ç´¢å¼•æ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š`1`è¡¨ç¤º**æœªè¢«æ©ç **çš„æ ‡è®°ï¼Œ`0`è¡¨ç¤º**è¢«æ©ç **çš„æ ‡è®°ã€‚'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`: `0` corresponds to a *sentence A* token,
    `1` corresponds to a *sentence B* token'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`ï¼ˆ`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*ï¼‰â€”
    æ®µæ ‡è®°ç´¢å¼•ï¼Œç”¨äºæŒ‡ç¤ºè¾“å…¥çš„ç¬¬ä¸€éƒ¨åˆ†å’Œç¬¬äºŒéƒ¨åˆ†ã€‚ç´¢å¼•åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š`0`å¯¹åº”äº*å¥å­A*çš„æ ‡è®°ï¼Œ`1`å¯¹åº”äº*å¥å­B*çš„æ ‡è®°'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯æ ‡è®°ç±»å‹IDï¼Ÿ
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`ï¼ˆ`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*ï¼‰â€”
    æ¯ä¸ªè¾“å…¥åºåˆ—æ ‡è®°åœ¨ä½ç½®åµŒå…¥ä¸­çš„ä½ç½®ç´¢å¼•ã€‚åœ¨èŒƒå›´`[0, config.max_position_embeddings - 1]`ä¸­é€‰æ‹©ã€‚'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ä½ç½®IDï¼Ÿ
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`: `1` indicates the head is **not masked**, `0` indicates
    the head is **masked**.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`ï¼Œ*å¯é€‰*ï¼‰â€”
    ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š`1`è¡¨ç¤ºå¤´éƒ¨**æœªè¢«æ©ç **ï¼Œ`0`è¡¨ç¤ºå¤´éƒ¨**è¢«æ©ç **ã€‚'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*ï¼‰â€”
    å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†*input_ids*ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œåˆ™è¿™å¾ˆæœ‰ç”¨ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” If set to `True`, the attentions
    tensors of all attention layers are returned. See `attentions` under returned
    tensors for more detail.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” If set to `True`, the hidden
    states of all layers are returned. See `hidden_states` under returned tensors
    for more detail.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” If set to `True`, the model will return
    a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œæ¨¡å‹å°†è¿”å›ä¸€ä¸ª[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€” Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[0, ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression loss
    is computed (Mean-Square loss), If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Classification (or regression if config.num_labels==1) loss.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) â€”
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [LayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: LayoutLMForTokenClassification
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.LayoutLMForTokenClassification`'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L1112)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LayoutLM Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for sequence labeling (information extraction)
    tasks such as the [FUNSD](https://guillaumejaume.github.io/FUNSD/) dataset and
    the [SROIE](https://rrc.cvc.uab.es/?ch=13) dataset.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'The LayoutLM model was proposed in [LayoutLM: Pre-training of Text and Layout
    for Document Image Understanding](https://arxiv.org/abs/1912.13318) by Yiheng
    Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei and Ming Zhou.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L1134)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) â€”
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    â€” Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner. See [Overview](#Overview)
    for normalization.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`: `1` for tokens that are NOT MASKED, `0` for MASKED
    tokens.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`: `0` corresponds to a *sentence A* token,
    `1` corresponds to a *sentence B* token'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) â€” Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`: `1` indicates the head is **not masked**, `0` indicates
    the head is **masked**.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” If set to `True`, the attentions
    tensors of all attention layers are returned. See `attentions` under returned
    tensors for more detail.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” If set to `True`, the hidden
    states of all layers are returned. See `hidden_states` under returned tensors
    for more detail.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” If set to `True`, the model will return
    a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    â€” Labels for computing the token classification loss. Indices should be in `[0,
    ..., config.num_labels - 1]`.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå–å†³äºé…ç½®([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))å’Œè¾“å…¥ã€‚
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Classification loss.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(1,)`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›) â€” åˆ†ç±»æŸå¤±ã€‚'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_labels)`)
    â€” Classification scores (before SoftMax).'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, config.num_labels)`)
    â€” åˆ†ç±»åˆ†æ•°ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥è¾“å‡ºçš„è¾“å‡º+æ¯å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨æ³¨æ„åŠ›softmaxä¹‹åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The [LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE25]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: LayoutLMForQuestionAnswering
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMForQuestionAnswering
- en: '### `class transformers.LayoutLMForQuestionAnswering`'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L1230)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L1230)'
- en: '[PRE26]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•æ¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: LayoutLM Model with a span classification head on top for extractive question-answering
    tasks such as [DocVQA](https://rrc.cvc.uab.es/?ch=17) (a linear layer on top of
    the final hidden-states output to compute `span start logits` and `span end logits`).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: LayoutLMæ¨¡å‹åœ¨é¡¶éƒ¨æœ‰ä¸€ä¸ªè·¨åº¦åˆ†ç±»å¤´ï¼Œç”¨äºæå–é—®ç­”ä»»åŠ¡ï¼Œä¾‹å¦‚[DocVQA](https://rrc.cvc.uab.es/?ch=17)ï¼ˆåœ¨æœ€ç»ˆéšè—çŠ¶æ€è¾“å‡ºçš„é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼Œç”¨äºè®¡ç®—`span
    start logits`å’Œ`span end logits`ï¼‰ã€‚
- en: 'The LayoutLM model was proposed in [LayoutLM: Pre-training of Text and Layout
    for Document Image Understanding](https://arxiv.org/abs/1912.13318) by Yiheng
    Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei and Ming Zhou.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 'LayoutLMæ¨¡å‹ç”±Yiheng Xuã€Minghao Liã€Lei Cuiã€Shaohan Huangã€Furu Weiå’ŒMing Zhouåœ¨[LayoutLM:
    Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318)ä¸­æå‡ºã€‚'
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹æ˜¯PyTorchçš„[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ä¿¡æ¯ã€‚
- en: '#### `forward`'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L1252)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_layoutlm.py#L1252)'
- en: '[PRE27]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Returns
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)æˆ–`torch.FloatTensor`å…ƒç»„'
- en: A [transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª [transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    æˆ–ä¸€ä¸ª `torch.FloatTensor` å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº† `return_dict=False` æˆ– `config.return_dict=False`ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Total span extraction loss is the sum of a Cross-Entropy for the
    start and end positions.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º `(1,)`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾› `labels` æ—¶è¿”å›ï¼‰ â€” æ€»è·¨åº¦æå–æŸå¤±æ˜¯èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®çš„äº¤å‰ç†µä¹‹å’Œã€‚'
- en: '`start_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    â€” Span-start scores (before SoftMax).'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start_logits` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, sequence_length)`) â€”
    è·¨åº¦èµ·å§‹åˆ†æ•°ï¼ˆSoftMax ä¹‹å‰ï¼‰ã€‚'
- en: '`end_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    â€” Span-end scores (before SoftMax).'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`end_logits` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, sequence_length)`) â€” è·¨åº¦ç»“æŸåˆ†æ•°ï¼ˆSoftMax
    ä¹‹å‰ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’ `output_hidden_states=True`
    æˆ– `config.output_hidden_states=True` æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º `(batch_size, sequence_length,
    hidden_size)` çš„ `torch.FloatTensor` å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º + æ¯å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’ `output_attentions=True`
    æˆ– `config.output_attentions=True` æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º `(batch_size, num_heads, sequence_length,
    sequence_length)` çš„ `torch.FloatTensor` å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„åŠ› softmax åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: 'start_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):
    Labels for position (index) of the start of the labelled span for computing the
    token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss. end_positions (`torch.LongTensor` of shape `(batch_size,)`,
    *optional*): Labels for position (index) of the end of the labelled span for computing
    the token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: start_positions (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size,)`ï¼Œ*å¯é€‰*ï¼‰ï¼šç”¨äºè®¡ç®—æ ‡è®°è·¨åº¦çš„èµ·å§‹ä½ç½®ï¼ˆç´¢å¼•ï¼‰çš„æ ‡ç­¾ã€‚ä½ç½®è¢«å¤¹ç´§åˆ°åºåˆ—çš„é•¿åº¦ï¼ˆ`sequence_length`ï¼‰ã€‚è¶…å‡ºåºåˆ—èŒƒå›´çš„ä½ç½®ä¸ä¼šè®¡å…¥æŸå¤±è®¡ç®—ã€‚end_positions
    (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size,)`ï¼Œ*å¯é€‰*ï¼‰ï¼šç”¨äºè®¡ç®—æ ‡è®°è·¨åº¦çš„ç»“æŸä½ç½®ï¼ˆç´¢å¼•ï¼‰çš„æ ‡ç­¾ã€‚ä½ç½®è¢«å¤¹ç´§åˆ°åºåˆ—çš„é•¿åº¦ï¼ˆ`sequence_length`ï¼‰ã€‚è¶…å‡ºåºåˆ—èŒƒå›´çš„ä½ç½®ä¸ä¼šè®¡å…¥æŸå¤±è®¡ç®—ã€‚
- en: 'Example:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: In the example below, we prepare a question + context pair for the LayoutLM
    model. It will give us a prediction of what it thinks the answer is (the span
    of the answer within the texts parsed from the image).
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä¸º LayoutLM æ¨¡å‹å‡†å¤‡äº†ä¸€ä¸ªé—®é¢˜ + ä¸Šä¸‹æ–‡å¯¹ã€‚å®ƒå°†ç»™æˆ‘ä»¬ä¸€ä¸ªé¢„æµ‹ï¼Œå‘Šè¯‰æˆ‘ä»¬å®ƒè®¤ä¸ºç­”æ¡ˆæ˜¯ä»€ä¹ˆï¼ˆä»å›¾åƒè§£æçš„æ–‡æœ¬ä¸­æå–çš„ç­”æ¡ˆè·¨åº¦ï¼‰ã€‚
- en: '[PRE28]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: TensorFlowHide TensorFlow content
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè— TensorFlow å†…å®¹
- en: TFLayoutLMModel
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFLayoutLMModel
- en: '### `class transformers.TFLayoutLMModel`'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFLayoutLMModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1046)'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1046)'
- en: '[PRE29]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)ï¼‰
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare LayoutLM Model transformer outputting raw hidden-states without any
    specific head on top.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸çš„ LayoutLM æ¨¡å‹å˜å‹å™¨è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ï¼Œäº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ª [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„ TF 2.0 Keras æ¨¡å‹ï¼Œå¹¶å‚è€ƒ TF 2.0 æ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers` ä¸­çš„ TensorFlow æ¨¡å‹å’Œå±‚æ¥å—ä¸¤ç§æ ¼å¼çš„è¾“å…¥ï¼š'
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should â€œjust workâ€ for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you donâ€™t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1056)'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    â€” Indices of input sequence tokens in the vocabulary.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length,
    4)`, *optional*) â€” Bounding Boxes of each input sequence tokens. Selected in the
    range `[0, config.max_2d_position_embeddings- 1]`.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-382
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-383
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-386
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-387
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`Numpy array` or `tf.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the self-attention
    modules. Mask values selected in `[0, 1]`:'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-392
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-393
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) â€” Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`training` (`bool`, *optional*, defaults to `False`) â€” Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions)
    or `tuple(tf.Tensor)`'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    â€” Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooler_output` (`tf.Tensor` of shape `(batch_size, hidden_size)`) â€” Last layer
    hidden-state of the first token of the sequence (classification token) further
    processed by a Linear layer and a Tanh activation function. The Linear layer weights
    are trained from the next sentence prediction (classification) objective during
    pretraining.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This output is usually *not* a good summary of the semantic content of the input,
    youâ€™re often better with averaging or pooling the sequence of hidden-states for
    the whole input sequence.
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`past_key_values` (`List[tf.Tensor]`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) â€” List of `tf.Tensor` of length `config.n_layers`,
    with each tensor of shape `(2, batch_size, num_heads, sequence_length, embed_size_per_head)`).'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFLayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel)
    forward method, overrides the `__call__` special method.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: TFLayoutLMForMaskedLM
  id: totrans-417
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFLayoutLMForMaskedLM`'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1136)'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LayoutLM Model with a `language modeling` head on top.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should â€œjust workâ€ for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you donâ€™t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1165)'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Parameters
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    â€” Indices of input sequence tokens in the vocabulary.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length,
    4)`, *optional*) â€” Bounding Boxes of each input sequence tokens. Selected in the
    range `[0, config.max_2d_position_embeddings- 1]`.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-443
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-444
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-447
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-448
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`Numpy array` or `tf.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the self-attention
    modules. Mask values selected in `[0, 1]`:'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-453
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-454
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) â€” Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`training` (`bool`, *optional*, defaults to `False`) â€” Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`tf.Tensor` or `np.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Labels for computing the masked language modeling loss. Indices
    should be in `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens
    with indices set to `-100` are ignored (masked), the loss is only computed for
    the tokens with labels in `[0, ..., config.vocab_size]`'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFMaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFMaskedLMOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFMaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFMaskedLMOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`tf.Tensor` of shape `(n,)`, *optional*, where n is the number of non-masked
    labels, returned when `labels` is provided) â€” Masked language modeling (MLM) loss.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    â€” Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    forward method, overrides the `__call__` special method.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: TFLayoutLMForSequenceClassification
  id: totrans-474
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFLayoutLMForSequenceClassification`'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1268)'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LayoutLM Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output) e.g. for GLUE tasks.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should â€œjust workâ€ for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you donâ€™t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1294)'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Parameters
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    â€” Indices of input sequence tokens in the vocabulary.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-497
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length,
    4)`, *optional*) â€” Bounding Boxes of each input sequence tokens. Selected in the
    range `[0, config.max_2d_position_embeddings- 1]`.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-500
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-501
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-504
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-505
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-506
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-508
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`Numpy array` or `tf.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the self-attention
    modules. Mask values selected in `[0, 1]`:'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-510
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-511
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) â€” Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`training` (`bool`, *optional*, defaults to `False`) â€” Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`tf.Tensor` or `np.ndarray` of shape `(batch_size,)`, *optional*)
    â€” Labels for computing the sequence classification/regression loss. Indices should
    be in `[0, ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression
    loss is computed (Mean-Square loss), If `config.num_labels > 1` a classification
    loss is computed (Cross-Entropy).'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`tf.Tensor` of shape `(batch_size, )`, *optional*, returned when `labels`
    is provided) â€” Classification (or regression if config.num_labels==1) loss.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`) â€” Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-524
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFLayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-530
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: TFLayoutLMForTokenClassification
  id: totrans-531
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFLayoutLMForTokenClassification`'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1398)'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Parameters
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LayoutLM Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should â€œjust workâ€ for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you donâ€™t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1430)'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Parameters
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    â€” Indices of input sequence tokens in the vocabulary.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-553
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-554
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length,
    4)`, *optional*) â€” Bounding Boxes of each input sequence tokens. Selected in the
    range `[0, config.max_2d_position_embeddings- 1]`.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-557
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-558
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-561
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-562
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-563
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-565
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`Numpy array` or `tf.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the self-attention
    modules. Mask values selected in `[0, 1]`:'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-567
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-568
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) â€” Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`training` (`bool`, *optional*, defaults to `False`) â€” Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`tf.Tensor` or `np.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Labels for computing the token classification loss. Indices should
    be in `[0, ..., config.num_labels - 1]`.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFTokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFTokenClassifierOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFTokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFTokenClassifierOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`tf.Tensor` of shape `(n,)`, *optional*, where n is the number of unmasked
    labels, returned when `labels` is provided) â€” Classification loss.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.num_labels)`)
    â€” Classification scores (before SoftMax).'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-581
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-583
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFLayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-587
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: TFLayoutLMForQuestionAnswering
  id: totrans-588
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFLayoutLMForQuestionAnswering`'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1532)'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-591
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Parameters
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LayoutLM Model with a span classification head on top for extractive question-answering
    tasks such as [DocVQA](https://rrc.cvc.uab.es/?ch=17) (a linear layer on top of
    the final hidden-states output to compute `span start logits` and `span end logits`).
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should â€œjust workâ€ for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you donâ€™t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlm/modeling_tf_layoutlm.py#L1562)'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-607
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Parameters
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    â€” Indices of input sequence tokens in the vocabulary.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    and [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    for details.
  id: totrans-610
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-611
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length,
    4)`, *optional*) â€” Bounding Boxes of each input sequence tokens. Selected in the
    range `[0, config.max_2d_position_embeddings- 1]`.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-614
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-615
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-616
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-618
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-619
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-620
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-622
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`Numpy array` or `tf.Tensor` of shape `(num_heads,)` or `(num_layers,
    num_heads)`, *optional*) â€” Mask to nullify selected heads of the self-attention
    modules. Mask values selected in `[0, 1]`:'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-624
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-625
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) â€” Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert `input_ids` indices into associated vectors than the modelâ€™s internal
    embedding lookup matrix.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`training` (`bool`, *optional*, defaults to `False`) â€” Whether or not to use
    the model in training mode (some modules like dropout modules have different behaviors
    between training and evaluation).'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_positions` (`tf.Tensor` or `np.ndarray` of shape `(batch_size,)`, *optional*)
    â€” Labels for position (index) of the start of the labelled span for computing
    the token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_positions` (`tf.Tensor` or `np.ndarray` of shape `(batch_size,)`, *optional*)
    â€” Labels for position (index) of the end of the labelled span for computing the
    token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig))
    and inputs.
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`tf.Tensor` of shape `(batch_size, )`, *optional*, returned when `start_positions`
    and `end_positions` are provided) â€” Total span extraction loss is the sum of a
    Cross-Entropy for the start and end positions.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_logits` (`tf.Tensor` of shape `(batch_size, sequence_length)`) â€” Span-start
    scores (before SoftMax).'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_logits` (`tf.Tensor` of shape `(batch_size, sequence_length)`) â€” Span-end
    scores (before SoftMax).'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-640
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-642
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFLayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-646
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
