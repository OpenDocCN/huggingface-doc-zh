- en: SpeechT5
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SpeechT5
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/speecht5](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/speecht5)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/speecht5](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/speecht5)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The SpeechT5 model was proposed in [SpeechT5: Unified-Modal Encoder-Decoder
    Pre-Training for Spoken Language Processing](https://arxiv.org/abs/2110.07205)
    by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom
    Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'SpeechT5 模型是由 Junyi Ao、Rui Wang、Long Zhou、Chengyi Wang、Shuo Ren、Yu Wu、Shujie
    Liu、Tom Ko、Qing Li、Yu Zhang、Zhihua Wei、Yao Qian、Jinyu Li、Furu Wei 在 [SpeechT5:
    Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing](https://arxiv.org/abs/2110.07205)
    中提出的。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Motivated by the success of T5 (Text-To-Text Transfer Transformer) in pre-trained
    natural language processing models, we propose a unified-modal SpeechT5 framework
    that explores the encoder-decoder pre-training for self-supervised speech/text
    representation learning. The SpeechT5 framework consists of a shared encoder-decoder
    network and six modal-specific (speech/text) pre/post-nets. After preprocessing
    the input speech/text through the pre-nets, the shared encoder-decoder network
    models the sequence-to-sequence transformation, and then the post-nets generate
    the output in the speech/text modality based on the output of the decoder. Leveraging
    large-scale unlabeled speech and text data, we pre-train SpeechT5 to learn a unified-modal
    representation, hoping to improve the modeling capability for both speech and
    text. To align the textual and speech information into this unified semantic space,
    we propose a cross-modal vector quantization approach that randomly mixes up speech/text
    states with latent units as the interface between encoder and decoder. Extensive
    evaluations show the superiority of the proposed SpeechT5 framework on a wide
    variety of spoken language processing tasks, including automatic speech recognition,
    speech synthesis, speech translation, voice conversion, speech enhancement, and
    speaker identification.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 受T5（文本到文本转换变压器）在预训练自然语言处理模型中的成功启发，我们提出了一个统一的 SpeechT5 框架，探索编码器-解码器的预训练，用于自监督语音/文本表示学习。SpeechT5
    框架由一个共享的编码器-解码器网络和六个模态特定的（语音/文本）预/后网络组成。通过预网络对输入的语音/文本进行预处理后，共享的编码器-解码器网络对序列到序列的转换进行建模，然后后网络根据解码器的输出在语音/文本模态中生成输出。利用大规模未标记的语音和文本数据，我们预训练
    SpeechT5 来学习一个统一的模态表示，希望提高对语音和文本的建模能力。为了将文本和语音信息对齐到这个统一的语义空间中，我们提出了一种跨模态向量量化方法，随机混合语音/文本状态和潜在单元作为编码器和解码器之间的接口。广泛的评估显示了所提出的
    SpeechT5 框架在各种口语处理任务上的优越性，包括自动语音识别、语音合成、语音翻译、语音转换、语音增强和说话人识别。
- en: This model was contributed by [Matthijs](https://huggingface.co/Matthijs). The
    original code can be found [here](https://github.com/microsoft/SpeechT5).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由 [Matthijs](https://huggingface.co/Matthijs) 贡献。原始代码可以在 [这里](https://github.com/microsoft/SpeechT5)
    找到。
- en: SpeechT5Config
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5Config
- en: '### `class transformers.SpeechT5Config`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5Config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/configuration_speecht5.py#L37)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/configuration_speecht5.py#L37)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 81) — Vocabulary size of the SpeechT5
    model. Defines the number of different tokens that can be represented by the `inputs_ids`
    passed to the forward method of [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size`（`int`，*可选*，默认为81）— SpeechT5 模型的词汇量。定义了可以由传递给 [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)
    的 `inputs_ids` 表示的不同标记数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimensionality of the
    encoder layers and the pooler layer.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size`（`int`，*可选*，默认为768）— 编码器层和池化层的维度。'
- en: '`encoder_layers` (`int`, *optional*, defaults to 12) — Number of hidden layers
    in the Transformer encoder.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layers`（`int`，*可选*，默认为12）— Transformer 编码器中的隐藏层数。'
- en: '`encoder_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_heads`（`int`，*可选*，默认为12）— Transformer 编码器中每个注意力层的注意力头数。'
- en: '`encoder_ffn_dim` (`int`, *optional*, defaults to 3072) — Dimensionality of
    the “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_ffn_dim`（`int`，*可选*，默认为3072）— Transformer 编码器中“中间”（即前馈）层的维度。'
- en: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.1) — The LayerDrop
    probability for the encoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layerdrop`（`float`，*可选*，默认为0.1）— 编码器的 LayerDrop 概率。有关更多详细信息，请参阅 [LayerDrop
    论文](https://arxiv.org/abs/1909.11556)。'
- en: '`decoder_layers` (`int`, *optional*, defaults to 6) — Number of hidden layers
    in the Transformer decoder.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers`（`int`，*可选*，默认为6）— Transformer 解码器中的隐藏层数。'
- en: '`decoder_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer decoder.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_heads`（`int`，*可选*，默认为12）— Transformer 解码器中每个注意力层的注意力头数。'
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 3072) — Dimensionality of
    the “intermediate” (often named feed-forward) layer in the Transformer decoder.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ffn_dim`（`int`，*可选*，默认为3072）— Transformer 解码器中“中间”（通常称为前馈）层的维度。'
- en: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.1) — The LayerDrop
    probability for the decoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layerdrop`（`float`，*可选*，默认为0.1）— 解码器的 LayerDrop 概率。有关更多详细信息，请参阅 [LayerDrop
    论文](https://arxiv.org/abs/1909.11556)。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`和`"gelu_new"`。'
- en: '`positional_dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for the text position encoding layers.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`positional_dropout` (`float`, *optional*, defaults to 0.1) — 文本位置编码层的dropout概率。'
- en: '`hidden_dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout` (`float`, *optional*, defaults to 0.1) — 嵌入层、编码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.1) — The dropout ratio
    for the attention probabilities.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout` (`float`, *optional*, defaults to 0.1) — 注意力概率的dropout比率。'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.1) — The dropout ratio
    for activations inside the fully connected layer.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout` (`float`, *optional*, defaults to 0.1) — 全连接层内部激活的dropout比率。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-5) — The epsilon used
    by the layer normalization layers.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-5) — 层归一化层使用的epsilon。'
- en: '`scale_embedding` (`bool`, *optional*, defaults to `False`) — Scale embeddings
    by diving by sqrt(d_model).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale_embedding` (`bool`, *optional*, defaults to `False`) — 通过sqrt(d_model)缩放嵌入。'
- en: '`feat_extract_norm` (`str`, *optional*, defaults to `"group"`) — The norm to
    be applied to 1D convolutional layers in the speech encoder pre-net. One of `"group"`
    for group normalization of only the first 1D convolutional layer or `"layer"`
    for layer normalization of all 1D convolutional layers.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feat_extract_norm` (`str`, *optional*, defaults to `"group"`) — 应用于语音编码器预网络中1D卷积层的规范化方式。可以选择`"group"`表示仅对第一个1D卷积层进行组归一化，或者选择`"layer"`表示对所有1D卷积层进行层归一化。'
- en: '`feat_proj_dropout` (`float`, *optional*, defaults to 0.0) — The dropout probability
    for output of the speech encoder pre-net.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feat_proj_dropout` (`float`, *optional*, defaults to 0.0) — 语音编码器预网络输出的dropout概率。'
- en: '`feat_extract_activation` (`str,` optional`, defaults to` “gelu”`) -- The non-linear
    activation function (function or string) in the 1D convolutional layers of the
    feature extractor. If string,` “gelu”`,` “relu”`,` “selu”`and`“gelu_new”` are
    supported.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feat_extract_activation` (`str,` optional`, defaults to` “gelu”`) -- 特征提取器中1D卷积层的非线性激活函数（函数或字符串）。如果是字符串，支持`“gelu”`、`“relu”`、`“selu”`和`“gelu_new”`。'
- en: '`conv_dim` (`Tuple[int]` or `List[int]`, *optional*, defaults to `(512, 512,
    512, 512, 512, 512, 512)`) — A tuple of integers defining the number of input
    and output channels of each 1D convolutional layer in the speech encoder pre-net.
    The length of *conv_dim* defines the number of 1D convolutional layers.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conv_dim` (`Tuple[int]` or `List[int]`, *optional*, defaults to `(512, 512,
    512, 512, 512, 512, 512)`) — 一个整数元组，定义语音编码器预网络中每个1D卷积层的输入和输出通道数。*conv_dim*的长度定义了1D卷积层的数量。'
- en: '`conv_stride` (`Tuple[int]` or `List[int]`, *optional*, defaults to `(5, 2,
    2, 2, 2, 2, 2)`) — A tuple of integers defining the stride of each 1D convolutional
    layer in the speech encoder pre-net. The length of *conv_stride* defines the number
    of convolutional layers and has to match the length of *conv_dim*.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conv_stride` (`Tuple[int]` or `List[int]`, *optional*, defaults to `(5, 2,
    2, 2, 2, 2, 2)`) — 一个整数元组，定义语音编码器预网络中每个1D卷积层的步幅。*conv_stride*的长度定义了卷积层的数量，并且必须与*conv_dim*的长度匹配。'
- en: '`conv_kernel` (`Tuple[int]` or `List[int]`, *optional*, defaults to `(10, 3,
    3, 3, 3, 3, 3)`) — A tuple of integers defining the kernel size of each 1D convolutional
    layer in the speech encoder pre-net. The length of *conv_kernel* defines the number
    of convolutional layers and has to match the length of *conv_dim*.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conv_kernel` (`Tuple[int]` or `List[int]`, *optional*, defaults to `(10, 3,
    3, 3, 3, 3, 3)`) — 一个整数元组，定义语音编码器预网络中每个1D卷积层的内核大小。*conv_kernel*的长度定义了卷积层的数量，并且必须与*conv_dim*的长度匹配。'
- en: '`conv_bias` (`bool`, *optional*, defaults to `False`) — Whether the 1D convolutional
    layers have a bias.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conv_bias` (`bool`, *optional*, defaults to `False`) — 1D卷积层是否具有偏置。'
- en: '`num_conv_pos_embeddings` (`int`, *optional*, defaults to 128) — Number of
    convolutional positional embeddings. Defines the kernel size of 1D convolutional
    positional embeddings layer.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_conv_pos_embeddings` (`int`, *optional*, defaults to 128) — 卷积位置嵌入的数量。定义了1D卷积位置嵌入层的内核大小。'
- en: '`num_conv_pos_embedding_groups` (`int`, *optional*, defaults to 16) — Number
    of groups of 1D convolutional positional embeddings layer.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_conv_pos_embedding_groups` (`int`, *optional*, defaults to 16) — 1D卷积位置嵌入层的组数。'
- en: '`apply_spec_augment` (`bool`, *optional*, defaults to `True`) — Whether to
    apply *SpecAugment* data augmentation to the outputs of the speech encoder pre-net.
    For reference see [SpecAugment: A Simple Data Augmentation Method for Automatic
    Speech Recognition](https://arxiv.org/abs/1904.08779).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apply_spec_augment` (`bool`, *optional*, defaults to `True`) — 是否对语音编码器预网络的输出应用*SpecAugment*数据增强。有关详细信息，请参阅[SpecAugment:
    A Simple Data Augmentation Method for Automatic Speech Recognition](https://arxiv.org/abs/1904.08779)。'
- en: '`mask_time_prob` (`float`, *optional*, defaults to 0.05) — Percentage (between
    0 and 1) of all feature vectors along the time axis which will be masked. The
    masking procecure generates ”mask_time_prob*len(time_axis)/mask_time_length” independent
    masks over the axis. If reasoning from the propability of each feature vector
    to be chosen as the start of the vector span to be masked,* mask_time_prob *should
    be `prob_vector_start*mask_time_length`. Note that overlap may decrease the actual
    percentage of masked vectors. This is only relevant if` apply_spec_augment is
    True`.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_time_prob` (`float`, *optional*, 默认为0.05) — 沿时间轴的所有特征向量中将被掩盖的百分比（介于0和1之间）。掩盖过程在该轴上生成”mask_time_prob*len(time_axis)/mask_time_length”个独立的掩码。如果从每个特征向量被选择为掩盖的向量跨度的起始的概率推理，*mask_time_prob*应该是`prob_vector_start*mask_time_length`。请注意，重叠可能会降低实际掩盖向量的百分比。只有在`apply_spec_augment`为True时才相关。'
- en: '`mask_time_length` (`int`, *optional*, defaults to 10) — Length of vector span
    along the time axis.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_time_length` (`int`, *optional*, 默认为10) — 沿时间轴的向量跨度长度。'
- en: '`mask_time_min_masks` (`int`, *optional*, defaults to 2), — The minimum number
    of masks of length `mask_feature_length` generated along the time axis, each time
    step, irrespectively of `mask_feature_prob`. Only relevant if ”mask_time_prob*len(time_axis)/mask_time_length
    < mask_time_min_masks”'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_time_min_masks` (`int`, *optional*, 默认为2) — 沿时间轴生成的长度为`mask_feature_length`的掩码的最小数量，每个时间步，与`mask_feature_prob`无关。只有在”mask_time_prob*len(time_axis)/mask_time_length
    < mask_time_min_masks”时才相关。'
- en: '`mask_feature_prob` (`float`, *optional*, defaults to 0.0) — Percentage (between
    0 and 1) of all feature vectors along the feature axis which will be masked. The
    masking procecure generates ”mask_feature_prob*len(feature_axis)/mask_time_length”
    independent masks over the axis. If reasoning from the propability of each feature
    vector to be chosen as the start of the vector span to be masked,* mask_feature_prob
    *should be `prob_vector_start*mask_feature_length`. Note that overlap may decrease
    the actual percentage of masked vectors. This is only relevant if` apply_spec_augment
    is True`.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_feature_prob` (`float`, *optional*, 默认为0.0) — 沿特征轴的所有特征向量中将被掩盖的百分比（介于0和1之间）。掩盖过程在该轴上生成”mask_feature_prob*len(feature_axis)/mask_time_length”个独立的掩码。如果从每个特征向量被选择为掩盖的向量跨度的起始的概率推理，*mask_feature_prob*应该是`prob_vector_start*mask_feature_length`。请注意，重叠可能会降低实际掩盖向量的百分比。只有在`apply_spec_augment`为True时才相关。'
- en: '`mask_feature_length` (`int`, *optional*, defaults to 10) — Length of vector
    span along the feature axis.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_feature_length` (`int`, *optional*, 默认为10) — 沿特征轴的向量跨度长度。'
- en: '`mask_feature_min_masks` (`int`, *optional*, defaults to 0), — The minimum
    number of masks of length `mask_feature_length` generated along the feature axis,
    each time step, irrespectively of `mask_feature_prob`. Only relevant if ”mask_feature_prob*len(feature_axis)/mask_feature_length
    < mask_feature_min_masks”'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_feature_min_masks` (`int`, *optional*, 默认为0) — 沿特征轴生成的长度为`mask_feature_length`的掩码的最小数量，每个时间步，与`mask_feature_prob`无关。只有在”mask_feature_prob*len(feature_axis)/mask_feature_length
    < mask_feature_min_masks”时才相关。'
- en: '`num_mel_bins` (`int`, *optional*, defaults to 80) — Number of mel features
    used per input features. Used by the speech decoder pre-net. Should correspond
    to the value used in the [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)
    class.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_mel_bins` (`int`, *optional*, 默认为80) — 每个输入特征中使用的梅尔特征数量。由语音解码器预网络使用。应与[SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)类中使用的值对应。'
- en: '`speech_decoder_prenet_layers` (`int`, *optional*, defaults to 2) — Number
    of layers in the speech decoder pre-net.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_decoder_prenet_layers` (`int`, *optional*, 默认为2) — 语音解码器预网络中的层数。'
- en: '`speech_decoder_prenet_units` (`int`, *optional*, defaults to 256) — Dimensionality
    of the layers in the speech decoder pre-net.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_decoder_prenet_units` (`int`, *optional*, 默认为256) — 语音解码器预网络中层的维度。'
- en: '`speech_decoder_prenet_dropout` (`float`, *optional*, defaults to 0.5) — The
    dropout probability for the speech decoder pre-net layers.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_decoder_prenet_dropout` (`float`, *optional*, 默认为0.5) — 语音解码器预网络层的丢失概率。'
- en: '`speaker_embedding_dim` (`int`, *optional*, defaults to 512) — Dimensionality
    of the *XVector* embedding vectors.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embedding_dim` (`int`, *optional*, 默认为512) — *XVector*嵌入向量的维度。'
- en: '`speech_decoder_postnet_layers` (`int`, *optional*, defaults to 5) — Number
    of layers in the speech decoder post-net.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_decoder_postnet_layers` (`int`, *optional*, 默认为5) — 语音解码器后置网络中的层数。'
- en: '`speech_decoder_postnet_units` (`int`, *optional*, defaults to 256) — Dimensionality
    of the layers in the speech decoder post-net.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_decoder_postnet_units` (`int`, *optional*, 默认为256) — 语音解码器后置网络中层的维度。'
- en: '`speech_decoder_postnet_kernel` (`int`, *optional*, defaults to 5) — Number
    of convolutional filter channels in the speech decoder post-net.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_decoder_postnet_kernel` (`int`, *optional*, 默认为5) — 语音解码器后置网络中的卷积滤波器通道数。'
- en: '`speech_decoder_postnet_dropout` (`float`, *optional*, defaults to 0.5) — The
    dropout probability for the speech decoder post-net layers.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_decoder_postnet_dropout` (`float`, *optional*, 默认为0.5) — 语音解码器后置网络层的丢失概率。'
- en: '`reduction_factor` (`int`, *optional*, defaults to 2) — Spectrogram length
    reduction factor for the speech decoder inputs.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reduction_factor` (`int`, *optional*, 默认为2) — 用于语音解码器输入的频谱长度缩减因子。'
- en: '`max_speech_positions` (`int`, *optional*, defaults to 4000) — The maximum
    sequence length of speech features that this model might ever be used with.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_speech_positions` (`int`, *optional*, 默认为4000) — 该模型可能用于的语音特征的最大序列长度。'
- en: '`max_text_positions` (`int`, *optional*, defaults to 450) — The maximum sequence
    length of text features that this model might ever be used with.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_text_positions` (`int`, *optional*, 默认为450) — 该模型可能用于的文本特征的最大序列长度。'
- en: '`encoder_max_relative_position` (`int`, *optional*, defaults to 160) — Maximum
    distance for relative position embedding in the encoder.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_max_relative_position` (`int`, *optional*, 默认为160) — 编码器中相对位置嵌入的最大距离。'
- en: '`use_guided_attention_loss` (`bool`, *optional*, defaults to `True`) — Whether
    to apply guided attention loss while training the TTS model.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_guided_attention_loss` (`bool`, *optional*, 默认为`True`) — 在训练TTS模型时是否应用引导注意力损失。'
- en: '`guided_attention_loss_num_heads` (`int`, *optional*, defaults to 2) — Number
    of attention heads the guided attention loss will be applied to. Use -1 to apply
    this loss to all attention heads.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guided_attention_loss_num_heads` (`int`, *optional*, defaults to 2) — 引导注意力损失将应用的注意力头数。使用-1将此损失应用于所有注意力头。'
- en: '`guided_attention_loss_sigma` (`float`, *optional*, defaults to 0.4) — Standard
    deviation for guided attention loss.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guided_attention_loss_sigma` (`float`, *optional*, defaults to 0.4) — 引导注意力损失的标准差。'
- en: '`guided_attention_loss_scale` (`float`, *optional*, defaults to 10.0) — Scaling
    coefficient for guided attention loss (also known as lambda).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guided_attention_loss_scale` (`float`, *optional*, defaults to 10.0) — 引导注意力损失的缩放系数（也称为lambda）。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, defaults to `True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。'
- en: This is the configuration class to store the configuration of a [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model).
    It is used to instantiate a SpeechT5 model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the SpeechT5 [microsoft/speecht5_asr](https://huggingface.co/microsoft/speecht5_asr)
    architecture.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储[SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)的配置。它用于根据指定的参数实例化一个SpeechT5模型，定义模型架构。使用默认值实例化配置将产生类似于SpeechT5
    [microsoft/speecht5_asr](https://huggingface.co/microsoft/speecht5_asr)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: SpeechT5HifiGanConfig
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5HifiGanConfig
- en: '### `class transformers.SpeechT5HifiGanConfig`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5HifiGanConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/configuration_speecht5.py#L350)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/configuration_speecht5.py#L350)'
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model_in_dim` (`int`, *optional*, defaults to 80) — The number of frequency
    bins in the input log-mel spectrogram.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_in_dim` (`int`, *optional*, defaults to 80) — 输入对数梅尔频谱中的频率箱数。'
- en: '`sampling_rate` (`int`, *optional*, defaults to 16000) — The sampling rate
    at which the output audio will be generated, expressed in hertz (Hz).'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`, *optional*, defaults to 16000) — 生成输出音频的采样率，以赫兹（Hz）表示。'
- en: '`upsample_initial_channel` (`int`, *optional*, defaults to 512) — The number
    of input channels into the upsampling network.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upsample_initial_channel` (`int`, *optional*, defaults to 512) — 输入通道数到上采样网络。'
- en: '`upsample_rates` (`Tuple[int]` or `List[int]`, *optional*, defaults to `[4,
    4, 4, 4]`) — A tuple of integers defining the stride of each 1D convolutional
    layer in the upsampling network. The length of *upsample_rates* defines the number
    of convolutional layers and has to match the length of *upsample_kernel_sizes*.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upsample_rates` (`Tuple[int]` or `List[int]`, *optional*, defaults to `[4,
    4, 4, 4]`) — 一个整数元组，定义了上采样网络中每个1D卷积层的步幅。*upsample_rates*的长度定义了卷积层的数量，并且必须与*upsample_kernel_sizes*的长度匹配。'
- en: '`upsample_kernel_sizes` (`Tuple[int]` or `List[int]`, *optional*, defaults
    to `[8, 8, 8, 8]`) — A tuple of integers defining the kernel size of each 1D convolutional
    layer in the upsampling network. The length of *upsample_kernel_sizes* defines
    the number of convolutional layers and has to match the length of *upsample_rates*.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upsample_kernel_sizes` (`Tuple[int]` or `List[int]`, *optional*, defaults
    to `[8, 8, 8, 8]`) — 一个整数元组，定义了上采样网络中每个1D卷积层的内核大小。*upsample_kernel_sizes*的长度定义了卷积层的数量，并且必须与*upsample_rates*的长度匹配。'
- en: '`resblock_kernel_sizes` (`Tuple[int]` or `List[int]`, *optional*, defaults
    to `[3, 7, 11]`) — A tuple of integers defining the kernel sizes of the 1D convolutional
    layers in the multi-receptive field fusion (MRF) module.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resblock_kernel_sizes` (`Tuple[int]` or `List[int]`, *optional*, defaults
    to `[3, 7, 11]`) — 一个整数元组，定义了多接受域融合（MRF）模块中1D卷积层的内核大小。'
- en: '`resblock_dilation_sizes` (`Tuple[Tuple[int]]` or `List[List[int]]`, *optional*,
    defaults to `[[1, 3, 5], [1, 3, 5], [1, 3, 5]]`) — A nested tuple of integers
    defining the dilation rates of the dilated 1D convolutional layers in the multi-receptive
    field fusion (MRF) module.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resblock_dilation_sizes` (`Tuple[Tuple[int]]` or `List[List[int]]`, *optional*,
    defaults to `[[1, 3, 5], [1, 3, 5], [1, 3, 5]]`) — 一个嵌套的整数元组，定义了多接受域融合（MRF）模块中扩张的1D卷积层的扩张率。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.01) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.01) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`leaky_relu_slope` (`float`, *optional*, defaults to 0.1) — The angle of the
    negative slope used by the leaky ReLU activation.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leaky_relu_slope` (`float`, *optional*, defaults to 0.1) — 漏斗ReLU激活使用的负斜率的角度。'
- en: '`normalize_before` (`bool`, *optional*, defaults to `True`) — Whether or not
    to normalize the spectrogram before vocoding using the vocoder’s learned mean
    and variance.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalize_before` (`bool`, *optional*, defaults to `True`) — 是否在使用声码器的学习均值和方差进行声码之前对频谱进行归一化。'
- en: This is the configuration class to store the configuration of a `SpeechT5HifiGanModel`.
    It is used to instantiate a SpeechT5 HiFi-GAN vocoder model according to the specified
    arguments, defining the model architecture. Instantiating a configuration with
    the defaults will yield a similar configuration to that of the SpeechT5 [microsoft/speecht5_hifigan](https://huggingface.co/microsoft/speecht5_hifigan)
    architecture.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储`SpeechT5HifiGanModel`配置的配置类。它用于根据指定的参数实例化一个SpeechT5 HiFi-GAN声码器模型，定义模型架构。使用默认值实例化配置将产生类似于SpeechT5
    [microsoft/speecht5_hifigan](https://huggingface.co/microsoft/speecht5_hifigan)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: SpeechT5Tokenizer
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5Tokenizer
- en: '### `class transformers.SpeechT5Tokenizer`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5Tokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/tokenization_speecht5.py#L48)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/tokenization_speecht5.py#L48)'
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — [SentencePiece](https://github.com/google/sentencepiece)
    file (generally has a *.spm* extension) that contains the vocabulary necessary
    to instantiate a tokenizer.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 包含实例化分词器所需词汇的[SentencePiece](https://github.com/google/sentencepiece)文件（通常具有*.spm*扩展名）。'
- en: '`bos_token` (`str`, *optional*, defaults to `"<s>"`) — The begin of sequence
    token.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str`, *可选*, 默认为`"<s>"`) — 序列开始标记。'
- en: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) — The end of sequence
    token.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token` (`str`, *可选*, 默认为`"</s>"`) — 序列结束标记。'
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *可选*, 默认为`"<unk>"`) — 未知标记。词汇表中没有的标记无法转换为ID，而是设置为此标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *可选*, 默认为`"<pad>"`) — 用于填充的标记，例如在批处理不同长度的序列时。'
- en: '`normalize` (`bool`, *optional*, defaults to `False`) — Whether to convert
    numeric quantities in the text to their spelt-out english counterparts.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalize` (`bool`, *可选*, 默认为`False`) — 是否将文本中的数字量转换为其拼写的英文对应项。'
- en: '`sp_model_kwargs` (`dict`, *optional*) — Will be passed to the `SentencePieceProcessor.__init__()`
    method. The [Python wrapper for SentencePiece](https://github.com/google/sentencepiece/tree/master/python)
    can be used, among other things, to set:'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sp_model_kwargs` (`dict`, *可选*) — 将传递给`SentencePieceProcessor.__init__()`方法。[SentencePiece的Python包装器](https://github.com/google/sentencepiece/tree/master/python)可用于设置：'
- en: '`enable_sampling`: Enable subword regularization.'
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enable_sampling`: 启用子词正则化。'
- en: '`nbest_size`: Sampling parameters for unigram. Invalid for BPE-Dropout.'
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size`: 一元采样的参数。对于BPE-Dropout无效。'
- en: '`nbest_size = {0,1}`: No sampling is performed.'
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size = {0,1}`: 不执行采样。'
- en: '`nbest_size > 1`: samples from the nbest_size results.'
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size > 1`: 从nbest_size结果中进行采样。'
- en: '`nbest_size < 0`: assuming that nbest_size is infinite and samples from the
    all hypothesis (lattice) using forward-filtering-and-backward-sampling algorithm.'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size < 0`: 假设nbest_size为无限，并使用前向过滤和后向采样算法从所有假设（格）中进行采样。'
- en: '`alpha`: Smoothing parameter for unigram sampling, and dropout probability
    of merge operations for BPE-dropout.'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`: 一元采样的平滑参数，以及BPE-dropout的合并操作的丢弃概率。'
- en: '`sp_model` (`SentencePieceProcessor`) — The *SentencePiece* processor that
    is used for every conversion (string, tokens and IDs).'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sp_model` (`SentencePieceProcessor`) — 用于每次转换（字符串、标记和ID）的*SentencePiece*处理器。'
- en: Construct a SpeechT5 tokenizer. Based on [SentencePiece](https://github.com/google/sentencepiece).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个SpeechT5分词器。基于[SentencePiece](https://github.com/google/sentencepiece)。
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此分词器继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '#### `__call__`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2729)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2729)'
- en: '[PRE5]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]`, `List[List[str]]`, *optional*) — The sequence or
    batch of sequences to be encoded. Each sequence can be a string or a list of strings
    (pretokenized string). If the sequences are provided as list of strings (pretokenized),
    you must set `is_split_into_words=True` (to lift the ambiguity with a batch of
    sequences).'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`, `List[str]`, `List[List[str]]`, *可选*) — 要编码的序列或批量序列。每个序列可以是一个字符串或一个字符串列表（预分词字符串）。如果序列以字符串列表（预分词）的形式提供，则必须设置`is_split_into_words=True`（以消除与批量序列的歧义）。'
- en: '`text_pair` (`str`, `List[str]`, `List[List[str]]`, *optional*) — The sequence
    or batch of sequences to be encoded. Each sequence can be a string or a list of
    strings (pretokenized string). If the sequences are provided as list of strings
    (pretokenized), you must set `is_split_into_words=True` (to lift the ambiguity
    with a batch of sequences).'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair` (`str`, `List[str]`, `List[List[str]]`, *可选*) — 要编码的序列或批量序列。每个序列可以是一个字符串或一个字符串列表（预分词字符串）。如果序列以字符串列表（预分词）的形式提供，则必须设置`is_split_into_words=True`（以消除与批量序列的歧义）。'
- en: '`text_target` (`str`, `List[str]`, `List[List[str]]`, *optional*) — The sequence
    or batch of sequences to be encoded as target texts. Each sequence can be a string
    or a list of strings (pretokenized string). If the sequences are provided as list
    of strings (pretokenized), you must set `is_split_into_words=True` (to lift the
    ambiguity with a batch of sequences).'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_target` (`str`, `List[str]`, `List[List[str]]`, *可选*) — 要编码为目标文本的序列或序列批次。每个序列可以是字符串或字符串列表（预分词字符串）。如果将序列提供为字符串列表（预分词），则必须设置`is_split_into_words=True`（以消除与序列批次的歧义）。'
- en: '`text_pair_target` (`str`, `List[str]`, `List[List[str]]`, *optional*) — The
    sequence or batch of sequences to be encoded as target texts. Each sequence can
    be a string or a list of strings (pretokenized string). If the sequences are provided
    as list of strings (pretokenized), you must set `is_split_into_words=True` (to
    lift the ambiguity with a batch of sequences).'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair_target` (`str`, `List[str]`, `List[List[str]]`, *可选*) — 要编码为目标文本的序列或序列批次。每个序列可以是字符串或字符串列表（预分词字符串）。如果将序列提供为字符串列表（预分词），则必须设置`is_split_into_words=True`（以消除与序列批次的歧义）。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to add special tokens when encoding the sequences. This will use the underlying
    `PretrainedTokenizerBase.build_inputs_with_special_tokens` function, which defines
    which tokens are automatically added to the input ids. This is usefull if you
    want to add `bos` or `eos` tokens automatically.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens` (`bool`, *可选*, 默认为 `True`) — 在编码序列时是否添加特殊标记。这将使用底层的`PretrainedTokenizerBase.build_inputs_with_special_tokens`函数，该函数定义了自动添加到输入id的标记。如果要自动添加`bos`或`eos`标记，则这很有用。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding` (`bool`, `str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *可选*, 默认为 `False`) — 激活和控制填充。接受以下值:'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`: 填充到批次中最长的序列（如果只提供了单个序列，则不进行填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 使用参数`max_length`指定的最大长度进行填充，或者如果未提供该参数，则填充到模型的最大可接受输入长度。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）: 无填充（即，可以输出具有不同长度序列的批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`, `str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *可选*, 默认为 `False`) — 激活和控制截断。接受以下值:'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`: 使用参数`max_length`指定的最大长度进行截断，或者如果未提供该参数，则截断到模型的最大可接受输入长度。如果提供了一对序列（或一批序列），则将逐标记截断，从一对序列中最长的序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`: 使用参数`max_length`指定的最大长度进行截断，或者如果未提供该参数，则截断到模型的最大可接受输入长度。如果提供了一对序列（或一批序列），则只会截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`: 使用参数`max_length`指定的最大长度进行截断，或者如果未提供该参数，则截断到模型的最大可接受输入长度。如果提供了一对序列（或一批序列），则只会截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''`（默认）: 无截断（即，可以输出具有大于模型最大可接受输入大小的序列长度的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *可选*) — 控制截断/填充参数使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为`None`，则如果截断/填充参数中的一个需要最大长度，则将使用预定义的模型最大长度。如果模型没有特定的最大输入长度（如XLNet），则将停用截断/填充到最大长度。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride` (`int`, *可选*, 默认为 0) — 如果与`max_length`一起设置为一个数字，则当`return_overflowing_tokens=True`时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。该参数的值定义了重叠标记的数量。'
- en: '`is_split_into_words` (`bool`, *optional*, defaults to `False`) — Whether or
    not the input is already pre-tokenized (e.g., split into words). If set to `True`,
    the tokenizer assumes the input is already split into words (for instance, by
    splitting it on whitespace) which it will tokenize. This is useful for NER or
    token classification.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_split_into_words` (`bool`，*可选*，默认为`False`) — 输入是否已经预分词（例如，已经分成单词）。如果设置为`True`，分词器会假定输入已经分成单词（例如，通过在空格上分割），然后进行分词。这对于NER或标记分类很有用。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. Requires `padding` to be activated. This is
    especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute
    capability `>= 7.5` (Volta).'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`，*可选*) — 如果设置，将填充序列到提供的值的倍数。需要激活`padding`。这对于在具有计算能力`>=
    7.5`（Volta）的NVIDIA硬件上启用Tensor Cores特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*)
    — 如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`：返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`：返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`：返回Numpy `np.ndarray`对象。'
- en: '`return_token_type_ids` (`bool`, *optional*) — Whether to return token type
    IDs. If left to the default, will return the token type IDs according to the specific
    tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_token_type_ids` (`bool`，*可选*） — 是否返回token类型ID。如果保持默认值，将根据特定分词器的默认值返回token类型ID，由`return_outputs`属性定义。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是token类型ID？](../glossary#token-type-ids)'
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific tokenizer’s default, defined by the `return_outputs` attribute.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask` (`bool`，*可选*) — 是否返回注意力掩码。如果保持默认值，将根据特定分词器的默认值返回注意力掩码，由`return_outputs`属性定义。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`return_overflowing_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return overflowing token sequences. If a pair of sequences of input
    ids (or a batch of pairs) is provided with `truncation_strategy = longest_first`
    or `True`, an error is raised instead of returning overflowing tokens.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_overflowing_tokens` (`bool`，*可选*，默认为`False`) — 是否返回溢出的标记序列。如果提供一对输入ID序列（或一批对）并且`truncation_strategy
    = longest_first`或`True`，则会引发错误，而不是返回溢出的标记。'
- en: '`return_special_tokens_mask` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return special tokens mask information.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_special_tokens_mask` (`bool`，*可选*，默认为`False`) — 是否返回特殊标记掩码信息。'
- en: '`return_offsets_mapping` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return `(char_start, char_end)` for each token.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_offsets_mapping` (`bool`，*可选*，默认为`False`) — 是否返回每个标记的`(char_start,
    char_end)`。'
- en: This is only available on fast tokenizers inheriting from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast),
    if using Python’s tokenizer, this method will raise `NotImplementedError`.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这仅适用于继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)的快速分词器，如果使用Python的分词器，此方法将引发`NotImplementedError`。
- en: '`return_length` (`bool`, *optional*, defaults to `False`) — Whether or not
    to return the lengths of the encoded inputs.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_length` (`bool`，*可选*，默认为`False`) — 是否返回编码输入的长度。'
- en: '`verbose` (`bool`, *optional*, defaults to `True`) — Whether or not to print
    more information and warnings. **kwargs — passed to the `self.tokenize()` method'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose` (`bool`，*可选*，默认为`True`) — 是否打印更多信息和警告。**kwargs — 传递给`self.tokenize()`方法'
- en: Returns
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
- en: 'A [BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)
    with the following fields:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '一个带有以下字段的[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)： '
- en: '`input_ids` — List of token ids to be fed to a model.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` — 要提供给模型的标记ID列表。'
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`token_type_ids` — List of token type ids to be fed to a model (when `return_token_type_ids=True`
    or if *“token_type_ids”* is in `self.model_input_names`).'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` — 要提供给模型的token类型ID列表（当`return_token_type_ids=True`或*“token_type_ids”*在`self.model_input_names`中时）。'
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是token类型ID？](../glossary#token-type-ids)'
- en: '`attention_mask` — List of indices specifying which tokens should be attended
    to by the model (when `return_attention_mask=True` or if *“attention_mask”* is
    in `self.model_input_names`).'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` — 指定哪些标记应该被模型关注的索引列表（当`return_attention_mask=True`或*“attention_mask”*在`self.model_input_names`中时）。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`overflowing_tokens` — List of overflowing tokens sequences (when a `max_length`
    is specified and `return_overflowing_tokens=True`).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overflowing_tokens` — 溢出标记序列的列表（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`num_truncated_tokens` — Number of tokens truncated (when a `max_length` is
    specified and `return_overflowing_tokens=True`).'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_truncated_tokens` — 截断的标记数量（当指定`max_length`并且`return_overflowing_tokens=True`时）。'
- en: '`special_tokens_mask` — List of 0s and 1s, with 1 specifying added special
    tokens and 0 specifying regular sequence tokens (when `add_special_tokens=True`
    and `return_special_tokens_mask=True`).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`special_tokens_mask` — 由0和1组成的列表，其中1指定添加的特殊标记，0指定常规序列标记（当`add_special_tokens=True`和`return_special_tokens_mask=True`时）。'
- en: '`length` — The length of the inputs (when `return_length=True`)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length` — 输入的长度（当`return_length=True`时）'
- en: Main method to tokenize and prepare for the model one or several sequence(s)
    or one or several pair(s) of sequences.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个或多个序列或一个或多个序列对标记化并准备好传递给模型的主要方法。
- en: '#### `save_vocabulary`'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_vocabulary`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/tokenization_speecht5.py#L220)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/tokenization_speecht5.py#L220)'
- en: '[PRE6]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#### `decode`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3726)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3726)'
- en: '[PRE7]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids` (`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`)
    — List of tokenized input ids. Can be obtained using the `__call__` method.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids` (`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`)
    — 标记化输入id的列表。可以使用`__call__`方法获得。'
- en: '`skip_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove special tokens in the decoding.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens` (`bool`, *optional*, 默认为`False`) — 是否在解码中删除特殊标记。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*) — Whether or not to clean
    up the tokenization spaces. If `None`, will default to `self.clean_up_tokenization_spaces`.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces` (`bool`, *optional*) — 是否清理标记化空格。如果为`None`，将默认为`self.clean_up_tokenization_spaces`。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    underlying model specific decode method.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*optional*） — 将传递给底层模型特定的解码方法。'
- en: Returns
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The decoded sentence.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 解码后的句子。
- en: Converts a sequence of ids in a string, using the tokenizer and vocabulary with
    options to remove special tokens and clean up tokenization spaces.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 使用标记器和词汇表将id序列转换为字符串，具有删除特殊标记和清理标记化空格的选项。
- en: Similar to doing `self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于执行`self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`。
- en: '#### `batch_decode`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3692)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3692)'
- en: '[PRE8]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sequences` (`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`)
    — List of tokenized input ids. Can be obtained using the `__call__` method.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequences` (`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`)
    — 标记化输入id的列表。可以使用`__call__`方法获得。'
- en: '`skip_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove special tokens in the decoding.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens` (`bool`, *optional*, 默认为`False`) — 是否在解码中删除特殊标记。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*) — Whether or not to clean
    up the tokenization spaces. If `None`, will default to `self.clean_up_tokenization_spaces`.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces` (`bool`, *optional*) — 是否清理标记化空格。如果为`None`，将默认为`self.clean_up_tokenization_spaces`。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    underlying model specific decode method.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*optional*） — 将传递给底层模型特定的解码方法。'
- en: Returns
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[str]`'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[str]`'
- en: The list of decoded sentences.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 解码后的句子列表。
- en: Convert a list of lists of token ids into a list of strings by calling decode.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用解码将标记id的列表转换为字符串列表。
- en: SpeechT5FeatureExtractor
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5FeatureExtractor
- en: '### `class transformers.SpeechT5FeatureExtractor`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5FeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/feature_extraction_speecht5.py#L31)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/feature_extraction_speecht5.py#L31)'
- en: '[PRE9]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`feature_size` (`int`, *optional*, defaults to 1) — The feature dimension of
    the extracted features.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_size` (`int`, *optional*, 默认为1) — 提取特征的特征维度。'
- en: '`sampling_rate` (`int`, *optional*, defaults to 16000) — The sampling rate
    at which the audio files should be digitalized expressed in hertz (Hz).'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`, *optional*, 默认为16000) — 音频文件应数字化的采样率，以赫兹（Hz）表示。'
- en: '`padding_value` (`float`, *optional*, defaults to 0.0) — The value that is
    used to fill the padding values.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_value` (`float`, *optional*, 默认为0.0) — 用于填充值的值。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `False`) — Whether or not to
    zero-mean unit-variance normalize the input. Normalizing can help to significantly
    improve the performance for some models.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *optional*, 默认为`False`) — 是否对输入进行零均值单位方差归一化。归一化可以帮助显著提高某些模型的性能。'
- en: '`num_mel_bins` (`int`, *optional*, defaults to 80) — The number of mel-frequency
    bins in the extracted spectrogram features.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_mel_bins` (`int`, *optional*, 默认为80) — 提取的频谱图特征中的mel频率箱数。'
- en: '`hop_length` (`int`, *optional*, defaults to 16) — Number of ms between windows.
    Otherwise referred to as “shift” in many papers.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hop_length` (`int`, *optional*, 默认为16) — 窗口之间的毫秒数。在许多论文中也称为“shift”。'
- en: '`win_length` (`int`, *optional*, defaults to 64) — Number of ms per window.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`win_length` (`int`, *optional*, 默认为64) — 每个窗口的毫秒数。'
- en: '`win_function` (`str`, *optional*, defaults to `"hann_window"`) — Name for
    the window function used for windowing, must be accessible via `torch.{win_function}`'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`win_function` (`str`, *optional*, 默认为`"hann_window"`) — 用于窗口化的窗口函数的名称，必须可以通过`torch.{win_function}`访问。'
- en: '`frame_signal_scale` (`float`, *optional*, defaults to 1.0) — Constant multiplied
    in creating the frames before applying DFT. This argument is deprecated.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frame_signal_scale` (`float`, *optional*, 默认为1.0) — 在应用DFT之前创建帧时乘以的常数。此参数已弃用。'
- en: '`fmin` (`float`, *optional*, defaults to 80) — Minimum mel frequency in Hz.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fmin` (`float`, *optional*, 默认为80) — Hz中的最小mel频率。'
- en: '`fmax` (`float`, *optional*, defaults to 7600) — Maximum mel frequency in Hz.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fmax` (`float`, *optional*, 默认为7600) — Hz中的最大mel频率。'
- en: '`mel_floor` (`float`, *optional*, defaults to 1e-10) — Minimum value of mel
    frequency banks.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mel_floor` (`float`, *optional*, 默认为1e-10) — mel频率银行的最小值。'
- en: '`reduction_factor` (`int`, *optional*, defaults to 2) — Spectrogram length
    reduction factor. This argument is deprecated.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reduction_factor` (`int`, *optional*, 默认为2) — 频谱长度缩减因子。此参数已弃用。'
- en: '`return_attention_mask` (`bool`, *optional*, defaults to `True`) — Whether
    or not [`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor.__call__)
    should return `attention_mask`.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask` (`bool`, *可选*, 默认为`True`) — 是否[`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor.__call__)应该返回`attention_mask`。'
- en: Constructs a SpeechT5 feature extractor.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个SpeechT5特征提取器。
- en: This class can pre-process a raw speech signal by (optionally) normalizing to
    zero-mean unit-variance, for use by the SpeechT5 speech encoder prenet.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类可以通过（可选）将原始语音信号归一化为零均值单位方差，供SpeechT5语音编码器prenet使用。
- en: This class can also extract log-mel filter bank features from raw speech, for
    use by the SpeechT5 speech decoder prenet.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类还可以从原始语音中提取log-mel滤波器组特征，供SpeechT5语音解码器prenet使用。
- en: This feature extractor inherits from [SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特征提取器继承自[SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)，其中包含大部分主要方法。用户应参考这个超类以获取有关这些方法的更多信息。
- en: '#### `__call__`'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/feature_extraction_speecht5.py#L180)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/feature_extraction_speecht5.py#L180)'
- en: '[PRE10]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`audio` (`np.ndarray`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`,
    *optional*) — The sequence or batch of sequences to be processed. Each sequence
    can be a numpy array, a list of float values, a list of numpy arrays or a list
    of list of float values. This outputs waveform features. Must be mono channel
    audio, not stereo, i.e. single float per timestep.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio` (`np.ndarray`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`,
    *可选*) — 要处理的序列或批次。每个序列可以是一个numpy数组，一个浮点值列表，一个numpy数组列表或一个浮点值列表的列表。这将输出波形特征。必须是单声道音频，不是立体声，即每个时间步长一个浮点数。'
- en: '`audio_target` (`np.ndarray`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`,
    *optional*) — The sequence or batch of sequences to be processed as targets. Each
    sequence can be a numpy array, a list of float values, a list of numpy arrays
    or a list of list of float values. This outputs log-mel spectrogram features.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio_target` (`np.ndarray`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`,
    *可选*) — 要处理为目标的序列或批次。每个序列可以是一个numpy数组，一个浮点值列表，一个numpy数组列表或一个浮点值列表的列表。这将输出log-mel频谱特征。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Select a strategy to pad the returned sequences
    (according to the model’s padding side and padding index) among:'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding` (`bool`, `str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *可选*, 默认为`False`) — 在以下选项中选择一种策略来填充返回的序列（根据模型的填充方向和填充索引）：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`: 填充到批次中最长的序列（如果只提供一个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 使用参数`max_length`指定的最大长度进行填充，或者如果未提供该参数，则使用模型可接受的最大输入长度进行填充。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''` (默认): 不填充（即，可以输出具有不同长度序列的批次）。'
- en: '`max_length` (`int`, *optional*) — Maximum length of the returned list and
    optionally padding length (see above).'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *可选*) — 返回列表的最大长度和可选填充长度（见上文）。'
- en: '`truncation` (`bool`) — Activates truncation to cut input sequences longer
    than *max_length* to *max_length*.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`) — 激活截断，将输入序列截断为*max_length*长。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *可选*) — 如果设置，将序列填充到提供的值的倍数。'
- en: This is especially useful to enable the use of Tensor Cores on NVIDIA hardware
    with compute capability `>= 7.5` (Volta), or on TPUs which benefit from having
    sequence lengths be a multiple of 128.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这对于启用NVIDIA硬件上的Tensor Cores特别有用，其计算能力为`>= 7.5`（Volta），或者对于受益于序列长度为128的倍数的TPUs。
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific feature_extractor’s default.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask` (`bool`, *可选*) — 是否返回注意力掩码。如果保持默认设置，将根据特定的feature_extractor的默认设置返回注意力掩码。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *可选*) — 如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回Numpy `np.ndarray`对象。'
- en: '`sampling_rate` (`int`, *optional*) — The sampling rate at which the `audio`
    or `audio_target` input was sampled. It is strongly recommended to pass `sampling_rate`
    at the forward call to prevent silent errors.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate` (`int`, *可选*) — `audio`或`audio_target`输入的采样率。强烈建议在前向调用时传递`sampling_rate`以防止潜在错误。'
- en: Main method to featurize and prepare for the model one or several sequence(s).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 对一个或多个序列进行特征化和为模型准备的主要方法。
- en: Pass in a value for `audio` to extract waveform features. Pass in a value for
    `audio_target` to extract log-mel spectrogram features.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 传入一个值给`audio`以提取波形特征。传入一个值给`audio_target`以提取log-mel频谱特征。
- en: SpeechT5Processor
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5Processor
- en: '### `class transformers.SpeechT5Processor`'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5Processor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L20)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L20)'
- en: '[PRE11]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`feature_extractor` (`SpeechT5FeatureExtractor`) — An instance of [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor).
    The feature extractor is a required input.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor`（`SpeechT5FeatureExtractor`）- [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor)的实例。特征提取器是必需的输入。'
- en: '`tokenizer` (`SpeechT5Tokenizer`) — An instance of [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer).
    The tokenizer is a required input.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（`SpeechT5Tokenizer`）- [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer)的实例。分词器是必需的输入。'
- en: Constructs a SpeechT5 processor which wraps a feature extractor and a tokenizer
    into a single processor.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个SpeechT5处理器，将特征提取器和分词器包装成一个单一的处理器。
- en: '[SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)
    offers all the functionalities of [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor)
    and [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer).
    See the docstring of [**call**()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)
    and [decode()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.decode)
    for more information.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '[SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)提供了[SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor)和[SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer)的所有功能。有关更多信息，请参阅[**call**()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)和[decode()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.decode)的文档字符串。'
- en: '#### `__call__`'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L40)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L40)'
- en: '[PRE12]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Processes audio and text input, as well as audio and text targets.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 处理音频和文本输入，以及音频和文本目标。
- en: You can process audio by using the argument `audio`, or process audio targets
    by using the argument `audio_target`. This forwards the arguments to SpeechT5FeatureExtractor’s
    [**call**()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor.__call__).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用参数`audio`处理音频，或者使用参数`audio_target`处理音频目标。这将参数转发到SpeechT5FeatureExtractor的[**call**()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor.__call__)。
- en: You can process text by using the argument `text`, or process text labels by
    using the argument `text_target`. This forwards the arguments to SpeechT5Tokenizer’s
    [**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用参数`text`处理文本，或者使用参数`text_target`处理文本标签。这将参数转发到SpeechT5Tokenizer的[**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: 'Valid input combinations are:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的输入组合是：
- en: '`text` only'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅`text`
- en: '`audio` only'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅`audio`
- en: '`text_target` only'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅`text_target`
- en: '`audio_target` only'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅`audio_target`
- en: '`text` and `audio_target`'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`和`audio_target`'
- en: '`audio` and `audio_target`'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio`和`audio_target`'
- en: '`text` and `text_target`'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`和`text_target`'
- en: '`audio` and `text_target`'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio`和`text_target`'
- en: Please refer to the docstring of the above two methods for more information.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，请参阅上述两种方法的文档字符串。
- en: '#### `pad`'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `pad`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L111)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L111)'
- en: '[PRE13]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Collates the audio and text inputs, as well as their targets, into a padded
    batch.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 将音频和文本输入以及它们的目标整合到填充的批次中。
- en: Audio inputs are padded by SpeechT5FeatureExtractor’s [pad()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor.pad).
    Text inputs are padded by SpeechT5Tokenizer’s [pad()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.pad).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 音频输入由SpeechT5FeatureExtractor的[pad()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor.pad)进行填充。文本输入由SpeechT5Tokenizer的[pad()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.pad)进行填充。
- en: 'Valid input combinations are:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的输入组合是：
- en: '`input_ids` only'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅`input_ids`
- en: '`input_values` only'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅`input_values`
- en: '`labels` only, either log-mel spectrograms or text tokens'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅`labels`，可以是log-mel频谱图或文本标记
- en: '`input_ids` and log-mel spectrogram `labels`'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`和log-mel频谱`labels`'
- en: '`input_values` and text `labels`'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_values`和文本`labels`'
- en: Please refer to the docstring of the above two methods for more information.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，请参阅上述两种方法的文档字符串。
- en: '#### `from_pretrained`'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
- en: '[PRE14]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）- 这可以是：'
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练特征提取器的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: a path to a *directory* containing a feature extractor file saved using the
    [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)方法保存的特征提取器文件，例如，`./my_model_directory/`。
- en: a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
    **kwargs — Additional keyword arguments passed along to both [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)
    and `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`.
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存特征提取器JSON *文件*的路径或url，例如`./my_model_directory/preprocessor_config.json`。**kwargs
    — 传递给[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)和`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`的其他关键字参数。
- en: Instantiate a processor associated with a pretrained model.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化与预训练模型相关联的处理器。
- en: This class method is simply calling the feature extractor [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained),
    image processor [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    and the tokenizer `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`
    methods. Please refer to the docstrings of the methods above for more information.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 此类方法只是调用特征提取器[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)、图像处理器[ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)和标记器`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`方法。有关更多信息，请参考上述方法的文档字符串。
- en: '#### `save_pretrained`'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
- en: '[PRE15]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory where the feature extractor
    JSON file and the tokenizer files will be saved (directory will be created if
    it does not exist).'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory` (`str`或`os.PathLike`) — 特征提取器JSON文件和标记器文件将保存在的目录（如果目录不存在，则将创建该目录）。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub` (`bool`, *可选*, 默认为`False`) — 在保存模型后是否将其推送到Hugging Face模型中心。您可以使用`repo_id`指定要推送到的存储库（将默认为您的命名空间中的`save_directory`名称）。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（`Dict[str, Any]`，*可选*） — 传递给[push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)方法的其他关键字参数。'
- en: Saves the attributes of this processor (feature extractor, tokenizer…) in the
    specified directory so that it can be reloaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    method.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 将此处理器的属性（特征提取器、标记器等）保存在指定目录中，以便可以使用[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)方法重新加载。
- en: This class method is simply calling [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    and [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained).
    Please refer to the docstrings of the methods above for more information.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 此类方法只是调用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)和[save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)。有关更多信息，请参考上述方法的文档字符串。
- en: '#### `batch_decode`'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L171)'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L171)'
- en: '[PRE16]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This method forwards all its arguments to SpeechT5Tokenizer’s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法将其所有参数转发到SpeechT5Tokenizer的[batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)。有关更多信息，请参考此方法的文档字符串。
- en: '#### `decode`'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L178)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/processing_speecht5.py#L178)'
- en: '[PRE17]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This method forwards all its arguments to SpeechT5Tokenizer’s [decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode).
    Please refer to the docstring of this method for more information.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法将其所有参数转发到SpeechT5Tokenizer的[decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode)。有关更多信息，请参考此方法的文档字符串。
- en: SpeechT5Model
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5Model
- en: '### `class transformers.SpeechT5Model`'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5Model`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2090)'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2090)'
- en: '[PRE18]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)）
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: '`encoder` (`SpeechT5EncoderWithSpeechPrenet` or `SpeechT5EncoderWithTextPrenet`
    or `None`) — The Transformer encoder module that applies the appropiate speech
    or text encoder prenet. If `None`, `SpeechT5EncoderWithoutPrenet` will be used
    and the `input_values` are assumed to be hidden states.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder`（`SpeechT5EncoderWithSpeechPrenet`或`SpeechT5EncoderWithTextPrenet`或`None`）—
    应用适当的语音或文本编码器预网络的Transformer编码器模块。如果为`None`，将使用`SpeechT5EncoderWithoutPrenet`，并假定`input_values`为隐藏状态。'
- en: '`decoder` (`SpeechT5DecoderWithSpeechPrenet` or `SpeechT5DecoderWithTextPrenet`
    or `None`) — The Transformer decoder module that applies the appropiate speech
    or text decoder prenet. If `None`, `SpeechT5DecoderWithoutPrenet` will be used
    and the `decoder_input_values` are assumed to be hidden states.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder`（`SpeechT5DecoderWithSpeechPrenet`或`SpeechT5DecoderWithTextPrenet`或`None`）—
    应用适当的语音或文本解码器预网络的Transformer解码器模块。如果为`None`，将使用`SpeechT5DecoderWithoutPrenet`，并假定`decoder_input_values`为隐藏状态。'
- en: The bare SpeechT5 Encoder-Decoder Model outputting raw hidden-states without
    any specific pre- or post-nets. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的SpeechT5编码器-解码器模型输出原始隐藏状态，没有任何特定的预处理或后处理网络。该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头部等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2136)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2136)'
- en: '[PRE19]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing convolution and attention on padding token
    indices. Mask values selected in `[0, 1]`:'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）—
    用于避免在填充令牌索引上执行卷积和注意力的蒙版。蒙版值选定在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示令牌未被遮蔽，
- en: 0 for tokens that are `masked`.
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示令牌被遮蔽。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力蒙版？](../glossary#attention-mask)'
- en: '`attention_mask` should only be passed if the corresponding processor has `config.return_attention_mask
    == True`. For all models whose processor has `config.return_attention_mask ==
    False`, `attention_mask` should `not` be passed to avoid degraded performance
    when doing batched inference. For such models `input_values` should simply be
    padded with 0 and passed without `attention_mask`. Be aware that these models
    also yield slightly different results depending on whether `input_values` is padded
    or not.'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 只有当相应的处理器具有`config.return_attention_mask == True`时，才应传递`attention_mask`。对于所有处理器具有`config.return_attention_mask
    == False`的模型，应避免在进行批量推断时传递`attention_mask`以避免性能下降。对于这样的模型，`input_values`应简单地填充为0并在不传递`attention_mask`的情况下传递。请注意，这些模型的结果也会因`input_values`是否填充而略有不同。
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_values`.
    Causal mask will also be used by default.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）—
    默认行为：生成一个忽略`decoder_input_values`中填充令牌的张量。默认情况下还将使用因果蒙版。'
- en: If you want to change padding behavior, you should read `SpeechT5Decoder._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，应阅读`SpeechT5Decoder._prepare_decoder_attention_mask`并根据需要进行修改。有关默认策略的更多信息，请参阅[论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`head_mask` (`torch.FloatTensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(encoder_layers, encoder_attention_heads)`的`torch.FloatTensor`，*可选*）—
    用于在编码器中使注意力模块的选定头部失效的蒙版。蒙版值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-321
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`decoder_head_mask` (`torch.FloatTensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.FloatTensor`，*可选*）—
    用于在解码器中使注意力模块的选定头部失效的蒙版。蒙版值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）—
    用于使交叉注意力模块的选定头部失效的蒙版。蒙版值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs`（`tuple(tuple(torch.FloatTensor)`，*可选*）— 元组包括（`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`）`last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*可选*）是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或者`config.use_cache=True`时返回）-
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（请参见`past_key_values`输入）。
- en: 'If `past_key_values` are used, the user can optionally input only the last
    `decoder_input_values` (those that don’t have their past key value states given
    to this model) of shape `(batch_size, 1)` instead of all `decoder_input_values`
    of shape `(batch_size, sequence_length)`. decoder_inputs_embeds (`torch.FloatTensor`
    of shape `(batch_size, target_sequence_length, hidden_size)`, *optional*): Optionally,
    instead of passing `decoder_input_values` you can choose to directly pass an embedded
    representation. If `past_key_values` is used, optionally only the last `decoder_inputs_embeds`
    have to be input (see `past_key_values`). This is useful if you want more control
    over how to convert `decoder_input_values` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择只输入最后一个`decoder_input_values`（那些没有将它们的过去键值状态提供给该模型的）的形状为`(batch_size,
    1)`，而不是形状为`(batch_size, sequence_length)`的所有`decoder_input_values`。decoder_inputs_embeds（形状为`(batch_size,
    target_sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）：可选地，可以直接传递嵌入表示，而不是传递`decoder_input_values`。如果使用`past_key_values`，可选择只输入最后一个`decoder_inputs_embeds`（参见`past_key_values`）。如果您想要更多控制如何将`decoder_input_values`索引转换为相关向量，而不是模型的内部嵌入查找矩阵，则这很有用。
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*）- 如果设置为`True`，将返回`past_key_values`键值状态，并可用于加速解码（请参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）- 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）- 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）- 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`input_values` (`torch.Tensor` of shape `(batch_size, sequence_length)`) —
    Depending on which encoder is being used, the `input_values` are either: float
    values of the input raw speech waveform, or indices of input sequence tokens in
    the vocabulary, or hidden states.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_values`（形状为`(batch_size, sequence_length)`的`torch.Tensor`）- 根据使用的编码器，`input_values`可以是：输入原始语音波形的浮点值，或者词汇表中输入序列标记的索引，或者隐藏状态。'
- en: '`decoder_input_values` (`torch.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Depending on which decoder is being used, the `decoder_input_values`
    are either: float values of log-mel filterbank features extracted from the raw
    speech waveform, or indices of decoder input sequence tokens in the vocabulary,
    or hidden states.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_values`（形状为`(batch_size, target_sequence_length)`的`torch.Tensor`，*可选*）-
    根据使用的解码器，`decoder_input_values`可以是：从原始语音波形中提取的对数梅尔滤波器特征的浮点值，或者词汇表中解码器输入序列标记的索引，或者隐藏状态。'
- en: '`speaker_embeddings` (`torch.FloatTensor` of shape `(batch_size, config.speaker_embedding_dim)`,
    *optional*) — Tensor containing the speaker embeddings.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embeddings`（形状为`(batch_size, config.speaker_embedding_dim)`的`torch.FloatTensor`，*可选*）-
    包含说话者嵌入的张量。'
- en: Returns
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config))
    and inputs.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)或者一个`torch.FloatTensor`的元组（如果传递了`return_dict=False`或者`config.return_dict=False`时）包括不同的元素，取决于配置（[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)）和输入。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`）-
    模型解码器最后一层的隐藏状态序列。'
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，则仅输出形状为`(batch_size, 1, hidden_size)`的序列的最后一个隐藏状态。
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *可选*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出和每一层的输出各一个）。'
- en: Hidden-states of the decoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`,
    *可选*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出和每一层的输出各一个）。'
- en: Hidden-states of the encoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *可选*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)
    forward method, overrides the `__call__` special method.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '[SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行前后处理步骤，而后者会默默地忽略它们。
- en: SpeechT5ForSpeechToText
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5ForSpeechToText
- en: '### `class transformers.SpeechT5ForSpeechToText`'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5ForSpeechToText`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2238)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2238)'
- en: '[PRE20]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: SpeechT5 Model with a speech encoder and a text decoder. This model inherits
    from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: SpeechT5 模型具有语音编码器和文本解码器。该模型继承自 [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为其所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还是一个 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取与一般使用和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2284)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2284)'
- en: '[PRE21]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing convolution and attention on padding token
    indices. Mask values selected in `[0, 1]`:'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 避免在填充标记索引上执行卷积和注意力的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 for tokens that are `not masked`,
  id: totrans-372
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示未被 `masked` 的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-373
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示被 `masked` 的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`attention_mask` should only be passed if the corresponding processor has `config.return_attention_mask
    == True`. For all models whose processor has `config.return_attention_mask ==
    False`, `attention_mask` should `not` be passed to avoid degraded performance
    when doing batched inference. For such models `input_values` should simply be
    padded with 0 and passed without `attention_mask`. Be aware that these models
    also yield slightly different results depending on whether `input_values` is padded
    or not.'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 只有当相应的处理器具有 `config.return_attention_mask == True` 时才应传递 `attention_mask`。对于所有处理器具有
    `config.return_attention_mask == False` 的模型，应避免传递 `attention_mask` 以避免在进行批量推理时性能下降。对于这样的模型，`input_values`
    应该简单地用 0 填充并在不传递 `attention_mask` 的情况下传递。请注意，这些模型根据 `input_values` 是否填充也会产生略有不同的结果。
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_values`.
    Causal mask will also be used by default.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — 默认行为：生成一个忽略 `decoder_input_values` 中填充标记的张量。默认情况下还将使用因果掩码。'
- en: If you want to change padding behavior, you should read `SpeechT5Decoder._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，应阅读 `SpeechT5Decoder._prepare_decoder_attention_mask` 并根据需要进行修改。有关默认策略的更多信息，请参阅[论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`head_mask` (`torch.FloatTensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — 编码器中注意力模块中选择性头部置零的掩码。掩码值在 `[0, 1]` 中选择。'
- en: 1 indicates the head is `not masked`,
  id: totrans-379
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被 `masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-380
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被 `masked`。
- en: '`decoder_head_mask` (`torch.FloatTensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask` (`torch.FloatTensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — 解码器中注意力模块中选择性头部置零的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-382
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被 `masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-383
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被 `masked`。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — 交叉注意力模块中选择性头部置零的掩码。掩码值在 `[0, 1]` 中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-385
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被 `masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-386
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被 `masked`。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — 元组包括 (`last_hidden_state`,
    *optional*: `hidden_states`, *optional*: `attentions`) `last_hidden_state` 的形状为
    `(batch_size, sequence_length, hidden_size)`，是编码器最后一层的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）-
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（请参阅`past_key_values`输入）。
- en: 'If `past_key_values` are used, the user can optionally input only the last
    `decoder_input_values` (those that don’t have their past key value states given
    to this model) of shape `(batch_size, 1)` instead of all `decoder_input_values`
    of shape `(batch_size, sequence_length)`. decoder_inputs_embeds (`torch.FloatTensor`
    of shape `(batch_size, target_sequence_length, hidden_size)`, *optional*): Optionally,
    instead of passing `decoder_input_values` you can choose to directly pass an embedded
    representation. If `past_key_values` is used, optionally only the last `decoder_inputs_embeds`
    have to be input (see `past_key_values`). This is useful if you want more control
    over how to convert `decoder_input_values` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入最后的`decoder_input_values`（即不将其过去的键值状态提供给此模型的那些）的形状为`(batch_size,
    1)`的张量，而不是形状为`(batch_size, sequence_length)`的所有`decoder_input_values`。`decoder_inputs_embeds`（形状为`(batch_size,
    target_sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）：可选择直接传递嵌入表示，而不是传递`decoder_input_values`。如果使用`past_key_values`，可以选择仅输入最后的`decoder_inputs_embeds`（请参阅`past_key_values`）。如果要更好地控制如何将`decoder_input_values`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*）- 如果设置为`True`，将返回`past_key_values`键值状态，并可用于加速解码（请参阅`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）- 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）- 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）- 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`input_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Float values of input raw speech waveform. Values can be obtained by loading
    a *.flac* or *.wav* audio file into an array of type `List[float]` or a `numpy.ndarray`,
    *e.g.* via the soundfile library (*pip install soundfile*). To prepare the array
    into `input_values`, the [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)
    should be used for padding and conversion into a tensor of type `torch.FloatTensor`.
    See [SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)
    for details.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_values`（形状为`(batch_size, sequence_length)`的`torch.FloatTensor`）- 输入原始语音波形的浮点值。可以通过将*.flac*或*.wav*音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中获得值，例如通过声音文件库（*pip
    install soundfile*）。要准备好将数组转换为`input_values`，应使用[SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)进行填充和转换为`torch.FloatTensor`类型的张量。有关详细信息，请参阅[SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)。'
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）-
    词汇表中解码器输入序列标记的索引。'
- en: Indices can be obtained using [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer)来获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是解码器输入ID？](../glossary#decoder-input-ids)'
- en: SpeechT5 uses the `eos_token_id` as the starting token for `decoder_input_ids`
    generation. If `past_key_values` is used, optionally only the last `decoder_input_ids`
    have to be input (see `past_key_values`).
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SpeechT5使用`eos_token_id`作为`decoder_input_ids`生成的起始标记。如果使用`past_key_values`，可以选择仅输入最后的`decoder_input_ids`（请参阅`past_key_values`）。
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the language modeling loss. Indices should either be in
    `[0, ..., config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with
    indices set to `-100` are ignored (masked), the loss is only computed for the
    tokens with labels in `[0, ..., config.vocab_size]`.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）- 用于计算语言建模损失的标签。索引应该在`[0,
    ..., config.vocab_size]`范围内，或者为-100（请参阅`input_ids`文档字符串）。索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有标签在`[0,
    ..., config.vocab_size]`范围内的标记。'
- en: Label indices can be obtained using [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer)获取标签索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: Returns
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config))
    and inputs.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)）和输入的各种元素。'
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) —
    语言建模损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出和每一层的输出）。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每一层解码器的隐藏状态以及初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每一层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力SoftMax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每一层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器交叉注意力层的注意力权重，在注意力SoftMax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出和每一层的输出）。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器每一层的隐藏状态以及初始嵌入输出。
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText)
    forward method, overrides the `__call__` special method.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '[SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE22]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: SpeechT5ForTextToSpeech
  id: totrans-425
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5ForTextToSpeech
- en: '### `class transformers.SpeechT5ForTextToSpeech`'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5ForTextToSpeech`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2602)'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2602)'
- en: '[PRE24]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: SpeechT5 Model with a text encoder and a speech decoder. This model inherits
    from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 具有文本编码器和语音解码器的SpeechT5模型。该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2635)'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2635)'
- en: '[PRE25]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing convolution and attention on padding token
    indices. Mask values selected in `[0, 1]`:'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）—
    用于避免在填充标记索引上执行卷积和注意力的遮罩。遮罩值选定在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-438
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被遮罩的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-439
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被遮罩的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力遮罩？](../glossary#attention-mask)'
- en: '`attention_mask` should only be passed if the corresponding processor has `config.return_attention_mask
    == True`. For all models whose processor has `config.return_attention_mask ==
    False`, `attention_mask` should `not` be passed to avoid degraded performance
    when doing batched inference. For such models `input_values` should simply be
    padded with 0 and passed without `attention_mask`. Be aware that these models
    also yield slightly different results depending on whether `input_values` is padded
    or not.'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 只有当相应的处理器具有`config.return_attention_mask == True`时，才应传递`attention_mask`。对于所有处理器具有`config.return_attention_mask
    == False`的模型，在进行批量推理时，应避免传递`attention_mask`以避免性能下降。对于这样的模型，`input_values`应简单地用0填充并在不传递`attention_mask`的情况下传递。请注意，这些模型根据`input_values`是否填充，也会产生略有不同的结果。
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_values`.
    Causal mask will also be used by default.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）—
    默认行为：生成一个忽略`decoder_input_values`中填充标记的张量。因果遮罩也将默认使用。'
- en: If you want to change padding behavior, you should read `SpeechT5Decoder._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，应阅读`SpeechT5Decoder._prepare_decoder_attention_mask`并根据需要进行修改。有关默认策略的更多信息，请参见[论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`head_mask` (`torch.FloatTensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(encoder_layers, encoder_attention_heads)`的`torch.FloatTensor`，*可选*）—
    用于在编码器中使注意力模块中的选定头部失效的遮罩。遮罩值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-445
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮罩，
- en: 0 indicates the head is `masked`.
  id: totrans-446
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮罩。
- en: '`decoder_head_mask` (`torch.FloatTensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.FloatTensor`，*可选*）-
    用于使解码器中注意力模块的选定头部失效的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-448
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被“掩盖”，
- en: 0 indicates the head is `masked`.
  id: totrans-449
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被“掩盖”。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）-
    用于使解码器中交叉注意力模块的选定头部失效的掩码。掩码值在`[0, 1]`中选择：'
- en: 1 indicates the head is `not masked`,
  id: totrans-451
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被“掩盖”，
- en: 0 indicates the head is `masked`.
  id: totrans-452
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被“掩盖”。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs`（`tuple(tuple(torch.FloatTensor)`，*可选*）- 元组包括（`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`）`last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*可选*是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）-
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`的元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: 'If `past_key_values` are used, the user can optionally input only the last
    `decoder_input_values` (those that don’t have their past key value states given
    to this model) of shape `(batch_size, 1)` instead of all `decoder_input_values`
    of shape `(batch_size, sequence_length)`. decoder_inputs_embeds (`torch.FloatTensor`
    of shape `(batch_size, target_sequence_length, hidden_size)`, *optional*): Optionally,
    instead of passing `decoder_input_values` you can choose to directly pass an embedded
    representation. If `past_key_values` is used, optionally only the last `decoder_inputs_embeds`
    have to be input (see `past_key_values`). This is useful if you want more control
    over how to convert `decoder_input_values` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入最后的`decoder_input_values`（这些值没有传递给该模型的过去键值状态）的形状为`(batch_size,
    1)`，而不是形状为`(batch_size, sequence_length)`的所有`decoder_input_values`。decoder_inputs_embeds（形状为`(batch_size,
    target_sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）：可选择直接传递嵌入表示，而不是传递`decoder_input_values`。如果使用`past_key_values`，可以选择只输入最后的`decoder_inputs_embeds`（参见`past_key_values`）。如果要更好地控制如何将`decoder_input_values`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*）- 如果设置为`True`，将返回`past_key_values`键值状态，可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）- 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）- 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）- 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）- 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer).
    See [encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer)获取索引。有关详细信息，请参见[encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`decoder_input_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    config.num_mel_bins)`) — Float values of input mel spectrogram.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_values`（形状为`(batch_size, sequence_length, config.num_mel_bins)`的`torch.FloatTensor`）-
    输入梅尔频谱的浮点值。'
- en: SpeechT5 uses an all-zero spectrum as the starting token for `decoder_input_values`
    generation. If `past_key_values` is used, optionally only the last `decoder_input_values`
    have to be input (see `past_key_values`).
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SpeechT5使用全零频谱作为`decoder_input_values`生成的起始令牌。如果使用`past_key_values`，可以选择只输入最后的`decoder_input_values`（参见`past_key_values`）。
- en: '`speaker_embeddings` (`torch.FloatTensor` of shape `(batch_size, config.speaker_embedding_dim)`,
    *optional*) — Tensor containing the speaker embeddings.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embeddings`（形状为`(batch_size, config.speaker_embedding_dim)`的`torch.FloatTensor`，*可选*）-
    包含说话者嵌入的张量。'
- en: '`labels` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_mel_bins)`,
    *optional*) — Float values of target mel spectrogram. Timesteps set to `-100.0`
    are ignored (masked) for the loss computation. Spectrograms can be obtained using
    [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor).
    See [SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)
    for details.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, sequence_length, config.num_mel_bins)`的`torch.FloatTensor`，*可选*）-
    目标梅尔频谱的浮点值。时间步设置为`-100.0`将被忽略（掩码）用于损失计算。可以使用[SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)获取频谱图。有关详细信息，请参阅[SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)。'
- en: Returns
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '[transformers.modeling_outputs.Seq2SeqSpectrogramOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSpectrogramOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqSpectrogramOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSpectrogramOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqSpectrogramOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSpectrogramOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config))
    and inputs.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.Seq2SeqSpectrogramOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSpectrogramOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)）和输入的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Spectrogram generation loss.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回）- 频谱生成损失。'
- en: '`spectrogram` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_bins)`) — The predicted spectrogram.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spectrogram`（形状为`(batch_size, sequence_length, num_bins)`的`torch.FloatTensor`）-
    预测的频谱图。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）-
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器每一层的隐藏状态以及初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）-
    模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层的隐藏状态加上初始嵌入输出。
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions`（*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组，每层一个。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [SpeechT5ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForTextToSpeech)
    forward method, overrides the `__call__` special method.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '[SpeechT5ForTextToSpeech](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForTextToSpeech)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE26]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '#### `generate`'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2755)'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2755)'
- en: '[PRE27]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`） — 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer).
    See [encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-495
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer)获取索引。有关详细信息，请参阅[encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`)
    — Attention mask from the tokenizer, required for batched inference to signal
    to the model where to ignore padded tokens from the input_ids.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`） — 来自分词器的注意力蒙版，用于批量推理，指示模型在哪里忽略输入的填充标记。'
- en: '`speaker_embeddings` (`torch.FloatTensor` of shape `(batch_size, config.speaker_embedding_dim)`,
    *optional*) — Tensor containing the speaker embeddings.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embeddings`（形状为`(batch_size, config.speaker_embedding_dim)`的`torch.FloatTensor`，*可选*）
    — 包含说话者嵌入的张量。'
- en: '`threshold` (`float`, *optional*, defaults to 0.5) — The generated sequence
    ends when the predicted stop token probability exceeds this value.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold`（*可选*，默认为0.5的`float`） — 当预测的停止标记概率超过此值时，生成的序列结束。'
- en: '`minlenratio` (`float`, *optional*, defaults to 0.0) — Used to calculate the
    minimum required length for the output sequence.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minlenratio`（*可选*，默认为0.0的`float`） — 用于计算输出序列的最小所需长度。'
- en: '`maxlenratio` (`float`, *optional*, defaults to 20.0) — Used to calculate the
    maximum allowed length for the output sequence.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxlenratio`（*可选*，默认为20.0的`float`） — 用于计算输出序列的最大允许长度。'
- en: '`vocoder` (`nn.Module`, *optional*) — The vocoder that converts the mel spectrogram
    into a speech waveform. If `None`, the output is the mel spectrogram.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocoder`（*可选*，`nn.Module`） — 将梅尔频谱图转换为语音波形的声码器。如果为`None`，则输出为梅尔频谱图。'
- en: '`output_cross_attentions` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return the attentions tensors of the decoder’s cross-attention layers.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_cross_attentions`（*可选*，默认为`False`的`bool`） — 是否返回解码器的交叉注意力层的注意力张量。'
- en: '`return_output_lengths` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return the concrete spectrogram/waveform lengths.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_output_lengths`（*可选*，默认为`False`的`bool`） — 是否返回具体的频谱/波形长度。'
- en: Returns
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`tuple(torch.FloatTensor)` comprising various elements depending on the inputs'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`元组，包含根据输入不同的元素'
- en: when `return_output_lengths` is False
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当`return_output_lengths`为False时
- en: '`spectrogram` (*optional*, returned when no `vocoder` is provided) `torch.FloatTensor`
    of shape `(output_sequence_length, config.num_mel_bins)` — The predicted log-mel
    spectrogram.'
  id: totrans-508
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spectrogram`（*可选*，当未提供`vocoder`时返回）`torch.FloatTensor`，形状为`(output_sequence_length,
    config.num_mel_bins)` — 预测的对数梅尔频谱图。'
- en: '`waveform` (*optional*, returned when a `vocoder` is provided) `torch.FloatTensor`
    of shape `(num_frames,)` — The predicted speech waveform.'
  id: totrans-509
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`waveform`（*可选*，当提供`vocoder`时返回）`torch.FloatTensor`，形状为`(num_frames,)` — 预测的语音波形。'
- en: '`cross_attentions` (*optional*, returned when `output_cross_attentions` is
    `True`) `torch.FloatTensor` of shape `(config.decoder_layers, config.decoder_attention_heads,
    output_sequence_length, input_sequence_length)` — The outputs of the decoder’s
    cross-attention layers.'
  id: totrans-510
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`（*可选*，当`output_cross_attentions`为`True`时返回）`torch.FloatTensor`，形状为`(config.decoder_layers,
    config.decoder_attention_heads, output_sequence_length, input_sequence_length)`
    — 解码器的交叉注意力层的输出。'
- en: when `return_output_lengths` is True
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当`return_output_lengths`为True时
- en: '`spectrograms` (*optional*, returned when no `vocoder` is provided) `torch.FloatTensor`
    of shape `(batch_size, output_sequence_length, config.num_mel_bins)` — The predicted
    log-mel spectrograms that are padded to the maximum length.'
  id: totrans-512
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spectrograms`（*可选*，当未提供`vocoder`时返回）`torch.FloatTensor`，形状为`(batch_size, output_sequence_length,
    config.num_mel_bins)` — 预测的对数梅尔频谱图，填充到最大长度。'
- en: '`spectrogram_lengths` (*optional*, returned when no `vocoder` is provided)
    `List[Int]` — A list of all the concrete lengths for each spectrogram.'
  id: totrans-513
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spectrogram_lengths`（*可选*，在没有提供`vocoder`时返回）`List[Int]` — 每个频谱图的具体长度的列表。'
- en: '`waveforms` (*optional*, returned when a `vocoder` is provided) `torch.FloatTensor`
    of shape `(batch_size, num_frames)` — The predicted speech waveforms that are
    padded to the maximum length.'
  id: totrans-514
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`waveforms`（*可选*，在提供`vocoder`时返回）`torch.FloatTensor`，形状为`(batch_size, num_frames)`
    — 预测的语音波形，填充到最大长度。'
- en: '`waveform_lengths` (*optional*, returned when a `vocoder` is provided) `List[Int]`
    — A list of all the concrete lengths for each waveform.'
  id: totrans-515
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`waveform_lengths`（*可选*，在提供`vocoder`时返回）`List[Int]` — 每个波形的具体长度的列表。'
- en: '`cross_attentions` (*optional*, returned when `output_cross_attentions` is
    `True`) `torch.FloatTensor` of shape `(batch_size, config.decoder_layers, config.decoder_attention_heads,
    output_sequence_length, input_sequence_length)` — The outputs of the decoder’s
    cross-attention layers.'
  id: totrans-516
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`（*可选*，当`output_cross_attentions`为`True`时返回）`torch.FloatTensor`，形状为`(batch_size,
    config.decoder_layers, config.decoder_attention_heads, output_sequence_length,
    input_sequence_length)` — 解码器的交叉注意力层的输出。'
- en: Converts a sequence of input tokens into a sequence of mel spectrograms, which
    are subsequently turned into a speech waveform using a vocoder.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 将一系列输入标记转换为一系列mel频谱图，随后使用声码器将其转换为语音波形。
- en: SpeechT5ForSpeechToSpeech
  id: totrans-518
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5ForSpeechToSpeech
- en: '### `class transformers.SpeechT5ForSpeechToSpeech`'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5ForSpeechToSpeech`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2944)'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2944)'
- en: '[PRE28]'
  id: totrans-521
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)）—
    包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: SpeechT5 Model with a speech encoder and a speech decoder. This model inherits
    from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 具有语音编码器和语音解码器的SpeechT5模型。该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2974)'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L2974)'
- en: '[PRE29]'
  id: totrans-528
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`attention_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing convolution and attention on padding token
    indices. Mask values selected in `[0, 1]`:'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*）—
    用于避免在填充标记索引上执行卷积和注意力的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-531
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示未被`masked`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-532
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`masked`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`attention_mask` should only be passed if the corresponding processor has `config.return_attention_mask
    == True`. For all models whose processor has `config.return_attention_mask ==
    False`, `attention_mask` should `not` be passed to avoid degraded performance
    when doing batched inference. For such models `input_values` should simply be
    padded with 0 and passed without `attention_mask`. Be aware that these models
    also yield slightly different results depending on whether `input_values` is padded
    or not.'
  id: totrans-534
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 只有在相应的处理器具有`config.return_attention_mask == True`时才应传递`attention_mask`。对于所有处理器具有`config.return_attention_mask
    == False`的模型，应避免传递`attention_mask`以避免在进行批量推断时性能下降。对于这些模型，`input_values`应简单地用0填充并在不传递`attention_mask`的情况下传递。请注意，这些模型还会根据`input_values`是否填充而产生略有不同的结果。
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_values`.
    Causal mask will also be used by default.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（`torch.LongTensor`，形状为`(batch_size, target_sequence_length)`，*可选*）—
    默认行为：生成一个张量，忽略`decoder_input_values`中的填充标记。因果掩码也将默认使用。'
- en: If you want to change padding behavior, you should read `SpeechT5Decoder._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-536
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，您应阅读`SpeechT5Decoder._prepare_decoder_attention_mask`并根据需要进行修改。有关默认策略的更多信息，请参阅[论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`head_mask` (`torch.FloatTensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（`torch.FloatTensor`，形状为`(encoder_layers, encoder_attention_heads)`，*可选*）—
    用于将编码器中注意力模块的选定头部置零的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-538
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-539
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`masked`。
- en: '`decoder_head_mask` (`torch.FloatTensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask` (`torch.FloatTensor`，形状为`(decoder_layers, decoder_attention_heads)`，*可选*）—
    用于使解码器中选择的注意力模块的头部失效的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-541
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-542
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`torch.Tensor`，形状为`(decoder_layers, decoder_attention_heads)`，*可选*）—
    用于使交叉注意力模块中选择的头部失效的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-544
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-545
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`，*可选*）— 元组包含(`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`)
    `last_hidden_state`形状为`(batch_size, sequence_length, hidden_size)`，*可选*）是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）—
    长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-548
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（请参阅`past_key_values`输入）。
- en: 'If `past_key_values` are used, the user can optionally input only the last
    `decoder_input_values` (those that don’t have their past key value states given
    to this model) of shape `(batch_size, 1)` instead of all `decoder_input_values`
    of shape `(batch_size, sequence_length)`. decoder_inputs_embeds (`torch.FloatTensor`
    of shape `(batch_size, target_sequence_length, hidden_size)`, *optional*): Optionally,
    instead of passing `decoder_input_values` you can choose to directly pass an embedded
    representation. If `past_key_values` is used, optionally only the last `decoder_inputs_embeds`
    have to be input (see `past_key_values`). This is useful if you want more control
    over how to convert `decoder_input_values` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入最后一个形状为`(batch_size, 1)`的`decoder_input_values`（那些没有将其过去键值状态提供给此模型的值），而不是形状为`(batch_size,
    sequence_length)`的所有`decoder_input_values`。`decoder_inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size,
    target_sequence_length, hidden_size)`，*可选*）：可选地，您可以选择直接传递嵌入表示，而不是传递`decoder_input_values`。如果使用`past_key_values`，可以选择仅输入最后一个`decoder_inputs_embeds`（请参阅`past_key_values`）。如果您想要更多控制权来将`decoder_input_values`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`，*可选*）— 如果设置为`True`，将返回`past_key_values`键值状态，可用于加速解码（请参阅`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多细节，请参阅返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多细节，请参阅返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`input_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Float values of input raw speech waveform. Values can be obtained by loading
    a *.flac* or *.wav* audio file into an array of type `List[float]` or a `numpy.ndarray`,
    *e.g.* via the soundfile library (*pip install soundfile*). To prepare the array
    into `input_values`, the [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)
    should be used for padding and conversion into a tensor of type `torch.FloatTensor`.
    See [SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)
    for details.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_values` (`torch.FloatTensor`，形状为`(batch_size, sequence_length)`）— 输入原始语音波形的浮点值。可以通过将*.flac*或*.wav*音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中获得值，例如通过soundfile库（*pip
    install soundfile*）。要将数组准备成`input_values`，应使用[SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)进行填充和转换为`torch.FloatTensor`类型的张量。有关详细信息，请参阅[SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)。'
- en: '`decoder_input_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    config.num_mel_bins)`) — Float values of input mel spectrogram.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_values` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    config.num_mel_bins)`）— 输入梅尔频谱图的浮点值。'
- en: SpeechT5 uses an all-zero spectrum as the starting token for `decoder_input_values`
    generation. If `past_key_values` is used, optionally only the last `decoder_input_values`
    have to be input (see `past_key_values`).
  id: totrans-556
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SpeechT5使用全零频谱作为`decoder_input_values`生成的起始标记。如果使用`past_key_values`，可以选择只输入最后的`decoder_input_values`（参见`past_key_values`）。
- en: '`speaker_embeddings` (`torch.FloatTensor` of shape `(batch_size, config.speaker_embedding_dim)`,
    *optional*) — Tensor containing the speaker embeddings.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embeddings` (`torch.FloatTensor`，形状为`(batch_size, config.speaker_embedding_dim)`，*可选*)
    — 包含说话者嵌入的张量。'
- en: '`labels` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_mel_bins)`,
    *optional*) — Float values of target mel spectrogram. Spectrograms can be obtained
    using [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor).
    See [SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)
    for details.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, config.num_mel_bins)`，*可选*)
    — 目标梅尔频谱的浮点值。可以使用[SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)获取频谱图。详细信息请参见[SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)。'
- en: Returns
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.Seq2SeqSpectrogramOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSpectrogramOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqSpectrogramOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSpectrogramOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqSpectrogramOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSpectrogramOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config))
    and inputs.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.Seq2SeqSpectrogramOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSpectrogramOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含各种元素，取决于配置（[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)）和输入。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Spectrogram generation loss.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，在提供`labels`时返回) — 频谱图生成损失。'
- en: '`spectrogram` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_bins)`) — The predicted spectrogram.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spectrogram` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, num_bins)`)
    — 预测的频谱图。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`，*可选*，在传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-565
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（查看`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，在传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出的一个
    + 每一层的输出一个）。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-567
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器每一层输出的隐藏状态加上初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`，*可选*，在传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`，*可选*，在传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-571
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-574
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层输出的隐藏状态以及初始嵌入输出。
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-576
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [SpeechT5ForSpeechToSpeech](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToSpeech)
    forward method, overrides the `__call__` special method.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: '[SpeechT5ForSpeechToSpeech](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToSpeech)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此之后调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE30]'
  id: totrans-580
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '#### `generate_speech`'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate_speech`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L3088)'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L3088)'
- en: '[PRE31]'
  id: totrans-583
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Float values of input raw speech waveform.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_values` (`torch.FloatTensor`，形状为`(batch_size, sequence_length)`) — 输入原始语音波形的浮点值。'
- en: Values can be obtained by loading a *.flac* or *.wav* audio file into an array
    of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile library (*pip
    install soundfile*). To prepare the array into `input_values`, the [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)
    should be used for padding and conversion into a tensor of type `torch.FloatTensor`.
    See [SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)
    for details.
  id: totrans-586
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以通过将*.flac*或*.wav*音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中来获取值，例如通过声音文件库(*pip
    install soundfile*)。要将数组准备成`input_values`，应该使用[SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)进行填充和转换为`torch.FloatTensor`类型的张量。有关详细信息，请参阅[SpeechT5Processor.`call`()](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor.__call__)。
- en: '`speaker_embeddings` (`torch.FloatTensor` of shape `(batch_size, config.speaker_embedding_dim)`,
    *optional*) — Tensor containing the speaker embeddings.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speaker_embeddings` (`torch.FloatTensor`，形状为`(batch_size, config.speaker_embedding_dim)`，*optional*)
    — 包含说话者嵌入的张量。'
- en: '`attention_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing convolution and attention on padding token
    indices. Mask values selected in `[0, 1]`:'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*optional*)
    — 用于避免在填充标记索引上执行卷积和注意力的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-589
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被`masked`的标记，值为1。
- en: 0 for tokens that are `masked`.
  id: totrans-590
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于被`masked`的标记，值为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-591
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`threshold` (`float`, *optional*, defaults to 0.5) — The generated sequence
    ends when the predicted stop token probability exceeds this value.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold` (`float`，*optional*，默认为0.5) — 当预测的停止标记概率超过此值时，生成的序列结束。'
- en: '`minlenratio` (`float`, *optional*, defaults to 0.0) — Used to calculate the
    minimum required length for the output sequence.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minlenratio` (`float`，*optional*，默认为0.0) — 用于计算输出序列的最小所需长度。'
- en: '`maxlenratio` (`float`, *optional*, defaults to 20.0) — Used to calculate the
    maximum allowed length for the output sequence.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxlenratio` (`float`，*optional*，默认为20.0) — 用于计算输出序列的最大允许长度。'
- en: '`vocoder` (`nn.Module`, *optional*, defaults to `None`) — The vocoder that
    converts the mel spectrogram into a speech waveform. If `None`, the output is
    the mel spectrogram.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocoder` (`nn.Module`，*optional*，默认为`None`) — 将梅尔频谱图转换为语音波形的声码器。如果为`None`，则输出为梅尔频谱图。'
- en: '`output_cross_attentions` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return the attentions tensors of the decoder’s cross-attention layers.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_cross_attentions` (`bool`，*optional*，默认为`False`) — 是否返回解码器交叉注意力层的注意力张量。'
- en: '`return_output_lengths` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return the concrete spectrogram/waveform lengths.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_output_lengths` (`bool`，*optional*，默认为`False`) — 是否返回具体的频谱/波形长度。'
- en: Returns
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`tuple(torch.FloatTensor)` comprising various elements depending on the inputs'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 包含各种元素的`tuple(torch.FloatTensor)`，取决于输入
- en: when `return_output_lengths` is False
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当`return_output_lengths`为False时
- en: '`spectrogram` (*optional*, returned when no `vocoder` is provided) `torch.FloatTensor`
    of shape `(output_sequence_length, config.num_mel_bins)` — The predicted log-mel
    spectrogram.'
  id: totrans-601
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spectrogram` (*optional*，当未提供`vocoder`时返回) 形状为`(output_sequence_length, config.num_mel_bins)`的`torch.FloatTensor`
    — 预测的对数梅尔频谱图。'
- en: '`waveform` (*optional*, returned when a `vocoder` is provided) `torch.FloatTensor`
    of shape `(num_frames,)` — The predicted speech waveform.'
  id: totrans-602
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`waveform` (*optional*，当提供`vocoder`时返回) 形状为`(num_frames,)`的`torch.FloatTensor`
    — 预测的语音波形。'
- en: '`cross_attentions` (*optional*, returned when `output_cross_attentions` is
    `True`) `torch.FloatTensor` of shape `(config.decoder_layers, config.decoder_attention_heads,
    output_sequence_length, input_sequence_length)` — The outputs of the decoder’s
    cross-attention layers.'
  id: totrans-603
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (*可选*, 当`output_cross_attentions`为`True`时返回) `torch.FloatTensor`，形状为`(config.decoder_layers,
    config.decoder_attention_heads, output_sequence_length, input_sequence_length)`
    — 解码器交叉注意力层的输出。'
- en: when `return_output_lengths` is True
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当`return_output_lengths`为True时
- en: '`spectrograms` (*optional*, returned when no `vocoder` is provided) `torch.FloatTensor`
    of shape `(batch_size, output_sequence_length, config.num_mel_bins)` — The predicted
    log-mel spectrograms that are padded to the maximum length.'
  id: totrans-605
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spectrograms` (*可选*, 当未提供`vocoder`时返回) `torch.FloatTensor`，形状为`(batch_size,
    output_sequence_length, config.num_mel_bins)` — 预测的对数梅尔频谱图，已填充到最大长度。'
- en: '`spectrogram_lengths` (*optional*, returned when no `vocoder` is provided)
    `List[Int]` — A list of all the concrete lengths for each spectrogram.'
  id: totrans-606
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spectrogram_lengths` (*可选*, 当未提供`vocoder`时返回) `List[Int]` — 每个频谱图的具体长度列表。'
- en: '`waveforms` (*optional*, returned when a `vocoder` is provided) `torch.FloatTensor`
    of shape `(batch_size, num_frames)` — The predicted speech waveforms that are
    padded to the maximum length.'
  id: totrans-607
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`waveforms` (*可选*, 当提供`vocoder`时返回) `torch.FloatTensor`，形状为`(batch_size, num_frames)`
    — 预测的语音波形，已填充到最大长度。'
- en: '`waveform_lengths` (*optional*, returned when a `vocoder` is provided) `List[Int]`
    — A list of all the concrete lengths for each waveform.'
  id: totrans-608
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`waveform_lengths` (*可选*, 当提供`vocoder`时返回) `List[Int]` — 每个波形的具体长度列表。'
- en: '`cross_attentions` (*optional*, returned when `output_cross_attentions` is
    `True`) `torch.FloatTensor` of shape `(batch_size, config.decoder_layers, config.decoder_attention_heads,
    output_sequence_length, input_sequence_length)` — The outputs of the decoder’s
    cross-attention layers.'
  id: totrans-609
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (*可选*, 当`output_cross_attentions`为`True`时返回) `torch.FloatTensor`，形状为`(batch_size,
    config.decoder_layers, config.decoder_attention_heads, output_sequence_length,
    input_sequence_length)` — 解码器交叉注意力层的输出。'
- en: Converts a raw speech waveform into a sequence of mel spectrograms, which are
    subsequently turned back into a speech waveform using a vocoder.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 将原始语音波形转换为一系列梅尔频谱图，随后使用语音合成器将其转换回语音波形。
- en: SpeechT5HifiGan
  id: totrans-611
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpeechT5HifiGan
- en: '### `class transformers.SpeechT5HifiGan`'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.SpeechT5HifiGan`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L3253)'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L3253)'
- en: '[PRE32]'
  id: totrans-614
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([SpeechT5HifiGanConfig](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5HifiGanConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([SpeechT5HifiGanConfig](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5HifiGanConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: HiFi-GAN vocoder. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: HiFi-GAN 语音合成器。该模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库实现的所有模型的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型也是一个 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    子类。将其用作常规的 PyTorch 模块，并参考 PyTorch 文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L3322)'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/speecht5/modeling_speecht5.py#L3322)'
- en: '[PRE33]'
  id: totrans-621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Parameters
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`spectrogram` (`torch.FloatTensor`) — Tensor containing the log-mel spectrograms.
    Can be batched and of shape `(batch_size, sequence_length, config.model_in_dim)`,
    or un-batched and of shape `(sequence_length, config.model_in_dim)`.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spectrogram` (`torch.FloatTensor`) — 包含对数梅尔频谱图的张量。可以是批处理的，形状为`(batch_size,
    sequence_length, config.model_in_dim)`，也可以是未经批处理的，形状为`(sequence_length, config.model_in_dim)`。'
- en: Returns
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.FloatTensor`'
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: Tensor containing the speech waveform. If the input spectrogram is batched,
    will be of shape `(batch_size, num_frames,)`. If un-batched, will be of shape
    `(num_frames,)`.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 包含语音波形的张量。如果输入的频谱图是批处理的，则形状为`(batch_size, num_frames,)`。如果未经批处理，则形状为`(num_frames,)`。
- en: Converts a log-mel spectrogram into a speech waveform. Passing a batch of log-mel
    spectrograms returns a batch of speech waveforms. Passing a single, un-batched
    log-mel spectrogram returns a single, un-batched speech waveform.
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 将对数梅尔频谱图转换为语音波形。传递一批对数梅尔频谱图将返回一批语音波形。传递单个、未经批处理的对数梅尔频谱图将返回单个、未经批处理的语音波形。
