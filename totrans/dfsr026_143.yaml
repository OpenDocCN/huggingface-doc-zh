- en: DiT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/diffusers/api/pipelines/dit](https://huggingface.co/docs/diffusers/api/pipelines/dit)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/47.f118c67b.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Tip.230e2334.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Docstring.93f6f462.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/globals.7f7f1b26.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/ExampleCodeBlock.658f5cd6.js">
  prefs: []
  type: TYPE_NORMAL
- en: '[Scalable Diffusion Models with Transformers](https://huggingface.co/papers/2212.09748)
    (DiT) is by William Peebles and Saining Xie.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is:'
  prefs: []
  type: TYPE_NORMAL
- en: '*We explore a new class of diffusion models based on the transformer architecture.
    We train latent diffusion models of images, replacing the commonly-used U-Net
    backbone with a transformer that operates on latent patches. We analyze the scalability
    of our Diffusion Transformers (DiTs) through the lens of forward pass complexity
    as measured by Gflops. We find that DiTs with higher Gflops — through increased
    transformer depth/width or increased number of input tokens — consistently have
    lower FID. In addition to possessing good scalability properties, our largest
    DiT-XL/2 models outperform all prior diffusion models on the class-conditional
    ImageNet 512x512 and 256x256 benchmarks, achieving a state-of-the-art FID of 2.27
    on the latter.*'
  prefs: []
  type: TYPE_NORMAL
- en: The original codebase can be found at [facebookresearch/dit](https://github.com/facebookresearch/dit).
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to check out the Schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: DiTPipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.DiTPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L31)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`transformer` ([Transformer2DModel](/docs/diffusers/v0.26.3/en/api/models/transformer2d#diffusers.Transformer2DModel))
    — A class conditioned `Transformer2DModel` to denoise the encoded image latents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    — Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — A scheduler to be used in combination with `transformer` to denoise the encoded
    image latents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline for image generation based on a Transformer backbone instead of a UNet.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L92)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`class_labels` (List[int]) — List of ImageNet class labels for the images to
    be generated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator`, *optional*) — A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, *optional*, defaults to 250) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: If `return_dict` is `True`, [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images
  prefs: []
  type: TYPE_NORMAL
- en: The call function to the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#### `get_label_ids`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/dit/pipeline_dit.py#L67)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`label` (`str` or `dict` of `str`) — Label strings to be mapped to class ids.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`list` of `int`'
  prefs: []
  type: TYPE_NORMAL
- en: Class ids to be processed by pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Map label strings from ImageNet to corresponding class ids.
  prefs: []
  type: TYPE_NORMAL
- en: ImagePipelineOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.ImagePipelineOutput`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L116)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) — List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output class for image pipelines.
  prefs: []
  type: TYPE_NORMAL
