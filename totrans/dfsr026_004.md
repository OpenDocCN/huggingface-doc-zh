# æœ‰æ•ˆå’Œé«˜æ•ˆçš„æ‰©æ•£

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/stable_diffusion](https://huggingface.co/docs/diffusers/stable_diffusion)

è®©[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ç”Ÿæˆç‰¹å®šé£æ ¼çš„å›¾åƒæˆ–åŒ…å«æ‚¨æƒ³è¦çš„å†…å®¹å¯èƒ½æœ‰äº›æ£˜æ‰‹ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæ‚¨å¿…é¡»å¤šæ¬¡è¿è¡Œ[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)æ‰èƒ½å¾—åˆ°æ»¡æ„çš„å›¾åƒã€‚ä½†æ˜¯ä»æ— åˆ°æœ‰åœ°ç”Ÿæˆä¸œè¥¿æ˜¯ä¸€ä¸ªè®¡ç®—å¯†é›†å‹çš„è¿‡ç¨‹ï¼Œç‰¹åˆ«æ˜¯å¦‚æœæ‚¨ä¸€éåˆä¸€éåœ°è¿è¡Œæ¨ç†ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä»ç®¡é“ä¸­è·å¾—æœ€é«˜çš„*è®¡ç®—*ï¼ˆé€Ÿåº¦ï¼‰å’Œ*å†…å­˜*ï¼ˆGPU vRAMï¼‰æ•ˆç‡éå¸¸é‡è¦ï¼Œä»¥å‡å°‘æ¨ç†å‘¨æœŸä¹‹é—´çš„æ—¶é—´ï¼Œä½¿æ‚¨å¯ä»¥æ›´å¿«åœ°è¿­ä»£ã€‚

æœ¬æ•™ç¨‹å°†æŒ‡å¯¼æ‚¨å¦‚ä½•ä½¿ç”¨[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)æ›´å¿«æ›´å¥½åœ°ç”Ÿæˆã€‚

é¦–å…ˆåŠ è½½[`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5)æ¨¡å‹ï¼š

```py
from diffusers import DiffusionPipeline

model_id = "runwayml/stable-diffusion-v1-5"
pipeline = DiffusionPipeline.from_pretrained(model_id, use_safetensors=True)
```

æ‚¨å°†ä½¿ç”¨çš„ç¤ºä¾‹æç¤ºæ˜¯ä¸€ä½è€æˆ˜å£«é¦–é¢†çš„è‚–åƒï¼Œä½†è¯·éšæ„ä½¿ç”¨æ‚¨è‡ªå·±çš„æç¤ºï¼š

```py
prompt = "portrait photo of a old warrior chief"
```

## é€Ÿåº¦

ğŸ’¡ å¦‚æœæ‚¨æ²¡æœ‰GPUè®¿é—®æƒé™ï¼Œæ‚¨å¯ä»¥å…è´¹ä½¿ç”¨GPUæä¾›å•†ï¼ˆå¦‚[Colab](https://colab.research.google.com/)ï¼‰çš„GPUï¼

åŠ å¿«æ¨ç†çš„æœ€ç®€å•æ–¹æ³•ä¹‹ä¸€æ˜¯å°†ç®¡é“æ”¾åœ¨GPUä¸Šï¼Œå°±åƒæ‚¨å¯¹ä»»ä½•PyTorchæ¨¡å—æ‰€åšçš„é‚£æ ·ï¼š

```py
pipeline = pipeline.to("cuda")
```

ä¸ºäº†ç¡®ä¿æ‚¨å¯ä»¥ä½¿ç”¨ç›¸åŒçš„å›¾åƒå¹¶å¯¹å…¶è¿›è¡Œæ”¹è¿›ï¼Œè¯·ä½¿ç”¨[`Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)å¹¶ä¸º[å¯é‡ç°æ€§](./using-diffusers/reproducibility)è®¾ç½®ä¸€ä¸ªç§å­ï¼š

```py
import torch

generator = torch.Generator("cuda").manual_seed(0)
```

ç°åœ¨æ‚¨å¯ä»¥ç”Ÿæˆå›¾åƒï¼š

```py
image = pipeline(prompt, generator=generator).images[0]
image
```

![](../Images/97b4b76d7c052f96d96b7a8b402a25ce.png)

è¿™ä¸ªè¿‡ç¨‹åœ¨T4 GPUä¸ŠèŠ±è´¹äº†~30ç§’ï¼ˆå¦‚æœæ‚¨åˆ†é…çš„GPUæ¯”T4æ›´å¥½ï¼Œåˆ™å¯èƒ½ä¼šæ›´å¿«ï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ä»¥å®Œæ•´çš„`float32`ç²¾åº¦è¿è¡Œ50ä¸ªæ¨ç†æ­¥éª¤ã€‚æ‚¨å¯ä»¥é€šè¿‡åˆ‡æ¢åˆ°è¾ƒä½ç²¾åº¦ï¼ˆå¦‚`float16`ï¼‰æˆ–å‡å°‘æ¨ç†æ­¥éª¤æ¥åŠ å¿«é€Ÿåº¦ã€‚

è®©æˆ‘ä»¬ä»åœ¨`float16`ä¸­åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆå›¾åƒå¼€å§‹ï¼š

```py
import torch

pipeline = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_safetensors=True)
pipeline = pipeline.to("cuda")
generator = torch.Generator("cuda").manual_seed(0)
image = pipeline(prompt, generator=generator).images[0]
image
```

![](../Images/66880d2cc1c9bb78b8e03483b16d1ca3.png)

è¿™æ¬¡ï¼Œç”Ÿæˆå›¾åƒä»…èŠ±è´¹äº†~11ç§’ï¼Œæ¯”ä»¥å‰å¿«äº†è¿‘3å€ï¼

ğŸ’¡ æˆ‘ä»¬å¼ºçƒˆå»ºè®®å§‹ç»ˆåœ¨`float16`ä¸­è¿è¡Œæ‚¨çš„ç®¡é“ï¼Œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¾ˆå°‘çœ‹åˆ°è¾“å‡ºè´¨é‡ä¸‹é™ã€‚

å¦ä¸€ä¸ªé€‰é¡¹æ˜¯å‡å°‘æ¨ç†æ­¥éª¤çš„æ•°é‡ã€‚é€‰æ‹©æ›´é«˜æ•ˆçš„è°ƒåº¦å™¨å¯ä»¥å¸®åŠ©å‡å°‘æ­¥éª¤æ•°é‡ï¼Œè€Œä¸ä¼šç‰ºç‰²è¾“å‡ºè´¨é‡ã€‚æ‚¨å¯ä»¥é€šè¿‡è°ƒç”¨`compatibles`æ–¹æ³•åœ¨[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ä¸­æ‰¾åˆ°ä¸å½“å‰æ¨¡å‹å…¼å®¹çš„è°ƒåº¦å™¨ï¼š

```py
pipeline.scheduler.compatibles
[
    diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler,
    diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler,
    diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler,
    diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler,
    diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler,
    diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler,
    diffusers.schedulers.scheduling_ddpm.DDPMScheduler,
    diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler,
    diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler,
    diffusers.utils.dummy_torch_and_torchsde_objects.DPMSolverSDEScheduler,
    diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler,
    diffusers.schedulers.scheduling_pndm.PNDMScheduler,
    diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler,
    diffusers.schedulers.scheduling_ddim.DDIMScheduler,
]
```

ç¨³å®šçš„æ‰©æ•£æ¨¡å‹é»˜è®¤ä½¿ç”¨[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ï¼Œé€šå¸¸éœ€è¦~50ä¸ªæ¨ç†æ­¥éª¤ï¼Œä½†æ€§èƒ½æ›´å¥½çš„è°ƒåº¦å™¨å¦‚[DPMSolverMultistepScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler)ï¼Œåªéœ€è¦~20æˆ–25ä¸ªæ¨ç†æ­¥éª¤ã€‚ä½¿ç”¨[from_config()](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin.from_config)æ–¹æ³•åŠ è½½æ–°çš„è°ƒåº¦å™¨ï¼š

```py
from diffusers import DPMSolverMultistepScheduler

pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)
```

ç°åœ¨å°†`num_inference_steps`è®¾ç½®ä¸º20ï¼š

```py
generator = torch.Generator("cuda").manual_seed(0)
image = pipeline(prompt, generator=generator, num_inference_steps=20).images[0]
image
```

![](../Images/a0e3931ebf91a12e3caef2d780586fec.png)

å¾ˆå¥½ï¼Œæ‚¨å·²ç»æˆåŠŸå°†æ¨ç†æ—¶é—´ç¼©çŸ­åˆ°ä»…ä¸º4ç§’ï¼âš¡ï¸

## å†…å­˜

æ”¹è¿›ç®¡é“æ€§èƒ½çš„å¦ä¸€ä¸ªå…³é”®æ˜¯æ¶ˆè€—æ›´å°‘çš„å†…å­˜ï¼Œè¿™é—´æ¥æ„å‘³ç€æ›´å¿«çš„é€Ÿåº¦ï¼Œå› ä¸ºæ‚¨é€šå¸¸è¯•å›¾æœ€å¤§åŒ–æ¯ç§’ç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚æŸ¥çœ‹æ‚¨å¯ä»¥ä¸€æ¬¡ç”Ÿæˆå¤šå°‘å›¾åƒçš„æœ€ç®€å•æ–¹æ³•æ˜¯å°è¯•ä¸åŒçš„æ‰¹å¤„ç†å¤§å°ï¼Œç›´åˆ°å‡ºç°`OutOfMemoryError`ï¼ˆOOMï¼‰ã€‚

åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œä»æç¤ºå’Œ`Generators`åˆ—è¡¨ä¸­ç”Ÿæˆä¸€æ‰¹å›¾åƒã€‚ç¡®ä¿ä¸ºæ¯ä¸ª`Generator`åˆ†é…ä¸€ä¸ªç§å­ï¼Œè¿™æ ·å¦‚æœå®ƒäº§ç”Ÿäº†å¥½çš„ç»“æœï¼Œä½ å°±å¯ä»¥é‡å¤ä½¿ç”¨å®ƒã€‚

```py
def get_inputs(batch_size=1):
    generator = [torch.Generator("cuda").manual_seed(i) for i in range(batch_size)]
    prompts = batch_size * [prompt]
    num_inference_steps = 20

    return {"prompt": prompts, "generator": generator, "num_inference_steps": num_inference_steps}
```

ä»`batch_size=4`å¼€å§‹ï¼Œçœ‹çœ‹ä½ æ¶ˆè€—äº†å¤šå°‘å†…å­˜ï¼š

```py
from diffusers.utils import make_image_grid

images = pipeline(**get_inputs(batch_size=4)).images
make_image_grid(images, 2, 2)
```

é™¤éä½ æœ‰æ›´å¤švRAMçš„GPUï¼Œä¸Šé¢çš„ä»£ç å¯èƒ½è¿”å›äº†ä¸€ä¸ª`OOM`é”™è¯¯ï¼å¤§éƒ¨åˆ†å†…å­˜è¢«äº¤å‰æ³¨æ„åŠ›å±‚å ç”¨ã€‚ä½ å¯ä»¥å°†è¿™ä¸ªæ“ä½œé¡ºåºè¿è¡Œè€Œä¸æ˜¯æ‰¹é‡è¿è¡Œï¼Œä»¥èŠ‚çœå¤§é‡å†…å­˜ã€‚ä½ åªéœ€è¦é…ç½®ç®¡é“ä½¿ç”¨[enable_attention_slicing()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_attention_slicing)å‡½æ•°ï¼š

```py
pipeline.enable_attention_slicing()
```

ç°åœ¨å°è¯•å°†`batch_size`å¢åŠ åˆ°8ï¼

```py
images = pipeline(**get_inputs(batch_size=8)).images
make_image_grid(images, rows=2, cols=4)
```

![](../Images/f242684980096d86bea7fa383ccd606a.png)

ä»¥å‰ä½ ç”šè‡³ä¸èƒ½ç”Ÿæˆä¸€æ‰¹4å¼ å›¾åƒï¼Œç°åœ¨ä½ å¯ä»¥ä»¥æ¯å¼ å›¾åƒçº¦3.5ç§’çš„é€Ÿåº¦ç”Ÿæˆä¸€æ‰¹8å¼ å›¾åƒï¼è¿™å¯èƒ½æ˜¯åœ¨T4 GPUä¸Šä¿æŒè´¨é‡çš„æœ€å¿«é€Ÿåº¦äº†ã€‚

## è´¨é‡

åœ¨æœ€åä¸¤èŠ‚ä¸­ï¼Œä½ å­¦ä¼šäº†å¦‚ä½•é€šè¿‡ä½¿ç”¨`fp16`æ¥ä¼˜åŒ–ç®¡é“çš„é€Ÿåº¦ï¼Œé€šè¿‡ä½¿ç”¨æ›´é«˜æ€§èƒ½çš„è°ƒåº¦ç¨‹åºå‡å°‘æ¨ç†æ­¥éª¤çš„æ•°é‡ï¼Œå¹¶å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡æ¥å‡å°‘å†…å­˜æ¶ˆè€—ã€‚ç°åœ¨ä½ è¦ä¸“æ³¨äºå¦‚ä½•æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚

### æ›´å¥½çš„æ£€æŸ¥ç‚¹

æœ€æ˜æ˜¾çš„ä¸€æ­¥æ˜¯ä½¿ç”¨æ›´å¥½çš„æ£€æŸ¥ç‚¹ã€‚ç¨³å®šæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ï¼Œè‡ªä»å®ƒæ­£å¼æ¨å‡ºä»¥æ¥ï¼Œä¹Ÿå‘å¸ƒäº†å‡ ä¸ªæ”¹è¿›ç‰ˆæœ¬ã€‚ç„¶è€Œï¼Œä½¿ç”¨æ›´æ–°ç‰ˆæœ¬å¹¶ä¸æ„å‘³ç€ä½ ä¼šè‡ªåŠ¨è·å¾—æ›´å¥½çš„ç»“æœã€‚ä½ ä»ç„¶éœ€è¦è‡ªå·±å°è¯•ä¸åŒçš„æ£€æŸ¥ç‚¹ï¼Œå¹¶è¿›è¡Œä¸€äº›ç ”ç©¶ï¼ˆæ¯”å¦‚ä½¿ç”¨[è´Ÿé¢æç¤º](https://minimaxir.com/2022/11/stable-diffusion-negative-prompt/)ï¼‰æ¥è·å¾—æœ€ä½³ç»“æœã€‚

éšç€é¢†åŸŸçš„å‘å±•ï¼Œæœ‰è¶Šæ¥è¶Šå¤šçš„ç»è¿‡å¾®è°ƒçš„é«˜è´¨é‡æ£€æŸ¥ç‚¹ï¼Œç”¨äºäº§ç”Ÿç‰¹å®šé£æ ¼ã€‚å°è¯•æ¢ç´¢[Hub](https://huggingface.co/models?library=diffusers&sort=downloads)å’Œ[Diffusers Gallery](https://huggingface.co/spaces/huggingface-projects/diffusers-gallery)ï¼Œæ‰¾åˆ°ä½ æ„Ÿå…´è¶£çš„ä¸€ä¸ªï¼

### æ›´å¥½çš„ç®¡é“ç»„ä»¶

ä½ ä¹Ÿå¯ä»¥å°è¯•ç”¨æ›´æ–°ç‰ˆæœ¬æ›¿æ¢å½“å‰çš„ç®¡é“ç»„ä»¶ã€‚è®©æˆ‘ä»¬å°è¯•å°†Stability AIçš„æœ€æ–°[è‡ªåŠ¨ç¼–ç å™¨](https://huggingface.co/stabilityai/stable-diffusion-2-1/tree/main/vae)åŠ è½½åˆ°ç®¡é“ä¸­ï¼Œå¹¶ç”Ÿæˆä¸€äº›å›¾åƒï¼š

```py
from diffusers import AutoencoderKL

vae = AutoencoderKL.from_pretrained("stabilityai/sd-vae-ft-mse", torch_dtype=torch.float16).to("cuda")
pipeline.vae = vae
images = pipeline(**get_inputs(batch_size=8)).images
make_image_grid(images, rows=2, cols=4)
```

![](../Images/f35b7f9a028460ebed6e9b753a1241d3.png)

### æ›´å¥½çš„æç¤ºå·¥ç¨‹

ä½ ç”¨æ¥ç”Ÿæˆå›¾åƒçš„æ–‡æœ¬æç¤ºéå¸¸é‡è¦ï¼Œä»¥è‡³äºè¢«ç§°ä¸º*æç¤ºå·¥ç¨‹*ã€‚åœ¨è¿›è¡Œæç¤ºå·¥ç¨‹æ—¶è¦è€ƒè™‘çš„ä¸€äº›å› ç´ æ˜¯ï¼š

+   å›¾åƒæˆ–ç±»ä¼¼æˆ‘æƒ³ç”Ÿæˆçš„å›¾åƒåœ¨äº’è”ç½‘ä¸Šæ˜¯å¦‚ä½•å­˜å‚¨çš„ï¼Ÿ

+   æˆ‘å¯ä»¥æä¾›ä»€ä¹ˆé¢å¤–çš„ç»†èŠ‚æ¥å¼•å¯¼æ¨¡å‹æœç€æˆ‘æƒ³è¦çš„é£æ ¼å‘å±•ï¼Ÿ

è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬æ”¹è¿›æç¤ºï¼ŒåŒ…æ‹¬é¢œè‰²å’Œæ›´é«˜è´¨é‡çš„ç»†èŠ‚ï¼š

```py
prompt += ", tribal panther make up, blue on red, side profile, looking away, serious eyes"
prompt += " 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta"
```

ç”¨æ–°æç¤ºç”Ÿæˆä¸€æ‰¹å›¾åƒï¼š

```py
images = pipeline(**get_inputs(batch_size=8)).images
make_image_grid(images, rows=2, cols=4)
```

![](../Images/52c687d1d7c73bcf4a482dc45feea714.png)

ç›¸å½“ä»¤äººå°è±¡æ·±åˆ»ï¼è®©æˆ‘ä»¬å¾®è°ƒç¬¬äºŒå¼ å›¾åƒ - å¯¹åº”äºç§å­ä¸º`1`çš„`Generator` - æ·»åŠ ä¸€äº›å…³äºä¸»é¢˜å¹´é¾„çš„æ–‡å­—ï¼š

```py
prompts = [
    "portrait photo of the oldest warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
    "portrait photo of a old warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
    "portrait photo of a warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
    "portrait photo of a young warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes 50mm portrait photography, hard rim lighting photography--beta --ar 2:3  --beta --upbeta",
]

generator = [torch.Generator("cuda").manual_seed(1) for _ in range(len(prompts))]
images = pipeline(prompt=prompts, generator=generator, num_inference_steps=25).images
make_image_grid(images, 2, 2)
```

![](../Images/181d5d3b3b595630cddf8064c033ea4f.png)

## ä¸‹ä¸€æ­¥

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œä½ å­¦ä¼šäº†å¦‚ä½•ä¸ºè®¡ç®—å’Œå†…å­˜æ•ˆç‡ä»¥åŠæ”¹å–„ç”Ÿæˆè¾“å‡ºè´¨é‡ä¼˜åŒ–[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚å¦‚æœä½ æœ‰å…´è¶£è®©ä½ çš„ç®¡é“è¿è¡Œå¾—æ›´å¿«ï¼Œå¯ä»¥æŸ¥çœ‹ä»¥ä¸‹èµ„æºï¼š

+   äº†è§£å¦‚ä½•ä½¿ç”¨[PyTorch 2.0](./optimization/torch2.0)å’Œ[`torch.compile`](https://pytorch.org/docs/stable/generated/torch.compile.html)å¯ä»¥æé«˜5-300%çš„æ¨ç†é€Ÿåº¦ã€‚åœ¨A100 GPUä¸Šï¼Œæ¨ç†é€Ÿåº¦å¯ä»¥æé«˜50%ï¼

+   å¦‚æœä½ ä¸èƒ½ä½¿ç”¨PyTorch 2ï¼Œæˆ‘ä»¬å»ºè®®ä½ å®‰è£…[xFormers](./optimization/xformers)ã€‚å®ƒçš„å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶ä¸PyTorch 1.13.1éå¸¸æ­é…ï¼Œå¯ä»¥å®ç°æ›´å¿«çš„é€Ÿåº¦å’Œå‡å°‘å†…å­˜æ¶ˆè€—ã€‚

+   å…¶ä»–ä¼˜åŒ–æŠ€æœ¯ï¼Œæ¯”å¦‚æ¨¡å‹å¸è½½ï¼Œåœ¨[è¿™ä¸ªæŒ‡å—](./optimization/fp16)ä¸­æœ‰ä»‹ç»ã€‚
