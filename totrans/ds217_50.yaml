- en: Create a dataset loading script
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建数据集加载脚本
- en: 'Original text: [https://huggingface.co/docs/datasets/dataset_script](https://huggingface.co/docs/datasets/dataset_script)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/datasets/dataset_script](https://huggingface.co/docs/datasets/dataset_script)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset loading script is likely not needed if your dataset is in one of
    the following formats: CSV, JSON, JSON lines, text, images, audio or Parquet.
    With those formats, you should be able to load your dataset automatically with
    [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset),
    as long as your dataset repository has a [required structure](./repository_structure).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据集是以下格式之一，则可能不需要数据集加载脚本：CSV、JSON、JSON lines、文本、图像、音频或Parquet。对于这些格式，只要您的数据集存储库具有[所需结构](./repository_structure)，您应该能够使用[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)自动加载数据集。
- en: In the next major release, the new safety features of 🤗 Datasets will disable
    running dataset loading scripts by default, and you will have to pass `trust_remote_code=True`
    to load datasets that require running a dataset script.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个主要版本中，🤗 Datasets的新安全功能将默认禁用运行数据集加载脚本，并且您将需要传递`trust_remote_code=True`来加载需要运行数据集脚本的数据集。
- en: Write a dataset script to load and share datasets that consist of data files
    in unsupported formats or require more complex data preparation. This is a more
    advanced way to define a dataset than using [YAML metadata in the dataset card](./repository_structure#define-your-splits-in-yaml).
    A dataset script is a Python file that defines the different configurations and
    splits of your dataset, as well as how to download and process the data.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 编写数据集脚本以加载和共享由不受支持的格式中的数据文件组成或需要更复杂数据准备的数据集。这是一种比使用[数据集卡中的YAML元数据](./repository_structure#define-your-splits-in-yaml)更高级的定义数据集的方式。数据集脚本是一个定义数据集的不同配置和拆分以及如何下载和处理数据的Python文件。
- en: The script can download data files from any website, or from the same dataset
    repository.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本可以从任何网站或相同的数据集存储库下载数据文件。
- en: 'A dataset loading script should have the same name as a dataset repository
    or directory. For example, a repository named `my_dataset` should contain `my_dataset.py`
    script. This way it can be loaded with:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集加载脚本应该与数据集存储库或目录同名。例如，名为`my_dataset`的存储库应包含`my_dataset.py`脚本。这样可以通过以下方式加载：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following guide includes instructions for dataset scripts for how to:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以下指南包括有关数据集脚本的说明：
- en: Add dataset metadata.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加数据集元数据。
- en: Download data files.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载数据文件。
- en: Generate samples.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成样本。
- en: Generate dataset metadata.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成数据集元数据。
- en: Upload a dataset to the Hub.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集上传到Hub。
- en: Open the [SQuAD dataset loading script](https://huggingface.co/datasets/squad/blob/main/squad.py)
    template to follow along on how to share a dataset.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 打开[SQuAD数据集加载脚本](https://huggingface.co/datasets/squad/blob/main/squad.py)模板，以了解如何共享数据集。
- en: To help you get started, try beginning with the dataset loading script [template](https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py)!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您入门，请尝试从数据集加载脚本[模板](https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py)开始！
- en: Add dataset attributes
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加数据集属性
- en: 'The first step is to add some information, or attributes, about your dataset
    in `DatasetBuilder._info()`. The most important attributes you should specify
    are:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是在`DatasetBuilder._info()`中添加关于数据集的一些信息或属性。您应该指定的最重要的属性是：
- en: '`DatasetInfo.description` provides a concise description of your dataset. The
    description informs the user what’s in the dataset, how it was collected, and
    how it can be used for a NLP task.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetInfo.description`提供了数据集的简洁描述。描述告诉用户数据集中包含什么，如何收集数据以及如何用于NLP任务。'
- en: '`DatasetInfo.features` defines the name and type of each column in your dataset.
    This will also provide the structure for each example, so it is possible to create
    nested subfields in a column if you want. Take a look at [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    for a full list of feature types you can use.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetInfo.features`定义了数据集中每列的名称和类型。这也为每个示例提供了结构，因此可以在列中创建嵌套子字段。查看[Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)以获取可以使用的特征类型的完整列表。'
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`DatasetInfo.homepage` contains the URL to the dataset homepage so users can
    find more details about the dataset.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetInfo.homepage`包含数据集主页的URL，用户可以在那里找到有关数据集的更多详细信息。'
- en: '`DatasetInfo.citation` contains a BibTeX citation for the dataset.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetInfo.citation`包含数据集的BibTeX引用。'
- en: 'After you’ve filled out all these fields in the template, it should look like
    the following example from the SQuAD loading script:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在模板中填写所有这些字段后，它应该看起来像来自SQuAD加载脚本的以下示例：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Multiple configurations
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多个配置
- en: In some cases, your dataset may have multiple configurations. For example, the
    [SuperGLUE](https://huggingface.co/datasets/super_glue) dataset is a collection
    of 5 datasets designed to evaluate language understanding tasks. 🤗 Datasets provides
    [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    which allows you to create different configurations for the user to select from.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，您的数据集可能具有多个配置。例如，[SuperGLUE](https://huggingface.co/datasets/super_glue)数据集是一个包含5个数据集的集合，旨在评估语言理解任务。🤗
    Datasets提供了[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)，允许您为用户创建不同的配置选择。
- en: Let’s study the [SuperGLUE loading script](https://huggingface.co/datasets/super_glue/blob/main/super_glue.py)
    to see how you can define several configurations.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们研究[SuperGLUE加载脚本](https://huggingface.co/datasets/super_glue/blob/main/super_glue.py)，看看您如何定义多个配置。
- en: Create a [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    subclass with attributes about your dataset. These attributes can be the features
    of your dataset, label classes, and a URL to the data files.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含有关数据集属性的[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)子类。这些属性可以是数据集的特征、标签类别和数据文件的URL。
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create instances of your config to specify the values of the attributes of
    each configuration. This gives you the flexibility to specify all the name and
    description of each configuration. These sub-class instances should be listed
    under `DatasetBuilder.BUILDER_CONFIGS`:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建配置的实例以指定每个配置的属性值。这使您可以灵活地指定每个配置的名称和描述。这些子类实例应列在`DatasetBuilder.BUILDER_CONFIGS`下：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, users can load a specific configuration of the dataset with the configuration
    `name`:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，用户可以使用配置`name`加载数据集的特定配置：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Additionally, users can instantiate a custom builder configuration by passing
    the builder configuration arguments to [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，用户可以通过将构建器配置参数传递给[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)来实例化自定义构建器配置：
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Default configurations
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 默认配置
- en: 'Users must specify a configuration name when they load a dataset with multiple
    configurations. Otherwise, 🤗 Datasets will raise a `ValueError`, and prompt the
    user to select a configuration name. You can avoid this by setting a default dataset
    configuration with the `DEFAULT_CONFIG_NAME` attribute:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 用户在加载具有多个配置的数据集时必须指定配置名称。否则，🤗数据集将引发`ValueError`，并提示用户选择配置名称。您可以通过设置具有`DEFAULT_CONFIG_NAME`属性的默认数据集配置来避免这种情况：
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Only use a default configuration when it makes sense. Don’t set one because
    it may be more convenient for the user to not specify a configuration when they
    load your dataset. For example, multi-lingual datasets often have a separate configuration
    for each language. An appropriate default may be an aggregated configuration that
    loads all the languages of the dataset if the user doesn’t request a particular
    one.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在有意义的情况下才使用默认配置。不要设置默认配置，因为用户可能更方便地在加载数据集时不指定配置。例如，多语言数据集通常为每种语言设置单独的配置。一个合适的默认配置可能是一个聚合配置，如果用户没有请求特定语言，则加载数据集的所有语言。
- en: Download data files and organize splits
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载数据文件并组织拆分
- en: After you’ve defined the attributes of your dataset, the next step is to download
    the data files and organize them according to their splits.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义数据集属性之后，下一步是下载数据文件并根据它们的拆分进行组织。
- en: 'Create a dictionary of URLs in the loading script that point to the original
    SQuAD data files:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在加载脚本中创建一个指向原始SQuAD数据文件的URL字典：
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If the data files live in the same folder or repository of the dataset script,
    you can just pass the relative paths to the files instead of URLs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据文件存储在与数据集脚本相同的文件夹或存储库中，您可以只传递文件的相对路径而不是URL。
- en: '[DownloadManager.download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)
    takes this dictionary and downloads the data files. Once the files are downloaded,
    use [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    to organize each split in the dataset. This is a simple class that contains:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[DownloadManager.download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)接受此字典并下载数据文件。一旦文件下载完成，使用[SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)来组织数据集中的每个拆分。这是一个简单的类，包含：'
- en: 'The `name` of each split. You should use the standard split names: `Split.TRAIN`,
    `Split.TEST`, and `Split.VALIDATION`.'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个拆分的`name`。您应该使用标准的拆分名称：`Split.TRAIN`、`Split.TEST`和`Split.VALIDATION`。
- en: '`gen_kwargs` provides the file paths to the data files to load for each split.'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gen_kwargs`为每个拆分提供要加载的数据文件的文件路径。'
- en: 'Your `DatasetBuilder._split_generator()` should look like this now:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您的`DatasetBuilder._split_generator()`现在应该如下所示：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Generate samples
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成样本
- en: 'At this point, you have:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您已经有：
- en: Added the dataset attributes.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加数据集属性。
- en: Provided instructions for how to download the data files.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了如何下载数据文件的说明。
- en: Organized the splits.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织拆分。
- en: The next step is to actually generate the samples in each split.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是实际在每个拆分中生成样本。
- en: '`DatasetBuilder._generate_examples` takes the file path provided by `gen_kwargs`
    to read and parse the data files. You need to write a function that loads the
    data files and extracts the columns.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetBuilder._generate_examples`使用`gen_kwargs`提供的文件路径来读取和解析数据文件。您需要编写一个加载数据文件并提取列的函数。'
- en: Your function should yield a tuple of an `id_`, and an example from the dataset.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的函数应该生成一个元组，其中包含一个`id_`和数据集中的一个示例。
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: (Optional) Generate dataset metadata
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: （可选）生成数据集元数据
- en: Adding dataset metadata is a great way to include information about your dataset.
    The metadata is stored in the dataset card `README.md` in YAML. It includes information
    like the number of examples required to confirm the dataset was correctly generated,
    and information about the dataset like its `features`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 添加数据集元数据是包含有关数据集信息的重要方式。元数据存储在数据集卡片`README.md`中的YAML中。它包括诸如确认数据集是否正确生成所需的示例数量等信息，以及有关数据集的信息，如其`features`。
- en: 'Run the following command to generate your dataset metadata in `README.md`
    and make sure your new dataset loading script works correctly:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令生成`README.md`中的数据集元数据，并确保您的新数据集加载脚本正常工作：
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If your dataset loading script passed the test, you should now have a `README.md`
    file in your dataset folder containing a `dataset_info` field with some metadata.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据集加载脚本通过了测试，现在您的数据集文件夹中应该有一个包含一些元数据的`README.md`文件，其中包含一个`dataset_info`字段。
- en: Upload to the Hub
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传到Hub
- en: Once your script is ready, [create a dataset card](dataset_card) and [upload
    it to the Hub](share).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的脚本准备好了，[创建一个数据集卡片](dataset_card)并[上传到Hub](share)。
- en: Congratulations, you can now load your dataset from the Hub! 🥳
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，您现在可以从Hub加载您的数据集了！🥳
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Advanced features
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级特性
- en: Sharding
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分片
- en: If your dataset is made of many big files, 🤗 Datasets automatically runs your
    script in parallel to make it super fast! It can help if you have hundreds or
    thousands of TAR archives, or JSONL files like [oscar](https://huggingface.co/datasets/oscar/blob/main/oscar.py)
    for example.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据集由许多大文件组成，🤗数据集会自动并行运行您的脚本，使其运行速度非常快！例如，如果您有数百或数千个TAR存档文件，或者像[oscar](https://huggingface.co/datasets/oscar/blob/main/oscar.py)这样的JSONL文件。
- en: To make it work, we consider lists of files in `gen_kwargs` to be shards. Therefore
    🤗 Datasets can automatically spawn several workers to run `_generate_examples`
    in parallel, and each worker is given a subset of shards to process.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使其工作，我们认为`gen_kwargs`中的文件列表是分片。因此，🤗数据集可以自动启动多个工作进程并行运行`_generate_examples`，每个工作进程都会被分配一个要处理的分片子集。
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Users can also specify `num_proc=` in `load_dataset()` to specify the number
    of processes to use as workers.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 用户还可以在`load_dataset()`中指定`num_proc=`来指定要用作工作进程的进程数。
- en: ArrowBasedBuilder
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ArrowBasedBuilder
- en: 'For some datasets it can be much faster to yield batches of data rather than
    examples one by one. You can speed up the dataset generation by yielding Arrow
    tables directly, instead of examples. This is especially useful if your data comes
    from Pandas DataFrames for example, since the conversion from Pandas to Arrow
    is as simple as:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一些数据集，批量生成数据可能比逐个生成示例要快得多。您可以通过直接生成Arrow表而不是示例来加快数据集生成速度。这在您的数据来自Pandas DataFrames等情况下尤其有用，因为从Pandas转换为Arrow非常简单：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To yield Arrow tables instead of single examples, make your dataset builder
    inherit from [ArrowBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.ArrowBasedBuilder)
    instead of [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder),
    and use `_generate_tables` instead of `_generate_examples`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成Arrow表而不是单个示例，请使您的数据集构建器继承自[ArrowBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.ArrowBasedBuilder)而不是[GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder)，并使用`_generate_tables`而不是`_generate_examples`：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Don’t forget to keep your script memory efficient, in case users run them on
    machines with a low amount of RAM.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记保持脚本的内存效率，以防用户在内存较少的机器上运行它们。
