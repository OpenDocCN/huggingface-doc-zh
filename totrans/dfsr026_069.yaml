- en: Custom Diffusion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰æ‰©æ•£
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/custom_diffusion](https://huggingface.co/docs/diffusers/training/custom_diffusion)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/training/custom_diffusion](https://huggingface.co/docs/diffusers/training/custom_diffusion)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Custom Diffusion](https://huggingface.co/papers/2212.04488) is a training
    technique for personalizing image generation models. Like Textual Inversion, DreamBooth,
    and LoRA, Custom Diffusion only requires a few (~4-5) example images. This technique
    works by only training weights in the cross-attention layers, and it uses a special
    word to represent the newly learned concept. Custom Diffusion is unique because
    it can also learn multiple concepts at the same time.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Custom Diffusion](https://huggingface.co/papers/2212.04488)æ˜¯ä¸€ç§ç”¨äºä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæŠ€æœ¯ã€‚ä¸æ–‡æœ¬åè½¬ã€DreamBoothå’ŒLoRAä¸€æ ·ï¼Œè‡ªå®šä¹‰æ‰©æ•£åªéœ€è¦å‡ ä¸ªï¼ˆ~4-5ï¼‰ç¤ºä¾‹å›¾åƒã€‚è¿™ç§æŠ€æœ¯é€šè¿‡ä»…è®­ç»ƒäº¤å‰æ³¨æ„åŠ›å±‚ä¸­çš„æƒé‡æ¥å·¥ä½œï¼Œå¹¶ä½¿ç”¨ç‰¹æ®Šè¯æ¥è¡¨ç¤ºæ–°å­¦ä¹ çš„æ¦‚å¿µã€‚è‡ªå®šä¹‰æ‰©æ•£æ˜¯ç‹¬ç‰¹çš„ï¼Œå› ä¸ºå®ƒè¿˜å¯ä»¥åŒæ—¶å­¦ä¹ å¤šä¸ªæ¦‚å¿µã€‚'
- en: If youâ€™re training on a GPU with limited vRAM, you should try enabling xFormers
    with `--enable_xformers_memory_efficient_attention` for faster training with lower
    vRAM requirements (16GB). To save even more memory, add `--set_grads_to_none`
    in the training argument to set the gradients to `None` instead of zero (this
    option can cause some issues, so if you experience any, try removing this parameter).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨åœ¨å…·æœ‰æœ‰é™vRAMçš„GPUä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ‚¨åº”è¯¥å°è¯•ä½¿ç”¨`--enable_xformers_memory_efficient_attention`å¯ç”¨xFormersï¼Œä»¥å®ç°æ›´å¿«çš„è®­ç»ƒå’Œæ›´ä½çš„vRAMè¦æ±‚ï¼ˆ16GBï¼‰ã€‚ä¸ºäº†èŠ‚çœæ›´å¤šå†…å­˜ï¼Œå¯ä»¥åœ¨è®­ç»ƒå‚æ•°ä¸­æ·»åŠ `--set_grads_to_none`ï¼Œå°†æ¢¯åº¦è®¾ç½®ä¸º`None`è€Œä¸æ˜¯é›¶ï¼ˆæ­¤é€‰é¡¹å¯èƒ½ä¼šå¯¼è‡´ä¸€äº›é—®é¢˜ï¼Œå¦‚æœæ‚¨é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œè¯·å°è¯•åˆ é™¤æ­¤å‚æ•°ï¼‰ã€‚
- en: This guide will explore the [train_custom_diffusion.py](https://github.com/huggingface/diffusers/blob/main/examples/custom_diffusion/train_custom_diffusion.py)
    script to help you become more familiar with it, and how you can adapt it for
    your own use-case.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—å°†æ¢è®¨[train_custom_diffusion.py](https://github.com/huggingface/diffusers/blob/main/examples/custom_diffusion/train_custom_diffusion.py)è„šæœ¬ï¼Œå¸®åŠ©æ‚¨æ›´ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•ä¸ºè‡ªå·±çš„ç”¨ä¾‹è¿›è¡Œè°ƒæ•´ã€‚
- en: 'Before running the script, make sure you install the library from source:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨ä»æºä»£ç å®‰è£…åº“ï¼š
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Navigate to the example folder with the training script and install the required
    dependencies:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼èˆªåˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹å¹¶å®‰è£…æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ğŸ¤— Accelerate is a library for helping you train on multiple GPUs/TPUs or with
    mixed-precision. Itâ€™ll automatically configure your training setup based on your
    hardware and environment. Take a look at the ğŸ¤— Accelerate [Quick tour](https://huggingface.co/docs/accelerate/quicktour)
    to learn more.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Accelerateæ˜¯ä¸€ä¸ªå¸®åŠ©æ‚¨åœ¨å¤šä¸ªGPU/TPUä¸Šè®­ç»ƒæˆ–ä½¿ç”¨æ··åˆç²¾åº¦çš„åº“ã€‚å®ƒå°†æ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚æŸ¥çœ‹ğŸ¤— Accelerate
    [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour)ä»¥äº†è§£æ›´å¤šã€‚
- en: 'Initialize an ğŸ¤— Accelerate environment:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹åŒ–ğŸ¤— Accelerateç¯å¢ƒï¼š
- en: '[PRE2]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To setup a default ğŸ¤— Accelerate environment without choosing any configurations:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è®¾ç½®é»˜è®¤çš„ğŸ¤— Accelerateç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Or if your environment doesnâ€™t support an interactive shell, like a notebook,
    you can use:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…å¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼shellï¼Œæ¯”å¦‚ç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š
- en: '[PRE4]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lastly, if you want to train a model on your own dataset, take a look at the
    [Create a dataset for training](create_dataset) guide to learn how to create a
    dataset that works with the training script.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚
- en: The following sections highlight parts of the training script that are important
    for understanding how to modify it, but it doesnâ€™t cover every aspect of the script
    in detail. If youâ€™re interested in learning more, feel free to read through the
    [script](https://github.com/huggingface/diffusers/blob/main/examples/custom_diffusion/train_custom_diffusion.py)
    and let us know if you have any questions or concerns.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹éƒ¨åˆ†çªå‡ºæ˜¾ç¤ºäº†è®­ç»ƒè„šæœ¬çš„é‡è¦éƒ¨åˆ†ï¼Œæœ‰åŠ©äºäº†è§£å¦‚ä½•ä¿®æ”¹å®ƒï¼Œä½†å¹¶æœªè¯¦ç»†æ¶µç›–è„šæœ¬çš„æ¯ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·éšæ—¶é˜…è¯»[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/custom_diffusion/train_custom_diffusion.py)ï¼Œå¹¶å‘Šè¯‰æˆ‘ä»¬æ‚¨æ˜¯å¦æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ã€‚
- en: Script parameters
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è„šæœ¬å‚æ•°
- en: The training script contains all the parameters to help you customize your training
    run. These are found in the [`parse_args()`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/custom_diffusion/train_custom_diffusion.py#L319)
    function. The function comes with default values, but you can also set your own
    values in the training command if youâ€™d like.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬åŒ…å«æ‰€æœ‰å‚æ•°ï¼Œå¸®åŠ©æ‚¨å®šåˆ¶è®­ç»ƒè¿è¡Œã€‚è¿™äº›å‚æ•°åœ¨[`parse_args()`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/custom_diffusion/train_custom_diffusion.py#L319)å‡½æ•°ä¸­æ‰¾åˆ°ã€‚è¯¥å‡½æ•°å¸¦æœ‰é»˜è®¤å€¼ï¼Œä½†å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚
- en: 'For example, to change the resolution of the input image:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè¦æ›´æ”¹è¾“å…¥å›¾åƒçš„åˆ†è¾¨ç‡ï¼š
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Many of the basic parameters are described in the [DreamBooth](dreambooth#script-parameters)
    training guide, so this guide focuses on the parameters unique to Custom Diffusion:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šåŸºæœ¬å‚æ•°åœ¨[DreamBooth](dreambooth#script-parameters)è®­ç»ƒæŒ‡å—ä¸­æœ‰æè¿°ï¼Œå› æ­¤æœ¬æŒ‡å—é‡ç‚¹ä»‹ç»äº†è‡ªå®šä¹‰æ‰©æ•£çš„ç‹¬ç‰¹å‚æ•°ï¼š
- en: '`--freeze_model`: freezes the key and value parameters in the cross-attention
    layer; the default is `crossattn_kv`, but you can set it to `crossattn` to train
    all the parameters in the cross-attention layer'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--freeze_model`ï¼šå†»ç»“äº¤å‰æ³¨æ„åŠ›å±‚ä¸­çš„é”®å’Œå€¼å‚æ•°ï¼›é»˜è®¤å€¼ä¸º`crossattn_kv`ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥å°†å…¶è®¾ç½®ä¸º`crossattn`ä»¥è®­ç»ƒäº¤å‰æ³¨æ„åŠ›å±‚ä¸­çš„æ‰€æœ‰å‚æ•°'
- en: '`--concepts_list`: to learn multiple concepts, provide a path to a JSON file
    containing the concepts'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--concepts_list`ï¼šè¦å­¦ä¹ å¤šä¸ªæ¦‚å¿µï¼Œè¯·æä¾›åŒ…å«æ¦‚å¿µçš„JSONæ–‡ä»¶çš„è·¯å¾„'
- en: '`--modifier_token`: a special word used to represent the learned concept'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--modifier_token`ï¼šç”¨äºè¡¨ç¤ºå­¦ä¹ æ¦‚å¿µçš„ç‰¹æ®Šè¯'
- en: '`--initializer_token`:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--initializer_token`ï¼š'
- en: Prior preservation loss
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å…ˆå‰çš„ä¿ç•™æŸå¤±
- en: Prior preservation loss is a method that uses a modelâ€™s own generated samples
    to help it learn how to generate more diverse images. Because these generated
    sample images belong to the same class as the images you provided, they help the
    model retain what it has learned about the class and how it can use what it already
    knows about the class to make new compositions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å…ˆå‰ä¿å­˜æŸå¤±æ˜¯ä¸€ç§æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨æ¨¡å‹ç”Ÿæˆçš„æ ·æœ¬æ¥å¸®åŠ©æ¨¡å‹å­¦ä¹ å¦‚ä½•ç”Ÿæˆæ›´å¤šæ ·åŒ–çš„å›¾åƒã€‚ç”±äºè¿™äº›ç”Ÿæˆçš„æ ·æœ¬å›¾åƒå±äºæ‚¨æä¾›çš„å›¾åƒç›¸åŒçš„ç±»åˆ«ï¼Œå®ƒä»¬æœ‰åŠ©äºæ¨¡å‹ä¿ç•™å…¶å¯¹ç±»åˆ«çš„å­¦ä¹ ä»¥åŠå¦‚ä½•åˆ©ç”¨å…¶å·²çŸ¥çš„ç±»åˆ«çŸ¥è¯†æ¥ç”Ÿæˆæ–°æ„å›¾çš„å†…å®¹ã€‚
- en: Many of the parameters for prior preservation loss are described in the [DreamBooth](dreambooth#prior-preservation-loss)
    training guide.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šæœ‰å…³å…ˆå‰ä¿å­˜æŸå¤±çš„å‚æ•°åœ¨[DreamBooth](dreambooth#prior-preservation-loss)åŸ¹è®­æŒ‡å—ä¸­æœ‰æè¿°ã€‚
- en: Regularization
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ­£åˆ™åŒ–
- en: Custom Diffusion includes training the target images with a small set of real
    images to prevent overfitting. As you can imagine, this can be easy to do when
    youâ€™re only training on a few images! Download 200 real images with `clip_retrieval`.
    The `class_prompt` should be the same category as the target images. These images
    are stored in `class_data_dir`.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰æ‰©æ•£åŒ…æ‹¬ä½¿ç”¨å°‘é‡çœŸå®å›¾åƒè®­ç»ƒç›®æ ‡å›¾åƒï¼Œä»¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚å¯ä»¥æƒ³è±¡ï¼Œå½“æ‚¨åªå¯¹å°‘é‡å›¾åƒè¿›è¡Œè®­ç»ƒæ—¶ï¼Œè¿™å¯èƒ½å¾ˆå®¹æ˜“åšåˆ°ï¼ä½¿ç”¨`clip_retrieval`ä¸‹è½½200å¼ çœŸå®å›¾åƒã€‚`class_prompt`åº”è¯¥æ˜¯ä¸ç›®æ ‡å›¾åƒç›¸åŒç±»åˆ«ã€‚è¿™äº›å›¾åƒå­˜å‚¨åœ¨`class_data_dir`ä¸­ã€‚
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To enable regularization, add the following parameters:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å¯ç”¨æ­£åˆ™åŒ–ï¼Œè¯·æ·»åŠ ä»¥ä¸‹å‚æ•°ï¼š
- en: '`--with_prior_preservation`: whether to use prior preservation loss'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--with_prior_preservation`ï¼šæ˜¯å¦ä½¿ç”¨å…ˆå‰ä¿å­˜æŸå¤±'
- en: '`--prior_loss_weight`: controls the influence of the prior preservation loss
    on the model'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--prior_loss_weight`ï¼šæ§åˆ¶å…ˆå‰ä¿å­˜æŸå¤±å¯¹æ¨¡å‹çš„å½±å“'
- en: '`--real_prior`: whether to use a small set of real images to prevent overfitting'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--real_prior`ï¼šæ˜¯å¦ä½¿ç”¨å°‘é‡çœŸå®å›¾åƒä»¥é˜²æ­¢è¿‡æ‹Ÿåˆ'
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Training script
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒè„šæœ¬
- en: A lot of the code in the Custom Diffusion training script is similar to the
    [DreamBooth](dreambooth#training-script) script. This guide instead focuses on
    the code that is relevant to Custom Diffusion.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰æ‰©æ•£è®­ç»ƒè„šæœ¬ä¸­çš„è®¸å¤šä»£ç ä¸[DreamBooth](dreambooth#training-script)è„šæœ¬ç›¸ä¼¼ã€‚æœ¬æŒ‡å—é‡ç‚¹ä»‹ç»ä¸è‡ªå®šä¹‰æ‰©æ•£ç›¸å…³çš„ä»£ç ã€‚
- en: 'The Custom Diffusion training script has two dataset classes:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰æ‰©æ•£è®­ç»ƒè„šæœ¬æœ‰ä¸¤ä¸ªæ•°æ®é›†ç±»ï¼š
- en: '[`CustomDiffusionDataset`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/custom_diffusion/train_custom_diffusion.py#L165):
    preprocesses the images, class images, and prompts for training'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`CustomDiffusionDataset`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/custom_diffusion/train_custom_diffusion.py#L165)ï¼šå¯¹å›¾åƒã€ç±»å›¾åƒå’Œæç¤ºè¿›è¡Œé¢„å¤„ç†ä»¥è¿›è¡Œè®­ç»ƒ'
- en: '[`PromptDataset`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/custom_diffusion/train_custom_diffusion.py#L148):
    prepares the prompts for generating class images'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`PromptDataset`](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/custom_diffusion/train_custom_diffusion.py#L148)ï¼šå‡†å¤‡ç”¨äºç”Ÿæˆç±»å›¾åƒçš„æç¤º'
- en: Next, the `modifier_token` is [added to the tokenizer](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/custom_diffusion/train_custom_diffusion.py#L811),
    converted to token ids, and the token embeddings are resized to account for the
    new `modifier_token`. Then the `modifier_token` embeddings are initialized with
    the embeddings of the `initializer_token`. All parameters in the text encoder
    are frozen, except for the token embeddings since this is what the model is trying
    to learn to associate with the concepts.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œ`modifier_token`è¢«æ·»åŠ åˆ°åˆ†è¯å™¨ä¸­ï¼Œè½¬æ¢ä¸ºæ ‡è®°idï¼Œå¹¶ä¸”æ ‡è®°åµŒå…¥è¢«è°ƒæ•´å¤§å°ä»¥é€‚åº”æ–°çš„`modifier_token`ã€‚ç„¶åï¼Œ`modifier_token`çš„åµŒå…¥è¢«åˆå§‹åŒ–ä¸º`initializer_token`çš„åµŒå…¥ã€‚æ–‡æœ¬ç¼–ç å™¨ä¸­çš„æ‰€æœ‰å‚æ•°éƒ½è¢«å†»ç»“ï¼Œé™¤äº†æ ‡è®°åµŒå…¥ï¼Œå› ä¸ºè¿™æ˜¯æ¨¡å‹è¯•å›¾å­¦ä¹ ä¸æ¦‚å¿µç›¸å…³è”çš„å†…å®¹ã€‚
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now youâ€™ll need to add the [Custom Diffusion weights](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/custom_diffusion/train_custom_diffusion.py#L911C3-L911C3)
    to the attention layers. This is a really important step for getting the shape
    and size of the attention weights correct, and for setting the appropriate number
    of attention processors in each UNet block.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæ‚¨éœ€è¦å°†[è‡ªå®šä¹‰æ‰©æ•£æƒé‡](https://github.com/huggingface/diffusers/blob/64603389da01082055a901f2883c4810d1144edb/examples/custom_diffusion/train_custom_diffusion.py#L911C3-L911C3)æ·»åŠ åˆ°æ³¨æ„åŠ›å±‚ä¸­ã€‚è¿™æ˜¯ç¡®ä¿æ³¨æ„åŠ›æƒé‡çš„å½¢çŠ¶å’Œå¤§å°æ­£ç¡®çš„ä¸€ä¸ªéå¸¸é‡è¦çš„æ­¥éª¤ï¼Œä¹Ÿæ˜¯ä¸ºæ¯ä¸ªUNetå—è®¾ç½®é€‚å½“æ•°é‡çš„æ³¨æ„åŠ›å¤„ç†å™¨çš„å…³é”®ã€‚
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The [optimizer](https://github.com/huggingface/diffusers/blob/84cd9e8d01adb47f046b1ee449fc76a0c32dc4e2/examples/custom_diffusion/train_custom_diffusion.py#L982)
    is initialized to update the cross-attention layer parameters:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼˜åŒ–å™¨è¢«åˆå§‹åŒ–ä»¥æ›´æ–°äº¤å‰æ³¨æ„åŠ›å±‚å‚æ•°ï¼š
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the [training loop](https://github.com/huggingface/diffusers/blob/84cd9e8d01adb47f046b1ee449fc76a0c32dc4e2/examples/custom_diffusion/train_custom_diffusion.py#L1048),
    it is important to only update the embeddings for the concept youâ€™re trying to
    learn. This means setting the gradients of all the other token embeddings to zero:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/84cd9e8d01adb47f046b1ee449fc76a0c32dc4e2/examples/custom_diffusion/train_custom_diffusion.py#L1048)ä¸­ï¼Œåªæ›´æ–°æ‚¨è¦å­¦ä¹ çš„æ¦‚å¿µçš„åµŒå…¥æ˜¯å¾ˆé‡è¦çš„ã€‚è¿™æ„å‘³ç€å°†æ‰€æœ‰å…¶ä»–æ ‡è®°åµŒå…¥çš„æ¢¯åº¦è®¾ç½®ä¸ºé›¶ï¼š
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Launch the script
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯åŠ¨è„šæœ¬
- en: Once youâ€™ve made all your changes or youâ€™re okay with the default configuration,
    youâ€™re ready to launch the training script! ğŸš€
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨å®Œæˆäº†æ‰€æœ‰æ›´æ”¹æˆ–å¯¹é»˜è®¤é…ç½®æ„Ÿåˆ°æ»¡æ„ï¼Œæ‚¨å°±å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€
- en: In this guide, youâ€™ll download and use these example [cat images](https://www.cs.cmu.edu/~custom-diffusion/assets/data.zip).
    You can also create and use your own dataset if you want (see the [Create a dataset
    for training](create_dataset) guide).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæ‚¨å°†ä¸‹è½½å¹¶ä½¿ç”¨è¿™äº›ç¤ºä¾‹[çŒ«å›¾åƒ](https://www.cs.cmu.edu/~custom-diffusion/assets/data.zip)ã€‚å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åˆ›å»ºå¹¶ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼ˆè¯·å‚é˜…[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset)æŒ‡å—ï¼‰ã€‚
- en: Set the environment variable `MODEL_NAME` to a model id on the Hub or a path
    to a local model, `INSTANCE_DIR` to the path where you just downloaded the cat
    images to, and `OUTPUT_DIR` to where you want to save the model. Youâ€™ll use `<new1>`
    as the special word to tie the newly learned embeddings to. The script creates
    and saves model checkpoints and a pytorch_custom_diffusion_weights.bin file to
    your repository.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ç¯å¢ƒå˜é‡`MODEL_NAME`è®¾ç½®ä¸ºHubä¸Šçš„æ¨¡å‹IDæˆ–æœ¬åœ°æ¨¡å‹çš„è·¯å¾„ï¼Œå°†`INSTANCE_DIR`è®¾ç½®ä¸ºæ‚¨åˆšä¸‹è½½çŒ«å›¾ç‰‡çš„è·¯å¾„ï¼Œå°†`OUTPUT_DIR`è®¾ç½®ä¸ºæ‚¨æƒ³è¦ä¿å­˜æ¨¡å‹çš„è·¯å¾„ã€‚æ‚¨å°†ä½¿ç”¨`<new1>`ä½œä¸ºå°†æ–°å­¦ä¹ çš„åµŒå…¥ä¸ä¹‹å…³è”çš„ç‰¹æ®Šè¯ã€‚è¯¥è„šæœ¬å°†åˆ›å»ºå¹¶ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹å’Œä¸€ä¸ªpytorch_custom_diffusion_weights.binæ–‡ä»¶åˆ°æ‚¨çš„å­˜å‚¨åº“ä¸­ã€‚
- en: To monitor training progress with Weights and Biases, add the `--report_to=wandb`
    parameter to the training command and specify a validation prompt with `--validation_prompt`.
    This is useful for debugging and saving intermediate results.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨Weights and Biasesç›‘è§†è®­ç»ƒè¿›åº¦ï¼Œè¯·åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--report_to=wandb`å‚æ•°ï¼Œå¹¶ä½¿ç”¨`--validation_prompt`æŒ‡å®šéªŒè¯æç¤ºã€‚è¿™å¯¹äºè°ƒè¯•å’Œä¿å­˜ä¸­é—´ç»“æœå¾ˆæœ‰ç”¨ã€‚
- en: 'If youâ€™re training on human faces, the Custom Diffusion team has found the
    following parameters to work well:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ­£åœ¨è®­ç»ƒäººè„¸ï¼ŒCustom Diffusionå›¢é˜Ÿå‘ç°ä»¥ä¸‹å‚æ•°æ•ˆæœå¾ˆå¥½ï¼š
- en: '`--learning_rate=5e-6`'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--learning_rate=5e-6`'
- en: '`--max_train_steps` can be anywhere between 1000 and 2000'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--max_train_steps`å¯ä»¥åœ¨1000å’Œ2000ä¹‹é—´ä»»æ„é€‰æ‹©'
- en: '`--freeze_model=crossattn`'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--freeze_model=crossattn`'
- en: use at least 15-20 images to train with
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è‡³å°‘ä½¿ç”¨15-20å¼ å›¾ç‰‡è¿›è¡Œè®­ç»ƒ
- en: single conceptmultiple concepts
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å•ä¸€æ¦‚å¿µå¤šä¸ªæ¦‚å¿µ
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Once training is finished, you can use your new Custom Diffusion model for inference.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ‚¨çš„æ–°Custom Diffusionæ¨¡å‹è¿›è¡Œæ¨æ–­ã€‚
- en: single conceptmultiple concepts
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å•ä¸€æ¦‚å¿µå¤šä¸ªæ¦‚å¿µ
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Next steps
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥
- en: 'Congratulations on training a model with Custom Diffusion! ğŸ‰ To learn more:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œæ‚¨è®­ç»ƒäº†ä¸€ä¸ªCustom Diffusionæ¨¡å‹ï¼ğŸ‰ è¦äº†è§£æ›´å¤šï¼š
- en: Read the [Multi-Concept Customization of Text-to-Image Diffusion](https://www.cs.cmu.edu/~custom-diffusion/)
    blog post to learn more details about the experimental results from the Custom
    Diffusion team.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é˜…è¯»[æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£çš„å¤šæ¦‚å¿µå®šåˆ¶](https://www.cs.cmu.edu/~custom-diffusion/)åšæ–‡ï¼Œäº†è§£æœ‰å…³Custom Diffusionå›¢é˜Ÿå®éªŒç»“æœçš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
