["```py\nfrom diffusers import DiffusionPipeline\n\nrepo_id = \"runwayml/stable-diffusion-v1-5\"\npipe = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)\n```", "```py\nfrom diffusers import StableDiffusionPipeline\n\nrepo_id = \"runwayml/stable-diffusion-v1-5\"\npipe = StableDiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)\n```", "```py\nfrom diffusers import StableDiffusionImg2ImgPipeline\n\nrepo_id = \"runwayml/stable-diffusion-v1-5\"\npipe = StableDiffusionImg2ImgPipeline.from_pretrained(repo_id)\n```", "```py\ngit-lfs install\ngit clone https://huggingface.co/runwayml/stable-diffusion-v1-5\n```", "```py\nfrom diffusers import DiffusionPipeline\n\nrepo_id = \"./stable-diffusion-v1-5\"\nstable_diffusion = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)\n```", "```py\nfrom diffusers import DiffusionPipeline\n\nrepo_id = \"runwayml/stable-diffusion-v1-5\"\nstable_diffusion = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)\nstable_diffusion.scheduler.compatibles\n```", "```py\nfrom diffusers import DiffusionPipeline, EulerDiscreteScheduler\n\nrepo_id = \"runwayml/stable-diffusion-v1-5\"\nscheduler = EulerDiscreteScheduler.from_pretrained(repo_id, subfolder=\"scheduler\")\nstable_diffusion = DiffusionPipeline.from_pretrained(repo_id, scheduler=scheduler, use_safetensors=True)\n```", "```py\nfrom diffusers import DiffusionPipeline\n\nrepo_id = \"runwayml/stable-diffusion-v1-5\"\nstable_diffusion = DiffusionPipeline.from_pretrained(repo_id, safety_checker=None, use_safetensors=True)\n\"\"\"\nYou have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide by the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend keeping the safety filter enabled in all public-facing circumstances, disabling it only for use cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n\"\"\"\n```", "```py\nfrom diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\nstable_diffusion_txt2img = StableDiffusionPipeline.from_pretrained(model_id, use_safetensors=True)\n\ncomponents = stable_diffusion_txt2img.components\n```", "```py\nstable_diffusion_img2img = StableDiffusionImg2ImgPipeline(**components)\n```", "```py\nfrom diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\nstable_diffusion_txt2img = StableDiffusionPipeline.from_pretrained(model_id, use_safetensors=True)\nstable_diffusion_img2img = StableDiffusionImg2ImgPipeline(\n    vae=stable_diffusion_txt2img.vae,\n    text_encoder=stable_diffusion_txt2img.text_encoder,\n    tokenizer=stable_diffusion_txt2img.tokenizer,\n    unet=stable_diffusion_txt2img.unet,\n    scheduler=stable_diffusion_txt2img.scheduler,\n    safety_checker=None,\n    feature_extractor=None,\n    requires_safety_checker=False,\n)\n```", "```py\nfrom diffusers import DiffusionPipeline\nimport torch\n\n# load fp16 variant\nstable_diffusion = DiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", variant=\"fp16\", torch_dtype=torch.float16, use_safetensors=True\n)\n# load non_ema variant\nstable_diffusion = DiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", variant=\"non_ema\", use_safetensors=True\n)\n```", "```py\nfrom diffusers import DiffusionPipeline\n\n# save as fp16 variant\nstable_diffusion.save_pretrained(\"runwayml/stable-diffusion-v1-5\", variant=\"fp16\")\n# save as non-ema variant\nstable_diffusion.save_pretrained(\"runwayml/stable-diffusion-v1-5\", variant=\"non_ema\")\n```", "```py\n# \ud83d\udc4e this won't work\nstable_diffusion = DiffusionPipeline.from_pretrained(\n    \"./stable-diffusion-v1-5\", torch_dtype=torch.float16, use_safetensors=True\n)\n# \ud83d\udc4d this works\nstable_diffusion = DiffusionPipeline.from_pretrained(\n    \"./stable-diffusion-v1-5\", variant=\"fp16\", torch_dtype=torch.float16, use_safetensors=True\n)\n```", "```py\nfrom diffusers import UNet2DConditionModel\n\nrepo_id = \"runwayml/stable-diffusion-v1-5\"\nmodel = UNet2DConditionModel.from_pretrained(repo_id, subfolder=\"unet\", use_safetensors=True)\n```", "```py\nfrom diffusers import UNet2DModel\n\nrepo_id = \"google/ddpm-cifar10-32\"\nmodel = UNet2DModel.from_pretrained(repo_id, use_safetensors=True)\n```", "```py\nfrom diffusers import UNet2DConditionModel\n\nmodel = UNet2DConditionModel.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\", variant=\"non_ema\", use_safetensors=True\n)\nmodel.save_pretrained(\"./local-unet\", variant=\"non_ema\")\n```", "```py\nfrom diffusers import StableDiffusionPipeline\nfrom diffusers import (\n    DDPMScheduler,\n    DDIMScheduler,\n    PNDMScheduler,\n    LMSDiscreteScheduler,\n    EulerAncestralDiscreteScheduler,\n    EulerDiscreteScheduler,\n    DPMSolverMultistepScheduler,\n)\n\nrepo_id = \"runwayml/stable-diffusion-v1-5\"\n\nddpm = DDPMScheduler.from_pretrained(repo_id, subfolder=\"scheduler\")\nddim = DDIMScheduler.from_pretrained(repo_id, subfolder=\"scheduler\")\npndm = PNDMScheduler.from_pretrained(repo_id, subfolder=\"scheduler\")\nlms = LMSDiscreteScheduler.from_pretrained(repo_id, subfolder=\"scheduler\")\neuler_anc = EulerAncestralDiscreteScheduler.from_pretrained(repo_id, subfolder=\"scheduler\")\neuler = EulerDiscreteScheduler.from_pretrained(repo_id, subfolder=\"scheduler\")\ndpm = DPMSolverMultistepScheduler.from_pretrained(repo_id, subfolder=\"scheduler\")\n\n# replace `dpm` with any of `ddpm`, `ddim`, `pndm`, `lms`, `euler_anc`, `euler`\npipeline = StableDiffusionPipeline.from_pretrained(repo_id, scheduler=dpm, use_safetensors=True)\n```", "```py\nfrom diffusers import DiffusionPipeline\n\nrepo_id = \"runwayml/stable-diffusion-v1-5\"\npipeline = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)\nprint(pipeline)\n```", "```py\nStableDiffusionPipeline {\n  \"feature_extractor\": [\n    \"transformers\",\n    \"CLIPImageProcessor\"\n  ],\n  \"safety_checker\": [\n    \"stable_diffusion\",\n    \"StableDiffusionSafetyChecker\"\n  ],\n  \"scheduler\": [\n    \"diffusers\",\n    \"PNDMScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n```", "```py\n.\n\u251c\u2500\u2500 feature_extractor\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 preprocessor_config.json\n\u251c\u2500\u2500 model_index.json\n\u251c\u2500\u2500 safety_checker\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 config.json\n| \u251c\u2500\u2500 model.fp16.safetensors\n\u2502   \u251c\u2500\u2500 model.safetensors\n\u2502   \u251c\u2500\u2500 pytorch_model.bin | \u2514\u2500\u2500 pytorch_model.fp16.bin\n\u251c\u2500\u2500 scheduler\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 scheduler_config.json\n\u251c\u2500\u2500 text_encoder\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 config.json | \u251c\u2500\u2500 model.fp16.safetensors\n\u2502   \u251c\u2500\u2500 model.safetensors\n\u2502 |\u2500\u2500 pytorch_model.bin | \u2514\u2500\u2500 pytorch_model.fp16.bin\n\u251c\u2500\u2500 tokenizer\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 merges.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 special_tokens_map.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tokenizer_config.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 vocab.json\n\u251c\u2500\u2500 unet\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 config.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 diffusion_pytorch_model.bin |  |\u2500\u2500 diffusion_pytorch_model.fp16.bin\n\u2502 |\u2500\u2500 diffusion_pytorch_model.f16.safetensors\n\u2502 |\u2500\u2500 diffusion_pytorch_model.non_ema.bin\n\u2502 |\u2500\u2500 diffusion_pytorch_model.non_ema.safetensors\n\u2502   \u2514\u2500\u2500 diffusion_pytorch_model.safetensors |\u2500\u2500 vae\n.   \u251c\u2500\u2500 config.json\n.   \u251c\u2500\u2500 diffusion_pytorch_model.bin\n    \u251c\u2500\u2500 diffusion_pytorch_model.fp16.bin\n    \u251c\u2500\u2500 diffusion_pytorch_model.fp16.safetensors\n    \u2514\u2500\u2500 diffusion_pytorch_model.safetensors\n```", "```py\npipeline.tokenizer\nCLIPTokenizer(\n    name_or_path=\"/root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/39593d5650112b4cc580433f6b0435385882d819/tokenizer\",\n    vocab_size=49408,\n    model_max_length=77,\n    is_fast=False,\n    padding_side=\"right\",\n    truncation_side=\"right\",\n    special_tokens={\n        \"bos_token\": AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True),\n        \"eos_token\": AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True),\n        \"unk_token\": AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True),\n        \"pad_token\": \"<|endoftext|>\",\n    },\n    clean_up_tokenization_spaces=True\n)\n```", "```py\n{\n  \"_class_name\": \"StableDiffusionPipeline\",\n  \"_diffusers_version\": \"0.6.0\",\n  \"feature_extractor\": [\n    \"transformers\",\n    \"CLIPImageProcessor\"\n  ],\n  \"safety_checker\": [\n    \"stable_diffusion\",\n    \"StableDiffusionSafetyChecker\"\n  ],\n  \"scheduler\": [\n    \"diffusers\",\n    \"PNDMScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n```"]