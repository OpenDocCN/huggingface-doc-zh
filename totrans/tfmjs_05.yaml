- en: Use custom models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/transformers.js/custom_usage](https://huggingface.co/docs/transformers.js/custom_usage)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/transformers.js/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/entry/start.d68a6d16.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/scheduler.b108d059.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/singletons.e4b794f0.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/paths.0114e475.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/entry/app.c6513cb2.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/index.008de539.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/nodes/0.7513fd35.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/nodes/18.c32d883d.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/CodeBlock.3968c746.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/Heading.88bfeb84.js">
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, Transformers.js uses [hosted pretrained models](https://huggingface.co/models?library=transformers.js)
    and [precompiled WASM binaries](https://cdn.jsdelivr.net/npm/@xenova/transformers@2.15.0/dist/),
    which should work out-of-the-box. You can customize this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Settings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For a full list of available settings, check out the [API Reference](./api/env).
  prefs: []
  type: TYPE_NORMAL
- en: Convert your models to ONNX
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We recommend using our [conversion script](https://github.com/xenova/transformers.js/blob/main/scripts/convert.py)
    to convert your PyTorch, TensorFlow, or JAX models to ONNX in a single command.
    Behind the scenes, it uses [ðŸ¤— Optimum](https://huggingface.co/docs/optimum) to
    perform conversion and quantization of your model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, convert and quantize [bert-base-uncased](https://huggingface.co/bert-base-uncased)
    using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will save the following files to `./models/`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: For the full list of supported architectures, see the [Optimum documentation](https://huggingface.co/docs/optimum/main/en/exporters/onnx/overview).
  prefs: []
  type: TYPE_NORMAL
