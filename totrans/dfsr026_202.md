# 潜在一致性模型多步调度器

> 原文链接：[https://huggingface.co/docs/diffusers/api/schedulers/lcm](https://huggingface.co/docs/diffusers/api/schedulers/lcm)

## 概述

多步和单步调度器（算法3）与论文[Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference](https://arxiv.org/abs/2310.04378)中的潜在一致性模型一起引入，作者为Simian Luo、Yiqin Tan、Longbo Huang、Jian Li和Hang Zhao。该调度器应该能够在1-8步内从[LatentConsistencyModelPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/latent_consistency_models#diffusers.LatentConsistencyModelPipeline)生成良好的样本。

## LCMScheduler

### `class diffusers.LCMScheduler`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_lcm.py#L134)

```py
( num_train_timesteps: int = 1000 beta_start: float = 0.00085 beta_end: float = 0.012 beta_schedule: str = 'scaled_linear' trained_betas: Union = None original_inference_steps: int = 50 clip_sample: bool = False clip_sample_range: float = 1.0 set_alpha_to_one: bool = True steps_offset: int = 0 prediction_type: str = 'epsilon' thresholding: bool = False dynamic_thresholding_ratio: float = 0.995 sample_max_value: float = 1.0 timestep_spacing: str = 'leading' timestep_scaling: float = 10.0 rescale_betas_zero_snr: bool = False )
```

参数

+   `num_train_timesteps` (`int`, 默认为1000`) — 训练模型的扩散步数。

+   `beta_start` (`float`, 默认为0.0001`) — 推理的起始`beta`值。

+   `beta_end` (`float`, 默认为0.02`) — 最终的`beta`值。

+   `beta_schedule` (`str`, 默认为`"linear"`) — beta调度，从beta范围映射到用于步进模型的一系列beta。可选择`linear`、`scaled_linear`或`squaredcos_cap_v2`。

+   `trained_betas` (`np.ndarray`, *可选*) — 直接将一组beta传递给构造函数，以绕过`beta_start`和`beta_end`。

+   `original_inference_steps` (`int`, *可选*, 默认为50`) — 用于生成线性间隔时间步长调度的默认推理步数，最终我们将从中取`num_inference_steps`等间隔时间步长以形成最终时间步长调度。

+   `clip_sample` (`bool`, 默认为`True`) — 为了数值稳定性而裁剪预测样本。

+   `clip_sample_range` (`float`, 默认为1.0`) — 样本裁剪的最大幅度。仅在`clip_sample=True`时有效。

+   `set_alpha_to_one` (`bool`, 默认为`True`) — 每个扩散步骤使用该步骤和上一个步骤的alpha乘积值。对于最后一步，没有上一个alpha。当此选项为`True`时，前一个alpha乘积被固定为`1`，否则使用步骤0的alpha值。

+   `steps_offset` (`int`, 默认为0`) — 添加到推理步骤的偏移量。您可以使用`offset=1`和`set_alpha_to_one=False`的组合，使最后一步使用步骤0作为先前alpha乘积，就像在Stable Diffusion中一样。

+   `prediction_type` (`str`, 默认为`epsilon`, *可选*) — 调度函数的预测类型；可以是`epsilon`（预测扩散过程的噪声）、`sample`（直接预测有噪声的样本）或`v_prediction`（参见[Imagen Video](https://imagen.research.google/video/paper.pdf)论文的第2.4节）。

+   `thresholding` (`bool`, 默认为`False`) — 是否使用“动态阈值”方法。这对于稳定扩散等潜在空间扩散模型不适用。

+   `dynamic_thresholding_ratio` (`float`, 默认为0.995`) — 动态阈值方法的比率。仅在`thresholding=True`时有效。

+   `sample_max_value` (`float`, 默认为1.0`) — 动态阈值的阈值值。仅在`thresholding=True`时有效。

+   `timestep_spacing` (`str`, 默认为`"leading"`) — 时间步长应该如何缩放。更多信息请参考[Common Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891)的表2。

+   `timestep_scaling` (`float`, 默认为10.0`) — 计算一致性模型边界条件`c_skip`和`c_out`时，时间步长将乘以的因子。增加这个值将减少近似误差（尽管默认值为`10.0`时近似误差已经相当小）。

+   `rescale_betas_zero_snr` (`bool`，默认为`False`) — 是否重新缩放beta值以使终端信噪比为零。这使模型能够生成非常明亮和黑暗的样本，而不是将其限制为具有中等亮度的样本。与[`--offset_noise`](https://github.com/huggingface/diffusers/blob/74fd735eb073eb1d774b1ab4154a0876eb82f055/examples/dreambooth/train_dreambooth.py#L506) loosely相关。

`LCMScheduler` 扩展了引入非马尔可夫引导的去噪扩散概率模型（DDPMs）的过程。

该模型继承自[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)和[ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)。[~ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)负责存储传递给调度程序的`__init__`函数的所有配置属性，例如`num_train_timesteps`。可以通过`scheduler.config.num_train_timesteps`访问它们。[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)通过[SchedulerMixin.save_pretrained()](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin.save_pretrained)和[from_pretrained()](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin.from_pretrained)函数提供一般的加载和保存功能。

#### `scale_model_input`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_lcm.py#L276)

```py
( sample: FloatTensor timestep: Optional = None ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample` (`torch.FloatTensor`) — 输入样本。

+   `timestep` (`int`, *可选*) — 扩散链中的当前时间步长。

返回

`torch.FloatTensor`

一个经过缩放的输入样本。

确保与需要根据当前时间步长缩放去噪模型输入的调度程序可互换。

#### `set_timesteps`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_lcm.py#L326)

```py
( num_inference_steps: Optional = None device: Union = None original_inference_steps: Optional = None timesteps: Optional = None strength: int = 1.0 )
```

参数

+   `num_inference_steps` (`int`, *可选*) — 使用预训练模型生成样本时使用的扩散步数。如果使用，`timesteps`必须为`None`。

+   `device` (`str`或`torch.device`，*可选*) — 时间步长应移动到的设备。如果为`None`，则不移动时间步长。

+   `original_inference_steps` (`int`, *可选*) — 原始推断步数，将用于生成线性间隔的时间步长计划（与标准`diffusers`实现不同）。然后我们将从该计划中取`num_inference_steps`个时间步长，以索引均匀间隔，并将其用作我们的最终时间步长计划。如果未设置，将默认为`original_inference_steps`属性。

+   `timesteps` (`List[int]`, *可选*) — 用于支持时间步长之间任意间隔的自定义时间步长。如果为`None`，则使用默认的时间步长间隔策略，即在训练/蒸馏时间步长计划上的时间步长均匀间隔。如果传递了`timesteps`，则`num_inference_steps`必须为`None`。

设置用于扩散链的离散时间步长（在推断之前运行）。

#### `step`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_lcm.py#L474)

```py
( model_output: FloatTensor timestep: int sample: FloatTensor generator: Optional = None return_dict: bool = True ) → export const metadata = 'undefined';~schedulers.scheduling_utils.LCMSchedulerOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出的结果。

+   `timestep` (`float`) — 扩散链中的当前离散时间步长。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的样本的当前实例。

+   `generator` (`torch.Generator`，*可选*) — 一个随机数生成器。

+   `return_dict` (`bool`，*可选*，默认为`True`) — 是否返回`LCMSchedulerOutput`或`tuple`。

返回

`~schedulers.scheduling_utils.LCMSchedulerOutput`或`tuple`

如果`return_dict`为`True`，则返回`LCMSchedulerOutput`，否则返回一个元组，其中第一个元素是样本张量。

通过反转SDE来预测上一个时间步的样本。这个函数从学习模型的输出（通常是预测的噪音）中传播扩散过程。
