["```py\n( vae: AutoencoderKL text_encoder: CLIPTextModel tokenizer: CLIPTokenizer unet: UNet2DConditionModel scheduler: KarrasDiffusionSchedulers safety_checker: StableDiffusionSafetyChecker feature_extractor: CLIPImageProcessor requires_safety_checker: bool = True )\n```", "```py\n( prompt: Union token_indices: Union height: Optional = None width: Optional = None num_inference_steps: int = 50 guidance_scale: float = 7.5 negative_prompt: Union = None num_images_per_prompt: int = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None max_iter_to_alter: int = 25 thresholds: dict = {0: 0.05, 10: 0.5, 20: 0.8} scale_factor: int = 20 attn_res: Optional = (16, 16) clip_skip: Optional = None ) \u2192 export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple\n```", "```py\n>>> import torch\n>>> from diffusers import StableDiffusionAttendAndExcitePipeline\n\n>>> pipe = StableDiffusionAttendAndExcitePipeline.from_pretrained(\n...     \"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16\n... ).to(\"cuda\")\n\n>>> prompt = \"a cat and a frog\"\n\n>>> # use get_indices function to find out indices of the tokens you want to alter\n>>> pipe.get_indices(prompt)\n{0: '<|startoftext|>', 1: 'a</w>', 2: 'cat</w>', 3: 'and</w>', 4: 'a</w>', 5: 'frog</w>', 6: '<|endoftext|>'}\n\n>>> token_indices = [2, 5]\n>>> seed = 6141\n>>> generator = torch.Generator(\"cuda\").manual_seed(seed)\n\n>>> images = pipe(\n...     prompt=prompt,\n...     token_indices=token_indices,\n...     guidance_scale=7.5,\n...     generator=generator,\n...     num_inference_steps=50,\n...     max_iter_to_alter=25,\n... ).images\n\n>>> image = images[0]\n>>> image.save(f\"../images/{prompt}_{seed}.png\")\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( prompt device num_images_per_prompt do_classifier_free_guidance negative_prompt = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None lora_scale: Optional = None clip_skip: Optional = None )\n```", "```py\n( prompt: str )\n```", "```py\n( images: Union nsfw_content_detected: Optional )\n```"]