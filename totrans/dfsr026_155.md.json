["```py\npip install -U bitsandbytes\n```", "```py\nfrom transformers import T5EncoderModel\nfrom diffusers import PixArtAlphaPipeline\nimport torch\n\ntext_encoder = T5EncoderModel.from_pretrained(\n    \"PixArt-alpha/PixArt-XL-2-1024-MS\",\n    subfolder=\"text_encoder\",\n    load_in_8bit=True,\n    device_map=\"auto\",\n\n)\npipe = PixArtAlphaPipeline.from_pretrained(\n    \"PixArt-alpha/PixArt-XL-2-1024-MS\",\n    text_encoder=text_encoder,\n    transformer=None,\n    device_map=\"auto\"\n)\n```", "```py\nwith torch.no_grad():\n    prompt = \"cute cat\"\n    prompt_embeds, prompt_attention_mask, negative_embeds, negative_prompt_attention_mask = pipe.encode_prompt(prompt)\n```", "```py\nimport gc \n\ndef flush():\n    gc.collect()\n    torch.cuda.empty_cache()\n\ndel text_encoder\ndel pipe\nflush()\n```", "```py\npipe = PixArtAlphaPipeline.from_pretrained(\n    \"PixArt-alpha/PixArt-XL-2-1024-MS\",\n    text_encoder=None,\n    torch_dtype=torch.float16,\n).to(\"cuda\")\n\nlatents = pipe(\n    negative_prompt=None, \n    prompt_embeds=prompt_embeds,\n    negative_prompt_embeds=negative_embeds,\n    prompt_attention_mask=prompt_attention_mask,\n    negative_prompt_attention_mask=negative_prompt_attention_mask,\n    num_images_per_prompt=1,\n    output_type=\"latent\",\n).images\n\ndel pipe.transformer\nflush()\n```", "```py\nwith torch.no_grad():\n    image = pipe.vae.decode(latents / pipe.vae.config.scaling_factor, return_dict=False)[0]\nimage = pipe.image_processor.postprocess(image, output_type=\"pil\")[0]\nimage.save(\"cat.png\")\n```", "```py\n( tokenizer: T5Tokenizer text_encoder: T5EncoderModel vae: AutoencoderKL transformer: Transformer2DModel scheduler: DPMSolverMultistepScheduler )\n```", "```py\n( prompt: Union = None negative_prompt: str = '' num_inference_steps: int = 20 timesteps: List = None guidance_scale: float = 4.5 num_images_per_prompt: Optional = 1 height: Optional = None width: Optional = None eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None prompt_attention_mask: Optional = None negative_prompt_embeds: Optional = None negative_prompt_attention_mask: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 clean_caption: bool = True use_resolution_binning: bool = True **kwargs ) \u2192 export const metadata = 'undefined';ImagePipelineOutput or tuple\n```", "```py\n>>> import torch\n>>> from diffusers import PixArtAlphaPipeline\n\n>>> # You can replace the checkpoint id with \"PixArt-alpha/PixArt-XL-2-512x512\" too.\n>>> pipe = PixArtAlphaPipeline.from_pretrained(\"PixArt-alpha/PixArt-XL-2-1024-MS\", torch_dtype=torch.float16)\n>>> # Enable memory optimizations.\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = \"A small cactus with a happy face in the Sahara desert.\"\n>>> image = pipe(prompt).images[0]\n```", "```py\n( height: int width: int ratios: dict )\n```", "```py\n( prompt: Union do_classifier_free_guidance: bool = True negative_prompt: str = '' num_images_per_prompt: int = 1 device: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None prompt_attention_mask: Optional = None negative_prompt_attention_mask: Optional = None clean_caption: bool = False **kwargs )\n```"]