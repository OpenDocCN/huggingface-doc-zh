["```py\n>>> import torch\n>>> from transformers import Speech2Text2Processor, SpeechEncoderDecoderModel\n>>> from datasets import load_dataset\n>>> import soundfile as sf\n\n>>> model = SpeechEncoderDecoderModel.from_pretrained(\"facebook/s2t-wav2vec2-large-en-de\")\n>>> processor = Speech2Text2Processor.from_pretrained(\"facebook/s2t-wav2vec2-large-en-de\")\n\n>>> def map_to_array(batch):\n...     speech, _ = sf.read(batch[\"file\"])\n...     batch[\"speech\"] = speech\n...     return batch\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> ds = ds.map(map_to_array)\n\n>>> inputs = processor(ds[\"speech\"][0], sampling_rate=16_000, return_tensors=\"pt\")\n>>> generated_ids = model.generate(inputs=inputs[\"input_values\"], attention_mask=inputs[\"attention_mask\"])\n\n>>> transcription = processor.batch_decode(generated_ids)\n```", "```py\n>>> from datasets import load_dataset\n>>> from transformers import pipeline\n\n>>> librispeech_en = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> asr = pipeline(\n...     \"automatic-speech-recognition\",\n...     model=\"facebook/s2t-wav2vec2-large-en-de\",\n...     feature_extractor=\"facebook/s2t-wav2vec2-large-en-de\",\n... )\n\n>>> translation_de = asr(librispeech_en[0][\"file\"])\n```", "```py\n>>> from transformers import Speech2Text2Config, Speech2Text2ForCausalLM\n\n>>> # Initializing a Speech2Text2 s2t_transformer_s style configuration\n>>> configuration = Speech2Text2Config()\n\n>>> # Initializing a model (with random weights) from the s2t_transformer_s style configuration\n>>> model = Speech2Text2ForCausalLM(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import (\n...     SpeechEncoderDecoderModel,\n...     Speech2Text2ForCausalLM,\n...     Wav2Vec2Model,\n...     Speech2Text2Config,\n...     Wav2Vec2Config,\n...     Wav2Vec2FeatureExtractor,\n...     Speech2Text2Tokenizer,\n... )\n>>> from datasets import load_dataset\n\n>>> feature_extractor = Wav2Vec2FeatureExtractor()\n>>> tokenizer = Speech2Text2Tokenizer.from_pretrained(\"facebook/s2t-wav2vec2-large-en-de\")\n\n>>> encoder = Wav2Vec2Model(Wav2Vec2Config())\n>>> decoder = Speech2Text2ForCausalLM(Speech2Text2Config())\n>>> # init random speech2text model\n\n>>> model = SpeechEncoderDecoderModel(encoder=encoder, decoder=decoder)\n>>> model.config.pad_token_id = tokenizer.pad_token_id\n>>> model.config.decoder_start_token_id = tokenizer.bos_token_id\n>>> # pre-process inputs and labels\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> inputs = feature_extractor(\n...     ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\"\n... )\n>>> input_values = inputs.input_values\n>>> decoder_input_ids = tokenizer(ds[0][\"text\"], return_tensors=\"pt\").input_ids\n>>> # compute loss\n\n>>> loss = model(inputs=input_values, labels=decoder_input_ids).loss\n>>> # backprop loss\n\n>>> loss.backward()\n```"]