# Wav2Vec2Phoneme

> 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/wav2vec2_phoneme](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/wav2vec2_phoneme)

## 概述

Wav2Vec2Phoneme模型是由Qiantong Xu、Alexei Baevski、Michael Auli在[Simple and Effective Zero-shot Cross-lingual Phoneme Recognition (Xu et al., 2021](https://arxiv.org/abs/2109.11680)中提出的。

该论文的摘要如下：

*最近在自训练、自监督预训练和无监督学习方面取得的进展使得语音识别系统在没有任何标记数据的情况下表现良好。然而，在许多情况下，存在相关语言的标记数据，但这些方法没有利用这些数据。本文通过微调多语言预训练的wav2vec 2.0模型来扩展之前关于零样本跨语言迁移学习的工作，以转录未见过的语言。这是通过使用发音特征将训练语言的音素映射到目标语言来实现的。实验证明，这种简单的方法明显优于之前引入了任务特定架构并且仅使用了部分单语预训练模型的工作。*

相关的检查点可以在[https://huggingface.co/models?other=phoneme-recognition](https://huggingface.co/models?other=phoneme-recognition)下找到。

该模型由[patrickvonplaten](https://huggingface.co/patrickvonplaten)贡献

原始代码可以在[这里](https://github.com/pytorch/fairseq/tree/master/fairseq/models/wav2vec)找到。

## 使用提示

+   Wav2Vec2Phoneme使用与Wav2Vec2完全相同的架构

+   Wav2Vec2Phoneme是一个接受与语音信号的原始波形对应的浮点数组的语音模型。

+   Wav2Vec2Phoneme模型是使用连接主义时间分类（CTC）进行训练的，因此模型输出必须使用[Wav2Vec2PhonemeCTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer)进行解码。

+   Wav2Vec2Phoneme可以同时在多种语言上进行微调，并在单次前向传递中将未见过的语言解码为一系列音素。

+   默认情况下，该模型输出一系列音素。为了将音素转换为一系列单词，应该使用字典和语言模型。

Wav2Vec2Phoneme的架构基于Wav2Vec2模型，有关API参考，请查看[`Wav2Vec2`](wav2vec2)的文档页面，除了标记器。

## Wav2Vec2PhonemeCTCTokenizer

### `class transformers.Wav2Vec2PhonemeCTCTokenizer`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py#L94)

```py
( vocab_file bos_token = '<s>' eos_token = '</s>' unk_token = '<unk>' pad_token = '<pad>' phone_delimiter_token = ' ' word_delimiter_token = None do_phonemize = True phonemizer_lang = 'en-us' phonemizer_backend = 'espeak' **kwargs )
```

参数

+   `vocab_file` (`str`) — 包含词汇表的文件。

+   `bos_token` (`str`, *可选*，默认为`"<s>"`) — 句子开始标记。

+   `eos_token` (`str`, *可选*，默认为`"</s>"`) — 句子结束标记。

+   `unk_token` (`str`, *可选*，默认为`"<unk>"`) — 未知标记。词汇表中没有的标记无法转换为ID，而是设置为此标记。

+   `pad_token` (`str`, *可选*，默认为`"<pad>"`) — 用于填充的标记，例如在批处理不同长度的序列时。

+   `do_phonemize` (`bool`, *可选*，默认为`True`) — 标记器是否应该对输入进行音素化。只有当将一系列音素传递给标记器时，`do_phonemize`应设置为`False`。

+   `phonemizer_lang` (`str`, *可选*，默认为`"en-us"`) — 标记器应将输入文本音素化为的音素集的语言。

+   `phonemizer_backend` (`str`, *可选*，默认为`"espeak"`) — 由音素化库使用的后端音素化库。默认为`espeak-ng`。更多信息请参见[phonemizer package](https://github.com/bootphon/phonemizer#readme)。

    **kwargs — 传递给[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)的额外关键字参数

构建一个Wav2Vec2PhonemeCTC分词器。

该分词器继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含一些主要方法。用户应参考超类以获取有关这些方法的更多信息。

#### `__call__`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L2729)

```py
( text: Union = None text_pair: Union = None text_target: Union = None text_pair_target: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 is_split_into_words: bool = False pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs ) → export const metadata = 'undefined';BatchEncoding
```

参数

+   `text` (`str`, `List[str]`, `List[List[str]]`, *可选*) — 要编码的序列或序列批次。每个序列可以是字符串或字符串列表（预分词字符串）。如果序列以字符串列表（预分词）的形式提供，则必须设置`is_split_into_words=True`（以消除与批次序列的歧义）。

+   `text_pair` (`str`, `List[str]`, `List[List[str]]`, *可选*) — 要编码的序列或序列批次。每个序列可以是字符串或字符串列表（预分词字符串）。如果序列以字符串列表（预分词）的形式提供，则必须设置`is_split_into_words=True`（以消除与批次序列的歧义）。

+   `text_target` (`str`, `List[str]`, `List[List[str]]`, *可选*) — 要编码为目标文本的序列或序列批次。每个序列可以是字符串或字符串列表（预分词字符串）。如果序列以字符串列表（预分词）的形式提供，则必须设置`is_split_into_words=True`（以消除与批次序列的歧义）。

+   `text_pair_target` (`str`, `List[str]`, `List[List[str]]`, *可选*) — 要编码为目标文本的序列或序列批次。每个序列可以是字符串或字符串列表（预分词字符串）。如果序列以字符串列表（预分词）的形式提供，则必须设置`is_split_into_words=True`（以消除与批次序列的歧义）。

+   `add_special_tokens` (`bool`, *可选*, 默认为 `True`) — 在编码序列时是否添加特殊标记。这将使用底层的`PretrainedTokenizerBase.build_inputs_with_special_tokens`函数，该函数定义了自动添加到输入id的标记。如果要自动添加`bos`或`eos`标记，则这很有用。

+   `padding` (`bool`, `str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy), *可选*, 默认为 `False`) — 激活和控制填充。接受以下值：

    +   `True` 或 `'longest'`: 填充到批次中最长的序列（如果只提供单个序列，则不填充）。

    +   `'max_length'`: 填充到指定的最大长度或模型的最大可接受输入长度（如果未提供该参数）。

    +   `False` 或 `'do_not_pad'`（默认）: 不填充（即，可以输出长度不同的序列批次）。

+   `truncation` (`bool`, `str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy), *可选*, 默认为 `False`) — 激活和控制截断。接受以下值：

    +   `True` 或 `'longest_first'`: 截断到指定的最大长度或模型的最大可接受输入长度（如果未提供该参数）。这将逐标记截断，如果提供了一对序列（或一批对序列），则从该对中最长的序列中删除一个标记。

    +   `'only_first'`: 截断到指定的最大长度或模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则仅截断第一个序列。

    +   `'only_second'`: 截断到指定的最大长度，由参数 `max_length` 指定，或者截断到模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对输入 ID 序列（或一批对），并且 `truncation_strategy = longest_first` 或 `True`，则会引发错误，而不是返回溢出标记。

    +   `False` 或 `'do_not_truncate'`（默认）：不截断（即，可以输出长度大于模型最大可接受输入大小的批次）。

+   `max_length` (`int`, *optional*) — 控制截断/填充参数之一使用的最大长度。

    如果未设置或设置为 `None`，则将使用预定义的模型最大长度（如果截断/填充参数需要最大长度）。如果模型没有特定的最大输入长度（如 XLNet），则将禁用截断/填充到最大长度。

+   `stride` (`int`, *optional*, defaults to 0) — 如果设置为一个数字，并且与 `max_length` 一起使用，当 `return_overflowing_tokens=True` 时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。该参数的值定义了重叠标记的数量。

+   `is_split_into_words` (`bool`, *optional*, 默认为 `False`) — 输入是否已经预分词（例如，已经分成单词）。如果设置为 `True`，分词器会假定输入已经分成单词（例如，通过在空格上分割），然后对其进行分词。这对于 NER 或标记分类很有用。

+   `pad_to_multiple_of` (`int`, *optional*) — 如果设置，将填充序列到提供的值的倍数。需要激活 `padding`。这对于启用 NVIDIA 硬件上的 Tensor Cores 特别有用，计算能力 `>= 7.5`（Volta）。

+   `return_tensors` (`str` 或 [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType), *optional*) — 如果设置，将返回张量而不是 Python 整数列表。可接受的值为：

    +   `'tf'`: 返回 TensorFlow `tf.constant` 对象。

    +   `'pt'`: 返回 PyTorch `torch.Tensor` 对象。

    +   `'np'`: 返回 Numpy `np.ndarray` 对象。

+   `return_token_type_ids` (`bool`, *optional*) — 是否返回标记类型 ID。如果保持默认设置，将根据特定分词器的默认值返回标记类型 ID，由 `return_outputs` 属性定义。

    [什么是标记类型 ID？](../glossary#token-type-ids)

+   `return_attention_mask` (`bool`, *optional`) — 是否返回注意力掩码。如果保持默认设置，将根据特定分词器的默认值返回注意力掩码，由 `return_outputs` 属性定义。

    [什么是注意力掩码？](../glossary#attention-mask)

+   `return_overflowing_tokens` (`bool`, *optional*, 默认为 `False`) — 是否返回溢出标记序列。如果提供了一对输入 ID 序列（或一批对），并且 `truncation_strategy = longest_first` 或 `True`，则会引发错误，而不是返回溢出标记。

+   `return_special_tokens_mask` (`bool`, *optional*, 默认为 `False`) — 是否返回特殊标记掩码信息。

+   `return_offsets_mapping` (`bool`, *optional*, 默认为 `False`) — 是否返回每个标记的 `(char_start, char_end)`。

    仅适用于继承自 [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast) 的快速分词器，如果使用 Python 的分词器，此方法将引发 `NotImplementedError`。

+   `return_length` (`bool`, *optional*, 默认为 `False`) — 是否返回编码输入的长度。

+   `verbose` (`bool`, *optional*, 默认为 `True`) — 是否打印更多信息和警告。**kwargs — 传递给 `self.tokenize()` 方法

返回

[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)

一个具有以下字段的[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)：

+   `input_ids` — 要提供给模型的标记id列表。

    [什么是输入ID？](../glossary#input-ids)

+   `token_type_ids` — 要提供给模型的标记类型id列表（当`return_token_type_ids=True`或*`token_type_ids`*在`self.model_input_names`中时）。

    [什么是标记类型ID？](../glossary#token-type-ids)

+   `attention_mask` — 指定哪些标记应由模型关注的索引列表（当`return_attention_mask=True`或*`attention_mask`*在`self.model_input_names`中时）。

    [什么是注意力掩码？](../glossary#attention-mask)

+   `overflowing_tokens` — 溢出的标记序列列表（当指定`max_length`并且`return_overflowing_tokens=True`时）。

+   `num_truncated_tokens` — 截断的标记数（当指定`max_length`并且`return_overflowing_tokens=True`时）。

+   `special_tokens_mask` — 由0和1组成的列表，其中1指定添加的特殊标记，0指定常规序列标记（当`add_special_tokens=True`和`return_special_tokens_mask=True`时）。

+   `length` — 输入的长度（当`return_length=True`时）

将一个或多个序列或一个或多个序列对进行标记化和准备模型的主要方法。

#### `batch_decode`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py#L527)

```py
( sequences: Union skip_special_tokens: bool = False clean_up_tokenization_spaces: bool = None output_char_offsets: bool = False **kwargs ) → export const metadata = 'undefined';List[str] or ~models.wav2vec2.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizerOutput
```

参数

+   `sequences`（`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`） — 标记化输入id的列表。可以使用`__call__`方法获得。

+   `skip_special_tokens`（`bool`，*可选*，默认为`False`） — 是否在解码中删除特殊标记。

+   `clean_up_tokenization_spaces`（`bool`，*可选*） — 是否清除标记化空格。

+   `output_char_offsets`（`bool`，*可选*，默认为`False`） — 是否输出字符偏移。字符偏移可以与采样率和模型下采样率结合使用，计算转录字符的时间戳。

    请查看`~models.wav2vec2.tokenization_wav2vec2.decode`的示例，以更好地理解如何使用`output_word_offsets`。`~model.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.batch_decode`与音素和批处理输出的处理方式类似。

+   `kwargs`（其他关键字参数，*可选*） — 将传递给底层模型特定的解码方法。

返回

`List[str]`或`~models.wav2vec2.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizerOutput`

解码后的句子。当`output_char_offsets == True`时，将是`~models.wav2vec2.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizerOutput`。

通过调用解码将标记id的列表列表转换为字符串列表。

#### `decode`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py#L471)

```py
( token_ids: Union skip_special_tokens: bool = False clean_up_tokenization_spaces: bool = None output_char_offsets: bool = False **kwargs ) → export const metadata = 'undefined';str or ~models.wav2vec2.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizerOutput
```

参数

+   `token_ids`（`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`） — 标记化输入id的列表。可以使用`__call__`方法获得。

+   `skip_special_tokens`（`bool`，*可选*，默认为`False`） — 是否在解码中删除特殊标记。

+   `clean_up_tokenization_spaces`（`bool`，*可选*） — 是否清除标记化空格。

+   `output_char_offsets`（`bool`，*可选*，默认为`False`） — 是否输出字符偏移。字符偏移可以与采样率和模型下采样率结合使用，计算转录字符的时间戳。

    请查看`~models.wav2vec2.tokenization_wav2vec2.decode`的示例，以更好地理解如何使用`output_word_offsets`。`~model.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.batch_decode`与音素的处理方式相同。

+   `kwargs`（额外的关键字参数，*可选*）- 将传递给底层模型特定的解码方法。

返回

`str` 或 `~models.wav2vec2.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizerOutput`

解码后的句子。当 `output_char_offsets == True` 时，将是一个 `~models.wav2vec2.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizerOutput`。

将一系列id转换为字符串，使用分词器和词汇表，可以选择删除特殊标记并清理分词空格。

类似于执行 `self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`。

`phonemize`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py#L269)

```py
( text: str phonemizer_lang: Optional = None )
```
