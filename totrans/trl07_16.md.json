["```py\ndpo_dataset_dict = {\n    \"prompt\": [\n        \"hello\",\n        \"how are you\",\n        \"What is your name?\",\n        \"What is your name?\",\n        \"Which is the best programming language?\",\n        \"Which is the best programming language?\",\n        \"Which is the best programming language?\",\n    ],\n    \"chosen\": [\n        \"hi nice to meet you\",\n        \"I am fine\",\n        \"My name is Mary\",\n        \"My name is Mary\",\n        \"Python\",\n        \"Python\",\n        \"Java\",\n    ],\n    \"rejected\": [\n        \"leave me alone\",\n        \"I am not fine\",\n        \"Whats it to you?\",\n        \"I dont have a name\",\n        \"Javascript\",\n        \"C++\",\n        \"C++\",\n    ],\n}\n```", "```py\n dpo_trainer = DPOTrainer(\n    model,\n    model_ref,\n    args=training_args,\n    beta=0.1,\n    train_dataset=train_dataset,\n    tokenizer=tokenizer,\n)\n```", "```py\ndpo_trainer.train()\n```", "```py\nimport torch\nfrom transformers import TrainingArguments\nfrom trl import DPOTrainer\nfrom unsloth import FastLanguageModel\n\nmax_seq_length = 2048 # Supports automatic RoPE Scaling, so choose any number.\n\n# Load model\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/zephyr-sft\",\n    max_seq_length = max_seq_length,\n    dtype = None, # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n    load_in_4bit = True, # Use 4bit quantization to reduce memory usage. Can be False.\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)\n\n# Do model patching and add fast LoRA weights\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 16,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Dropout = 0 is currently optimized\n    bias = \"none\",    # Bias = \"none\" is currently optimized\n    use_gradient_checkpointing = True,\n    random_state = 3407,\n)\n\nargs = TrainingArguments(output_dir=\"./output\")\n\ndpo_trainer = DPOTrainer(\n    model,\n    model_ref=None,\n    args=training_args,\n    beta=0.1,\n    train_dataset=train_dataset,\n    tokenizer=tokenizer,\n)\ndpo_trainer.train()\n```", "```py\n# Load the base model.\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    llm_int8_threshold=6.0,\n    llm_int8_has_fp16_weight=False,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/mixtral-8x7b-v0.1\",\n    load_in_4bit=True,\n    quantization_config=bnb_config,\n    attn_implementation=\"flash_attention_2\",\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n)\nmodel.config.use_cache = False\n\n# Load the adapter.\nmodel = PeftModel.from_pretrained(\n    model,\n    \"/path/to/peft\",\n    is_trainable=True,\n    adapter_name=\"train\",\n)\n# Load the adapter a second time, with a different name, which will be our reference model.\nmodel.load_adapter(\"/path/to/peft\", adapter_name=\"reference\")\n\n# Initialize the trainer, without a ref_model param.\ndpo_trainer = DPOTrainer(\n    model,\n    ...\n    model_adapter_name=\"train\",\n    ref_adapter_name=\"reference\",\n)\n```", "```py\n( model: Union = None ref_model: Union = None beta: float = 0.1 label_smoothing: float = 0 loss_type: Literal = 'sigmoid' args: TrainingArguments = None data_collator: Optional = None label_pad_token_id: int = -100 padding_value: int = 0 truncation_mode: str = 'keep_end' train_dataset: Optional = None eval_dataset: Union = None tokenizer: Optional = None model_init: Optional = None callbacks: Optional = None optimizers: Tuple = (None, None) preprocess_logits_for_metrics: Optional = None max_length: Optional = None max_prompt_length: Optional = None max_target_length: Optional = None peft_config: Optional = None is_encoder_decoder: Optional = None disable_dropout: bool = True generate_during_eval: bool = False compute_metrics: Optional = None precompute_ref_log_probs: bool = False model_init_kwargs: Optional = None ref_model_init_kwargs: Optional = None model_adapter_name: str = None ref_adapter_name: str = None )\n```", "```py\n( prompt answer )\n```", "```py\n( padded_batch: Dict )\n```", "```py\n( model: Module batch: Dict )\n```", "```py\n( batch: Dict is_encoder_decoder: bool = False label_pad_token_id: int = -100 padding_value: int = 0 device: Optional = None )\n```", "```py\n( policy_chosen_logps: FloatTensor policy_rejected_logps: FloatTensor reference_chosen_logps: FloatTensor reference_rejected_logps: FloatTensor reference_free: bool = False ) \u2192 export const metadata = 'undefined';A tuple of three tensors\n```", "```py\n( dataloader: DataLoader description: str prediction_loss_only: Optional = None ignore_keys: Optional = None metric_key_prefix: str = 'eval' )\n```", "```py\n( logits: FloatTensor labels: LongTensor average_log_prob: bool = False label_pad_token_id: int = -100 is_encoder_decoder: bool = False )\n```", "```py\n( model batch: Dict train_eval: Literal = 'train' )\n```", "```py\n( model batch: Dict )\n```", "```py\n( eval_dataset: Optional = None )\n```", "```py\n( )\n```", "```py\n( logs: Dict )\n```", "```py\n( )\n```", "```py\n( feature model: Union = None )\n```"]