["```py\ngeneration_kwargs = {\n    \"min_length\": -1, # don't ignore the EOS token (see above)\n    \"top_k\": 0.0, # no top-k sampling\n    \"top_p\": 1.0, # no nucleus sampling\n    \"do_sample\": True, # yes, we want to sample\n    \"pad_token_id\": tokenizer.eos_token_id, # most decoder models don't have a padding token - use EOS token instead\n    \"max_new_tokens\": 32, # specify how many tokens you want to generate at most\n}\n```"]