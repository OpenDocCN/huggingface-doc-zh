["```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n)\npipe = pipe.to(\"cuda\")\n\nprompt = \"a photo of an astronaut riding a horse on mars\"\npipe.enable_vae_slicing()\n#pipe.enable_xformers_memory_efficient_attention()\nimages = pipe([prompt] * 32).images\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline, UniPCMultistepScheduler\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n)\npipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\npipe = pipe.to(\"cuda\")\nprompt = \"a beautiful landscape photograph\"\npipe.enable_vae_tiling()\n#pipe.enable_xformers_memory_efficient_attention()\n\nimage = pipe([prompt], width=3840, height=2224, num_inference_steps=20).images[0]\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n)\n\nprompt = \"a photo of an astronaut riding a horse on mars\"\npipe.enable_sequential_cpu_offload()\nimage = pipe(prompt).images[0]\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n)\n\nprompt = \"a photo of an astronaut riding a horse on mars\"\npipe.enable_model_cpu_offload()\nimage = pipe(prompt).images[0]\n```", "```py\nprint(pipe.unet.conv_out.state_dict()[\"weight\"].stride())  # (2880, 9, 3, 1)\npipe.unet.to(memory_format=torch.channels_last)  # in-place operation\nprint(\n    pipe.unet.conv_out.state_dict()[\"weight\"].stride()\n)  # (2880, 1, 960, 320) having a stride of 1 for the 2nd dimension proves that it works\n```", "```py\nimport time\nimport torch\nfrom diffusers import StableDiffusionPipeline\nimport functools\n\n# torch disable grad\ntorch.set_grad_enabled(False)\n\n# set variables\nn_experiments = 2\nunet_runs_per_experiment = 50\n\n# load inputs\ndef generate_inputs():\n    sample = torch.randn((2, 4, 64, 64), device=\"cuda\", dtype=torch.float16)\n    timestep = torch.rand(1, device=\"cuda\", dtype=torch.float16) * 999\n    encoder_hidden_states = torch.randn((2, 77, 768), device=\"cuda\", dtype=torch.float16)\n    return sample, timestep, encoder_hidden_states\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n).to(\"cuda\")\nunet = pipe.unet\nunet.eval()\nunet.to(memory_format=torch.channels_last)  # use channels_last memory format\nunet.forward = functools.partial(unet.forward, return_dict=False)  # set return_dict=False as default\n\n# warmup\nfor _ in range(3):\n    with torch.inference_mode():\n        inputs = generate_inputs()\n        orig_output = unet(*inputs)\n\n# trace\nprint(\"tracing..\")\nunet_traced = torch.jit.trace(unet, inputs)\nunet_traced.eval()\nprint(\"done tracing\")\n\n# warmup and optimize graph\nfor _ in range(5):\n    with torch.inference_mode():\n        inputs = generate_inputs()\n        orig_output = unet_traced(*inputs)\n\n# benchmarking\nwith torch.inference_mode():\n    for _ in range(n_experiments):\n        torch.cuda.synchronize()\n        start_time = time.time()\n        for _ in range(unet_runs_per_experiment):\n            orig_output = unet_traced(*inputs)\n        torch.cuda.synchronize()\n        print(f\"unet traced inference took {time.time() - start_time:.2f} seconds\")\n    for _ in range(n_experiments):\n        torch.cuda.synchronize()\n        start_time = time.time()\n        for _ in range(unet_runs_per_experiment):\n            orig_output = unet(*inputs)\n        torch.cuda.synchronize()\n        print(f\"unet inference took {time.time() - start_time:.2f} seconds\")\n\n# save the model\nunet_traced.save(\"unet_traced.pt\")\n```", "```py\nfrom diffusers import StableDiffusionPipeline\nimport torch\nfrom dataclasses import dataclass\n\n@dataclass\nclass UNet2DConditionOutput:\n    sample: torch.FloatTensor\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n).to(\"cuda\")\n\n# use jitted unet\nunet_traced = torch.jit.load(\"unet_traced.pt\")\n\n# del pipe.unet\nclass TracedUNet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.in_channels = pipe.unet.config.in_channels\n        self.device = pipe.unet.device\n\n    def forward(self, latent_model_input, t, encoder_hidden_states):\n        sample = unet_traced(latent_model_input, t, encoder_hidden_states)[0]\n        return UNet2DConditionOutput(sample=sample)\n\npipe.unet = TracedUNet()\n\nwith torch.inference_mode():\n    image = pipe([prompt] * 1, num_inference_steps=50).images[0]\n```", "```py\nfrom diffusers import DiffusionPipeline\nimport torch\n\npipe = DiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16,\n    use_safetensors=True,\n).to(\"cuda\")\n\npipe.enable_xformers_memory_efficient_attention()\n\nwith torch.inference_mode():\n    sample = pipe(\"a small cat\")\n\n# optional: You can disable it via\n# pipe.disable_xformers_memory_efficient_attention()\n```"]