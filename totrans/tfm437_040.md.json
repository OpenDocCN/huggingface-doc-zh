["```py\npip install transformers datasets evaluate -q\npip install jiwer -q\n```", "```py\nfrom huggingface_hub import notebook_login\n\nnotebook_login()\n```", "```py\nfrom datasets import load_dataset\n\nds = load_dataset(\"lambdalabs/pokemon-blip-captions\")\nds\n```", "```py\nDatasetDict({\n    train: Dataset({\n        features: ['image', 'text'],\n        num_rows: 833\n    })\n})\n```", "```py\nds = ds[\"train\"].train_test_split(test_size=0.1)\ntrain_ds = ds[\"train\"]\ntest_ds = ds[\"test\"]\n```", "```py\nfrom textwrap import wrap\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_images(images, captions):\n    plt.figure(figsize=(20, 20))\n    for i in range(len(images)):\n        ax = plt.subplot(1, len(images), i + 1)\n        caption = captions[i]\n        caption = \"\\n\".join(wrap(caption, 12))\n        plt.title(caption)\n        plt.imshow(images[i])\n        plt.axis(\"off\")\n\nsample_images_to_visualize = [np.array(train_ds[i][\"image\"]) for i in range(5)]\nsample_captions = [train_ds[i][\"text\"] for i in range(5)]\nplot_images(sample_images_to_visualize, sample_captions)\n```", "```py\nfrom transformers import AutoProcessor\n\ncheckpoint = \"microsoft/git-base\"\nprocessor = AutoProcessor.from_pretrained(checkpoint)\n```", "```py\ndef transforms(example_batch):\n    images = [x for x in example_batch[\"image\"]]\n    captions = [x for x in example_batch[\"text\"]]\n    inputs = processor(images=images, text=captions, padding=\"max_length\")\n    inputs.update({\"labels\": inputs[\"input_ids\"]})\n    return inputs\n\ntrain_ds.set_transform(transforms)\ntest_ds.set_transform(transforms)\n```", "```py\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint)\n```", "```py\nfrom evaluate import load\nimport torch\n\nwer = load(\"wer\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predicted = logits.argmax(-1)\n    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=True)\n    wer_score = wer.compute(predictions=decoded_predictions, references=decoded_labels)\n    return {\"wer_score\": wer_score}\n```", "```py\nfrom transformers import TrainingArguments, Trainer\n\nmodel_name = checkpoint.split(\"/\")[1]\n\ntraining_args = TrainingArguments(\n    output_dir=f\"{model_name}-pokemon\",\n    learning_rate=5e-5,\n    num_train_epochs=50,\n    fp16=True,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    gradient_accumulation_steps=2,\n    save_total_limit=3,\n    evaluation_strategy=\"steps\",\n    eval_steps=50,\n    save_strategy=\"steps\",\n    save_steps=50,\n    logging_steps=50,\n    remove_unused_columns=False,\n    push_to_hub=True,\n    label_names=[\"labels\"],\n    load_best_model_at_end=True,\n)\n```", "```py\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    compute_metrics=compute_metrics,\n)\n```", "```py\ntrainer.train()\n```", "```py\ntrainer.push_to_hub()\n```", "```py\nfrom PIL import Image\nimport requests\n\nurl = \"https://huggingface.co/datasets/sayakpaul/sample-datasets/resolve/main/pokemon.png\"\nimage = Image.open(requests.get(url, stream=True).raw)\nimage\n```", "```py\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ninputs = processor(images=image, return_tensors=\"pt\").to(device)\npixel_values = inputs.pixel_values\n```", "```py\ngenerated_ids = model.generate(pixel_values=pixel_values, max_length=50)\ngenerated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\nprint(generated_caption)\n```", "```py\na drawing of a pink and blue pokemon\n```"]