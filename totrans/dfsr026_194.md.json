["```py\n( num_train_timesteps: int = 1000 beta_start: float = 0.0001 beta_end: float = 0.02 beta_schedule: str = 'linear' trained_betas: Optional = None solver_order: int = 2 prediction_type: str = 'epsilon' thresholding: bool = False dynamic_thresholding_ratio: float = 0.995 sample_max_value: float = 1.0 algorithm_type: str = 'dpmsolver++' solver_type: str = 'midpoint' lower_order_final: bool = False use_karras_sigmas: Optional = False final_sigmas_type: Optional = 'zero' lambda_min_clipped: float = -inf variance_type: Optional = None )\n```", "```py\n( model_output: FloatTensor *args sample: FloatTensor = None **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( model_output: FloatTensor *args sample: FloatTensor = None **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( num_inference_steps: int )\n```", "```py\n( sample: FloatTensor *args **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( num_inference_steps: int device: Union = None )\n```", "```py\n( model_output_list: List *args sample: FloatTensor = None **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( model_output_list: List *args sample: FloatTensor = None **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( model_output_list: List *args sample: FloatTensor = None order: int = None **kwargs ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( model_output: FloatTensor timestep: int sample: FloatTensor return_dict: bool = True ) \u2192 export const metadata = 'undefined';SchedulerOutput or tuple\n```", "```py\n( prev_sample: FloatTensor )\n```"]