["```py\npip install transformers datasets evaluate\n```", "```py\n>>> from huggingface_hub import notebook_login\n\n>>> notebook_login()\n```", "```py\n>>> from datasets import load_dataset, Audio\n\n>>> minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n```", "```py\n>>> minds = minds.train_test_split(test_size=0.2)\n```", "```py\n>>> minds\nDatasetDict({\n    train: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 450\n    })\n    test: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 113\n    })\n})\n```", "```py\n>>> minds = minds.remove_columns([\"path\", \"transcription\", \"english_transcription\", \"lang_id\"])\n```", "```py\n>>> minds[\"train\"][0]\n{'audio': {'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00048828,\n         -0.00024414, -0.00024414], dtype=float32),\n  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',\n  'sampling_rate': 8000},\n 'intent_class': 2}\n```", "```py\n>>> labels = minds[\"train\"].features[\"intent_class\"].names\n>>> label2id, id2label = dict(), dict()\n>>> for i, label in enumerate(labels):\n...     label2id[label] = str(i)\n...     id2label[str(i)] = label\n```", "```py\n>>> id2label[str(2)]\n'app_error'\n```", "```py\n>>> from transformers import AutoFeatureExtractor\n\n>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n```", "```py\n>>> minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n>>> minds[\"train\"][0]\n{'audio': {'array': array([ 2.2098757e-05,  4.6582241e-05, -2.2803260e-05, ...,\n         -2.8419291e-04, -2.3305941e-04, -1.1425107e-04], dtype=float32),\n  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',\n  'sampling_rate': 16000},\n 'intent_class': 2}\n```", "```py\n>>> def preprocess_function(examples):\n...     audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n...     inputs = feature_extractor(\n...         audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True\n...     )\n...     return inputs\n```", "```py\n>>> encoded_minds = minds.map(preprocess_function, remove_columns=\"audio\", batched=True)\n>>> encoded_minds = encoded_minds.rename_column(\"intent_class\", \"label\")\n```", "```py\n>>> import evaluate\n\n>>> accuracy = evaluate.load(\"accuracy\")\n```", "```py\n>>> import numpy as np\n\n>>> def compute_metrics(eval_pred):\n...     predictions = np.argmax(eval_pred.predictions, axis=1)\n...     return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\n```", "```py\n>>> from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n\n>>> num_labels = len(id2label)\n>>> model = AutoModelForAudioClassification.from_pretrained(\n...     \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n... )\n```", "```py\n>>> training_args = TrainingArguments(\n...     output_dir=\"my_awesome_mind_model\",\n...     evaluation_strategy=\"epoch\",\n...     save_strategy=\"epoch\",\n...     learning_rate=3e-5,\n...     per_device_train_batch_size=32,\n...     gradient_accumulation_steps=4,\n...     per_device_eval_batch_size=32,\n...     num_train_epochs=10,\n...     warmup_ratio=0.1,\n...     logging_steps=10,\n...     load_best_model_at_end=True,\n...     metric_for_best_model=\"accuracy\",\n...     push_to_hub=True,\n... )\n\n>>> trainer = Trainer(\n...     model=model,\n...     args=training_args,\n...     train_dataset=encoded_minds[\"train\"],\n...     eval_dataset=encoded_minds[\"test\"],\n...     tokenizer=feature_extractor,\n...     compute_metrics=compute_metrics,\n... )\n\n>>> trainer.train()\n```", "```py\n>>> trainer.push_to_hub()\n```", "```py\n>>> from datasets import load_dataset, Audio\n\n>>> dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n>>> dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n>>> sampling_rate = dataset.features[\"audio\"].sampling_rate\n>>> audio_file = dataset[0][\"audio\"][\"path\"]\n```", "```py\n>>> from transformers import pipeline\n\n>>> classifier = pipeline(\"audio-classification\", model=\"stevhliu/my_awesome_minds_model\")\n>>> classifier(audio_file)\n[\n    {'score': 0.09766869246959686, 'label': 'cash_deposit'},\n    {'score': 0.07998877018690109, 'label': 'app_error'},\n    {'score': 0.0781070664525032, 'label': 'joint_account'},\n    {'score': 0.07667109370231628, 'label': 'pay_bill'},\n    {'score': 0.0755252093076706, 'label': 'balance'}\n]\n```", "```py\n>>> from transformers import AutoFeatureExtractor\n\n>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"stevhliu/my_awesome_minds_model\")\n>>> inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n```", "```py\n>>> from transformers import AutoModelForAudioClassification\n\n>>> model = AutoModelForAudioClassification.from_pretrained(\"stevhliu/my_awesome_minds_model\")\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n```", "```py\n>>> import torch\n\n>>> predicted_class_ids = torch.argmax(logits).item()\n>>> predicted_label = model.config.id2label[predicted_class_ids]\n>>> predicted_label\n'cash_deposit'\n```"]