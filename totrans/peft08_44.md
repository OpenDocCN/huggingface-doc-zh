# Polytropon

> 原文链接：[`huggingface.co/docs/peft/package_reference/poly`](https://huggingface.co/docs/peft/package_reference/poly)

[Polytropon](https://hf.co/papers/2202.13914) 是一个多任务模型，其中包含多个不同的 LoRA 适配器在其“库存”中。该模型通过路由函数学习从库存中选择适配器的正确组合，以选择特定任务的最佳模块子集。PEFT 还支持[多头适配器路由（MHR）](https://hf.co/papers/2211.03831)用于 Polytropon，它在路由函数上进行了改进，通过更细粒度地组合适配器头部。适配器头部被分成不相交的块，并为每个块学习不同的路由函数，从而实现更多的表达能力。

将模块化技能结合在多任务学习中跨任务泛化的多头适配器路由

该论文的摘要为：

*模块化设计鼓励神经模型将知识的不同方面解开并重新组合，以更系统地推广到新任务。在这项工作中，我们假设每个任务与来自（潜在小）库存的潜在离散技能子集相关联。反过来，技能对应于参数高效（稀疏/低秩）的模型参数化。通过共同学习这些和任务-技能分配矩阵，每个任务的网络被实例化为活动技能的参数的平均值。为了支持跨任务的非平凡软技能划分，我们尝试一系列归纳偏差，例如印度自助餐过程先验和双速学习率。我们在两个主要设置上评估我们的潜在技能模型：1）BabyAI 平台上 8 个级别的多任务强化学习，用于基于指令的跟随；2）在 CrossFit 上对预训练文本生成模型进行少样本适应，这是一个包含 160 个 NLP 任务的基准。我们发现，与完全共享、任务特定或有条件生成参数的基线相比，网络的模块化设计显著提高了强化学习中的样本效率和监督学习中的少样本泛化能力，其中知识在任务之间纠缠。此外，我们展示了离散技能如何帮助解释性，因为它们产生了任务的明确层次结构。*

## PolyConfig

### `class peft.PolyConfig`

[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/poly/config.py#L22)

```py
( peft_type: Union = None auto_mapping: Optional = None base_model_name_or_path: Optional = None revision: Optional = None task_type: Union = None inference_mode: bool = False r: int = 8 target_modules: Union = None modules_to_save: Optional = None init_weights: bool = True poly_type: Literal = 'poly' n_tasks: int = 1 n_skills: int = 4 n_splits: int = 1 )
```

参数

+   `r` (`int`) — Poly 中每个 LoRA 的注意力维度。

+   `target_modules` (`Union[List[str],str]`) — 要应用 Poly 的模块的名称。

+   `modules_to_save` (`List[str]`) — 除了 Poly 层之外要设置为可训练并保存在最终检查点中的模块列表。

+   `init_weights` (bool) — 是否对 Poly 权重进行初始化。

+   `poly_type` (`Literal["poly"]`) — 要使用的 Poly 模块的变体。目前仅支持“poly”。

+   `n_tasks` (`int`) — 多任务场景中的任务数量。

+   `n_skills` (`int`) — 每个 Poly 层中的技能（LoRA）数量。

+   `n_splits` (`int`) — Poly 层中每个 LoRA 内的分割数。大于 1 的值表示使用多头路由（MHR）。

这是用于存储 PolyModel 配置的配置类。

+   [Polytropon (Poly)](https://arxiv.org/abs/2202.13914)

+   [多头路由（MHR）](https://arxiv.org/abs/2211.03831)

## PolyModel

### `class peft.PolyModel`

[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/poly/model.py#L33)

```py
( model config adapter_name )
```
