- en: Troubleshooting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•…éšœæ’é™¤
- en: 'Original text: [https://huggingface.co/docs/datasets/troubleshoot](https://huggingface.co/docs/datasets/troubleshoot)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/datasets/troubleshoot](https://huggingface.co/docs/datasets/troubleshoot)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This guide aims to provide you the tools and knowledge required to navigate
    some common issues. If the suggestions listed in this guide do not cover your
    such situation, please refer to the [Asking for Help](#asking-for-help) section
    to learn where to find help with your specific issue.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—æ—¨åœ¨ä¸ºæ‚¨æä¾›å¯¼èˆªä¸€äº›å¸¸è§é—®é¢˜æ‰€éœ€çš„å·¥å…·å’ŒçŸ¥è¯†ã€‚å¦‚æœæœ¬æŒ‡å—ä¸­åˆ—å‡ºçš„å»ºè®®æœªæ¶µç›–æ‚¨çš„æƒ…å†µï¼Œè¯·å‚è€ƒ[å¯»æ±‚å¸®åŠ©](#asking-for-help)éƒ¨åˆ†ï¼Œäº†è§£åœ¨å“ªé‡Œæ‰¾åˆ°æœ‰å…³æ‚¨ç‰¹å®šé—®é¢˜çš„å¸®åŠ©ã€‚
- en: Issues when uploading datasets with push_to_hub
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨push_to_hubä¸Šä¼ æ•°æ®é›†æ—¶å‡ºç°çš„é—®é¢˜
- en: Authentication issues
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: èº«ä»½éªŒè¯é—®é¢˜
- en: 'If you are experiencing authentication issues when sharing a dataset on ğŸ¤— Hub
    using [Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)
    and a Hugging Face access token:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœåœ¨ä½¿ç”¨[Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)å’ŒHugging
    Faceè®¿é—®ä»¤ç‰Œåœ¨ğŸ¤— Hubä¸Šå…±äº«æ•°æ®é›†æ—¶é‡åˆ°èº«ä»½éªŒè¯é—®é¢˜ï¼š
- en: Make sure that the Hugging Face token youâ€™re using to authenticate yourself
    is a token with **write** permission.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®ä¿æ‚¨ç”¨äºèº«ä»½éªŒè¯çš„Hugging Faceä»¤ç‰Œå…·æœ‰**å†™å…¥**æƒé™ã€‚
- en: On OSX, it may help to clean up all the huggingface.co passwords on your keychain
    access, as well as reconfigure `git config --global credential.helper osxkeychain`,
    before using `huggingface-cli login`.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨OSXä¸Šï¼Œå¯èƒ½æœ‰åŠ©äºæ¸…ç†æ‚¨çš„é’¥åŒ™ä¸²è®¿é—®ä¸­æ‰€æœ‰çš„huggingface.coå¯†ç ï¼Œä»¥åŠåœ¨ä½¿ç”¨`huggingface-cli login`ä¹‹å‰é‡æ–°é…ç½®`git
    config --global credential.helper osxkeychain`ã€‚
- en: Alternatively, you can use SSH keys to authenticate yourself - read more in
    the [ğŸ¤— Hub documentation](https://huggingface.co/docs/hub/security-git-ssh).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨SSHå¯†é’¥è¿›è¡Œèº«ä»½éªŒè¯-åœ¨[ğŸ¤— Hubæ–‡æ¡£](https://huggingface.co/docs/hub/security-git-ssh)ä¸­é˜…è¯»æ›´å¤šä¿¡æ¯ã€‚
- en: Lost connection on large dataset upload
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¤§å‹æ•°æ®é›†ä¸Šä¼ æ—¶æ–­å¼€è¿æ¥
- en: When uploading large datasets to Hub, if the number of dataset shards is large,
    it can create too many commits for the Hub in a short period. This will result
    in a connection error. The connection error can also be caused by a HTTP 500 error
    returned by AWS S3 bucket that Hub uses internally. In either situation, you can
    re-run [Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)
    to proceed with the dataset upload. Hub will check the SHAs of already uploaded
    shards to avoid reuploading them. We are working on making upload process more
    robust to transient errors, so updating to the latest library version is always
    a good idea.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å‘Hubä¸Šä¼ å¤§å‹æ•°æ®é›†æ—¶ï¼Œå¦‚æœæ•°æ®é›†åˆ†ç‰‡æ•°é‡è¾ƒå¤šï¼Œå¯èƒ½ä¼šåœ¨çŸ­æ—¶é—´å†…ä¸ºHubåˆ›å»ºè¿‡å¤šçš„æäº¤ã€‚è¿™å°†å¯¼è‡´è¿æ¥é”™è¯¯ã€‚è¿æ¥é”™è¯¯ä¹Ÿå¯èƒ½æ˜¯ç”±Hubå†…éƒ¨ä½¿ç”¨çš„AWS
    S3å­˜å‚¨æ¡¶è¿”å›çš„HTTP 500é”™è¯¯å¼•èµ·çš„ã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥é‡æ–°è¿è¡Œ[Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)ä»¥ç»§ç»­è¿›è¡Œæ•°æ®é›†ä¸Šä¼ ã€‚Hubå°†æ£€æŸ¥å·²ä¸Šä¼ åˆ†ç‰‡çš„SHAsï¼Œä»¥é¿å…é‡æ–°ä¸Šä¼ å®ƒä»¬ã€‚æˆ‘ä»¬æ­£åœ¨åŠªåŠ›ä½¿ä¸Šä¼ è¿‡ç¨‹æ›´å…·é²æ£’æ€§ä»¥åº”å¯¹ç¬æ€é”™è¯¯ï¼Œå› æ­¤å§‹ç»ˆæ›´æ–°åˆ°æœ€æ–°çš„åº“ç‰ˆæœ¬æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚
- en: Too Many Requests
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¯·æ±‚è¿‡å¤š
- en: 'Uploading large datasets via `push_to_hub()` can result in an error:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡`push_to_hub()`ä¸Šä¼ å¤§å‹æ•°æ®é›†å¯èƒ½ä¼šå¯¼è‡´é”™è¯¯ï¼š
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you encounter this issue, you need to upgrade the `datasets` library to the
    latest version (or at least `2.15.0`).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœé‡åˆ°æ­¤é—®é¢˜ï¼Œæ‚¨éœ€è¦å°†`datasets`åº“å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬ï¼ˆæˆ–è‡³å°‘ä¸º`2.15.0`ï¼‰ã€‚
- en: Issues when creating datasets from custom data
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»è‡ªå®šä¹‰æ•°æ®åˆ›å»ºæ•°æ®é›†æ—¶å‡ºç°çš„é—®é¢˜
- en: Loading images and audio from a folder
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»æ–‡ä»¶å¤¹åŠ è½½å›¾åƒå’ŒéŸ³é¢‘
- en: When creating a dataset from a folder, one of the most common issues is that
    the file structure does not follow the expected format, or thereâ€™s an issue with
    the metadata file.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ–‡ä»¶å¤¹åˆ›å»ºæ•°æ®é›†æ—¶ï¼Œæœ€å¸¸è§çš„é—®é¢˜ä¹‹ä¸€æ˜¯æ–‡ä»¶ç»“æ„ä¸ç¬¦åˆé¢„æœŸæ ¼å¼ï¼Œæˆ–è€…å…ƒæ•°æ®æ–‡ä»¶å­˜åœ¨é—®é¢˜ã€‚
- en: 'Learn more about required folder structure in corresponding documentation pages:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç›¸åº”çš„æ–‡æ¡£é¡µé¢ä¸­äº†è§£æ‰€éœ€çš„æ–‡ä»¶å¤¹ç»“æ„ï¼š
- en: '[AudioFolder](https://huggingface.co/docs/datasets/audio_dataset#audiofolder)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AudioFolder](https://huggingface.co/docs/datasets/audio_dataset#audiofolder)'
- en: '[ImageFolder](https://huggingface.co/docs/datasets/image_dataset#imagefolder)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ImageFolder](https://huggingface.co/docs/datasets/image_dataset#imagefolder)'
- en: Pickling issues
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è…Œåˆ¶é—®é¢˜
- en: Pickling issues when using Dataset.from_generator
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: åœ¨ä½¿ç”¨Dataset.from_generatoræ—¶å‡ºç°çš„è…Œåˆ¶é—®é¢˜
- en: When creating a dataset, [IterableDataset.from_generator()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.from_generator)
    and [Dataset.from_generator()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_generator)
    expect a â€œpicklableâ€ generator function. This is required to hash the function
    using [`pickle`](https://docs.python.org/3/library/pickle.html) to be able to
    cache the dataset on disk.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºæ•°æ®é›†æ—¶ï¼Œ[IterableDataset.from_generator()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.from_generator)å’Œ[Dataset.from_generator()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_generator)éœ€è¦ä¸€ä¸ªâ€œå¯è…Œåˆ¶â€çš„ç”Ÿæˆå™¨å‡½æ•°ã€‚è¿™æ˜¯å¿…è¦çš„ï¼Œä»¥ä½¿ç”¨[`pickle`](https://docs.python.org/3/library/pickle.html)å¯¹å‡½æ•°è¿›è¡Œå“ˆå¸Œå¤„ç†ï¼Œä»¥ä¾¿èƒ½å¤Ÿå°†æ•°æ®é›†ç¼“å­˜åˆ°ç£ç›˜ä¸Šã€‚
- en: 'While generator functions are generally â€œpicklableâ€, note that generator objects
    are not. So if youâ€™re using a generator object, you will encounter a `TypeError`
    like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ç”Ÿæˆå™¨å‡½æ•°é€šå¸¸æ˜¯â€œå¯è…Œåˆ¶â€çš„ï¼Œä½†è¯·æ³¨æ„ç”Ÿæˆå™¨å¯¹è±¡ä¸æ˜¯ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨ä½¿ç”¨ç”Ÿæˆå™¨å¯¹è±¡ï¼Œæ‚¨å°†é‡åˆ°ç±»ä¼¼äºè¿™æ ·çš„`TypeError`ï¼š
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This error can also occur when using a generator function that uses a global
    object that is not â€œpicklableâ€, such as a DB connection, for example. If thatâ€™s
    the case, you can initialize such object directly inside the generator function
    to avoid this error.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½¿ç”¨ä¸€ä¸ªä½¿ç”¨å…¨å±€å¯¹è±¡çš„ç”Ÿæˆå™¨å‡½æ•°æ—¶ï¼Œè¯¥å…¨å±€å¯¹è±¡ä¸æ˜¯â€œå¯è…Œåˆ¶â€çš„ï¼Œä¾‹å¦‚æ•°æ®åº“è¿æ¥ï¼Œè¿™ç§é”™è¯¯ä¹Ÿå¯èƒ½å‘ç”Ÿã€‚å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨ç”Ÿæˆå™¨å‡½æ•°å†…åˆå§‹åŒ–è¿™æ ·çš„å¯¹è±¡ï¼Œä»¥é¿å…æ­¤é”™è¯¯ã€‚
- en: Pickling issues with Dataset.map
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Dataset.mapæ—¶çš„è…Œåˆ¶é—®é¢˜
- en: Pickling errors can also happen in the multiprocess [Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    - objects are pickled to be passed to child processes. If the objects used in
    the transformation are not picklable, itâ€™s not possible to cache the result of
    `map`, which leads to an error being raised.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤šè¿›ç¨‹Dataset.map()ä¸­ä¹Ÿå¯èƒ½å‘ç”Ÿè…Œåˆ¶é”™è¯¯-å¯¹è±¡è¢«è…Œåˆ¶ä»¥ä¼ é€’ç»™å­è¿›ç¨‹ã€‚å¦‚æœè½¬æ¢ä¸­ä½¿ç”¨çš„å¯¹è±¡ä¸å¯è…Œåˆ¶ï¼Œåˆ™æ— æ³•ç¼“å­˜`map`çš„ç»“æœï¼Œè¿™å°†å¯¼è‡´é”™è¯¯è¢«å¼•å‘ã€‚
- en: 'Here are some ways to address this issue:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: A universal solution to pickle issues is to make sure the objects (or generator
    classes) are pickable manually by implementing `__getstate__` / `__setstate__`
    / `__reduce__`.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also provide your own unique hash in `map` with the `new_fingerprint`
    argument.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also disable caching by calling `datasets.disable_caching()`, however,
    this is undesirable - [read more about importance of cache](cache)
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asking for help
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the above troubleshooting advice did not help you resolve your issue, reach
    out for help to the community and the team.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Forums
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ask for help on the Hugging Face forums - post your question in the [ğŸ¤—Datasets
    category](https://discuss.huggingface.co/c/datasets/10) Make sure to write a descriptive
    post with relevant context about your setup and reproducible code to maximize
    the likelihood that your problem is solved!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Discord
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Post a question on [Discord](http://hf.co/join/discord), and let the team and
    the community help you.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Community Discussions on ğŸ¤— Hub
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you are facing issues creating a custom dataset with a script on Hub, you
    can ask the Hugging Face team for help by opening a discussion in the Community
    tab of your dataset with this message:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: GitHub Issues
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, if you suspect to have found a bug related to the library itself,
    create an Issue on the ğŸ¤— Datasets [GitHub repository](https://github.com/huggingface/datasets/issues).
    Include context regarding the bug: code snippet to reproduce, details about your
    environment and data, etc. to help us figure out whatâ€™s wrong and how we can fix
    it.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
