- en: Troubleshooting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 故障排除
- en: 'Original text: [https://huggingface.co/docs/datasets/troubleshoot](https://huggingface.co/docs/datasets/troubleshoot)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/datasets/troubleshoot](https://huggingface.co/docs/datasets/troubleshoot)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This guide aims to provide you the tools and knowledge required to navigate
    some common issues. If the suggestions listed in this guide do not cover your
    such situation, please refer to the [Asking for Help](#asking-for-help) section
    to learn where to find help with your specific issue.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南旨在为您提供导航一些常见问题所需的工具和知识。如果本指南中列出的建议未涵盖您的情况，请参考[寻求帮助](#asking-for-help)部分，了解在哪里找到有关您特定问题的帮助。
- en: Issues when uploading datasets with push_to_hub
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用push_to_hub上传数据集时出现的问题
- en: Authentication issues
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 身份验证问题
- en: 'If you are experiencing authentication issues when sharing a dataset on 🤗 Hub
    using [Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)
    and a Hugging Face access token:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在使用[Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)和Hugging
    Face访问令牌在🤗 Hub上共享数据集时遇到身份验证问题：
- en: Make sure that the Hugging Face token you’re using to authenticate yourself
    is a token with **write** permission.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保您用于身份验证的Hugging Face令牌具有**写入**权限。
- en: On OSX, it may help to clean up all the huggingface.co passwords on your keychain
    access, as well as reconfigure `git config --global credential.helper osxkeychain`,
    before using `huggingface-cli login`.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在OSX上，可能有助于清理您的钥匙串访问中所有的huggingface.co密码，以及在使用`huggingface-cli login`之前重新配置`git
    config --global credential.helper osxkeychain`。
- en: Alternatively, you can use SSH keys to authenticate yourself - read more in
    the [🤗 Hub documentation](https://huggingface.co/docs/hub/security-git-ssh).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用SSH密钥进行身份验证-在[🤗 Hub文档](https://huggingface.co/docs/hub/security-git-ssh)中阅读更多信息。
- en: Lost connection on large dataset upload
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型数据集上传时断开连接
- en: When uploading large datasets to Hub, if the number of dataset shards is large,
    it can create too many commits for the Hub in a short period. This will result
    in a connection error. The connection error can also be caused by a HTTP 500 error
    returned by AWS S3 bucket that Hub uses internally. In either situation, you can
    re-run [Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)
    to proceed with the dataset upload. Hub will check the SHAs of already uploaded
    shards to avoid reuploading them. We are working on making upload process more
    robust to transient errors, so updating to the latest library version is always
    a good idea.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当向Hub上传大型数据集时，如果数据集分片数量较多，可能会在短时间内为Hub创建过多的提交。这将导致连接错误。连接错误也可能是由Hub内部使用的AWS
    S3存储桶返回的HTTP 500错误引起的。在任何情况下，您可以重新运行[Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)以继续进行数据集上传。Hub将检查已上传分片的SHAs，以避免重新上传它们。我们正在努力使上传过程更具鲁棒性以应对瞬态错误，因此始终更新到最新的库版本是一个好主意。
- en: Too Many Requests
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 请求过多
- en: 'Uploading large datasets via `push_to_hub()` can result in an error:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`push_to_hub()`上传大型数据集可能会导致错误：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you encounter this issue, you need to upgrade the `datasets` library to the
    latest version (or at least `2.15.0`).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果遇到此问题，您需要将`datasets`库升级到最新版本（或至少为`2.15.0`）。
- en: Issues when creating datasets from custom data
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从自定义数据创建数据集时出现的问题
- en: Loading images and audio from a folder
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从文件夹加载图像和音频
- en: When creating a dataset from a folder, one of the most common issues is that
    the file structure does not follow the expected format, or there’s an issue with
    the metadata file.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从文件夹创建数据集时，最常见的问题之一是文件结构不符合预期格式，或者元数据文件存在问题。
- en: 'Learn more about required folder structure in corresponding documentation pages:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在相应的文档页面中了解所需的文件夹结构：
- en: '[AudioFolder](https://huggingface.co/docs/datasets/audio_dataset#audiofolder)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AudioFolder](https://huggingface.co/docs/datasets/audio_dataset#audiofolder)'
- en: '[ImageFolder](https://huggingface.co/docs/datasets/image_dataset#imagefolder)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ImageFolder](https://huggingface.co/docs/datasets/image_dataset#imagefolder)'
- en: Pickling issues
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 腌制问题
- en: Pickling issues when using Dataset.from_generator
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在使用Dataset.from_generator时出现的腌制问题
- en: When creating a dataset, [IterableDataset.from_generator()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.from_generator)
    and [Dataset.from_generator()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_generator)
    expect a “picklable” generator function. This is required to hash the function
    using [`pickle`](https://docs.python.org/3/library/pickle.html) to be able to
    cache the dataset on disk.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 创建数据集时，[IterableDataset.from_generator()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.from_generator)和[Dataset.from_generator()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.from_generator)需要一个“可腌制”的生成器函数。这是必要的，以使用[`pickle`](https://docs.python.org/3/library/pickle.html)对函数进行哈希处理，以便能够将数据集缓存到磁盘上。
- en: 'While generator functions are generally “picklable”, note that generator objects
    are not. So if you’re using a generator object, you will encounter a `TypeError`
    like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然生成器函数通常是“可腌制”的，但请注意生成器对象不是。因此，如果您使用生成器对象，您将遇到类似于这样的`TypeError`：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This error can also occur when using a generator function that uses a global
    object that is not “picklable”, such as a DB connection, for example. If that’s
    the case, you can initialize such object directly inside the generator function
    to avoid this error.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用一个使用全局对象的生成器函数时，该全局对象不是“可腌制”的，例如数据库连接，这种错误也可能发生。如果是这种情况，您可以直接在生成器函数内初始化这样的对象，以避免此错误。
- en: Pickling issues with Dataset.map
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Dataset.map时的腌制问题
- en: Pickling errors can also happen in the multiprocess [Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    - objects are pickled to be passed to child processes. If the objects used in
    the transformation are not picklable, it’s not possible to cache the result of
    `map`, which leads to an error being raised.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在多进程Dataset.map()中也可能发生腌制错误-对象被腌制以传递给子进程。如果转换中使用的对象不可腌制，则无法缓存`map`的结果，这将导致错误被引发。
- en: 'Here are some ways to address this issue:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: A universal solution to pickle issues is to make sure the objects (or generator
    classes) are pickable manually by implementing `__getstate__` / `__setstate__`
    / `__reduce__`.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also provide your own unique hash in `map` with the `new_fingerprint`
    argument.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also disable caching by calling `datasets.disable_caching()`, however,
    this is undesirable - [read more about importance of cache](cache)
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asking for help
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the above troubleshooting advice did not help you resolve your issue, reach
    out for help to the community and the team.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Forums
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ask for help on the Hugging Face forums - post your question in the [🤗Datasets
    category](https://discuss.huggingface.co/c/datasets/10) Make sure to write a descriptive
    post with relevant context about your setup and reproducible code to maximize
    the likelihood that your problem is solved!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Discord
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Post a question on [Discord](http://hf.co/join/discord), and let the team and
    the community help you.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Community Discussions on 🤗 Hub
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you are facing issues creating a custom dataset with a script on Hub, you
    can ask the Hugging Face team for help by opening a discussion in the Community
    tab of your dataset with this message:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: GitHub Issues
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, if you suspect to have found a bug related to the library itself,
    create an Issue on the 🤗 Datasets [GitHub repository](https://github.com/huggingface/datasets/issues).
    Include context regarding the bug: code snippet to reproduce, details about your
    environment and data, etc. to help us figure out what’s wrong and how we can fix
    it.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
