# æ¨¡å‹

> [`huggingface.co/docs/transformers/v4.37.2/en/main_classes/model`](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model)

åŸºç±» PreTrainedModelã€TFPreTrainedModel å’Œ FlaxPreTrainedModel å®ç°äº†ä»æœ¬åœ°æ–‡ä»¶æˆ–ç›®å½•åŠ è½½/ä¿å­˜æ¨¡å‹çš„å¸¸ç”¨æ–¹æ³•ï¼Œæˆ–ä»åº“æä¾›çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®ï¼ˆä» HuggingFace çš„ AWS S3 å­˜å‚¨åº“ä¸‹è½½ï¼‰åŠ è½½æ¨¡å‹ã€‚

PreTrainedModel å’Œ TFPreTrainedModel è¿˜å®ç°äº†ä¸€äº›æ‰€æœ‰æ¨¡å‹å…±æœ‰çš„æ–¹æ³•ï¼š

+   å½“æ–°çš„æ ‡è®°æ·»åŠ åˆ°è¯æ±‡è¡¨ä¸­æ—¶ï¼Œè°ƒæ•´è¾“å…¥æ ‡è®°åµŒå…¥å¤§å°

+   ä¿®å‰ªæ¨¡å‹çš„æ³¨æ„åŠ›å¤´ã€‚

æ¯ä¸ªæ¨¡å‹å…±æœ‰çš„å…¶ä»–æ–¹æ³•åœ¨ ModuleUtilsMixinï¼ˆç”¨äº PyTorch æ¨¡å‹ï¼‰å’Œ `~modeling_tf_utils.TFModuleUtilsMixin`ï¼ˆç”¨äº TensorFlow æ¨¡å‹ï¼‰ä¸­å®šä¹‰ï¼Œæˆ–è€…ç”¨äºæ–‡æœ¬ç”Ÿæˆçš„ GenerationMixinï¼ˆç”¨äº PyTorch æ¨¡å‹ï¼‰ã€TFGenerationMixinï¼ˆç”¨äº TensorFlow æ¨¡å‹ï¼‰å’Œ FlaxGenerationMixinï¼ˆç”¨äº Flax/JAX æ¨¡å‹ï¼‰ã€‚

## PreTrainedModel

### `class transformers.PreTrainedModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1157)

```py
( config: PretrainedConfig *inputs **kwargs )
```

æ‰€æœ‰æ¨¡å‹çš„åŸºç±»ã€‚

PreTrainedModel è´Ÿè´£å­˜å‚¨æ¨¡å‹çš„é…ç½®ï¼Œå¹¶å¤„ç†åŠ è½½ã€ä¸‹è½½å’Œä¿å­˜æ¨¡å‹ä»¥åŠä¸€äº›æ‰€æœ‰æ¨¡å‹å…±æœ‰çš„æ–¹æ³•ï¼š

+   è°ƒæ•´è¾“å…¥åµŒå…¥å¤§å°ï¼Œ

+   ä¿®å‰ªè‡ªæ³¨æ„åŠ›å¤´ä¸­çš„å¤´ã€‚

ç±»å±æ€§ï¼ˆæ´¾ç”Ÿç±»è¦†ç›–ï¼‰ï¼š

+   `config_class` (PretrainedConfig) â€” ç”¨ä½œæ­¤æ¨¡å‹æ¶æ„çš„é…ç½®ç±»çš„ PretrainedConfig çš„å­ç±»ã€‚

+   `load_tf_weights` (`Callable`) â€” ç”¨äºåœ¨ PyTorch æ¨¡å‹ä¸­åŠ è½½ TensorFlow æ£€æŸ¥ç‚¹çš„ Python *æ–¹æ³•*ï¼Œå‚æ•°ä¸ºï¼š

    +   `model` (PreTrainedModel) â€” è¦åŠ è½½ TensorFlow æ£€æŸ¥ç‚¹çš„æ¨¡å‹å®ä¾‹ã€‚

    +   `config` (`PreTrainedConfig`) â€” ä¸æ¨¡å‹å…³è”çš„é…ç½®å®ä¾‹ã€‚

    +   `path` (`str`) â€” TensorFlow æ£€æŸ¥ç‚¹çš„è·¯å¾„ã€‚

+   `base_model_prefix` (`str`) â€” ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡ç¤ºæ´¾ç”Ÿç±»ä¸­åŸºç¡€æ¨¡å‹å…³è”çš„å±æ€§ï¼Œè¯¥å±æ€§åœ¨åŸºç¡€æ¨¡å‹çš„é¡¶éƒ¨æ·»åŠ æ¨¡å—ã€‚

+   `is_parallelizable` (`bool`) â€” ä¸€ä¸ªæŒ‡ç¤ºæ­¤æ¨¡å‹æ˜¯å¦æ”¯æŒæ¨¡å‹å¹¶è¡ŒåŒ–çš„æ ‡å¿—ã€‚

+   `main_input_name` (`str`) â€” æ¨¡å‹çš„ä¸»è¦è¾“å…¥åç§°ï¼ˆé€šå¸¸ä¸º NLP æ¨¡å‹çš„ `input_ids`ï¼Œè§†è§‰æ¨¡å‹çš„ `pixel_values` å’Œè¯­éŸ³æ¨¡å‹çš„ `input_values`ï¼‰ã€‚

#### `push_to_hub`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)

```py
( repo_id: str use_temp_dir: Optional = None commit_message: Optional = None private: Optional = None token: Union = None max_shard_size: Union = '5GB' create_pr: bool = False safe_serialization: bool = True revision: str = None commit_description: str = None tags: Optional = None **deprecated_kwargs )
```

å‚æ•°

+   `repo_id` (`str`) â€” æ‚¨è¦æ¨é€æ¨¡å‹çš„å­˜å‚¨åº“åç§°ã€‚åœ¨æ¨é€åˆ°ç‰¹å®šç»„ç»‡æ—¶ï¼Œåº”åŒ…å«æ‚¨çš„ç»„ç»‡åç§°ã€‚

+   `use_temp_dir`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦ä½¿ç”¨ä¸´æ—¶ç›®å½•å­˜å‚¨ä¿å­˜çš„æ–‡ä»¶ï¼Œç„¶åå°†å®ƒä»¬æ¨é€åˆ° Hubã€‚å¦‚æœæ²¡æœ‰åä¸º`repo_id`çš„ç›®å½•ï¼Œåˆ™é»˜è®¤ä¸º`True`ï¼Œå¦åˆ™ä¸º`False`ã€‚

+   `commit_message`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º`"Upload model"`ã€‚

+   `private`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦åº”è¯¥åˆ›å»ºç§æœ‰å­˜å‚¨åº“ã€‚

+   `token`ï¼ˆ`bool`æˆ–`str`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œå°†ä½¿ç”¨è¿è¡Œ`huggingface-cli login`æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ä¸­ï¼‰ã€‚å¦‚æœæœªæŒ‡å®š`repo_url`ï¼Œåˆ™é»˜è®¤ä¸º`True`ã€‚

+   `max_shard_size`ï¼ˆ`int`æˆ–`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"5GB"`ï¼‰â€” ä»…é€‚ç”¨äºæ¨¡å‹ã€‚åœ¨åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åï¼Œæ£€æŸ¥ç‚¹å°†åˆ†ç‰‡ï¼Œæ¯ä¸ªåˆ†ç‰‡çš„å¤§å°éƒ½å°äºæ­¤å¤§å°ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚`"5MB"`ï¼‰ã€‚æˆ‘ä»¬å°†å…¶é»˜è®¤è®¾ç½®ä¸º`"5GB"`ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥åœ¨å…è´¹çš„ Google Colab å®ä¾‹ä¸Šè½»æ¾åŠ è½½æ¨¡å‹ï¼Œè€Œä¸ä¼šå‡ºç°ä»»ä½• CPU OOM é—®é¢˜ã€‚

+   `create_pr`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦åˆ›å»ºå¸¦æœ‰ä¸Šä¼ æ–‡ä»¶çš„ PR æˆ–ç›´æ¥æäº¤ã€‚

+   `safe_serialization`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦å°†æ¨¡å‹æƒé‡è½¬æ¢ä¸º safetensors æ ¼å¼ä»¥è¿›è¡Œæ›´å®‰å…¨çš„åºåˆ—åŒ–ã€‚

+   `revision`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” è¦å°†ä¸Šä¼ çš„æ–‡ä»¶æ¨é€åˆ°çš„åˆ†æ”¯ã€‚

+   `commit_description`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” å°†åˆ›å»ºçš„æäº¤çš„æè¿°

+   `tags`ï¼ˆ`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦æ¨é€åˆ° Hub ä¸Šçš„æ ‡ç­¾åˆ—è¡¨ã€‚

å°†æ¨¡å‹æ–‡ä»¶ä¸Šä¼ åˆ°ğŸ¤—æ¨¡å‹ä¸­å¿ƒã€‚

ç¤ºä¾‹ï¼š

```py
from transformers import AutoModel

model = AutoModel.from_pretrained("bert-base-cased")

# Push the model to your namespace with the name "my-finetuned-bert".
model.push_to_hub("my-finetuned-bert")

# Push the model to an organization with the name "my-finetuned-bert".
model.push_to_hub("huggingface/my-finetuned-bert")
```

#### `add_model_tags`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1270)

```py
( tags: Union )
```

å‚æ•°

+   `tags`ï¼ˆ`Union[List[str], str]`ï¼‰â€” è¦æ³¨å…¥æ¨¡å‹ä¸­çš„æ‰€éœ€æ ‡ç­¾ã€‚

å°†è‡ªå®šä¹‰æ ‡ç­¾æ·»åŠ åˆ°æ¨é€åˆ° Hugging Face Hub çš„æ¨¡å‹ä¸­ã€‚ä¸ä¼šè¦†ç›–æ¨¡å‹ä¸­çš„ç°æœ‰æ ‡ç­¾ã€‚

ç¤ºä¾‹ï¼š

```py
from transformers import AutoModel

model = AutoModel.from_pretrained("bert-base-cased")

model.add_model_tags(["custom", "custom-bert"])

# Push the model to your namespace with the name "my-custom-bert".
model.push_to_hub("my-custom-bert")
```

#### `can_generate`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1438)

```py
( ) â†’ export const metadata = 'undefined';bool
```

è¿”å›

`bool`

æ­¤æ¨¡å‹æ˜¯å¦å¯ä»¥ç”Ÿæˆåºåˆ—ï¼Œä½¿ç”¨`.generate()`ã€‚

è¿”å›æ­¤æ¨¡å‹æ˜¯å¦å¯ä»¥ç”Ÿæˆåºåˆ—ï¼Œä½¿ç”¨`.generate()`ã€‚

#### `disable_input_require_grads`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1582)

```py
( )
```

åˆ é™¤`_require_grads_hook`ã€‚

#### `enable_input_require_grads`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1571)

```py
( )
```

å¯ç”¨è¾“å…¥åµŒå…¥çš„æ¢¯åº¦ã€‚è¿™å¯¹äºå¾®è°ƒé€‚é…å™¨æƒé‡å¹¶ä¿æŒæ¨¡å‹æƒé‡å›ºå®šå¾ˆæœ‰ç”¨ã€‚

#### `from_pretrained`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2617)

```py
( pretrained_model_name_or_path: Union *model_args config: Union = None cache_dir: Union = None ignore_mismatched_sizes: bool = False force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' use_safetensors: bool = None **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path`ï¼ˆ`str`æˆ–`os.PathLike`ï¼Œ*å¯é€‰*ï¼‰â€” å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ‰˜ç®¡åœ¨ huggingface.co æ¨¡å‹å­˜å‚¨åº“ä¸­çš„é¢„è®­ç»ƒæ¨¡å‹çš„*æ¨¡å‹ ID*ã€‚æœ‰æ•ˆçš„æ¨¡å‹ ID å¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚`bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´åŒ–ï¼Œå¦‚`dbmdz/bert-base-german-cased`ã€‚

    +   æŒ‡å‘åŒ…å«ä½¿ç”¨ save_pretrained()ä¿å­˜çš„æ¨¡å‹æƒé‡çš„*ç›®å½•*çš„è·¯å¾„ï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/`ã€‚

    +   æŒ‡å‘*TensorFlow ç´¢å¼•æ£€æŸ¥ç‚¹æ–‡ä»¶*çš„è·¯å¾„æˆ– URLï¼ˆä¾‹å¦‚ï¼Œ`./tf_model/model.ckpt.index`ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåº”å°†`from_tf`è®¾ç½®ä¸º`True`ï¼Œå¹¶å°†é…ç½®å¯¹è±¡ä½œä¸º`config`å‚æ•°æä¾›ã€‚ä½¿ç”¨æ­¤åŠ è½½è·¯å¾„æ¯”ä½¿ç”¨æä¾›çš„è½¬æ¢è„šæœ¬å°† TensorFlow æ£€æŸ¥ç‚¹è½¬æ¢ä¸º PyTorch æ¨¡å‹å¹¶éšååŠ è½½ PyTorch æ¨¡å‹è¦æ…¢ã€‚

    +   ä¸€ä¸ªåŒ…å«*flax checkpoint file*çš„æ¨¡å‹æ–‡ä»¶å¤¹çš„è·¯å¾„æˆ– urlï¼Œæ ¼å¼ä¸º*.msgpack*ï¼ˆä¾‹å¦‚ï¼Œ`./flax_model/`åŒ…å«`flax_model.msgpack`ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`from_flax`åº”è®¾ç½®ä¸º`True`ã€‚

    +   å¦‚æœæ‚¨åŒæ—¶æä¾›é…ç½®å’ŒçŠ¶æ€å­—å…¸ï¼ˆåˆ†åˆ«ä½¿ç”¨å…³é”®å­—å‚æ•°`config`å’Œ`state_dict`ï¼‰ï¼Œåˆ™ä¸º`None`ã€‚

+   `model_args`ï¼ˆä½ç½®å‚æ•°åºåˆ—ï¼Œ*å¯é€‰*ï¼‰â€” æ‰€æœ‰å‰©ä½™çš„ä½ç½®å‚æ•°å°†ä¼ é€’ç»™åº•å±‚æ¨¡å‹çš„`__init__`æ–¹æ³•ã€‚

+   `config`ï¼ˆ`Union[PretrainedConfig, str, os.PathLike]`ï¼Œ*å¯é€‰*ï¼‰â€” å¯ä»¥æ˜¯ï¼š

    +   ä» PretrainedConfig æ´¾ç”Ÿçš„ç±»çš„å®ä¾‹ï¼Œ

    +   ä¸€ä¸ªä½œä¸ºè¾“å…¥æœ‰æ•ˆçš„å­—ç¬¦ä¸²æˆ–è·¯å¾„ï¼Œç”¨äº from_pretrained()ã€‚

    ä»£æ›¿è‡ªåŠ¨åŠ è½½çš„é…ç½®ä½¿ç”¨çš„æ¨¡å‹é…ç½®ã€‚å½“ï¼š

    +   æ¨¡å‹æ˜¯åº“æä¾›çš„æ¨¡å‹ï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„*æ¨¡å‹ id*å­—ç¬¦ä¸²åŠ è½½ï¼‰ã€‚

    +   æ¨¡å‹æ˜¯ä½¿ç”¨ save_pretrained()ä¿å­˜çš„ï¼Œå¹¶é€šè¿‡æä¾›ä¿å­˜ç›®å½•é‡æ–°åŠ è½½ã€‚

    +   é€šè¿‡æä¾›æœ¬åœ°ç›®å½•ä½œä¸º`pretrained_model_name_or_path`åŠ è½½æ¨¡å‹ï¼Œå¹¶åœ¨ç›®å½•ä¸­æ‰¾åˆ°åä¸º*config.json*çš„é…ç½® JSON æ–‡ä»¶ã€‚

+   `state_dict`ï¼ˆ`Dict[str, torch.Tensor]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ä¸ªçŠ¶æ€å­—å…¸ï¼Œç”¨äºæ›¿ä»£ä»ä¿å­˜çš„æƒé‡æ–‡ä»¶åŠ è½½çš„çŠ¶æ€å­—å…¸ã€‚

    å¦‚æœæ‚¨æƒ³ä»é¢„è®­ç»ƒé…ç½®åˆ›å»ºæ¨¡å‹ä½†åŠ è½½è‡ªå·±çš„æƒé‡ï¼Œåˆ™å¯ä»¥ä½¿ç”¨æ­¤é€‰é¡¹ã€‚ä¸è¿‡ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ save_pretrained()å’Œ from_pretrained()ä¸æ˜¯æ›´ç®€å•çš„é€‰é¡¹ã€‚

+   `cache_dir`ï¼ˆ`Union[str, os.PathLike]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹é…ç½®åº”ç¼“å­˜åœ¨å…¶ä¸­çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸ä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚

+   `from_tf`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`) â€” ä» TensorFlow æ£€æŸ¥ç‚¹ä¿å­˜æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡ï¼ˆè¯·å‚é˜…`pretrained_model_name_or_path`å‚æ•°çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼‰ã€‚

+   `from_flax`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” ä» Flax æ£€æŸ¥ç‚¹ä¿å­˜æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡ï¼ˆè¯·å‚é˜…`pretrained_model_name_or_path`å‚æ•°çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼‰ã€‚

+   `ignore_mismatched_sizes`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`) â€” å¦‚æœæ£€æŸ¥ç‚¹ä¸­çš„æŸäº›æƒé‡ä¸æ¨¡å‹çš„æƒé‡å¤§å°ä¸åŒï¼Œæ˜¯å¦å¼•å‘é”™è¯¯ï¼ˆä¾‹å¦‚ï¼Œæ‚¨ä»å…·æœ‰ 3 ä¸ªæ ‡ç­¾çš„æ£€æŸ¥ç‚¹å®ä¾‹åŒ–å…·æœ‰ 10 ä¸ªæ ‡ç­¾çš„æ¨¡å‹ï¼‰ã€‚

+   `force_download`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

+   `resume_download`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`) â€” æ˜¯å¦åˆ é™¤æ¥æ”¶ä¸å®Œæ•´çš„æ–‡ä»¶ã€‚å¦‚æœå­˜åœ¨è¿™æ ·çš„æ–‡ä»¶ï¼Œå°†å°è¯•æ¢å¤ä¸‹è½½ã€‚

+   `proxies`ï¼ˆ`Dict[str, str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ä¸ªä»£ç†æœåŠ¡å™¨å­—å…¸ï¼ŒæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨ï¼Œä¾‹å¦‚ï¼Œ`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`ã€‚ä»£ç†åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚

+   `output_loading_info(bool,` *å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`) â€” æ˜¯å¦è¿”å›ä¸€ä¸ªåŒ…å«ç¼ºå¤±é”®ã€æ„å¤–é”®å’Œé”™è¯¯æ¶ˆæ¯çš„å­—å…¸ã€‚

+   `local_files_only(bool,` *å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`) â€” æ˜¯å¦ä»…æŸ¥çœ‹æœ¬åœ°æ–‡ä»¶ï¼ˆå³ï¼Œä¸å°è¯•ä¸‹è½½æ¨¡å‹ï¼‰ã€‚

+   `token`ï¼ˆ`str`æˆ–`bool`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`æˆ–æœªæŒ‡å®šï¼Œå°†ä½¿ç”¨è¿è¡Œ`huggingface-cli login`æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ä¸­ï¼‰ã€‚

+   `revision` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å®ƒå¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°æˆ–æäº¤ IDï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ huggingface.co ä¸Šä½¿ç”¨åŸºäº git çš„ç³»ç»Ÿæ¥å­˜å‚¨æ¨¡å‹å’Œå…¶ä»–å·¥ä»¶ï¼Œæ‰€ä»¥ `revision` å¯ä»¥æ˜¯ git å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚

    è¦æµ‹è¯•æ‚¨åœ¨ Hub ä¸Šåˆ›å»ºçš„æ‹‰å–è¯·æ±‚ï¼Œå¯ä»¥ä¼ é€’ `revision=â€œrefs/pr/<pr_number>â€œã€‚</pr_number>

+   `mirror` (`str`, *å¯é€‰*) â€” é•œåƒæºä»¥åŠ é€Ÿä¸­å›½çš„ä¸‹è½½ã€‚å¦‚æœæ‚¨æ¥è‡ªä¸­å›½å¹¶ä¸”æœ‰è®¿é—®é—®é¢˜ï¼Œæ‚¨å¯ä»¥è®¾ç½®æ­¤é€‰é¡¹æ¥è§£å†³ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¸ä¿è¯åŠæ—¶æ€§æˆ–å®‰å…¨æ€§ã€‚è¯·å‚è€ƒé•œåƒç«™ç‚¹è·å–æ›´å¤šä¿¡æ¯ã€‚

+   `_fast_init(bool,` *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦ç¦ç”¨å¿«é€Ÿåˆå§‹åŒ–ã€‚

    ä¸ºäº†ç¡®ä¿ä¸ `transformers.__version__ < 4.6.0` çš„ç§å­æ¨¡å‹åˆå§‹åŒ–å‘åå…¼å®¹ï¼Œåº”è¯¥åªç¦ç”¨ *_fast_init*ã€‚æ­¤å‚æ•°å°†åœ¨ä¸‹ä¸€ä¸ªä¸»è¦ç‰ˆæœ¬ä¸­åˆ é™¤ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[æ‹‰å–è¯·æ±‚ 11471](https://github.com/huggingface/transformers/pull/11471)ã€‚

å¤§å‹æ¨¡å‹æ¨ç†çš„å‚æ•°

+   `low_cpu_mem_usage(bool,` *å¯é€‰*) â€” å°è¯•åœ¨åŠ è½½æ¨¡å‹æ—¶ä¸ä½¿ç”¨è¶…è¿‡ CPU å†…å­˜ä¸­çš„ 1x æ¨¡å‹å¤§å°ï¼ˆåŒ…æ‹¬å³°å€¼å†…å­˜ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ï¼Œéšæ—¶å¯èƒ½æ›´æ”¹ã€‚

+   `torch_dtype` (`str` æˆ– `torch.dtype`, *å¯é€‰*) â€” è¦†ç›–é»˜è®¤çš„ `torch.dtype` å¹¶åœ¨ç‰¹å®šçš„ `dtype` ä¸‹åŠ è½½æ¨¡å‹ã€‚ä¸åŒçš„é€‰é¡¹æœ‰ï¼š

    1.  `torch.float16` æˆ– `torch.bfloat16` æˆ– `torch.float`: ä»¥æŒ‡å®šçš„ `dtype` åŠ è½½ï¼Œå¿½ç•¥æ¨¡å‹çš„ `config.torch_dtype`ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚å¦‚æœæœªæŒ‡å®š

        +   æ¨¡å‹å°†ä»¥ `torch.float` (fp32) åŠ è½½ã€‚

    1.  `"auto"` - å°†å°è¯•ä½¿ç”¨æ¨¡å‹çš„ `config.json` æ–‡ä»¶ä¸­çš„ `torch_dtype` æ¡ç›®ã€‚å¦‚æœæ‰¾ä¸åˆ°æ­¤æ¡ç›®ï¼Œåˆ™ä¸‹ä¸€ä¸ªæ£€æŸ¥æ˜¯æ£€æŸ¥ç‚¹ä¸­ç¬¬ä¸€ä¸ªæµ®ç‚¹ç±»å‹çš„æƒé‡çš„ `dtype` å¹¶å°†å…¶ç”¨ä½œ `dtype`ã€‚è¿™å°†ä½¿ç”¨æ¨¡å‹åœ¨è®­ç»ƒç»“æŸæ—¶ä¿å­˜çš„ `dtype` åŠ è½½æ¨¡å‹ã€‚å®ƒä¸èƒ½ç”¨ä½œæ¨¡å‹è®­ç»ƒæ–¹å¼çš„æŒ‡ç¤ºå™¨ã€‚å› ä¸ºå®ƒå¯èƒ½æ˜¯åœ¨åŠç²¾åº¦ `dtype` ä¸­è®­ç»ƒï¼Œä½†ä»¥ fp32 ä¿å­˜ã€‚

    <tip>å¯¹äºä¸€äº›æ¨¡å‹ï¼Œå®ƒä»¬è®­ç»ƒæ—¶ä½¿ç”¨çš„ `dtype` æ˜¯æœªçŸ¥çš„ - æ‚¨å¯ä»¥å°è¯•æŸ¥çœ‹æ¨¡å‹çš„è®ºæ–‡æˆ–è”ç³»ä½œè€…ï¼Œå¹¶è¦æ±‚ä»–ä»¬å°†æ­¤ä¿¡æ¯æ·»åŠ åˆ°æ¨¡å‹çš„å¡ç‰‡ä¸­ï¼Œå¹¶åœ¨ Hub ä¸Šçš„ `config.json` ä¸­æ’å…¥ `torch_dtype` æ¡ç›®ã€‚</tip>

+   `device_map` (`str` æˆ– `Dict[str, Union[int, str, torch.device]]` æˆ– `int` æˆ– `torch.device`, *å¯é€‰*) â€” ä¸€ä¸ªæŒ‡å®šæ¯ä¸ªå­æ¨¡å—åº”è¯¥æ”¾åœ¨å“ªé‡Œçš„æ˜ å°„ã€‚å®ƒä¸éœ€è¦ç»†åŒ–åˆ°æ¯ä¸ªå‚æ•°/ç¼“å†²åŒºåç§°ï¼Œä¸€æ—¦ç»™å®šæ¨¡å—åç§°åœ¨å†…ï¼Œå®ƒçš„æ¯ä¸ªå­æ¨¡å—éƒ½å°†è¢«å‘é€åˆ°åŒä¸€è®¾å¤‡ã€‚å¦‚æœæˆ‘ä»¬åªä¼ é€’æ¨¡å‹å°†è¢«åˆ†é…çš„è®¾å¤‡ï¼ˆä¾‹å¦‚ï¼Œ`"cpu"`ã€`"cuda:1"`ã€`"mps"`ï¼Œæˆ–è€…åƒ `1` è¿™æ ·çš„ GPU åºæ•°ç­‰ï¼‰ï¼Œè®¾å¤‡æ˜ å°„å°†æŠŠæ•´ä¸ªæ¨¡å‹æ˜ å°„åˆ°è¿™ä¸ªè®¾å¤‡ä¸Šã€‚ä¼ é€’ `device_map = 0` æ„å‘³ç€å°†æ•´ä¸ªæ¨¡å‹æ”¾åœ¨ GPU 0 ä¸Šã€‚

    è®© Accelerate è‡ªåŠ¨è®¡ç®—æœ€ä¼˜åŒ–çš„ `device_map`ï¼Œè¯·è®¾ç½® `device_map="auto"`ã€‚æœ‰å…³æ¯ä¸ªé€‰é¡¹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[è®¾è®¡è®¾å¤‡æ˜ å°„](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map)ã€‚

+   `max_memory` (`Dict`, *å¯é€‰*) â€” è®¾å¤‡æ ‡è¯†ç¬¦åˆ°æœ€å¤§å†…å­˜çš„å­—å…¸ã€‚å¦‚æœæœªè®¾ç½®ï¼Œå°†é»˜è®¤ä¸ºæ¯ä¸ª GPU å¯ç”¨çš„æœ€å¤§å†…å­˜å’Œå¯ç”¨çš„ CPU RAMã€‚

+   `offload_folder` (`str` æˆ– `os.PathLike`, *å¯é€‰*) â€” å¦‚æœ `device_map` åŒ…å«ä»»ä½•å€¼ `"disk"`ï¼Œåˆ™æˆ‘ä»¬å°†å¸è½½æƒé‡çš„æ–‡ä»¶å¤¹ã€‚

+   `offload_state_dict` (`bool`, *å¯é€‰*) â€” å¦‚æœä¸º `True`ï¼Œå°†ä¸´æ—¶å°† CPU çŠ¶æ€å­—å…¸è½¬ç§»åˆ°ç¡¬ç›˜ï¼Œä»¥é¿å… CPU RAM ä¸è¶³ï¼Œå¦‚æœ CPU çŠ¶æ€å­—å…¸çš„é‡é‡ + æ£€æŸ¥ç‚¹çš„æœ€å¤§åˆ†ç‰‡ä¸é€‚åˆã€‚å½“å­˜åœ¨ä¸€äº›ç£ç›˜å¸è½½æ—¶ï¼Œé»˜è®¤ä¸º `True`ã€‚

+   `load_in_8bit` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º`True`ï¼Œå°†åŠ è½½çš„æ¨¡å‹è½¬æ¢ä¸ºæ··åˆ 8 ä½é‡åŒ–æ¨¡å‹ã€‚è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·å®‰è£…`bitsandbytes`ï¼ˆ`pip install -U bitsandbytes`ï¼‰ã€‚

+   `load_in_4bit` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœä¸º`True`ï¼Œå°†åŠ è½½çš„æ¨¡å‹è½¬æ¢ä¸º 4 ä½ç²¾åº¦é‡åŒ–æ¨¡å‹ã€‚è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„`bitsandbytes`ï¼ˆ`pip install -U bitsandbytes`ï¼‰ã€‚

+   `quantization_config` (`Union[QuantizationConfigMixin,Dict]`, *å¯é€‰*) â€” é‡åŒ–çš„é…ç½®å‚æ•°å­—å…¸æˆ– QuantizationConfigMixin å¯¹è±¡ï¼ˆä¾‹å¦‚ bitsandbytes, gptqï¼‰

+   `subfolder` (`str`, *optional*, é»˜è®¤ä¸º `""`) â€” å¦‚æœç›¸å…³æ–‡ä»¶ä½äº huggingface.co æ¨¡å‹ä»“åº“çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡ŒæŒ‡å®šæ–‡ä»¶å¤¹åç§°ã€‚

+   `variant` (`str`, *optional*) â€” å¦‚æœæŒ‡å®šï¼Œå°†ä»`variant`æ–‡ä»¶ååŠ è½½æƒé‡ï¼Œä¾‹å¦‚ pytorch_model.<variant>.binã€‚åœ¨ä½¿ç”¨`from_tf`æˆ–`from_flax`æ—¶å¿½ç•¥`variant`ã€‚</variant>

+   `use_safetensors` (`bool`, *optional*, é»˜è®¤ä¸º `None`) â€” æ˜¯å¦ä½¿ç”¨`safetensors`æ£€æŸ¥ç‚¹ã€‚é»˜è®¤ä¸º`None`ã€‚å¦‚æœæœªæŒ‡å®šå¹¶ä¸”æœªå®‰è£…`safetensors`ï¼Œåˆ™å°†å…¶è®¾ç½®ä¸º`False`ã€‚

+   `kwargs`ï¼ˆå‰©ä½™çš„å…³é”®å­—å‚æ•°å­—å…¸ï¼Œ*å¯é€‰*ï¼‰ â€” å¯ç”¨äºæ›´æ–°é…ç½®å¯¹è±¡ï¼ˆåŠ è½½åï¼‰å¹¶åˆå§‹åŒ–æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œ`output_attentions=True`ï¼‰ã€‚æ ¹æ®æ˜¯å¦æä¾›äº†`config`æˆ–è‡ªåŠ¨åŠ è½½ï¼Œè¡Œä¸ºä¼šæœ‰æ‰€ä¸åŒï¼š

    +   å¦‚æœæä¾›äº†é…ç½®`config`ï¼Œ`**kwargs`å°†ç›´æ¥ä¼ é€’ç»™åº•å±‚æ¨¡å‹çš„`__init__`æ–¹æ³•ï¼ˆæˆ‘ä»¬å‡è®¾é…ç½®çš„æ‰€æœ‰ç›¸å…³æ›´æ–°å·²ç»å®Œæˆï¼‰

    +   å¦‚æœæœªæä¾›é…ç½®ï¼Œ`kwargs`å°†é¦–å…ˆä¼ é€’ç»™é…ç½®ç±»åˆå§‹åŒ–å‡½æ•°ï¼ˆfrom_pretrained()ï¼‰ã€‚ä¸é…ç½®å±æ€§å¯¹åº”çš„`kwargs`çš„æ¯ä¸ªé”®å°†ç”¨æä¾›çš„`kwargs`å€¼è¦†ç›–è¯¥å±æ€§ã€‚ä¸å¯¹åº”ä»»ä½•é…ç½®å±æ€§çš„å‰©ä½™é”®å°†ä¼ é€’ç»™åº•å±‚æ¨¡å‹çš„`__init__`å‡½æ•°ã€‚

ä»é¢„è®­ç»ƒæ¨¡å‹é…ç½®å®ä¾‹åŒ–ä¸€ä¸ªé¢„è®­ç»ƒçš„ pytorch æ¨¡å‹ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¨¡å‹ä»¥è¯„ä¼°æ¨¡å¼è®¾ç½®ï¼Œä½¿ç”¨`model.eval()`ï¼ˆDropout æ¨¡å—è¢«åœç”¨ï¼‰ã€‚è¦è®­ç»ƒæ¨¡å‹ï¼Œæ‚¨åº”è¯¥é¦–å…ˆä½¿ç”¨`model.train()`å°†å…¶è®¾ç½®å›è®­ç»ƒæ¨¡å¼ã€‚

è­¦å‘Š*Weights from XXX not initialized from pretrained model*è¡¨ç¤º XXX çš„æƒé‡ä¸æ˜¯ä¸æ¨¡å‹çš„å…¶ä½™éƒ¨åˆ†ä¸€èµ·é¢„è®­ç»ƒçš„ã€‚æ‚¨éœ€è¦ä½¿ç”¨ä¸‹æ¸¸å¾®è°ƒä»»åŠ¡æ¥è®­ç»ƒè¿™äº›æƒé‡ã€‚

è­¦å‘Š*Weights from XXX not used in YYY*è¡¨ç¤ºå±‚ XXX æœªè¢« YYY ä½¿ç”¨ï¼Œå› æ­¤è¿™äº›æƒé‡å°†è¢«ä¸¢å¼ƒã€‚

æ¿€æ´»ç‰¹æ®Šçš„[â€œç¦»çº¿æ¨¡å¼â€](https://huggingface.co/transformers/installation.html#offline-mode)ä»¥åœ¨å—é˜²ç«å¢™ä¿æŠ¤çš„ç¯å¢ƒä¸­ä½¿ç”¨æ­¤æ–¹æ³•ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import BertConfig, BertModel

>>> # Download model and configuration from huggingface.co and cache.
>>> model = BertModel.from_pretrained("bert-base-uncased")
>>> # Model was saved using *save_pretrained('./test/saved_model/')* (for example purposes, not runnable).
>>> model = BertModel.from_pretrained("./test/saved_model/")
>>> # Update configuration during loading.
>>> model = BertModel.from_pretrained("bert-base-uncased", output_attentions=True)
>>> assert model.config.output_attentions == True
>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower, for example purposes, not runnable).
>>> config = BertConfig.from_json_file("./tf_model/my_tf_model_config.json")
>>> model = BertModel.from_pretrained("./tf_model/my_tf_checkpoint.ckpt.index", from_tf=True, config=config)
>>> # Loading from a Flax checkpoint file instead of a PyTorch model (slower)
>>> model = BertModel.from_pretrained("bert-base-uncased", from_flax=True)
```

+   `low_cpu_mem_usage`ç®—æ³•ï¼š

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨çº¦ 1 å€æ¨¡å‹å¤§å° CPU å†…å­˜åŠ è½½æ¨¡å‹çš„å®éªŒæ€§åŠŸèƒ½

ä»¥ä¸‹æ˜¯å®ƒçš„å·¥ä½œåŸç†ï¼š

1.  ä¿å­˜æˆ‘ä»¬æ‹¥æœ‰çš„ state_dict é”®

1.  åœ¨åˆ›å»ºæ¨¡å‹ä¹‹å‰åˆ é™¤ state_dictï¼Œå› ä¸ºåè€…éœ€è¦ 1 å€æ¨¡å‹å¤§å°çš„ CPU å†…å­˜

1.  åœ¨å®ä¾‹åŒ–æ¨¡å‹åï¼Œåˆ‡æ¢åˆ°å…ƒè®¾å¤‡ï¼Œæ‰€æœ‰å°†ä»åŠ è½½çš„ state_dict ä¸­æ›¿æ¢çš„å‚æ•°/ç¼“å†²åŒº

1.  ç¬¬äºŒæ¬¡åŠ è½½ state_dict

1.  ä» state_dict ä¸­æ›¿æ¢å‚æ•°/ç¼“å†²åŒº

ç›®å‰ï¼Œå®ƒæ— æ³•å¤„ç† deepspeed ZeRO é˜¶æ®µ 3 å¹¶å¿½ç•¥åŠ è½½é”™è¯¯

#### `get_input_embeddings`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1588)

```py
( ) â†’ export const metadata = 'undefined';nn.Module
```

è¿”å›

`nn.Module`

å°†è¯æ±‡æ˜ å°„åˆ°éšè—çŠ¶æ€çš„ torch æ¨¡å—ã€‚

è¿”å›æ¨¡å‹çš„è¾“å…¥åµŒå…¥ã€‚

#### `get_memory_footprint`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2540)

```py
( return_buffers = True )
```

å‚æ•°

+   `return_buffers`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦åœ¨è®¡ç®—å†…å­˜å ç”¨æ—¶è¿”å›ç¼“å†²å¼ é‡çš„å¤§å°ã€‚ç¼“å†²åŒºæ˜¯ä¸éœ€è¦æ¢¯åº¦ä¸”æœªæ³¨å†Œä¸ºå‚æ•°çš„å¼ é‡ã€‚ä¾‹å¦‚ï¼Œæ‰¹é‡å½’ä¸€åŒ–å±‚ä¸­çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚è¯·å‚è§ï¼š[`discuss.pytorch.org/t/what-pytorch-means-by-buffers/120266/2`](https://discuss.pytorch.org/t/what-pytorch-means-by-buffers/120266/2)

è·å–æ¨¡å‹çš„å†…å­˜å ç”¨ã€‚è¿™å°†ä»¥å­—èŠ‚ä¸ºå•ä½è¿”å›å½“å‰æ¨¡å‹çš„å†…å­˜å ç”¨ã€‚æœ‰åŠ©äºåŸºå‡†æµ‹è¯•å½“å‰æ¨¡å‹çš„å†…å­˜å ç”¨å¹¶è®¾è®¡ä¸€äº›æµ‹è¯•ã€‚è§£å†³æ–¹æ¡ˆçµæ„Ÿæ¥è‡ª PyTorch è®¨è®ºï¼š[`discuss.pytorch.org/t/gpu-memory-that-model-uses/56822/2`](https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822/2)

#### `get_output_embeddings`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1614)

```py
( ) â†’ export const metadata = 'undefined';nn.Module
```

è¿”å›

`nn.Module`

å°†éšè—çŠ¶æ€æ˜ å°„åˆ°è¯æ±‡è¡¨çš„ torch æ¨¡å—ã€‚

è¿”å›æ¨¡å‹çš„è¾“å‡ºåµŒå…¥ã€‚

#### `gradient_checkpointing_disable`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2166)

```py
( )
```

ä¸ºå½“å‰æ¨¡å‹åœç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ã€‚

è¯·æ³¨æ„ï¼Œåœ¨å…¶ä»–æ¡†æ¶ä¸­ï¼Œæ­¤åŠŸèƒ½å¯èƒ½è¢«ç§°ä¸ºâ€œæ¿€æ´»æ£€æŸ¥ç‚¹â€æˆ–â€œæ£€æŸ¥ç‚¹æ¿€æ´»â€ã€‚

#### `gradient_checkpointing_enable`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2102)

```py
( gradient_checkpointing_kwargs = None )
```

å‚æ•°

+   `gradient_checkpointing_kwargs`ï¼ˆå­—å…¸ï¼Œ*å¯é€‰*ï¼‰â€” ä¼ é€’ç»™`torch.utils.checkpoint.checkpoint`å‡½æ•°çš„é™„åŠ å…³é”®å­—å‚æ•°ã€‚

ä¸ºå½“å‰æ¨¡å‹æ¿€æ´»æ¢¯åº¦æ£€æŸ¥ç‚¹ã€‚

è¯·æ³¨æ„ï¼Œåœ¨å…¶ä»–æ¡†æ¶ä¸­ï¼Œæ­¤åŠŸèƒ½å¯èƒ½è¢«ç§°ä¸ºâ€œæ¿€æ´»æ£€æŸ¥ç‚¹â€æˆ–â€œæ£€æŸ¥ç‚¹æ¿€æ´»â€ã€‚

æˆ‘ä»¬ä¼ é€’æ¨¡å—çš„`__call__`æ–¹æ³•è€Œä¸æ˜¯`forward`ï¼Œå› ä¸º`__call__`ä¼šé™„åŠ æ¨¡å—çš„æ‰€æœ‰é’©å­ã€‚[`discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690/2`](https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690/2)

#### `init_weights`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2068)

```py
( )
```

å¦‚æœéœ€è¦ä¿®å‰ªå¹¶å¯èƒ½åˆå§‹åŒ–æƒé‡ã€‚å¦‚æœä½¿ç”¨è‡ªå®šä¹‰`PreTrainedModel`ï¼Œåˆ™éœ€è¦åœ¨`_init_weights`ä¸­å®ç°ä»»ä½•åˆå§‹åŒ–é€»è¾‘ã€‚

#### `post_init`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1256)

```py
( )
```

åœ¨æ¯ä¸ª Transformer æ¨¡å‹åˆå§‹åŒ–ç»“æŸæ—¶æ‰§è¡Œçš„æ–¹æ³•ï¼Œç”¨äºæ‰§è¡Œéœ€è¦æ¨¡å‹æ¨¡å—æ­£ç¡®åˆå§‹åŒ–çš„ä»£ç ï¼ˆä¾‹å¦‚æƒé‡åˆå§‹åŒ–ï¼‰ã€‚

#### `prune_heads`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2085)

```py
( heads_to_prune: Dict )
```

å‚æ•°

+   `heads_to_prune`ï¼ˆ`Dict[int, List[int]]`ï¼‰â€” é”®ä¸ºé€‰å®šçš„å±‚ç´¢å¼•ï¼ˆ`int`ï¼‰çš„å­—å…¸ï¼Œç›¸å…³å€¼ä¸ºè¯¥å±‚ä¸­è¦ä¿®å‰ªçš„å¤´éƒ¨åˆ—è¡¨ï¼ˆ`int`çš„åˆ—è¡¨ï¼‰ã€‚ä¾‹å¦‚{1: [0, 2]ï¼Œ2: [2, 3]}å°†åœ¨ç¬¬ 1 å±‚ä¿®å‰ªå¤´éƒ¨ 0 å’Œ 2ï¼Œåœ¨ç¬¬ 2 å±‚ä¿®å‰ªå¤´éƒ¨ 2 å’Œ 3ã€‚

ä¿®å‰ªåŸºæœ¬æ¨¡å‹çš„å¤´éƒ¨ã€‚

#### `register_for_auto_class`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4427)

```py
( auto_class = 'AutoModel' )
```

å‚æ•°

+   `auto_class`ï¼ˆ`str`æˆ–`type`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"AutoModel"`ï¼‰â€” è¦æ³¨å†Œæ­¤æ–°æ¨¡å‹çš„è‡ªåŠ¨ç±»ã€‚

å°†æ­¤ç±»ä¸ç»™å®šçš„è‡ªåŠ¨ç±»æ³¨å†Œã€‚è¿™ä»…åº”ç”¨äºè‡ªå®šä¹‰æ¨¡å‹ï¼Œå› ä¸ºåº“ä¸­çš„æ¨¡å‹å·²ç»ä¸è‡ªåŠ¨ç±»æ˜ å°„ã€‚

æ­¤ API æ˜¯å®éªŒæ€§çš„ï¼Œå¯èƒ½åœ¨ä¸‹ä¸€ä¸ªç‰ˆæœ¬ä¸­æœ‰ä¸€äº›è½»å¾®çš„ç ´åæ€§æ›´æ”¹ã€‚

#### `resize_token_embeddings`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1786)

```py
( new_num_tokens: Optional = None pad_to_multiple_of: Optional = None ) â†’ export const metadata = 'undefined';torch.nn.Embedding
```

å‚æ•°

+   `new_num_tokens` (`int`, *optional*) â€” åµŒå…¥çŸ©é˜µä¸­çš„æ–°æ ‡è®°æ•°ã€‚å¢åŠ å¤§å°å°†åœ¨æœ«å°¾æ·»åŠ æ–°åˆå§‹åŒ–çš„å‘é‡ã€‚å‡å°å¤§å°å°†ä»æœ«å°¾åˆ é™¤å‘é‡ã€‚å¦‚æœæœªæä¾›æˆ–ä¸º`None`ï¼Œåˆ™åªè¿”å›æŒ‡å‘æ¨¡å‹çš„è¾“å…¥æ ‡è®°`torch.nn.Embedding`æ¨¡å—çš„æŒ‡é’ˆï¼Œè€Œä¸æ‰§è¡Œä»»ä½•æ“ä½œã€‚

+   `pad_to_multiple_of` (`int`, *optional*) â€” å¦‚æœè®¾ç½®ï¼Œå°†å¡«å……åµŒå…¥çŸ©é˜µåˆ°æä¾›çš„å€¼çš„å€æ•°ã€‚å¦‚æœ`new_num_tokens`è®¾ç½®ä¸º`None`ï¼Œåˆ™åªä¼šå°†åµŒå…¥å¡«å……åˆ°`pad_to_multiple_of`çš„å€æ•°ã€‚

    è¿™å¯¹äºå¯ç”¨ NVIDIA ç¡¬ä»¶ä¸Šçš„ Tensor Cores ç‰¹åˆ«æœ‰ç”¨ï¼Œè®¡ç®—èƒ½åŠ›`>= 7.5`ï¼ˆVoltaï¼‰ï¼Œæˆ–è€…å¯¹äºå—ç›Šäºåºåˆ—é•¿åº¦ä¸º 128 çš„å€æ•°çš„ TPUsã€‚æœ‰å…³æ­¤æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œæˆ–è€…æœ‰å…³é€‰æ‹©è°ƒæ•´å¤§å°çš„æ­£ç¡®å€¼çš„å¸®åŠ©ï¼Œè¯·å‚é˜…æ­¤æŒ‡å—ï¼š[`docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc`](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc)

è¿”å›

`torch.nn.Embedding`

æŒ‡å‘æ¨¡å‹çš„è¾“å…¥æ ‡è®°åµŒå…¥æ¨¡å—ã€‚

å¦‚æœ`new_num_tokens != config.vocab_size`ï¼Œåˆ™è°ƒæ•´æ¨¡å‹çš„è¾“å…¥æ ‡è®°åµŒå…¥çŸ©é˜µçš„å¤§å°ã€‚

åœ¨æ¨¡å‹ç±»å…·æœ‰`tie_weights()`æ–¹æ³•æ—¶è´Ÿè´£ç»‘å®šæƒé‡åµŒå…¥ã€‚

#### `reverse_bettertransformer`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4481)

```py
( ) â†’ export const metadata = 'undefined';PreTrainedModel
```

è¿”å›

PreTrainedModel

å°†æ¨¡å‹è½¬æ¢å›åŸå§‹å»ºæ¨¡ã€‚

æ’¤æ¶ˆä» to_bettertransformer()çš„è½¬æ¢ï¼Œä»¥ä¾¿ä½¿ç”¨åŸå§‹å»ºæ¨¡ï¼Œä¾‹å¦‚ä¸ºäº†ä¿å­˜æ¨¡å‹ã€‚

#### `save_pretrained`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L2199)

```py
( save_directory: Union is_main_process: bool = True state_dict: Optional = None save_function: Callable = <function save at 0x7f3c5f9b0160> push_to_hub: bool = False max_shard_size: Union = '5GB' safe_serialization: bool = True variant: Optional = None token: Union = None save_peft_format: bool = True **kwargs )
```

å‚æ•°

+   `save_directory`ï¼ˆ`str`æˆ–`os.PathLike`ï¼‰ â€” è¦ä¿å­˜åˆ°çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºè¯¥ç›®å½•ã€‚

+   `is_main_process` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚åœ¨åƒ TPU è¿™æ ·çš„åˆ†å¸ƒå¼è®­ç»ƒä¸­å¾ˆæœ‰ç”¨ï¼Œéœ€è¦åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨æ­¤å‡½æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½®`is_main_process=True`ï¼Œä»¥é¿å…ç«äº‰æ¡ä»¶ã€‚

+   `state_dict`ï¼ˆ`torch.Tensor`çš„åµŒå¥—å­—å…¸ï¼‰ â€” è¦ä¿å­˜çš„æ¨¡å‹çš„çŠ¶æ€å­—å…¸ã€‚å°†é»˜è®¤ä¸º`self.state_dict()`ï¼Œä½†å¯ä»¥ç”¨äºä»…ä¿å­˜æ¨¡å‹çš„éƒ¨åˆ†æˆ–è€…åœ¨æ¢å¤æ¨¡å‹çš„çŠ¶æ€å­—å…¸æ—¶éœ€è¦é‡‡å–ç‰¹æ®Šé¢„é˜²æªæ–½çš„æƒ…å†µï¼ˆä¾‹å¦‚åœ¨ä½¿ç”¨æ¨¡å‹å¹¶è¡Œæ—¶ï¼‰ã€‚

+   `save_function` (`Callable`) â€” ç”¨äºä¿å­˜çŠ¶æ€å­—å…¸çš„å‡½æ•°ã€‚åœ¨åƒ TPU è¿™æ ·çš„åˆ†å¸ƒå¼è®­ç»ƒä¸­å¾ˆæœ‰ç”¨ï¼Œå½“éœ€è¦ç”¨å¦ä¸€ç§æ–¹æ³•æ›¿æ¢`torch.save`æ—¶ã€‚

+   `push_to_hub` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” æ˜¯å¦åœ¨ä¿å­˜åå°†æ¨¡å‹æ¨é€åˆ° Hugging Face æ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨`repo_id`æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„`save_directory`çš„åç§°ï¼‰ã€‚

+   `max_shard_size` (`int`æˆ–`str`ï¼Œ*optional*ï¼Œé»˜è®¤ä¸º`"5GB"`) â€” åœ¨åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åï¼Œæ£€æŸ¥ç‚¹åˆ†ç‰‡çš„å¤§å°å°†å°äºæ­¤å¤§å°ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚`"5MB"`ï¼‰ã€‚æˆ‘ä»¬å°†å…¶é»˜è®¤ä¸º 5GBï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿåœ¨å…è´¹çš„ Google Colab å®ä¾‹ä¸Šè½»æ¾è¿è¡Œï¼Œè€Œä¸ä¼šå‡ºç° CPU OOM é—®é¢˜ã€‚

    å¦‚æœæ¨¡å‹çš„å•ä¸ªæƒé‡å¤§äº`max_shard_size`ï¼Œåˆ™å®ƒå°†åœ¨è‡ªå·±çš„æ£€æŸ¥ç‚¹åˆ†ç‰‡ä¸­ï¼Œè¯¥åˆ†ç‰‡å°†å¤§äº`max_shard_size`ã€‚

+   `safe_serialization` (`bool`, *optional*, é»˜è®¤ä¸º`True`) â€” æ˜¯å¦ä½¿ç”¨`safetensors`æˆ–ä¼ ç»Ÿçš„ PyTorch æ–¹å¼ï¼ˆä½¿ç”¨`pickle`ï¼‰ä¿å­˜æ¨¡å‹ã€‚

+   `variant` (`str`, *å¯é€‰*) â€” å¦‚æœæŒ‡å®šï¼Œæƒé‡å°†ä»¥ pytorch_model.<variant>.bin çš„æ ¼å¼ä¿å­˜ã€‚

+   `token` (`str` æˆ– `bool`, *å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä½¿ç”¨è¿è¡Œ `huggingface-cli login` æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface` ä¸­ï¼‰ã€‚

+   `save_peft_format` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `True`) â€” ä¸ºäº†å‘åå…¼å®¹ PEFT åº“ï¼Œå¦‚æœé€‚é…å™¨æƒé‡é™„åŠ åˆ°æ¨¡å‹ä¸Šï¼Œé€‚é…å™¨çŠ¶æ€å­—å…¸çš„æ‰€æœ‰é”®éƒ½éœ€è¦ä»¥ `base_model.model` ä¸ºå‰ç¼€ã€‚é«˜çº§ç”¨æˆ·å¯ä»¥é€šè¿‡å°† `save_peft_format` è®¾ç½®ä¸º `False` æ¥ç¦ç”¨æ­¤è¡Œä¸ºã€‚

+   `kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ä¼ é€’ç»™ push_to_hub() æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å°†æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶ä¿å­˜åˆ°ç›®å½•ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ from_pretrained() ç±»æ–¹æ³•é‡æ–°åŠ è½½ã€‚

#### `set_input_embeddings`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1601)

```py
( value: Module )
```

å‚æ•°

+   `value` (`nn.Module`) â€” å°†è¯æ±‡æ˜ å°„åˆ°éšè—çŠ¶æ€çš„æ¨¡å—ã€‚

è®¾ç½®æ¨¡å‹çš„è¾“å…¥åµŒå…¥ã€‚

#### `tie_weights`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1641)

```py
( )
```

å°†è¾“å…¥åµŒå…¥å’Œè¾“å‡ºåµŒå…¥ä¹‹é—´çš„æƒé‡ç»‘å®šåœ¨ä¸€èµ·ã€‚

å¦‚æœé…ç½®ä¸­è®¾ç½®äº† `torchscript` æ ‡å¿—ï¼Œåˆ™æ— æ³•å¤„ç†å‚æ•°å…±äº«ï¼Œå› æ­¤æˆ‘ä»¬ä¼šå…‹éš†æƒé‡ã€‚

#### `to_bettertransformer`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4453)

```py
( ) â†’ export const metadata = 'undefined';PreTrainedModel
```

è¿”å›

PreTrainedModel

è½¬æ¢ä¸º BetterTransformer çš„æ¨¡å‹ã€‚

å°†æ¨¡å‹è½¬æ¢ä¸ºä½¿ç”¨[PyTorch çš„æœ¬æœºæ³¨æ„åŠ›å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)ï¼Œé€šè¿‡[Optimum åº“](https://huggingface.co/docs/optimum/bettertransformer/overview)é›†æˆåˆ° Transformers ä¸­ã€‚ä»…æ”¯æŒæ‰€æœ‰ Transformers æ¨¡å‹çš„å­é›†ã€‚

PyTorch çš„æ³¨æ„åŠ›å¿«é€Ÿè·¯å¾„å…è®¸é€šè¿‡å†…æ ¸èåˆå’Œä½¿ç”¨[åµŒå¥—å¼ é‡](https://pytorch.org/docs/stable/nested.html)åŠ é€Ÿæ¨ç†ã€‚è¯¦ç»†çš„åŸºå‡†æµ‹è¯•å¯ä»¥åœ¨[è¿™ç¯‡åšæ–‡](https://medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2)ä¸­æ‰¾åˆ°ã€‚

#### `warn_if_padding_and_no_attention_mask`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L4503)

```py
( input_ids attention_mask )
```

å¦‚æœè¾“å…¥çš„ input_ids çœ‹èµ·æ¥åŒ…å«å¡«å……å¹¶ä¸”æ²¡æœ‰ç»™å‡ºæ³¨æ„åŠ›æ©ç ï¼Œåˆ™æ˜¾ç¤ºä¸€æ¬¡è­¦å‘Šã€‚

### å¤§å‹æ¨¡å‹åŠ è½½

åœ¨ Transformers 4.20.0 ä¸­ï¼Œfrom_pretrained() æ–¹æ³•å·²ç»é‡æ–°è®¾è®¡ï¼Œä»¥é€‚åº”ä½¿ç”¨[Accelerate](https://huggingface.co/docs/accelerate/big_modeling)çš„å¤§å‹æ¨¡å‹ã€‚è¿™éœ€è¦ Accelerate >= 0.9.0 å’Œ PyTorch >= 1.9.0ã€‚ä¸å…¶åœ¨å†…å­˜ä¸­åˆ›å»ºå®Œæ•´æ¨¡å‹ï¼Œç„¶ååŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆè¿™éœ€è¦æ¨¡å‹å¤§å°çš„ä¸¤å€çš„å†…å­˜ï¼Œä¸€ä¸ªç”¨äºéšæœºåˆå§‹åŒ–æ¨¡å‹ï¼Œä¸€ä¸ªç”¨äºæƒé‡ï¼‰ï¼Œç°åœ¨æœ‰ä¸€ä¸ªé€‰é¡¹å¯ä»¥åˆ›å»ºæ¨¡å‹ä½œä¸ºç©ºå£³ï¼Œç„¶ååªæœ‰åœ¨åŠ è½½é¢„è®­ç»ƒæƒé‡æ—¶æ‰å®ç°å…¶å‚æ•°ã€‚

å¯ä»¥é€šè¿‡ `low_cpu_mem_usage=True` æ¿€æ´»æ­¤é€‰é¡¹ã€‚æ¨¡å‹é¦–å…ˆåœ¨ Meta è®¾å¤‡ä¸Šåˆ›å»ºï¼ˆå¸¦æœ‰ç©ºæƒé‡ï¼‰ï¼Œç„¶åçŠ¶æ€å­—å…¸è¢«åŠ è½½åˆ°å…¶ä¸­ï¼ˆåœ¨åˆ†ç‰‡æ£€æŸ¥ç‚¹çš„æƒ…å†µä¸‹é€ä¸ªåˆ†ç‰‡ï¼‰ã€‚è¿™æ ·ï¼Œæœ€å¤§ä½¿ç”¨çš„ RAM ä»…ä¸ºæ¨¡å‹çš„å®Œæ•´å¤§å°ã€‚

```py
from transformers import AutoModelForSeq2SeqLM

t0pp = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0pp", low_cpu_mem_usage=True)
```

æ­¤å¤–ï¼Œå¦‚æœæ¨¡å‹æ— æ³•å®Œå…¨é€‚åº” RAMï¼ˆç›®å‰ä»…é€‚ç”¨äºæ¨æ–­ï¼‰ï¼Œåˆ™å¯ä»¥ç›´æ¥å°†æ¨¡å‹æ”¾ç½®åœ¨ä¸åŒçš„è®¾å¤‡ä¸Šã€‚ä½¿ç”¨`device_map="auto"`ï¼ŒAccelerate å°†ç¡®å®šå°†æ¯ä¸ªå±‚æ”¾ç½®åœ¨å“ªé‡Œä»¥æœ€å¤§åŒ–æ‚¨æœ€å¿«çš„è®¾å¤‡ï¼ˆGPUï¼‰çš„ä½¿ç”¨ï¼Œå¹¶å°†å…¶ä½™éƒ¨åˆ†å¸è½½åˆ° CPUï¼Œç”šè‡³ç¡¬ç›˜ï¼Œå¦‚æœæ‚¨æ²¡æœ‰è¶³å¤Ÿçš„ GPU RAMï¼ˆæˆ– CPU RAMï¼‰ã€‚å³ä½¿æ¨¡å‹åˆ†å¸ƒåœ¨å¤šä¸ªè®¾å¤‡ä¸Šï¼Œå®ƒä¹Ÿå°†æŒ‰ç…§æ‚¨é€šå¸¸çš„é¢„æœŸè¿è¡Œã€‚

åœ¨ä¼ é€’`device_map`æ—¶ï¼Œ`low_cpu_mem_usage`ä¼šè‡ªåŠ¨è®¾ç½®ä¸º`True`ï¼Œå› æ­¤æ‚¨æ— éœ€æŒ‡å®šå®ƒï¼š

```py
from transformers import AutoModelForSeq2SeqLM

t0pp = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0pp", device_map="auto")
```

æ‚¨å¯ä»¥æŸ¥çœ‹`hf_device_map`å±æ€§æ¥æŸ¥çœ‹æ¨¡å‹å¦‚ä½•åˆ†å¸ƒåœ¨è®¾å¤‡ä¸Šï¼š

```py
t0pp.hf_device_map
```

```py
{'shared': 0,
 'decoder.embed_tokens': 0,
 'encoder': 0,
 'decoder.block.0': 0,
 'decoder.block.1': 1,
 'decoder.block.2': 1,
 'decoder.block.3': 1,
 'decoder.block.4': 1,
 'decoder.block.5': 1,
 'decoder.block.6': 1,
 'decoder.block.7': 1,
 'decoder.block.8': 1,
 'decoder.block.9': 1,
 'decoder.block.10': 1,
 'decoder.block.11': 1,
 'decoder.block.12': 1,
 'decoder.block.13': 1,
 'decoder.block.14': 1,
 'decoder.block.15': 1,
 'decoder.block.16': 1,
 'decoder.block.17': 1,
 'decoder.block.18': 1,
 'decoder.block.19': 1,
 'decoder.block.20': 1,
 'decoder.block.21': 1,
 'decoder.block.22': 'cpu',
 'decoder.block.23': 'cpu',
 'decoder.final_layer_norm': 'cpu',
 'decoder.dropout': 'cpu',
 'lm_head': 'cpu'}
```

æ‚¨è¿˜å¯ä»¥æŒ‰ç…§ç›¸åŒæ ¼å¼ç¼–å†™è‡ªå·±çš„è®¾å¤‡æ˜ å°„ï¼ˆå°†å±‚åç§°æ˜ å°„åˆ°è®¾å¤‡çš„å­—å…¸ï¼‰ã€‚å®ƒåº”è¯¥å°†æ¨¡å‹çš„æ‰€æœ‰å‚æ•°æ˜ å°„åˆ°ç»™å®šè®¾å¤‡ï¼Œä½†å¦‚æœè¯¥å±‚å®Œå…¨ä½äºåŒä¸€è®¾å¤‡ä¸Šï¼Œåˆ™ä¸å¿…è¯¦ç»†è¯´æ˜ä¸€ä¸ªå±‚çš„æ‰€æœ‰å­æ¨¡å—å»å“ªé‡Œã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹è®¾å¤‡æ˜ å°„å¯¹äº T0pp å°†æ­£å¸¸å·¥ä½œï¼ˆåªè¦æ‚¨æœ‰ GPU å†…å­˜ï¼‰ï¼š

```py
device_map = {"shared": 0, "encoder": 0, "decoder": 1, "lm_head": 1}
```

å‡å°‘æ¨¡å‹å†…å­˜å½±å“çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä»¥è¾ƒä½ç²¾åº¦ dtypeï¼ˆå¦‚`torch.float16`ï¼‰å®ä¾‹åŒ–æ¨¡å‹ï¼Œæˆ–è€…ä½¿ç”¨ä¸‹é¢æè¿°çš„ç›´æ¥é‡åŒ–æŠ€æœ¯ã€‚

### æ¨¡å‹å®ä¾‹åŒ– dtype

åœ¨ Pytorch ä¸‹ï¼Œæ¨¡å‹é€šå¸¸ä»¥`torch.float32`æ ¼å¼å®ä¾‹åŒ–ã€‚å¦‚æœå°è¯•åŠ è½½æƒé‡ä¸º fp16 çš„æ¨¡å‹ï¼Œåˆ™å¯èƒ½ä¼šå‡ºç°é—®é¢˜ï¼Œå› ä¸ºå®ƒå°†éœ€è¦ä¸¤å€çš„å†…å­˜ã€‚ä¸ºäº†å…‹æœè¿™ä¸ªé™åˆ¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`torch_dtype`å‚æ•°æ˜¾å¼ä¼ é€’æ‰€éœ€çš„`dtype`ï¼š

```py
model = T5ForConditionalGeneration.from_pretrained("t5", torch_dtype=torch.float16)
```

æˆ–è€…ï¼Œå¦‚æœå¸Œæœ›æ¨¡å‹å§‹ç»ˆä»¥æœ€ä½³å†…å­˜æ¨¡å¼åŠ è½½ï¼Œå¯ä»¥ä½¿ç”¨ç‰¹æ®Šå€¼`"auto"`ï¼Œç„¶å`dtype`å°†è‡ªåŠ¨ä»æ¨¡å‹çš„æƒé‡ä¸­æ´¾ç”Ÿï¼š

```py
model = T5ForConditionalGeneration.from_pretrained("t5", torch_dtype="auto")
```

ä»å¤´å¼€å§‹å®ä¾‹åŒ–çš„æ¨¡å‹ä¹Ÿå¯ä»¥æŒ‡å®šä½¿ç”¨çš„`dtype`ï¼š

```py
config = T5Config.from_pretrained("t5")
model = AutoModel.from_config(config)
```

ç”±äº Pytorch è®¾è®¡ï¼Œæ­¤åŠŸèƒ½ä»…é€‚ç”¨äºæµ®ç‚¹ dtypeã€‚

## ModuleUtilsMixin

### `class transformers.modeling_utils.ModuleUtilsMixin`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L853)

```py
( )
```

ç”¨ä½œ mixin çš„`torch.nn.Modules`çš„ä¸€äº›å®ç”¨ç¨‹åºã€‚

#### `add_memory_hooks`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L884)

```py
( )
```

åœ¨æ¯ä¸ªå­æ¨¡å—æ­£å‘ä¼ é€’ä¹‹å‰å’Œä¹‹åæ·»åŠ å†…å­˜é’©å­ä»¥è®°å½•å†…å­˜æ¶ˆè€—çš„å¢åŠ ã€‚

å†…å­˜æ¶ˆè€—çš„å¢åŠ å­˜å‚¨åœ¨æ¯ä¸ªæ¨¡å—çš„`mem_rss_diff`å±æ€§ä¸­ï¼Œå¹¶å¯ä»¥ä½¿ç”¨`model.reset_memory_hooks_state()`å°†å…¶é‡ç½®ä¸ºé›¶ã€‚

#### `estimate_tokens`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1109)

```py
( input_dict: Dict ) â†’ export const metadata = 'undefined';int
```

å‚æ•°

+   `inputs`ï¼ˆ`dict`ï¼‰â€” æ¨¡å‹è¾“å…¥ã€‚

è¿”å›

`int`

ä»¤ç‰Œçš„æ€»æ•°ã€‚

ç”¨äºä¼°è®¡æ¨¡å‹è¾“å…¥ä¸­æ€»ä»¤ç‰Œæ•°çš„è¾…åŠ©å‡½æ•°ã€‚

#### `floating_point_ops`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1130)

```py
( input_dict: Dict exclude_embeddings: bool = True ) â†’ export const metadata = 'undefined';int
```

å‚æ•°

+   `batch_size`ï¼ˆ`int`ï¼‰â€” æ­£å‘ä¼ é€’çš„æ‰¹é‡å¤§å°ã€‚

+   `sequence_length`ï¼ˆ`int`ï¼‰â€” æ¯ä¸ªæ‰¹æ¬¡è¡Œä¸­çš„ä»¤ç‰Œæ•°ã€‚

+   `exclude_embeddings`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦è®¡ç®—åµŒå…¥å’Œ softmax æ“ä½œã€‚

è¿”å›

`int`

æµ®ç‚¹è¿ç®—çš„æ•°é‡ã€‚

ä½¿ç”¨æ­¤è½¬æ¢å™¨æ¨¡å‹çš„æ‰¹å¤„ç†çš„æ­£å‘å’Œåå‘ä¼ é€’çš„æµ®ç‚¹æ“ä½œçš„æ•°é‡ï¼ˆå¯é€‰ï¼ŒéåµŒå…¥ï¼‰ã€‚é»˜è®¤è¿‘ä¼¼å¿½ç•¥å¯¹ä»¤ç‰Œæ•°é‡çš„äºŒæ¬¡ä¾èµ–ï¼ˆå¦‚æœ`12 * d_model << sequence_length`ï¼‰å¦‚[æœ¬æ–‡](https://arxiv.org/pdf/2001.08361.pdf)ç¬¬ 2.1 èŠ‚æ‰€è¿°ã€‚å¯¹äºå…·æœ‰å‚æ•°é‡ç”¨çš„å˜å‹å™¨ï¼ˆä¾‹å¦‚ Albert æˆ–é€šç”¨å˜å‹å™¨ï¼‰æˆ–è€…å¦‚æœä½¿ç”¨éå¸¸é«˜çš„åºåˆ—é•¿åº¦è¿›è¡Œé•¿è·ç¦»å»ºæ¨¡ï¼Œåˆ™åº”è¯¥è¿›è¡Œè¦†ç›–ã€‚

#### `get_extended_attention_mask`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L972)

```py
( attention_mask: Tensor input_shape: Tuple device: device = None dtype: torch.float32 = None )
```

å‚æ•°

+   `attention_mask` (`torch.Tensor`) â€” ä¸€ä¸ªæ©ç ï¼Œå…¶ä¸­çš„ 1 è¡¨ç¤ºè¦å…³æ³¨çš„æ ‡è®°ï¼Œ0 è¡¨ç¤ºè¦å¿½ç•¥çš„æ ‡è®°ã€‚

+   `input_shape` (`Tuple[int]`) â€” æ¨¡å‹çš„è¾“å…¥å½¢çŠ¶ã€‚

ä½¿å¯å¹¿æ’­çš„æ³¨æ„åŠ›å’Œå› æœæ©ç ï¼Œä»¥ä¾¿å°†æ¥å’Œæ©ç çš„æ ‡è®°è¢«å¿½ç•¥ã€‚

#### `get_head_mask`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1024)

```py
( head_mask: Optional num_hidden_layers: int is_attention_chunked: bool = False )
```

å‚æ•°

+   `head_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`[num_heads]`æˆ–`[num_hidden_layers x num_heads]`ï¼Œ*å¯é€‰*) â€” æŒ‡ç¤ºæˆ‘ä»¬æ˜¯å¦åº”ä¿ç•™å¤´éƒ¨çš„æ©ç ï¼ˆä¿ç•™ä¸º 1.0ï¼Œä¸¢å¼ƒä¸º 0.0ï¼‰ã€‚

+   `num_hidden_layers` (`int`) â€” æ¨¡å‹ä¸­çš„éšè—å±‚æ•°é‡ã€‚

+   `is_attention_chunked` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ³¨æ„åŠ›åˆ†æ•°æ˜¯å¦æŒ‰å—è®¡ç®—ã€‚

å¦‚æœéœ€è¦ï¼Œå‡†å¤‡å¤´æ©ç ã€‚

#### `invert_attention_mask`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L920)

```py
( encoder_attention_mask: Tensor ) â†’ export const metadata = 'undefined';torch.Tensor
```

å‚æ•°

+   `encoder_attention_mask` (`torch.Tensor`) â€” ä¸€ä¸ªæ³¨æ„åŠ›æ©ç ã€‚

è¿”å›

`torch.Tensor`

åè½¬çš„æ³¨æ„åŠ›æ©ç ã€‚

åè½¬æ³¨æ„åŠ›æ©ç ï¼ˆä¾‹å¦‚ï¼Œåˆ‡æ¢ 0 å’Œ 1ï¼‰ã€‚

#### `num_parameters`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L1062)

```py
( only_trainable: bool = False exclude_embeddings: bool = False ) â†’ export const metadata = 'undefined';int
```

å‚æ•°

+   `only_trainable` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åªè¿”å›å¯è®­ç»ƒå‚æ•°çš„æ•°é‡

+   `exclude_embeddings` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åªè¿”å›éåµŒå…¥å‚æ•°çš„æ•°é‡

è¿”å›

`int`

å‚æ•°çš„æ•°é‡ã€‚

è·å–æ¨¡å—ä¸­ï¼ˆå¯é€‰åœ°ï¼Œå¯è®­ç»ƒæˆ–éåµŒå…¥ï¼‰å‚æ•°çš„æ•°é‡ã€‚

#### `reset_memory_hooks_state`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L896)

```py
( )
```

é‡ç½®æ¯ä¸ªæ¨¡å—çš„`mem_rss_diff`å±æ€§ï¼ˆå‚è§ add_memory_hooks()ï¼‰ã€‚

## TFPreTrainedModel

### `class transformers.TFPreTrainedModel`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1058)

```py
( config *inputs **kwargs )
```

æ‰€æœ‰ TF æ¨¡å‹çš„åŸºç±»ã€‚

TFPreTrainedModel ç±»è´Ÿè´£å­˜å‚¨æ¨¡å‹çš„é…ç½®ï¼Œå¹¶å¤„ç†åŠ è½½ã€ä¸‹è½½å’Œä¿å­˜æ¨¡å‹çš„æ–¹æ³•ï¼Œä»¥åŠä¸€äº›æ‰€æœ‰æ¨¡å‹é€šç”¨çš„æ–¹æ³•ï¼š

+   è°ƒæ•´è¾“å…¥åµŒå…¥ï¼Œ

+   ä¿®å‰ªè‡ªæ³¨æ„åŠ›å¤´ã€‚

ç±»å±æ€§ï¼ˆç”±æ´¾ç”Ÿç±»è¦†ç›–ï¼‰ï¼š

+   `config_class` (PretrainedConfig) â€” ç”¨ä½œæ­¤æ¨¡å‹æ¶æ„çš„é…ç½®ç±»çš„ PretrainedConfig çš„å­ç±»ã€‚

+   `base_model_prefix` (`str`) â€” ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡ç¤ºæ´¾ç”Ÿç±»ä¸­åŸºç¡€æ¨¡å‹å…³è”çš„å±æ€§ï¼Œåœ¨åŒä¸€æ¶æ„çš„æ´¾ç”Ÿç±»ä¸­æ·»åŠ æ¨¡å—åˆ°åŸºç¡€æ¨¡å‹ä¹‹ä¸Šã€‚

+   `main_input_name` (`str`) â€” æ¨¡å‹çš„ä¸»è¦è¾“å…¥çš„åç§°ï¼ˆé€šå¸¸ä¸º NLP æ¨¡å‹çš„`input_ids`ï¼Œè§†è§‰æ¨¡å‹çš„`pixel_values`å’Œè¯­éŸ³æ¨¡å‹çš„`input_values`ï¼‰ã€‚

#### `push_to_hub`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L3067)

```py
( repo_id: str use_temp_dir: Optional[bool] = None commit_message: Optional[str] = None private: Optional[bool] = None max_shard_size: Optional[Union[int, str]] = '10GB' token: Optional[Union[bool, str]] = None use_auth_token: Optional[Union[bool, str]] = None create_pr: bool = False **base_model_card_args )
```

å‚æ•°

+   `repo_id` (`str`) â€” æ‚¨è¦å°†æ¨¡å‹æ¨é€åˆ°çš„å­˜å‚¨åº“çš„åç§°ã€‚åœ¨æ¨é€åˆ°ç»™å®šç»„ç»‡æ—¶ï¼Œåº”åŒ…å«æ‚¨çš„ç»„ç»‡åç§°ã€‚

+   `use_temp_dir` (`bool`, *å¯é€‰*) â€” æ˜¯å¦ä½¿ç”¨ä¸´æ—¶ç›®å½•å­˜å‚¨ä¿å­˜çš„æ–‡ä»¶ï¼Œç›´åˆ°å®ƒä»¬è¢«æ¨é€åˆ° Hubã€‚å¦‚æœæ²¡æœ‰åä¸º`repo_id`çš„ç›®å½•ï¼Œåˆ™é»˜è®¤ä¸º`True`ï¼Œå¦åˆ™ä¸º`False`ã€‚

+   `commit_message` (`str`, *å¯é€‰*) â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º`"Upload model"`ã€‚

+   `private`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦åº”åˆ›å»ºç§æœ‰å­˜å‚¨åº“ã€‚

+   `token`ï¼ˆ`bool`æˆ–`str`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º`True`ï¼Œå°†ä½¿ç”¨è¿è¡Œ`huggingface-cli login`æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨`~/.huggingface`ä¸­ï¼‰ã€‚å¦‚æœæœªæŒ‡å®š`repo_url`ï¼Œåˆ™é»˜è®¤ä¸º`True`ã€‚

+   `max_shard_size`ï¼ˆ`int`æˆ–`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"10GB"`ï¼‰â€” ä»…é€‚ç”¨äºæ¨¡å‹ã€‚åœ¨åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åï¼Œæ£€æŸ¥ç‚¹åˆ†ç‰‡å°†æ¯ä¸ªå¤§å°å°äºæ­¤å¤§å°ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚`"5MB"`ï¼‰ã€‚

+   `create_pr`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€” æ˜¯å¦åˆ›å»ºå¸¦æœ‰ä¸Šä¼ æ–‡ä»¶çš„ PR æˆ–ç›´æ¥æäº¤ã€‚

å°†æ¨¡å‹æ–‡ä»¶ä¸Šä¼ åˆ°ğŸ¤—æ¨¡å‹ Hubï¼ŒåŒæ—¶åŒæ­¥å­˜å‚¨åº“çš„æœ¬åœ°å…‹éš†åˆ°`repo_path_or_name`ä¸­ã€‚

ç¤ºä¾‹ï¼š

```py
from transformers import TFAutoModel

model = TFAutoModel.from_pretrained("bert-base-cased")

# Push the model to your namespace with the name "my-finetuned-bert".
model.push_to_hub("my-finetuned-bert")

# Push the model to an organization with the name "my-finetuned-bert".
model.push_to_hub("huggingface/my-finetuned-bert")
```

#### `can_generate`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1301)

```py
( ) â†’ export const metadata = 'undefined';bool
```

è¿”å›

`bool`

æ­¤æ¨¡å‹æ˜¯å¦å¯ä»¥ä½¿ç”¨`.generate()`ç”Ÿæˆåºåˆ—ã€‚

è¿”å›æ­¤æ¨¡å‹æ˜¯å¦å¯ä»¥ä½¿ç”¨`.generate()`ç”Ÿæˆåºåˆ—ã€‚

#### `compile`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1496)

```py
( optimizer = 'rmsprop' loss = 'auto_with_warning' metrics = None loss_weights = None weighted_metrics = None run_eagerly = None steps_per_execution = None **kwargs )
```

è¿™æ˜¯ä¸€ä¸ªè–„åŒ…è£…å™¨ï¼Œå¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šè‡ªå·±çš„æŸå¤±å‡½æ•°ï¼Œåˆ™å°†æ¨¡å‹çš„æŸå¤±è¾“å‡ºå¤´è®¾ç½®ä¸ºæŸå¤±ã€‚

#### `create_model_card`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1791)

```py
( output_dir model_name: str language: Optional[str] = None license: Optional[str] = None tags: Optional[str] = None finetuned_from: Optional[str] = None tasks: Optional[str] = None dataset_tags: Optional[Union[str, List[str]]] = None dataset: Optional[Union[str, List[str]]] = None dataset_args: Optional[Union[str, List[str]]] = None )
```

å‚æ•°

+   `output_dir`ï¼ˆ`str`æˆ–`os.PathLike`ï¼‰â€” åˆ›å»ºæ¨¡å‹å¡ç‰‡çš„æ–‡ä»¶å¤¹ã€‚

+   `model_name`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” æ¨¡å‹çš„åç§°ã€‚

+   `language`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” æ¨¡å‹çš„è¯­è¨€ï¼ˆå¦‚æœé€‚ç”¨ï¼‰

+   `license`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” æ¨¡å‹çš„è®¸å¯è¯ã€‚å¦‚æœç»™å®šç»™`Trainer`çš„åŸå§‹æ¨¡å‹æ¥è‡ª Hub ä¸Šçš„ repoï¼Œåˆ™é»˜è®¤ä¸ºä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹çš„è®¸å¯è¯ã€‚

+   `tags`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” è¦åŒ…å«åœ¨æ¨¡å‹å¡ç‰‡çš„å…ƒæ•°æ®ä¸­çš„ä¸€äº›æ ‡ç­¾ã€‚

+   `finetuned_from`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºå¾®è°ƒæ­¤æ¨¡å‹çš„æ¨¡å‹çš„åç§°ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ã€‚å¦‚æœæ¥è‡ª Hub çš„åŸå§‹æ¨¡å‹çš„`Trainer`ç»™å‡ºçš„ repo çš„åç§°ï¼Œåˆ™é»˜è®¤ä¸ºåŸå§‹æ¨¡å‹çš„åç§°ã€‚

+   `tasks`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ä¸ªæˆ–å¤šä¸ªä»»åŠ¡æ ‡è¯†ç¬¦ï¼Œè¦åŒ…å«åœ¨æ¨¡å‹å¡ç‰‡çš„å…ƒæ•°æ®ä¸­ã€‚

+   `dataset_tags`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®é›†æ ‡ç­¾ï¼Œè¦åŒ…å«åœ¨æ¨¡å‹å¡ç‰‡çš„å…ƒæ•°æ®ä¸­ã€‚

+   `dataset`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®é›†æ ‡è¯†ç¬¦ï¼Œè¦åŒ…å«åœ¨æ¨¡å‹å¡ç‰‡çš„å…ƒæ•°æ®ä¸­ã€‚

+   `dataset_args`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®é›†å‚æ•°ï¼Œè¦åŒ…å«åœ¨æ¨¡å‹å¡ç‰‡çš„å…ƒæ•°æ®ä¸­ã€‚

ä½¿ç”¨`Trainer`å¯ç”¨çš„ä¿¡æ¯åˆ›å»ºæ¨¡å‹å¡ç‰‡çš„è‰ç¨¿ã€‚

#### `eager_serving`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1213)

```py
( inputs )
```

å‚æ•°

+   `inputs`ï¼ˆ`Dict[str, tf.Tensor]`ï¼‰â€” ä¿å­˜æ¨¡å‹çš„è¾“å…¥ï¼Œä½œä¸ºå¼ é‡å­—å…¸ã€‚

ç”¨äºæä¾›æ¨¡å‹çš„æ–¹æ³•ã€‚æ­¤æ–¹æ³•å·²å¼ƒç”¨ï¼Œå°†è¢«ç§»é™¤ã€‚

#### `from_pretrained`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L2499)

```py
( pretrained_model_name_or_path: Optional[Union[str, os.PathLike]] *model_args config: Optional[Union[PretrainedConfig, str, os.PathLike]] = None cache_dir: Optional[Union[str, os.PathLike]] = None ignore_mismatched_sizes: bool = False force_download: bool = False local_files_only: bool = False token: Optional[Union[str, bool]] = None revision: str = 'main' use_safetensors: bool = None **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼‰â€” å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒæ¨¡å‹çš„*æ¨¡å‹ id*ï¼Œæ‰˜ç®¡åœ¨ huggingface.co ä¸Šçš„æ¨¡å‹å­˜å‚¨åº“ä¸­ã€‚æœ‰æ•ˆçš„æ¨¡å‹ id å¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚`bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´ï¼Œå¦‚`dbmdz/bert-base-german-cased`ã€‚

    +   ä¸€ä¸ª*ç›®å½•*çš„è·¯å¾„ï¼Œå…¶ä¸­åŒ…å«ä½¿ç”¨ save_pretrained()ä¿å­˜çš„æ¨¡å‹æƒé‡ï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/`ã€‚

    +   ä¸€ä¸ª *PyTorch state_dict ä¿å­˜æ–‡ä»¶* çš„è·¯å¾„æˆ– urlï¼ˆä¾‹å¦‚ï¼Œ`./pt_model/pytorch_model.bin`ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`from_pt` åº”è®¾ç½®ä¸º `True`ï¼Œå¹¶ä¸”åº”å°†é…ç½®å¯¹è±¡ä½œä¸º `config` å‚æ•°æä¾›ã€‚ä½¿ç”¨æ­¤åŠ è½½è·¯å¾„æ¯”ä½¿ç”¨æä¾›çš„è½¬æ¢è„šæœ¬å°† PyTorch æ¨¡å‹è½¬æ¢ä¸º TensorFlow æ¨¡å‹å¹¶éšååŠ è½½ TensorFlow æ¨¡å‹è¦æ…¢ã€‚

    +   å¦‚æœæ‚¨åŒæ—¶æä¾›é…ç½®å’ŒçŠ¶æ€å­—å…¸ï¼ˆåˆ†åˆ«ä½¿ç”¨å…³é”®å­—å‚æ•° `config` å’Œ `state_dict`ï¼‰ï¼Œåˆ™ä¸º `None`ã€‚

+   `model_args`ï¼ˆä½ç½®å‚æ•°åºåˆ—ï¼Œ*å¯é€‰*ï¼‰ â€” æ‰€æœ‰å‰©ä½™çš„ä½ç½®å‚æ•°å°†ä¼ é€’ç»™åº•å±‚æ¨¡å‹çš„ `__init__` æ–¹æ³•ã€‚

+   `config` (`Union[PretrainedConfig, str]`, *å¯é€‰*) â€” å¯ä»¥æ˜¯ï¼š

    +   ä» PretrainedConfig æ´¾ç”Ÿçš„ç±»çš„å®ä¾‹ï¼Œ

    +   ä½œä¸º from_pretrained() è¾“å…¥æœ‰æ•ˆçš„å­—ç¬¦ä¸²ã€‚

    ç”¨äºæ›¿ä»£è‡ªåŠ¨åŠ è½½é…ç½®çš„æ¨¡å‹é…ç½®ã€‚å½“ä»¥ä¸‹æƒ…å†µå‘ç”Ÿæ—¶ï¼Œé…ç½®å¯ä»¥è‡ªåŠ¨åŠ è½½ï¼š

    +   æ¨¡å‹æ˜¯åº“æä¾›çš„æ¨¡å‹ï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„ *æ¨¡å‹ id* å­—ç¬¦ä¸²åŠ è½½ï¼‰ã€‚

    +   æ¨¡å‹æ˜¯ä½¿ç”¨ save_pretrained() ä¿å­˜çš„ï¼Œå¹¶é€šè¿‡æä¾›ä¿å­˜ç›®å½•é‡æ–°åŠ è½½ã€‚

    +   é€šè¿‡æä¾›æœ¬åœ°ç›®å½•ä½œä¸º `pretrained_model_name_or_path` å¹¶åœ¨ç›®å½•ä¸­æ‰¾åˆ°åä¸º *config.json* çš„é…ç½® JSON æ–‡ä»¶æ¥åŠ è½½æ¨¡å‹ã€‚

+   `from_pt` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” ä» PyTorch state_dict ä¿å­˜æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡ï¼ˆè¯·å‚é˜… `pretrained_model_name_or_path` å‚æ•°çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼‰ã€‚

+   `ignore_mismatched_sizes` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨æ£€æŸ¥ç‚¹çš„æŸäº›æƒé‡ä¸æ¨¡å‹çš„æƒé‡å¤§å°ä¸åŒæ—¶å¼•å‘é”™è¯¯ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä»å…·æœ‰ 3 ä¸ªæ ‡ç­¾çš„æ£€æŸ¥ç‚¹å®ä¾‹åŒ–å…·æœ‰ 10 ä¸ªæ ‡ç­¾çš„æ¨¡å‹ï¼‰ã€‚

+   `cache_dir` (`str`, *å¯é€‰*) â€” ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®åº”ç¼“å­˜åœ¨å…¶ä¸­çš„ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸åº”ä½¿ç”¨æ ‡å‡†ç¼“å­˜ã€‚

+   `force_download` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

+   `resume_download` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åˆ é™¤æ¥æ”¶ä¸å®Œæ•´çš„æ–‡ä»¶ã€‚å¦‚æœå­˜åœ¨è¿™æ ·çš„æ–‡ä»¶ï¼Œå°†å°è¯•æ¢å¤ä¸‹è½½ã€‚ä»£ç† â€” (`Dict[str, str],` å¯é€‰`): ç”¨äºæ¯ä¸ªè¯·æ±‚çš„åè®®æˆ–ç«¯ç‚¹çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚` {â€˜httpâ€™: â€˜foo.bar:3128â€™, â€˜http://hostnameâ€™: â€˜foo.bar:4012â€™}`ã€‚ä»£ç†å°†ç”¨äºæ¯ä¸ªè¯·æ±‚ã€‚output_loading_info(`bool`, *å¯é€‰*, é»˜è®¤ä¸º` False`): æ˜¯å¦è¿”å›åŒ…å«ç¼ºå¤±é”®ã€æ„å¤–é”®å’Œé”™è¯¯æ¶ˆæ¯çš„å­—å…¸ã€‚

+   `local_files_only(bool,` *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…æŸ¥çœ‹æœ¬åœ°æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼Œä¸å°è¯•ä¸‹è½½æ¨¡å‹ï¼‰ã€‚

+   `token` (`str` æˆ– `bool`, *å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œæˆ–è€…æœªæŒ‡å®šï¼Œåˆ™å°†ä½¿ç”¨è¿è¡Œ `huggingface-cli login` æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface` ä¸­ï¼‰ã€‚

+   `revision` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å®ƒå¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°æˆ–æäº¤ idï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ huggingface.co ä¸Šä½¿ç”¨åŸºäº git çš„ç³»ç»Ÿå­˜å‚¨æ¨¡å‹å’Œå…¶ä»–å·¥ä»¶ï¼Œæ‰€ä»¥ `revision` å¯ä»¥æ˜¯ git å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚

ä»é¢„è®­ç»ƒæ¨¡å‹é…ç½®å®ä¾‹åŒ–é¢„è®­ç»ƒçš„ TF 2.0 æ¨¡å‹ã€‚

è­¦å‘Š *Weights from XXX not initialized from pretrained model* æ„å‘³ç€ XXX çš„æƒé‡ä¸æ˜¯ä¸æ¨¡å‹çš„å…¶ä½™éƒ¨åˆ†ä¸€èµ·é¢„è®­ç»ƒçš„ã€‚æ‚¨éœ€è¦ä½¿ç”¨ä¸‹æ¸¸å¾®è°ƒä»»åŠ¡æ¥è®­ç»ƒè¿™äº›æƒé‡ã€‚

è­¦å‘Š*æ¥è‡ª XXX çš„æƒé‡åœ¨ YYY ä¸­æœªä½¿ç”¨*è¡¨ç¤ºå±‚ XXX æœªè¢« YYY ä½¿ç”¨ï¼Œå› æ­¤è¿™äº›æƒé‡è¢«ä¸¢å¼ƒã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import BertConfig, TFBertModel

>>> # Download model and configuration from huggingface.co and cache.
>>> model = TFBertModel.from_pretrained("bert-base-uncased")
>>> # Model was saved using *save_pretrained('./test/saved_model/')* (for example purposes, not runnable).
>>> model = TFBertModel.from_pretrained("./test/saved_model/")
>>> # Update configuration during loading.
>>> model = TFBertModel.from_pretrained("bert-base-uncased", output_attentions=True)
>>> assert model.config.output_attentions == True
>>> # Loading from a Pytorch model file instead of a TensorFlow checkpoint (slower, for example purposes, not runnable).
>>> config = BertConfig.from_json_file("./pt_model/my_pt_model_config.json")
>>> model = TFBertModel.from_pretrained("./pt_model/my_pytorch_model.bin", from_pt=True, config=config)
```

#### `get_bias`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1931)

```py
( ) â†’ export const metadata = 'undefined';tf.Variable
```

è¿”å›

`tf.Variable`

è¡¨ç¤ºåç½®çš„æƒé‡ï¼Œå¦‚æœä¸æ˜¯ LM æ¨¡å‹åˆ™ä¸º Noneã€‚

é™„åŠ åˆ° LM head çš„åç½®çš„å­—å…¸ã€‚é”®è¡¨ç¤ºåç½®å±æ€§çš„åç§°ã€‚

#### `get_head_mask`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1168)

```py
( head_mask: tf.Tensor | None num_hidden_layers: int )
```

å‚æ•°

+   `head_mask` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º `[num_heads]` æˆ– `[num_hidden_layers x num_heads]`ï¼Œ*å¯é€‰*) â€” æŒ‡ç¤ºæˆ‘ä»¬æ˜¯å¦åº”ä¿ç•™å¤´éƒ¨çš„æ©ç ï¼ˆä¿ç•™ä¸º 1.0ï¼Œä¸¢å¼ƒä¸º 0.0ï¼‰ã€‚

+   `num_hidden_layers` (`int`) â€” æ¨¡å‹ä¸­çš„éšè—å±‚æ•°é‡ã€‚

å¦‚æœéœ€è¦ï¼Œå‡†å¤‡å¤´éƒ¨æ©ç ã€‚

#### `get_input_embeddings`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1315)

```py
( ) â†’ export const metadata = 'undefined';tf.Variable
```

è¿”å›

`tf.Variable`

å°†è¯æ±‡æ˜ å°„åˆ°éšè—çŠ¶æ€çš„åµŒå…¥å±‚ã€‚

è¿”å›æ¨¡å‹çš„è¾“å…¥åµŒå…¥å±‚ã€‚

#### `get_lm_head`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1964)

```py
( ) â†’ export const metadata = 'undefined';tf.keras.layers.Layer
```

è¿”å›

`tf.keras.layers.Layer`

å¦‚æœæ¨¡å‹æœ‰ LM head å±‚ï¼Œåˆ™ä¸º LM head å±‚ï¼Œå¦åˆ™ä¸º Noneã€‚

LM Head å±‚ã€‚è¯¥æ–¹æ³•å¿…é¡»è¢«æ‰€æœ‰å…·æœ‰ lm head çš„æ¨¡å‹è¦†ç›–ã€‚

#### `get_output_embeddings`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1871)

```py
( ) â†’ export const metadata = 'undefined';tf.Variable
```

è¿”å›

`tf.Variable`

å°†è¯æ±‡æ˜ å°„åˆ°éšè—çŠ¶æ€çš„æ–°æƒé‡ã€‚

è¿”å›æ¨¡å‹çš„è¾“å‡ºåµŒå…¥

#### `get_output_layer_with_bias`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1908)

```py
( ) â†’ export const metadata = 'undefined';tf.keras.layers.Layer
```

è¿”å›

`tf.keras.layers.Layer`

å¤„ç†åç½®çš„å±‚ï¼Œå¦‚æœä¸æ˜¯ LM æ¨¡å‹åˆ™ä¸º Noneã€‚

è·å–å¤„ç†åç½®å±æ€§çš„å±‚ï¼Œå¦‚æœæ¨¡å‹å…·æœ‰å°†æƒé‡ç»‘å®šåˆ°åµŒå…¥çš„ LM head

#### `get_prefix_bias_name`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1921)

```py
( ) â†’ export const metadata = 'undefined';str
```

è¿”å›

`str`

åç½®çš„è¿æ¥å‰ç¼€åç§°ã€‚

ä»æ¨¡å‹åç§°åˆ°çˆ¶å±‚çš„åç½®çš„è¿æ¥å‰ç¼€åç§°

#### `load_repo_checkpoint`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1342)

```py
( repo_path_or_name ) â†’ export const metadata = 'undefined';dict
```

å‚æ•°

+   `repo_path_or_name` (`str`) â€” å¯ä»¥æ˜¯ Hub ä¸­æ‚¨çš„ {object} çš„å­˜å‚¨åº“åç§°ï¼Œä¹Ÿå¯ä»¥æ˜¯æœ¬åœ°æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå­˜å‚¨åº“å°†ä½¿ç”¨è¯¥æœ¬åœ°æ–‡ä»¶å¤¹çš„åç§°ï¼‰ã€‚

è¿”å›

`dict`

æ¥è‡ªæ£€æŸ¥ç‚¹çš„é¢å¤–å…ƒæ•°æ®å­—å…¸ï¼Œé€šå¸¸æ˜¯â€œæ—¶ä»£â€è®¡æ•°ã€‚

ä»å­˜å‚¨åº“åŠ è½½å·²ä¿å­˜çš„æ£€æŸ¥ç‚¹ï¼ˆæ¨¡å‹æƒé‡å’Œä¼˜åŒ–å™¨çŠ¶æ€ï¼‰ã€‚è¿”å›æ£€æŸ¥ç‚¹ç”Ÿæˆæ—¶çš„å½“å‰æ—¶ä»£è®¡æ•°ã€‚

#### `prepare_tf_dataset`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1391)

```py
( dataset: 'datasets.Dataset' batch_size: int = 8 shuffle: bool = True tokenizer: Optional['PreTrainedTokenizerBase'] = None collate_fn: Optional[Callable] = None collate_fn_args: Optional[Dict[str, Any]] = None drop_remainder: Optional[bool] = None prefetch: bool = True ) â†’ export const metadata = 'undefined';Dataset
```

å‚æ•°

+   `dataset` (`Any`) â€” è¦åŒ…è£…ä¸º `tf.data.Dataset` çš„ [~`datasets.Dataset`]ã€‚

+   `batch_size` (`int`ï¼Œé»˜è®¤ä¸º 8) â€” è¦è¿”å›çš„æ‰¹æ¬¡å¤§å°ã€‚

+   `shuffle` (`bool`ï¼Œé»˜è®¤ä¸º `True`) â€” æ˜¯å¦ä»¥éšæœºé¡ºåºè¿”å›æ•°æ®é›†ä¸­çš„æ ·æœ¬ã€‚é€šå¸¸å¯¹äºè®­ç»ƒæ•°æ®é›†ä¸º `True`ï¼Œå¯¹äºéªŒè¯/æµ‹è¯•æ•°æ®é›†ä¸º `False`ã€‚

+   `tokenizer`ï¼ˆPreTrainedTokenizerBaseï¼Œ*å¯é€‰*ï¼‰ â€” ç”¨äºå¡«å……æ ·æœ¬ä»¥åˆ›å»ºæ‰¹æ¬¡çš„ `PreTrainedTokenizer`ã€‚å¦‚æœä¼ é€’äº†ç‰¹å®šçš„ `collate_fn`ï¼Œåˆ™ä¸ä¼šäº§ç”Ÿå½±å“ã€‚

+   `collate_fn` (`Callable`ï¼Œ*å¯é€‰*) â€” ä¸€ä¸ªå°†æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•´ç†æˆå•ä¸ªæ‰¹æ¬¡çš„å‡½æ•°ã€‚å¦‚æœæœªæä¾› `tokenizer`ï¼Œåˆ™é»˜è®¤ä¸º `DefaultDataCollator`ï¼Œå¦‚æœä¼ é€’äº† `tokenizer`ï¼Œåˆ™ä¸º `DataCollatorWithPadding`ã€‚

+   `collate_fn_args` (`Dict[str, Any]`, *å¯é€‰*) â€” ä¼ é€’ç»™`collate_fn`çš„å‚æ•°å­—å…¸ï¼Œä»¥åŠæ ·æœ¬åˆ—è¡¨ã€‚

+   `drop_remainder` (`bool`, *å¯é€‰*) â€” æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªæ‰¹æ¬¡ï¼Œå¦‚æœæ‰¹æ¬¡å¤§å°ä¸èƒ½æ•´é™¤æ•°æ®é›†é•¿åº¦ã€‚é»˜è®¤è®¾ç½®ä¸`shuffle`ç›¸åŒã€‚

+   `prefetch` (`bool`, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦åœ¨`tf.data`ç®¡é“çš„æœ«å°¾æ·»åŠ é¢„å–ã€‚è¿™å‡ ä¹æ€»æ˜¯æœ‰åˆ©äºæ€§èƒ½ï¼Œä½†åœ¨è¾¹ç¼˜æƒ…å†µä¸‹å¯ä»¥ç¦ç”¨ã€‚

è¿”å›

`Dataset`

ä¸€ä¸ªå‡†å¤‡ä¼ é€’ç»™ Keras API çš„`tf.data.Dataset`ã€‚

å°† HuggingFace [Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)åŒ…è£…ä¸ºå¸¦æœ‰æ•´ç†å’Œæ‰¹å¤„ç†çš„`tf.data.Dataset`ã€‚æ­¤æ–¹æ³•æ—¨åœ¨åˆ›å»ºä¸€ä¸ªâ€œå³æ’å³ç”¨â€çš„æ•°æ®é›†ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’ç»™ Keras æ–¹æ³•ï¼Œå¦‚`fit()`ï¼Œè€Œæ— éœ€è¿›ä¸€æ­¥ä¿®æ”¹ã€‚å¦‚æœæ•°æ®é›†ä¸­çš„åˆ—ä¸æ¨¡å‹çš„è¾“å…¥åç§°ä¸åŒ¹é…ï¼Œè¯¥æ–¹æ³•å°†åˆ é™¤è¿™äº›åˆ—ã€‚å¦‚æœæ‚¨æƒ³æŒ‡å®šè¦è¿”å›çš„åˆ—åï¼Œè€Œä¸æ˜¯ä½¿ç”¨ä¸æ­¤æ¨¡å‹åŒ¹é…çš„åç§°ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨`Dataset.to_tf_dataset()`ã€‚

#### `prune_heads`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L2311)

```py
( heads_to_prune )
```

å‚æ•°

+   `heads_to_prune` (`Dict[int, List[int]]`) â€” é”®ä¸ºé€‰å®šçš„å±‚ç´¢å¼•ï¼ˆ`int`ï¼‰çš„å­—å…¸ï¼Œç›¸å…³å€¼ä¸ºè¦åœ¨è¯¥å±‚ä¸­ä¿®å‰ªçš„å¤´éƒ¨åˆ—è¡¨ï¼ˆ`int`åˆ—è¡¨ï¼‰ã€‚ä¾‹å¦‚ï¼Œ{1: [0, 2], 2: [2, 3]}å°†åœ¨ç¬¬ 1 å±‚ä¿®å‰ªå¤´éƒ¨ 0 å’Œ 2ï¼Œåœ¨ç¬¬ 2 å±‚ä¿®å‰ªå¤´éƒ¨ 2 å’Œ 3ã€‚

ä¿®å‰ªåŸºç¡€æ¨¡å‹çš„å¤´éƒ¨ã€‚

#### `register_for_auto_class`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L3176)

```py
( auto_class = 'TFAutoModel' )
```

å‚æ•°

+   `auto_class` (`str` æˆ– `type`, *å¯é€‰*, é»˜è®¤ä¸º `"TFAutoModel"`) â€” è¦æ³¨å†Œæ­¤æ–°æ¨¡å‹çš„è‡ªåŠ¨ç±»ã€‚

ä½¿ç”¨ç»™å®šçš„è‡ªåŠ¨ç±»æ³¨å†Œæ­¤ç±»ã€‚è¿™åº”ä»…ç”¨äºè‡ªå®šä¹‰æ¨¡å‹ï¼Œå› ä¸ºåº“ä¸­çš„æ¨¡å‹å·²ç»ä¸è‡ªåŠ¨ç±»æ˜ å°„ã€‚

æ­¤ API æ˜¯å®éªŒæ€§çš„ï¼Œå¯èƒ½åœ¨ä¸‹ä¸€ä¸ªç‰ˆæœ¬ä¸­æœ‰ä¸€äº›è½»å¾®çš„ç ´åæ€§æ›´æ”¹ã€‚

#### `resize_token_embeddings`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1973)

```py
( new_num_tokens: Optional[int] = None ) â†’ export const metadata = 'undefined';tf.Variable or tf.keras.layers.Embedding
```

å‚æ•°

+   `new_num_tokens` (`int`, *å¯é€‰*) â€” åµŒå…¥çŸ©é˜µä¸­çš„æ–°æ ‡è®°æ•°é‡ã€‚å¢åŠ å¤§å°å°†åœ¨æœ«å°¾æ·»åŠ æ–°åˆå§‹åŒ–çš„å‘é‡ã€‚å‡å°å¤§å°å°†ä»æœ«å°¾åˆ é™¤å‘é‡ã€‚å¦‚æœæœªæä¾›æˆ–ä¸º`None`ï¼Œåˆ™åªè¿”å›æŒ‡å‘è¾“å…¥æ ‡è®°çš„æŒ‡é’ˆï¼Œè€Œä¸æ‰§è¡Œä»»ä½•æ“ä½œã€‚

è¿”å›

`tf.Variable` æˆ– `tf.keras.layers.Embedding`

æ¨¡å‹çš„è¾“å…¥æ ‡è®°çš„æŒ‡é’ˆã€‚

å¦‚æœ`new_num_tokens != config.vocab_size`ï¼Œåˆ™è°ƒæ•´æ¨¡å‹çš„è¾“å…¥æ ‡è®°åµŒå…¥çŸ©é˜µå¤§å°ã€‚

å¦‚æœæ¨¡å‹ç±»å…·æœ‰`tie_weights()`æ–¹æ³•ï¼Œåˆ™åœ¨ä¹‹åå¤„ç†æƒé‡åµŒå…¥ã€‚

#### `save_pretrained`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L2323)

```py
( save_directory saved_model = False version = 1 push_to_hub = False signatures = None max_shard_size: Union[int, str] = '10GB' create_pr: bool = False safe_serialization: bool = False token: Optional[Union[str, bool]] = None **kwargs )
```

å‚æ•°

+   `save_directory` (`str`) â€” è¦ä¿å­˜åˆ°çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºè¯¥ç›®å½•ã€‚

+   `saved_model` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦è¿˜è¦å°†æ¨¡å‹ä¿å­˜ä¸º saved model æ ¼å¼ã€‚

+   `version` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 1) â€” å·²ä¿å­˜æ¨¡å‹çš„ç‰ˆæœ¬ã€‚ä¸ºäº†èƒ½å¤Ÿè¢« TensorFlow Serving æ­£ç¡®åŠ è½½ï¼Œä¿å­˜çš„æ¨¡å‹éœ€è¦è¿›è¡Œç‰ˆæœ¬åŒ–ï¼Œè¯¦ç»†ä¿¡æ¯è¯·å‚é˜…å®˜æ–¹æ–‡æ¡£[`www.tensorflow.org/tfx/serving/serving_basic`](https://www.tensorflow.org/tfx/serving/serving_basic)

+   `push_to_hub` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åœ¨ä¿å­˜åå°†æ¨¡å‹æ¨é€åˆ° Hugging Face æ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨`repo_id`æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„`save_directory`åç§°ï¼‰ã€‚

+   `signatures` (`dict` æˆ– `tf.function`, *å¯é€‰*) â€” ç”¨äº serving çš„æ¨¡å‹ç­¾åã€‚è¿™å°†ä¼ é€’ç»™ model.save()çš„`signatures`å‚æ•°ã€‚

+   `max_shard_size` (`int` æˆ– `str`, *å¯é€‰*, é»˜è®¤ä¸º `"10GB"`) - åœ¨åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åï¼Œæ£€æŸ¥ç‚¹åˆ†ç‰‡å°†å°äºæ­¤å¤§å°ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚ `"5MB"`ï¼‰ã€‚

    å¦‚æœæ¨¡å‹çš„å•ä¸ªæƒé‡å¤§äº `max_shard_size`ï¼Œå®ƒå°†åœ¨è‡ªå·±çš„æ£€æŸ¥ç‚¹åˆ†ç‰‡ä¸­ï¼Œè¯¥åˆ†ç‰‡å°†å¤§äº `max_shard_size`ã€‚

+   `create_pr` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) - æ˜¯å¦åˆ›å»ºå¸¦æœ‰ä¸Šä¼ æ–‡ä»¶çš„ PR æˆ–ç›´æ¥æäº¤ã€‚

+   `safe_serialization` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) - æ˜¯å¦ä½¿ç”¨ `safetensors` æˆ–ä¼ ç»Ÿçš„ TensorFlow æ–¹å¼ï¼ˆä½¿ç”¨ `h5`ï¼‰ä¿å­˜æ¨¡å‹ã€‚

+   `token` (`str` æˆ– `bool`, *å¯é€‰*) - ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä½¿ç”¨è¿è¡Œ `huggingface-cli login` æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface` ä¸­ï¼‰ã€‚

+   `kwargs` (`Dict[str, Any]`, *å¯é€‰*) - ä¼ é€’ç»™ push_to_hub() æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

å°†æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶ä¿å­˜åˆ°ç›®å½•ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ from_pretrained() ç±»æ–¹æ³•é‡æ–°åŠ è½½ã€‚

#### `serving`

```py
( inputs )
```

å‚æ•°

+   ç”¨äºæä¾›æ¨¡å‹çš„æ–¹æ³•ã€‚æ²¡æœ‰ç‰¹å®šçš„ç­¾åï¼Œä½†å°†ä½œä¸ºå…·ä½“çš„ä¸“ä¸šåŒ– -

+   ä½¿ç”¨ `save_pretrained` ä¿å­˜æ—¶çš„ `functions`ã€‚ - è¾“å…¥ï¼ˆ`Dict[str, tf.Tensor]`ï¼‰ï¼šä¿å­˜æ¨¡å‹çš„è¾“å…¥ï¼Œä½œä¸ºå¼ é‡å­—å…¸ã€‚

#### `serving_output`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1277)

```py
( output )
```

å‡†å¤‡ä¿å­˜æ¨¡å‹çš„è¾“å‡ºã€‚å¦‚æœéœ€è¦ç‰¹å®šçš„æœåŠ¡ä¿®æ”¹ï¼Œå¯ä»¥è¿›è¡Œè¦†ç›–ã€‚

#### `set_bias`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1948)

```py
( value )
```

å‚æ•°

+   `value` (`Dict[tf.Variable]`) - é™„åŠ åˆ° LM å¤´éƒ¨çš„æ‰€æœ‰æ–°åç½®ã€‚

è®¾ç½® LM å¤´éƒ¨ä¸­çš„æ‰€æœ‰åç½®ã€‚

#### `set_input_embeddings`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1851)

```py
( value )
```

å‚æ•°

+   `value` (`tf.Variable`) - å°†éšè—çŠ¶æ€æ˜ å°„åˆ°è¯æ±‡è¡¨çš„æ–°æƒé‡ã€‚

è®¾ç½®æ¨¡å‹çš„è¾“å…¥åµŒå…¥

#### `set_output_embeddings`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1891)

```py
( value )
```

å‚æ•°

+   `value` (`tf.Variable`) - å°†éšè—çŠ¶æ€æ˜ å°„åˆ°è¯æ±‡è¡¨çš„æ–°æƒé‡ã€‚

è®¾ç½®æ¨¡å‹çš„è¾“å‡ºåµŒå…¥

#### `test_step`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1687)

```py
( data )
```

å¯¹ Keras é»˜è®¤çš„ `train_step` è¿›è¡Œä¿®æ”¹ï¼Œæ­£ç¡®å¤„ç†æ¨¡å‹è¾“å‡ºä¸æ ‡ç­¾çš„åŒ¹é…ï¼Œå¹¶æ”¯æŒç›´æ¥åœ¨æŸå¤±è¾“å‡ºå¤´ä¸Šè¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œå®ƒç¡®ä¿é€‚å½“æ—¶å°†è¾“å…¥é”®å¤åˆ¶åˆ°æ ‡ç­¾ä¸­ã€‚å½“ä½¿ç”¨è™šæ‹ŸæŸå¤±æ—¶ï¼Œå®ƒè¿˜ä¼šå°†æ ‡ç­¾é”®å¤åˆ¶åˆ°è¾“å…¥å­—å…¸ä¸­ï¼Œä»¥ç¡®ä¿å®ƒä»¬åœ¨å‰å‘ä¼ é€’æœŸé—´å¯¹æ¨¡å‹å¯ç”¨ã€‚

#### `train_step`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L1579)

```py
( data )
```

å¯¹ Keras é»˜è®¤çš„ `train_step` è¿›è¡Œä¿®æ”¹ï¼Œæ­£ç¡®å¤„ç†æ¨¡å‹è¾“å‡ºä¸æ ‡ç­¾çš„åŒ¹é…ï¼Œå¹¶æ”¯æŒç›´æ¥åœ¨æŸå¤±è¾“å‡ºå¤´ä¸Šè¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œå®ƒç¡®ä¿é€‚å½“æ—¶å°†è¾“å…¥é”®å¤åˆ¶åˆ°æ ‡ç­¾ä¸­ã€‚å½“ä½¿ç”¨è™šæ‹ŸæŸå¤±æ—¶ï¼Œå®ƒè¿˜ä¼šå°†æ ‡ç­¾é”®å¤åˆ¶åˆ°è¾“å…¥å­—å…¸ä¸­ï¼Œä»¥ç¡®ä¿å®ƒä»¬åœ¨å‰å‘ä¼ é€’æœŸé—´å¯¹æ¨¡å‹å¯ç”¨ã€‚

## TFModelUtilsMixin

### `class transformers.modeling_tf_utils.TFModelUtilsMixin`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L104)

```py
( )
```

ç”¨äº `tf.keras.Model` çš„ä¸€äº›å®ç”¨ç¨‹åºï¼Œå¯ç”¨ä½œæ··åˆã€‚

#### `num_parameters`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_tf_utils.py#L109)

```py
( only_trainable: bool = False ) â†’ export const metadata = 'undefined';int
```

å‚æ•°

+   `only_trainable` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…è¿”å›å¯è®­ç»ƒå‚æ•°çš„æ•°é‡

è¿”å›

`int`

å‚æ•°æ•°é‡ã€‚

è·å–æ¨¡å‹ä¸­çš„ï¼ˆå¯é€‰çš„å¯è®­ç»ƒï¼‰å‚æ•°æ•°é‡ã€‚

## FlaxPreTrainedModel

### `class transformers.FlaxPreTrainedModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L166)

```py
( config: PretrainedConfig module: Module input_shape: Tuple = (1, 1) seed: int = 0 dtype: dtype = <class 'jax.numpy.float32'> _do_init: bool = True )
```

æ‰€æœ‰æ¨¡å‹çš„åŸºç±»ã€‚

FlaxPreTrainedModel è´Ÿè´£å­˜å‚¨æ¨¡å‹çš„é…ç½®ï¼Œå¹¶å¤„ç†åŠ è½½ã€ä¸‹è½½å’Œä¿å­˜æ¨¡å‹çš„æ–¹æ³•ã€‚

ç±»å±æ€§ï¼ˆç”±æ´¾ç”Ÿç±»è¦†ç›–ï¼‰ï¼š

+   `config_class` (PretrainedConfig) â€” ç”¨ä½œæ­¤æ¨¡å‹æ¶æ„çš„é…ç½®ç±»çš„ PretrainedConfig çš„å­ç±»ã€‚

+   `base_model_prefix` (`str`) â€” ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒæŒ‡ç¤ºæ´¾ç”Ÿç±»ä¸­åŸºç¡€æ¨¡å‹å…³è”çš„å±æ€§ï¼Œè¯¥æ´¾ç”Ÿç±»åœ¨åŸºç¡€æ¨¡å‹ä¹‹ä¸Šæ·»åŠ æ¨¡å—ã€‚

+   `main_input_name` (`str`) â€” æ¨¡å‹çš„ä¸»è¦è¾“å…¥çš„åç§°ï¼ˆé€šå¸¸ä¸º NLP æ¨¡å‹çš„ `input_ids`ï¼Œè§†è§‰æ¨¡å‹çš„ `pixel_values` å’Œè¯­éŸ³æ¨¡å‹çš„ `input_values`ï¼‰ã€‚

#### `push_to_hub`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)

```py
( repo_id: str use_temp_dir: Optional = None commit_message: Optional = None private: Optional = None token: Union = None max_shard_size: Union = '5GB' create_pr: bool = False safe_serialization: bool = True revision: str = None commit_description: str = None tags: Optional = None **deprecated_kwargs )
```

å‚æ•°

+   `repo_id` (`str`) â€” æ‚¨è¦å°†æ¨¡å‹æ¨é€åˆ°çš„å­˜å‚¨åº“çš„åç§°ã€‚åœ¨æ¨é€åˆ°ç»™å®šç»„ç»‡æ—¶ï¼Œåº”åŒ…å«æ‚¨çš„ç»„ç»‡åç§°ã€‚

+   `use_temp_dir` (`bool`, *optional*) â€” æ˜¯å¦ä½¿ç”¨ä¸´æ—¶ç›®å½•å­˜å‚¨åœ¨æ¨é€åˆ° Hub ä¹‹å‰ä¿å­˜çš„æ–‡ä»¶ã€‚å¦‚æœæ²¡æœ‰åä¸º `repo_id` çš„ç›®å½•ï¼Œåˆ™é»˜è®¤ä¸º `True`ï¼Œå¦åˆ™ä¸º `False`ã€‚

+   `commit_message` (`str`, *optional*) â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º `"Upload model"`ã€‚

+   `private` (`bool`, *optional*) â€” æ˜¯å¦åˆ›å»ºçš„å­˜å‚¨åº“åº”ä¸ºç§æœ‰ã€‚

+   `token` (`bool` æˆ– `str`, *optional*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œå°†ä½¿ç”¨è¿è¡Œ `huggingface-cli login` æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface` ä¸­ï¼‰ã€‚å¦‚æœæœªæŒ‡å®š `repo_url`ï¼Œåˆ™é»˜è®¤ä¸º `True`ã€‚

+   `max_shard_size` (`int` æˆ– `str`, *optional*, é»˜è®¤ä¸º `"5GB"`) â€” ä»…é€‚ç”¨äºæ¨¡å‹ã€‚åœ¨è¢«åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åæ£€æŸ¥ç‚¹å°†è¢«åˆ†æˆå°äºæ­¤å¤§å°çš„æ¯ä¸ªéƒ¨åˆ†ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚ `"5MB"`ï¼‰ã€‚æˆ‘ä»¬å°†å…¶é»˜è®¤ä¸º `"5GB"`ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥åœ¨å…è´¹çš„ Google Colab å®ä¾‹ä¸Šè½»æ¾åŠ è½½æ¨¡å‹ï¼Œè€Œä¸ä¼šå‡ºç°ä»»ä½• CPU OOM é—®é¢˜ã€‚

+   `create_pr` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ä¸Šä¼ æ–‡ä»¶çš„ PR æˆ–ç›´æ¥æäº¤ã€‚

+   `safe_serialization` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†æ¨¡å‹æƒé‡è½¬æ¢ä¸º safetensors æ ¼å¼ä»¥è¿›è¡Œæ›´å®‰å…¨çš„åºåˆ—åŒ–ã€‚

+   `revision` (`str`, *optional*) â€” è¦å°†ä¸Šä¼ çš„æ–‡ä»¶æ¨é€åˆ°çš„åˆ†æ”¯ã€‚

+   `commit_description` (`str`, *optional*) â€” å°†è¦åˆ›å»ºçš„æäº¤çš„æè¿°

+   `tags` (`List[str]`, *optional*) â€” è¦æ¨é€åˆ° Hub ä¸Šçš„æ ‡ç­¾åˆ—è¡¨ã€‚

ä¸Šä¼ æ¨¡å‹æ£€æŸ¥ç‚¹åˆ° ğŸ¤— Model Hubã€‚

ç¤ºä¾‹ï¼š

```py
from transformers import FlaxAutoModel

model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Push the model to your namespace with the name "my-finetuned-bert".
model.push_to_hub("my-finetuned-bert")

# Push the model to an organization with the name "my-finetuned-bert".
model.push_to_hub("huggingface/my-finetuned-bert")
```

#### `can_generate`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L506)

```py
( )
```

è¿”å›æ­¤æ¨¡å‹æ˜¯å¦å¯ä»¥ä½¿ç”¨ `.generate()` ç”Ÿæˆåºåˆ—ã€‚è¿”å›ï¼š`bool`: æ­¤æ¨¡å‹æ˜¯å¦å¯ä»¥ä½¿ç”¨ `.generate()` ç”Ÿæˆåºåˆ—ã€‚

#### `from_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L518)

```py
( pretrained_model_name_or_path: Union dtype: dtype = <class 'jax.numpy.float32'> *model_args config: Union = None cache_dir: Union = None ignore_mismatched_sizes: bool = False force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str`æˆ–`os.PathLike`) â€” å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ‰˜ç®¡åœ¨ huggingface.co æ¨¡å‹å­˜å‚¨åº“ä¸­çš„é¢„è®­ç»ƒæ¨¡å‹çš„*æ¨¡å‹ ID*ã€‚æœ‰æ•ˆçš„æ¨¡å‹ ID å¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚`bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´åŒ–ï¼Œå¦‚`dbmdz/bert-base-german-cased`ã€‚

    +   ä¸€ä¸ªåŒ…å«ä½¿ç”¨ save_pretrained()ä¿å­˜çš„æ¨¡å‹æƒé‡çš„*ç›®å½•*è·¯å¾„ï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/`ã€‚

    +   *pt ç´¢å¼•æ£€æŸ¥ç‚¹æ–‡ä»¶*çš„è·¯å¾„æˆ– URLï¼ˆä¾‹å¦‚ï¼Œ`./tf_model/model.ckpt.index`ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`from_pt`åº”è®¾ç½®ä¸º`True`ã€‚

+   `dtype` (`jax.numpy.dtype`, *optional*, é»˜è®¤ä¸º `jax.numpy.float32`) â€” è®¡ç®—çš„æ•°æ®ç±»å‹ã€‚å¯ä»¥æ˜¯`jax.numpy.float32`ã€`jax.numpy.float16`ï¼ˆåœ¨ GPU ä¸Šï¼‰å’Œ`jax.numpy.bfloat16`ï¼ˆåœ¨ TPU ä¸Šï¼‰ä¹‹ä¸€ã€‚

    è¿™å¯ä»¥ç”¨äºåœ¨ GPU æˆ– TPU ä¸Šå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒæˆ–åŠç²¾åº¦æ¨æ–­ã€‚å¦‚æœæŒ‡å®šäº†`dtype`ï¼Œåˆ™æ‰€æœ‰è®¡ç®—å°†ä½¿ç”¨ç»™å®šçš„`dtype`æ‰§è¡Œã€‚

    `è¯·æ³¨æ„ï¼Œè¿™ä»…æŒ‡å®šè®¡ç®—çš„æ•°æ®ç±»å‹ï¼Œä¸å½±å“æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹ã€‚`

    å¦‚æœè¦æ›´æ”¹æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹ï¼Œè¯·å‚é˜… to_fp16()å’Œ to_bf16()ã€‚

+   `model_args`ï¼ˆä½ç½®å‚æ•°åºåˆ—ï¼Œ*optional*ï¼‰ â€” æ‰€æœ‰å‰©ä½™çš„ä½ç½®å‚æ•°å°†ä¼ é€’ç»™åº•å±‚æ¨¡å‹çš„`__init__`æ–¹æ³•ã€‚

+   `config` (`Union[PretrainedConfig, str, os.PathLike]`, *optional*) â€” å¯ä»¥æ˜¯ï¼š

    +   ä» PretrainedConfig æ´¾ç”Ÿçš„ç±»çš„å®ä¾‹ï¼Œ

    +   ä¸€ä¸ªä½œä¸º from_pretrained()è¾“å…¥æœ‰æ•ˆçš„å­—ç¬¦ä¸²æˆ–è·¯å¾„ã€‚

    è¦ä½¿ç”¨çš„æ¨¡å‹é…ç½®ï¼Œè€Œä¸æ˜¯è‡ªåŠ¨åŠ è½½çš„é…ç½®ã€‚å½“ä»¥ä¸‹æƒ…å†µè‡ªåŠ¨åŠ è½½é…ç½®æ—¶ï¼š

    +   æ¨¡å‹æ˜¯åº“æä¾›çš„æ¨¡å‹ï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„*æ¨¡å‹ ID*å­—ç¬¦ä¸²åŠ è½½ï¼‰ã€‚

    +   æ¨¡å‹æ˜¯ä½¿ç”¨ save_pretrained()ä¿å­˜çš„ï¼Œå¹¶é€šè¿‡æä¾›ä¿å­˜ç›®å½•é‡æ–°åŠ è½½ã€‚

    +   é€šè¿‡æä¾›æœ¬åœ°ç›®å½•ä½œä¸º`pretrained_model_name_or_path`åŠ è½½æ¨¡å‹ï¼Œå¹¶åœ¨ç›®å½•ä¸­æ‰¾åˆ°åä¸º*config.json*çš„é…ç½® JSON æ–‡ä»¶ã€‚

+   `cache_dir` (`Union[str, os.PathLike]`, *optional*) â€” å¦‚æœä¸åº”ä½¿ç”¨æ ‡å‡†ç¼“å­˜ï¼Œåˆ™åº”å°†ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹é…ç½®ç¼“å­˜åœ¨å…¶ä¸­çš„ç›®å½•è·¯å¾„ã€‚

+   `from_pt` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” ä» PyTorch æ£€æŸ¥ç‚¹ä¿å­˜æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡ï¼ˆè¯·å‚é˜…`pretrained_model_name_or_path`å‚æ•°çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼‰ã€‚

+   `ignore_mismatched_sizes` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” å¦‚æœæ£€æŸ¥ç‚¹ä¸­çš„æŸäº›æƒé‡ä¸æ¨¡å‹çš„æƒé‡å¤§å°ä¸åŒï¼Œæ˜¯å¦å¼•å‘é”™è¯¯ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä»å…·æœ‰ 3 ä¸ªæ ‡ç­¾çš„æ£€æŸ¥ç‚¹å®ä¾‹åŒ–å…·æœ‰ 10 ä¸ªæ ‡ç­¾çš„æ¨¡å‹ï¼‰ã€‚

+   `force_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å¼ºåˆ¶ï¼ˆé‡æ–°ï¼‰ä¸‹è½½æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¼“å­˜ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

+   `resume_download` (`bool`, *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦åˆ é™¤æ¥æ”¶ä¸å®Œæ•´çš„æ–‡ä»¶ã€‚å¦‚æœå­˜åœ¨è¿™æ ·çš„æ–‡ä»¶ï¼Œå°†å°è¯•æ¢å¤ä¸‹è½½ã€‚

+   `proxies` (`Dict[str, str]`, *optional*) â€” ä¸€ä¸ªæŒ‰åè®®æˆ–ç«¯ç‚¹ä½¿ç”¨çš„ä»£ç†æœåŠ¡å™¨å­—å…¸ï¼Œä¾‹å¦‚ï¼Œ`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`ã€‚ä»£ç†åœ¨æ¯ä¸ªè¯·æ±‚ä¸Šä½¿ç”¨ã€‚

+   `local_files_only(bool,` *optional*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä»…æŸ¥çœ‹æœ¬åœ°æ–‡ä»¶ï¼ˆå³ï¼Œä¸å°è¯•ä¸‹è½½æ¨¡å‹ï¼‰ã€‚

+   `token` (`str` æˆ– `bool`, *å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä½¿ç”¨è¿è¡Œ `huggingface-cli login` æ—¶ç”Ÿæˆçš„ä»¤ç‰Œ (å­˜å‚¨åœ¨ `~/.huggingface` ä¸­)ã€‚

+   `revision` (`str`, *å¯é€‰*, é»˜è®¤ä¸º `"main"`) â€” è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹ç‰ˆæœ¬ã€‚å®ƒå¯ä»¥æ˜¯åˆ†æ”¯åç§°ã€æ ‡ç­¾åç§°æˆ–æäº¤ IDï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ huggingface.co ä¸Šä½¿ç”¨åŸºäº git çš„ç³»ç»Ÿæ¥å­˜å‚¨æ¨¡å‹å’Œå…¶ä»–å·¥ä»¶ï¼Œæ‰€ä»¥ `revision` å¯ä»¥æ˜¯ git å…è®¸çš„ä»»ä½•æ ‡è¯†ç¬¦ã€‚

ä»é¢„è®­ç»ƒæ¨¡å‹é…ç½®å®ä¾‹åŒ–ä¸€ä¸ªé¢„è®­ç»ƒçš„ flax æ¨¡å‹ã€‚

è­¦å‘Š *æ¥è‡ª XXX çš„æƒé‡æœªä»é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–* æ„å‘³ç€ XXX çš„æƒé‡ä¸æ˜¯ä¸æ¨¡å‹çš„å…¶ä½™éƒ¨åˆ†ä¸€èµ·é¢„è®­ç»ƒçš„ã€‚æ‚¨éœ€è¦ä½¿ç”¨ä¸‹æ¸¸å¾®è°ƒä»»åŠ¡æ¥è®­ç»ƒè¿™äº›æƒé‡ã€‚

è­¦å‘Š *æ¥è‡ª XXX çš„æƒé‡åœ¨ YYY ä¸­æœªä½¿ç”¨* æ„å‘³ç€å±‚ XXX åœ¨ YYY ä¸­æœªè¢«ä½¿ç”¨ï¼Œå› æ­¤è¿™äº›æƒé‡è¢«ä¸¢å¼ƒã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import BertConfig, FlaxBertModel

>>> # Download model and configuration from huggingface.co and cache.
>>> model = FlaxBertModel.from_pretrained("bert-base-cased")
>>> # Model was saved using *save_pretrained('./test/saved_model/')* (for example purposes, not runnable).
>>> model = FlaxBertModel.from_pretrained("./test/saved_model/")
>>> # Loading from a PyTorch checkpoint file instead of a PyTorch model (slower, for example purposes, not runnable).
>>> config = BertConfig.from_json_file("./pt_model/config.json")
>>> model = FlaxBertModel.from_pretrained("./pt_model/pytorch_model.bin", from_pt=True, config=config)
```

#### `load_flax_sharded_weights`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L459)

```py
( shard_files ) â†’ export const metadata = 'undefined';Dict
```

å‚æ•°

+   `shard_files` (`List[str]` â€” è¦åŠ è½½çš„åˆ†ç‰‡æ–‡ä»¶åˆ—è¡¨ã€‚

è¿”å›

`Dict`

æ¨¡å‹å‚æ•°çš„åµŒå¥—å­—å…¸ï¼Œç¬¦åˆ flax æ¨¡å‹çš„é¢„æœŸæ ¼å¼ï¼š`{'model': {'params': {'...'}}}`ã€‚

è¿™ä¸ `flax.serialization.from_bytes` ç›¸åŒ (https:lax.readthedocs.io/en/latest/_modules/flax/serialization.html#from_bytes)ï¼Œä½†é€‚ç”¨äºåˆ†ç‰‡æ£€æŸ¥ç‚¹ã€‚

è¿™ç§åŠ è½½æ•ˆç‡å¾ˆé«˜ï¼šæ¯ä¸ªæ£€æŸ¥ç‚¹åˆ†ç‰‡éƒ½ä¼šé€ä¸ªåŠ è½½åˆ° RAM ä¸­ï¼Œå¹¶åœ¨åŠ è½½åˆ°æ¨¡å‹ååˆ é™¤ã€‚

#### `register_for_auto_class`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L1226)

```py
( auto_class = 'FlaxAutoModel' )
```

å‚æ•°

+   `auto_class` (`str` æˆ– `type`, *å¯é€‰*, é»˜è®¤ä¸º `"FlaxAutoModel"`) â€” ç”¨äºæ³¨å†Œè¿™ä¸ªæ–°æ¨¡å‹çš„è‡ªåŠ¨ç±»ã€‚

ä½¿ç”¨ç»™å®šçš„è‡ªåŠ¨ç±»æ³¨å†Œæ­¤ç±»ã€‚è¿™åº”è¯¥ä»…ç”¨äºè‡ªå®šä¹‰æ¨¡å‹ï¼Œå› ä¸ºåº“ä¸­çš„æ¨¡å‹å·²ç»ä¸è‡ªåŠ¨ç±»æ˜ å°„ã€‚

æ­¤ API æ˜¯å®éªŒæ€§çš„ï¼Œå¯èƒ½åœ¨ä¸‹ä¸€ä¸ªç‰ˆæœ¬ä¸­æœ‰ä¸€äº›è½»å¾®çš„ç ´åæ€§æ›´æ”¹ã€‚

#### `save_pretrained`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L1088)

```py
( save_directory: Union params = None push_to_hub = False max_shard_size = '10GB' token: Union = None safe_serialization: bool = False **kwargs )
```

å‚æ•°

+   `save_directory` (`str` æˆ– `os.PathLike`) â€” è¦ä¿å­˜åˆ°çš„ç›®å½•ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºã€‚

+   `push_to_hub` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” ä¿å­˜æ¨¡å‹åæ˜¯å¦å°†å…¶æ¨é€åˆ° Hugging Face æ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ (å°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` åç§°)ã€‚

+   `max_shard_size` (`int` æˆ– `str`, *å¯é€‰*, é»˜è®¤ä¸º `"10GB"`) â€” åœ¨åˆ†ç‰‡ä¹‹å‰æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚æ£€æŸ¥ç‚¹åˆ†ç‰‡å°†å°äºæ­¤å¤§å°ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ (å¦‚ `"5MB"`)ã€‚

    å¦‚æœæ¨¡å‹çš„å•ä¸ªæƒé‡å¤§äº `max_shard_size`ï¼Œå®ƒå°†åœ¨è‡ªå·±çš„æ£€æŸ¥ç‚¹åˆ†ç‰‡ä¸­ï¼Œè¯¥åˆ†ç‰‡å°†å¤§äº `max_shard_size`ã€‚

+   `token` (`str` æˆ– `bool`, *å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œæˆ–æœªæŒ‡å®šï¼Œå°†ä½¿ç”¨è¿è¡Œ `huggingface-cli login` æ—¶ç”Ÿæˆçš„ä»¤ç‰Œ (å­˜å‚¨åœ¨ `~/.huggingface` ä¸­)ã€‚

+   `kwargs` (`Dict[str, Any]`, *å¯é€‰*) â€” ä¼ é€’ç»™ push_to_hub() æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

+   `safe_serialization` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦ä½¿ç”¨ `safetensors` æˆ–é€šè¿‡ msgpack ä¿å­˜æ¨¡å‹ã€‚

å°†æ¨¡å‹åŠå…¶é…ç½®æ–‡ä»¶ä¿å­˜åˆ°ç›®å½•ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ `from_pretrained()` ç±»æ–¹æ³•é‡æ–°åŠ è½½ã€‚

#### `to_bf16`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L329)

```py
( params: Union mask: Any = None )
```

å‚æ•°

+   `params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„ `PyTree`ã€‚

+   `mask` (`Union[Dict, FrozenDict]`) â€” ä¸ `params` æ ‘å…·æœ‰ç›¸åŒç»“æ„çš„ `PyTree`ã€‚å¶å­åº”ä¸ºå¸ƒå°”å€¼ï¼Œå¯¹äºè¦è½¬æ¢çš„å‚æ•°åº”ä¸º `True`ï¼Œå¯¹äºè¦è·³è¿‡çš„å‚æ•°åº”ä¸º `False`ã€‚

å°†æµ®ç‚¹ `params` è½¬æ¢ä¸º `jax.numpy.bfloat16`ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæ–°çš„ `params` æ ‘ï¼Œä¸ä¼šç›´æ¥åœ¨åŸåœ°è½¬æ¢ `params`ã€‚

æ­¤æ–¹æ³•å¯åœ¨ TPU ä¸Šä½¿ç”¨ï¼Œæ˜¾å¼å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸º bfloat16 ç²¾åº¦ï¼Œä»¥è¿›è¡Œå®Œå…¨çš„åŠç²¾åº¦è®­ç»ƒæˆ–ä»¥ bfloat16 ä¿å­˜æƒé‡ä»¥ç”¨äºæ¨ç†ï¼Œä»¥èŠ‚çœå†…å­˜å¹¶æé«˜é€Ÿåº¦ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import FlaxBertModel

>>> # load model
>>> model = FlaxBertModel.from_pretrained("bert-base-cased")
>>> # By default, the model parameters will be in fp32 precision, to cast these to bfloat16 precision
>>> model.params = model.to_bf16(model.params)
>>> # If you want don't want to cast certain parameters (for example layer norm bias and scale)
>>> # then pass the mask as follows
>>> from flax import traverse_util

>>> model = FlaxBertModel.from_pretrained("bert-base-cased")
>>> flat_params = traverse_util.flatten_dict(model.params)
>>> mask = {
...     path: (path[-2] != ("LayerNorm", "bias") and path[-2:] != ("LayerNorm", "scale"))
...     for path in flat_params
... }
>>> mask = traverse_util.unflatten_dict(mask)
>>> model.params = model.to_bf16(model.params, mask)
```

#### `to_fp16`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L395)

```py
( params: Union mask: Any = None )
```

å‚æ•°

+   `params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„ `PyTree`ã€‚

+   `mask` (`Union[Dict, FrozenDict]`) â€” ä¸ `params` æ ‘å…·æœ‰ç›¸åŒç»“æ„çš„ `PyTree`ã€‚å¶å­åº”ä¸ºå¸ƒå°”å€¼ï¼Œå¯¹äºè¦è½¬æ¢çš„å‚æ•°åº”ä¸º `True`ï¼Œå¯¹äºè¦è·³è¿‡çš„å‚æ•°åº”ä¸º `False`ã€‚

å°†æµ®ç‚¹ `params` è½¬æ¢ä¸º `jax.numpy.float16`ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæ–°çš„ `params` æ ‘ï¼Œä¸ä¼šç›´æ¥åœ¨åŸåœ°è½¬æ¢ `params`ã€‚

æ­¤æ–¹æ³•å¯åœ¨ GPU ä¸Šä½¿ç”¨ï¼Œæ˜¾å¼å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸º float16 ç²¾åº¦ï¼Œä»¥è¿›è¡Œå®Œå…¨çš„åŠç²¾åº¦è®­ç»ƒæˆ–ä»¥ float16 ä¿å­˜æƒé‡ä»¥ç”¨äºæ¨ç†ï¼Œä»¥èŠ‚çœå†…å­˜å¹¶æé«˜é€Ÿåº¦ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import FlaxBertModel

>>> # load model
>>> model = FlaxBertModel.from_pretrained("bert-base-cased")
>>> # By default, the model params will be in fp32, to cast these to float16
>>> model.params = model.to_fp16(model.params)
>>> # If you want don't want to cast certain parameters (for example layer norm bias and scale)
>>> # then pass the mask as follows
>>> from flax import traverse_util

>>> model = FlaxBertModel.from_pretrained("bert-base-cased")
>>> flat_params = traverse_util.flatten_dict(model.params)
>>> mask = {
...     path: (path[-2] != ("LayerNorm", "bias") and path[-2:] != ("LayerNorm", "scale"))
...     for path in flat_params
... }
>>> mask = traverse_util.unflatten_dict(mask)
>>> model.params = model.to_fp16(model.params, mask)
```

#### `to_fp32`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_flax_utils.py#L368)

```py
( params: Union mask: Any = None )
```

å‚æ•°

+   `params` (`Union[Dict, FrozenDict]`) â€” æ¨¡å‹å‚æ•°çš„ `PyTree`ã€‚

+   `mask` (`Union[Dict, FrozenDict]`) â€” ä¸ `params` æ ‘å…·æœ‰ç›¸åŒç»“æ„çš„ `PyTree`ã€‚å¶å­åº”ä¸ºå¸ƒå°”å€¼ï¼Œå¯¹äºè¦è½¬æ¢çš„å‚æ•°åº”ä¸º `True`ï¼Œå¯¹äºè¦è·³è¿‡çš„å‚æ•°åº”ä¸º `False`ã€‚

å°†æµ®ç‚¹ `params` è½¬æ¢ä¸º `jax.numpy.float32`ã€‚æ­¤æ–¹æ³•å¯ç”¨äºæ˜¾å¼å°†æ¨¡å‹å‚æ•°è½¬æ¢ä¸º fp32 ç²¾åº¦ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæ–°çš„ `params` æ ‘ï¼Œä¸ä¼šç›´æ¥åœ¨åŸåœ°è½¬æ¢ `params`ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import FlaxBertModel

>>> # Download model and configuration from huggingface.co
>>> model = FlaxBertModel.from_pretrained("bert-base-cased")
>>> # By default, the model params will be in fp32, to illustrate the use of this method,
>>> # we'll first cast to fp16 and back to fp32
>>> model.params = model.to_f16(model.params)
>>> # now cast back to fp32
>>> model.params = model.to_fp32(model.params)
```

## æ¨é€åˆ° Hub

### `class transformers.utils.PushToHubMixin`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L639)

```py
( )
```

ä¸€ä¸ªåŒ…å«å°†æ¨¡å‹æˆ–åˆ†è¯å™¨æ¨é€åˆ° Hub çš„åŠŸèƒ½çš„ Mixinã€‚

#### `push_to_hub`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)

```py
( repo_id: str use_temp_dir: Optional = None commit_message: Optional = None private: Optional = None token: Union = None max_shard_size: Union = '5GB' create_pr: bool = False safe_serialization: bool = True revision: str = None commit_description: str = None tags: Optional = None **deprecated_kwargs )
```

å‚æ•°

+   `repo_id` (`str`) â€” æ‚¨è¦å°† {object} æ¨é€åˆ°çš„å­˜å‚¨åº“çš„åç§°ã€‚åœ¨æ¨é€åˆ°ç»™å®šç»„ç»‡æ—¶ï¼Œåº”åŒ…å«æ‚¨çš„ç»„ç»‡åç§°ã€‚

+   `use_temp_dir` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦ä½¿ç”¨ä¸´æ—¶ç›®å½•å­˜å‚¨åœ¨æ¨é€åˆ° Hub ä¹‹å‰ä¿å­˜çš„æ–‡ä»¶ã€‚å¦‚æœæ²¡æœ‰åä¸º `repo_id` çš„ç›®å½•ï¼Œåˆ™é»˜è®¤ä¸º `True`ï¼Œå¦åˆ™ä¸º `False`ã€‚

+   `commit_message` (`str`ï¼Œ*å¯é€‰*) â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º `"Upload {object}"`ã€‚

+   `private` (`bool`ï¼Œ*å¯é€‰*) â€” åˆ›å»ºçš„å­˜å‚¨åº“æ˜¯å¦åº”ä¸ºç§æœ‰ã€‚

+   `token` (`bool` æˆ– `str`ï¼Œ*å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œå°†ä½¿ç”¨è¿è¡Œ `huggingface-cli login` æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface`ï¼‰ã€‚å¦‚æœæœªæŒ‡å®š `repo_url`ï¼Œåˆ™é»˜è®¤ä¸º `True`ã€‚

+   `max_shard_size` (`int` æˆ– `str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"5GB"`) â€” ä»…é€‚ç”¨äºæ¨¡å‹ã€‚åœ¨è¢«åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åæ£€æŸ¥ç‚¹å°†è¢«åˆ†æˆå°äºæ­¤å¤§å°çš„æ¯ä¸ªåˆ†ç‰‡ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚ `"5MB"`ï¼‰ã€‚æˆ‘ä»¬å°†å…¶é»˜è®¤ä¸º `"5GB"`ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥åœ¨å…è´¹çš„ Google Colab å®ä¾‹ä¸Šè½»æ¾åŠ è½½æ¨¡å‹ï¼Œè€Œä¸ä¼šå‡ºç°ä»»ä½• CPU OOM é—®é¢˜ã€‚

+   `create_pr` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`) â€” æ˜¯å¦åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ä¸Šä¼ æ–‡ä»¶çš„ PR æˆ–ç›´æ¥æäº¤ã€‚

+   `safe_serialization` (`bool`, *å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`) â€” æ˜¯å¦å°†æ¨¡å‹æƒé‡è½¬æ¢ä¸º safetensors æ ¼å¼ä»¥è¿›è¡Œæ›´å®‰å…¨çš„åºåˆ—åŒ–ã€‚

+   `revision` (`str`, *å¯é€‰*) â€” è¦å°†ä¸Šä¼ çš„æ–‡ä»¶æ¨é€åˆ°çš„åˆ†æ”¯ã€‚

+   `commit_description` (`str`, *å¯é€‰*) â€” å°†åˆ›å»ºçš„æäº¤æè¿°

+   `tags` (`List[str]`, *å¯é€‰*) â€” è¦æ¨é€åˆ°ä¸­å¿ƒçš„æ ‡ç­¾åˆ—è¡¨ã€‚

å°†{object_files}ä¸Šä¼ åˆ°ğŸ¤—æ¨¡å‹ä¸­å¿ƒã€‚

ç¤ºä¾‹ï¼š

```py
from transformers import {object_class}

{object} = {object_class}.from_pretrained("bert-base-cased")

# Push the {object} to your namespace with the name "my-finetuned-bert".
{object}.push_to_hub("my-finetuned-bert")

# Push the {object} to an organization with the name "my-finetuned-bert".
{object}.push_to_hub("huggingface/my-finetuned-bert")
```

## åˆ†ç‰‡æ£€æŸ¥ç‚¹

#### `transformers.modeling_utils.load_sharded_checkpoint`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/modeling_utils.py#L415)

```py
( model folder strict = True prefer_safe = True ) â†’ export const metadata = 'undefined';NamedTuple
```

å‚æ•°

+   `model` (`torch.nn.Module`) â€” è¦åŠ è½½æ£€æŸ¥ç‚¹çš„æ¨¡å‹ã€‚

+   `folder` (`str`æˆ–`os.PathLike`) â€” åŒ…å«åˆ†ç‰‡æ£€æŸ¥ç‚¹çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚

+   `strict` (`bool`, *å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`) â€” æ˜¯å¦ä¸¥æ ¼æ‰§è¡Œæ¨¡å‹çŠ¶æ€å­—å…¸ä¸­çš„é”®ä¸åˆ†ç‰‡æ£€æŸ¥ç‚¹ä¸­çš„é”®åŒ¹é…ã€‚

+   `prefer_safe` (`bool`, *å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`) â€” å¦‚æœæ£€æŸ¥ç‚¹ä¸­åŒæ—¶å­˜åœ¨ safetensors å’Œ PyTorch ä¿å­˜æ–‡ä»¶ï¼Œå¹¶ä¸”`prefer_safe`ä¸º Trueï¼Œåˆ™å°†åŠ è½½ safetensors æ–‡ä»¶ã€‚å¦åˆ™ï¼Œå°½å¯èƒ½åŠ è½½ PyTorch æ–‡ä»¶ã€‚

è¿”å›

`NamedTuple`

ä¸€ä¸ªå¸¦æœ‰`missing_keys`å’Œ`unexpected_keys`å­—æ®µçš„å‘½åå…ƒç»„

+   `missing_keys`æ˜¯ä¸€ä¸ªåŒ…å«ç¼ºå¤±é”®çš„å­—ç¬¦ä¸²åˆ—è¡¨

+   `unexpected_keys`æ˜¯ä¸€ä¸ªåŒ…å«æ„å¤–é”®çš„å­—ç¬¦ä¸²åˆ—è¡¨

è¿™ä¸[`torch.nn.Module.load_state_dict`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=load_state_dict#torch.nn.Module.load_state_dict)ç›¸åŒï¼Œä½†é€‚ç”¨äºåˆ†ç‰‡æ£€æŸ¥ç‚¹ã€‚

è¿™ç§åŠ è½½æ•ˆç‡å¾ˆé«˜ï¼šæ¯ä¸ªæ£€æŸ¥ç‚¹åˆ†ç‰‡éƒ½ä¼šé€ä¸ªåœ¨ RAM ä¸­åŠ è½½ï¼ŒåŠ è½½åˆ°æ¨¡å‹åä¼šè¢«åˆ é™¤ã€‚
