- en: Troubleshoot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/troubleshooting](https://huggingface.co/docs/transformers/v4.37.2/en/troubleshooting)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/transformers/v4.37.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/start.1af50ed5.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/scheduler.9bc65507.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/singletons.a2d7fdf1.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.3b203c72.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/paths.b8f1dad4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/app.59e74a31.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.707bf1b6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/0.dbd8cc12.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/374.d241981c.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Tip.c2ecdbf4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Youtube.e1129c6f.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/CodeBlock.54a9f38d.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Heading.342b1fa6.js">
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes errors occur, but we are here to help! This guide covers some of
    the most common issues weâ€™ve seen and how you can resolve them. However, this
    guide isnâ€™t meant to be a comprehensive collection of every ðŸ¤— Transformers issue.
    For more help with troubleshooting your issue, try:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.youtube-nocookie.com/embed/S2EEG3JIt2A](https://www.youtube-nocookie.com/embed/S2EEG3JIt2A)'
  prefs: []
  type: TYPE_NORMAL
- en: Asking for help on the [forums](https://discuss.huggingface.co/). There are
    specific categories you can post your question to, like [Beginners](https://discuss.huggingface.co/c/beginners/5)
    or [ðŸ¤— Transformers](https://discuss.huggingface.co/c/transformers/9). Make sure
    you write a good descriptive forum post with some reproducible code to maximize
    the likelihood that your problem is solved!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://www.youtube-nocookie.com/embed/_PAli-V4wj0](https://www.youtube-nocookie.com/embed/_PAli-V4wj0)'
  prefs: []
  type: TYPE_NORMAL
- en: Create an [Issue](https://github.com/huggingface/transformers/issues/new/choose)
    on the ðŸ¤— Transformers repository if it is a bug related to the library. Try to
    include as much information describing the bug as possible to help us better figure
    out whatâ€™s wrong and how we can fix it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the [Migration](migration) guide if you use an older version of ðŸ¤— Transformers
    since some important changes have been introduced between versions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For more details about troubleshooting and getting help, take a look at [Chapter
    8](https://huggingface.co/course/chapter8/1?fw=pt) of the Hugging Face course.
  prefs: []
  type: TYPE_NORMAL
- en: Firewalled environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some GPU instances on cloud and intranet setups are firewalled to external
    connections, resulting in a connection error. When your script attempts to download
    model weights or datasets, the download will hang and then timeout with the following
    message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this case, you should try to run ðŸ¤— Transformers on [offline mode](installation#offline-mode)
    to avoid the connection error.
  prefs: []
  type: TYPE_NORMAL
- en: CUDA out of memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Training large models with millions of parameters can be challenging without
    the appropriate hardware. A common error you may encounter when the GPU runs out
    of memory is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some potential solutions you can try to lessen memory use:'
  prefs: []
  type: TYPE_NORMAL
- en: Reduce the [`per_device_train_batch_size`](main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size)
    value in [TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try using [`gradient_accumulation_steps`](main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps)
    in [TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)
    to effectively increase overall batch size.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the Performance [guide](performance) for more details about memory-saving
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Unable to load a saved TensorFlow model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TensorFlowâ€™s [model.save](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)
    method will save the entire model - architecture, weights, training configuration
    - in a single file. However, when you load the model file again, you may run into
    an error because ðŸ¤— Transformers may not load all the TensorFlow-related objects
    in the model file. To avoid issues with saving and loading TensorFlow models,
    we recommend you:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the model weights as a `h5` file extension with [`model.save_weights`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)
    and then reload the model with [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Save the model with `~TFPretrainedModel.save_pretrained` and load it again
    with [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: ImportError
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another common error you may encounter, especially if it is a newly released
    model, is `ImportError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'For these error types, check to make sure you have the latest version of ðŸ¤—
    Transformers installed to access the most recent models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'CUDA error: device-side assert triggered'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes you may run into a generic CUDA error about an error in the device
    code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You should try to run the code on a CPU first to get a more descriptive error
    message. Add the following environment variable to the beginning of your code
    to switch to a CPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Another option is to get a better traceback from the GPU. Add the following
    environment variable to the beginning of your code to get the traceback to point
    to the source of the error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Incorrect output when padding tokens arenâ€™t masked
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In some cases, the output `hidden_state` may be incorrect if the `input_ids`
    include padding tokens. To demonstrate, load a model and tokenizer. You can access
    a modelâ€™s `pad_token_id` to see its value. The `pad_token_id` may be `None` for
    some models, but you can always manually set it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following example shows the output without masking the padding tokens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the actual output of the second sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Most of the time, you should provide an `attention_mask` to your model to ignore
    the padding tokens to avoid this silent error. Now the output of the second sequence
    matches its actual output:'
  prefs: []
  type: TYPE_NORMAL
- en: By default, the tokenizer creates an `attention_mask` for you based on your
    specific tokenizerâ€™s defaults.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'ðŸ¤— Transformers doesnâ€™t automatically create an `attention_mask` to mask a padding
    token if it is provided because:'
  prefs: []
  type: TYPE_NORMAL
- en: Some models donâ€™t have a padding token.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For some use-cases, users want a model to attend to a padding token.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ValueError: Unrecognized configuration class XYZ for this kind of AutoModel'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Generally, we recommend using the [AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)
    class to load pretrained instances of models. This class can automatically infer
    and load the correct architecture from a given checkpoint based on the configuration.
    If you see this `ValueError` when loading a model from a checkpoint, this means
    the Auto class couldnâ€™t find a mapping from the configuration in the given checkpoint
    to the kind of model you are trying to load. Most commonly, this happens when
    a checkpoint doesnâ€™t support a given task. For instance, youâ€™ll see this error
    in the following example because there is no GPT2 for question answering:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
