["```py\n>>> from transformers import AutoProcessor, SeamlessM4TModel\n\n>>> processor = AutoProcessor.from_pretrained(\"facebook/hf-seamless-m4t-medium\")\n>>> model = SeamlessM4TModel.from_pretrained(\"facebook/hf-seamless-m4t-medium\")\n```", "```py\n>>> # let's load an audio sample from an Arabic speech corpus\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"arabic_speech_corpus\", split=\"test\", streaming=True)\n>>> audio_sample = next(iter(dataset))[\"audio\"]\n\n>>> # now, process it\n>>> audio_inputs = processor(audios=audio_sample[\"array\"], return_tensors=\"pt\")\n\n>>> # now, process some English test as well\n>>> text_inputs = processor(text = \"Hello, my dog is cute\", src_lang=\"eng\", return_tensors=\"pt\")\n```", "```py\n>>> audio_array_from_text = model.generate(**text_inputs, tgt_lang=\"rus\")[0].cpu().numpy().squeeze()\n>>> audio_array_from_audio = model.generate(**audio_inputs, tgt_lang=\"rus\")[0].cpu().numpy().squeeze()\n```", "```py\n>>> # from audio\n>>> output_tokens = model.generate(**audio_inputs, tgt_lang=\"fra\", generate_speech=False)\n>>> translated_text_from_audio = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n\n>>> # from text\n>>> output_tokens = model.generate(**text_inputs, tgt_lang=\"fra\", generate_speech=False)\n>>> translated_text_from_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n```", "```py\n>>> from transformers import SeamlessM4TForSpeechToSpeech\n>>> model = SeamlessM4TForSpeechToSpeech.from_pretrained(\"facebook/hf-seamless-m4t-medium\")\n```", "```py\n>>> from transformers import SeamlessM4TForTextToText\n>>> model = SeamlessM4TForTextToText.from_pretrained(\"facebook/hf-seamless-m4t-medium\")\n```", "```py\n( config current_modality = 'text' )\n```", "```py\n( input_ids: Optional = None input_features: Optional = None return_intermediate_token_ids: Optional = None tgt_lang: Optional = None spkr_id: Optional = 0 generate_speech: Optional = True **kwargs ) \u2192 export const metadata = 'undefined';Union[SeamlessM4TGenerationOutput, Tuple[Tensor], ModelOutput]\n```", "```py\n( config: SeamlessM4TConfig )\n```", "```py\n( input_ids: Optional = None return_intermediate_token_ids: Optional = None tgt_lang: Optional = None spkr_id: Optional = 0 **kwargs ) \u2192 export const metadata = 'undefined';Union[SeamlessM4TGenerationOutput, Tuple[Tensor]]\n```", "```py\n( config )\n```", "```py\n( input_features: Optional = None return_intermediate_token_ids: Optional = None tgt_lang: Optional = None spkr_id: Optional = 0 **kwargs ) \u2192 export const metadata = 'undefined';Union[SeamlessM4TGenerationOutput, Tuple[Tensor]]\n```", "```py\n( config: SeamlessM4TConfig )\n```", "```py\n( input_ids: LongTensor = None attention_mask: Optional = None decoder_input_ids: Optional = None decoder_attention_mask: Optional = None encoder_outputs: Optional = None past_key_values: Optional = None inputs_embeds: Optional = None decoder_inputs_embeds: Optional = None labels: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs )\n```", "```py\n( input_ids = None tgt_lang = None generation_config = None logits_processor = None stopping_criteria = None prefix_allowed_tokens_fn = None synced_gpus = False **kwargs ) \u2192 export const metadata = 'undefined';ModelOutput or torch.LongTensor\n```", "```py\n( config: SeamlessM4TConfig )\n```", "```py\n( input_features: LongTensor = None attention_mask: Optional = None decoder_input_ids: Optional = None decoder_attention_mask: Optional = None encoder_outputs: Optional = None past_key_values: Optional = None inputs_embeds: Optional = None decoder_inputs_embeds: Optional = None labels: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs )\n```", "```py\n( input_features = None tgt_lang = None generation_config = None logits_processor = None stopping_criteria = None prefix_allowed_tokens_fn = None synced_gpus = False **kwargs ) \u2192 export const metadata = 'undefined';ModelOutput or torch.LongTensor\n```", "```py\n( vocab_size = 256102 t2u_vocab_size = 10082 hidden_size = 1024 initializer_range = 0.02 layer_norm_eps = 1e-05 use_cache = True max_position_embeddings = 1024 is_encoder_decoder = True encoder_layerdrop = 0.05 decoder_layerdrop = 0.05 activation_function = 'relu' dropout = 0.1 attention_dropout = 0.1 activation_dropout = 0.0 scale_embedding = True encoder_layers = 24 encoder_ffn_dim = 8192 encoder_attention_heads = 16 decoder_layers = 24 decoder_ffn_dim = 8192 decoder_attention_heads = 16 decoder_start_token_id = 3 max_new_tokens = 256 pad_token_id = 0 bos_token_id = 2 eos_token_id = 3 speech_encoder_layers = 24 speech_encoder_attention_heads = 16 speech_encoder_intermediate_size = 4096 speech_encoder_hidden_act = 'swish' speech_encoder_dropout = 0.0 add_adapter = True speech_encoder_layerdrop = 0.1 feature_projection_input_dim = 160 num_conv_pos_embeddings = 128 num_conv_pos_embedding_groups = 16 adaptor_kernel_size = 8 adaptor_stride = 8 adaptor_dropout = 0.1 num_adapter_layers = 1 position_embeddings_type = 'relative' rotary_embedding_base = 10000 max_source_positions = 4096 conv_depthwise_kernel_size = 31 t2u_bos_token_id = 0 t2u_pad_token_id = 1 t2u_eos_token_id = 2 t2u_decoder_start_token_id = 2 t2u_max_new_tokens = 1024 t2u_encoder_layers = 6 t2u_encoder_ffn_dim = 8192 t2u_encoder_attention_heads = 16 t2u_decoder_layers = 6 t2u_decoder_ffn_dim = 8192 t2u_decoder_attention_heads = 16 t2u_max_position_embeddings = 2048 sampling_rate = 16000 upsample_initial_channel = 512 upsample_rates = [5, 4, 4, 2, 2] upsample_kernel_sizes = [11, 8, 8, 4, 4] resblock_kernel_sizes = [3, 7, 11] resblock_dilation_sizes = [[1, 3, 5], [1, 3, 5], [1, 3, 5]] leaky_relu_slope = 0.1 unit_hifi_gan_vocab_size = 10000 unit_embed_dim = 1280 lang_embed_dim = 256 spkr_embed_dim = 256 vocoder_num_langs = 36 vocoder_num_spkrs = 200 variance_predictor_kernel_size = 3 var_pred_dropout = 0.5 vocoder_offset = 4 **kwargs )\n```", "```py\n>>> from transformers import SeamlessM4TModel, SeamlessM4TConfig\n\n>>> # Initializing a SeamlessM4T \"facebook/hf-seamless-m4t-medium\" style configuration\n>>> configuration = SeamlessM4TConfig()\n\n>>> # Initializing a model from the \"facebook/hf-seamless-m4t-medium\" style configuration\n>>> model = SeamlessM4TModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( vocab_file bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' tokenizer_file = None src_lang = 'eng' tgt_lang = 'fra' sp_model_kwargs: Optional = None additional_special_tokens = None **kwargs )\n```", "```py\n>>> from transformers import SeamlessM4TTokenizer\n\n>>> tokenizer = SeamlessM4TTokenizer.from_pretrained(\n...     \"facebook/hf-seamless-m4t-medium\", src_lang=\"eng\", tgt_lang=\"fra\"\n... )\n>>> example_english_phrase = \" UN Chief Says There Is No Military Solution in Syria\"\n>>> expected_translation_french = \"Le chef de l'ONU affirme qu'il n'y a pas de solution militaire en Syrie.\"\n>>> inputs = tokenizer(example_english_phrase, text_target=expected_translation_french, return_tensors=\"pt\")\n```", "```py\n( text: Union = None text_pair: Union = None text_target: Union = None text_pair_target: Union = None padding: Union = True pad_to_multiple_of: Optional = 2 src_lang: Optional = None tgt_lang: Optional = None **kwargs )\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( save_directory: str filename_prefix: Optional = None )\n```", "```py\n( vocab_file = None tokenizer_file = None bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' src_lang = 'eng' tgt_lang = 'fra' additional_special_tokens = None **kwargs )\n```", "```py\n>>> from transformers import SeamlessM4TTokenizerFast\n\n>>> tokenizer = SeamlessM4TTokenizerFast.from_pretrained(\n...     \"facebook/hf-seamless-m4t-medium\", src_lang=\"eng\", tgt_lang=\"fra\"\n... )\n>>> example_english_phrase = \" UN Chief Says There Is No Military Solution in Syria\"\n>>> expected_translation_french = \"Le chef de l'ONU affirme qu'il n'y a pas de solution militaire en Syrie.\"\n>>> inputs = tokenizer(example_english_phrase, text_target=expected_translation_french, return_tensors=\"pt\")\n```", "```py\n( text: Union = None text_pair: Union = None text_target: Union = None text_pair_target: Union = None padding: Union = True pad_to_multiple_of: Optional = 2 src_lang: Optional = None tgt_lang: Optional = None **kwargs )\n```", "```py\n( feature_size = 80 sampling_rate = 16000 num_mel_bins = 80 padding_value = 0.0 stride = 2 **kwargs )\n```", "```py\n( raw_speech: Union padding: Union = True pad_to_multiple_of: Optional = 2 max_length: Optional = None truncation: bool = False return_tensors: Union = None sampling_rate: Optional = None return_attention_mask: Optional = None do_normalize_per_mel_bins: Optional = True **kwargs )\n```", "```py\n( feature_extractor tokenizer )\n```", "```py\n( text = None audios = None src_lang = None tgt_lang = None **kwargs ) \u2192 export const metadata = 'undefined';BatchEncoding\n```", "```py\n( config )\n```", "```py\n( input_ids: LongTensor spkr_id: Tensor lang_id: Tensor )\n```", "```py\n( config: SeamlessM4TConfig )\n```", "```py\n( input_embeds: FloatTensor ) \u2192 export const metadata = 'undefined';torch.FloatTensor\n```", "```py\n( config: SeamlessM4TConfig embed_tokens_decoder: Optional = None )\n```", "```py\n( config: SeamlessM4TConfig embed_tokens_decoder: Optional = None )\n```", "```py\n( input_ids: LongTensor = None attention_mask: Optional = None decoder_input_ids: Optional = None decoder_attention_mask: Optional = None encoder_outputs: Optional = None past_key_values: Optional = None inputs_embeds: Optional = None decoder_inputs_embeds: Optional = None labels: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None )\n```"]