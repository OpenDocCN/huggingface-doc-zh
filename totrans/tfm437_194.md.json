["```py\n>>> from transformers import MarianMTModel, MarianTokenizer\n\n>>> src_text = [\n...     \">>fra<< this is a sentence in english that we want to translate to french\",\n...     \">>por<< This should go to portuguese\",\n...     \">>esp<< And this to Spanish\",\n... ]\n\n>>> model_name = \"Helsinki-NLP/opus-mt-en-roa\"\n>>> tokenizer = MarianTokenizer.from_pretrained(model_name)\n>>> print(tokenizer.supported_language_codes)\n['>>zlm_Latn<<', '>>mfe<<', '>>hat<<', '>>pap<<', '>>ast<<', '>>cat<<', '>>ind<<', '>>glg<<', '>>wln<<', '>>spa<<', '>>fra<<', '>>ron<<', '>>por<<', '>>ita<<', '>>oci<<', '>>arg<<', '>>min<<']\n\n>>> model = MarianMTModel.from_pretrained(model_name)\n>>> translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n>>> [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n[\"c'est une phrase en anglais que nous voulons traduire en fran\u00e7ais\",\n 'Isto deve ir para o portugu\u00eas.',\n 'Y esto al espa\u00f1ol']\n```", "```py\nfrom huggingface_hub import list_models\n\nmodel_list = list_models()\norg = \"Helsinki-NLP\"\nmodel_ids = [x.modelId for x in model_list if x.modelId.startswith(org)]\nsuffix = [x.split(\"/\")[1] for x in model_ids]\nold_style_multi_models = [f\"{org}/{s}\" for s in suffix if s != s.lower()]\n```", "```py\n['Helsinki-NLP/opus-mt-NORTH_EU-NORTH_EU',\n 'Helsinki-NLP/opus-mt-ROMANCE-en',\n 'Helsinki-NLP/opus-mt-SCANDINAVIA-SCANDINAVIA',\n 'Helsinki-NLP/opus-mt-de-ZH',\n 'Helsinki-NLP/opus-mt-en-CELTIC',\n 'Helsinki-NLP/opus-mt-en-ROMANCE',\n 'Helsinki-NLP/opus-mt-es-NORWAY',\n 'Helsinki-NLP/opus-mt-fi-NORWAY',\n 'Helsinki-NLP/opus-mt-fi-ZH',\n 'Helsinki-NLP/opus-mt-fi_nb_no_nn_ru_sv_en-SAMI',\n 'Helsinki-NLP/opus-mt-sv-NORWAY',\n 'Helsinki-NLP/opus-mt-sv-ZH']\nGROUP_MEMBERS = {\n 'ZH': ['cmn', 'cn', 'yue', 'ze_zh', 'zh_cn', 'zh_CN', 'zh_HK', 'zh_tw', 'zh_TW', 'zh_yue', 'zhs', 'zht', 'zh'],\n 'ROMANCE': ['fr', 'fr_BE', 'fr_CA', 'fr_FR', 'wa', 'frp', 'oc', 'ca', 'rm', 'lld', 'fur', 'lij', 'lmo', 'es', 'es_AR', 'es_CL', 'es_CO', 'es_CR', 'es_DO', 'es_EC', 'es_ES', 'es_GT', 'es_HN', 'es_MX', 'es_NI', 'es_PA', 'es_PE', 'es_PR', 'es_SV', 'es_UY', 'es_VE', 'pt', 'pt_br', 'pt_BR', 'pt_PT', 'gl', 'lad', 'an', 'mwl', 'it', 'it_IT', 'co', 'nap', 'scn', 'vec', 'sc', 'ro', 'la'],\n 'NORTH_EU': ['de', 'nl', 'fy', 'af', 'da', 'fo', 'is', 'no', 'nb', 'nn', 'sv'],\n 'SCANDINAVIA': ['da', 'fo', 'is', 'no', 'nb', 'nn', 'sv'],\n 'SAMI': ['se', 'sma', 'smj', 'smn', 'sms'],\n 'NORWAY': ['nb_NO', 'nb', 'nn_NO', 'nn', 'nog', 'no_nb', 'no'],\n 'CELTIC': ['ga', 'cy', 'br', 'gd', 'kw', 'gv']\n}\n```", "```py\n>>> from transformers import MarianMTModel, MarianTokenizer\n\n>>> src_text = [\n...     \">>fr<< this is a sentence in english that we want to translate to french\",\n...     \">>pt<< This should go to portuguese\",\n...     \">>es<< And this to Spanish\",\n... ]\n\n>>> model_name = \"Helsinki-NLP/opus-mt-en-ROMANCE\"\n>>> tokenizer = MarianTokenizer.from_pretrained(model_name)\n\n>>> model = MarianMTModel.from_pretrained(model_name)\n>>> translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n>>> tgt_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n[\"c'est une phrase en anglais que nous voulons traduire en fran\u00e7ais\", \n 'Isto deve ir para o portugu\u00eas.',\n 'Y esto al espa\u00f1ol']\n```", "```py\n>>> from transformers import MarianModel, MarianConfig\n\n>>> # Initializing a Marian Helsinki-NLP/opus-mt-en-de style configuration\n>>> configuration = MarianConfig()\n\n>>> # Initializing a model from the Helsinki-NLP/opus-mt-en-de style configuration\n>>> model = MarianModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import MarianForCausalLM, MarianTokenizer\n\n>>> model = MarianForCausalLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n>>> tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n>>> src_texts = [\"I am a small frog.\", \"Tom asked his teacher for advice.\"]\n>>> tgt_texts = [\"Ich bin ein kleiner Frosch.\", \"Tom bat seinen Lehrer um Rat.\"]  # optional\n>>> inputs = tokenizer(src_texts, text_target=tgt_texts, return_tensors=\"pt\", padding=True)\n\n>>> outputs = model(**inputs)  # should work\n```", "```py\n>>> from transformers import AutoTokenizer, MarianModel\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n>>> model = MarianModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n\n>>> inputs = tokenizer(\"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\")\n>>> decoder_inputs = tokenizer(\n...     \"<pad> Studien haben gezeigt dass es hilfreich ist einen Hund zu besitzen\",\n...     return_tensors=\"pt\",\n...     add_special_tokens=False,\n... )\n>>> outputs = model(input_ids=inputs.input_ids, decoder_input_ids=decoder_inputs.input_ids)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 26, 512]\n```", "```py\n>>> from transformers import AutoTokenizer, MarianMTModel\n\n>>> src = \"fr\"  # source language\n>>> trg = \"en\"  # target language\n\n>>> model_name = f\"Helsinki-NLP/opus-mt-{src}-{trg}\"\n>>> model = MarianMTModel.from_pretrained(model_name)\n>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n>>> sample_text = \"o\u00f9 est l'arr\u00eat de bus ?\"\n>>> batch = tokenizer([sample_text], return_tensors=\"pt\")\n\n>>> generated_ids = model.generate(**batch)\n>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\"Where's the bus stop?\"\n```", "```py\n>>> from transformers import AutoTokenizer, MarianForCausalLM\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n>>> model = MarianForCausalLM.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\", add_cross_attention=False)\n>>> assert model.config.is_decoder, f\"{model.__class__} has to be configured as a decoder.\"\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> logits = outputs.logits\n>>> expected_shape = [1, inputs.input_ids.shape[-1], model.config.vocab_size]\n>>> list(logits.shape) == expected_shape\nTrue\n```", "```py\n>>> from transformers import AutoTokenizer, TFMarianModel\n>>> import tensorflow as tf\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n>>> model = TFMarianModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n>>> outputs = model(inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, TFMarianMTModel\n>>> from typing import List\n\n>>> src = \"fr\"  # source language\n>>> trg = \"en\"  # target language\n>>> sample_text = \"o\u00f9 est l'arr\u00eat de bus ?\"\n>>> model_name = f\"Helsinki-NLP/opus-mt-{src}-{trg}\"\n\n>>> model = TFMarianMTModel.from_pretrained(model_name)\n>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n>>> batch = tokenizer([sample_text], return_tensors=\"tf\")\n>>> gen = model.generate(**batch)\n>>> tokenizer.batch_decode(gen, skip_special_tokens=True)\n\"Where is the bus stop ?\"\n```", "```py\n>>> from transformers import AutoTokenizer, FlaxMarianModel\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n>>> model = FlaxMarianModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"jax\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, FlaxMarianMTModel\n\n>>> model = FlaxMarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n\n>>> text = \"My friends are cool but they eat too many carbs.\"\n>>> input_ids = tokenizer(text, max_length=64, return_tensors=\"jax\").input_ids\n\n>>> sequences = model.generate(input_ids, max_length=64, num_beams=2).sequences\n\n>>> outputs = tokenizer.batch_decode(sequences, skip_special_tokens=True)\n>>> # should give *Meine Freunde sind cool, aber sie essen zu viele Kohlenhydrate.*\n```"]