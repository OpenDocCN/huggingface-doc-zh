["```py\ngit clone https://github.com/huggingface/diffusers\ncd diffusers\npip install .\n```", "```py\ncd examples/wuerstchen/text_to_image\npip install -r requirements.txt\n```", "```py\naccelerate config\n```", "```py\naccelerate config default\n```", "```py\nfrom accelerate.utils import write_basic_config\n\nwrite_basic_config()\n```", "```py\naccelerate launch train_text_to_image_prior.py \\\n  --mixed_precision=\"fp16\"\n```", "```py\nwith ContextManagers(deepspeed_zero_init_disabled_context_manager()):\n    pretrained_checkpoint_file = hf_hub_download(\"dome272/wuerstchen\", filename=\"model_v2_stage_b.pt\")\n    state_dict = torch.load(pretrained_checkpoint_file, map_location=\"cpu\")\n    image_encoder = EfficientNetEncoder()\n    image_encoder.load_state_dict(state_dict[\"effnet_state_dict\"])\n    image_encoder.eval()\n```", "```py\nprior = WuerstchenPrior.from_pretrained(args.pretrained_prior_model_name_or_path, subfolder=\"prior\")\n\noptimizer = optimizer_cls(\n    prior.parameters(),\n    lr=args.learning_rate,\n    betas=(args.adam_beta1, args.adam_beta2),\n    weight_decay=args.adam_weight_decay,\n    eps=args.adam_epsilon,\n)\n```", "```py\ndef preprocess_train(examples):\n    images = [image.convert(\"RGB\") for image in examples[image_column]]\n    examples[\"effnet_pixel_values\"] = [effnet_transforms(image) for image in images]\n    examples[\"text_input_ids\"], examples[\"text_mask\"] = tokenize_captions(examples)\n    return examples\n```", "```py\npred_noise = prior(noisy_latents, timesteps, prompt_embeds)\n```", "```py\nexport DATASET_NAME=\"lambdalabs/pokemon-blip-captions\"\n\naccelerate launch  train_text_to_image_prior.py \\\n  --mixed_precision=\"fp16\" \\\n  --dataset_name=$DATASET_NAME \\\n  --resolution=768 \\\n  --train_batch_size=4 \\\n  --gradient_accumulation_steps=4 \\\n  --gradient_checkpointing \\\n  --dataloader_num_workers=4 \\\n  --max_train_steps=15000 \\\n  --learning_rate=1e-05 \\\n  --max_grad_norm=1 \\\n  --checkpoints_total_limit=3 \\\n  --lr_scheduler=\"constant\" \\\n  --lr_warmup_steps=0 \\\n  --validation_prompts=\"A robot pokemon, 4k photo\" \\\n  --report_to=\"wandb\" \\\n  --push_to_hub \\\n  --output_dir=\"wuerstchen-prior-pokemon-model\"\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForText2Image\nfrom diffusers.pipelines.wuerstchen import DEFAULT_STAGE_C_TIMESTEPS\n\npipeline = AutoPipelineForText2Image.from_pretrained(\"path/to/saved/model\", torch_dtype=torch.float16).to(\"cuda\")\n\ncaption = \"A cute bird pokemon holding a shield\"\nimages = pipeline(\n    caption, \n    width=1024,\n    height=1536,\n    prior_timesteps=DEFAULT_STAGE_C_TIMESTEPS,\n    prior_guidance_scale=4.0,\n    num_images_per_prompt=2,\n).images\n```"]