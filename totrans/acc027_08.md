# 启动您的🤗 Accelerate脚本

> 原始文本：[https://huggingface.co/docs/accelerate/basic_tutorials/launch](https://huggingface.co/docs/accelerate/basic_tutorials/launch)

在上一个教程中，您已经了解了如何修改当前的训练脚本以使用🤗 Accelerate。该代码的最终版本如下所示：

```py
from accelerate import Accelerator

accelerator = Accelerator()

model, optimizer, training_dataloader, scheduler = accelerator.prepare(
    model, optimizer, training_dataloader, scheduler
)

for batch in training_dataloader:
    optimizer.zero_grad()
    inputs, targets = batch
    outputs = model(inputs)
    loss = loss_function(outputs, targets)
    accelerator.backward(loss)
    optimizer.step()
    scheduler.step()
```

但是如何运行此代码并使其利用可用的特殊硬件呢？

首先，您应该将上述代码重写为一个函数，并使其可调用为脚本。例如：

```py
  from accelerate import Accelerator

+ def main():
      accelerator = Accelerator()

      model, optimizer, training_dataloader, scheduler = accelerator.prepare(
          model, optimizer, training_dataloader, scheduler
      )

      for batch in training_dataloader:
          optimizer.zero_grad()
          inputs, targets = batch
          outputs = model(inputs)
          loss = loss_function(outputs, targets)
          accelerator.backward(loss)
          optimizer.step()
          scheduler.step()

+ if __name__ == "__main__":
+     main()
```

接下来，您需要使用`accelerate launch`启动它。

建议在使用`accelerate launch`之前运行`accelerate config`以根据您的喜好配置您的环境。否则，🤗 Accelerate将根据您的系统设置使用非常基本的默认值。

## 使用accelerate launch

🤗 Accelerate具有一个特殊的CLI命令，可通过`accelerate launch`在您的系统中启动您的代码。此命令包装了在各种平台上启动脚本所需的所有不同命令，而无需记住每个命令是什么。

如果您熟悉自己在PyTorch中启动脚本的方法，例如使用`torchrun`，您仍然可以这样做。不需要使用`accelerate launch`。

您可以通过以下方式快速启动您的脚本：

```py
accelerate launch {script_name.py} --arg1 --arg2 ...
```

只需在命令的开头放置`accelerate launch`，然后像平常一样传递其他参数和参数给您的脚本！

由于这会运行各种torch spawn方法，因此所有预期的环境变量也可以在此处进行修改。例如，以下是如何使用单个GPU运行`accelerate launch`：

```py
CUDA_VISIBLE_DEVICES="0" accelerate launch {script_name.py} --arg1 --arg2 ...
```

您还可以在执行`accelerate config`之前使用`accelerate launch`，但可能需要手动传递正确的配置参数。在这种情况下，🤗 Accelerate将为您做出一些超参数决策，例如，如果有GPU可用，默认情况下将使用所有GPU而不使用混合精度。以下是如何使用所有GPU并禁用混合精度进行训练：

```py
accelerate launch --multi_gpu {script_name.py} {--arg1} {--arg2} ...
```

或者通过指定要使用的GPU数量：

```py
accelerate launch --num_processes=2 {script_name.py} {--arg1} {--arg2} ...
```

要更具体，您应该自己传递所需的参数。例如，以下是如何在两个GPU上使用混合精度启动相同脚本并避免所有警告：

```py
accelerate launch --multi_gpu --mixed_precision=fp16 --num_processes=2 {script_name.py} {--arg1} {--arg2} ...
```

要查看可以传递的参数的完整列表，请运行：

```py
accelerate launch -h
```

即使您的代码中没有使用🤗 Accelerate，您仍然可以使用启动器启动您的脚本！

为了可视化这种差异，之前在多GPU上运行的`accelerate launch`将如下所示与`torchrun`一起：

```py
MIXED_PRECISION="fp16" torchrun --nproc_per_node=2 --num_machines=1 {script_name.py} {--arg1} {--arg2} ...
```

您还可以启动您的脚本，利用启动CLI作为Python模块本身，从而使能够传递其他特定于Python的启动行为。为此，请使用`accelerate.commands.launch`而不是`accelerate launch`：

```py
python -m accelerate.commands.launch --num_processes=2 {script_name.py} {--arg1} {--arg2}
```

如果要使用任何其他Python标志执行脚本，也可以将它们传递进来，类似于`-m`，例如下面的示例启用无缓冲的标准输出和标准错误：

```py
python -u -m accelerate.commands.launch --num_processes=2 {script_name.py} {--arg1} {--arg2}
```

您也可以在CPU上运行您的代码！这对于在玩具模型和数据集上进行调试和测试非常有帮助。

```py
accelerate launch --cpu {script_name.py} {--arg1} {--arg2}
```

## 为什么您应该始终使用accelerate config

为什么它如此有用，以至于您应该**始终**运行`accelerate config`？

记得之前调用`accelerate launch`和`torchrun`吗？配置完成后，要运行该脚本并使用所需部分，只需直接使用`accelerate launch`，无需传递其他内容：

```py
accelerate launch {script_name.py} {--arg1} {--arg2} ...
```

## 自定义配置

正如之前简要提到的，`accelerate launch`应主要通过结合使用`accelerate config`命令进行的设置配置。这些配置保存在您的缓存文件夹中的`default_config.yaml`文件中，用于🤗 Accelerate。此缓存文件夹位于以下位置（按优先级递减）：

+   使用您的环境变量`HF_HOME`的内容后缀为`accelerate`。

+   如果不存在，则使用您的环境变量`XDG_CACHE_HOME`的内容后缀为`huggingface/accelerate`。

+   如果这也不存在，则文件夹`~/.cache/huggingface/accelerate`。

要有多个配置，可以将标志`--config_file`传递给`accelerate launch`命令，并与自定义yaml的位置配对。

一个示例yaml可能如下所示，用于在单台机器上使用两个GPU，并使用`fp16`进行混合精度：

```py
compute_environment: LOCAL_MACHINE
deepspeed_config: {}
distributed_type: MULTI_GPU
fsdp_config: {}
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 2
use_cpu: false
```

从自定义yaml文件的位置启动脚本如下所示：

```py
accelerate launch --config_file {path/to/config/my_config_file.yaml} {script_name.py} {--arg1} {--arg2} ...
```

## 多节点训练

使用🤗Accelerate进行多节点训练类似于[使用torchrun进行多节点训练](https://pytorch.org/tutorials/intermediate/ddp_series_multinode.html)。启动多节点训练运行的最简单方法是执行以下操作：

+   将您的代码库和数据复制到所有节点。（或将它们放在共享文件系统上）

+   在所有节点上设置您的Python软件包。

+   首先在主单节点上运行`accelerate config`。在指定节点数后，您将被要求指定每个节点的等级（主/主节点的等级将为0），以及主进程的IP地址和端口。这是为了让工作节点与主进程进行通信。之后，您可以复制或发送此配置文件到所有节点，将`machine_rank`更改为1、2、3等，以避免运行该命令（或直接按照它们的指示使用`torchrun`启动）。

完成此操作后，您可以通过在所有节点上运行`accelerate launch`（或`torchrun`）来启动多节点训练运行。

需要在所有节点上运行该命令才能启动所有内容，而不仅仅是从主节点运行它。您可以使用类似SLURM或不同的进程执行器来包装这个要求，并从单个命令中调用所有内容。

建议使用主节点的内部IP而不是公共IP以获得更好的延迟。这是当您在主节点上运行`hostname -I`时看到的`192.168.x.x`或`172.x.x.x`地址。

要更好地了解多节点训练，请查看我们关于[multi-node training with FSDP](https://huggingface.co/blog/ram-efficient-pytorch-fsdp)的示例。
