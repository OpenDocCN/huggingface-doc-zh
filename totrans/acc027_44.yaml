- en: Utilities for DeepSpeed
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/accelerate/package_reference/deepspeed](https://huggingface.co/docs/accelerate/package_reference/deepspeed)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '<link href="/docs/accelerate/v0.27.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/entry/start.6e0fb178.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/scheduler.69131cc3.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/singletons.ac467c20.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/paths.b2f3aeca.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/entry/app.67e11fc0.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/index.e1f30d73.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/nodes/0.bfeed9f0.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/nodes/19.b16c6bcd.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/Docstring.ae1a1e2d.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/Heading.0aab6758.js">
    ### `class accelerate.DeepSpeedPlugin`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L562)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This plugin is used to integrate DeepSpeed.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `deepspeed_config_process`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L756)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Process the DeepSpeed config with the values from the kwargs.
  prefs: []
  type: TYPE_NORMAL
- en: '### `class accelerate.utils.DummyOptim`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/deepspeed.py#L226)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`lr` (float) — Learning rate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`params` (iterable) — iterable of parameters to optimize or dicts defining
    parameter groups'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`weight_decay` (float) — Weight decay. **kwargs — Other arguments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dummy optimizer presents model parameters or param groups, this is primarily
    used to follow conventional training loop when optimizer config is specified in
    the deepspeed config file.
  prefs: []
  type: TYPE_NORMAL
- en: '### `class accelerate.utils.DummyScheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/deepspeed.py#L249)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`optimizer` (`torch.optim.optimizer.Optimizer`) — The optimizer to wrap.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`total_num_steps` (int, *optional*) — Total number of steps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`warmup_num_steps` (int, *optional*) — Number of steps for warmup.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lr_scheduler_callable` (callable, *optional*) — A callable function that creates
    an LR Scheduler. It accepts only one argument `optimizer`. **kwargs — Other arguments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dummy scheduler presents model parameters or param groups, this is primarily
    used to follow conventional training loop when scheduler config is specified in
    the deepspeed config file.
  prefs: []
  type: TYPE_NORMAL
- en: '### `class accelerate.utils.DeepSpeedEngineWrapper`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/deepspeed.py#L154)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`engine` (deepspeed.runtime.engine.DeepSpeedEngine) — deepspeed engine to wrap'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Internal wrapper for deepspeed.runtime.engine.DeepSpeedEngine. This is used
    to follow conventional training loop.
  prefs: []
  type: TYPE_NORMAL
- en: '### `class accelerate.utils.DeepSpeedOptimizerWrapper`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/deepspeed.py#L182)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`optimizer` (`torch.optim.optimizer.Optimizer`) — The optimizer to wrap.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Internal wrapper around a deepspeed optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: '### `class accelerate.utils.DeepSpeedSchedulerWrapper`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/deepspeed.py#L209)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`scheduler` (`torch.optim.lr_scheduler.LambdaLR`) — The scheduler to wrap.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`optimizers` (one or a list of `torch.optim.Optimizer`) —'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Internal wrapper around a deepspeed scheduler.
  prefs: []
  type: TYPE_NORMAL
