["```py\ninput_ids = tokenizer.encode(\"This is a sentence from the training data\", return_tensors=\"pt\")\nloss = model(input_ids, labels=input_ids)[0]\n```", "```py\n>>> from transformers import ReformerConfig, ReformerModel\n\n>>> # Initializing a Reformer configuration\n>>> configuration = ReformerConfig()\n\n>>> # Initializing a Reformer model (with random weights)\n>>> model = ReformerModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import AutoTokenizer, ReformerModel\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/reformer-crime-and-punishment\")\n>>> model = ReformerModel.from_pretrained(\"google/reformer-crime-and-punishment\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> import torch\n>>> from transformers import AutoTokenizer, ReformerModelWithLMHead\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/reformer-crime-and-punishment\")\n>>> model = ReformerModelWithLMHead.from_pretrained(\"google/reformer-crime-and-punishment\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs, labels=inputs[\"input_ids\"])\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n>>> import torch\n>>> from transformers import AutoTokenizer, ReformerForMaskedLM\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"hf-internal-testing/tiny-random-reformer\")\n>>> model = ReformerForMaskedLM.from_pretrained(\"hf-internal-testing/tiny-random-reformer\")\n\n>>> # add mask_token\n>>> tokenizer.add_special_tokens({\"mask_token\": \"[MASK]\"})\n>>> inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\n\n>>> # resize model's embedding matrix\n>>> model.resize_token_embeddings(new_num_tokens=model.config.vocab_size + 1)\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> # retrieve index of [MASK]\n>>> mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n\n>>> predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n>>> predicted_token = tokenizer.decode(predicted_token_id)\n```", "```py\n>>> labels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n>>> # mask labels of non-[MASK] tokens\n>>> labels = torch.where(\n...     inputs.input_ids == tokenizer.mask_token_id, labels[:, : inputs[\"input_ids\"].shape[-1]], -100\n... )\n\n>>> outputs = model(**inputs, labels=labels)\n>>> loss = round(outputs.loss.item(), 2)\n```", "```py\n>>> import torch\n>>> from transformers import AutoTokenizer, ReformerForSequenceClassification\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/reformer-crime-and-punishment\")\n>>> model = ReformerForSequenceClassification.from_pretrained(\"google/reformer-crime-and-punishment\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> predicted_class_id = logits.argmax().item()\n>>> label = model.config.id2label[predicted_class_id]\n```", "```py\n>>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n>>> num_labels = len(model.config.id2label)\n>>> model = ReformerForSequenceClassification.from_pretrained(\n...     \"google/reformer-crime-and-punishment\", num_labels=num_labels\n... )\n\n>>> labels = torch.tensor(1)\n>>> loss = model(**inputs, labels=labels).loss\n```", "```py\n>>> from transformers import AutoTokenizer, ReformerForQuestionAnswering\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/reformer-crime-and-punishment\")\n>>> model = ReformerForQuestionAnswering.from_pretrained(\"google/reformer-crime-and-punishment\")\n\n>>> question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n\n>>> inputs = tokenizer(question, text, return_tensors=\"pt\")\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> answer_start_index = outputs.start_logits.argmax()\n>>> answer_end_index = outputs.end_logits.argmax()\n\n>>> predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n\n>>> # target is \"nice puppet\"\n>>> target_start_index = torch.tensor([14])\n>>> target_end_index = torch.tensor([15])\n\n>>> outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)\n>>> loss = outputs.loss\n```"]