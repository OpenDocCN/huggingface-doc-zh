- en: Efficient Training on Multiple GPUs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/perf_train_gpu_many](https://huggingface.co/docs/transformers/v4.37.2/en/perf_train_gpu_many)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: If training a model on a single GPU is too slow or if the model’s weights do
    not fit in a single GPU’s memory, transitioning to a multi-GPU setup may be a
    viable option. Prior to making this transition, thoroughly explore all the strategies
    covered in the [Methods and tools for efficient training on a single GPU](perf_train_gpu_one)
    as they are universally applicable to model training on any number of GPUs. Once
    you have employed those strategies and found them insufficient for your case on
    a single GPU, consider moving to multiple GPUs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Transitioning from a single GPU to multiple GPUs requires the introduction of
    some form of parallelism, as the workload must be distributed across the resources.
    Multiple techniques can be employed to achieve parallelism, such as data parallelism,
    tensor parallelism, and pipeline parallelism. It’s important to note that there
    isn’t a one-size-fits-all solution, and the optimal settings depend on the specific
    hardware configuration you are using.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: This guide offers an in-depth overview of individual types of parallelism, as
    well as guidance on ways to combine
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: techniques and choosing an appropriate approach. For step-by-step tutorials
    on distributed training, please refer to the [🤗 Accelerate documentation](https://huggingface.co/docs/accelerate/index).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: While the main concepts discussed in this guide are likely applicable across
    frameworks, here we focus on PyTorch-based implementations.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Before diving deeper into the specifics of each technique, let’s go over the
    rough decision process when training large models on a large infrastructure.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Scalability strategy
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Begin by estimating how much vRAM is required to train your model. For models
    hosted on the 🤗 Hub, use our [Model Memory Calculator](https://huggingface.co/spaces/hf-accelerate/model-memory-usage),
    which gives you accurate calculations within a few percent margin.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '**Parallelization strategy for a single Node / multi-GPU setup**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'When training a model on a single node with multiple GPUs, your choice of parallelization
    strategy can significantly impact performance. Here’s a breakdown of your options:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 1: Your model fits onto a single GPU**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'If your model can comfortably fit onto a single GPU, you have two primary options:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: DDP - Distributed DataParallel
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ZeRO - depending on the situation and configuration used, this method may or
    may not be faster, however, it’s worth experimenting with it.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Case 2: Your model doesn’t fit onto a single GPU:**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: 'If your model is too large for a single GPU, you have several alternatives
    to consider:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: PipelineParallel (PP)
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ZeRO
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: TensorParallel (TP)
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With very fast inter-node connectivity (e.g., NVLINK or NVSwitch) all three
    strategies (PP, ZeRO, TP) should result in similar performance. However, without
    these, PP will be faster than TP or ZeRO. The degree of TP may also make a difference.
    It’s best to experiment with your specific setup to determine the most suitable
    strategy.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: TP is almost always used within a single node. That is TP size <= GPUs per node.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 3: Largest layer of your model does not fit onto a single GPU**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: If you are not using ZeRO, you have to use TensorParallel (TP), because PipelineParallel
    (PP) alone won’t be sufficient to accommodate the large layer.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you are using ZeRO, additionally adopt techniques from the [Methods and tools
    for efficient training on a single GPU](perf_train_gpu_one).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Parallelization strategy for a multi-Node / multi-GPU setup**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'When you have fast inter-node connectivity (e.g., NVLINK or NVSwitch) consider
    using one of these options:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ZeRO - as it requires close to no modifications to the model
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A combination of PipelineParallel(PP) with TensorParallel(TP) and DataParallel(DP)
    - this approach will result in fewer communications, but requires significant
    changes to the model
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When you have slow inter-node connectivity and still low on GPU memory:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Employ a combination of DataParallel(DP) with PipelineParallel(PP), TensorParallel(TP),
    and ZeRO.
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following sections of this guide we dig deeper into how these different
    parallelism methods work.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Data Parallelism
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even with only 2 GPUs, you can readily leverage the accelerated training capabilities
    offered by PyTorch’s built-in features, such as `DataParallel` (DP) and `DistributedDataParallel`
    (DDP). Note that [PyTorch documentation](https://pytorch.org/docs/master/generated/torch.nn.DataParallel.html)
    recommends to prefer `DistributedDataParallel` (DDP) over `DataParallel` (DP)
    for multi-GPU training as it works for all models. Let’s take a look at how these
    two methods work and what makes them different.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: DataParallel vs DistributedDataParallel
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To understand the key differences in inter-GPU communication overhead between
    the two methods, let’s review the processes per batch:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[DDP](https://pytorch.org/docs/master/notes/ddp.html):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: At the start time the main process replicates the model once from GPU 0 to the
    rest of GPUs
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then for each batch:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each GPU directly consumes its mini-batch of data.
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: During `backward`, once the local gradients are ready, they are averaged across
    all processes.
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[DP](https://pytorch.org/docs/master/generated/torch.nn.DataParallel.html):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'For each batch:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: GPU 0 reads the batch of data and then sends a mini-batch to each GPU.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The up-to-date model is replicated from GPU 0 to each GPU.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`forward` is executed, and output from each GPU is sent to GPU 0 to compute
    the loss.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The loss is distributed from GPU 0 to all GPUs, and `backward` is run.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Gradients from each GPU are sent to GPU 0 and averaged.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Key differences include:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: DDP performs only a single communication per batch - sending gradients, while
    DP performs five different data exchanges per batch. DDP copies data using [torch.distributed](https://pytorch.org/docs/master/distributed.html),
    while DP copies data within the process via Python threads (which introduces limitations
    associated with GIL). As a result, **`DistributedDataParallel` (DDP) is generally
    faster than `DataParallel` (DP)** unless you have slow GPU card inter-connectivity.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under DP, GPU 0 performs significantly more work than other GPUs, resulting
    in GPU under-utilization.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: DDP supports distributed training across multiple machines, whereas DP does
    not.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is not an exhaustive list of differences between DP and DDP, however, other
    nuances are out of scope of this guide. You can get a deeper understanding of
    these methods by reading this [article](https://www.telesens.co/2019/04/04/distributed-data-parallel-training-using-pytorch-on-aws/).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s illustrate the differences between DP and DDP with an experiment. We’ll
    benchmark the differences between DP and DDP with an added context of NVLink presence:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Hardware: 2x TITAN RTX 24GB each + NVlink with 2 NVLinks (`NV2` in `nvidia-smi
    topo -m`).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Software: `pytorch-1.8-to-be` + `cuda-11.0` / `transformers==4.3.0.dev0`.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To disable the NVLink feature on one of the benchmarks, we use `NCCL_P2P_DISABLE=1`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the benchmarking code and outputs:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '**DP**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**DDP w/ NVlink**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**DDP w/o NVlink**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here are the same benchmarking results gathered in a table for convenience:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '| Type | NVlink | Time |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
- en: '| :-- | --- | --: |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| 2:DP | Y | 110s |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| 2:DDP | Y | 101s |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| 2:DDP | N | 131s |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: As you can see, in this case DP is ~10% slower than DDP with NVlink, but ~15%
    faster than DDP without NVlink. The real difference will depend on how much data
    each GPU needs to sync with the others - the more there is to sync, the more a
    slow link will impede the overall runtime.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: ZeRO Data Parallelism
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ZeRO-powered data parallelism (ZeRO-DP) is illustrated in the following diagram
    from this [blog post](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '![DeepSpeed-Image-1](../Images/61da03a3a1a0e2c5e704642f87f2f216.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
- en: While it may appear complex, it is a very similar concept to `DataParallel`
    (DP). The difference is that instead of replicating the full model parameters,
    gradients and optimizer states, each GPU stores only a slice of it. Then, at run-time
    when the full layer parameters are needed just for the given layer, all GPUs synchronize
    to give each other parts that they miss.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然看起来复杂，但这与`DataParallel`（DP）非常相似。不同之处在于，每个GPU只存储其一部分，而不是复制完整的模型参数、梯度和优化器状态。然后，在运行时，当需要完整的层参数时，所有GPU会同步以互相提供它们缺少的部分。
- en: 'To illustrate this idea, consider a simple model with 3 layers (La, Lb, and
    Lc), where each layer has 3 parameters. Layer La, for example, has weights a0,
    a1 and a2:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个想法，考虑一个具有3层（La，Lb和Lc）的简单模型，其中每层有3个参数。例如，层La有权重a0，a1和a2：
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If we have 3 GPUs, ZeRO-DP splits the model onto 3 GPUs like so:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有3个GPU，ZeRO-DP将模型分割到3个GPU上：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In a way, this is the same horizontal slicing as tensor parallelism, as opposed
    to Vertical slicing, where one puts whole layer-groups on different GPUs. Now
    let’s see how this works:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在某种程度上，这与张量并行性相同的水平切片，与垂直切片相对，其中将整个层组放在不同的GPU上。现在让我们看看这是如何工作的：
- en: 'Each of these GPUs will get the usual mini-batch as it works in DP:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些GPU中的每一个都将像DP中那样获得通常的小批量：
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The inputs are passed without modifications as if they would be processed by
    the original model.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 输入被传递而不进行修改，就好像原始模型会处理它们一样。
- en: First, the inputs get to the layer `La`. What happens at this point?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，输入到达层`La`。在这一点上会发生什么？
- en: 'On GPU0: the x0 mini-batch requires the a0, a1, a2 parameters to do its forward
    path through the layer, but the GPU0 has only a0. It will get a1 from GPU1 and
    a2 from GPU2, bringing all the pieces of the model together.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPU0上：x0小批量需要a0，a1，a2参数通过层进行前向路径，但GPU0只有a0。它将从GPU1获取a1，从GPU2获取a2，将模型的所有部分汇集在一起。
- en: In parallel, GPU1 gets another mini-batch - x1\. GPU1 has the a1 parameter,
    but needs a0 and a2, so it gets those from GPU0 and GPU2. Same happens to GPU2
    that gets the mini-batch x2\. It gets a0 and a1 from GPU0 and GPU1.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，GPU1获得另一个小批量-x1。GPU1具有a1参数，但需要a0和a2，因此它从GPU0和GPU2获取这些。GPU2也发生同样的情况，它获得小批量x2。它从GPU0和GPU1获取a0和a1。
- en: This way each of the 3 GPUs gets the full tensors reconstructed and makes a
    forward pass with its own mini-batch. As soon as the calculation is done, the
    data that is no longer needed gets dropped - it’s only used during the calculation.
    The reconstruction is done efficiently via a pre-fetch.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，每个3个GPU都会得到完整的张量重建，并使用自己的小批量进行前向传递。一旦计算完成，不再需要的数据将被丢弃-它只在计算过程中使用。重建通过预取高效地完成。
- en: Then the whole process is repeated for layer Lb, then Lc forward-wise, and then
    backward Lc -> Lb -> La.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然后整个过程会为层Lb重复，然后是Lc的前向，然后是Lc -> Lb -> La的后向。
- en: 'This mechanism is similar to an efficient group backpacking strategy: person
    A carries the tent, person B carries the stove, and person C carries the axe.
    Each night they all share what they have with others and get from others what
    they don’t have, and in the morning they pack up their allocated type of gear
    and continue on their way. This is what ZeRO DP/Sharded DDP is. Compare this strategy
    to the simple one where each person has to carry their own tent, stove and axe
    (similar to DataParallel (DP and DDP) in PyTorch), which would be far more inefficient.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这种机制类似于一种高效的团体背包策略：A人携带帐篷，B人携带炉灶，C人携带斧头。每晚他们都分享自己拥有的东西，并从他人那里得到他们没有的东西，早上他们收拾好自己分配的装备类型，继续前进。这就是ZeRO
    DP/Sharded DDP。将这种策略与每个人都必须携带自己的帐篷、炉灶和斧头的简单策略进行比较（类似于PyTorch中的DataParallel（DP和DDP）），后者将更加低效。
- en: 'While reading the literature on this topic you may encounter the following
    synonyms: Sharded, Partitioned. If you pay close attention the way ZeRO partitions
    the model’s weights - it looks very similar to tensor parallelism which will be
    discussed later. This is because it partitions/shards each layer’s weights, unlike
    vertical model parallelism which is discussed next.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读这个主题的文献时，您可能会遇到以下同义词：分片，分区。如果您仔细注意ZeRO如何分割模型的权重-它看起来非常类似于张量并行性，稍后将对此进行讨论。这是因为它分割/分片每个层的权重，与接下来将讨论的垂直模型并行性不同。
- en: 'Implementations:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 实施：
- en: '[DeepSpeed](https://www.deepspeed.ai/tutorials/zero/) ZeRO-DP stages 1+2+3'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepSpeed](https://www.deepspeed.ai/tutorials/zero/) ZeRO-DP 阶段1+2+3'
- en: '[`Accelerate` integration](https://huggingface.co/docs/accelerate/en/usage_guides/deepspeed)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`加速`集成](https://huggingface.co/docs/accelerate/en/usage_guides/deepspeed)'
- en: '[`transformers` integration](main_classes/trainer#trainer-integrations)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`transformers` 集成](main_classes/trainer#trainer-integrations)'
- en: From Naive Model Parallelism to Pipeline Parallelism
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从天真的模型并行性到管道并行性
- en: To explain Pipeline parallelism, we’ll first look into Naive Model Parallelism
    (MP), also known as Vertical MP. This approach involves distributing groups of
    model layers across multiple GPUs by assigning specific layers to specific GPUs
    with `.to()`. As data flows through these layers, it is moved to the same GPU
    as the layer, while the other layers remain untouched.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 解释管道并行性，我们首先将研究天真的模型并行性（MP），也称为垂直MP。这种方法涉及通过使用`.to()`将模型层组分配到多个GPU上，将特定层分配给特定GPU。当数据流经这些层时，它被移动到与该层相同的GPU上，而其他层保持不变。
- en: 'We refer to this Model parallelism as “Vertical” because of how models are
    typically visualized. For example, the following diagram shows an 8-layer model
    split vertically into two slices, placing layers 0-3 onto GPU0 and 4-7 to GPU1:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这种模型并行性称为“垂直”，因为模型通常是如何可视化的。例如，以下图表显示将8层模型垂直分割成两个切片，将层0-3放在GPU0上，将层4-7放在GPU1上：
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this example, when data moves from layer 0 to 3, it’s no different from regular
    forward pass. However, passing data from layer 3 to 4 requires moving it from
    GPU0 to GPU1, introducing a communication overhead. If the participating GPUs
    are on the same compute node (e.g. same physical machine) this copying is fast,
    but if the GPUs are distributed across different compute nodes (e.g. multiple
    machines), the communication overhead could be substantially greater.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Following that, layers 4 to 7 work as they would in the original model. Upon
    completion of the 7th layer, there is often a need to send the data back to layer
    0 where the labels are (or alternatively send the labels to the last layer). Now
    the loss can be computed and the optimizer can do its work.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'Naive Model Parallelism comes several shortcomings:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '**All but one GPU are idle at any given moment**: if 4 GPUs are used, it’s
    nearly identical to quadrupling the amount of memory of a single GPU, and ignoring
    the rest of the hardware.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overhead in data transfer between devices**: E.g. 4x 6GB cards will be able
    to accommodate the same size as 1x 24GB card using naive MP, but a single 24GB
    card will complete the training faster, because it doesn’t have the data copying
    overhead. But, say, if you have 40GB cards and need to fit a 45GB model you can
    with 4x 40GB cards (but barely because of the gradient and optimizer states)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Copying shared embeddings**: Shared embeddings may need to get copied back
    and forth between GPUs.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you are familiar with how the naive approach to model parallelism works
    and its shortcomings, let’s look at Pipeline Parallelism (PP). PP is almost identical
    to a naive MP, but it solves the GPU idling problem by chunking the incoming batch
    into micro-batches and artificially creating a pipeline, which allows different
    GPUs to concurrently participate in the computation process.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'The following illustration from the [GPipe paper](https://ai.googleblog.com/2019/03/introducing-gpipe-open-source-library.html)
    shows the naive MP on the top, and PP on the bottom:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![MP vs PP](../Images/ba7b60c4785caa5f69f0731aec905196.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: At the bottom of the diagram, you can observe that the Pipeline Parallelism
    (PP) approach minimizes the number of idle GPU zones, referred to as ‘bubbles’.
    Both parts of the diagram show a parallelism level of degree 4, meaning that 4
    GPUs are involved in the pipeline. You can see that there’s a forward path of
    4 pipe stages (F0, F1, F2 and F3) followed by a backward path in reverse order
    (B3, B2, B1, and B0).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: PP introduces a new hyperparameter to tune - `chunks`, which determines how
    many data chunks are sent in a sequence through the same pipe stage. For example,
    in the bottom diagram you can see `chunks=4`. GPU0 performs the same forward path
    on chunk 0, 1, 2 and 3 (F0,0, F0,1, F0,2, F0,3) and then it waits for other GPUs
    to do complete their work. Only when the other GPUs begin to complete their work,
    GPU0 starts to work again doing the backward path for chunks 3, 2, 1 and 0 (B0,3,
    B0,2, B0,1, B0,0).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is the same concept as gradient accumulation steps. PyTorch uses
    `chunks`, while DeepSpeed refers to the same hyperparameter as gradient accumulation
    steps.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Because of the chunks, PP introduces the notion of micro-batches (MBS). DP
    splits the global data batch size into mini-batches, so if you have a DP degree
    of 4, a global batch size of 1024 gets split up into 4 mini-batches of 256 each
    (1024/4). And if the number of `chunks` (or GAS) is 32 we end up with a micro-batch
    size of 8 (256/32). Each Pipeline stage works with a single micro-batch at a time.
    To calculate the global batch size of the DP + PP setup, use the formula: `mbs
    * chunks * dp_degree` (`8 * 32 * 4 = 1024`). With `chunks=1` you end up with the
    naive MP, which is inefficient. With a large `chunks` value you end up with tiny
    micro-batch sizes which is also inefficient. For this reason, we encourage to
    experiment with the `chunks` value to find the one that leads to the most efficient
    GPUs utilization.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 由于chunks，PP引入了微批次（MBS）的概念。DP将全局数据批次大小分成小批次，因此如果DP度为4，则全局批次大小为1024将分成4个每个256的小批次（1024/4）。如果`chunks`（或GAS）的数量为32，则我们最终得到一个微批次大小为8（256/32）。每个管道阶段一次处理一个微批次。要计算DP
    + PP设置的全局批次大小，请使用公式：`mbs * chunks * dp_degree`（`8 * 32 * 4 = 1024`）。当`chunks=1`时，您将得到天真的MP，这是低效的。当`chunks`值很大时，您将得到微小的微批次大小，这也是低效的。因此，我们鼓励尝试不同的`chunks`值，以找到导致最有效的GPU利用率的值。
- en: You may notice a bubble of “dead” time on the diagram that can’t be parallelized
    because the last `forward` stage has to wait for `backward` to complete the pipeline.
    The purpose of finding the best value for `chunks` is to enable a high concurrent
    GPU utilization across all participating GPUs which translates to minimizing the
    size of the bubble.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到图表上的“死”时间泡泡，因为最后的`forward`阶段必须等待`backward`完成管道。找到`chunks`的最佳值的目的是实现所有参与GPU之间的高并发GPU利用率，从而最小化泡泡的大小。
- en: 'Pipeline API solutions have been implemented in:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Pipeline API解决方案已在以下平台中实施：
- en: PyTorch
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch
- en: DeepSpeed
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeepSpeed
- en: Megatron-LM
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Megatron-LM
- en: 'These come with some shortcomings:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些存在一些缺点：
- en: They have to modify the model quite heavily, because Pipeline requires one to
    rewrite the normal flow of modules into a `nn.Sequential` sequence of the same,
    which may require changes to the design of the model.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们必须对模型进行相当大的修改，因为Pipeline要求将模块的正常流重写为相同的`nn.Sequential`序列，这可能需要对模型的设计进行更改。
- en: Currently the Pipeline API is very restricted. If you had a bunch of Python
    variables being passed in the very first stage of the Pipeline, you will have
    to find a way around it. Currently, the pipeline interface requires either a single
    Tensor or a tuple of Tensors as the only input and output. These tensors must
    have a batch size as the very first dimension, since pipeline is going to chunk
    the mini batch into micro-batches. Possible improvements are being discussed here
    [https://github.com/pytorch/pytorch/pull/50693](https://github.com/pytorch/pytorch/pull/50693)
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前，Pipeline API非常受限制。如果在管道的第一个阶段传递了一堆Python变量，您将不得不找到解决方法。目前，管道接口要求作为唯一输入和输出的是单个张量或张量元组。这些张量的批次大小必须作为第一个维度，因为管道将小批次分成微批次。这里正在讨论可能的改进[https://github.com/pytorch/pytorch/pull/50693](https://github.com/pytorch/pytorch/pull/50693)
- en: Conditional control flow at the level of pipe stages is not possible - e.g.,
    Encoder-Decoder models like T5 require special workarounds to handle a conditional
    encoder stage.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在管道阶段的条件控制流不可能-例如，编码器-解码器模型（如T5）需要特殊的解决方案来处理条件编码器阶段。
- en: They have to arrange each layer so that the output of one layer becomes an input
    to the other layer.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们必须安排每一层，以便一层的输出成为另一层的输入。
- en: 'More recent solutions include:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 更近期的解决方案包括：
- en: Varuna
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Varuna
- en: Sagemaker
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sagemaker
- en: We have not experimented with Varuna and SageMaker but their papers report that
    they have overcome the list of problems mentioned above and that they require
    smaller changes to the user’s model.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尚未尝试Varuna和SageMaker，但他们的论文报告称，他们已经克服了上述问题列表，并且需要对用户模型进行较小的更改。
- en: 'Implementations:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 实施：
- en: '[PyTorch](https://pytorch.org/docs/stable/pipeline.html) (initial support in
    pytorch-1.8, and progressively getting improved in 1.9 and more so in 1.10). Some
    [examples](https://github.com/pytorch/pytorch/blob/master/benchmarks/distributed/pipeline/pipe.py)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch](https://pytorch.org/docs/stable/pipeline.html)（在pytorch-1.8中提供初始支持，并在1.9中逐渐改进，在1.10中更是如此）。一些[示例](https://github.com/pytorch/pytorch/blob/master/benchmarks/distributed/pipeline/pipe.py)'
- en: '[DeepSpeed](https://www.deepspeed.ai/tutorials/pipeline/)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepSpeed](https://www.deepspeed.ai/tutorials/pipeline/)'
- en: '[Megatron-LM](https://github.com/NVIDIA/Megatron-LM) has an internal implementation
    - no API.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)具有内部实现-没有API。'
- en: '[Varuna](https://github.com/microsoft/varuna)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Varuna](https://github.com/microsoft/varuna)'
- en: '[SageMaker](https://arxiv.org/abs/2111.05972) - this is a proprietary solution
    that can only be used on AWS.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker](https://arxiv.org/abs/2111.05972) - 这是一种专有解决方案，只能在AWS上使用。'
- en: '[OSLO](https://github.com/tunib-ai/oslo) - this is implemented based on the
    Hugging Face Transformers.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OSLO](https://github.com/tunib-ai/oslo) - 这是基于Hugging Face Transformers实现的。'
- en: '🤗 Transformers status: as of this writing none of the models supports full-PP.
    GPT2 and T5 models have naive MP support. The main obstacle is being unable to
    convert the models to `nn.Sequential` and have all the inputs to be Tensors. This
    is because currently the models include many features that make the conversion
    very complicated, and will need to be removed to accomplish that.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers状态：截至目前，没有模型支持完整的PP。GPT2和T5模型具有天真的MP支持。主要障碍是无法将模型转换为`nn.Sequential`并使所有输入为张量。这是因为当前模型包含许多使转换非常复杂的特性，并且需要将其删除才能实现转换。
- en: DeepSpeed and Megatron-LM integrations are available in [🤗 Accelerate](https://huggingface.co/docs/accelerate/main/en/usage_guides/deepspeed)
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSpeed和Megatron-LM集成可在[🤗 Accelerate](https://huggingface.co/docs/accelerate/main/en/usage_guides/deepspeed)中找到
- en: 'Other approaches:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 其他方法：
- en: DeepSpeed, Varuna and SageMaker use the concept of an [Interleaved Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-core-features.html)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSpeed、Varuna和SageMaker使用[交错管道](https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-core-features.html)的概念
- en: '![Interleaved pipeline execution](../Images/fe4c5248602104a9d60765bc134bfd01.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![交错管道执行](../Images/fe4c5248602104a9d60765bc134bfd01.png)'
- en: Here the bubble (idle time) is further minimized by prioritizing backward passes.
    Varuna further attempts to improve the schedule by using simulations to discover
    the most efficient scheduling.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，通过优先考虑反向传递来进一步减少气泡（空闲时间）。Varuna通过使用模拟来发现最有效的调度来尝试改进时间表。
- en: OSLO has pipeline parallelism implementation based on the Transformers without
    `nn.Sequential` conversion.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: OSLO具有基于Transformers的管道并行实现，无需`nn.Sequential`转换。
- en: Tensor Parallelism
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量并行
- en: 'In Tensor Parallelism, each GPU processes a slice of a tensor and only aggregates
    the full tensor for operations requiring it. To describe this method, this section
    of the guide relies on the concepts and diagrams from the [Megatron-LM](https://github.com/NVIDIA/Megatron-LM)
    paper: [Efficient Large-Scale Language Model Training on GPU Clusters](https://arxiv.org/abs/2104.04473).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在张量并行中，每个GPU处理张量的一个切片，并且仅在需要时聚合完整的张量进行操作。为了描述这种方法，本指南的这一部分依赖于[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)论文中的概念和图表：[在GPU集群上进行高效的大规模语言模型训练](https://arxiv.org/abs/2104.04473)。
- en: The main building block of any transformer is a fully connected `nn.Linear`
    followed by a nonlinear activation `GeLU`. The dot dot-product part of it, following
    the Megatron’s paper notation, can be written as `Y = GeLU(XA)`, where `X` is
    an input vector, `Y` is the output vector, and `A` is the weight matrix.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 任何transformer的主要构建块是一个完全连接的`nn.Linear`，后面跟着一个非线性激活`GeLU`。它的点积部分，根据Megatron的论文符号表示法，可以写成`Y
    = GeLU(XA)`，其中`X`是输入向量，`Y`是输出向量，`A`是权重矩阵。
- en: 'If we look at the computation in matrix form, you can see how the matrix multiplication
    can be split between multiple GPUs:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以矩阵形式看计算，您可以看到矩阵乘法如何在多个GPU之间分割：
- en: '![Parallel GEMM](../Images/24e76c89c6e86afa3bc79043047b8082.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![并行GEMM](../Images/24e76c89c6e86afa3bc79043047b8082.png)'
- en: 'If we split the weight matrix `A` column-wise across `N` GPUs and perform matrix
    multiplications `XA_1` through `XA_n` in parallel, then we will end up with `N`
    output vectors `Y_1, Y_2, ..., Y_n` which can be fed into `GeLU` independently:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将权重矩阵`A`在`N`个GPU上按列划分，并在并行执行矩阵乘法`XA_1`到`XA_n`，那么我们将得到`N`个输出向量`Y_1, Y_2,
    ..., Y_n`，可以独立地输入到`GeLU`中：
- en: '![Independent GeLU](../Images/03ee256eff323b38a197978ce627170d.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![独立GeLU](../Images/03ee256eff323b38a197978ce627170d.png)'
- en: 'Using this principle, we can update a multi-layer perceptron of arbitrary depth,
    without the need for any synchronization between GPUs until the very end, where
    we need to reconstruct the output vector from shards. The Megatron-LM paper authors
    provide a helpful illustration for that:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个原则，我们可以更新任意深度的多层感知器，而无需在GPU之间进行任何同步，直到最后，在那里我们需要从碎片中重建输出向量。Megatron-LM论文的作者为此提供了一个有用的插图：
- en: '![Parallel shard processing](../Images/31d292bdb9b6fa0edbf59e631b8b21c8.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![并行碎片处理](../Images/31d292bdb9b6fa0edbf59e631b8b21c8.png)'
- en: Parallelizing the multi-headed attention layers is even simpler, since they
    are already inherently parallel, due to having multiple independent heads!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化多头注意力层甚至更简单，因为它们已经天生是并行的，由于具有多个独立的头！
- en: '![Parallel self-attention](../Images/6fc3dbac64ede57965d6026e9a2fe8c2.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![并行自注意力](../Images/6fc3dbac64ede57965d6026e9a2fe8c2.png)'
- en: 'Special considerations: TP requires very fast network, and therefore it’s not
    advisable to do TP across more than one node. Practically, if a node has 4 GPUs,
    the highest TP degree is therefore 4\. If you need a TP degree of 8, you need
    to use nodes that have at least 8 GPUs.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 特殊考虑：TP需要非常快的网络，因此不建议在多个节点之间进行TP。实际上，如果一个节点有4个GPU，则最高的TP度数为4。如果您需要8的TP度数，则需要使用至少有8个GPU的节点。
- en: This section is based on the original much more [detailed TP overview](https://github.com/huggingface/transformers/issues/10321#issuecomment-783543530).
    by [@anton-l](https://github.com/anton-l).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 本节基于原始的更详细的[TP概述](https://github.com/huggingface/transformers/issues/10321#issuecomment-783543530)。by
    [@anton-l](https://github.com/anton-l)。
- en: 'Alternative names:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 替代名称：
- en: DeepSpeed calls it [tensor slicing](https://www.deepspeed.ai/training/#model-parallelism)
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeepSpeed称之为[张量切片](https://www.deepspeed.ai/training/#model-parallelism)
- en: 'Implementations:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 实施：
- en: '[Megatron-LM](https://github.com/NVIDIA/Megatron-LM) has an internal implementation,
    as it’s very model-specific'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)具有内部实现，因为它非常特定于模型。'
- en: '[parallelformers](https://github.com/tunib-ai/parallelformers) (only inference
    at the moment)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[parallelformers](https://github.com/tunib-ai/parallelformers)（目前仅推理）'
- en: '[SageMaker](https://arxiv.org/abs/2111.05972) - this is a proprietary solution
    that can only be used on AWS.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker](https://arxiv.org/abs/2111.05972) - 这是一个专有解决方案，只能在AWS上使用。'
- en: '[OSLO](https://github.com/tunib-ai/oslo) has the tensor parallelism implementation
    based on the Transformers.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OSLO](https://github.com/tunib-ai/oslo)具有基于Transformers的张量并行实现。'
- en: SageMaker combines TP with DP for a more efficient processing.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker将TP与DP结合起来，以实现更高效的处理。
- en: '🤗 Transformers status:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers状态：
- en: 'core: not yet implemented in the core'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心：核心尚未实现
- en: but if you want inference [parallelformers](https://github.com/tunib-ai/parallelformers)
    provides this support for most of our models. So until this is implemented in
    the core you can use theirs. And hopefully training mode will be supported too.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 但是如果您需要推理[parallelformers](https://github.com/tunib-ai/parallelformers)为我们大多数模型提供了支持。因此，在核心实现之前，您可以使用它们的支持。希望训练模式也会得到支持。
- en: Deepspeed-Inference also supports our BERT, GPT-2, and GPT-Neo models in their
    super-fast CUDA-kernel-based inference mode, see more [here](https://www.deepspeed.ai/tutorials/inference-tutorial/)
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deepspeed-Inference还支持我们的BERT、GPT-2和GPT-Neo模型，采用超快的基于CUDA内核的推理模式，更多信息请参见[这里](https://www.deepspeed.ai/tutorials/inference-tutorial/)
- en: 🤗 Accelerate integrates with [TP from Megatron-LM](https://huggingface.co/docs/accelerate/v0.23.0/en/usage_guides/megatron_lm).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Accelerate集成了[Megatron-LM的TP](https://huggingface.co/docs/accelerate/v0.23.0/en/usage_guides/megatron_lm)。
- en: Data Parallelism + Pipeline Parallelism
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据并行 + 管道并行
- en: The following diagram from the DeepSpeed [pipeline tutorial](https://www.deepspeed.ai/tutorials/pipeline/)
    demonstrates how one can combine DP with PP.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 来自DeepSpeed [pipeline教程](https://www.deepspeed.ai/tutorials/pipeline/)的以下图表演示了如何将DP与PP结合使用。
- en: '![DP + PP-2d](../Images/2aea4e58b8f741571e02a891090ecb48.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![DP + PP-2d](../Images/2aea4e58b8f741571e02a891090ecb48.png)'
- en: Here it’s important to see how DP rank 0 doesn’t see GPU2 and DP rank 1 doesn’t
    see GPU3\. To DP there is just GPUs 0 and 1 where it feeds data as if there were
    just 2 GPUs. GPU0 “secretly” offloads some of its load to GPU2 using PP. And GPU1
    does the same by enlisting GPU3 to its aid.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，重要的是看到DP等级0看不到GPU2，DP等级1看不到GPU3。对于DP来说，只有GPU 0和1，它们像只有2个GPU一样提供数据。GPU0“秘密”地将一些负载转移到GPU2上，使用PP。GPU1也通过将GPU3列入其援助来做同样的事情。
- en: Since each dimension requires at least 2 GPUs, here you’d need at least 4 GPUs.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个维度至少需要2个GPU，所以这里至少需要4个GPU。
- en: 'Implementations:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 实现：
- en: '[DeepSpeed](https://github.com/microsoft/DeepSpeed)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepSpeed](https://github.com/microsoft/DeepSpeed)'
- en: '[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)'
- en: '[Varuna](https://github.com/microsoft/varuna)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Varuna](https://github.com/microsoft/varuna)'
- en: '[SageMaker](https://arxiv.org/abs/2111.05972)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker](https://arxiv.org/abs/2111.05972)'
- en: '[OSLO](https://github.com/tunib-ai/oslo)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OSLO](https://github.com/tunib-ai/oslo)'
- en: '🤗 Transformers status: not yet implemented'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers状态：尚未实现
- en: Data Parallelism + Pipeline Parallelism + Tensor Parallelism
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据并行 + 流水线并行 + 张量并行
- en: To get an even more efficient training a 3D parallelism is used where PP is
    combined with TP and DP. This can be seen in the following diagram.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更高效的训练，使用了3D并行，其中PP与TP和DP结合使用。可以在以下图表中看到。
- en: '![dp-pp-tp-3d](../Images/576dd96e11eaad105f11f0b16e8458b1.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![dp-pp-tp-3d](../Images/576dd96e11eaad105f11f0b16e8458b1.png)'
- en: 'This diagram is from a blog post [3D parallelism: Scaling to trillion-parameter
    models](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/),
    which is a good read as well.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表来自一篇博文[3D并行：扩展到万亿参数模型](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/)，也是一篇很好的阅读。
- en: Since each dimension requires at least 2 GPUs, here you’d need at least 8 GPUs.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个维度至少需要2个GPU，所以这里至少需要8个GPU。
- en: 'Implementations:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 实现：
- en: '[DeepSpeed](https://github.com/microsoft/DeepSpeed) - DeepSpeed also includes
    an even more efficient DP, which they call ZeRO-DP.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepSpeed](https://github.com/microsoft/DeepSpeed) - DeepSpeed还包括一个更高效的DP，他们称之为ZeRO-DP。'
- en: '[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)'
- en: '[Varuna](https://github.com/microsoft/varuna)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Varuna](https://github.com/microsoft/varuna)'
- en: '[SageMaker](https://arxiv.org/abs/2111.05972)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker](https://arxiv.org/abs/2111.05972)'
- en: '[OSLO](https://github.com/tunib-ai/oslo)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OSLO](https://github.com/tunib-ai/oslo)'
- en: '🤗 Transformers status: not yet implemented, since we have no PP and TP.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers状态：尚未实现，因为我们没有PP和TP。
- en: ZeRO Data Parallelism + Pipeline Parallelism + Tensor Parallelism
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ZeRO数据并行 + 流水线并行 + 张量并行
- en: One of the main features of DeepSpeed is ZeRO, which is a super-scalable extension
    of DP. It has already been discussed in [ZeRO Data Parallelism](#zero-data-parallelism).
    Normally it’s a standalone feature that doesn’t require PP or TP. But it can be
    combined with PP and TP.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSpeed的主要特点之一是ZeRO，它是DP的一个超可扩展扩展。已经在[ZeRO数据并行](#zero-data-parallelism)中讨论过。通常它是一个独立的功能，不需要PP或TP。但它可以与PP和TP结合使用。
- en: When ZeRO-DP is combined with PP (and optionally TP) it typically enables only
    ZeRO stage 1 (optimizer sharding).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 当ZeRO-DP与PP（和可选的TP）结合时，通常只启用ZeRO阶段1（优化器分片）。
- en: While it’s theoretically possible to use ZeRO stage 2 (gradient sharding) with
    Pipeline Parallelism, it will have negative performance impacts. There would need
    to be an additional reduce-scatter collective for every micro-batch to aggregate
    the gradients before sharding, which adds a potentially significant communication
    overhead. By nature of Pipeline Parallelism, small micro-batches are used and
    instead the focus is on trying to balance arithmetic intensity (micro-batch size)
    with minimizing the Pipeline bubble (number of micro-batches). Therefore those
    communication costs are going to impact the performance.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然理论上可以使用ZeRO阶段2（梯度分片）与流水线并行，但会对性能产生负面影响。每个微批次都需要额外的reduce-scatter集合来聚合梯度，然后再进行分片，这会增加潜在的显著通信开销。由于流水线并行的特性，使用小微批次，而重点是尝试平衡算术强度（微批次大小）和最小化流水线气泡（微批次数量）。因此，这些通信成本将影响性能。
- en: In addition, there are already fewer layers than normal due to PP and so the
    memory savings won’t be huge. PP already reduces gradient size by `1/PP`, and
    so gradient sharding savings on top of that are less significant than pure DP.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于PP已经减少了梯度大小`1/PP`，所以梯度分片的节省并不像纯DP那样显著。
- en: ZeRO stage 3 is not a good choice either for the same reason - more inter-node
    communications required.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ZeRO阶段3也不是一个好选择，原因是需要更多的节点间通信。
- en: And since we have ZeRO, the other benefit is ZeRO-Offload. Since this is stage
    1 optimizer states can be offloaded to CPU.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有ZeRO，另一个好处是ZeRO-Offload。由于这是阶段1优化器状态可以转移到CPU。
- en: 'Implementations:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 实现：
- en: '[Megatron-DeepSpeed](https://github.com/microsoft/Megatron-DeepSpeed) and [Megatron-Deepspeed
    from BigScience](https://github.com/bigscience-workshop/Megatron-DeepSpeed), which
    is the fork of the former repo.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Megatron-DeepSpeed](https://github.com/microsoft/Megatron-DeepSpeed)和[BigScience的Megatron-Deepspeed](https://github.com/bigscience-workshop/Megatron-DeepSpeed)，这是前一个存储库的分支。'
- en: '[OSLO](https://github.com/tunib-ai/oslo)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OSLO](https://github.com/tunib-ai/oslo)'
- en: 'Important papers:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 重要论文：
- en: '[Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale
    Generative Language Model](https://arxiv.org/abs/2201.11990)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用DeepSpeed和Megatron训练Megatron-Turing NLG 530B，一个大规模生成式语言模型
- en: '🤗 Transformers status: not yet implemented, since we have no PP and TP.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers状态：尚未实现，因为我们没有PP和TP。
- en: FlexFlow
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlexFlow
- en: '[FlexFlow](https://github.com/flexflow/FlexFlow) also solves the parallelization
    problem in a slightly different approach.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlexFlow](https://github.com/flexflow/FlexFlow) 也以略有不同的方式解决了并行化问题。'
- en: 'Paper: [“Beyond Data and Model Parallelism for Deep Neural Networks” by Zhihao
    Jia, Matei Zaharia, Alex Aiken](https://arxiv.org/abs/1807.05358)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 论文：[“Beyond Data and Model Parallelism for Deep Neural Networks” by Zhihao Jia,
    Matei Zaharia, Alex Aiken](https://arxiv.org/abs/1807.05358)
- en: It performs a sort of 4D Parallelism over Sample-Operator-Attribute-Parameter.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 它执行一种4D并行化，涵盖样本-操作-属性-参数。
- en: Sample = Data Parallelism (sample-wise parallel)
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 样本 = 数据并行化（样本方向并行）
- en: Operator = Parallelize a single operation into several sub-operations
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 操作 = 将单个操作并行化为多个子操作
- en: Attribute = Data Parallelism (length-wise parallel)
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 属性 = 数据并行化（长度方向并行）
- en: Parameter = Model Parallelism (regardless of dimension - horizontal or vertical)
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参数 = 模型并行化（无论维度是水平还是垂直）
- en: 'Examples:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: Sample
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本
- en: Let’s take 10 batches of sequence length 512\. If we parallelize them by sample
    dimension into 2 devices, we get 10 x 512 which becomes be 5 x 2 x 512.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们拿10批次的序列长度为512。如果我们按样本维度将它们并行化为2个设备，我们得到10 x 512，这将变为 5 x 2 x 512。
- en: Operator
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作
- en: If we perform layer normalization, we compute std first and mean second, and
    then we can normalize data. Operator parallelism allows computing std and mean
    in parallel. So if we parallelize them by operator dimension into 2 devices (cuda:0,
    cuda:1), first we copy input data into both devices, and cuda:0 computes std,
    cuda:1 computes mean at the same time.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们执行层归一化，首先计算标准差，然后计算均值，然后我们可以对数据进行归一化。操作并行性允许并行计算标准差和均值。因此，如果我们按操作维度将它们并行化为2个设备（cuda:0，cuda:1），首先将输入数据复制到两个设备中，cuda:0同时计算标准差，cuda:1计算均值。
- en: Attribute
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 属性
- en: We have 10 batches of 512 length. If we parallelize them by attribute dimension
    into 2 devices, 10 x 512 will be 10 x 2 x 256.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有10批次，每个长度为512。如果我们按属性维度将它们并行化为2个设备，10 x 512 将变为 10 x 2 x 256。
- en: Parameter
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数
- en: It is similar with tensor model parallelism or naive layer-wise model parallelism.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这与张量模型并行化或天真的逐层模型并行化类似。
- en: '![flex-flow-soap](../Images/afd0fc78628855e58b9faf6fa5778e42.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![flex-flow-soap](../Images/afd0fc78628855e58b9faf6fa5778e42.png)'
- en: The significance of this framework is that it takes resources like (1) GPU/TPU/CPU
    vs. (2) RAM/DRAM vs. (3) fast-intra-connect/slow-inter-connect and it automatically
    optimizes all these algorithmically deciding which parallelisation to use where.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这个框架的重要性在于，它以算法方式占用资源，如（1）GPU/TPU/CPU vs.（2）RAM/DRAM vs.（3）快速内部连接/慢速外部连接，并自动优化所有这些，决定在哪里使用哪种并行化。
- en: One very important aspect is that FlexFlow is designed for optimizing DNN parallelizations
    for models with static and fixed workloads, since models with dynamic behavior
    may prefer different parallelization strategies across iterations.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常重要的方面是，FlexFlow专为优化具有静态和固定工作负载的DNN并行化而设计，因为具有动态行为的模型可能会在迭代中更喜欢不同的并行化策略。
- en: So the promise is very attractive - it runs a 30min simulation on the cluster
    of choice and it comes up with the best strategy to utilise this specific environment.
    If you add/remove/replace any parts it’ll run and re-optimize the plan for that.
    And then you can train. A different setup will have its own custom optimization.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个承诺非常吸引人 - 它在所选集群上运行30分钟的模拟，并提出了最佳策略来利用这个特定环境。如果添加/删除/替换任何部分，它将运行并重新优化该计划。然后您可以进行训练。不同的设置将有自己的定制优化。
- en: '🤗 Transformers status: Transformers models are FX-trace-able via [transformers.utils.fx](https://github.com/huggingface/transformers/blob/master/src/transformers/utils/fx.py),
    which is a prerequisite for FlexFlow, however, changes are required on the FlexFlow
    side to make it work with Transformers models.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers 状态：Transformers 模型可以通过[transformers.utils.fx](https://github.com/huggingface/transformers/blob/master/src/transformers/utils/fx.py)进行
    FX-trace-able，这是FlexFlow的先决条件，但需要在FlexFlow方面进行更改以使其与Transformers模型配合使用。
- en: GPU selection
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU选择
- en: When training on multiple GPUs, you can specify the number of GPUs to use and
    in what order. This can be useful for instance when you have GPUs with different
    computing power and want to use the faster GPU first. The selection process works
    for both [DistributedDataParallel](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)
    and [DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html)
    to use only a subset of the available GPUs, and you don’t need Accelerate or the
    [DeepSpeed integration](./main_classes/deepspeed).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个GPU上训练时，您可以指定要使用的GPU数量和顺序。例如，当您有计算能力不同的GPU并希望首先使用速度更快的GPU时，这可能很有用。选择过程适用于[DistributedDataParallel](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)和[DataParallel](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html)，以仅使用可用GPU的子集，您不需要Accelerate或[DeepSpeed
    integration](./main_classes/deepspeed)。
- en: Number of GPUs
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPU的数量
- en: 'For example, if you have 4 GPUs and you only want to use the first 2:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您有4个GPU，但只想使用前2个：
- en: torchrunAccelerateDeepSpeed
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: torchrunAccelerateDeepSpeed
- en: Use the `--nproc_per_node` to select how many GPUs to use.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`--nproc_per_node`来选择使用多少个GPU。
- en: '[PRE7]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Order of GPUs
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPU的顺序
- en: 'Now, to select which GPUs to use and their order, you’ll use the `CUDA_VISIBLE_DEVICES`
    environment variable. It is easiest to set the environment variable in a `~/bashrc`
    or another startup config file. `CUDA_VISIBLE_DEVICES` is used to map which GPUs
    are used. For example, if you have 4 GPUs (0, 1, 2, 3) and you only want to run
    GPUs 0 and 2:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要选择要使用的GPU及其顺序，您将使用`CUDA_VISIBLE_DEVICES`环境变量。最简单的方法是在`~/bashrc`或其他启动配置文件中设置环境变量。`CUDA_VISIBLE_DEVICES`用于映射要使用的GPU。例如，如果您有4个GPU（0、1、2、3），但只想运行GPU
    0和 2：
- en: '[PRE8]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Only the 2 physical GPUs (0 and 2) are “visible” to PyTorch and these are mapped
    to `cuda:0` and `cuda:1` respectively. You can also reverse the order of the GPUs
    to use 2 first. Now, the mapping is `cuda:1` for GPU 0 and `cuda:0` for GPU 2.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 只有2个物理GPU（0和2）对PyTorch是“可见的”，它们分别映射到`cuda:0`和`cuda:1`。您还可以颠倒GPU的顺序以先使用2个。现在，映射是GPU
    0为`cuda:1`，GPU 2为`cuda:0`。
- en: '[PRE9]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can also set the `CUDA_VISIBLE_DEVICES` environment variable to an empty
    value to create an environment without GPUs.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将 `CUDA_VISIBLE_DEVICES` 环境变量设置为空值，以创建一个没有 GPU 的环境。
- en: '[PRE10]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As with any environment variable, they can be exported instead of being added
    to the command line. However, this is not recommended because it can be confusing
    if you forget how the environment variable was setup and you end up using the
    wrong GPUs. Instead, it is common practice to set the environment variable for
    a specific training run on the same command line.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何环境变量一样，它们可以被导出，而不是添加到命令行中。然而，这并不推荐，因为如果您忘记了环境变量的设置方式，最终使用了错误的 GPU，会让人感到困惑。相反，通常的做法是在同一命令行上为特定的训练运行设置环境变量。
- en: '`CUDA_DEVICE_ORDER` is an alternative environment variable you can use to control
    how the GPUs are ordered. You can either order them by:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '`CUDA_DEVICE_ORDER` 是一个替代环境变量，您可以使用它来控制 GPU 的顺序。您可以按照以下方式对它们进行排序：'
- en: PCIe bus ID’s that matches the order of [`nvidia-smi`](https://developer.nvidia.com/nvidia-system-management-interface)
    and [`rocm-smi`](https://rocm.docs.amd.com/projects/rocm_smi_lib/en/latest/.doxygen/docBin/html/index.html)
    for NVIDIA and AMD GPUs respectively
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与 [`nvidia-smi`](https://developer.nvidia.com/nvidia-system-management-interface)
    和 [`rocm-smi`](https://rocm.docs.amd.com/projects/rocm_smi_lib/en/latest/.doxygen/docBin/html/index.html)
    分别匹配的 PCIe 总线 ID，用于 NVIDIA 和 AMD GPU
- en: '[PRE11]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: GPU compute ability
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU 计算能力
- en: '[PRE12]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `CUDA_DEVICE_ORDER` is especially useful if your training setup consists
    of an older and newer GPU, where the older GPU appears first, but you cannot physically
    swap the cards to make the newer GPU appear first. In this case, set `CUDA_DEVICE_ORDER=FASTEST_FIRST`
    to always use the newer and faster GPU first (`nvidia-smi` or `rocm-smi` still
    reports the GPUs in their PCIe order). Or you could also set `export CUDA_VISIBLE_DEVICES=1,0`.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的训练设置包括一台较旧和一台较新的 GPU，其中较旧的 GPU 显示在前，但您无法物理交换卡片使较新的 GPU 显示在前，那么 `CUDA_DEVICE_ORDER`
    就特别有用。在这种情况下，设置 `CUDA_DEVICE_ORDER=FASTEST_FIRST`，始终使用较新和更快的 GPU（`nvidia-smi`
    或 `rocm-smi` 仍然按照 PCIe 顺序报告 GPU）。或者您也可以设置 `export CUDA_VISIBLE_DEVICES=1,0`。
