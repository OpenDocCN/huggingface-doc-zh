- en: Intel® Extension for PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Intel® PyTorch扩展
- en: 'Original text: [https://huggingface.co/docs/accelerate/usage_guides/ipex](https://huggingface.co/docs/accelerate/usage_guides/ipex)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/accelerate/usage_guides/ipex](https://huggingface.co/docs/accelerate/usage_guides/ipex)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[IPEX](https://github.com/intel/intel-extension-for-pytorch) is optimized for
    CPUs with AVX-512 or above, and functionally works for CPUs with only AVX2\. So,
    it is expected to bring performance benefit for Intel CPU generations with AVX-512
    or above while CPUs with only AVX2 (e.g., AMD CPUs or older Intel CPUs) might
    result in a better performance under IPEX, but not guaranteed. IPEX provides performance
    optimizations for CPU training with both Float32 and BFloat16\. The usage of BFloat16
    is the main focus of the following sections.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[IPEX](https://github.com/intel/intel-extension-for-pytorch)经过优化，适用于具有AVX-512或更高版本的CPU，并且在仅具有AVX2的CPU上也可以正常运行。因此，预计在具有AVX-512或更高版本的Intel
    CPU代数上会带来性能优势，而仅具有AVX2的CPU（例如AMD CPU或较旧的Intel CPU）在IPEX下可能会获得更好的性能，但不能保证。IPEX为使用Float32和BFloat16进行CPU训练提供了性能优化。以下部分主要关注BFloat16的使用。'
- en: Low precision data type BFloat16 has been natively supported on the 3rd Generation
    Xeon® Scalable Processors (aka Cooper Lake) with AVX512 instruction set and will
    be supported on the next generation of Intel® Xeon® Scalable Processors with Intel®
    Advanced Matrix Extensions (Intel® AMX) instruction set with further boosted performance.
    The Auto Mixed Precision for CPU backend has been enabled since PyTorch-1.10\.
    At the same time, the support of Auto Mixed Precision with BFloat16 for CPU and
    BFloat16 optimization of operators has been massively enabled in Intel® Extension
    for PyTorch, and partially upstreamed to PyTorch master branch. Users can get
    better performance and user experience with IPEX Auto Mixed Precision.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 低精度数据类型BFloat16已经在第三代Xeon® Scalable处理器（也称为Cooper Lake）上本地支持，具有AVX512指令集，并将在下一代Intel®
    Xeon® Scalable处理器上支持，具有Intel® Advanced Matrix Extensions（Intel® AMX）指令集，进一步提高性能。自PyTorch-1.10以来，CPU后端的自动混合精度已经启用。同时，在Intel®
    PyTorch扩展中，已经大规模启用了CPU和BFloat16优化运算符的自动混合精度，并部分上游到PyTorch主分支。用户可以通过IPEX自动混合精度获得更好的性能和用户体验。
- en: 'IPEX installation:'
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IPEX安装：
- en: 'IPEX release is following PyTorch, to install via pip:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: IPEX发布遵循PyTorch版本，可以通过pip进行安装：
- en: '| PyTorch Version | IPEX version |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch版本 | IPEX版本 |'
- en: '| :-: | :-: |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| :-: | :-: |'
- en: '| 2.0 | 2.0.0 |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 2.0 | 2.0.0 |'
- en: '| 1.13 | 1.13.0 |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 1.13 | 1.13.0 |'
- en: '| 1.12 | 1.12.300 |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 1.12 | 1.12.300 |'
- en: '| 1.11 | 1.11.200 |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 1.11 | 1.11.200 |'
- en: '| 1.10 | 1.10.100 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 1.10 | 1.10.100 |'
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Check more approaches for [IPEX installation](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/installation.html).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 查看更多[IPEX安装方法](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/installation.html)。
- en: How It Works For Training optimization in CPU
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CPU训练优化的工作原理
- en: 🤗 Accelerate has integrated [IPEX](https://github.com/intel/intel-extension-for-pytorch),
    all you need to do is enabling it through the config.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Accelerate已经集成了[IPEX](https://github.com/intel/intel-extension-for-pytorch)，您只需要通过配置启用它。
- en: '**Scenario 1**: Acceleration of No distributed CPU training'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**场景1**：无分布式CPU训练加速'
- en: 'Run accelerate config on your machine:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的机器上运行accelerate config：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will generate a config file that will be used automatically to properly
    set the default options when doing
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个配置文件，将自动用于在进行时正确设置默认选项
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For instance, here is how you would run the NLP example `examples/nlp_example.py`
    (from the root of the repo) with IPEX enabled. default_config.yaml that is generated
    after `accelerate config`
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这是如何在启用IPEX的情况下运行NLP示例`examples/nlp_example.py`（从存储库的根目录）的方法。在`accelerate
    config`之后生成的default_config.yaml
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Scenario 2**: Acceleration of distributed CPU training we use Intel oneCCL
    for communication, combined with Intel® MPI library to deliver flexible, efficient,
    scalable cluster messaging on Intel® architecture. you could refer the [here](https://huggingface.co/docs/transformers/perf_train_cpu_many)
    for the installation guide'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**场景2**：分布式CPU训练加速，我们使用Intel oneCCL进行通信，结合Intel® MPI库在Intel®架构上提供灵活、高效、可扩展的集群消息传递。您可以参考[这里](https://huggingface.co/docs/transformers/perf_train_cpu_many)进行安装指南'
- en: 'Run accelerate config on your machine(node0):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的机器上运行accelerate config（node0）：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For instance, here is how you would run the NLP example `examples/nlp_example.py`
    (from the root of the repo) with IPEX enabled for distributed CPU training.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这是如何在启用IPEX的情况下运行NLP示例`examples/nlp_example.py`（从存储库的根目录）进行分布式CPU训练的方法。
- en: default_config.yaml that is generated after `accelerate config`
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在`accelerate config`之后生成的default_config.yaml
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Set following env and using intel MPI to launch the training
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 设置以下环境并使用Intel MPI启动训练
- en: In node0, you need to create a configuration file which contains the IP addresses
    of each node (for example hostfile) and pass that configuration file path as an
    argument.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在node0中，您需要创建一个包含每个节点IP地址的配置文件（例如hostfile），并将该配置文件路径作为参数传递。
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, run the following command in node0 and **16DDP** will be enabled in node0,node1,node2,node3
    with BF16 mixed precision:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在node0中运行以下命令，将在node0、node1、node2、node3中启用**16DDP**，并使用BF16混合精度：
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Related Resources
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关资源
- en: '[Project’s github](https://github.com/intel/intel-extension-for-pytorch)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[项目的github](https://github.com/intel/intel-extension-for-pytorch)'
- en: '[API docs](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/api_doc.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[API文档](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/api_doc.html)'
- en: '[Tuning guide](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/performance_tuning/tuning_guide.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[调优指南](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/performance_tuning/tuning_guide.html)'
- en: '[Blogs & Publications](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/blogs_publications.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[博客和出版物](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/blogs_publications.html)'
