# ä½¿ç”¨ AutoClass åŠ è½½é¢„è®­ç»ƒå®ä¾‹

> åŸæ–‡é“¾æ¥ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial`](https://huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial)

ç”±äºæœ‰è¿™ä¹ˆå¤šä¸åŒçš„ Transformer æ¶æ„ï¼Œä¸ºæ‚¨çš„æ£€æŸ¥ç‚¹åˆ›å»ºä¸€ä¸ªå¯èƒ½æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚ä½œä¸ºğŸ¤— Transformers æ ¸å¿ƒç†å¿µçš„ä¸€éƒ¨åˆ†ï¼Œä½¿åº“æ˜“äºä½¿ç”¨ã€ç®€å•çµæ´»ï¼Œ`AutoClass`ä¼šè‡ªåŠ¨æ¨æ–­å¹¶ä»ç»™å®šçš„æ£€æŸ¥ç‚¹åŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚`from_pretrained()`æ–¹æ³•è®©æ‚¨å¿«é€ŸåŠ è½½ä»»ä½•æ¶æ„çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™æ ·æ‚¨å°±ä¸å¿…èŠ±æ—¶é—´å’Œèµ„æºä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹ã€‚ç”Ÿæˆè¿™ç§ä¸æ£€æŸ¥ç‚¹æ— å…³çš„ä»£ç æ„å‘³ç€ï¼Œå¦‚æœæ‚¨çš„ä»£ç é€‚ç”¨äºä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼Œå®ƒå°†é€‚ç”¨äºå¦ä¸€ä¸ªæ£€æŸ¥ç‚¹ - åªè¦å®ƒæ˜¯ä¸ºç±»ä¼¼ä»»åŠ¡è®­ç»ƒçš„ - å³ä½¿æ¶æ„ä¸åŒã€‚

è¯·è®°ä½ï¼Œæ¶æ„æŒ‡çš„æ˜¯æ¨¡å‹çš„éª¨æ¶ï¼Œæ£€æŸ¥ç‚¹æ˜¯ç»™å®šæ¶æ„çš„æƒé‡ã€‚ä¾‹å¦‚ï¼Œ[BERT](https://huggingface.co/bert-base-uncased)æ˜¯ä¸€ä¸ªæ¶æ„ï¼Œè€Œ`bert-base-uncased`æ˜¯ä¸€ä¸ªæ£€æŸ¥ç‚¹ã€‚æ¨¡å‹æ˜¯ä¸€ä¸ªé€šç”¨æœ¯è¯­ï¼Œå¯ä»¥æŒ‡ä»£æ¶æ„æˆ–æ£€æŸ¥ç‚¹ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œå­¦ä¹ ï¼š

+   åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒåˆ†è¯å™¨ã€‚

+   åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒå›¾åƒå¤„ç†å™¨

+   åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒç‰¹å¾æå–å™¨ã€‚

+   åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒå¤„ç†å™¨ã€‚

+   åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ã€‚

+   åŠ è½½ä¸€ä¸ªä½œä¸ºéª¨å¹²çš„æ¨¡å‹ã€‚

## AutoTokenizer

å‡ ä¹æ¯ä¸ª NLP ä»»åŠ¡éƒ½ä»¥åˆ†è¯å™¨å¼€å§‹ã€‚åˆ†è¯å™¨å°†æ‚¨çš„è¾“å…¥è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„æ ¼å¼ã€‚

ä½¿ç”¨ AutoTokenizer.from_pretrained()åŠ è½½ä¸€ä¸ªåˆ†è¯å™¨ï¼š

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
```

ç„¶åæŒ‰ç…§ä¸‹é¢æ‰€ç¤ºå¯¹æ‚¨çš„è¾“å…¥è¿›è¡Œæ ‡è®°åŒ–ï¼š

```py
>>> sequence = "In a hole in the ground there lived a hobbit."
>>> print(tokenizer(sequence))
{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], 
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

## AutoImageProcessor

å¯¹äºè§†è§‰ä»»åŠ¡ï¼Œå›¾åƒå¤„ç†å™¨å°†å›¾åƒå¤„ç†æˆæ­£ç¡®çš„è¾“å…¥æ ¼å¼ã€‚

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
```

## AutoFeatureExtractor

å¯¹äºéŸ³é¢‘ä»»åŠ¡ï¼Œç‰¹å¾æå–å™¨å°†éŸ³é¢‘ä¿¡å·å¤„ç†æˆæ­£ç¡®çš„è¾“å…¥æ ¼å¼ã€‚

ä½¿ç”¨ AutoFeatureExtractor.from_pretrained()åŠ è½½ä¸€ä¸ªç‰¹å¾æå–å™¨ï¼š

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained(
...     "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
... )
```

## AutoProcessor

å¤šæ¨¡æ€ä»»åŠ¡éœ€è¦ä¸€ä¸ªç»“åˆä¸¤ç§é¢„å¤„ç†å·¥å…·çš„å¤„ç†å™¨ã€‚ä¾‹å¦‚ï¼ŒLayoutLMV2 æ¨¡å‹éœ€è¦ä¸€ä¸ªå›¾åƒå¤„ç†å™¨æ¥å¤„ç†å›¾åƒï¼Œä¸€ä¸ªåˆ†è¯å™¨æ¥å¤„ç†æ–‡æœ¬ï¼›å¤„ç†å™¨å°†ä¸¤è€…ç»“åˆèµ·æ¥ã€‚

ä½¿ç”¨ AutoProcessor.from_pretrained()åŠ è½½ä¸€ä¸ªå¤„ç†å™¨ï¼š

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv2-base-uncased")
```

## AutoModel

PytorchHide Pytorch content

`AutoModelFor`ç±»è®©æ‚¨åŠ è½½ç»™å®šä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆè¯·å‚é˜…æ­¤å¤„ä»¥è·å–å¯ç”¨ä»»åŠ¡çš„å®Œæ•´åˆ—è¡¨ï¼‰ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ AutoModelForSequenceClassification.from_pretrained()åŠ è½½ä¸€ä¸ªç”¨äºåºåˆ—åˆ†ç±»çš„æ¨¡å‹ï¼š

```py
>>> from transformers import AutoModelForSequenceClassification

>>> model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
```

è½»æ¾é‡ç”¨ç›¸åŒçš„æ£€æŸ¥ç‚¹æ¥åŠ è½½ä¸åŒä»»åŠ¡çš„æ¶æ„ï¼š

```py
>>> from transformers import AutoModelForTokenClassification

>>> model = AutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")
```

å¯¹äº PyTorch æ¨¡å‹ï¼Œ`from_pretrained()`æ–¹æ³•ä½¿ç”¨`torch.load()`ï¼Œå†…éƒ¨ä½¿ç”¨`pickle`ï¼Œå·²çŸ¥å­˜åœ¨å®‰å…¨é£é™©ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæ°¸è¿œä¸è¦åŠ è½½å¯èƒ½æ¥è‡ªä¸å—ä¿¡ä»»æ¥æºæˆ–å¯èƒ½è¢«ç¯¡æ”¹çš„æ¨¡å‹ã€‚å¯¹äºåœ¨ Hugging Face Hub ä¸Šæ‰˜ç®¡çš„å…¬å…±æ¨¡å‹ï¼Œè¿™ç§å®‰å…¨é£é™©éƒ¨åˆ†å¾—åˆ°ç¼“è§£ï¼Œè¿™äº›æ¨¡å‹åœ¨æ¯æ¬¡æäº¤æ—¶éƒ½ä¼šè¿›è¡Œ[æ¶æ„è½¯ä»¶æ‰«æ](https://huggingface.co/docs/hub/security-malware)ã€‚æŸ¥çœ‹[Hub æ–‡æ¡£](https://huggingface.co/docs/hub/security)ä»¥è·å–æœ€ä½³å®è·µï¼Œå¦‚ä½¿ç”¨ GPG è¿›è¡Œ[ç­¾åæäº¤éªŒè¯](https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg)ã€‚

TensorFlow å’Œ Flax æ£€æŸ¥ç‚¹ä¸å—å½±å“ï¼Œå¯ä»¥åœ¨ PyTorch æ¶æ„ä¸­ä½¿ç”¨`from_tf`å’Œ`from_flax`å‚æ•°åŠ è½½ï¼Œä»¥ç»•è¿‡æ­¤é—®é¢˜ã€‚

é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨`AutoTokenizer`ç±»å’Œ`AutoModelFor`ç±»æ¥åŠ è½½æ¨¡å‹çš„é¢„è®­ç»ƒå®ä¾‹ã€‚è¿™å°†ç¡®ä¿æ‚¨æ¯æ¬¡åŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚åœ¨ä¸‹ä¸€ä¸ªæ•™ç¨‹ä¸­ï¼Œå­¦ä¹ å¦‚ä½•ä½¿ç”¨æ–°åŠ è½½çš„åˆ†è¯å™¨ã€å›¾åƒå¤„ç†å™¨ã€ç‰¹å¾æå–å™¨å’Œå¤„ç†å™¨æ¥é¢„å¤„ç†æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚

TensorFlow éšè— TensorFlow å†…å®¹

æœ€åï¼Œ`TFAutoModelFor`ç±»è®©æ‚¨åŠ è½½ç»™å®šä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆè¯·å‚é˜…æ­¤å¤„ä»¥è·å–å¯ç”¨ä»»åŠ¡çš„å®Œæ•´åˆ—è¡¨ï¼‰ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ TFAutoModelForSequenceClassification.from_pretrained()åŠ è½½ç”¨äºåºåˆ—åˆ†ç±»çš„æ¨¡å‹ï¼š

```py
>>> from transformers import TFAutoModelForSequenceClassification

>>> model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
```

è½»æ¾åœ°é‡å¤ä½¿ç”¨ç›¸åŒçš„æ£€æŸ¥ç‚¹æ¥åŠ è½½ä¸åŒä»»åŠ¡çš„æ¶æ„ï¼š

```py
>>> from transformers import TFAutoModelForTokenClassification

>>> model = TFAutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")
```

é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨`AutoTokenizer`ç±»å’Œ`TFAutoModelFor`ç±»æ¥åŠ è½½æ¨¡å‹çš„é¢„è®­ç»ƒå®ä¾‹ã€‚è¿™å°†ç¡®ä¿æ‚¨æ¯æ¬¡åŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚åœ¨ä¸‹ä¸€ä¸ªæ•™ç¨‹ä¸­ï¼Œå­¦ä¹ å¦‚ä½•ä½¿ç”¨æ–°åŠ è½½çš„åˆ†è¯å™¨ã€å›¾åƒå¤„ç†å™¨ã€ç‰¹å¾æå–å™¨å’Œå¤„ç†å™¨æ¥é¢„å¤„ç†æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚

## AutoBackbone

`AutoBackbone`å…è®¸æ‚¨å°†é¢„è®­ç»ƒæ¨¡å‹ç”¨ä½œéª¨å¹²ï¼Œå¹¶ä»æ¨¡å‹çš„ä¸åŒé˜¶æ®µè·å¾—ç‰¹å¾å›¾ä½œä¸ºè¾“å‡ºã€‚ä¸‹é¢æ‚¨å¯ä»¥çœ‹åˆ°å¦‚ä½•ä» Swin æ£€æŸ¥ç‚¹è·å–ç‰¹å¾å›¾ã€‚

```py
>>> from transformers import AutoImageProcessor, AutoBackbone
>>> import torch
>>> from PIL import Image
>>> import requests
>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)
>>> processor = AutoImageProcessor.from_pretrained("microsoft/swin-tiny-patch4-window7-224")
>>> model = AutoBackbone.from_pretrained("microsoft/swin-tiny-patch4-window7-224", out_indices=(0,))

>>> inputs = processor(image, return_tensors="pt")
>>> outputs = model(**inputs)
>>> feature_maps = outputs.feature_maps
>>> list(feature_maps[-1].shape)
[1, 96, 56, 56]
```
