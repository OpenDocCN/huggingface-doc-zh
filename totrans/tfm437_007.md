# 使用 AutoClass 加载预训练实例

> 原文链接：[`huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial`](https://huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial)

由于有这么多不同的 Transformer 架构，为您的检查点创建一个可能是具有挑战性的。作为🤗 Transformers 核心理念的一部分，使库易于使用、简单灵活，`AutoClass`会自动推断并从给定的检查点加载正确的架构。`from_pretrained()`方法让您快速加载任何架构的预训练模型，这样您就不必花时间和资源从头开始训练模型。生成这种与检查点无关的代码意味着，如果您的代码适用于一个检查点，它将适用于另一个检查点 - 只要它是为类似任务训练的 - 即使架构不同。

请记住，架构指的是模型的骨架，检查点是给定架构的权重。例如，[BERT](https://huggingface.co/bert-base-uncased)是一个架构，而`bert-base-uncased`是一个检查点。模型是一个通用术语，可以指代架构或检查点。

在本教程中，学习：

+   加载一个预训练分词器。

+   加载一个预训练图像处理器

+   加载一个预训练特征提取器。

+   加载一个预训练处理器。

+   加载一个预训练模型。

+   加载一个作为骨干的模型。

## AutoTokenizer

几乎每个 NLP 任务都以分词器开始。分词器将您的输入转换为模型可以处理的格式。

使用 AutoTokenizer.from_pretrained()加载一个分词器：

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
```

然后按照下面所示对您的输入进行标记化：

```py
>>> sequence = "In a hole in the ground there lived a hobbit."
>>> print(tokenizer(sequence))
{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], 
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

## AutoImageProcessor

对于视觉任务，图像处理器将图像处理成正确的输入格式。

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
```

## AutoFeatureExtractor

对于音频任务，特征提取器将音频信号处理成正确的输入格式。

使用 AutoFeatureExtractor.from_pretrained()加载一个特征提取器：

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained(
...     "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
... )
```

## AutoProcessor

多模态任务需要一个结合两种预处理工具的处理器。例如，LayoutLMV2 模型需要一个图像处理器来处理图像，一个分词器来处理文本；处理器将两者结合起来。

使用 AutoProcessor.from_pretrained()加载一个处理器：

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("microsoft/layoutlmv2-base-uncased")
```

## AutoModel

PytorchHide Pytorch content

`AutoModelFor`类让您加载给定任务的预训练模型（请参阅此处以获取可用任务的完整列表）。例如，使用 AutoModelForSequenceClassification.from_pretrained()加载一个用于序列分类的模型：

```py
>>> from transformers import AutoModelForSequenceClassification

>>> model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
```

轻松重用相同的检查点来加载不同任务的架构：

```py
>>> from transformers import AutoModelForTokenClassification

>>> model = AutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")
```

对于 PyTorch 模型，`from_pretrained()`方法使用`torch.load()`，内部使用`pickle`，已知存在安全风险。一般来说，永远不要加载可能来自不受信任来源或可能被篡改的模型。对于在 Hugging Face Hub 上托管的公共模型，这种安全风险部分得到缓解，这些模型在每次提交时都会进行[恶意软件扫描](https://huggingface.co/docs/hub/security-malware)。查看[Hub 文档](https://huggingface.co/docs/hub/security)以获取最佳实践，如使用 GPG 进行[签名提交验证](https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg)。

TensorFlow 和 Flax 检查点不受影响，可以在 PyTorch 架构中使用`from_tf`和`from_flax`参数加载，以绕过此问题。

通常，我们建议使用`AutoTokenizer`类和`AutoModelFor`类来加载模型的预训练实例。这将确保您每次加载正确的架构。在下一个教程中，学习如何使用新加载的分词器、图像处理器、特征提取器和处理器来预处理数据集进行微调。

TensorFlow 隐藏 TensorFlow 内容

最后，`TFAutoModelFor`类让您加载给定任务的预训练模型（请参阅此处以获取可用任务的完整列表）。例如，使用 TFAutoModelForSequenceClassification.from_pretrained()加载用于序列分类的模型：

```py
>>> from transformers import TFAutoModelForSequenceClassification

>>> model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
```

轻松地重复使用相同的检查点来加载不同任务的架构：

```py
>>> from transformers import TFAutoModelForTokenClassification

>>> model = TFAutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")
```

通常，我们建议使用`AutoTokenizer`类和`TFAutoModelFor`类来加载模型的预训练实例。这将确保您每次加载正确的架构。在下一个教程中，学习如何使用新加载的分词器、图像处理器、特征提取器和处理器来预处理数据集进行微调。

## AutoBackbone

`AutoBackbone`允许您将预训练模型用作骨干，并从模型的不同阶段获得特征图作为输出。下面您可以看到如何从 Swin 检查点获取特征图。

```py
>>> from transformers import AutoImageProcessor, AutoBackbone
>>> import torch
>>> from PIL import Image
>>> import requests
>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)
>>> processor = AutoImageProcessor.from_pretrained("microsoft/swin-tiny-patch4-window7-224")
>>> model = AutoBackbone.from_pretrained("microsoft/swin-tiny-patch4-window7-224", out_indices=(0,))

>>> inputs = processor(image, return_tensors="pt")
>>> outputs = model(**inputs)
>>> feature_maps = outputs.feature_maps
>>> list(feature_maps[-1].shape)
[1, 96, 56, 56]
```
