- en: Philosophy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哲学
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/philosophy](https://huggingface.co/docs/transformers/v4.37.2/en/philosophy)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/philosophy](https://huggingface.co/docs/transformers/v4.37.2/en/philosophy)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '🤗 Transformers is an opinionated library built for:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Transformers是一个为以下人群构建的主观库：
- en: machine learning researchers and educators seeking to use, study or extend large-scale
    Transformers models.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 希望使用、研究或扩展大规模Transformer模型的机器学习研究人员和教育工作者。
- en: hands-on practitioners who want to fine-tune those models or serve them in production,
    or both.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 希望微调这些模型或在生产中使用它们的实践者。
- en: engineers who just want to download a pretrained model and use it to solve a
    given machine learning task.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只想下载预训练模型并用于解决特定机器学习任务的工程师。
- en: 'The library was designed with two strong goals in mind:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 该库设计时有两个强烈的目标：
- en: 'Be as easy and fast to use as possible:'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽可能简单快捷地使用：
- en: 'We strongly limited the number of user-facing abstractions to learn, in fact,
    there are almost no abstractions, just three standard classes required to use
    each model: [configuration](main_classes/configuration), [models](main_classes/model),
    and a preprocessing class ([tokenizer](main_classes/tokenizer) for NLP, [image
    processor](main_classes/image_processor) for vision, [feature extractor](main_classes/feature_extractor)
    for audio, and [processor](main_classes/processors) for multimodal inputs).'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们强烈限制了用户接触的抽象数量，事实上，几乎没有抽象，只需要三个标准类来使用每个模型：[配置](main_classes/configuration)、[模型](main_classes/model)和一个预处理类（NLP的[分词器](main_classes/tokenizer)、视觉的[图像处理器](main_classes/image_processor)、音频的[特征提取器](main_classes/feature_extractor)以及多模态输入的[处理器](main_classes/processors)）。
- en: All of these classes can be initialized in a simple and unified way from pretrained
    instances by using a common `from_pretrained()` method which downloads (if needed),
    caches and loads the related class instance and associated data (configurations’
    hyperparameters, tokenizers’ vocabulary, and models’ weights) from a pretrained
    checkpoint provided on [Hugging Face Hub](https://huggingface.co/models) or your
    own saved checkpoint.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有这些类都可以通过使用通用的`from_pretrained()`方法从预训练实例中简单统一地初始化，该方法会从[Hugging Face Hub](https://huggingface.co/models)提供的预训练检查点或您自己保存的检查点下载（如果需要），缓存并加载相关的类实例和相关数据（配置的超参数、分词器的词汇和模型的权重）。
- en: 'On top of those three base classes, the library provides two APIs: [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for quickly using a model for inference on a given task and [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)
    to quickly train or fine-tune a PyTorch model (all TensorFlow models are compatible
    with `Keras.fit`).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了这三个基本类之外，该库还提供两个API：[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)用于快速在给定任务上使用模型进行推断，以及[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)用于快速训练或微调PyTorch模型（所有TensorFlow模型都兼容`Keras.fit`）。
- en: As a consequence, this library is NOT a modular toolbox of building blocks for
    neural nets. If you want to extend or build upon the library, just use regular
    Python, PyTorch, TensorFlow, Keras modules and inherit from the base classes of
    the library to reuse functionalities like model loading and saving. If you’d like
    to learn more about our coding philosophy for models, check out our [Repeat Yourself](https://huggingface.co/blog/transformers-design-philosophy)
    blog post.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，该库不是神经网络的模块化工具箱。如果您想扩展或构建该库，只需使用常规的Python、PyTorch、TensorFlow、Keras模块，并从库的基类继承以重用模型加载和保存等功能。如果您想了解更多关于我们模型编码哲学的信息，请查看我们的[Repeat
    Yourself](https://huggingface.co/blog/transformers-design-philosophy)博客文章。
- en: 'Provide state-of-the-art models with performances as close as possible to the
    original models:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供性能尽可能接近原始模型的最新模型：
- en: We provide at least one example for each architecture which reproduces a result
    provided by the official authors of said architecture.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们至少为每种架构提供一个示例，该示例重现了该架构的官方作者提供的结果。
- en: The code is usually as close to the original code base as possible which means
    some PyTorch code may be not as *pytorchic* as it could be as a result of being
    converted TensorFlow code and vice versa.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码通常尽可能接近原始代码库，这意味着一些PyTorch代码可能不像*pytorchic*那样，因为它可能是转换为TensorFlow代码，反之亦然。
- en: 'A few other goals:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另外几个目标：
- en: 'Expose the models’ internals as consistently as possible:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽可能一致地暴露模型的内部：
- en: We give access, using a single API, to the full hidden-states and attention
    weights.
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用单个API访问完整的隐藏状态和注意力权重。
- en: The preprocessing classes and base model APIs are standardized to easily switch
    between models.
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理类和基础模型API被标准化，以便轻松在模型之间切换。
- en: 'Incorporate a subjective selection of promising tools for fine-tuning and investigating
    these models:'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整合一组有前途的工具，用于微调和研究这些模型：
- en: A simple and consistent way to add new tokens to the vocabulary and embeddings
    for fine-tuning.
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种简单而一致的方法，用于向词汇表和嵌入中添加新的标记以进行微调。
- en: Simple ways to mask and prune Transformer heads.
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的方法来屏蔽和修剪Transformer头。
- en: Easily switch between PyTorch, TensorFlow 2.0 and Flax, allowing training with
    one framework and inference with another.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轻松在PyTorch、TensorFlow 2.0和Flax之间切换，允许使用一个框架进行训练，使用另一个框架进行推断。
- en: Main concepts
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要概念
- en: 'The library is built around three types of classes for each model:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 该库围绕每个模型的三种类型的类构建：
- en: '**Model classes** can be PyTorch models ([torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)),
    Keras models ([tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model))
    or JAX/Flax models ([flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html))
    that work with the pretrained weights provided in the library.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型类**可以是PyTorch模型（[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)）、Keras模型（[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)）或JAX/Flax模型（[flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)），可以使用库中提供的预训练权重。'
- en: '**Configuration classes** store the hyperparameters required to build a model
    (such as the number of layers and hidden size). You don’t always need to instantiate
    these yourself. In particular, if you are using a pretrained model without any
    modification, creating the model will automatically take care of instantiating
    the configuration (which is part of the model).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**配置类**存储构建模型所需的超参数（例如层数和隐藏大小）。您不总是需要自己实例化这些。特别是，如果您使用预训练模型而没有任何修改，创建模型将自动处理实例化配置（这是模型的一部分）。'
- en: '**Preprocessing classes** convert the raw data into a format accepted by the
    model. A [tokenizer](main_classes/tokenizer) stores the vocabulary for each model
    and provide methods for encoding and decoding strings in a list of token embedding
    indices to be fed to a model. [Image processors](main_classes/image_processor)
    preprocess vision inputs, [feature extractors](main_classes/feature_extractor)
    preprocess audio inputs, and a [processor](main_classes/processors) handles multimodal
    inputs.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预处理类**将原始数据转换为模型接受的格式。一个[tokenizer](main_classes/tokenizer)存储每个模型的词汇表，并提供编码和解码字符串的方法，以便将其转换为要馈送给模型的标记嵌入索引列表。[图像处理器](main_classes/image_processor)预处理视觉输入，[特征提取器](main_classes/feature_extractor)预处理音频输入，以及一个[处理器](main_classes/processors)处理多模态输入。'
- en: 'All these classes can be instantiated from pretrained instances, saved locally,
    and shared on the Hub with three methods:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些类都可以从预训练实例实例化，保存在本地，并通过三种方法在Hub上共享：
- en: '`from_pretrained()` lets you instantiate a model, configuration, and preprocessing
    class from a pretrained version either provided by the library itself (the supported
    models can be found on the [Model Hub](https://huggingface.co/models)) or stored
    locally (or on a server) by the user.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pretrained()`允许您从库本身提供的预训练版本（支持的模型可以在[Model Hub](https://huggingface.co/models)上找到）或用户本地（或服务器上）存储的模型、配置和预处理类实例化。'
- en: '`save_pretrained()` lets you save a model, configuration, and preprocessing
    class locally so that it can be reloaded using `from_pretrained()`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_pretrained()`允许您将模型、配置和预处理类保存在本地，以便可以使用`from_pretrained()`重新加载。'
- en: '`push_to_hub()` lets you share a model, configuration, and a preprocessing
    class to the Hub, so it is easily accessible to everyone.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub()`允许您将模型、配置和预处理类共享到Hub，以便所有人都可以轻松访问。'
