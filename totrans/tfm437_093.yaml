- en: Philosophy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å“²å­¦
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/philosophy](https://huggingface.co/docs/transformers/v4.37.2/en/philosophy)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/philosophy](https://huggingface.co/docs/transformers/v4.37.2/en/philosophy)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'ğŸ¤— Transformers is an opinionated library built for:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Transformersæ˜¯ä¸€ä¸ªä¸ºä»¥ä¸‹äººç¾¤æ„å»ºçš„ä¸»è§‚åº“ï¼š
- en: machine learning researchers and educators seeking to use, study or extend large-scale
    Transformers models.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½¿ç”¨ã€ç ”ç©¶æˆ–æ‰©å±•å¤§è§„æ¨¡Transformeræ¨¡å‹çš„æœºå™¨å­¦ä¹ ç ”ç©¶äººå‘˜å’Œæ•™è‚²å·¥ä½œè€…ã€‚
- en: hands-on practitioners who want to fine-tune those models or serve them in production,
    or both.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¸Œæœ›å¾®è°ƒè¿™äº›æ¨¡å‹æˆ–åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨å®ƒä»¬çš„å®è·µè€…ã€‚
- en: engineers who just want to download a pretrained model and use it to solve a
    given machine learning task.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åªæƒ³ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶ç”¨äºè§£å†³ç‰¹å®šæœºå™¨å­¦ä¹ ä»»åŠ¡çš„å·¥ç¨‹å¸ˆã€‚
- en: 'The library was designed with two strong goals in mind:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥åº“è®¾è®¡æ—¶æœ‰ä¸¤ä¸ªå¼ºçƒˆçš„ç›®æ ‡ï¼š
- en: 'Be as easy and fast to use as possible:'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°½å¯èƒ½ç®€å•å¿«æ·åœ°ä½¿ç”¨ï¼š
- en: 'We strongly limited the number of user-facing abstractions to learn, in fact,
    there are almost no abstractions, just three standard classes required to use
    each model: [configuration](main_classes/configuration), [models](main_classes/model),
    and a preprocessing class ([tokenizer](main_classes/tokenizer) for NLP, [image
    processor](main_classes/image_processor) for vision, [feature extractor](main_classes/feature_extractor)
    for audio, and [processor](main_classes/processors) for multimodal inputs).'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼ºçƒˆé™åˆ¶äº†ç”¨æˆ·æ¥è§¦çš„æŠ½è±¡æ•°é‡ï¼Œäº‹å®ä¸Šï¼Œå‡ ä¹æ²¡æœ‰æŠ½è±¡ï¼Œåªéœ€è¦ä¸‰ä¸ªæ ‡å‡†ç±»æ¥ä½¿ç”¨æ¯ä¸ªæ¨¡å‹ï¼š[é…ç½®](main_classes/configuration)ã€[æ¨¡å‹](main_classes/model)å’Œä¸€ä¸ªé¢„å¤„ç†ç±»ï¼ˆNLPçš„[åˆ†è¯å™¨](main_classes/tokenizer)ã€è§†è§‰çš„[å›¾åƒå¤„ç†å™¨](main_classes/image_processor)ã€éŸ³é¢‘çš„[ç‰¹å¾æå–å™¨](main_classes/feature_extractor)ä»¥åŠå¤šæ¨¡æ€è¾“å…¥çš„[å¤„ç†å™¨](main_classes/processors)ï¼‰ã€‚
- en: All of these classes can be initialized in a simple and unified way from pretrained
    instances by using a common `from_pretrained()` method which downloads (if needed),
    caches and loads the related class instance and associated data (configurationsâ€™
    hyperparameters, tokenizersâ€™ vocabulary, and modelsâ€™ weights) from a pretrained
    checkpoint provided on [Hugging Face Hub](https://huggingface.co/models) or your
    own saved checkpoint.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è¿™äº›ç±»éƒ½å¯ä»¥é€šè¿‡ä½¿ç”¨é€šç”¨çš„`from_pretrained()`æ–¹æ³•ä»é¢„è®­ç»ƒå®ä¾‹ä¸­ç®€å•ç»Ÿä¸€åœ°åˆå§‹åŒ–ï¼Œè¯¥æ–¹æ³•ä¼šä»[Hugging Face Hub](https://huggingface.co/models)æä¾›çš„é¢„è®­ç»ƒæ£€æŸ¥ç‚¹æˆ–æ‚¨è‡ªå·±ä¿å­˜çš„æ£€æŸ¥ç‚¹ä¸‹è½½ï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼Œç¼“å­˜å¹¶åŠ è½½ç›¸å…³çš„ç±»å®ä¾‹å’Œç›¸å…³æ•°æ®ï¼ˆé…ç½®çš„è¶…å‚æ•°ã€åˆ†è¯å™¨çš„è¯æ±‡å’Œæ¨¡å‹çš„æƒé‡ï¼‰ã€‚
- en: 'On top of those three base classes, the library provides two APIs: [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)
    for quickly using a model for inference on a given task and [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)
    to quickly train or fine-tune a PyTorch model (all TensorFlow models are compatible
    with `Keras.fit`).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤äº†è¿™ä¸‰ä¸ªåŸºæœ¬ç±»ä¹‹å¤–ï¼Œè¯¥åº“è¿˜æä¾›ä¸¤ä¸ªAPIï¼š[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)ç”¨äºå¿«é€Ÿåœ¨ç»™å®šä»»åŠ¡ä¸Šä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼Œä»¥åŠ[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ç”¨äºå¿«é€Ÿè®­ç»ƒæˆ–å¾®è°ƒPyTorchæ¨¡å‹ï¼ˆæ‰€æœ‰TensorFlowæ¨¡å‹éƒ½å…¼å®¹`Keras.fit`ï¼‰ã€‚
- en: As a consequence, this library is NOT a modular toolbox of building blocks for
    neural nets. If you want to extend or build upon the library, just use regular
    Python, PyTorch, TensorFlow, Keras modules and inherit from the base classes of
    the library to reuse functionalities like model loading and saving. If youâ€™d like
    to learn more about our coding philosophy for models, check out our [Repeat Yourself](https://huggingface.co/blog/transformers-design-philosophy)
    blog post.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè¯¥åº“ä¸æ˜¯ç¥ç»ç½‘ç»œçš„æ¨¡å—åŒ–å·¥å…·ç®±ã€‚å¦‚æœæ‚¨æƒ³æ‰©å±•æˆ–æ„å»ºè¯¥åº“ï¼Œåªéœ€ä½¿ç”¨å¸¸è§„çš„Pythonã€PyTorchã€TensorFlowã€Kerasæ¨¡å—ï¼Œå¹¶ä»åº“çš„åŸºç±»ç»§æ‰¿ä»¥é‡ç”¨æ¨¡å‹åŠ è½½å’Œä¿å­˜ç­‰åŠŸèƒ½ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äºæˆ‘ä»¬æ¨¡å‹ç¼–ç å“²å­¦çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„[Repeat
    Yourself](https://huggingface.co/blog/transformers-design-philosophy)åšå®¢æ–‡ç« ã€‚
- en: 'Provide state-of-the-art models with performances as close as possible to the
    original models:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æä¾›æ€§èƒ½å°½å¯èƒ½æ¥è¿‘åŸå§‹æ¨¡å‹çš„æœ€æ–°æ¨¡å‹ï¼š
- en: We provide at least one example for each architecture which reproduces a result
    provided by the official authors of said architecture.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è‡³å°‘ä¸ºæ¯ç§æ¶æ„æä¾›ä¸€ä¸ªç¤ºä¾‹ï¼Œè¯¥ç¤ºä¾‹é‡ç°äº†è¯¥æ¶æ„çš„å®˜æ–¹ä½œè€…æä¾›çš„ç»“æœã€‚
- en: The code is usually as close to the original code base as possible which means
    some PyTorch code may be not as *pytorchic* as it could be as a result of being
    converted TensorFlow code and vice versa.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»£ç é€šå¸¸å°½å¯èƒ½æ¥è¿‘åŸå§‹ä»£ç åº“ï¼Œè¿™æ„å‘³ç€ä¸€äº›PyTorchä»£ç å¯èƒ½ä¸åƒ*pytorchic*é‚£æ ·ï¼Œå› ä¸ºå®ƒå¯èƒ½æ˜¯è½¬æ¢ä¸ºTensorFlowä»£ç ï¼Œåä¹‹äº¦ç„¶ã€‚
- en: 'A few other goals:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å¦å¤–å‡ ä¸ªç›®æ ‡ï¼š
- en: 'Expose the modelsâ€™ internals as consistently as possible:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°½å¯èƒ½ä¸€è‡´åœ°æš´éœ²æ¨¡å‹çš„å†…éƒ¨ï¼š
- en: We give access, using a single API, to the full hidden-states and attention
    weights.
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨å•ä¸ªAPIè®¿é—®å®Œæ•´çš„éšè—çŠ¶æ€å’Œæ³¨æ„åŠ›æƒé‡ã€‚
- en: The preprocessing classes and base model APIs are standardized to easily switch
    between models.
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„å¤„ç†ç±»å’ŒåŸºç¡€æ¨¡å‹APIè¢«æ ‡å‡†åŒ–ï¼Œä»¥ä¾¿è½»æ¾åœ¨æ¨¡å‹ä¹‹é—´åˆ‡æ¢ã€‚
- en: 'Incorporate a subjective selection of promising tools for fine-tuning and investigating
    these models:'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•´åˆä¸€ç»„æœ‰å‰é€”çš„å·¥å…·ï¼Œç”¨äºå¾®è°ƒå’Œç ”ç©¶è¿™äº›æ¨¡å‹ï¼š
- en: A simple and consistent way to add new tokens to the vocabulary and embeddings
    for fine-tuning.
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ç§ç®€å•è€Œä¸€è‡´çš„æ–¹æ³•ï¼Œç”¨äºå‘è¯æ±‡è¡¨å’ŒåµŒå…¥ä¸­æ·»åŠ æ–°çš„æ ‡è®°ä»¥è¿›è¡Œå¾®è°ƒã€‚
- en: Simple ways to mask and prune Transformer heads.
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç®€å•çš„æ–¹æ³•æ¥å±è”½å’Œä¿®å‰ªTransformerå¤´ã€‚
- en: Easily switch between PyTorch, TensorFlow 2.0 and Flax, allowing training with
    one framework and inference with another.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è½»æ¾åœ¨PyTorchã€TensorFlow 2.0å’ŒFlaxä¹‹é—´åˆ‡æ¢ï¼Œå…è®¸ä½¿ç”¨ä¸€ä¸ªæ¡†æ¶è¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨å¦ä¸€ä¸ªæ¡†æ¶è¿›è¡Œæ¨æ–­ã€‚
- en: Main concepts
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸»è¦æ¦‚å¿µ
- en: 'The library is built around three types of classes for each model:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥åº“å›´ç»•æ¯ä¸ªæ¨¡å‹çš„ä¸‰ç§ç±»å‹çš„ç±»æ„å»ºï¼š
- en: '**Model classes** can be PyTorch models ([torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)),
    Keras models ([tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model))
    or JAX/Flax models ([flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html))
    that work with the pretrained weights provided in the library.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹ç±»**å¯ä»¥æ˜¯PyTorchæ¨¡å‹ï¼ˆ[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)ï¼‰ã€Kerasæ¨¡å‹ï¼ˆ[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)ï¼‰æˆ–JAX/Flaxæ¨¡å‹ï¼ˆ[flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨åº“ä¸­æä¾›çš„é¢„è®­ç»ƒæƒé‡ã€‚'
- en: '**Configuration classes** store the hyperparameters required to build a model
    (such as the number of layers and hidden size). You donâ€™t always need to instantiate
    these yourself. In particular, if you are using a pretrained model without any
    modification, creating the model will automatically take care of instantiating
    the configuration (which is part of the model).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é…ç½®ç±»**å­˜å‚¨æ„å»ºæ¨¡å‹æ‰€éœ€çš„è¶…å‚æ•°ï¼ˆä¾‹å¦‚å±‚æ•°å’Œéšè—å¤§å°ï¼‰ã€‚æ‚¨ä¸æ€»æ˜¯éœ€è¦è‡ªå·±å®ä¾‹åŒ–è¿™äº›ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¦‚æœæ‚¨ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è€Œæ²¡æœ‰ä»»ä½•ä¿®æ”¹ï¼Œåˆ›å»ºæ¨¡å‹å°†è‡ªåŠ¨å¤„ç†å®ä¾‹åŒ–é…ç½®ï¼ˆè¿™æ˜¯æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼‰ã€‚'
- en: '**Preprocessing classes** convert the raw data into a format accepted by the
    model. A [tokenizer](main_classes/tokenizer) stores the vocabulary for each model
    and provide methods for encoding and decoding strings in a list of token embedding
    indices to be fed to a model. [Image processors](main_classes/image_processor)
    preprocess vision inputs, [feature extractors](main_classes/feature_extractor)
    preprocess audio inputs, and a [processor](main_classes/processors) handles multimodal
    inputs.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é¢„å¤„ç†ç±»**å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹æ¥å—çš„æ ¼å¼ã€‚ä¸€ä¸ª[tokenizer](main_classes/tokenizer)å­˜å‚¨æ¯ä¸ªæ¨¡å‹çš„è¯æ±‡è¡¨ï¼Œå¹¶æä¾›ç¼–ç å’Œè§£ç å­—ç¬¦ä¸²çš„æ–¹æ³•ï¼Œä»¥ä¾¿å°†å…¶è½¬æ¢ä¸ºè¦é¦ˆé€ç»™æ¨¡å‹çš„æ ‡è®°åµŒå…¥ç´¢å¼•åˆ—è¡¨ã€‚[å›¾åƒå¤„ç†å™¨](main_classes/image_processor)é¢„å¤„ç†è§†è§‰è¾“å…¥ï¼Œ[ç‰¹å¾æå–å™¨](main_classes/feature_extractor)é¢„å¤„ç†éŸ³é¢‘è¾“å…¥ï¼Œä»¥åŠä¸€ä¸ª[å¤„ç†å™¨](main_classes/processors)å¤„ç†å¤šæ¨¡æ€è¾“å…¥ã€‚'
- en: 'All these classes can be instantiated from pretrained instances, saved locally,
    and shared on the Hub with three methods:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è¿™äº›ç±»éƒ½å¯ä»¥ä»é¢„è®­ç»ƒå®ä¾‹å®ä¾‹åŒ–ï¼Œä¿å­˜åœ¨æœ¬åœ°ï¼Œå¹¶é€šè¿‡ä¸‰ç§æ–¹æ³•åœ¨Hubä¸Šå…±äº«ï¼š
- en: '`from_pretrained()` lets you instantiate a model, configuration, and preprocessing
    class from a pretrained version either provided by the library itself (the supported
    models can be found on the [Model Hub](https://huggingface.co/models)) or stored
    locally (or on a server) by the user.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pretrained()`å…è®¸æ‚¨ä»åº“æœ¬èº«æä¾›çš„é¢„è®­ç»ƒç‰ˆæœ¬ï¼ˆæ”¯æŒçš„æ¨¡å‹å¯ä»¥åœ¨[Model Hub](https://huggingface.co/models)ä¸Šæ‰¾åˆ°ï¼‰æˆ–ç”¨æˆ·æœ¬åœ°ï¼ˆæˆ–æœåŠ¡å™¨ä¸Šï¼‰å­˜å‚¨çš„æ¨¡å‹ã€é…ç½®å’Œé¢„å¤„ç†ç±»å®ä¾‹åŒ–ã€‚'
- en: '`save_pretrained()` lets you save a model, configuration, and preprocessing
    class locally so that it can be reloaded using `from_pretrained()`.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_pretrained()`å…è®¸æ‚¨å°†æ¨¡å‹ã€é…ç½®å’Œé¢„å¤„ç†ç±»ä¿å­˜åœ¨æœ¬åœ°ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨`from_pretrained()`é‡æ–°åŠ è½½ã€‚'
- en: '`push_to_hub()` lets you share a model, configuration, and a preprocessing
    class to the Hub, so it is easily accessible to everyone.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub()`å…è®¸æ‚¨å°†æ¨¡å‹ã€é…ç½®å’Œé¢„å¤„ç†ç±»å…±äº«åˆ°Hubï¼Œä»¥ä¾¿æ‰€æœ‰äººéƒ½å¯ä»¥è½»æ¾è®¿é—®ã€‚'
