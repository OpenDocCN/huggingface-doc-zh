["```py\n\nfrom transformers import pipeline, AutoTokenizer\nfrom trl import AutoModelForCausalLMWithValueHead\nfrom trl.core import LengthSampler\nfrom trl.extras import BestOfNSampler\n\nref_model = AutoModelForCausalLMWithValueHead.from_pretrained(ref_model_name)\nreward_pipe = pipeline(\"sentiment-analysis\", model=reward_model, device=device)\ntokenizer = AutoTokenizer.from_pretrained(ref_model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n# callable that takes a list of raw text and returns a list of corresponding reward scores\ndef queries_to_scores(list_of_strings):\n  return [output[\"score\"] for output in reward_pipe(list_of_strings)]\n\nbest_of_n = BestOfNSampler(model, tokenizer, queries_to_scores, length_sampler=output_length_sampler)\n\n```", "```py\n\nbest_of_n.generate(query_tensors, device=device, **gen_kwargs)\n\n```", "```py\n\nbest_of_n = BestOfNSampler(model, tokenizer, queries_to_scores, length_sampler=output_length_sampler, sample_size=8)\n\n```", "```py\n\nbest_of_n = BestOfNSampler(model, tokenizer, queries_to_scores, length_sampler=output_length_sampler, n_candidates=2)\n\n```", "```py\n\nfrom transformers import GenerationConfig\n\ngeneration_config = GenerationConfig(min_length= -1, top_k=0.0, top_p= 1.0, do_sample= True, pad_token_id=tokenizer.eos_token_id)\n\nbest_of_n = BestOfNSampler(model, tokenizer, queries_to_scores, length_sampler=output_length_sampler, generation_config=generation_config)\n\nbest_of_n.generate(query_tensors, device=device)\n\n```"]