- en: REALM
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: REALM
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/realm](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/realm)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/realm](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/realm)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The REALM model was proposed in [REALM: Retrieval-Augmented Language Model
    Pre-Training](https://arxiv.org/abs/2002.08909) by Kelvin Guu, Kenton Lee, Zora
    Tung, Panupong Pasupat and Ming-Wei Chang. It’s a retrieval-augmented language
    model that firstly retrieves documents from a textual knowledge corpus and then
    utilizes retrieved documents to process question answering tasks.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'REALM模型是由Kelvin Guu、Kenton Lee、Zora Tung、Panupong Pasupat和Ming-Wei Chang在[REALM:
    Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909)中提出的。这是一个检索增强语言模型，首先从文本知识语料库中检索文档，然后利用检索到的文档来处理问答任务。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的摘要如下：
- en: '*Language model pre-training has been shown to capture a surprising amount
    of world knowledge, crucial for NLP tasks such as question answering. However,
    this knowledge is stored implicitly in the parameters of a neural network, requiring
    ever-larger networks to cover more facts. To capture knowledge in a more modular
    and interpretable way, we augment language model pre-training with a latent knowledge
    retriever, which allows the model to retrieve and attend over documents from a
    large corpus such as Wikipedia, used during pre-training, fine-tuning and inference.
    For the first time, we show how to pre-train such a knowledge retriever in an
    unsupervised manner, using masked language modeling as the learning signal and
    backpropagating through a retrieval step that considers millions of documents.
    We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training
    (REALM) by fine-tuning on the challenging task of Open-domain Question Answering
    (Open-QA). We compare against state-of-the-art models for both explicit and implicit
    knowledge storage on three popular Open-QA benchmarks, and find that we outperform
    all previous methods by a significant margin (4-16% absolute accuracy), while
    also providing qualitative benefits such as interpretability and modularity.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*语言模型预训练已被证明可以捕获大量世界知识，对于诸如问答等NLP任务至关重要。然而，这些知识隐式存储在神经网络的参数中，需要越来越大的网络来涵盖更多事实。为了以更模块化和可解释的方式捕获知识，我们通过潜在知识检索器增强了语言模型预训练，使模型能够从大型语料库（如维基百科）中检索和关注文档，这些文档在预训练、微调和推理过程中使用。我们首次展示了如何以无监督方式预训练这样一个知识检索器，使用掩码语言建模作为学习信号，并通过考虑数百万文档的检索步骤进行反向传播。我们通过在具有挑战性的开放域问答（Open-QA）任务上微调来展示检索增强语言模型预训练（REALM）的有效性。我们在三个流行的开放域问答基准上与最先进的显式和隐式知识存储模型进行比较，发现我们在绝对准确率上表现优异（4-16%），同时还提供了诸如可解释性和模块化等质量优势。*'
- en: This model was contributed by [qqaatw](https://huggingface.co/qqaatw). The original
    code can be found [here](https://github.com/google-research/language/tree/master/language/realm).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[qqaatw](https://huggingface.co/qqaatw)贡献。原始代码可在[此处](https://github.com/google-research/language/tree/master/language/realm)找到。
- en: RealmConfig
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RealmConfig
- en: '### `class transformers.RealmConfig`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RealmConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/configuration_realm.py#L44)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/configuration_realm.py#L44)'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 30522) — Vocabulary size of the
    REALM model. Defines the number of different tokens that can be represented by
    the `inputs_ids` passed when calling [RealmEmbedder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmEmbedder),
    [RealmScorer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmScorer),
    [RealmKnowledgeAugEncoder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmKnowledgeAugEncoder),
    or [RealmReader](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmReader).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, 默认为30522) — REALM模型的词汇量。定义了在调用[RealmEmbedder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmEmbedder)、[RealmScorer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmScorer)、[RealmKnowledgeAugEncoder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmKnowledgeAugEncoder)或[RealmReader](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmReader)时可以表示的不同标记数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimension of the encoder
    layers and the pooler layer.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, 默认为768) — 编码器层和池化器层的维度。'
- en: '`retriever_proj_size` (`int`, *optional*, defaults to 128) — Dimension of the
    retriever(embedder) projection.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`retriever_proj_size` (`int`, *optional*, 默认为128) — 检索器（嵌入器）投影的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, 默认为12) — Transformer编码器中的隐藏层数量。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, 默认为12) — Transformer编码器中每个注意力层的注意力头数。'
- en: '`num_candidates` (`int`, *optional*, defaults to 8) — Number of candidates
    inputted to the RealmScorer or RealmKnowledgeAugEncoder.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_candidates` (`int`, *optional*, 默认为8) — 输入到RealmScorer或RealmKnowledgeAugEncoder的候选项数量。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimension of the
    “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, 默认为3072) — Transformer编码器中“中间”（即前馈）层的维度。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu_new"`) —
    The non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str`或`function`, *optional*, 默认为`"gelu_new"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`和`"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, 默认为0.1) — 嵌入层、编码器和池化器中所有全连接层的丢失概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — The
    dropout ratio for the attention probabilities.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — 注意力概率的丢弃比率。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — 此模型可能使用的最大序列长度。通常将其设置为较大的值以防万一（例如，512或1024或2048）。'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) — The vocabulary size
    of the `token_type_ids` passed when calling [RealmEmbedder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmEmbedder),
    [RealmScorer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmScorer),
    [RealmKnowledgeAugEncoder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmKnowledgeAugEncoder),
    or [RealmReader](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmReader).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size` (`int`, *optional*, defaults to 2) — 在调用[RealmEmbedder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmEmbedder)、[RealmScorer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmScorer)、[RealmKnowledgeAugEncoder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmKnowledgeAugEncoder)或[RealmReader](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmReader)时传递的`token_type_ids`的词汇表大小。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — 层归一化层使用的epsilon。'
- en: '`span_hidden_size` (`int`, *optional*, defaults to 256) — Dimension of the
    reader’s spans.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`span_hidden_size` (`int`, *optional*, defaults to 256) — 读者跨度的维度。'
- en: '`max_span_width` (`int`, *optional*, defaults to 10) — Max span width of the
    reader.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_span_width` (`int`, *optional*, defaults to 10) — 读者的最大跨度宽度。'
- en: '`reader_layer_norm_eps` (`float`, *optional*, defaults to 1e-3) — The epsilon
    used by the reader’s layer normalization layers.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reader_layer_norm_eps` (`float`, *optional*, defaults to 1e-3) — 读者的层归一化层使用的epsilon。'
- en: '`reader_beam_size` (`int`, *optional*, defaults to 5) — Beam size of the reader.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reader_beam_size` (`int`, *optional*, defaults to 5) — 读者的波束大小。'
- en: '`reader_seq_len` (`int`, *optional*, defaults to 288+32) — Maximum sequence
    length of the reader.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reader_seq_len` (`int`, *optional*, defaults to 288+32) — 读者的最大序列长度。'
- en: '`num_block_records` (`int`, *optional*, defaults to 13353718) — Number of block
    records.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_block_records` (`int`, *optional*, defaults to 13353718) — 区块记录的数量。'
- en: '`searcher_beam_size` (`int`, *optional*, defaults to 5000) — Beam size of the
    searcher. Note that when eval mode is enabled, *searcher_beam_size* will be the
    same as *reader_beam_size*.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`searcher_beam_size` (`int`, *optional*, defaults to 5000) — 搜索器的波束大小。请注意，当启用评估模式时，*searcher_beam_size*将与*reader_beam_size*相同。'
- en: This is the configuration class to store the configuration of
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储配置的配置类
- en: '[RealmEmbedder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmEmbedder)'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[RealmEmbedder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmEmbedder)'
- en: '[RealmScorer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmScorer)'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[RealmScorer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmScorer)'
- en: '[RealmKnowledgeAugEncoder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmKnowledgeAugEncoder)'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[RealmKnowledgeAugEncoder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmKnowledgeAugEncoder)'
- en: '[RealmRetriever](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmRetriever)'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[RealmRetriever](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmRetriever)'
- en: '[RealmReader](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmReader)'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[RealmReader](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmReader)'
- en: '[RealmForOpenQA](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmForOpenQA)'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[RealmForOpenQA](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmForOpenQA)'
- en: It is used to instantiate an REALM model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the REALM [google/realm-cc-news-pretrained-embedder](https://huggingface.co/google/realm-cc-news-pretrained-embedder)
    architecture.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 它用于根据指定的参数实例化一个REALM模型，定义模型架构。使用默认值实例化配置将产生类似于REALM [google/realm-cc-news-pretrained-embedder](https://huggingface.co/google/realm-cc-news-pretrained-embedder)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读来自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: RealmTokenizer
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RealmTokenizer
- en: '### `class transformers.RealmTokenizer`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RealmTokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm.py#L95)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm.py#L95)'
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — File containing the vocabulary.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 包含词汇表的文件。'
- en: '`do_lower_case` (`bool`, *optional*, defaults to `True`) — Whether or not to
    lowercase the input when tokenizing.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_lower_case` (`bool`, *optional*, defaults to `True`) — 在标记化时是否将输入转换为小写。'
- en: '`do_basic_tokenize` (`bool`, *optional*, defaults to `True`) — Whether or not
    to do basic tokenization before WordPiece.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_basic_tokenize` (`bool`, *optional*, defaults to `True`) — 在WordPiece之前是否进行基本标记化。'
- en: '`never_split` (`Iterable`, *optional*) — Collection of tokens which will never
    be split during tokenization. Only has an effect when `do_basic_tokenize=True`'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`never_split` (`Iterable`, *optional*) — 在标记化过程中永远不会拆分的标记集合。仅在`do_basic_tokenize=True`时有效'
- en: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) — 未知标记。词汇表中没有的标记无法转换为ID，而是设置为此标记。'
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) — Whether
    or not to tokenize Chinese characters.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This should likely be deactivated for Japanese (see this [issue](https://github.com/huggingface/transformers/issues/328)).
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`strip_accents` (`bool`, *optional*) — Whether or not to strip all accents.
    If this option is not specified, then it will be determined by the value for `lowercase`
    (as in the original BERT).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Construct a REALM tokenizer.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[RealmTokenizer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizer)
    is identical to [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    and runs end-to-end tokenization: punctuation splitting and wordpiece.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm.py#L300)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs to which the special tokens will
    be added.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. A REALM sequence has the following
    format:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'single sequence: `[CLS] X [SEP]`'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'pair of sequences: `[CLS] A [SEP] B [SEP]`'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `get_special_tokens_mask`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm.py#L325)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm.py#L353)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: List of [token type IDs](../glossary#token-type-ids) according to the given
    sequence(s).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. A REALM sequence
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'pair mask has the following format:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If `token_ids_1` is `None`, this method only returns the first portion of the
    mask (0s).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '#### `save_vocabulary`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm.py#L382)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#### `batch_encode_candidates`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm.py#L227)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '`text` (`List[List[str]]`) — The batch of sequences to be encoded. Each sequence
    must be in this format: (batch_size, num_candidates, text).'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_pair` (`List[List[str]]`, *optional*) — The batch of sequences to be
    encoded. Each sequence must be in this format: (batch_size, num_candidates, text).
    **kwargs — Keyword arguments of the **call** method.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Encoded text or text pair.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'Encode a batch of text or text pair. This method is similar to regular **call**
    method but has the following differences:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Handle additional num_candidate axis. (batch_size, num_candidates, text)
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Always pad the sequences to *max_length*.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Must specify *max_length* in order to stack packs of candidates into a batch.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'single sequence: `[CLS] X [SEP]`'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'pair of sequences: `[CLS] A [SEP] B [SEP]`'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: RealmTokenizerFast
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.RealmTokenizerFast`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm_fast.py#L102)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab_file` (`str`) — File containing the vocabulary.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_lower_case` (`bool`, *optional*, defaults to `True`) — Whether or not to
    lowercase the input when tokenizing.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clean_text` (`bool`, *optional*, defaults to `True`) — Whether or not to clean
    the text before tokenization by removing any control characters and replacing
    all whitespaces by the classic one.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenize_chinese_chars` (`bool`, *optional*, defaults to `True`) — Whether
    or not to tokenize Chinese characters. This should likely be deactivated for Japanese
    (see [this issue](https://github.com/huggingface/transformers/issues/328)).'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strip_accents` (`bool`, *optional*) — Whether or not to strip all accents.
    If this option is not specified, then it will be determined by the value for `lowercase`
    (as in the original BERT).'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`wordpieces_prefix` (`str`, *optional*, defaults to `"##"`) — The prefix for
    subwords.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Construct a “fast” REALM tokenizer (backed by HuggingFace’s *tokenizers* library).
    Based on WordPiece.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[RealmTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizerFast)
    is identical to [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    and runs end-to-end tokenization: punctuation splitting and wordpiece.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此分词器继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)，其中包含大部分主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '#### `batch_encode_candidates`'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_encode_candidates`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm_fast.py#L193)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/tokenization_realm_fast.py#L193)'
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`List[List[str]]`) — The batch of sequences to be encoded. Each sequence
    must be in this format: (batch_size, num_candidates, text).'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`List[List[str]]`) — 要编码的序列批次。每个序列必须采用以下格式：(batch_size, num_candidates,
    text)。'
- en: '`text_pair` (`List[List[str]]`, *optional*) — The batch of sequences to be
    encoded. Each sequence must be in this format: (batch_size, num_candidates, text).
    **kwargs — Keyword arguments of the **call** method.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair` (`List[List[str]]`, *可选*) — 要编码的序列批次。每个序列必须采用以下格式：(batch_size,
    num_candidates, text)。**kwargs — **call**方法的关键字参数。'
- en: Returns
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[BatchEncoding](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.BatchEncoding)'
- en: Encoded text or text pair.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 编码的文本或文本对。
- en: 'Encode a batch of text or text pair. This method is similar to regular **call**
    method but has the following differences:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 编码一批文本或文本对。此方法类似于常规的**call**方法，但具有以下区别：
- en: Handle additional num_candidate axis. (batch_size, num_candidates, text)
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理额外的num_candidate轴。(batch_size, num_candidates, text)
- en: Always pad the sequences to *max_length*.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 始终将序列填充到*max_length*。
- en: Must specify *max_length* in order to stack packs of candidates into a batch.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 必须指定*max_length*以将候选项堆叠成批次。
- en: 'single sequence: `[CLS] X [SEP]`'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个序列：`[CLS] X [SEP]`
- en: 'pair of sequences: `[CLS] A [SEP] B [SEP]`'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列对：`[CLS] A [SEP] B [SEP]`
- en: 'Example:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE12]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: RealmRetriever
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RealmRetriever
- en: '### `class transformers.RealmRetriever`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RealmRetriever`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/retrieval_realm.py#L72)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/retrieval_realm.py#L72)'
- en: '[PRE13]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`block_records` (`np.ndarray`) — A numpy array which cantains evidence texts.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`block_records` (`np.ndarray`) — 包含证据文本的numpy数组。'
- en: '`tokenizer` ([RealmTokenizer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizer))
    — The tokenizer to encode retrieved texts.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` ([RealmTokenizer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizer))
    — 用于编码检索文本的分词器。'
- en: The retriever of REALM outputting the retrieved evidence block and whether the
    block has answers as well as answer positions.”
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: REALM的检索器输出检索到的证据块以及该块是否有答案以及答案位置。
- en: '#### `block_has_answer`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `block_has_answer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/retrieval_realm.py#L129)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/retrieval_realm.py#L129)'
- en: '[PRE14]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: check if retrieved_blocks has answers.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 检查retrieved_blocks是否有答案。
- en: RealmEmbedder
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RealmEmbedder
- en: '### `class transformers.RealmEmbedder`'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RealmEmbedder`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1142)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1142)'
- en: '[PRE15]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The embedder of REALM outputting projected score that will be used to calculate
    relevance score. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: REALM的嵌入器输出投影分数，将用于计算相关性分数。该模型是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1162)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1162)'
- en: '[PRE16]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor`，形状为`(batch_size, sequence_length)`） — 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor`，形状为`(batch_size, sequence_length)`，*可选*)
    — 避免在填充标记索引上执行注意力的掩码。掩码值选择在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于未被遮蔽的标记，为1，
- en: 0 for tokens that are `masked`.
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.models.realm.modeling_realm.RealmEmbedderOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.models.realm.modeling_realm.RealmEmbedderOutput` or a tuple
    of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    and inputs.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '`projected_score` (`torch.FloatTensor` of shape `(batch_size, config.retriever_proj_size)`)
    — Projected score.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [RealmEmbedder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmEmbedder)
    forward method, overrides the `__call__` special method.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: RealmScorer
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.RealmScorer`'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1224)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`query_embedder` ([RealmEmbedder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmEmbedder))
    — Embedder for input sequences. If not specified, it will use the same embedder
    as candidate sequences.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The scorer of REALM outputting relevance scores representing the score of document
    candidates (before softmax). This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1244)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`candidate_input_ids` (`torch.LongTensor` of shape `(batch_size, num_candidates,
    sequence_length)`) — Indices of candidate input sequence tokens in the vocabulary.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)来获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是input IDs？](../glossary#input-ids)'
- en: '`candidate_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_candidates,
    sequence_length)`, *optional*) — Mask to avoid performing attention on padding
    token indices. Mask values selected in `[0, 1]`:'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`candidate_attention_mask`（形状为`(batch_size, num_candidates, sequence_length)`的`torch.FloatTensor`，*可选*）-
    用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示*未被mask*的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示被`masked`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`candidate_token_type_ids` (`torch.LongTensor` of shape `(batch_size, num_candidates,
    sequence_length)`, *optional*) — Segment token indices to indicate first and second
    portions of the inputs. Indices are selected in `[0, 1]`:'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`candidate_token_type_ids`（形状为`(batch_size, num_candidates, sequence_length)`的`torch.LongTensor`，*可选*）-
    段标记索引，用于指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于*句子B*标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是token type IDs？](../glossary#token-type-ids)'
- en: '`candidate_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size * num_candidates,
    sequence_length, hidden_size)`, *optional*) — Optionally, instead of passing `candidate_input_ids`
    you can choose to directly pass an embedded representation. This is useful if
    you want more control over how to convert *candidate_input_ids* indices into associated
    vectors than the model’s internal embedding lookup matrix.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`candidate_inputs_embeds`（形状为`(batch_size * num_candidates, sequence_length,
    hidden_size)`的`torch.FloatTensor`，*可选*）- 可选地，您可以选择直接传递嵌入表示，而不是传递`candidate_input_ids`。如果您想要更多控制权，以便将*candidate_input_ids*索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这将非常有用。'
- en: Returns
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.realm.modeling_realm.RealmScorerOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.realm.modeling_realm.RealmScorerOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.realm.modeling_realm.RealmScorerOutput` or a tuple of
    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    and inputs.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.realm.modeling_realm.RealmScorerOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时），包括根据配置（[RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig)）和输入的不同元素。
- en: '`relevance_score` (`torch.FloatTensor` of shape `(batch_size, config.num_candidates)`)
    — The relevance score of document candidates (before softmax).'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`relevance_score`（形状为`(batch_size, config.num_candidates)`的`torch.FloatTensor`）-
    文档候选项的相关性分数（softmax之前）。'
- en: '`query_score` (`torch.FloatTensor` of shape `(batch_size, config.retriever_proj_size)`)
    — Query score derived from the query embedder.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query_score`（形状为`(batch_size, config.retriever_proj_size)`的`torch.FloatTensor`）-
    从查询嵌入器派生的查询分数。'
- en: '`candidate_score` (`torch.FloatTensor` of shape `(batch_size, config.num_candidates,
    config.retriever_proj_size)`) — Candidate score derived from the embedder.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`candidate_score`（形状为`(batch_size, config.num_candidates, config.retriever_proj_size)`的`torch.FloatTensor`）-
    从嵌入器派生的候选分数。'
- en: The [RealmScorer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmScorer)
    forward method, overrides the `__call__` special method.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '[RealmScorer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmScorer)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行前处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE20]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: RealmKnowledgeAugEncoder
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RealmKnowledgeAugEncoder
- en: '### `class transformers.RealmKnowledgeAugEncoder`'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RealmKnowledgeAugEncoder`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1371)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1371)'
- en: '[PRE21]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig)）-
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The knowledge-augmented encoder of REALM outputting masked language model logits
    and marginal log-likelihood loss. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: REALM的知识增强编码器输出掩码语言模型对数和边际对数似然损失。这个模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1397)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1397)'
- en: '[PRE22]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, num_candidates, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_candidates,
    sequence_length)`, *optional*) — Mask to avoid performing attention on padding
    token indices. Mask values selected in `[0, 1]`:'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, num_candidates,
    sequence_length)`, *optional*) — Segment token indices to indicate first and second
    portions of the inputs. Indices are selected in `[0, 1]`:'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, num_candidates, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_candidates,
    sequence_length, hidden_size)`, *optional*) — Optionally, instead of passing `input_ids`
    you can choose to directly pass an embedded representation. This is useful if
    you want more control over how to convert *input_ids* indices into associated
    vectors than the model’s internal embedding lookup matrix.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`relevance_score` (`torch.FloatTensor` of shape `(batch_size, num_candidates)`,
    *optional*) — Relevance score derived from RealmScorer, must be specified if you
    want to compute the masked language modeling loss.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should be in
    `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-100` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mlm_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Mask to avoid calculating joint loss on certain positions. If not specified,
    the loss will not be masked. Mask values selected in `[0, 1]`:'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    and inputs.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Masked language modeling (MLM) loss.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [RealmKnowledgeAugEncoder](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmKnowledgeAugEncoder)
    forward method, overrides the `__call__` special method.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: RealmReader
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.RealmReader`'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1525)'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The reader of REALM. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1537)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(reader_beam_size, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(reader_beam_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(reader_beam_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(reader_beam_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(reader_beam_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`relevance_score` (`torch.FloatTensor` of shape `(searcher_beam_size,)`, *optional*)
    — Relevance score, which must be specified if you want to compute the logits and
    marginal log loss.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`block_mask` (`torch.BoolTensor` of shape `(searcher_beam_size, sequence_length)`,
    *optional*) — The mask of the evidence block, which must be specified if you want
    to compute the logits and marginal log loss.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_positions` (`torch.LongTensor` of shape `(searcher_beam_size,)`, *optional*)
    — Labels for position (index) of the start of the labelled span for computing
    the token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_positions` (`torch.LongTensor` of shape `(searcher_beam_size,)`, *optional*)
    — Labels for position (index) of the end of the labelled span for computing the
    token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`has_answers` (`torch.BoolTensor` of shape `(searcher_beam_size,)`, *optional*)
    — Whether or not the evidence block has answer(s).'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.models.realm.modeling_realm.RealmReaderOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.models.realm.modeling_realm.RealmReaderOutput` or a tuple of
    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    and inputs.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `start_positions`,
    `end_positions`, `has_answers` are provided) — Total loss.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`retriever_loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned
    when `start_positions`, `end_positions`, `has_answers` are provided) — Retriever
    loss.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reader_loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when
    `start_positions`, `end_positions`, `has_answers` are provided) — Reader loss.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`retriever_correct` (`torch.BoolTensor` of shape `(config.searcher_beam_size,)`,
    *optional*) — Whether or not an evidence block contains answer.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reader_correct` (`torch.BoolTensor` of shape `(config.reader_beam_size, num_candidates)`,
    *optional*) — Whether or not a span candidate contains answer.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`block_idx` (`torch.LongTensor` of shape `()`) — The index of the retrieved
    evidence block in which the predicted answer is most likely.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`candidate` (`torch.LongTensor` of shape `()`) — The index of the retrieved
    span candidates in which the predicted answer is most likely.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_pos` (`torch.IntTensor` of shape `()`) — Predicted answer starting position
    in *RealmReader*’s inputs.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_pos` (`torch.IntTensor` of shape `()`) — Predicted answer ending position
    in *RealmReader*’s inputs.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [RealmReader](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmReader)
    forward method, overrides the `__call__` special method.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: RealmForOpenQA
  id: totrans-369
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.RealmForOpenQA`'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1726)'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RealmForOpenQA` for end-to-end open domain question answering. This model
    is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '#### `block_embedding_to`'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1753)'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: '`device` (`str` or `torch.device`) — The device to which `self.block_emb` will
    be sent.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Send `self.block_emb` to a specific device.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/realm/modeling_realm.py#L1763)'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(1, sequence_length)`) — Indices
    of input sequence tokens in the vocabulary.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(1, sequence_length)`, *optional*)
    — Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-390
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-391
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(1, sequence_length)`, *optional*)
    — Segment token indices to indicate first and second portions of the inputs. Indices
    are selected in `[0, 1]`:'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-394
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token (should not be used in this model by design).
  id: totrans-395
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`answer_ids` (`list` of shape `(num_answers, answer_length)`, *optional*) —
    Answer ids for computing the marginal log-likelihood loss. Indices should be in
    `[-1, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-1` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.models.realm.modeling_realm.RealmForOpenQAOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.models.realm.modeling_realm.RealmForOpenQAOutput` or a tuple
    of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig))
    and inputs.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: '`reader_output` (`dict`) — Reader output.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predicted_answer_ids` (`torch.LongTensor` of shape `(answer_sequence_length)`)
    — Predicted answer ids.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [RealmForOpenQA](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmForOpenQA)
    forward method, overrides the `__call__` special method.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
