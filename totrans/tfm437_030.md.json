["```py\npip install transformers datasets evaluate\n```", "```py\n>>> from huggingface_hub import notebook_login\n\n>>> notebook_login()\n```", "```py\n>>> from datasets import load_dataset\n\n>>> food = load_dataset(\"food101\", split=\"train[:5000]\")\n```", "```py\n>>> food = food.train_test_split(test_size=0.2)\n```", "```py\n>>> food[\"train\"][0]\n{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at 0x7F52AFC8AC50>,\n 'label': 79}\n```", "```py\n>>> labels = food[\"train\"].features[\"label\"].names\n>>> label2id, id2label = dict(), dict()\n>>> for i, label in enumerate(labels):\n...     label2id[label] = str(i)\n...     id2label[str(i)] = label\n```", "```py\n>>> id2label[str(79)]\n'prime_rib'\n```", "```py\n>>> from transformers import AutoImageProcessor\n\n>>> checkpoint = \"google/vit-base-patch16-224-in21k\"\n>>> image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n```", "```py\n>>> from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n\n>>> normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n>>> size = (\n...     image_processor.size[\"shortest_edge\"]\n...     if \"shortest_edge\" in image_processor.size\n...     else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n... )\n>>> _transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])\n```", "```py\n>>> def transforms(examples):\n...     examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n...     del examples[\"image\"]\n...     return examples\n```", "```py\n>>> food = food.with_transform(transforms)\n```", "```py\n>>> from transformers import DefaultDataCollator\n\n>>> data_collator = DefaultDataCollator()\n```", "```py\n>>> from tensorflow import keras\n>>> from tensorflow.keras import layers\n\n>>> size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n\n>>> train_data_augmentation = keras.Sequential(\n...     [\n...         layers.RandomCrop(size[0], size[1]),\n...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n...         layers.RandomFlip(\"horizontal\"),\n...         layers.RandomRotation(factor=0.02),\n...         layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n...     ],\n...     name=\"train_data_augmentation\",\n... )\n\n>>> val_data_augmentation = keras.Sequential(\n...     [\n...         layers.CenterCrop(size[0], size[1]),\n...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n...     ],\n...     name=\"val_data_augmentation\",\n... )\n```", "```py\n>>> import numpy as np\n>>> import tensorflow as tf\n>>> from PIL import Image\n\n>>> def convert_to_tf_tensor(image: Image):\n...     np_image = np.array(image)\n...     tf_image = tf.convert_to_tensor(np_image)\n...     # `expand_dims()` is used to add a batch dimension since\n...     # the TF augmentation layers operates on batched inputs.\n...     return tf.expand_dims(tf_image, 0)\n\n>>> def preprocess_train(example_batch):\n...     \"\"\"Apply train_transforms across a batch.\"\"\"\n...     images = [\n...         train_data_augmentation(convert_to_tf_tensor(image.convert(\"RGB\"))) for image in example_batch[\"image\"]\n...     ]\n...     example_batch[\"pixel_values\"] = [tf.transpose(tf.squeeze(image)) for image in images]\n...     return example_batch\n\n... def preprocess_val(example_batch):\n...     \"\"\"Apply val_transforms across a batch.\"\"\"\n...     images = [\n...         val_data_augmentation(convert_to_tf_tensor(image.convert(\"RGB\"))) for image in example_batch[\"image\"]\n...     ]\n...     example_batch[\"pixel_values\"] = [tf.transpose(tf.squeeze(image)) for image in images]\n...     return example_batch\n```", "```py\nfood[\"train\"].set_transform(preprocess_train)\nfood[\"test\"].set_transform(preprocess_val)\n```", "```py\n>>> from transformers import DefaultDataCollator\n\n>>> data_collator = DefaultDataCollator(return_tensors=\"tf\")\n```", "```py\n>>> import evaluate\n\n>>> accuracy = evaluate.load(\"accuracy\")\n```", "```py\n>>> import numpy as np\n\n>>> def compute_metrics(eval_pred):\n...     predictions, labels = eval_pred\n...     predictions = np.argmax(predictions, axis=1)\n...     return accuracy.compute(predictions=predictions, references=labels)\n```", "```py\n>>> from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n\n>>> model = AutoModelForImageClassification.from_pretrained(\n...     checkpoint,\n...     num_labels=len(labels),\n...     id2label=id2label,\n...     label2id=label2id,\n... )\n```", "```py\n>>> training_args = TrainingArguments(\n...     output_dir=\"my_awesome_food_model\",\n...     remove_unused_columns=False,\n...     evaluation_strategy=\"epoch\",\n...     save_strategy=\"epoch\",\n...     learning_rate=5e-5,\n...     per_device_train_batch_size=16,\n...     gradient_accumulation_steps=4,\n...     per_device_eval_batch_size=16,\n...     num_train_epochs=3,\n...     warmup_ratio=0.1,\n...     logging_steps=10,\n...     load_best_model_at_end=True,\n...     metric_for_best_model=\"accuracy\",\n...     push_to_hub=True,\n... )\n\n>>> trainer = Trainer(\n...     model=model,\n...     args=training_args,\n...     data_collator=data_collator,\n...     train_dataset=food[\"train\"],\n...     eval_dataset=food[\"test\"],\n...     tokenizer=image_processor,\n...     compute_metrics=compute_metrics,\n... )\n\n>>> trainer.train()\n```", "```py\n>>> trainer.push_to_hub()\n```", "```py\n>>> from transformers import create_optimizer\n\n>>> batch_size = 16\n>>> num_epochs = 5\n>>> num_train_steps = len(food[\"train\"]) * num_epochs\n>>> learning_rate = 3e-5\n>>> weight_decay_rate = 0.01\n\n>>> optimizer, lr_schedule = create_optimizer(\n...     init_lr=learning_rate,\n...     num_train_steps=num_train_steps,\n...     weight_decay_rate=weight_decay_rate,\n...     num_warmup_steps=0,\n... )\n```", "```py\n>>> from transformers import TFAutoModelForImageClassification\n\n>>> model = TFAutoModelForImageClassification.from_pretrained(\n...     checkpoint,\n...     id2label=id2label,\n...     label2id=label2id,\n... )\n```", "```py\n>>> # converting our train dataset to tf.data.Dataset\n>>> tf_train_dataset = food[\"train\"].to_tf_dataset(\n...     columns=\"pixel_values\", label_cols=\"label\", shuffle=True, batch_size=batch_size, collate_fn=data_collator\n... )\n\n>>> # converting our test dataset to tf.data.Dataset\n>>> tf_eval_dataset = food[\"test\"].to_tf_dataset(\n...     columns=\"pixel_values\", label_cols=\"label\", shuffle=True, batch_size=batch_size, collate_fn=data_collator\n... )\n```", "```py\n>>> from tensorflow.keras.losses import SparseCategoricalCrossentropy\n\n>>> loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n>>> model.compile(optimizer=optimizer, loss=loss)\n```", "```py\n>>> from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback\n\n>>> metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_eval_dataset)\n>>> push_to_hub_callback = PushToHubCallback(\n...     output_dir=\"food_classifier\",\n...     tokenizer=image_processor,\n...     save_strategy=\"no\",\n... )\n>>> callbacks = [metric_callback, push_to_hub_callback]\n```", "```py\n>>> model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=num_epochs, callbacks=callbacks)\nEpoch 1/5\n250/250 [==============================] - 313s 1s/step - loss: 2.5623 - val_loss: 1.4161 - accuracy: 0.9290\nEpoch 2/5\n250/250 [==============================] - 265s 1s/step - loss: 0.9181 - val_loss: 0.6808 - accuracy: 0.9690\nEpoch 3/5\n250/250 [==============================] - 252s 1s/step - loss: 0.3910 - val_loss: 0.4303 - accuracy: 0.9820\nEpoch 4/5\n250/250 [==============================] - 251s 1s/step - loss: 0.2028 - val_loss: 0.3191 - accuracy: 0.9900\nEpoch 5/5\n250/250 [==============================] - 238s 949ms/step - loss: 0.1232 - val_loss: 0.3259 - accuracy: 0.9890\n```", "```py\n>>> ds = load_dataset(\"food101\", split=\"validation[:10]\")\n>>> image = ds[\"image\"][0]\n```", "```py\n>>> from transformers import pipeline\n\n>>> classifier = pipeline(\"image-classification\", model=\"my_awesome_food_model\")\n>>> classifier(image)\n[{'score': 0.31856709718704224, 'label': 'beignets'},\n {'score': 0.015232225880026817, 'label': 'bruschetta'},\n {'score': 0.01519392803311348, 'label': 'chicken_wings'},\n {'score': 0.013022331520915031, 'label': 'pork_chop'},\n {'score': 0.012728818692266941, 'label': 'prime_rib'}]\n```", "```py\n>>> from transformers import AutoImageProcessor\n>>> import torch\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"my_awesome_food_model\")\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n```", "```py\n>>> from transformers import AutoModelForImageClassification\n\n>>> model = AutoModelForImageClassification.from_pretrained(\"my_awesome_food_model\")\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n```", "```py\n>>> predicted_label = logits.argmax(-1).item()\n>>> model.config.id2label[predicted_label]\n'beignets'\n```", "```py\n>>> from transformers import AutoImageProcessor\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"MariaK/food_classifier\")\n>>> inputs = image_processor(image, return_tensors=\"tf\")\n```", "```py\n>>> from transformers import TFAutoModelForImageClassification\n\n>>> model = TFAutoModelForImageClassification.from_pretrained(\"MariaK/food_classifier\")\n>>> logits = model(**inputs).logits\n```", "```py\n>>> predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])\n>>> model.config.id2label[predicted_class_id]\n'beignets'\n```"]