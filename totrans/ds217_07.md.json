["```py\n>>> from datasets import load_dataset_builder\n>>> ds_builder = load_dataset_builder(\"rotten_tomatoes\")\n\n# Inspect dataset description\n>>> ds_builder.info.description\nMovie Review Dataset. This is a dataset of containing 5,331 positive and 5,331 negative processed sentences from Rotten Tomatoes movie reviews. This data was first used in Bo Pang and Lillian Lee, ``Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.'', Proceedings of the ACL, 2005.\n\n# Inspect dataset features\n>>> ds_builder.info.features\n{'label': ClassLabel(num_classes=2, names=['neg', 'pos'], id=None),\n 'text': Value(dtype='string', id=None)}\n```", "```py\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"rotten_tomatoes\", split=\"train\")\n```", "```py\n>>> from datasets import get_dataset_split_names\n\n>>> get_dataset_split_names(\"rotten_tomatoes\")\n['train', 'validation', 'test']\n```", "```py\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"rotten_tomatoes\", split=\"train\")\n>>> dataset\nDataset({\n    features: ['text', 'label'],\n    num_rows: 8530\n})\n```", "```py\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"rotten_tomatoes\")\nDatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 8530\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1066\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1066\n    })\n})\n```", "```py\n>>> from datasets import get_dataset_config_names\n\n>>> configs = get_dataset_config_names(\"PolyAI/minds14\")\n>>> print(configs)\n['cs-CZ', 'de-DE', 'en-AU', 'en-GB', 'en-US', 'es-ES', 'fr-FR', 'it-IT', 'ko-KR', 'nl-NL', 'pl-PL', 'pt-PT', 'ru-RU', 'zh-CN', 'all']\n```", "```py\n>>> from datasets import load_dataset\n\n>>> mindsFR = load_dataset(\"PolyAI/minds14\", \"fr-FR\", split=\"train\")\n```", "```py\n>>> from datasets import get_dataset_config_names, get_dataset_split_names, load_dataset\n\n>>> c4 = load_dataset(\"c4\", \"en\", split=\"train\", trust_remote_code=True)\n>>> get_dataset_config_names(\"c4\", trust_remote_code=True)\n['en', 'realnewslike', 'en.noblocklist', 'en.noclean']\n>>> get_dataset_split_names(\"c4\", \"en\", trust_remote_code=True)\n['train', 'validation']\n```"]