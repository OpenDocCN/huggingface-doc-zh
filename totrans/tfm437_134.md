# BARTpho

> 原始文本: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bartpho](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bartpho)

## 概述

BARTpho模型是由Nguyen Luong Tran, Duong Minh Le和Dat Quoc Nguyen在[《BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese》](https://arxiv.org/abs/2109.09701)中提出的。

论文摘要如下：

*我们提供了两个版本的BARTpho — BARTpho_word和BARTpho_syllable — 这是为越南语预训练的首个公开大规模单语序列到序列模型。我们的BARTpho使用了BART序列到序列去噪模型的“large”架构和预训练方案，因此特别适用于生成式NLP任务。在越南语文本摘要的下游任务上的实验表明，在自动和人工评估中，我们的BARTpho优于强基线mBART，并改进了最新技术。我们发布BARTpho以促进未来的生成式越南语NLP任务的研究和应用。*

这个模型是由[dqnguyen](https://huggingface.co/dqnguyen)贡献的。原始代码可以在[这里](https://github.com/VinAIResearch/BARTpho)找到。

## 用法示例

```py
>>> import torch
>>> from transformers import AutoModel, AutoTokenizer

>>> bartpho = AutoModel.from_pretrained("vinai/bartpho-syllable")

>>> tokenizer = AutoTokenizer.from_pretrained("vinai/bartpho-syllable")

>>> line = "Chúng tôi là những nghiên cứu viên."

>>> input_ids = tokenizer(line, return_tensors="pt")

>>> with torch.no_grad():
...     features = bartpho(**input_ids)  # Models outputs are now tuples

>>> # With TensorFlow 2.0+:
>>> from transformers import TFAutoModel

>>> bartpho = TFAutoModel.from_pretrained("vinai/bartpho-syllable")
>>> input_ids = tokenizer(line, return_tensors="tf")
>>> features = bartpho(**input_ids)
```

## 用法提示

+   与mBART一样，BARTpho使用BART的“large”架构，并在编码器和解码器的顶部增加了一个额外的层归一化层。因此，在[BART文档](bart)中的用法示例，在适应BARTpho时，应通过用mBART专用类替换BART专用类来进行调整。例如：

```py
>>> from transformers import MBartForConditionalGeneration

>>> bartpho = MBartForConditionalGeneration.from_pretrained("vinai/bartpho-syllable")
>>> TXT = "Chúng tôi là <mask> nghiên cứu viên."
>>> input_ids = tokenizer([TXT], return_tensors="pt")["input_ids"]
>>> logits = bartpho(input_ids).logits
>>> masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()
>>> probs = logits[0, masked_index].softmax(dim=0)
>>> values, predictions = probs.topk(5)
>>> print(tokenizer.decode(predictions).split())
```

+   这个实现仅用于标记化：“monolingual_vocab_file”包含从多语言XLM-RoBERTa的预训练SentencePiece模型“vocab_file”中提取的越南语专用类型。其他语言，如果使用这个预训练的多语言SentencePiece模型“vocab_file”进行子词分割，可以重用BartphoTokenizer与自己的语言专用“monolingual_vocab_file”。

## BartphoTokenizer

### `class transformers.BartphoTokenizer`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bartpho/tokenization_bartpho.py#L46)

```py
( vocab_file monolingual_vocab_file bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' sp_model_kwargs: Optional = None **kwargs )
```

参数

+   `vocab_file` (`str`) — 词汇文件的路径。这个词汇是来自多语言XLM-RoBERTa的预训练SentencePiece模型，也被mBART使用，包含250K种类型。

+   `monolingual_vocab_file` (`str`) — 单语词汇文件的路径。这个单语词汇包含从250K种类型的多语言词汇`vocab_file`中提取的越南语专用类型。

+   `bos_token` (`str`, *可选*, 默认为 `"<s>"`) — 在预训练期间使用的序列开始标记。可以用作序列分类器标记。

    在构建序列时使用特殊标记时，这不是用于序列开头的标记。使用的标记是`cls_token`。

+   `eos_token` (`str`, *可选*, 默认为 `"</s>"`) — 序列结束标记。

    在构建序列时使用特殊标记时，这不是用于序列结尾的标记。使用的标记是`sep_token`。

+   `sep_token` (`str`, *可选*, 默认为 `"</s>"`) — 分隔符标记，用于从多个序列构建序列，例如用于序列分类的两个序列或用于文本和问题的问题回答。它也用作使用特殊标记构建的序列的最后一个标记。

+   `cls_token` (`str`, *可选*, 默认为 `"<s>"`) — 用于进行序列分类（对整个序列而不是每个标记进行分类）时使用的分类器标记。在使用特殊标记构建序列时，它是序列的第一个标记。

+   `unk_token` (`str`, *可选*, 默认为 `"<unk>"`) — 未知标记。词汇中不存在的标记无法转换为ID，而是设置为此标记。

+   `pad_token`（`str`，*可选*，默认为`"<pad>"`）- 用于填充的标记，例如在批处理不同长度的序列时。

+   `mask_token`（`str`，*可选*，默认为`"<mask>"`）- 用于屏蔽值的标记。这是在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。

+   `sp_model_kwargs`（`dict`，*可选*）- 将传递给`SentencePieceProcessor.__init__()`方法。[SentencePiece的Python包装器](https://github.com/google/sentencepiece/tree/master/python)可用于设置：

    +   `enable_sampling`：启用子词正则化。

    +   `nbest_size`：unigram的抽样参数。对于BPE-Dropout无效。

        +   `nbest_size = {0,1}`：不执行抽样。

        +   `nbest_size > 1`：从nbest_size结果中抽样。

        +   `nbest_size < 0`: 假设nbest_size是无限的，并使用前向过滤和后向抽样算法从所有假设（格子）中抽样。

    +   `alpha`：unigram抽样的平滑参数，以及BPE-dropout合并操作的丢失概率。

+   `sp_model`（`SentencePieceProcessor`）- 用于每次转换（字符串、标记和ID）的*SentencePiece*处理器。

改编自[XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)。基于[SentencePiece](https://github.com/google/sentencepiece)。

此标记器继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。

#### `build_inputs_with_special_tokens`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bartpho/tokenization_bartpho.py#L191)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0`（`List[int]`）- 将添加特殊标记的ID列表。

+   `token_ids_1`（`List[int]`，*可选*）- 序列对的可选第二个ID列表。

返回

`List[int]`

具有适当特殊标记的[input IDs](../glossary#input-ids)列表。

通过连接和添加特殊标记构建用于序列分类任务的序列或序列对的模型输入。BARTPho序列的格式如下：

+   单个序列：`<s> X </s>`

+   序列对：`<s> A </s></s> B </s>`

#### `convert_tokens_to_string`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bartpho/tokenization_bartpho.py#L293)

```py
( tokens )
```

将一系列标记（子词的字符串）转换为单个字符串。

#### `create_token_type_ids_from_sequences`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bartpho/tokenization_bartpho.py#L245)

```py
( token_ids_0: List token_ids_1: Optional = None ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0`（`List[int]`）- ID列表。

+   `token_ids_1`（`List[int]`，*可选*）- 序列对的可选第二个ID列表。

返回

`List[int]`

零的列表。

从传递的两个序列创建一个用于序列对分类任务的掩码。BARTPho不使用标记类型ID，因此返回一个零的列表。

#### `get_special_tokens_mask`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/bartpho/tokenization_bartpho.py#L217)

```py
( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) → export const metadata = 'undefined';List[int]
```

参数

+   `token_ids_0`（`List[int]`）- ID列表。

+   `token_ids_1`（`List[int]`，*可选*）- 序列对的可选第二个ID列表。

+   `already_has_special_tokens`（`bool`，*可选*，默认为`False`）- 标记列表是否已经格式化为模型的特殊标记。

返回

`List[int]`

一个整数列表，范围为[0, 1]：1表示特殊标记，0表示序列标记。

从没有添加特殊标记的标记列表中检索序列ID。在使用标记器`prepare_for_model`方法添加特殊标记时调用此方法。
