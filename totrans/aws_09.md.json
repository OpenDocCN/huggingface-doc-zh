["```py\npip install \"optimum[neuronx, diffusers]\"\n```", "```py\noptimum-cli export neuron --model stabilityai/stable-diffusion-2-1-base \\\n  --task stable-diffusion \\\n  --batch_size 1 \\\n  --height 512 `# height in pixels of generated image, eg. 512, 768` \\\n  --width 512 `# width in pixels of generated image, eg. 512, 768` \\\n  --num_images_per_prompt 4 `# number of images to generate per prompt, defaults to 1` \\\n  --auto_cast matmul `# cast only matrix multiplication operations` \\\n  --auto_cast_type bf16 `# cast operations from FP32 to BF16` \\\n  sd_neuron/\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionPipeline\n\n>>> model_id = \"runwayml/stable-diffusion-v1-5\"\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 512, \"width\": 512}\n\n>>> stable_diffusion = NeuronStableDiffusionPipeline.from_pretrained(model_id, export=True, **compiler_args, **input_shapes)\n\n# Save locally or upload to the HuggingFace Hub\n>>> save_directory = \"sd_neuron/\"\n>>> stable_diffusion.save_pretrained(save_directory)\n>>> stable_diffusion.push_to_hub(\n...     save_directory, repository_id=\"my-neuron-repo\", use_auth_token=True\n... )\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionPipeline\n\n>>> stable_diffusion = NeuronStableDiffusionPipeline.from_pretrained(\"sd_neuron/\")\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> image = stable_diffusion(prompt).images[0]\n```", "```py\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nfrom optimum.neuron import NeuronStableDiffusionImg2ImgPipeline\n\n# compile & save\nmodel_id = \"nitrosocke/Ghibli-Diffusion\"\ninput_shapes = {\"batch_size\": 1, \"height\": 512, \"width\": 512}\npipeline = NeuronStableDiffusionImg2ImgPipeline.from_pretrained(model_id, export=True, **input_shapes)\npipeline.save_pretrained(\"sd_img2img/\")\n\nurl = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n\nresponse = requests.get(url)\ninit_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\ninit_image = init_image.resize((512, 512))\n\nprompt = \"ghibli style, a fantasy landscape with snowcapped mountains, trees, lake with detailed reflection. sunlight and cloud in the sky, warm colors, 8K\"\n\nimage = pipeline(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images[0]\nimage.save(\"fantasy_landscape.png\")\n```", "```py\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nfrom optimum.neuron import NeuronStableDiffusionInpaintPipeline\n\nmodel_id = \"runwayml/stable-diffusion-inpainting\"\ninput_shapes = {\"batch_size\": 1, \"height\": 512, \"width\": 512}\npipeline = NeuronStableDiffusionInpaintPipeline.from_pretrained(model_id, export=True, **input_shapes)\npipeline.save_pretrained(\"sd_inpaint/\")\n\ndef download_image(url):\n    response = requests.get(url)\n    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n\nimg_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\nmask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n\ninit_image = download_image(img_url).resize((512, 512))\nmask_image = download_image(mask_url).resize((512, 512))\n\nprompt = \"Face of a yellow cat, high resolution, sitting on a park bench\"\nimage = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]\nimage.save(\"cat_on_bench.png\")\n```", "```py\noptimum-cli export neuron --model stabilityai/stable-diffusion-xl-base-1.0 \\\n  --task stable-diffusion-xl \\\n  --batch_size 1 \\\n  --height 1024 `# height in pixels of generated image, eg. 768, 1024` \\\n  --width 1024 `# width in pixels of generated image, eg. 768, 1024` \\\n  --num_images_per_prompt 4 `# number of images to generate per prompt, defaults to 1` \\\n  --auto_cast matmul `# cast only matrix multiplication operations` \\\n  --auto_cast_type bf16 `# cast operations from FP32 to BF16` \\\n  sd_neuron_xl/\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionXLPipeline\n\n>>> model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 1024, \"width\": 1024}\n\n>>> stable_diffusion_xl = NeuronStableDiffusionXLPipeline.from_pretrained(model_id, export=True, **compiler_args, **input_shapes)\n\n# Save locally or upload to the HuggingFace Hub\n>>> save_directory = \"sd_neuron_xl/\"\n>>> stable_diffusion_xl.save_pretrained(save_directory)\n>>> stable_diffusion_xl.push_to_hub(\n...     save_directory, repository_id=\"my-neuron-repo\", use_auth_token=True\n... )\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionXLPipeline\n\n>>> stable_diffusion_xl = NeuronStableDiffusionXLPipeline.from_pretrained(\"sd_neuron_xl/\")\n>>> prompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n>>> image = stable_diffusion_xl(prompt).images[0]\n```", "```py\nfrom optimum.neuron import NeuronStableDiffusionXLImg2ImgPipeline\nfrom diffusers.utils import load_image\n\nprompt = \"a dog running, lake, moat\"\nurl = \"https://huggingface.co/datasets/optimum/documentation-images/resolve/main/intel/openvino/sd_xl/castle_friedrich.png\"\ninit_image = load_image(url).convert(\"RGB\")\n\npipe = NeuronStableDiffusionXLImg2ImgPipeline.from_pretrained(\"sd_neuron_xl/\")\nimage = pipe(prompt=prompt, image=init_image).images[0]\n```", "```py\nfrom optimum.neuron import NeuronStableDiffusionXLInpaintPipeline\nfrom diffusers.utils import load_image\n\nimg_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png\"\nmask_url = (\n    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-inpaint-mask.png\"\n)\n\ninit_image = load_image(img_url).convert(\"RGB\")\nmask_image = load_image(mask_url).convert(\"RGB\")\nprompt = \"A deep sea diver floating\"\n\npipe = NeuronStableDiffusionXLInpaintPipeline.from_pretrained(\"sd_neuron_xl/\")\nimage = pipe(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.85, guidance_scale=12.5).images[0]\n```", "```py\nfrom optimum.neuron import NeuronStableDiffusionXLPipeline, NeuronStableDiffusionXLImg2ImgPipeline\n\nprompt = \"A majestic lion jumping from a big stone at night\"\nbase = NeuronStableDiffusionXLPipeline.from_pretrained(\"sd_neuron_xl/\")\nimage = base(\n    prompt=prompt,\n    num_images_per_prompt=num_images_per_prompt,\n    num_inference_steps=40,\n    denoising_end=0.8,\n    output_type=\"latent\",\n).images[0]\ndel base  # To avoid neuron device OOM\n\nrefiner = NeuronStableDiffusionXLImg2ImgPipeline.from_pretrained(\"sd_neuron_xl_refiner/\")\nimage = image = refiner(\n    prompt=prompt,\n    num_inference_steps=40,\n    denoising_start=0.8,\n    image=image,\n).images[0]\n```", "```py\nfrom optimum.neuron import NeuronStableDiffusionXLPipeline, NeuronStableDiffusionXLImg2ImgPipeline\n\nprompt = \"A majestic lion jumping from a big stone at night\"\nbase = NeuronStableDiffusionXLPipeline.from_pretrained(\"sd_neuron_xl/\")\nimage = base(prompt=prompt, output_type=\"latent\").images[0]\ndel base  # To avoid neuron device OOM\n\nrefiner = NeuronStableDiffusionXLImg2ImgPipeline.from_pretrained(\"sd_neuron_xl_refiner/\")\nimage = refiner(prompt=prompt, image=image[None, :]).images[0]\n```", "```py\nfrom optimum.neuron import NeuronLatentConsistencyModelPipeline\n\nmodel_id = \"SimianLuo/LCM_Dreamshaper_v7\"\nnum_images_per_prompt = 1\ninput_shapes = {\"batch_size\": 1, \"height\": 768, \"width\": 768, \"num_images_per_prompt\": num_images_per_prompt}\ncompiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n\nstable_diffusion = NeuronLatentConsistencyModelPipeline.from_pretrained(\n    model_id, export=True, **compiler_args, **input_shapes\n)\nsave_directory = \"lcm_sd_neuron/\"\nstable_diffusion.save_pretrained(save_directory)\n\n# Push to hub\nstable_diffusion.push_to_hub(save_directory, repository_id=\"my-neuron-repo\", use_auth_token=True)  # Replace with your repo id, eg. \"Jingya/LCM_Dreamshaper_v7_neuronx\"\n```", "```py\nfrom optimum.neuron import NeuronStableDiffusionXLPipeline\n\nmodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\nunet_id = \"latent-consistency/lcm-sdxl\"\nnum_images_per_prompt = 1\ninput_shapes = {\"batch_size\": 1, \"height\": 1024, \"width\": 1024, \"num_images_per_prompt\": num_images_per_prompt}\ncompiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n\nstable_diffusion = NeuronStableDiffusionXLPipeline.from_pretrained(\n    model_id, unet_id=unet_id, export=True, **compiler_args, **input_shapes\n)\nsave_directory = \"lcm_sdxl_neuron/\"\nstable_diffusion.save_pretrained(save_directory)\n\n# Push to hub\nstable_diffusion.push_to_hub(save_directory, repository_id=\"my-neuron-repo\", use_auth_token=True)   # Replace with your repo id, eg. \"Jingya/lcm-sdxl-neuronx\"\n```", "```py\nfrom optimum.neuron import NeuronLatentConsistencyModelPipeline\n\npipe = NeuronLatentConsistencyModelPipeline.from_pretrained(\"Jingya/LCM_Dreamshaper_v7_neuronx\")\nprompts = [\"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\"] * 2\n\nimages = pipe(prompt=prompts, num_inference_steps=4, guidance_scale=8.0).images\n```", "```py\nfrom optimum.neuron import NeuronStableDiffusionXLPipeline\n\npipe = NeuronStableDiffusionXLPipeline.from_pretrained(\"Jingya/lcm-sdxl-neuronx\")\nprompts = [\"a close-up picture of an old man standing in the rain\"] * 2\n\nimages = pipe(prompt=prompts, num_inference_steps=4, guidance_scale=8.0).images\n```", "```py\noptimum-cli export neuron --model stabilityai/sdxl-turbo --task stable-diffusion-xl --batch_size 1 --height 512 --width 512 --auto_cast matmul --auto_cast_type bf16 sdxl_turbo_neuron/\n```", "```py\nfrom optimum.neuron import NeuronStableDiffusionXLPipeline\n\npipe = NeuronStableDiffusionXLPipeline.from_pretrained(\"sdxl_turbo_neuron/\", data_parallel_mode=\"all\")\nprompt = [\"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\"] * 2\n\nimages = pipe(prompt=prompt, guidance_scale=0.0, num_inference_steps=1).images\n```"]