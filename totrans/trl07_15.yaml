- en: 'Best of N sampling: Alternative ways to get better model output without RL
    based fine-tuning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/trl/best_of_n](https://huggingface.co/docs/trl/best_of_n)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/trl/v0.7.10/en/_app/immutable/assets/0.e3b0c442.css" rel="modulepreload">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/entry/start.d9a24ea1.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/scheduler.9039eef2.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/singletons.9eef12cc.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/paths.1355483e.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/entry/app.5bef33b8.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/index.ded8f90d.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/nodes/0.abccdcd8.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/nodes/2.122a8737.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/CodeBlock.8580f3e8.js">
    <link rel="modulepreload" href="/docs/trl/v0.7.10/en/_app/immutable/chunks/Heading.f027f30d.js">
  prefs: []
  type: TYPE_NORMAL
- en: Within the extras module is the `best-of-n` sampler class that serves as an
    alternative method of generating better model output. As to how it fares against
    the RL based fine-tuning, please look in the `examples` directory for a comparison
    example
  prefs: []
  type: TYPE_NORMAL
- en: Usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get started quickly, instantiate an instance of the class with a model, a
    length sampler, a tokenizer and a callable that serves as a proxy reward pipeline
    that outputs reward scores for input queries
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: And assuming you have a list/tensor of tokenized queries, you can generate better
    output by calling the `generate` method
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The default sample size is 4, but you can change it at the time of instance
    initialization like so
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The default output is the result of taking the top scored output for each query,
    but you can change it to top 2 and so on by passing the `n_candidates` argument
    at the time of instance initialization
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: There is the option of setting the generation settings (like `temperature`,
    `pad_token_id`) at the time of instance creation as opposed to when calling the
    `generate` method. This is done by passing a `GenerationConfig` from the `transformers`
    library at the time of initialization
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Furthermore, at the time of initialization you can set the seed to control repeatability
    of the generation process and the number of samples to generate for each query
  prefs: []
  type: TYPE_NORMAL
