- en: Quickstart
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速入门
- en: 'Original text: [https://huggingface.co/docs/timm/quickstart](https://huggingface.co/docs/timm/quickstart)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/timm/quickstart](https://huggingface.co/docs/timm/quickstart)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This quickstart is intended for developers who are ready to dive into the code
    and see an example of how to integrate `timm` into their model training workflow.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这个快速入门旨在为那些准备深入代码并查看如何将`timm`集成到他们的模型训练工作流程中的开发人员提供一个示例。
- en: First, you’ll need to install `timm`. For more information on installation,
    see [Installation](installation).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要安装`timm`。有关安装的更多信息，请参阅[Installation](installation)。
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Load a Pretrained Model
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载预训练模型
- en: Pretrained models can be loaded using [create_model()](/docs/timm/v0.9.12/en/reference/models#timm.create_model).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用[create_model()](/docs/timm/v0.9.12/en/reference/models#timm.create_model)加载预训练模型。
- en: Here, we load the pretrained `mobilenetv3_large_100` model.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们加载了预训练的`mobilenetv3_large_100`模型。
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Note: The returned PyTorch model is set to train mode by default, so you must
    call .eval() on it if you plan to use it for inference.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：返回的PyTorch模型默认设置为训练模式，因此如果您计划用它进行推断，必须调用.eval()。
- en: List Models with Pretrained Weights
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列出具有预训练权重的模型
- en: To list models packaged with `timm`, you can use [list_models()](/docs/timm/v0.9.12/en/reference/models#timm.list_models).
    If you specify `pretrained=True`, this function will only return model names that
    have associated pretrained weights available.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要列出打包在`timm`中的模型，您可以使用[list_models()](/docs/timm/v0.9.12/en/reference/models#timm.list_models)。如果指定`pretrained=True`，此函数将仅返回具有相关预训练权重的模型名称。
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can also list models with a specific pattern in their name.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以列出具有特定模式名称的模型。
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Fine-Tune a Pretrained Model
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微调预训练模型
- en: You can finetune any of the pre-trained models just by changing the classifier
    (the last layer).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 只需更改分类器（最后一层），就可以微调任何预训练模型。
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To fine-tune on your own dataset, you have to write a PyTorch training loop
    or adapt `timm`’s [training script](training_script) to use your dataset.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要在自己的数据集上进行微调，您必须编写一个PyTorch训练循环或者调整`timm`的[训练脚本](training_script)以使用您的数据集。
- en: Use a Pretrained Model for Feature Extraction
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用预训练模型进行特征提取
- en: Without modifying the network, one can call model.forward_features(input) on
    any model instead of the usual model(input). This will bypass the head classifier
    and global pooling for networks.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在不修改网络的情况下，可以在任何模型上调用model.forward_features(input)而不是通常的model(input)。这将绕过网络的头分类器和全局池化。
- en: For a more in depth guide to using `timm` for feature extraction, see [Feature
    Extraction](feature_extraction).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何使用`timm`进行特征提取的更详细指南，请参阅[Feature Extraction](feature_extraction)。
- en: '[PRE5]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Image Augmentation
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像增强
- en: To transform images into valid inputs for a model, you can use [timm.data.create_transform()](/docs/timm/v0.9.12/en/reference/data#timm.data.create_transform),
    providing the desired `input_size` that the model expects.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将图像转换为模型的有效输入，您可以使用[timm.data.create_transform()](/docs/timm/v0.9.12/en/reference/data#timm.data.create_transform)，提供模型期望的所需`input_size`。
- en: This will return a generic transform that uses reasonable defaults.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个使用合理默认值的通用转换。
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Pretrained models have specific transforms that were applied to images fed into
    them while training. If you use the wrong transform on your image, the model won’t
    understand what it’s seeing!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型在训练时应用了特定的转换，用于输入到模型中。如果您在图像上使用错误的转换，模型将无法理解它看到的内容！
- en: To figure out which transformations were used for a given pretrained model,
    we can start by taking a look at its `pretrained_cfg`
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要找出给定预训练模型使用了哪些转换，我们可以首先查看其`pretrained_cfg`
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We can then resolve only the data related configuration by using [timm.data.resolve_data_config()](/docs/timm/v0.9.12/en/reference/data#timm.data.resolve_data_config).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用[timm.data.resolve_data_config()](/docs/timm/v0.9.12/en/reference/data#timm.data.resolve_data_config)来解决仅与数据相关的配置。
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can pass this data config to [timm.data.create_transform()](/docs/timm/v0.9.12/en/reference/data#timm.data.create_transform)
    to initialize the model’s associated transform.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些数据配置传递给[timm.data.create_transform()](/docs/timm/v0.9.12/en/reference/data#timm.data.create_transform)来初始化模型的相关转换。
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Note: Here, the pretrained model''s config happens to be the same as the generic
    config we made earlier. This is not always the case. So, it''s safer to use the
    data config to create the transform as we did here instead of using the generic
    transform.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在这里，预训练模型的配置恰好与我们之前制作的通用配置相同。这并不总是这样。因此，与使用通用转换不同，更安全的做法是使用数据配置来创建转换，就像我们在这里所做的那样。
- en: Using Pretrained Models for Inference
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用预训练模型进行推断
- en: Here, we will put together the above sections and use a pretrained model for
    inference.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将整合上述部分并使用一个预训练模型进行推断。
- en: 'First we’ll need an image to do inference on. Here we load a picture of a leaf
    from the web:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一张图像进行推断。这里我们从网络上加载了一张叶子的图片：
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here’s the image we loaded:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们加载的图像：
- en: '![An Image from a link](../Images/044552025856bd5e75f92f37bef155ce.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![来自链接的图像](../Images/044552025856bd5e75f92f37bef155ce.png)'
- en: Now, we’ll create our model and transforms again. This time, we make sure to
    set our model in evaluation mode.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将再次创建我们的模型和转换。这次，我们确保将我们的模型设置为评估模式。
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can prepare this image for the model by passing it to the transform.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将图像传递给转换来为模型准备这个图像。
- en: '[PRE12]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now we can pass that image to the model to get the predictions. We use `unsqueeze(0)`
    in this case, as the model is expecting a batch dimension.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将该图像传递给模型以获取预测。在这种情况下，我们使用`unsqueeze(0)`，因为模型期望有一个批次维度。
- en: '[PRE13]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: To get the predicted probabilities, we apply softmax to the output. This leaves
    us with a tensor of shape `(num_classes,)`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取预测的概率，我们将softmax应用于输出。这将使我们得到一个形状为`(num_classes,)`的张量。
- en: '[PRE14]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now we’ll find the top 5 predicted class indexes and values using `torch.topk`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用`torch.topk`找到前5个预测类别的索引和值。
- en: '[PRE15]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If we check the imagenet labels for the top index, we can see what the model
    predicted…
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查顶部索引的imagenet标签，我们可以看到模型预测的结果...
- en: '[PRE16]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
