["```py\n( vae: AutoencoderKL text_encoder: CLIPTextModel tokenizer: CLIPTokenizer unet: UNet2DConditionModel scheduler: DDIMScheduler safety_checker: StableDiffusionSafetyChecker feature_extractor: CLIPImageProcessor image_encoder: Optional = None requires_safety_checker: bool = True )\n```", "```py\n( prompt: Union = None height: Optional = 512 width: Optional = 2048 num_inference_steps: int = 50 guidance_scale: float = 7.5 view_batch_size: int = 1 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None ip_adapter_image: Union = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: Optional = 1 cross_attention_kwargs: Optional = None circular_padding: bool = False clip_skip: Optional = None ) \u2192 export const metadata = 'undefined';StableDiffusionPipelineOutput or tuple\n```", "```py\n>>> import torch\n>>> from diffusers import StableDiffusionPanoramaPipeline, DDIMScheduler\n\n>>> model_ckpt = \"stabilityai/stable-diffusion-2-base\"\n>>> scheduler = DDIMScheduler.from_pretrained(model_ckpt, subfolder=\"scheduler\")\n>>> pipe = StableDiffusionPanoramaPipeline.from_pretrained(\n...     model_ckpt, scheduler=scheduler, torch_dtype=torch.float16\n... )\n\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"a photo of the dolomites\"\n>>> image = pipe(prompt).images[0]\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( prompt device num_images_per_prompt do_classifier_free_guidance negative_prompt = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None lora_scale: Optional = None clip_skip: Optional = None )\n```", "```py\n( images: Union nsfw_content_detected: Optional )\n```"]