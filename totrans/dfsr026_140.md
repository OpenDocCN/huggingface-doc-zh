# DDPM

> 原始文本：[https://huggingface.co/docs/diffusers/api/pipelines/ddpm](https://huggingface.co/docs/diffusers/api/pipelines/ddpm)

由Jonathan Ho、Ajay Jain和Pieter Abbeel提出的[Denoising Diffusion Probabilistic Models](https://huggingface.co/papers/2006.11239)（DDPM）提出了同名的扩散模型。在🤗 Diffusers库中，DDPM指的是论文中的*离散去噪调度器*以及管道。

论文摘要为：

*我们使用扩散概率模型呈现高质量的图像合成结果，这是一类受非平衡热力学考虑启发的潜变量模型。我们的最佳结果是通过根据扩散概率模型和Langevin动力学的去噪得分匹配之间的新颖连接设计的加权变分界限进行训练获得的，我们的模型自然地采用了一种渐进的有损解压缩方案，可以解释为自回归解码的一般化。在无条件的CIFAR10数据集上，我们获得了9.46的Inception分数和3.17的最先进的FID分数。在256x256的LSUN上，我们获得了类似于ProgressiveGAN的样本质量。*

原始代码库可以在[hohonathanho/diffusion](https://github.com/hojonathanho/diffusion)找到。

确保查看调度器[指南](../../using-diffusers/schedulers)以了解如何探索调度器速度和质量之间的权衡，并查看[跨管道重用组件](../../using-diffusers/loading#reuse-components-across-pipelines)部分以了解如何有效地将相同组件加载到多个管道中。

# DDPMPipeline

### `class diffusers.DDPMPipeline`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/ddpm/pipeline_ddpm.py#L24)

```py
( unet scheduler )
```

参数

+   `unet`（[UNet2DModel](/docs/diffusers/v0.26.3/en/api/models/unet2d#diffusers.UNet2DModel)）— 用于去噪编码图像潜变量的`UNet2DModel`。

+   `scheduler`（[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)）— 用于与`unet`结合使用的调度器以去噪编码图像。可以是[DDPMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.DDPMScheduler)或[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)之一。

用于图像生成的管道。

这个模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。检查超类文档以了解为所有管道实现的通用方法（下载、保存、在特定设备上运行等）。

#### `__call__`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/ddpm/pipeline_ddpm.py#L45)

```py
( batch_size: int = 1 generator: Union = None num_inference_steps: int = 1000 output_type: Optional = 'pil' return_dict: bool = True ) → export const metadata = 'undefined';ImagePipelineOutput or tuple
```

参数

+   `batch_size`（`int`，*可选*，默认为1）— 要生成的图像数量。

+   `generator`（`torch.Generator`，*可选*）— 用于使生成具有确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。

+   `num_inference_steps`（`int`，*可选*，默认为1000）— 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。

+   `output_type`（`str`，*可选*，默认为`"pil"`）— 生成图像的输出格式。选择`PIL.Image`或`np.array`之间的一个。

+   `return_dict`（`bool`，*可选*，默认为`True`）— 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。

返回

[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)或`tuple`

如果`return_dict`为`True`，则返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)，否则返回一个`tuple`，其中第一个元素是生成的图像列表

用于生成的管道的调用函数。

示例：

```py
>>> from diffusers import DDPMPipeline

>>> # load model and scheduler
>>> pipe = DDPMPipeline.from_pretrained("google/ddpm-cat-256")

>>> # run pipeline in inference (sample random noise and denoise)
>>> image = pipe().images[0]

>>> # save image
>>> image.save("ddpm_generated_image.png")
```

## ImagePipelineOutput

### `class diffusers.ImagePipelineOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L116)

```py
( images: Union )
```

参数

+   `images` (`List[PIL.Image.Image]` 或 `np.ndarray`) — 长度为 `batch_size` 的去噪 PIL 图像列表或形状为 `(batch_size, height, width, num_channels)` 的 NumPy 数组。

图像管道的输出类。
