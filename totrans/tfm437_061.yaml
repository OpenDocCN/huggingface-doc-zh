- en: ğŸ¤— Transformers Notebooks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ¤— Transformers ç¬”è®°æœ¬
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/notebooks](https://huggingface.co/docs/transformers/v4.37.2/en/notebooks)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/notebooks](https://huggingface.co/docs/transformers/v4.37.2/en/notebooks)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: You can find here a list of the official notebooks provided by Hugging Face.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°Hugging Faceæä¾›çš„å®˜æ–¹ç¬”è®°æœ¬åˆ—è¡¨ã€‚
- en: Also, we would like to list here interesting content created by the community.
    If you wrote some notebook(s) leveraging ğŸ¤— Transformers and would like to be listed
    here, please open a Pull Request so it can be included under the Community notebooks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æƒ³åœ¨è¿™é‡Œåˆ—å‡ºç¤¾åŒºåˆ›å»ºçš„æœ‰è¶£å†…å®¹ã€‚å¦‚æœæ‚¨ç¼–å†™äº†ä¸€äº›åˆ©ç”¨ğŸ¤— Transformersçš„ç¬”è®°æœ¬ï¼Œå¹¶å¸Œæœ›åœ¨æ­¤åˆ—å‡ºï¼Œè¯·æäº¤ä¸€ä¸ªPull Requestï¼Œä»¥ä¾¿å°†å…¶åŒ…å«åœ¨ç¤¾åŒºç¬”è®°æœ¬ä¸‹ã€‚
- en: Hugging Faceâ€™s notebooks ğŸ¤—
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Faceçš„ç¬”è®°æœ¬ ğŸ¤—
- en: Documentation notebooks
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ–‡æ¡£ç¬”è®°
- en: 'You can open any page of the documentation as a notebook in Colab (there is
    a button directly on said pages) but they are also listed here if you need them:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨Colabä¸­å°†æ–‡æ¡£çš„ä»»ä½•é¡µé¢æ‰“å¼€ä¸ºç¬”è®°æœ¬ï¼ˆè¿™äº›é¡µé¢ä¸Šç›´æ¥æœ‰ä¸€ä¸ªæŒ‰é’®ï¼‰ï¼Œä½†å¦‚æœæ‚¨éœ€è¦ï¼Œå®ƒä»¬ä¹Ÿåœ¨è¿™é‡Œåˆ—å‡ºï¼š
- en: '| Notebook | Description |  |  |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| ç¬”è®°æœ¬ | æè¿° |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [Quicktour of the library](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)
    | A presentation of the various APIs in Transformers | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/en/transformers_doc/quicktour.ipynb)
    |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| [åº“çš„å¿«é€Ÿæµè§ˆ](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)
    | Transformersä¸­å„ç§APIçš„ä»‹ç» | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/en/transformers_doc/quicktour.ipynb)
    |'
- en: '| [Summary of the tasks](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    | How to run the models of the Transformers library task by task | [![Open in
    Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| [ä»»åŠ¡æ‘˜è¦](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    | å¦‚ä½•é€ä¸ªä»»åŠ¡è¿è¡ŒTransformersåº“çš„æ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    |'
- en: '| [Preprocessing data](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    | How to use a tokenizer to preprocess your data | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [æ•°æ®é¢„å¤„ç†](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    | å¦‚ä½•ä½¿ç”¨åˆ†è¯å™¨é¢„å¤„ç†æ•°æ® | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    |'
- en: '| [Fine-tuning a pretrained model](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    | How to use the Trainer to fine-tune a pretrained model | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| [å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    | å¦‚ä½•ä½¿ç”¨Trainerå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    |'
- en: '| [Summary of the tokenizers](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    | The differences between the tokenizers algorithm | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| [åˆ†è¯å™¨æ‘˜è¦](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    | åˆ†è¯å™¨ç®—æ³•ä¹‹é—´çš„å·®å¼‚ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    |'
- en: '| [Multilingual models](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    | How to use the multilingual models of the library | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| [å¤šè¯­è¨€æ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    | å¦‚ä½•ä½¿ç”¨åº“ä¸­çš„å¤šè¯­è¨€æ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    |'
- en: PyTorch Examples
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorchç¤ºä¾‹
- en: Natural Language Processing
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è‡ªç„¶è¯­è¨€å¤„ç†
- en: '| Notebook | Description |  |  |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| ç¬”è®°æœ¬ | æè¿° |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [Train your tokenizer](https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | How to train and use your very own tokenizer | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [è®­ç»ƒæ‚¨çš„åˆ†è¯å™¨](https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | å¦‚ä½•è®­ç»ƒå’Œä½¿ç”¨æ‚¨è‡ªå·±çš„åˆ†è¯å™¨ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    |'
- en: '| [Train your language model](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    | How to easily start using transformers | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [è®­ç»ƒæ‚¨çš„è¯­è¨€æ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    | å¦‚ä½•è½»æ¾å¼€å§‹ä½¿ç”¨transformers | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    |'
- en: '| [How to fine-tune a model on text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on any GLUE
    task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨æ–‡æœ¬åˆ†ç±»ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨ä»»ä½•GLUEä»»åŠ¡ä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ã€‚ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    |'
- en: '| [How to fine-tune a model on language modeling](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on a causal
    or masked LM task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨è¯­è¨€å»ºæ¨¡ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨å› æœæˆ–æ©ç LMä»»åŠ¡ä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ã€‚ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    |'
- en: '| [How to fine-tune a model on token classification](https://github.com/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on a token
    classification task (NER, PoS). | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨æ ‡è®°åˆ†ç±»ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨æ ‡è®°åˆ†ç±»ä»»åŠ¡ï¼ˆNERï¼ŒPoSï¼‰ä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ã€‚ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    |'
- en: '| [How to fine-tune a model on question answering](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on SQUAD. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨é—®ç­”ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨SQUADä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    |'
- en: '| [How to fine-tune a model on multiple choice](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on SWAG. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨å¤šé¡¹é€‰æ‹©ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨SWAGä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    |'
- en: '| [How to fine-tune a model on translation](https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on WMT. | [![Open
    in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation.ipynb)
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨ç¿»è¯‘ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨WMTä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation.ipynb)
    |'
- en: '| [How to fine-tune a model on summarization](https://github.com/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on XSUM. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨æ‘˜è¦ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨XSUMä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    |'
- en: '| [How to train a language model from scratch](https://github.com/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    | Highlight all the steps to effectively train Transformer model on custom data
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•ä»å¤´å¼€å§‹è®­ç»ƒè¯­è¨€æ¨¡å‹](https://github.com/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    | çªå‡ºæ˜¾ç¤ºæœ‰æ•ˆè®­ç»ƒTransformeræ¨¡å‹åœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šçš„æ‰€æœ‰æ­¥éª¤ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    |'
- en: '| [How to generate text](https://github.com/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    | How to use different decoding methods for language generation with transformers
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•ç”Ÿæˆæ–‡æœ¬](https://github.com/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    | å¦‚ä½•ä½¿ç”¨ä¸åŒçš„è§£ç æ–¹æ³•ä¸ºtransformersè¿›è¡Œè¯­è¨€ç”Ÿæˆ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    |'
- en: '| [How to generate text (with constraints)](https://github.com/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    | How to guide language generation with user-provided constraints | [![Open in
    Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•ç”Ÿæˆæ–‡æœ¬ï¼ˆå¸¦çº¦æŸï¼‰](https://github.com/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    | å¦‚ä½•é€šè¿‡ç”¨æˆ·æä¾›çš„çº¦æŸæ¥å¼•å¯¼è¯­è¨€ç”Ÿæˆ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    |'
- en: '| [Reformer](https://github.com/huggingface/blog/blob/main/notebooks/03_reformer.ipynb)
    | How Reformer pushes the limits of language modeling | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| [Reformer](https://github.com/huggingface/blog/blob/main/notebooks/03_reformer.ipynb)
    | Reformerå¦‚ä½•æ¨åŠ¨è¯­è¨€å»ºæ¨¡çš„æé™ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)
    |'
- en: Computer Vision
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è®¡ç®—æœºè§†è§‰
- en: '| Notebook | Description |  |  |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| ç¬”è®°æœ¬ | æè¿° |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [How to fine-tune a model on image classification (Torchvision)](https://github.com/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    | Show how to preprocess the data using Torchvision and fine-tune any pretrained
    Vision model on Image Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨å›¾åƒåˆ†ç±»ä¸Šå¾®è°ƒæ¨¡å‹ï¼ˆTorchvisionï¼‰](https://github.com/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    | å±•ç¤ºå¦‚ä½•ä½¿ç”¨Torchvisioné¢„å¤„ç†æ•°æ®å¹¶åœ¨å›¾åƒåˆ†ç±»ä¸Šå¾®è°ƒä»»ä½•é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    |'
- en: '| [How to fine-tune a model on image classification (Albumentations)](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    | Show how to preprocess the data using Albumentations and fine-tune any pretrained
    Vision model on Image Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨å›¾åƒåˆ†ç±»ä¸Šå¾®è°ƒæ¨¡å‹ï¼ˆAlbumentationsï¼‰](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    | å±•ç¤ºå¦‚ä½•ä½¿ç”¨Albumentationsé¢„å¤„ç†æ•°æ®å¹¶åœ¨å›¾åƒåˆ†ç±»ä¸Šå¾®è°ƒä»»ä½•é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    |'
- en: '| [How to fine-tune a model on image classification (Kornia)](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    | Show how to preprocess the data using Kornia and fine-tune any pretrained Vision
    model on Image Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨å›¾åƒåˆ†ç±»ä¸Šå¾®è°ƒæ¨¡å‹ï¼ˆKorniaï¼‰](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    | å±•ç¤ºå¦‚ä½•ä½¿ç”¨Korniaé¢„å¤„ç†æ•°æ®å¹¶åœ¨å›¾åƒåˆ†ç±»ä¸Šå¾®è°ƒä»»ä½•é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    |'
- en: '| [How to perform zero-shot object detection with OWL-ViT](https://github.com/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    | Show how to perform zero-shot object detection on images with text queries |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•ä½¿ç”¨OWL-ViTè¿›è¡Œé›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹](https://github.com/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    | å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–‡æœ¬æŸ¥è¯¢åœ¨å›¾åƒä¸Šæ‰§è¡Œé›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    |'
- en: '| [How to fine-tune an image captioning model](https://github.com/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    | Show how to fine-tune BLIP for image captioning on a custom dataset | [![Open
    in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•å¾®è°ƒå›¾åƒå­—å¹•æ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    | å±•ç¤ºå¦‚ä½•åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šå¾®è°ƒBLIPä»¥è¿›è¡Œå›¾åƒå­—å¹• | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    |'
- en: '| [How to build an image similarity system with Transformers](https://github.com/huggingface/notebooks/blob/main/examples/image_similarity.ipynb)
    | Show how to build an image similarity system | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_similarity.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_similarity.ipynb)
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a SegFormer model on semantic segmentation](https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained SegFormer model on
    Semantic Segmentation | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a VideoMAE model on video classification](https://github.com/huggingface/notebooks/blob/main/examples/video_classification.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained VideoMAE model on
    Video Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/video_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/video_classification.ipynb)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: Audio
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a speech recognition model in English](https://github.com/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained Speech model on TIMIT
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a speech recognition model in any language](https://github.com/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb)
    | Show how to preprocess the data and fine-tune a multi-lingually pretrained speech
    model on Common Voice | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb)
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on audio classification](https://github.com/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained Speech model on Keyword
    Spotting | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: Biological Sequences
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a pre-trained protein model](https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb)
    | See how to tokenize proteins and fine-tune a large pre-trained protein â€œlanguageâ€
    model | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb)
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
- en: '| [How to generate protein folds](https://github.com/huggingface/notebooks/blob/main/examples/protein_folding.ipynb)
    | See how to go from protein sequence to a full protein model and PDB file | [![Open
    in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_folding.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_folding.ipynb)
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a Nucleotide Transformer model](https://github.com/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling.ipynb)
    | See how to tokenize DNA and fine-tune a large pre-trained DNA â€œlanguageâ€ model
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling.ipynb)
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: '| [Fine-tune a Nucleotide Transformer model with LoRA](https://github.com/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling_with_peft.ipynb)
    | Train even larger DNA models in a memory-efficient way | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling_with_peft.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling_with_peft.ipynb)
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: Other modalities
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| [Probabilistic Time Series Forecasting](https://github.com/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb)
    | See how to train Time Series Transformer on a custom dataset | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb)
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: Utility notebooks
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| [How to export model to ONNX](https://github.com/huggingface/notebooks/blob/main/examples/onnx-export.ipynb)
    | Highlight how to export and run inference workloads through ONNX |  |  |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| [How to use Benchmarks](https://github.com/huggingface/notebooks/blob/main/examples/benchmark.ipynb)
    | How to benchmark models with transformers | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/benchmark.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/benchmark.ipynb)
    |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: TensorFlow Examples
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Natural Language Processing
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| [Train your tokenizer](https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | How to train and use your very own tokenizer | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| [Train your language model](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch-tf.ipynb)
    | How to easily start using transformers | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch-tf.ipynb)
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on any GLUE
    task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)
    |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on language modeling](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on a causal
    or masked LM task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on token classification](https://github.com/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on a token
    classification task (NER, PoS). | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)
    |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on question answering](https://github.com/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on SQUAD. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on multiple choice](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on SWAG. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨å¤šé¡¹é€‰æ‹©ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨SWAGä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    |'
- en: '| [How to fine-tune a model on translation](https://github.com/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on WMT. | [![Open
    in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨ç¿»è¯‘ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨WMTä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    |'
- en: '| [How to fine-tune a model on summarization](https://github.com/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on XSUM. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨æ‘˜è¦ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨XSUMä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    |'
- en: Computer Vision
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è®¡ç®—æœºè§†è§‰
- en: '| Notebook | Description |  |  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| ç¬”è®°æœ¬ | æè¿° |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [How to fine-tune a model on image classification](https://github.com/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    | Show how to preprocess the data and fine-tune any pretrained Vision model on
    Image Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨å›¾åƒåˆ†ç±»ä¸Šå¾®è°ƒæ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨å›¾åƒåˆ†ç±»ä¸Šå¾®è°ƒä»»ä½•é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    |'
- en: '| [How to fine-tune a SegFormer model on semantic segmentation](https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained SegFormer model on
    Semantic Segmentation | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•åœ¨è¯­ä¹‰åˆ†å‰²ä¸Šå¾®è°ƒSegFormeræ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    | å±•ç¤ºå¦‚ä½•é¢„å¤„ç†æ•°æ®å¹¶åœ¨è¯­ä¹‰åˆ†å‰²ä¸Šå¾®è°ƒé¢„è®­ç»ƒçš„SegFormeræ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    |'
- en: Biological Sequences
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç”Ÿç‰©åºåˆ—
- en: '| Notebook | Description |  |  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| ç¬”è®°æœ¬ | æè¿° |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [How to fine-tune a pre-trained protein model](https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    | See how to tokenize proteins and fine-tune a large pre-trained protein â€œlanguageâ€
    model | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| [å¦‚ä½•å¾®è°ƒé¢„è®­ç»ƒçš„è›‹ç™½è´¨æ¨¡å‹](https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    | æŸ¥çœ‹å¦‚ä½•å¯¹è›‹ç™½è´¨è¿›è¡Œæ ‡è®°åŒ–ï¼Œå¹¶å¾®è°ƒä¸€ä¸ªå¤§å‹é¢„è®­ç»ƒçš„è›‹ç™½è´¨â€œè¯­è¨€â€æ¨¡å‹ | [![åœ¨Colabä¸­æ‰“å¼€](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    | [![åœ¨AWS Studioä¸­æ‰“å¼€](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    |'
- en: Utility notebooks
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å®ç”¨ç¬”è®°æœ¬
- en: '| Notebook | Description |  |  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| ç¬”è®°æœ¬ | æè¿° |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [How to train TF/Keras models on TPU](https://github.com/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb)
    | See how to train at high speed on Googleâ€™s TPU hardware | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb)
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
- en: Optimum notebooks
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ğŸ¤— [Optimum](https://github.com/huggingface/optimum) is an extension of ğŸ¤— Transformers,
    providing a set of performance optimization tools enabling maximum efficiency
    to train and run models on targeted hardwares.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
- en: '| [How to quantize a model with ONNX Runtime for text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb)
    | Show how to apply static and dynamic quantization on a model using [ONNX Runtime](https://github.com/microsoft/onnxruntime)
    for any GLUE task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb)
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
- en: '| [How to quantize a model with Intel Neural Compressor for text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb)
    | Show how to apply static, dynamic and aware training quantization on a model
    using [Intel Neural Compressor (INC)](https://github.com/intel/neural-compressor)
    for any GLUE task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb)
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on text classification with ONNX Runtime](https://github.com/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb)
    | Show how to preprocess the data and fine-tune a model on any GLUE task using
    [ONNX Runtime](https://github.com/microsoft/onnxruntime). | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb)
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on summarization with ONNX Runtime](https://github.com/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb)
    | Show how to preprocess the data and fine-tune a model on XSUM using [ONNX Runtime](https://github.com/microsoft/onnxruntime).
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb)
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
- en: 'Community notebooks:'
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: More notebooks developed by the community are available [here](https://hf.co/docs/transformers/community#community-notebooks).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
