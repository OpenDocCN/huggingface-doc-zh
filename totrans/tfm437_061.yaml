- en: 🤗 Transformers Notebooks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🤗 Transformers 笔记本
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/notebooks](https://huggingface.co/docs/transformers/v4.37.2/en/notebooks)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/notebooks](https://huggingface.co/docs/transformers/v4.37.2/en/notebooks)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: You can find here a list of the official notebooks provided by Hugging Face.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里找到Hugging Face提供的官方笔记本列表。
- en: Also, we would like to list here interesting content created by the community.
    If you wrote some notebook(s) leveraging 🤗 Transformers and would like to be listed
    here, please open a Pull Request so it can be included under the Community notebooks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还想在这里列出社区创建的有趣内容。如果您编写了一些利用🤗 Transformers的笔记本，并希望在此列出，请提交一个Pull Request，以便将其包含在社区笔记本下。
- en: Hugging Face’s notebooks 🤗
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Face的笔记本 🤗
- en: Documentation notebooks
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文档笔记
- en: 'You can open any page of the documentation as a notebook in Colab (there is
    a button directly on said pages) but they are also listed here if you need them:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在Colab中将文档的任何页面打开为笔记本（这些页面上直接有一个按钮），但如果您需要，它们也在这里列出：
- en: '| Notebook | Description |  |  |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本 | 描述 |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [Quicktour of the library](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)
    | A presentation of the various APIs in Transformers | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/en/transformers_doc/quicktour.ipynb)
    |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| [库的快速浏览](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)
    | Transformers中各种API的介绍 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/en/transformers_doc/quicktour.ipynb)
    |'
- en: '| [Summary of the tasks](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    | How to run the models of the Transformers library task by task | [![Open in
    Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| [任务摘要](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    | 如何逐个任务运行Transformers库的模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)
    |'
- en: '| [Preprocessing data](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    | How to use a tokenizer to preprocess your data | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [数据预处理](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    | 如何使用分词器预处理数据 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)
    |'
- en: '| [Fine-tuning a pretrained model](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    | How to use the Trainer to fine-tune a pretrained model | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| [微调预训练模型](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    | 如何使用Trainer微调预训练模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)
    |'
- en: '| [Summary of the tokenizers](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    | The differences between the tokenizers algorithm | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| [分词器摘要](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    | 分词器算法之间的差异 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)
    |'
- en: '| [Multilingual models](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    | How to use the multilingual models of the library | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| [多语言模型](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    | 如何使用库中的多语言模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)
    |'
- en: PyTorch Examples
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch示例
- en: Natural Language Processing
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自然语言处理
- en: '| Notebook | Description |  |  |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本 | 描述 |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [Train your tokenizer](https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | How to train and use your very own tokenizer | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [训练您的分词器](https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | 如何训练和使用您自己的分词器 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    |'
- en: '| [Train your language model](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    | How to easily start using transformers | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [训练您的语言模型](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    | 如何轻松开始使用transformers | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)
    |'
- en: '| [How to fine-tune a model on text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on any GLUE
    task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| [如何在文本分类上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    | 展示如何预处理数据并在任何GLUE任务上微调预训练模型。 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)
    |'
- en: '| [How to fine-tune a model on language modeling](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on a causal
    or masked LM task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| [如何在语言建模上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    | 展示如何预处理数据并在因果或掩码LM任务上微调预训练模型。 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)
    |'
- en: '| [How to fine-tune a model on token classification](https://github.com/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on a token
    classification task (NER, PoS). | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| [如何在标记分类上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    | 展示如何预处理数据并在标记分类任务（NER，PoS）上微调预训练模型。 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)
    |'
- en: '| [How to fine-tune a model on question answering](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on SQUAD. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| [如何在问答上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    | 展示如何预处理数据并在SQUAD上微调预训练模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
    |'
- en: '| [How to fine-tune a model on multiple choice](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on SWAG. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| [如何在多项选择上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    | 展示如何预处理数据并在SWAG上微调预训练模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
    |'
- en: '| [How to fine-tune a model on translation](https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on WMT. | [![Open
    in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation.ipynb)
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| [如何在翻译上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb)
    | 展示如何预处理数据并在WMT上微调预训练模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation.ipynb)
    |'
- en: '| [How to fine-tune a model on summarization](https://github.com/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on XSUM. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| [如何在摘要上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    | 展示如何预处理数据并在XSUM上微调预训练模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)
    |'
- en: '| [How to train a language model from scratch](https://github.com/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    | Highlight all the steps to effectively train Transformer model on custom data
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| [如何从头开始训练语言模型](https://github.com/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    | 突出显示有效训练Transformer模型在自定义数据上的所有步骤 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)
    |'
- en: '| [How to generate text](https://github.com/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    | How to use different decoding methods for language generation with transformers
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| [如何生成文本](https://github.com/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    | 如何使用不同的解码方法为transformers进行语言生成 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)
    |'
- en: '| [How to generate text (with constraints)](https://github.com/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    | How to guide language generation with user-provided constraints | [![Open in
    Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| [如何生成文本（带约束）](https://github.com/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    | 如何通过用户提供的约束来引导语言生成 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)
    |'
- en: '| [Reformer](https://github.com/huggingface/blog/blob/main/notebooks/03_reformer.ipynb)
    | How Reformer pushes the limits of language modeling | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| [Reformer](https://github.com/huggingface/blog/blob/main/notebooks/03_reformer.ipynb)
    | Reformer如何推动语言建模的极限 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)
    |'
- en: Computer Vision
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: '| Notebook | Description |  |  |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本 | 描述 |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [How to fine-tune a model on image classification (Torchvision)](https://github.com/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    | Show how to preprocess the data using Torchvision and fine-tune any pretrained
    Vision model on Image Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| [如何在图像分类上微调模型（Torchvision）](https://github.com/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    | 展示如何使用Torchvision预处理数据并在图像分类上微调任何预训练的视觉模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)
    |'
- en: '| [How to fine-tune a model on image classification (Albumentations)](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    | Show how to preprocess the data using Albumentations and fine-tune any pretrained
    Vision model on Image Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| [如何在图像分类上微调模型（Albumentations）](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    | 展示如何使用Albumentations预处理数据并在图像分类上微调任何预训练的视觉模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)
    |'
- en: '| [How to fine-tune a model on image classification (Kornia)](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    | Show how to preprocess the data using Kornia and fine-tune any pretrained Vision
    model on Image Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| [如何在图像分类上微调模型（Kornia）](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    | 展示如何使用Kornia预处理数据并在图像分类上微调任何预训练的视觉模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)
    |'
- en: '| [How to perform zero-shot object detection with OWL-ViT](https://github.com/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    | Show how to perform zero-shot object detection on images with text queries |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| [如何使用OWL-ViT进行零样本目标检测](https://github.com/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    | 展示如何使用文本查询在图像上执行零样本目标检测 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)
    |'
- en: '| [How to fine-tune an image captioning model](https://github.com/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    | Show how to fine-tune BLIP for image captioning on a custom dataset | [![Open
    in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| [如何微调图像字幕模型](https://github.com/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    | 展示如何在自定义数据集上微调BLIP以进行图像字幕 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)
    |'
- en: '| [How to build an image similarity system with Transformers](https://github.com/huggingface/notebooks/blob/main/examples/image_similarity.ipynb)
    | Show how to build an image similarity system | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_similarity.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_similarity.ipynb)
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a SegFormer model on semantic segmentation](https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained SegFormer model on
    Semantic Segmentation | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a VideoMAE model on video classification](https://github.com/huggingface/notebooks/blob/main/examples/video_classification.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained VideoMAE model on
    Video Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/video_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/video_classification.ipynb)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: Audio
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a speech recognition model in English](https://github.com/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained Speech model on TIMIT
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a speech recognition model in any language](https://github.com/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb)
    | Show how to preprocess the data and fine-tune a multi-lingually pretrained speech
    model on Common Voice | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb)
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on audio classification](https://github.com/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained Speech model on Keyword
    Spotting | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: Biological Sequences
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a pre-trained protein model](https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb)
    | See how to tokenize proteins and fine-tune a large pre-trained protein “language”
    model | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb)
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
- en: '| [How to generate protein folds](https://github.com/huggingface/notebooks/blob/main/examples/protein_folding.ipynb)
    | See how to go from protein sequence to a full protein model and PDB file | [![Open
    in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_folding.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_folding.ipynb)
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a Nucleotide Transformer model](https://github.com/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling.ipynb)
    | See how to tokenize DNA and fine-tune a large pre-trained DNA “language” model
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling.ipynb)
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: '| [Fine-tune a Nucleotide Transformer model with LoRA](https://github.com/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling_with_peft.ipynb)
    | Train even larger DNA models in a memory-efficient way | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling_with_peft.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling_with_peft.ipynb)
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: Other modalities
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| [Probabilistic Time Series Forecasting](https://github.com/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb)
    | See how to train Time Series Transformer on a custom dataset | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb)
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: Utility notebooks
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| [How to export model to ONNX](https://github.com/huggingface/notebooks/blob/main/examples/onnx-export.ipynb)
    | Highlight how to export and run inference workloads through ONNX |  |  |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| [How to use Benchmarks](https://github.com/huggingface/notebooks/blob/main/examples/benchmark.ipynb)
    | How to benchmark models with transformers | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/benchmark.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/benchmark.ipynb)
    |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: TensorFlow Examples
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Natural Language Processing
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| [Train your tokenizer](https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | How to train and use your very own tokenizer | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| [Train your language model](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch-tf.ipynb)
    | How to easily start using transformers | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch-tf.ipynb)
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on any GLUE
    task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)
    |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on language modeling](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on a causal
    or masked LM task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on token classification](https://github.com/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on a token
    classification task (NER, PoS). | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)
    |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on question answering](https://github.com/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on SQUAD. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on multiple choice](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on SWAG. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| [如何在多项选择上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    | 展示如何预处理数据并在SWAG上微调预训练模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)
    |'
- en: '| [How to fine-tune a model on translation](https://github.com/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on WMT. | [![Open
    in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| [如何在翻译上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    | 展示如何预处理数据并在WMT上微调预训练模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)
    |'
- en: '| [How to fine-tune a model on summarization](https://github.com/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained model on XSUM. |
    [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| [如何在摘要上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    | 展示如何预处理数据并在XSUM上微调预训练模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)
    |'
- en: Computer Vision
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: '| Notebook | Description |  |  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本 | 描述 |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [How to fine-tune a model on image classification](https://github.com/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    | Show how to preprocess the data and fine-tune any pretrained Vision model on
    Image Classification | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| [如何在图像分类上微调模型](https://github.com/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    | 展示如何预处理数据并在图像分类上微调任何预训练的视觉模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)
    |'
- en: '| [How to fine-tune a SegFormer model on semantic segmentation](https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    | Show how to preprocess the data and fine-tune a pretrained SegFormer model on
    Semantic Segmentation | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| [如何在语义分割上微调SegFormer模型](https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    | 展示如何预处理数据并在语义分割上微调预训练的SegFormer模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)
    |'
- en: Biological Sequences
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生物序列
- en: '| Notebook | Description |  |  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本 | 描述 |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [How to fine-tune a pre-trained protein model](https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    | See how to tokenize proteins and fine-tune a large pre-trained protein “language”
    model | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| [如何微调预训练的蛋白质模型](https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    | 查看如何对蛋白质进行标记化，并微调一个大型预训练的蛋白质“语言”模型 | [![在Colab中打开](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    | [![在AWS Studio中打开](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb)
    |'
- en: Utility notebooks
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实用笔记本
- en: '| Notebook | Description |  |  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本 | 描述 |  |  |'
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | --: |'
- en: '| [How to train TF/Keras models on TPU](https://github.com/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb)
    | See how to train at high speed on Google’s TPU hardware | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb)
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
- en: Optimum notebooks
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 🤗 [Optimum](https://github.com/huggingface/optimum) is an extension of 🤗 Transformers,
    providing a set of performance optimization tools enabling maximum efficiency
    to train and run models on targeted hardwares.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '| Notebook | Description |  |  |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- | --: |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
- en: '| [How to quantize a model with ONNX Runtime for text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb)
    | Show how to apply static and dynamic quantization on a model using [ONNX Runtime](https://github.com/microsoft/onnxruntime)
    for any GLUE task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb)
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
- en: '| [How to quantize a model with Intel Neural Compressor for text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb)
    | Show how to apply static, dynamic and aware training quantization on a model
    using [Intel Neural Compressor (INC)](https://github.com/intel/neural-compressor)
    for any GLUE task. | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb)
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on text classification with ONNX Runtime](https://github.com/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb)
    | Show how to preprocess the data and fine-tune a model on any GLUE task using
    [ONNX Runtime](https://github.com/microsoft/onnxruntime). | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb)
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
- en: '| [How to fine-tune a model on summarization with ONNX Runtime](https://github.com/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb)
    | Show how to preprocess the data and fine-tune a model on XSUM using [ONNX Runtime](https://github.com/microsoft/onnxruntime).
    | [![Open in Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb)
    | [![Open in AWS Studio](../Images/b853c984b1efccec36ff5b904fac75b9.png)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb)
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
- en: 'Community notebooks:'
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: More notebooks developed by the community are available [here](https://hf.co/docs/transformers/community#community-notebooks).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
