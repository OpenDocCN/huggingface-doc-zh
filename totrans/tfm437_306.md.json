["```py\n>>> from datasets import load_dataset, Audio\n>>> from transformers import EncodecModel, AutoProcessor\n>>> librispeech_dummy = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n\n>>> model = EncodecModel.from_pretrained(\"facebook/encodec_24khz\")\n>>> processor = AutoProcessor.from_pretrained(\"facebook/encodec_24khz\")\n>>> librispeech_dummy = librispeech_dummy.cast_column(\"audio\", Audio(sampling_rate=processor.sampling_rate))\n>>> audio_sample = librispeech_dummy[-1][\"audio\"][\"array\"]\n>>> inputs = processor(raw_audio=audio_sample, sampling_rate=processor.sampling_rate, return_tensors=\"pt\")\n\n>>> encoder_outputs = model.encode(inputs[\"input_values\"], inputs[\"padding_mask\"])\n>>> audio_values = model.decode(encoder_outputs.audio_codes, encoder_outputs.audio_scales, inputs[\"padding_mask\"])[0]\n>>> # or the equivalent with a forward pass\n>>> audio_values = model(inputs[\"input_values\"], inputs[\"padding_mask\"]).audio_values\n```", "```py\n>>> from transformers import EncodecModel, EncodecConfig\n\n>>> # Initializing a \"facebook/encodec_24khz\" style configuration\n>>> configuration = EncodecConfig()\n\n>>> # Initializing a model (with random weights) from the \"facebook/encodec_24khz\" style configuration\n>>> model = EncodecModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from datasets import load_dataset\n>>> from transformers import AutoProcessor, EncodecModel\n\n>>> dataset = load_dataset(\"ashraq/esc50\")\n>>> audio_sample = dataset[\"train\"][\"audio\"][0][\"array\"]\n\n>>> model_id = \"facebook/encodec_24khz\"\n>>> model = EncodecModel.from_pretrained(model_id)\n>>> processor = AutoProcessor.from_pretrained(model_id)\n\n>>> inputs = processor(raw_audio=audio_sample, return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> audio_codes = outputs.audio_codes\n>>> audio_values = outputs.audio_values\n```"]