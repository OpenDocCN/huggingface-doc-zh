- en: How Huggy works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/learn/deep-rl-course/unitbonus1/how-huggy-works](https://huggingface.co/learn/deep-rl-course/unitbonus1/how-huggy-works)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/deep-rl-course/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/start.c0547f01.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/scheduler.37c15a92.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/singletons.b4cd11ef.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.18351ede.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/paths.3cd722f3.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/app.41e0adab.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.7cb9c9b8.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/0.b906e680.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/90.f59495f6.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Heading.d3928e2a.js">
  prefs: []
  type: TYPE_NORMAL
- en: Huggy is a Deep Reinforcement Learning environment made by Hugging Face and
    based on [Puppo the Corgi, a project by the Unity MLAgents team](https://blog.unity.com/technology/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit).
    This environment was created using the [Unity game engine](https://unity.com/)
    and [MLAgents](https://github.com/Unity-Technologies/ml-agents). ML-Agents is
    a toolkit for the game engine from Unity that allows us to **create environments
    using Unity or use pre-made environments to train our agents**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy](../Images/57b557f6c646b773c9c9c0173a5adf4f.png)'
  prefs: []
  type: TYPE_IMG
- en: In this environment we aim to train Huggy to **fetch the stick we throw. This
    means he needs to move correctly toward the stick**.
  prefs: []
  type: TYPE_NORMAL
- en: The State Space, what Huggy perceives.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Huggy doesn’t “see” his environment. Instead, we provide him information about
    the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: The target (stick) position
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The relative position between himself and the target
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The orientation of his legs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given all this information, Huggy can **use his policy to determine which action
    to take next to fulfill his goal**.
  prefs: []
  type: TYPE_NORMAL
- en: The Action Space, what moves Huggy can perform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Huggy action](../Images/df930c385e7a4439c314cb4356dc2db4.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Joint motors drive Huggy’s legs**. This means that to get the target, Huggy
    needs to **learn to rotate the joint motors of each of his legs correctly so he
    can move**.'
  prefs: []
  type: TYPE_NORMAL
- en: The Reward Function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The reward function is designed so that **Huggy will fulfill his goal**: fetch
    the stick.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember that one of the foundations of Reinforcement Learning is the *reward
    hypothesis*: a goal can be described as the **maximization of the expected cumulative
    reward**.'
  prefs: []
  type: TYPE_NORMAL
- en: Here, our goal is that Huggy **goes towards the stick but without spinning too
    much**. Hence, our reward function must translate this goal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our reward function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy reward function](../Images/02ce46ce021fe61f090b79e963e5fc0e.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Orientation bonus*: we **reward him for getting close to the target**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time penalty*: a fixed-time penalty given at every action to **force him to
    get to the stick as fast as possible**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Rotation penalty*: we penalize Huggy if **he spins too much and turns too
    quickly**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Getting to the target reward*: we reward Huggy for **reaching the target**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to see what this reward function looks like mathematically, check
    [Puppo the Corgi presentation](https://blog.unity.com/technology/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit).
  prefs: []
  type: TYPE_NORMAL
- en: Train Huggy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Huggy aims **to learn to run correctly and as fast as possible toward the goal**.
    To do that, at every step and given the environment observation, he needs to decide
    how to rotate each joint motor of his legs to move correctly (not spinning too
    much) and towards the goal.
  prefs: []
  type: TYPE_NORMAL
- en: 'The training loop looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy loop](../Images/0086bd47ee63acbf18ec6dafecaadb0d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The training environment looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy training env](../Images/2835c90e4b4250494efe778ec6a42cfd.png)'
  prefs: []
  type: TYPE_IMG
- en: It’s a place where a **stick is spawned randomly**. When Huggy reaches it, the
    stick get spawned somewhere else. We built **multiple copies of the environment
    for the training**. This helps speed up the training by providing more diverse
    experiences.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have the big picture of the environment, you’re ready to train
    Huggy to fetch the stick.
  prefs: []
  type: TYPE_NORMAL
- en: To do that, we’re going to use [MLAgents](https://github.com/Unity-Technologies/ml-agents).
    Don’t worry if you have never used it before. In this unit we’ll use Google Colab
    to train Huggy, and then you’ll be able to load your trained Huggy and play with
    him directly in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: In a future unit, we will study MLAgents more in-depth and see how it works.
    But for now, we keep things simple by just using the provided implementation.
  prefs: []
  type: TYPE_NORMAL
