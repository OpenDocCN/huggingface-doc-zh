# å¤„ç†å™¨

> åŸæ–‡ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/main_classes/processors`](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/processors)

åœ¨ Transformers åº“ä¸­ï¼Œå¤„ç†å™¨å¯ä»¥æœ‰ä¸¤ç§ä¸åŒçš„å«ä¹‰ï¼š

+   ä¸ºå¤šæ¨¡æ€æ¨¡å‹é¢„å¤„ç†è¾“å…¥çš„å¯¹è±¡ï¼Œå¦‚ Wav2Vec2ï¼ˆè¯­éŸ³å’Œæ–‡æœ¬ï¼‰æˆ– CLIPï¼ˆæ–‡æœ¬å’Œè§†è§‰ï¼‰

+   åœ¨åº“çš„æ—§ç‰ˆæœ¬ä¸­ç”¨äºé¢„å¤„ç† GLUE æˆ– SQUAD æ•°æ®çš„å·²å¼ƒç”¨å¯¹è±¡ã€‚

## å¤šæ¨¡æ€å¤„ç†å™¨

ä»»ä½•å¤šæ¨¡æ€æ¨¡å‹éƒ½éœ€è¦ä¸€ä¸ªå¯¹è±¡æ¥ç¼–ç æˆ–è§£ç å°†å¤šä¸ªæ¨¡æ€ï¼ˆæ–‡æœ¬ã€è§†è§‰å’ŒéŸ³é¢‘ï¼‰ç»„åˆåœ¨ä¸€èµ·çš„æ•°æ®ã€‚è¿™ç”±ç§°ä¸ºå¤„ç†å™¨çš„å¯¹è±¡å¤„ç†ï¼Œè¿™äº›å¯¹è±¡å°†å¤šä¸ªå¤„ç†å¯¹è±¡ï¼ˆå¦‚æ–‡æœ¬æ¨¡æ€çš„åˆ†è¯å™¨ã€è§†è§‰çš„å›¾åƒå¤„ç†å™¨å’ŒéŸ³é¢‘çš„ç‰¹å¾æå–å™¨ï¼‰ç»„åˆåœ¨ä¸€èµ·ã€‚

è¿™äº›å¤„ç†å™¨ç»§æ‰¿è‡ªå®ç°ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½çš„ä»¥ä¸‹åŸºç±»ï¼š

### `class transformers.ProcessorMixin`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L56)

```py
( *args **kwargs )
```

è¿™æ˜¯ä¸€ä¸ªæ··åˆç±»ï¼Œç”¨äºä¸ºæ‰€æœ‰å¤„ç†å™¨ç±»æä¾›ä¿å­˜/åŠ è½½åŠŸèƒ½ã€‚

#### `from_args_and_dict`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L365)

```py
( args processor_dict: Dict **kwargs ) â†’ export const metadata = 'undefined';~processing_utils.ProcessingMixin
```

å‚æ•°

+   `processor_dict` (`Dict[str, Any]`) â€” å°†ç”¨äºå®ä¾‹åŒ–å¤„ç†å™¨å¯¹è±¡çš„å­—å…¸ã€‚å¯ä»¥é€šè¿‡åˆ©ç”¨`~processing_utils.ProcessingMixin.to_dict`æ–¹æ³•ä»é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ä¸­æ£€ç´¢è¿™æ ·çš„å­—å…¸ã€‚

+   `kwargs` (`Dict[str, Any]`) â€” ç”¨äºåˆå§‹åŒ–å¤„ç†å™¨å¯¹è±¡çš„å…¶ä»–å‚æ•°ã€‚

è¿”å›

`~processing_utils.ProcessingMixin`

ä»è¿™äº›å‚æ•°å®ä¾‹åŒ–çš„å¤„ç†å™¨å¯¹è±¡ã€‚

ä» Python å‚æ•°å­—å…¸ä¸­å®ä¾‹åŒ–`~processing_utils.ProcessingMixin`ç±»å‹ã€‚

#### `from_pretrained`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)

```py
( pretrained_model_name_or_path: Union cache_dir: Union = None force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' **kwargs )
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str`æˆ–`os.PathLike`) â€” è¿™å¯ä»¥æ˜¯ï¼š

    +   ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œé¢„è®­ç»ƒç‰¹å¾æå–å™¨çš„*æ¨¡å‹æ ‡è¯†*ï¼Œæ‰˜ç®¡åœ¨ huggingface.co ä¸Šçš„æ¨¡å‹ä»“åº“å†…ã€‚æœ‰æ•ˆçš„æ¨¡å‹æ ‡è¯†å¯ä»¥ä½äºæ ¹çº§åˆ«ï¼Œå¦‚`bert-base-uncased`ï¼Œæˆ–è€…åœ¨ç”¨æˆ·æˆ–ç»„ç»‡åç§°ä¸‹å‘½åç©ºé—´åŒ–ï¼Œå¦‚`dbmdz/bert-base-german-cased`ã€‚

    +   ä¸€ä¸ª*ç›®å½•*çš„è·¯å¾„ï¼Œå…¶ä¸­åŒ…å«ä½¿ç”¨ save_pretrained()æ–¹æ³•ä¿å­˜çš„ç‰¹å¾æå–å™¨æ–‡ä»¶ï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/`ã€‚

    +   ä¿å­˜çš„ç‰¹å¾æå–å™¨ JSON *æ–‡ä»¶*çš„è·¯å¾„æˆ– URLï¼Œä¾‹å¦‚ï¼Œ`./my_model_directory/preprocessor_config.json`ã€‚**kwargs â€” ä¼ é€’ç»™ from_pretrained()å’Œ`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`çš„å…¶ä»–å…³é”®å­—å‚æ•°ã€‚

å®ä¾‹åŒ–ä¸é¢„è®­ç»ƒæ¨¡å‹ç›¸å…³è”çš„å¤„ç†å™¨ã€‚

è¿™ä¸ªç±»æ–¹æ³•åªæ˜¯è°ƒç”¨ç‰¹å¾æå–å™¨ from_pretrained()ã€å›¾åƒå¤„ç†å™¨ ImageProcessingMixin å’Œåˆ†è¯å™¨`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`æ–¹æ³•ã€‚è¯·å‚è€ƒä¸Šè¿°æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

#### `get_processor_dict`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L256)

```py
( pretrained_model_name_or_path: Union **kwargs ) â†’ export const metadata = 'undefined';Tuple[Dict, Dict]
```

å‚æ•°

+   `pretrained_model_name_or_path` (`str`æˆ–`os.PathLike`) â€” æˆ‘ä»¬æƒ³è¦å‚æ•°å­—å…¸çš„é¢„è®­ç»ƒæ£€æŸ¥ç‚¹çš„æ ‡è¯†ç¬¦ã€‚

+   `subfolder` (`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `""`) â€” å¦‚æœç›¸å…³æ–‡ä»¶ä½äº huggingface.co ä¸Šæ¨¡å‹å­˜å‚¨åº“çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œå¯ä»¥åœ¨æ­¤å¤„æŒ‡å®šæ–‡ä»¶å¤¹åç§°ã€‚

è¿”å›

`Tuple[Dict, Dict]`

å°†ç”¨äºå®ä¾‹åŒ–å¤„ç†å™¨å¯¹è±¡çš„å­—å…¸ã€‚

ä» `pretrained_model_name_or_path`ï¼Œè§£æä¸ºå‚æ•°å­—å…¸ï¼Œç”¨äºä½¿ç”¨ `from_args_and_dict` å®ä¾‹åŒ–ç±»å‹ä¸º `~processing_utils.ProcessingMixin` çš„å¤„ç†å™¨ã€‚

#### `push_to_hub`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/utils/hub.py#L755)

```py
( repo_id: str use_temp_dir: Optional = None commit_message: Optional = None private: Optional = None token: Union = None max_shard_size: Union = '5GB' create_pr: bool = False safe_serialization: bool = True revision: str = None commit_description: str = None tags: Optional = None **deprecated_kwargs )
```

å‚æ•°

+   `repo_id` (`str`) â€” è¦å°†å¤„ç†å™¨æ¨é€åˆ°çš„å­˜å‚¨åº“çš„åç§°ã€‚åœ¨æ¨é€åˆ°ç»™å®šç»„ç»‡æ—¶ï¼Œåº”åŒ…å«æ‚¨çš„ç»„ç»‡åç§°ã€‚

+   `use_temp_dir` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦ä½¿ç”¨ä¸´æ—¶ç›®å½•æ¥å­˜å‚¨åœ¨æ¨é€åˆ° Hub ä¹‹å‰ä¿å­˜çš„æ–‡ä»¶ã€‚å¦‚æœæ²¡æœ‰åä¸º `repo_id` çš„ç›®å½•ï¼Œåˆ™é»˜è®¤ä¸º `True`ï¼Œå¦åˆ™ä¸º `False`ã€‚

+   `commit_message` (`str`ï¼Œ*å¯é€‰*) â€” æ¨é€æ—¶è¦æäº¤çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º `"Upload processor"`ã€‚

+   `private` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦åº”è¯¥åˆ›å»ºçš„å­˜å‚¨åº“æ˜¯ç§æœ‰çš„ã€‚

+   `token` (`bool` æˆ– `str`ï¼Œ*å¯é€‰*) â€” ç”¨ä½œè¿œç¨‹æ–‡ä»¶çš„ HTTP bearer æˆæƒçš„ä»¤ç‰Œã€‚å¦‚æœä¸º `True`ï¼Œå°†ä½¿ç”¨è¿è¡Œ `huggingface-cli login` æ—¶ç”Ÿæˆçš„ä»¤ç‰Œï¼ˆå­˜å‚¨åœ¨ `~/.huggingface`ï¼‰ã€‚å¦‚æœæœªæŒ‡å®š `repo_url`ï¼Œåˆ™é»˜è®¤ä¸º `True`ã€‚

+   `max_shard_size` (`int` æˆ– `str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"5GB"`) â€” ä»…é€‚ç”¨äºæ¨¡å‹ã€‚åœ¨åˆ†ç‰‡ä¹‹å‰çš„æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°ã€‚ç„¶åï¼Œæ£€æŸ¥ç‚¹åˆ†ç‰‡çš„å¤§å°å°†å°äºæ­¤å¤§å°ã€‚å¦‚æœè¡¨ç¤ºä¸ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜¯æ•°å­—åè·Ÿä¸€ä¸ªå•ä½ï¼ˆå¦‚ `"5MB"`ï¼‰ã€‚æˆ‘ä»¬å°†å…¶é»˜è®¤ä¸º `"5GB"`ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥åœ¨å…è´¹çš„ Google Colab å®ä¾‹ä¸Šè½»æ¾åŠ è½½æ¨¡å‹ï¼Œè€Œä¸ä¼šå‡ºç°ä»»ä½• CPU OOM é—®é¢˜ã€‚

+   `create_pr` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`) â€” æ˜¯å¦åˆ›å»ºä¸€ä¸ªåŒ…å«ä¸Šä¼ æ–‡ä»¶çš„ PR æˆ–ç›´æ¥æäº¤ã€‚

+   `safe_serialization` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†æ¨¡å‹æƒé‡è½¬æ¢ä¸º safetensors æ ¼å¼ä»¥è¿›è¡Œæ›´å®‰å…¨çš„åºåˆ—åŒ–ã€‚

+   `revision` (`str`ï¼Œ*å¯é€‰*) â€” è¦å°†ä¸Šä¼ çš„æ–‡ä»¶æ¨é€åˆ°çš„åˆ†æ”¯ã€‚

+   `commit_description` (`str`ï¼Œ*å¯é€‰*) â€” å°†åˆ›å»ºçš„æäº¤çš„æè¿°

+   `tags` (`List[str]`ï¼Œ*å¯é€‰*) â€” è¦æ¨é€åˆ° Hub ä¸Šçš„æ ‡ç­¾åˆ—è¡¨ã€‚

å°†å¤„ç†å™¨æ–‡ä»¶ä¸Šä¼ åˆ° ğŸ¤— æ¨¡å‹ä¸­å¿ƒã€‚

ç¤ºä¾‹ï¼š

```py
from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("bert-base-cased")

# Push the processor to your namespace with the name "my-finetuned-bert".
processor.push_to_hub("my-finetuned-bert")

# Push the processor to an organization with the name "my-finetuned-bert".
processor.push_to_hub("huggingface/my-finetuned-bert")
```

#### `register_for_auto_class`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L471)

```py
( auto_class = 'AutoProcessor' )
```

å‚æ•°

+   `auto_class` (`str` æˆ– `type`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"AutoProcessor"`) â€” è¦å°†æ­¤æ–°ç‰¹å¾æå–å™¨æ³¨å†Œåˆ°çš„è‡ªåŠ¨ç±»ã€‚

å°†æ­¤ç±»æ³¨å†Œåˆ°ç»™å®šçš„è‡ªåŠ¨ç±»ä¸­ã€‚è¿™åº”è¯¥ä»…ç”¨äºè‡ªå®šä¹‰ç‰¹å¾æå–å™¨ï¼Œå› ä¸ºåº“ä¸­çš„ç‰¹å¾æå–å™¨å·²ç»ä¸ `AutoProcessor` æ˜ å°„ã€‚

æ­¤ API æ˜¯å®éªŒæ€§çš„ï¼Œå¯èƒ½åœ¨ä¸‹ä¸€ä¸ªç‰ˆæœ¬ä¸­æœ‰ä¸€äº›è½»å¾®çš„ç ´åæ€§æ›´æ”¹ã€‚

#### `save_pretrained`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)

```py
( save_directory push_to_hub: bool = False **kwargs )
```

å‚æ•°

+   `save_directory` (`str` æˆ– `os.PathLike`) â€” å°†ä¿å­˜ç‰¹å¾æå–å™¨ JSON æ–‡ä»¶å’Œåˆ†è¯å™¨æ–‡ä»¶çš„ç›®å½•ï¼ˆå¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™å°†åˆ›å»ºè¯¥ç›®å½•ï¼‰ã€‚

+   `push_to_hub` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `False`) â€” ä¿å­˜æ¨¡å‹åæ˜¯å¦å°†æ¨¡å‹æ¨é€åˆ° Hugging Face æ¨¡å‹ä¸­å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `repo_id` æŒ‡å®šè¦æ¨é€åˆ°çš„å­˜å‚¨åº“ï¼ˆå°†é»˜è®¤ä¸ºæ‚¨çš„å‘½åç©ºé—´ä¸­çš„ `save_directory` çš„åç§°ï¼‰ã€‚

+   `kwargs` (`Dict[str, Any]`ï¼Œ*å¯é€‰*) â€” ä¼ é€’ç»™ push_to_hub() æ–¹æ³•çš„å…¶ä»–å…³é”®å­—å‚æ•°ã€‚

ä¿å­˜æ­¤å¤„ç†å™¨çš„å±æ€§ï¼ˆç‰¹å¾æå–å™¨ã€åˆ†è¯å™¨ç­‰ï¼‰åˆ°æŒ‡å®šç›®å½•ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ from_pretrained() æ–¹æ³•é‡æ–°åŠ è½½ã€‚

è¿™ä¸ªç±»æ–¹æ³•åªæ˜¯è°ƒç”¨ save_pretrained() å’Œ save_pretrained()ã€‚è¯·å‚è€ƒä¸Šè¿°æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

#### `to_dict`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L102)

```py
( ) â†’ export const metadata = 'undefined';Dict[str, Any]
```

è¿”å›å€¼

`Dict[str, Any]`

åŒ…å«æ„æˆæ­¤å¤„ç†å™¨å®ä¾‹çš„æ‰€æœ‰å±æ€§çš„å­—å…¸ã€‚

å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸º Python å­—å…¸ã€‚

#### `to_json_file`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L151)

```py
( json_file_path: Union )
```

å‚æ•°

+   `json_file_path` (`str` æˆ– `os.PathLike`) â€” ä¿å­˜æ­¤å¤„ç†å™¨å®ä¾‹å‚æ•°çš„ JSON æ–‡ä»¶è·¯å¾„ã€‚

å°†æ­¤å®ä¾‹ä¿å­˜åˆ° JSON æ–‡ä»¶ä¸­ã€‚

#### `to_json_string`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L140)

```py
( ) â†’ export const metadata = 'undefined';str
```

è¿”å›å€¼

`str`

ä»¥ JSON æ ¼å¼åŒ…å«æ„æˆæ­¤ feature_extractor å®ä¾‹çš„æ‰€æœ‰å±æ€§çš„å­—ç¬¦ä¸²ã€‚

å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ã€‚

## å·²å¼ƒç”¨çš„å¤„ç†å™¨

æ‰€æœ‰å¤„ç†å™¨éƒ½éµå¾ªç›¸åŒçš„æ¶æ„ï¼Œå³ DataProcessor çš„æ¶æ„ã€‚å¤„ç†å™¨è¿”å›ä¸€ä¸ª InputExample åˆ—è¡¨ã€‚è¿™äº› InputExample å¯ä»¥è½¬æ¢ä¸º InputFeaturesï¼Œä»¥ä¾¿é¦ˆé€åˆ°æ¨¡å‹ä¸­ã€‚

### `class transformers.DataProcessor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L80)

```py
( )
```

ç”¨äºåºåˆ—åˆ†ç±»æ•°æ®é›†çš„æ•°æ®è½¬æ¢å™¨çš„åŸºç±»ã€‚

#### `get_dev_examples`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L97)

```py
( data_dir )
```

ä¸ºå¼€å‘é›†è·å–ä¸€ç»„ InputExampleã€‚

#### `get_example_from_tensor_dict`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L83)

```py
( tensor_dict )
```

ä»å¸¦æœ‰ tensorflow å¼ é‡çš„å­—å…¸ä¸­è·å–ä¸€ä¸ªç¤ºä¾‹ã€‚

#### `get_labels`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L105)

```py
( )
```

è·å–æ­¤æ•°æ®é›†çš„æ ‡ç­¾åˆ—è¡¨ã€‚

#### `get_test_examples`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L101)

```py
( data_dir )
```

ä¸ºæµ‹è¯•é›†è·å–ä¸€ç»„ InputExampleã€‚

#### `get_train_examples`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L93)

```py
( data_dir )
```

ä¸ºè®­ç»ƒé›†è·å–ä¸€ç»„ InputExampleã€‚

#### `tfds_map`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L109)

```py
( example )
```

æŸäº› tensorflow_datasets æ•°æ®é›†çš„æ ¼å¼ä¸ GLUE æ•°æ®é›†ä¸åŒã€‚æ­¤æ–¹æ³•å°†ç¤ºä¾‹è½¬æ¢ä¸ºæ­£ç¡®çš„æ ¼å¼ã€‚

### `class transformers.InputExample`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L29)

```py
( guid: str text_a: str text_b: Optional = None label: Optional = None )
```

ç”¨äºç®€å•åºåˆ—åˆ†ç±»çš„å•ä¸ªè®­ç»ƒ/æµ‹è¯•ç¤ºä¾‹ã€‚

#### `to_json_string`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L49)

```py
( )
```

å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ã€‚

### `class transformers.InputFeatures`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L54)

```py
( input_ids: List attention_mask: Optional = None token_type_ids: Optional = None label: Union = None )
```

æ•°æ®çš„ä¸€ç»„ç‰¹å¾ã€‚å±æ€§åç§°ä¸æ¨¡å‹çš„ç›¸åº”è¾“å…¥åç§°ç›¸åŒã€‚

#### `to_json_string`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/utils.py#L75)

```py
( )
```

å°†æ­¤å®ä¾‹åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ã€‚

## GLUE

[é€šç”¨è¯­è¨€ç†è§£è¯„ä¼°ï¼ˆGLUEï¼‰](https://gluebenchmark.com/)æ˜¯ä¸€ä¸ªåŸºå‡†ï¼Œè¯„ä¼°æ¨¡å‹åœ¨å„ç§ç°æœ‰ NLU ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å®ƒä¸è®ºæ–‡[GLUEï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„å¤šä»»åŠ¡åŸºå‡†å’Œåˆ†æå¹³å°](https://openreview.net/pdf?id=rJ4km2R5t7)ä¸€èµ·å‘å¸ƒ

è¿™ä¸ªåº“ä¸ºä»¥ä¸‹ä»»åŠ¡æä¾›äº†æ€»å…± 10 ä¸ªå¤„ç†å™¨ï¼šMRPCï¼ŒMNLIï¼ŒMNLIï¼ˆä¸åŒ¹é…ï¼‰ï¼ŒCoLAï¼ŒSST2ï¼ŒSTSBï¼ŒQQPï¼ŒQNLIï¼ŒRTE å’Œ WNLIã€‚

è¿™äº›å¤„ç†å™¨æ˜¯ï¼š

+   `~data.processors.utils.MrpcProcessor`

+   `~data.processors.utils.MnliProcessor`

+   `~data.processors.utils.MnliMismatchedProcessor`

+   `~data.processors.utils.Sst2Processor`

+   `~data.processors.utils.StsbProcessor`

+   `~data.processors.utils.QqpProcessor`

+   `~data.processors.utils.QnliProcessor`

+   `~data.processors.utils.RteProcessor`

+   `~data.processors.utils.WnliProcessor`

æ­¤å¤–ï¼Œä»¥ä¸‹æ–¹æ³•å¯ç”¨äºä»æ•°æ®æ–‡ä»¶åŠ è½½å€¼å¹¶å°†å…¶è½¬æ¢ä¸º InputExample åˆ—è¡¨ã€‚

#### `transformers.glue_convert_examples_to_features`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/glue.py#L41)

```py
( examples: Union tokenizer: PreTrainedTokenizer max_length: Optional = None task = None label_list = None output_mode = None )
```

å°†æ•°æ®æ–‡ä»¶åŠ è½½åˆ°`InputFeatures`åˆ—è¡¨ä¸­

## XNLI

[è·¨è¯­è¨€ NLI è¯­æ–™åº“ï¼ˆXNLIï¼‰](https://www.nyu.edu/projects/bowman/xnli/)æ˜¯ä¸€ä¸ªåŸºå‡†ï¼Œè¯„ä¼°è·¨è¯­è¨€æ–‡æœ¬è¡¨ç¤ºçš„è´¨é‡ã€‚XNLI æ˜¯åŸºäº[*MultiNLI*](http://www.nyu.edu/projects/bowman/multinli/)çš„ä¼—åŒ…æ•°æ®é›†ï¼šæ–‡æœ¬å¯¹ä½¿ç”¨ 15 ç§ä¸åŒè¯­è¨€ï¼ˆåŒ…æ‹¬é«˜èµ„æºè¯­è¨€å¦‚è‹±è¯­å’Œä½èµ„æºè¯­è¨€å¦‚æ–¯ç“¦å¸Œé‡Œè¯­ï¼‰è¿›è¡Œæ–‡æœ¬è•´æ¶µæ³¨é‡Šã€‚

å®ƒä¸è®ºæ–‡[XNLIï¼šè¯„ä¼°è·¨è¯­è¨€å¥å­è¡¨ç¤º](https://arxiv.org/abs/1809.05053)ä¸€èµ·å‘å¸ƒ

è¿™ä¸ªåº“æä¾›äº†åŠ è½½ XNLI æ•°æ®çš„å¤„ç†å™¨ï¼š

+   `~data.processors.utils.XnliProcessor`

è¯·æ³¨æ„ï¼Œç”±äºæµ‹è¯•é›†ä¸Šæœ‰é‡‘æ ‡ç­¾ï¼Œè¯„ä¼°æ˜¯åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œçš„ã€‚

åœ¨[run_xnli.py](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification/run_xnli.py)è„šæœ¬ä¸­æä¾›äº†ä½¿ç”¨è¿™äº›å¤„ç†å™¨çš„ç¤ºä¾‹ã€‚

## SQuAD

[æ–¯å¦ç¦é—®ç­”æ•°æ®é›†ï¼ˆSQuADï¼‰](https://rajpurkar.github.io/SQuAD-explorer//)æ˜¯ä¸€ä¸ªåŸºå‡†ï¼Œè¯„ä¼°æ¨¡å‹åœ¨é—®ç­”ä¸Šçš„è¡¨ç°ã€‚æœ‰ä¸¤ä¸ªç‰ˆæœ¬å¯ç”¨ï¼Œv1.1 å’Œ v2.0ã€‚ç¬¬ä¸€ä¸ªç‰ˆæœ¬ï¼ˆv1.1ï¼‰ä¸è®ºæ–‡[SQuADï¼šæ–‡æœ¬æœºå™¨ç†è§£çš„ 10 ä¸‡+é—®é¢˜](https://arxiv.org/abs/1606.05250)ä¸€èµ·å‘å¸ƒã€‚ç¬¬äºŒä¸ªç‰ˆæœ¬ï¼ˆv2.0ï¼‰ä¸è®ºæ–‡[çŸ¥é“ä½ ä¸çŸ¥é“çš„ï¼šSQuAD çš„æ— æ³•å›ç­”é—®é¢˜](https://arxiv.org/abs/1806.03822)ä¸€èµ·å‘å¸ƒã€‚

è¿™ä¸ªåº“ä¸ºä¸¤ä¸ªç‰ˆæœ¬ä¸­çš„æ¯ä¸ªç‰ˆæœ¬æä¾›äº†å¤„ç†å™¨ï¼š

### å¤„ç†å™¨

è¿™äº›å¤„ç†å™¨æ˜¯ï¼š

+   `~data.processors.utils.SquadV1Processor`

+   `~data.processors.utils.SquadV2Processor`

å®ƒä»¬éƒ½ç»§æ‰¿è‡ªæŠ½è±¡ç±»`~data.processors.utils.SquadProcessor`

### `class transformers.data.processors.squad.SquadProcessor`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L541)

```py
( )
```

SQuAD æ•°æ®é›†çš„å¤„ç†å™¨ã€‚è¢« SquadV1Processor å’Œ SquadV2Processor è¦†ç›–ï¼Œåˆ†åˆ«ç”± SQuAD çš„ç‰ˆæœ¬ 1.1 å’Œç‰ˆæœ¬ 2.0 ä½¿ç”¨ã€‚

#### `get_dev_examples`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L629)

```py
( data_dir filename = None )
```

ä»æ•°æ®ç›®å½•è¿”å›è¯„ä¼°ç¤ºä¾‹ã€‚

#### `get_examples_from_dataset`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L574)

```py
( dataset evaluate = False )
```

ä½¿ç”¨ TFDS æ•°æ®é›†åˆ›å»º`SquadExample`åˆ—è¡¨ã€‚

ç¤ºä¾‹ï¼š

```py
>>> import tensorflow_datasets as tfds

>>> dataset = tfds.load("squad")

>>> training_examples = get_examples_from_dataset(dataset, evaluate=False)
>>> evaluation_examples = get_examples_from_dataset(dataset, evaluate=True)
```

#### `get_train_examples`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L607)

```py
( data_dir filename = None )
```

ä»æ•°æ®ç›®å½•è¿”å›è®­ç»ƒç¤ºä¾‹ã€‚

æ­¤å¤–ï¼Œä»¥ä¸‹æ–¹æ³•å¯ç”¨äºå°† SQuAD ç¤ºä¾‹è½¬æ¢ä¸ºå¯ç”¨ä½œæ¨¡å‹è¾“å…¥çš„`~data.processors.utils.SquadFeatures`ã€‚

#### `transformers.squad_convert_examples_to_features`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/data/processors/squad.py#L316)

```py
( examples tokenizer max_seq_length doc_stride max_query_length is_training padding_strategy = 'max_length' return_dataset = False threads = 1 tqdm_enabled = True )
```

å°†ç¤ºä¾‹åˆ—è¡¨è½¬æ¢ä¸ºå¯ä»¥ç›´æ¥ä½œä¸ºæ¨¡å‹è¾“å…¥çš„ç‰¹å¾åˆ—è¡¨ã€‚å®ƒå–å†³äºæ¨¡å‹ï¼Œå¹¶åˆ©ç”¨è®¸å¤šåˆ†è¯å™¨çš„ç‰¹æ€§æ¥åˆ›å»ºæ¨¡å‹çš„è¾“å…¥ã€‚

ä¾‹å­ï¼š

```py
processor = SquadV2Processor()
examples = processor.get_dev_examples(data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=args.max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=args.max_query_length,
    is_training=not evaluate,
)
```

è¿™äº›å¤„ç†å™¨ä»¥åŠå‰è¿°æ–¹æ³•å¯ä»¥ä¸åŒ…å«æ•°æ®çš„æ–‡ä»¶ä»¥åŠ*tensorflow_datasets*åŒ…ä¸€èµ·ä½¿ç”¨ã€‚ä¸‹é¢ç»™å‡ºäº†ç¤ºä¾‹ã€‚

### ç¤ºä¾‹ç”¨æ³•

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œä½¿ç”¨å¤„ç†å™¨ä»¥åŠä½¿ç”¨æ•°æ®æ–‡ä»¶çš„è½¬æ¢æ–¹æ³•ï¼š

```py
# Loading a V2 processor
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

# Loading a V1 processor
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
)
```

ä½¿ç”¨*tensorflow_datasets*å°±åƒä½¿ç”¨æ•°æ®æ–‡ä»¶ä¸€æ ·ç®€å•ï¼š

```py
# tensorflow_datasets only handle Squad V1.
tfds_examples = tfds.load("squad")
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
)
```

å¦ä¸€ä¸ªä½¿ç”¨è¿™äº›å¤„ç†å™¨çš„ç¤ºä¾‹åœ¨[run_squad.py](https://github.com/huggingface/transformers/tree/main/examples/legacy/question-answering/run_squad.py)è„šæœ¬ä¸­ç»™å‡ºã€‚
