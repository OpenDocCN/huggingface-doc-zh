- en: LayoutLMv3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LayoutLMv3
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv3](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv3)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv3](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/layoutlmv3)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The LayoutLMv3 model was proposed in [LayoutLMv3: Pre-training for Document
    AI with Unified Text and Image Masking](https://arxiv.org/abs/2204.08387) by Yupan
    Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei. LayoutLMv3 simplifies [LayoutLMv2](layoutlmv2)
    by using patch embeddings (as in [ViT](vit)) instead of leveraging a CNN backbone,
    and pre-trains the model on 3 objectives: masked language modeling (MLM), masked
    image modeling (MIM) and word-patch alignment (WPA).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'LayoutLMv3模型由Yupan Huang、Tengchao Lv、Lei Cui、Yutong Lu、Furu Wei在[LayoutLMv3:
    Pre-training for Document AI with Unified Text and Image Masking](https://arxiv.org/abs/2204.08387)中提出。LayoutLMv3通过使用补丁嵌入（如[ViT](vit)中的方式）简化了[LayoutLMv2](layoutlmv2)，并在3个目标上对模型进行了预训练：掩码语言建模（MLM）、掩码图像建模（MIM）和单词-补丁对齐（WPA）。'
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Self-supervised pre-training techniques have achieved remarkable progress
    in Document AI. Most multimodal pre-trained models use a masked language modeling
    objective to learn bidirectional representations on the text modality, but they
    differ in pre-training objectives for the image modality. This discrepancy adds
    difficulty to multimodal representation learning. In this paper, we propose LayoutLMv3
    to pre-train multimodal Transformers for Document AI with unified text and image
    masking. Additionally, LayoutLMv3 is pre-trained with a word-patch alignment objective
    to learn cross-modal alignment by predicting whether the corresponding image patch
    of a text word is masked. The simple unified architecture and training objectives
    make LayoutLMv3 a general-purpose pre-trained model for both text-centric and
    image-centric Document AI tasks. Experimental results show that LayoutLMv3 achieves
    state-of-the-art performance not only in text-centric tasks, including form understanding,
    receipt understanding, and document visual question answering, but also in image-centric
    tasks such as document image classification and document layout analysis.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*自监督预训练技术在文档AI领域取得了显著进展。大多数多模态预训练模型使用掩码语言建模目标来学习文本模态上的双向表示，但它们在图像模态的预训练目标上有所不同。这种差异增加了多模态表示学习的难度。在本文中，我们提出了LayoutLMv3，用于为文档AI预训练多模态Transformers，统一文本和图像掩码。此外，LayoutLMv3还使用了单词-补丁对齐目标进行预训练，通过预测文本单词的相应图像补丁是否被掩码来学习跨模态对齐。简单的统一架构和训练目标使LayoutLMv3成为文本中心和图像中心文档AI任务的通用预训练模型。实验结果表明，LayoutLMv3不仅在文本中心任务（如表单理解、收据理解和文档视觉问答）中取得了最先进的性能，而且在图像中心任务（如文档图像分类和文档布局分析）中也取得了最先进的性能。*'
- en: '![drawing](../Images/af2a6f9e13d097092393e586cc161f9d.png) LayoutLMv3 architecture.
    Taken from the [original paper](https://arxiv.org/abs/2204.08387).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![drawing](../Images/af2a6f9e13d097092393e586cc161f9d.png) LayoutLMv3架构。摘自[原始论文](https://arxiv.org/abs/2204.08387)。'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The TensorFlow
    version of this model was added by [chriskoo](https://huggingface.co/chriskoo),
    [tokec](https://huggingface.co/tokec), and [lre](https://huggingface.co/lre).
    The original code can be found [here](https://github.com/microsoft/unilm/tree/master/layoutlmv3).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由[nielsr](https://huggingface.co/nielsr)贡献。该模型的TensorFlow版本由[chriskoo](https://huggingface.co/chriskoo)、[tokec](https://huggingface.co/tokec)和[lre](https://huggingface.co/lre)添加。原始代码可以在[这里](https://github.com/microsoft/unilm/tree/master/layoutlmv3)找到。
- en: Usage tips
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: 'In terms of data processing, LayoutLMv3 is identical to its predecessor [LayoutLMv2](layoutlmv2),
    except that:'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据处理方面，LayoutLMv3与其前身[LayoutLMv2](layoutlmv2)相同，只是：
- en: images need to be resized and normalized with channels in regular RGB format.
    LayoutLMv2 on the other hand normalizes the images internally and expects the
    channels in BGR format.
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像需要调整大小并使用常规RGB格式的通道进行归一化。另一方面，LayoutLMv2在内部对图像进行归一化，并期望通道以BGR格式提供。
- en: text is tokenized using byte-pair encoding (BPE), as opposed to WordPiece. Due
    to these differences in data preprocessing, one can use [LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)
    which internally combines a [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)
    (for the image modality) and a [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)/[LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)
    (for the text modality) to prepare all data for the model.
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本使用字节对编码（BPE）进行标记化，而不是WordPiece。由于数据预处理中的这些差异，可以使用[LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)，它内部结合了[LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)（用于图像模态）和[LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)/[LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)（用于文本模态）来为模型准备所有数据。
- en: Regarding usage of [LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor),
    we refer to the [usage guide](layoutlmv2#usage-layoutlmv2processor) of its predecessor.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于[LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)的使用，我们参考其前身的[使用指南](layoutlmv2#usage-layoutlmv2processor)。
- en: Resources
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with LayoutLMv3\. If you’re interested in submitting a resource
    to be included here, please feel free to open a Pull Request and we’ll review
    it! The resource should ideally demonstrate something new instead of duplicating
    an existing resource.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face官方和社区（🌎表示）资源列表，帮助您开始使用LayoutLMv3。如果您有兴趣提交资源以包含在此处，请随时打开一个Pull Request，我们将进行审核！资源应该最好展示一些新东西，而不是重复现有资源。
- en: LayoutLMv3 is nearly identical to LayoutLMv2, so we’ve also included LayoutLMv2
    resources you can adapt for LayoutLMv3 tasks. For these notebooks, take care to
    use [LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)
    instead when preparing data for the model!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: LayoutLMv3几乎与LayoutLMv2相同，因此我们还包含了您可以为LayoutLMv3任务调整的LayoutLMv2资源。在准备模型数据时，请务必使用[LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)！
- en: Demo notebooks for LayoutLMv3 can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/LayoutLMv3).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LayoutLMv3的演示笔记本可以在[这里](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/LayoutLMv3)找到。
- en: Demo scripts can be found [here](https://github.com/huggingface/transformers/tree/main/examples/research_projects/layoutlmv3).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 演示脚本可以在[这里](https://github.com/huggingface/transformers/tree/main/examples/research_projects/layoutlmv3)找到。
- en: Text Classification
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类
- en: '[LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)
    is supported by this [notebook](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/RVL-CDIP/Fine_tuning_LayoutLMv2ForSequenceClassification_on_RVL_CDIP.ipynb).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个[笔记本](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/RVL-CDIP/Fine_tuning_LayoutLMv2ForSequenceClassification_on_RVL_CDIP.ipynb)支持[LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)。
- en: '[Text classification task guide](../tasks/sequence_classification)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文本分类任务指南](../tasks/sequence_classification)'
- en: Token Classification
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 标记分类
- en: '[LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/research_projects/layoutlmv3)
    and [notebook](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv3/Fine_tune_LayoutLMv3_on_FUNSD_(HuggingFace_Trainer).ipynb).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个[示例脚本](https://github.com/huggingface/transformers/tree/main/examples/research_projects/layoutlmv3)和[笔记本](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv3/Fine_tune_LayoutLMv3_on_FUNSD_(HuggingFace_Trainer).ipynb)支持[LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)。
- en: A [notebook](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/Inference_with_LayoutLMv2ForTokenClassification.ipynb)
    for how to perform inference with [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)
    and a [notebook](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/True_inference_with_LayoutLMv2ForTokenClassification_%2B_Gradio_demo.ipynb)
    for how to perform inference when no labels are available with [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification).
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于如何使用[LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)进行推断的[笔记本](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/Inference_with_LayoutLMv2ForTokenClassification.ipynb)，以及一个关于如何在没有标签的情况下使用[LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)进行推断的[笔记本](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/True_inference_with_LayoutLMv2ForTokenClassification_%2B_Gradio_demo.ipynb)。
- en: A [notebook](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/Fine_tuning_LayoutLMv2ForTokenClassification_on_FUNSD_using_HuggingFace_Trainer.ipynb)
    for how to finetune [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)
    with the 🤗 Trainer.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于如何使用🤗 Trainer对[LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)进行微调的[笔记本](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/FUNSD/Fine_tuning_LayoutLMv2ForTokenClassification_on_FUNSD_using_HuggingFace_Trainer.ipynb)。
- en: '[Token classification task guide](../tasks/token_classification)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[标记分类任务指南](../tasks/token_classification)'
- en: Question Answering
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 问答
- en: '[LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    is supported by this [notebook](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/DocVQA/Fine_tuning_LayoutLMv2ForQuestionAnswering_on_DocVQA.ipynb).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个[笔记本](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLMv2/DocVQA/Fine_tuning_LayoutLMv2ForQuestionAnswering_on_DocVQA.ipynb)支持[LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)。
- en: '[Question answering task guide](../tasks/question_answering)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[问答任务指南](../tasks/question_answering)'
- en: '**Document question answering**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**文档问答**'
- en: '[Document question answering task guide](../tasks/document_question_answering)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文档问答任务指南](../tasks/document_question_answering)'
- en: LayoutLMv3Config
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv3Config
- en: '### `class transformers.LayoutLMv3Config`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv3Config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/configuration_layoutlmv3.py#L40)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/configuration_layoutlmv3.py#L40)'
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 50265) — Vocabulary size of the
    LayoutLMv3 model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, 默认为50265) — LayoutLMv3模型的词汇量。定义了在调用[LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)时可以表示的不同标记数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimension of the encoder
    layers and the pooler layer.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, 默认为768) — 编码器层和池化层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, 默认为12) — Transformer编码器中隐藏层的数量。'
- en: '`num_attention_heads` (`int`, *optional*, defaults to 12) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_attention_heads` (`int`, *optional*, 默认为 12) — Transformer编码器中每个注意力层的注意力头数。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimension of the
    “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, 默认为 3072) — Transformer编码器中“中间”（即前馈）层的维度。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — The
    non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` 或 `function`, *optional*, 默认为 `"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持
    `"gelu"`, `"relu"`, `"selu"` 和 `"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, 默认为 0.1) — 嵌入、编码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_probs_dropout_prob` (`float`, *optional*, defaults to 0.1) — The
    dropout ratio for the attention probabilities.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_probs_dropout_prob` (`float`, *optional*, 默认为 0.1) — 注意力概率的dropout比率。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_position_embeddings` (`int`, *optional*, 默认为 512) — 该模型可能使用的最大序列长度。通常设置为一个较大的值以防万一（例如，512或1024或2048）。'
- en: '`type_vocab_size` (`int`, *optional*, defaults to 2) — The vocabulary size
    of the `token_type_ids` passed when calling [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type_vocab_size` (`int`, *optional*, 默认为 2) — 在调用 [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)
    时传递的 `token_type_ids` 的词汇表大小。'
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initializer_range` (`float`, *optional*, 默认为 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-5) — The epsilon used
    by the layer normalization layers.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_norm_eps` (`float`, *optional*, 默认为 1e-5) — 层归一化层使用的epsilon。'
- en: '`max_2d_position_embeddings` (`int`, *optional*, defaults to 1024) — The maximum
    value that the 2D position embedding might ever be used with. Typically set this
    to something large just in case (e.g., 1024).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_2d_position_embeddings` (`int`, *optional*, 默认为 1024) — 2D位置嵌入可能使用的最大值。通常设置为一个较大的值以防万一（例如，1024）。'
- en: '`coordinate_size` (`int`, *optional*, defaults to `128`) — Dimension of the
    coordinate embeddings.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`coordinate_size` (`int`, *optional*, 默认为 `128`) — 坐标嵌入的维度。'
- en: '`shape_size` (`int`, *optional*, defaults to `128`) — Dimension of the width
    and height embeddings.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shape_size` (`int`, *optional*, 默认为 `128`) — 宽度和高度嵌入的维度。'
- en: '`has_relative_attention_bias` (`bool`, *optional*, defaults to `True`) — Whether
    or not to use a relative attention bias in the self-attention mechanism.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`has_relative_attention_bias` (`bool`, *optional*, 默认为 `True`) — 是否在自注意力机制中使用相对注意力偏置。'
- en: '`rel_pos_bins` (`int`, *optional*, defaults to 32) — The number of relative
    position bins to be used in the self-attention mechanism.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rel_pos_bins` (`int`, *optional*, 默认为 32) — 在自注意力机制中使用的相对位置桶的数量。'
- en: '`max_rel_pos` (`int`, *optional*, defaults to 128) — The maximum number of
    relative positions to be used in the self-attention mechanism.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_rel_pos` (`int`, *optional*, 默认为 128) — 在自注意力机制中使用的最大相对位置数。'
- en: '`max_rel_2d_pos` (`int`, *optional*, defaults to 256) — The maximum number
    of relative 2D positions in the self-attention mechanism.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_rel_2d_pos` (`int`, *optional*, 默认为 256) — 自注意力机制中的最大2D相对位置数。'
- en: '`rel_2d_pos_bins` (`int`, *optional*, defaults to 64) — The number of 2D relative
    position bins in the self-attention mechanism.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rel_2d_pos_bins` (`int`, *optional*, 默认为 64) — 自注意力机制中的2D相对位置桶的数量。'
- en: '`has_spatial_attention_bias` (`bool`, *optional*, defaults to `True`) — Whether
    or not to use a spatial attention bias in the self-attention mechanism.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`has_spatial_attention_bias` (`bool`, *optional*, 默认为 `True`) — 是否在自注意力机制中使用空间注意偏置。'
- en: '`visual_embed` (`bool`, *optional*, defaults to `True`) — Whether or not to
    add patch embeddings.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_embed` (`bool`, *optional*, 默认为 `True`) — 是否添加补丁嵌入。'
- en: '`input_size` (`int`, *optional*, defaults to `224`) — The size (resolution)
    of the images.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_size` (`int`, *optional*, 默认为 `224`) — 图像的大小（分辨率）。'
- en: '`num_channels` (`int`, *optional*, defaults to `3`) — The number of channels
    of the images.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *optional*, 默认为 `3`) — 图像的通道数。'
- en: '`patch_size` (`int`, *optional*, defaults to `16`) — The size (resolution)
    of the patches.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch_size` (`int`, *optional*, 默认为 `16`) — 补丁的大小（分辨率）。'
- en: '`classifier_dropout` (`float`, *optional*) — The dropout ratio for the classification
    head.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`classifier_dropout` (`float`, *optional*) — 分类头的dropout比率。'
- en: This is the configuration class to store the configuration of a [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model).
    It is used to instantiate an LayoutLMv3 model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the LayoutLMv3 [microsoft/layoutlmv3-base](https://huggingface.co/microsoft/layoutlmv3-base)
    architecture.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储 [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)
    的配置。它用于根据指定的参数实例化一个 LayoutLMv3 模型，定义模型架构。使用默认值实例化配置将产生类似于 LayoutLMv3 [microsoft/layoutlmv3-base](https://huggingface.co/microsoft/layoutlmv3-base)
    架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档以获取更多信息。
- en: 'Example:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: LayoutLMv3FeatureExtractor
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv3FeatureExtractor
- en: '### `class transformers.LayoutLMv3FeatureExtractor`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv3FeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/feature_extraction_layoutlmv3.py#L28)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/feature_extraction_layoutlmv3.py#L28)'
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `__call__`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)'
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Preprocess an image or a batch of images.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理一张图像或一批图像。
- en: LayoutLMv3ImageProcessor
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv3ImageProcessor
- en: '### `class transformers.LayoutLMv3ImageProcessor`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv3ImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/image_processing_layoutlmv3.py#L95)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/image_processing_layoutlmv3.py#L95)'
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Whether to resize the
    image’s (height, width) dimensions to `(size["height"], size["width"])`. Can be
    overridden by `do_resize` in `preprocess`.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *optional*, 默认为 `True`) — 是否将图像的 (高度，宽度) 尺寸调整为 `(size["height"],
    size["width"])`。可以被 `preprocess` 中的 `do_resize` 覆盖。'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"height" -- 224, "width":
    224}`): Size of the image after resizing. Can be overridden by `size` in `preprocess`.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]` *optional*, 默认为 `{"height" -- 224, "width": 224}`):
    调整大小后的图像尺寸。可以被 `preprocess` 中的 `size` 覆盖。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BILINEAR`)
    — Resampling filter to use if resizing the image. Can be overridden by `resample`
    in `preprocess`.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *optional*, 默认为 `PILImageResampling.BILINEAR`)
    — 如果调整图像大小，要使用的重采样滤波器。可以被 `preprocess` 中的 `resample` 覆盖。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Whether to rescale
    the image’s pixel values by the specified `rescale_value`. Can be overridden by
    `do_rescale` in `preprocess`.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *optional*, 默认为 `True`) — 是否按指定的 `rescale_value` 重新缩放图像的像素值。可以被
    `preprocess` 中的 `do_rescale` 覆盖。'
- en: '`rescale_factor` (`float`, *optional*, defaults to 1 / 255) — Value by which
    the image’s pixel values are rescaled. Can be overridden by `rescale_factor` in
    `preprocess`.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`float`, *optional*, 默认为 1 / 255) — 图像的像素值被重新缩放的值。可以被 `preprocess`
    中的 `rescale_factor` 覆盖。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `True`) — Whether to normalize
    the image. Can be overridden by the `do_normalize` parameter in the `preprocess`
    method.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *optional*, 默认为 `True`) — 是否对图像进行规范化。可以被 `preprocess`
    方法中的 `do_normalize` 参数覆盖。'
- en: '`image_mean` (`Iterable[float]` or `float`, *optional*, defaults to `IMAGENET_STANDARD_MEAN`)
    — Mean to use if normalizing the image. This is a float or list of floats the
    length of the number of channels in the image. Can be overridden by the `image_mean`
    parameter in the `preprocess` method.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`Iterable[float]` 或 `float`, *optional*, 默认为 `IMAGENET_STANDARD_MEAN`)
    — 如果规范化图像要使用的均值。这是一个浮点数或与图像通道数相同长度的浮点数列表。可以被 `preprocess` 方法中的 `image_mean` 参数覆盖。'
- en: '`image_std` (`Iterable[float]` or `float`, *optional*, defaults to `IMAGENET_STANDARD_STD`)
    — Standard deviation to use if normalizing the image. This is a float or list
    of floats the length of the number of channels in the image. Can be overridden
    by the `image_std` parameter in the `preprocess` method.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`Iterable[float]` 或 `float`, *optional*, 默认为 `IMAGENET_STANDARD_STD`)
    — 如果规范化图像要使用的标准差。这是一个浮点数或与图像通道数相同长度的浮点数列表。可以被 `preprocess` 方法中的 `image_std` 参数覆盖。'
- en: '`apply_ocr` (`bool`, *optional*, defaults to `True`) — Whether to apply the
    Tesseract OCR engine to get words + normalized bounding boxes. Can be overridden
    by the `apply_ocr` parameter in the `preprocess` method.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apply_ocr` (`bool`, *optional*, 默认为 `True`) — 是否应用 Tesseract OCR 引擎以获取单词 +
    规范化边界框。可以被 `preprocess` 方法中的 `apply_ocr` 参数覆盖。'
- en: '`ocr_lang` (`str`, *optional*) — The language, specified by its ISO code, to
    be used by the Tesseract OCR engine. By default, English is used. Can be overridden
    by the `ocr_lang` parameter in the `preprocess` method.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ocr_lang` (`str`, *optional*) — Tesseract OCR 引擎要使用的语言，由其 ISO 代码指定。默认情况下使用英语。可以被
    `preprocess` 方法中的 `ocr_lang` 参数覆盖。'
- en: '`tesseract_config` (`str`, *optional*) — Any additional custom configuration
    flags that are forwarded to the `config` parameter when calling Tesseract. For
    example: ‘—psm 6’. Can be overridden by the `tesseract_config` parameter in the
    `preprocess` method.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tesseract_config` (`str`, *optional*) — 转发到调用 Tesseract 时 `config` 参数的任何额外自定义配置标志。例如：‘—psm
    6’。可以被 `preprocess` 方法中的 `tesseract_config` 参数覆盖。'
- en: Constructs a LayoutLMv3 image processor.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个 LayoutLMv3 图像处理器。
- en: '#### `preprocess`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/image_processing_layoutlmv3.py#L216)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/image_processing_layoutlmv3.py#L216)'
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — Image to preprocess. Expects a single or batch of
    images with pixel values ranging from 0 to 255\. If passing in images with pixel
    values between 0 and 1, set `do_rescale=False`.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) — 要预处理的图像。期望单个或批量图像，像素值范围为 0 到 255。如果传入像素值在 0 到 1 之间的图像，请设置
    `do_rescale=False`。'
- en: '`do_resize` (`bool`, *optional*, defaults to `self.do_resize`) — Whether to
    resize the image.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *optional*, 默认为 `self.do_resize`) — 是否调整图像大小。'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to `self.size`) — Desired size
    of the output image after applying `resize`.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]`, *optional*, 默认为 `self.size`) — 应用 `resize` 后输出图像的期望大小。'
- en: '`resample` (`int`, *optional*, defaults to `self.resample`) — Resampling filter
    to use if resizing the image. This can be one of the `PILImageResampling` filters.
    Only has an effect if `do_resize` is set to `True`.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`int`, *optional*, defaults to `self.resample`) — 如果调整图像大小，则要使用的重采样滤波器。这可以是
    `PILImageResampling` 滤波器之一。仅在 `do_resize` 设置为 `True` 时有效。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) — Whether
    to rescale the image pixel values between [0, 1].'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *optional*, defaults to `self.do_rescale`) — 是否将图像像素值重新缩放到
    [0, 1] 之间。'
- en: '`rescale_factor` (`float`, *optional*, defaults to `self.rescale_factor`) —
    Rescale factor to apply to the image pixel values. Only has an effect if `do_rescale`
    is set to `True`.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`float`, *optional*, defaults to `self.rescale_factor`) —
    应用于图像像素值的重新缩放因子。仅在 `do_rescale` 设置为 `True` 时有效。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) — Whether
    to normalize the image.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize` (`bool`, *optional*, defaults to `self.do_normalize`) — 是否对图像进行归一化。'
- en: '`image_mean` (`float` or `Iterable[float]`, *optional*, defaults to `self.image_mean`)
    — Mean values to be used for normalization. Only has an effect if `do_normalize`
    is set to `True`.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` or `Iterable[float]`, *optional*, defaults to `self.image_mean`)
    — 用于归一化的均值。仅在 `do_normalize` 设置为 `True` 时有效。'
- en: '`image_std` (`float` or `Iterable[float]`, *optional*, defaults to `self.image_std`)
    — Standard deviation values to be used for normalization. Only has an effect if
    `do_normalize` is set to `True`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` or `Iterable[float]`, *optional*, defaults to `self.image_std`)
    — 用于归一化的标准差值。仅在 `do_normalize` 设置为 `True` 时有效。'
- en: '`apply_ocr` (`bool`, *optional*, defaults to `self.apply_ocr`) — Whether to
    apply the Tesseract OCR engine to get words + normalized bounding boxes.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apply_ocr` (`bool`, *optional*, defaults to `self.apply_ocr`) — 是否应用 Tesseract
    OCR 引擎以获取单词 + 规范化边界框。'
- en: '`ocr_lang` (`str`, *optional*, defaults to `self.ocr_lang`) — The language,
    specified by its ISO code, to be used by the Tesseract OCR engine. By default,
    English is used.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ocr_lang` (`str`, *optional*, defaults to `self.ocr_lang`) — Tesseract OCR
    引擎使用的语言，由其 ISO 代码指定。默认情况下使用英语。'
- en: '`tesseract_config` (`str`, *optional*, defaults to `self.tesseract_config`)
    — Any additional custom configuration flags that are forwarded to the `config`
    parameter when calling Tesseract.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tesseract_config` (`str`, *optional*, defaults to `self.tesseract_config`)
    — 转发到调用 Tesseract 时 `config` 参数的任何额外自定义配置标志。'
- en: '`return_tensors` (`str` or `TensorType`, *optional*) — The type of tensors
    to return. Can be one of:'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` or `TensorType`, *optional*) — 要返回的张量类型。可以是以下之一：'
- en: 'Unset: Return a list of `np.ndarray`.'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：返回 `np.ndarray` 的列表。
- en: '`TensorType.TENSORFLOW` or `''tf''`: Return a batch of type `tf.Tensor`.'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.TENSORFLOW` 或 `''tf''`：返回类型为 `tf.Tensor` 的批次。'
- en: '`TensorType.PYTORCH` or `''pt''`: Return a batch of type `torch.Tensor`.'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.PYTORCH` 或 `''pt''`：返回类型为 `torch.Tensor` 的批次。'
- en: '`TensorType.NUMPY` or `''np''`: Return a batch of type `np.ndarray`.'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.NUMPY` 或 `''np''`：返回类型为 `np.ndarray` 的批次。'
- en: '`TensorType.JAX` or `''jax''`: Return a batch of type `jax.numpy.ndarray`.'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorType.JAX` 或 `''jax''`：返回类型为 `jax.numpy.ndarray` 的批次。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format` (`ChannelDimension` 或 `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — 输出图像的通道维度格式。可以是以下之一：'
- en: '`ChannelDimension.FIRST`: image in (num_channels, height, width) format.'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.FIRST`：图像以 (通道数, 高度, 宽度) 格式。'
- en: '`ChannelDimension.LAST`: image in (height, width, num_channels) format.'
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChannelDimension.LAST`：图像以 (高度, 宽度, 通道数) 格式。'
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format` (`ChannelDimension` 或 `str`, *optional*) — 输入图像的通道维度格式。如果未设置，则从输入图像中推断通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"` 或 `ChannelDimension.FIRST`：图像以 (通道数, 高度, 宽度) 格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"` 或 `ChannelDimension.LAST`：图像以 (高度, 宽度, 通道数) 格式。'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"` 或 `ChannelDimension.NONE`：图像以 (高度, 宽度) 格式。'
- en: Preprocess an image or batch of images.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理图像或图像批次。
- en: LayoutLMv3Tokenizer
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv3Tokenizer
- en: '### `class transformers.LayoutLMv3Tokenizer`'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv3Tokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py#L200)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py#L200)'
- en: '[PRE6]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — Path to the vocabulary file.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 词汇文件的路径。'
- en: '`merges_file` (`str`) — Path to the merges file.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`merges_file` (`str`) — 合并文件的路径。'
- en: '`errors` (`str`, *optional*, defaults to `"replace"`) — Paradigm to follow
    when decoding bytes to UTF-8\. See [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode)
    for more information.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`errors` (`str`, *optional*, defaults to `"replace"`) — 解码字节为 UTF-8 时要遵循的范例。有关更多信息，请参阅
    [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode)。'
- en: '`bos_token` (`str`, *optional*, defaults to `"<s>"`) — The beginning of sequence
    token that was used during pretraining. Can be used a sequence classifier token.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str`, *optional*, defaults to `"<s>"`) — 在预训练期间使用的序列开头标记。可用作序列分类器标记。'
- en: When building a sequence using special tokens, this is not the token that is
    used for the beginning of sequence. The token used is the `cls_token`.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 构建序列时使用特殊标记，这不是序列开头使用的标记。使用的标记是 `cls_token`。
- en: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) — The end of sequence
    token.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) — 序列结束标记。'
- en: When building a sequence using special tokens, this is not the token that is
    used for the end of sequence. The token used is the `sep_token`.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 构建序列时使用特殊标记，这不是序列末尾使用的标记。使用的标记是 `sep_token`。
- en: '`sep_token` (`str`, *optional*, defaults to `"</s>"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str`, *optional*, 默认为 `"</s>"`) — 分隔符标记，在构建来自多个序列的序列时使用，例如用于序列分类的两个序列或用于问题回答的文本和问题。它还用作使用特殊标记构建的序列的最后一个标记。'
- en: '`cls_token` (`str`, *optional*, defaults to `"<s>"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str`, *optional*, 默认为 `"<s>"`) — 分类器标记，用于进行序列分类（对整个序列进行分类，而不是每个标记进行分类）。它是使用特殊标记构建的序列的第一个标记。'
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *optional*, 默认为 `"<unk>"`) — 未知标记。词汇表中没有的标记无法转换为ID，而是设置为此标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *optional*, 默认为 `"<pad>"`) — 用于填充的标记，例如在批处理不同长度的序列时使用。'
- en: '`mask_token` (`str`, *optional*, defaults to `"<mask>"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str`, *optional*, 默认为 `"<mask>"`) — 用于屏蔽值的标记。这是在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。'
- en: '`add_prefix_space` (`bool`, *optional*, defaults to `True`) — Whether or not
    to add an initial space to the input. This allows to treat the leading word just
    as any other word. (RoBERTa tokenizer detect beginning of words by the preceding
    space).'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_prefix_space` (`bool`, *optional*, 默认为 `True`) — 是否在输入中添加初始空格。这允许将前导单词视为任何其他单词。（RoBERTa分词器通过前面的空格检测单词的开头）。'
- en: '`cls_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — The
    bounding box to use for the special [CLS] token.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token_box` (`List[int]`, *optional*, 默认为 `[0, 0, 0, 0]`) — 用于特殊[CLS]标记的边界框。'
- en: '`sep_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — The
    bounding box to use for the special [SEP] token.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token_box` (`List[int]`, *optional*, 默认为 `[0, 0, 0, 0]`) — 用于特殊[SEP]标记的边界框。'
- en: '`pad_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — The
    bounding box to use for the special [PAD] token.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_box` (`List[int]`, *optional*, 默认为 `[0, 0, 0, 0]`) — 用于特殊[PAD]标记的边界框。'
- en: '`pad_token_label` (`int`, *optional*, defaults to -100) — The label to use
    for padding tokens. Defaults to -100, which is the `ignore_index` of PyTorch’s
    CrossEntropyLoss.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_label` (`int`, *optional*, 默认为 -100) — 用于填充标记的标签。默认为-100，这是PyTorch的CrossEntropyLoss的`ignore_index`。'
- en: '`only_label_first_subword` (`bool`, *optional*, defaults to `True`) — Whether
    or not to only label the first subword, in case word labels are provided.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`only_label_first_subword` (`bool`, *optional*, 默认为 `True`) — 是否仅标记第一个子词，如果提供了单词标签。'
- en: Construct a LayoutLMv3 tokenizer. Based on `RoBERTatokenizer` (Byte Pair Encoding
    or BPE). [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    can be used to turn words, word-level bounding boxes and optional word labels
    to token-level `input_ids`, `attention_mask`, `token_type_ids`, `bbox`, and optional
    `labels` (for token classification).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个LayoutLMv3分词器。基于`RoBERTatokenizer`（字节对编码或BPE）。[LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    可用于将单词、单词级边界框和可选单词标签转换为标记级`input_ids`、`attention_mask`、`token_type_ids`、`bbox`和可选`labels`（用于标记分类）。
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 此分词器继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '[LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    runs end-to-end tokenization: punctuation splitting and wordpiece. It also turns
    the word-level bounding boxes into token-level bounding boxes.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    运行端到端的分词：标点符号拆分和词块。它还将单词级边界框转换为标记级边界框。'
- en: '#### `__call__`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py#L550)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py#L550)'
- en: '[PRE7]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]`, `List[List[str]]`) — The sequence or batch of sequences
    to be encoded. Each sequence can be a string, a list of strings (words of a single
    example or questions of a batch of examples) or a list of list of strings (batch
    of words).'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`, `List[str]`, `List[List[str]]`) — 要编码的序列或批次序列。每个序列可以是一个字符串，一个字符串列表（单个示例的单词或一批示例的问题）或一个字符串列表的列表（一批单词）。'
- en: '`text_pair` (`List[str]`, `List[List[str]]`) — The sequence or batch of sequences
    to be encoded. Each sequence should be a list of strings (pretokenized string).'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair` (`List[str]`, `List[List[str]]`) — 要编码的序列或批次序列。每个序列应该是一个字符串列表（预分词的字符串）。'
- en: '`boxes` (`List[List[int]]`, `List[List[List[int]]]`) — Word-level bounding
    boxes. Each bounding box should be normalized to be on a 0-1000 scale.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`boxes` (`List[List[int]]`, `List[List[List[int]]]`) — 单词级边界框。每个边界框应标准化为0-1000的比例。'
- en: '`word_labels` (`List[int]`, `List[List[int]]`, *optional*) — Word-level integer
    labels (for token classification tasks such as FUNSD, CORD).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`word_labels` (`List[int]`, `List[List[int]]`, *optional*) — 单词级整数标签（用于诸如FUNSD、CORD之类的标记分类任务）。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to encode the sequences with the special tokens relative to their model.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — 是否对序列进行编码，使用相对于其模型的特殊标记。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding` (`bool`, `str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — 激活并控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`: 填充到批次中最长的序列（如果只提供了单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 填充到指定的最大长度（使用参数 `max_length`）或模型的最大可接受输入长度（如果未提供该参数）。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）：无填充（即，可以输出具有不同长度序列的批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`, `str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — 激活并控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`: 截断到指定的最大长度（使用参数 `max_length`）或模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则逐标记截断，从最长序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`: 截断到指定的最大长度（使用参数 `max_length`）或模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则仅截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`: 截断到指定的最大长度（使用参数 `max_length`）或模型的最大可接受输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则仅截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''`（默认）：无截断（即，可以输出具有大于模型最大可接受输入大小的序列长度的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *optional*) — 控制截断/填充参数使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为 `None`，则将使用预定义的模型最大长度（如果截断/填充参数需要最大长度）。如果模型没有特定的最大输入长度（如 XLNet），则将禁用截断/填充到最大长度。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride` (`int`, *optional*, defaults to 0) — 如果设置为一个数字，并且与 `max_length` 一起使用，当
    `return_overflowing_tokens=True` 时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。该参数的值定义了重叠标记的数量。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. This is especially useful to enable the use
    of Tensor Cores on NVIDIA hardware with compute capability `>= 7.5` (Volta).'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *optional*) — 如果设置，将填充序列到提供的值的倍数。这对于在具有计算能力 `>=
    7.5`（Volta）的 NVIDIA 硬件上启用 Tensor Cores 特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — 如果设置，将返回张量而不是 Python 整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回 TensorFlow `tf.constant` 对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回 PyTorch `torch.Tensor` 对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回 Numpy `np.ndarray` 对象。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to encode the sequences with the special tokens relative to their model.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — 是否对序列进行编码，使用相对于其模型的特殊标记。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding` (`bool`, `str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — 激活并控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`: 填充到批次中最长的序列（如果只提供了单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 填充到指定的最大长度，该长度由参数 `max_length` 指定，或者填充到模型的最大可接受输入长度，如果未提供该参数。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）：不填充（即，可以输出具有不同长度序列的批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation` (`bool`, `str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *可选*, 默认为 `False`) — 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`: 截断到由参数 `max_length` 指定的最大长度，或者截断到模型的最大可接受输入长度，如果未提供该参数。如果提供了一对序列（或一批序列对），则将逐个标记截断，从较长序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`: 截断到由参数 `max_length` 指定的最大长度，或者截断到模型的最大可接受输入长度，如果未提供该参数。如果提供了一对序列（或一批序列对），则仅截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`: 截断到由参数 `max_length` 指定的最大长度，或者截断到模型的最大可接受输入长度，如果未提供该参数。如果提供了一对序列（或一批序列对），则仅截断第二个序列。 '
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''`（默认）：不截断（即，可以输出具有大于模型最大可接受输入大小的序列长度的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters. If left unset or set to `None`, this will
    use the predefined model maximum length if a maximum length is required by one
    of the truncation/padding parameters. If the model has no specific maximum input
    length (like XLNet) truncation/padding to a maximum length will be deactivated.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`, *可选*) — 控制截断/填充参数之一使用的最大长度。如果未设置或设置为 `None`，则将使用预定义的模型最大长度，如果截断/填充参数需要最大长度。如果模型没有特定的最大输入长度（如
    XLNet），则将禁用截断/填充到最大长度。'
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride` (`int`, *可选*, 默认为 0) — 如果与 `max_length` 一起设置为一个数字，则当 `return_overflowing_tokens=True`
    时返回的溢出标记将包含从截断序列末尾返回的一些标记，以提供截断和溢出序列之间的一些重叠。该参数的值定义了重叠标记的数量。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. This is especially useful to enable the use
    of Tensor Cores on NVIDIA hardware with compute capability `>= 7.5` (Volta).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of` (`int`, *可选*) — 如果设置，将填充序列到提供的值的倍数。这对于在具有计算能力 `>= 7.5`（Volta）的
    NVIDIA 硬件上启用 Tensor Cores 特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors` (`str` 或 [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *可选*) — 如果设置，将返回张量而不是 Python 整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回 TensorFlow `tf.constant` 对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回 PyTorch `torch.Tensor` 对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回 Numpy `np.ndarray` 对象。'
- en: Main method to tokenize and prepare for the model one or several sequence(s)
    or one or several pair(s) of sequences with word-level normalized bounding boxes
    and optional labels.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 用于对一个或多个序列或一个或多个序列对进行标记化和为模型准备的主要方法，其中包括单词级别的归一化边界框和可选标签。
- en: '#### `save_vocabulary`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_vocabulary`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py#L431)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py#L431)'
- en: '[PRE8]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: LayoutLMv3TokenizerFast
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv3TokenizerFast
- en: '### `class transformers.LayoutLMv3TokenizerFast`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv3TokenizerFast`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py#L65)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py#L65)'
- en: '[PRE9]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — Path to the vocabulary file.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 词汇表文件的路径。'
- en: '`merges_file` (`str`) — Path to the merges file.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`merges_file` (`str`) — 合并文件的路径。'
- en: '`errors` (`str`, *optional*, defaults to `"replace"`) — Paradigm to follow
    when decoding bytes to UTF-8\. See [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode)
    for more information.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`errors` (`str`, *可选*, 默认为 `"replace"`) — 解码字节为 UTF-8 时要遵循的范例。有关更多信息，请参阅 [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode)。'
- en: '`bos_token` (`str`, *optional*, defaults to `"<s>"`) — The beginning of sequence
    token that was used during pretraining. Can be used a sequence classifier token.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str`, *可选*, 默认为 `"<s>"`) — 在预训练期间使用的序列开始标记。可以用作序列分类器标记。'
- en: When building a sequence using special tokens, this is not the token that is
    used for the beginning of sequence. The token used is the `cls_token`.
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 构建序列时使用特殊标记时，这不是用于序列开头的标记。使用的标记是`cls_token`。
- en: '`eos_token` (`str`, *optional*, defaults to `"</s>"`) — The end of sequence
    token.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token` (`str`, *可选*, 默认为 `"</s>"`) — 序列结束标记。'
- en: When building a sequence using special tokens, this is not the token that is
    used for the end of sequence. The token used is the `sep_token`.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 构建序列时使用特殊标记时，这不是用于序列结尾的标记。使用的标记是`sep_token`。
- en: '`sep_token` (`str`, *optional*, defaults to `"</s>"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str`, *可选*, 默认为 `"</s>"`) — 分隔符标记，用于从多个序列构建序列，例如用于序列分类的两个序列或用于文本和问题的问题回答。它也用作使用特殊标记构建的序列的最后一个标记。'
- en: '`cls_token` (`str`, *optional*, defaults to `"<s>"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str`, *可选*, 默认为 `"<s>"`) — 在进行序列分类（整个序列而不是每个标记的分类）时使用的分类器标记。当使用特殊标记构建序列时，它是序列的第一个标记。'
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *可选*, 默认为 `"<unk>"`) — 未知标记。词汇表中没有的标记无法转换为ID，而是设置为此标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *可选*, 默认为 `"<pad>"`) — 用于填充的标记，例如在批处理不同长度的序列时使用。'
- en: '`mask_token` (`str`, *optional*, defaults to `"<mask>"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str`, *可选*, 默认为 `"<mask>"`) — 用于屏蔽值的标记。这是在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。'
- en: '`add_prefix_space` (`bool`, *optional*, defaults to `False`) — Whether or not
    to add an initial space to the input. This allows to treat the leading word just
    as any other word. (RoBERTa tokenizer detect beginning of words by the preceding
    space).'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_prefix_space` (`bool`, *可选*, 默认为 `False`) — 是否在输入中添加初始空格。这允许将前导单词视为任何其他单词。（RoBERTa标记器通过前面的空格检测单词的开头）。'
- en: '`trim_offsets` (`bool`, *optional*, defaults to `True`) — Whether the post
    processing step should trim offsets to avoid including whitespaces.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trim_offsets` (`bool`, *可选*, 默认为 `True`) — 后处理步骤是否应修剪偏移量以避免包含空格。'
- en: '`cls_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — The
    bounding box to use for the special [CLS] token.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token_box` (`List[int]`, *可选*, 默认为 `[0, 0, 0, 0]`) — 用于特殊[CLS]标记的边界框。'
- en: '`sep_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — The
    bounding box to use for the special [SEP] token.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token_box` (`List[int]`, *可选*, 默认为 `[0, 0, 0, 0]`) — 用于特殊[SEP]标记的边界框。'
- en: '`pad_token_box` (`List[int]`, *optional*, defaults to `[0, 0, 0, 0]`) — The
    bounding box to use for the special [PAD] token.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_box` (`List[int]`, *可选*, 默认为 `[0, 0, 0, 0]`) — 用于特殊[PAD]标记的边界框。'
- en: '`pad_token_label` (`int`, *optional*, defaults to -100) — The label to use
    for padding tokens. Defaults to -100, which is the `ignore_index` of PyTorch’s
    CrossEntropyLoss.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_label` (`int`, *可选*, 默认为 -100) — 用于填充标记的标签。默认为-100，这是PyTorch的CrossEntropyLoss的`ignore_index`。'
- en: '`only_label_first_subword` (`bool`, *optional*, defaults to `True`) — Whether
    or not to only label the first subword, in case word labels are provided.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`only_label_first_subword` (`bool`, *可选*, 默认为 `True`) — 是否仅标记第一个子词，如果提供了单词标签。'
- en: Construct a “fast” LayoutLMv3 tokenizer (backed by HuggingFace’s *tokenizers*
    library). Based on BPE.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 构建“快速”LayoutLMv3标记器（由HuggingFace的*tokenizers*库支持）。基于BPE。
- en: This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 此标记器继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '#### `__call__`'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py#L224)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py#L224)'
- en: '[PRE10]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`, `List[str]`, `List[List[str]]`) — The sequence or batch of sequences
    to be encoded. Each sequence can be a string, a list of strings (words of a single
    example or questions of a batch of examples) or a list of list of strings (batch
    of words).'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`, `List[str]`, `List[List[str]]`) — 要编码的序列或序列批次。每个序列可以是一个字符串，一个字符串列表（单个示例的单词或一批示例的问题）或一个字符串列表的列表（单词批次）。'
- en: '`text_pair` (`List[str]`, `List[List[str]]`) — The sequence or batch of sequences
    to be encoded. Each sequence should be a list of strings (pretokenized string).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_pair` (`List[str]`, `List[List[str]]`) — 要编码的序列或序列批次。每个序列应该是一个字符串列表（预先标记化的字符串）。'
- en: '`boxes` (`List[List[int]]`, `List[List[List[int]]]`) — Word-level bounding
    boxes. Each bounding box should be normalized to be on a 0-1000 scale.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`boxes` (`List[List[int]]`, `List[List[List[int]]]`) — 单词级别的边界框。每个边界框应该被归一化为0-1000的比例。'
- en: '`word_labels` (`List[int]`, `List[List[int]]`, *optional*) — Word-level integer
    labels (for token classification tasks such as FUNSD, CORD).'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`word_labels`（`List[int]`、`List[List[int]]`，*可选*） — 单词级整数标签（用于诸如 FUNSD、CORD
    等标记分类任务）。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to encode the sequences with the special tokens relative to their model.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens`（`bool`，*可选*，默认为 `True`） — 是否使用相对于其模型的特殊标记对序列进行编码。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`、`str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为
    `False`） — 激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest''`：填充到批次中最长的序列（如果只提供了单个序列，则不进行填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`：填充到由参数 `max_length` 指定的最大长度，或者填充到模型可接受的最大输入长度（如果未提供该参数）。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_pad''`（默认）：不进行填充（即可以输出长度不同的批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`bool`、`str` 或 [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy)，*可选*，默认为
    `False`） — 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True` 或 `''longest_first''`：截断到由参数 `max_length` 指定的最大长度，或者截断到模型可接受的最大输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则将逐个标记进行截断，从一对序列中最长的序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`：截断到由参数 `max_length` 指定的最大长度，或者截断到模型可接受的最大输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则只会截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`：截断到由参数 `max_length` 指定的最大长度，或者截断到模型可接受的最大输入长度（如果未提供该参数）。如果提供了一对序列（或一批对序列），则只会截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False` 或 `''do_not_truncate''`（默认）：不进行截断（即可以输出长度大于模型最大可接受输入大小的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*） — 控制截断/填充参数之一使用的最大长度。'
- en: If left unset or set to `None`, this will use the predefined model maximum length
    if a maximum length is required by one of the truncation/padding parameters. If
    the model has no specific maximum input length (like XLNet) truncation/padding
    to a maximum length will be deactivated.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未设置或设置为 `None`，则将使用预定义的模型最大长度（如果截断/填充参数需要最大长度）。如果模型没有特定的最大输入长度（如 XLNet），则将禁用截断/填充到最大长度。
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride`（`int`，*可选*，默认为 0） — 如果设置为一个数字，并且与 `max_length` 一起使用，当 `return_overflowing_tokens=True`
    时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。该参数的值定义了重叠标记的数量。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. This is especially useful to enable the use
    of Tensor Cores on NVIDIA hardware with compute capability `>= 7.5` (Volta).'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of`（`int`，*可选*） — 如果设置，将填充序列到提供的值的倍数。这对于在具有计算能力 `>= 7.5`（Volta）的
    NVIDIA 硬件上启用 Tensor Cores 特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str` 或 [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）
    — 如果设置，将返回张量而不是 Python 整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`：返回 TensorFlow `tf.constant` 对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`：返回 PyTorch `torch.Tensor` 对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`：返回 Numpy `np.ndarray` 对象。'
- en: '`add_special_tokens` (`bool`, *optional*, defaults to `True`) — Whether or
    not to encode the sequences with the special tokens relative to their model.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_special_tokens`（`bool`，*可选*，默认为 `True`） — 是否使用相对于其模型的特殊标记对序列进行编码。'
- en: '`padding` (`bool`, `str` or [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy),
    *optional*, defaults to `False`) — Activates and controls padding. Accepts the
    following values:'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`（`bool`、`str` 或 [PaddingStrategy](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.utils.PaddingStrategy)，*可选*，默认为
    `False`） — 激活和控制填充。接受以下值：'
- en: '`True` or `''longest''`: Pad to the longest sequence in the batch (or no padding
    if only a single sequence if provided).'
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`或`''longest''`: 填充到批次中最长的序列（如果只提供单个序列，则不填充）。'
- en: '`''max_length''`: Pad to a maximum length specified with the argument `max_length`
    or to the maximum acceptable input length for the model if that argument is not
    provided.'
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''max_length''`: 使用参数`max_length`指定的最大长度填充，或者如果未提供该参数，则填充到模型的最大可接受输入长度。'
- en: '`False` or `''do_not_pad''` (default): No padding (i.e., can output a batch
    with sequences of different lengths).'
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`或`''do_not_pad''`（默认）：不填充（即可以输出具有不同长度序列的批次）。'
- en: '`truncation` (`bool`, `str` or [TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy),
    *optional*, defaults to `False`) — Activates and controls truncation. Accepts
    the following values:'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`bool`，`str`或[TruncationStrategy](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.tokenization_utils_base.TruncationStrategy)，*可选*，默认为`False`）
    - 激活和控制截断。接受以下值：'
- en: '`True` or `''longest_first''`: Truncate to a maximum length specified with
    the argument `max_length` or to the maximum acceptable input length for the model
    if that argument is not provided. This will truncate token by token, removing
    a token from the longest sequence in the pair if a pair of sequences (or a batch
    of pairs) is provided.'
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`True`或`''longest_first''`: 使用参数`max_length`指定的最大长度截断，或者如果未提供该参数，则截断到模型的最大可接受输入长度。如果提供了一对序列（或一批对序列），则将逐标记截断，从一对序列中最长的序列中删除一个标记。'
- en: '`''only_first''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the first sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_first''`: 使用参数`max_length`指定的最大长度截断，或者如果未提供该参数，则截断到模型的最大可接受输入长度。如果提供了一对序列（或一批对序列），则只会截断第一个序列。'
- en: '`''only_second''`: Truncate to a maximum length specified with the argument
    `max_length` or to the maximum acceptable input length for the model if that argument
    is not provided. This will only truncate the second sequence of a pair if a pair
    of sequences (or a batch of pairs) is provided.'
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''only_second''`: 使用参数`max_length`指定的最大长度截断，或者如果未提供该参数，则截断到模型的最大可接受输入长度。如果提供了一对序列（或一批对序列），则只会截断第二个序列。'
- en: '`False` or `''do_not_truncate''` (default): No truncation (i.e., can output
    batch with sequence lengths greater than the model maximum admissible input size).'
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`False`或`''do_not_truncate''`（默认）：不截断（即可以输出长度大于模型最大可接受输入大小的批次）。'
- en: '`max_length` (`int`, *optional*) — Controls the maximum length to use by one
    of the truncation/padding parameters. If left unset or set to `None`, this will
    use the predefined model maximum length if a maximum length is required by one
    of the truncation/padding parameters. If the model has no specific maximum input
    length (like XLNet) truncation/padding to a maximum length will be deactivated.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*） - 控制截断/填充参数之一使用的最大长度。如果未设置或设置为`None`，则将使用预定义的模型最大长度（如果截断/填充参数需要最大长度）。如果模型没有特定的最大输入长度（如XLNet），则将禁用截断/填充到最大长度。'
- en: '`stride` (`int`, *optional*, defaults to 0) — If set to a number along with
    `max_length`, the overflowing tokens returned when `return_overflowing_tokens=True`
    will contain some tokens from the end of the truncated sequence returned to provide
    some overlap between truncated and overflowing sequences. The value of this argument
    defines the number of overlapping tokens.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride`（`int`，*可选*，默认为0） - 如果与`max_length`一起设置为一个数字，则当`return_overflowing_tokens=True`时返回的溢出标记将包含截断序列末尾的一些标记，以提供截断和溢出序列之间的一些重叠。该参数的值定义了重叠标记的数量。'
- en: '`pad_to_multiple_of` (`int`, *optional*) — If set will pad the sequence to
    a multiple of the provided value. This is especially useful to enable the use
    of Tensor Cores on NVIDIA hardware with compute capability `>= 7.5` (Volta).'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of`（`int`，*可选*） - 如果设置，将序列填充到提供的值的倍数。这对于启用具有计算能力`>= 7.5`（Volta）的NVIDIA硬件上的Tensor
    Cores特别有用。'
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）
    - 如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`: 返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`: 返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`: 返回Numpy `np.ndarray`对象。'
- en: Main method to tokenize and prepare for the model one or several sequence(s)
    or one or several pair(s) of sequences with word-level normalized bounding boxes
    and optional labels.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 用于标记和准备一个或多个序列或一个或多个序列对的主要方法，具有单词级别的归一化边界框和可选标签。
- en: LayoutLMv3Processor
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv3Processor
- en: '### `class transformers.LayoutLMv3Processor`'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv3Processor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/processing_layoutlmv3.py#L27)'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/processing_layoutlmv3.py#L27)'
- en: '[PRE11]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image_processor` (`LayoutLMv3ImageProcessor`, *optional*) — An instance of
    [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor).
    The image processor is a required input.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor`（`LayoutLMv3ImageProcessor`，*可选*） - [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)的一个实例。图像处理器是必需的输入。'
- en: '`tokenizer` (`LayoutLMv3Tokenizer` or `LayoutLMv3TokenizerFast`, *optional*)
    — An instance of [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    or [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast).
    The tokenizer is a required input.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（`LayoutLMv3Tokenizer`或`LayoutLMv3TokenizerFast`，*可选*）- [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)或[LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)的实例。标记器是必需的输入。'
- en: Constructs a LayoutLMv3 processor which combines a LayoutLMv3 image processor
    and a LayoutLMv3 tokenizer into a single processor.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个LayoutLMv3处理器，将LayoutLMv3图像处理器和LayoutLMv3标记器组合成一个单一处理器。
- en: '[LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)
    offers all the functionalities you need to prepare data for the model.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)提供了准备数据给模型所需的所有功能。'
- en: It first uses [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)
    to resize and normalize document images, and optionally applies OCR to get words
    and normalized bounding boxes. These are then provided to [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    or [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast),
    which turns the words and bounding boxes into token-level `input_ids`, `attention_mask`,
    `token_type_ids`, `bbox`. Optionally, one can provide integer `word_labels`, which
    are turned into token-level `labels` for token classification tasks (such as FUNSD,
    CORD).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '它首先使用[LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)来调整和规范文档图像，并可选择应用OCR以获取单词和规范化的边界框。然后将它们提供给[LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)或[LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)，将单词和边界框转换为标记级`input_ids`、`attention_mask`、`token_type_ids`、`bbox`。可选地，可以提供整数`word_labels`，这些标签被转换为用于标记分类任务（如FUNSD、CORD）的标记级`labels`。 '
- en: '#### `__call__`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/processing_layoutlmv3.py#L69)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/processing_layoutlmv3.py#L69)'
- en: '[PRE12]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This method first forwards the `images` argument to [**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__).
    In case [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)
    was initialized with `apply_ocr` set to `True`, it passes the obtained words and
    bounding boxes along with the additional arguments to [**call**()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer.__call__)
    and returns the output, together with resized and normalized `pixel_values`. In
    case [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)
    was initialized with `apply_ocr` set to `False`, it passes the words (`text`/``text_pair`)
    and `boxes` specified by the user along with the additional arguments to [**call**()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer.__call__)
    and returns the output, together with resized and normalized `pixel_values`.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法首先将`images`参数转发到[**call**()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。如果[LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)初始化时将`apply_ocr`设置为`True`，则将获得的单词和边界框连同其他参数传递给[**call**()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer.__call__)并返回输出，以及调整大小和规范化的`pixel_values`。如果[LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)初始化时将`apply_ocr`设置为`False`，则将用户指定的单词（`text`/``text_pair`）和`boxes`连同其他参数传递给[**call**()](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer.__call__)并返回输出，以及调整大小和规范化的`pixel_values`。
- en: Please refer to the docstring of the above two methods for more information.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息请参考上述两种方法的文档字符串。
- en: PytorchHide Pytorch content
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorch隐藏 Pytorch内容
- en: LayoutLMv3Model
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv3Model
- en: '### `class transformers.LayoutLMv3Model`'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv3Model`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L734)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L734)'
- en: '[PRE13]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)）-
    模型的所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare LayoutLMv3 Model transformer outputting raw hidden-states without any
    specific head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的LayoutLMv3模型变换器输出没有特定头部的原始隐藏状态。这个模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L827)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L827)'
- en: '[PRE14]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, token_sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, token_sequence_length, 4)`,
    *optional*) — Bounding boxes of each input sequence tokens. Selected in the range
    `[0, config.max_2d_position_embeddings-1]`. Each bounding box should be a normalized
    version in (x0, y0, x1, y1) format, where (x0, y0) corresponds to the position
    of the upper left corner in the bounding box, and (x1, y1) represents the position
    of the lower right corner.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Batch of document images. Each image is divided into patches of shape
    `(num_channels, config.patch_size, config.patch_size)` and the total number of
    patches (=`patch_sequence_length`) equals to `((height / config.patch_size) *
    (width / config.patch_size))`.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, token_sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, token_sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, token_sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, token_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    and inputs.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包括根据配置（[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)）和输入的各种元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`）—
    模型最后一层输出的隐藏状态序列。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层的输出，则为嵌入层的输出+每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层的输出隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)
    forward method, overrides the `__call__` special method.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)的前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE15]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: LayoutLMv3ForSequenceClassification
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv3ForSequenceClassification
- en: '### `class transformers.LayoutLMv3ForSequenceClassification`'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv3ForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1259)'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1259)'
- en: '[PRE16]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: LayoutLMv3 Model with a sequence classification head on top (a linear layer
    on top of the final hidden state of the [CLS] token) e.g. for document image classification
    tasks such as the [RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/) dataset.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: LayoutLMv3模型在顶部具有序列分类头部（在[CLS]标记的最终隐藏状态之上的线性层），例如用于文档图像分类任务，如[RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/)数据集。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有内容。
- en: '#### `forward`'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1277)'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1277)'
- en: '[PRE17]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参阅 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入 ID？](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    — Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox` (`torch.LongTensor`，形状为 `(batch_size, sequence_length, 4)`，*optional*)
    — 每个输入序列标记的边界框。选定范围为 `[0, config.max_2d_position_embeddings-1]`。每个边界框应该是 (x0,
    y0, x1, y1) 格式的归一化版本，其中 (x0, y0) 对应于边界框左上角的位置，(x1, y1) 表示右下角的位置。'
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Batch of document images. Each image is divided into patches of shape
    `(num_channels, config.patch_size, config.patch_size)` and the total number of
    patches (=`patch_sequence_length`) equals to `((height / config.patch_size) *
    (width / config.patch_size))`.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为 `(batch_size, num_channels, height,
    width)`) — 文档图像的批处理。每个图像被分成形状为 `(num_channels, config.patch_size, config.patch_size)`
    的补丁，并且补丁的总数（=`patch_sequence_length`）等于 `((height / config.patch_size) * (width
    / config.patch_size))`。'
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length)`，*optional*)
    — 用于避免在填充标记索引上执行注意力的掩码。掩码值选定在 `[0, 1]` 之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 代表未被 `masked` 的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 代表被 `masked` 的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor`，形状为 `(batch_size, sequence_length)`，*optional*)
    — 段标记索引，指示输入的第一部分和第二部分。索引选定在 `[0, 1]` 之间：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于 *句子 A* 标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型 ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor`，形状为 `(batch_size, sequence_length)`，*optional*)
    — 每个输入序列标记在位置嵌入中的位置索引。选定范围为 `[0, config.max_position_embeddings - 1]`。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置 ID？](../glossary#position-ids)'
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.FloatTensor`，形状为 `(num_heads,)` 或 `(num_layers, num_heads)`，*optional*)
    — 用于使自注意力模块中的特定头部失效的掩码。掩码值选定在 `[0, 1]` 之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-359
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被 `masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-360
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被 `masked`。
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`，形状为 `(batch_size, sequence_length, hidden_size)`，*optional*)
    — 可选地，可以直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制权，以便将 *input_ids* 索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的
    `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: Returns
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    and inputs.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    或 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或 `config.return_dict=False`）包含根据配置（[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)）和输入不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，当提供`labels`时返回）- 分类（如果config.num_labels==1则为回归）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, config.num_labels)`的`torch.FloatTensor`）- 分类（如果config.num_labels==1则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '[LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传播的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE18]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: LayoutLMv3ForTokenClassification
  id: totrans-378
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LayoutLMv3ForTokenClassification
- en: '### `class transformers.LayoutLMv3ForTokenClassification`'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.LayoutLMv3ForTokenClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1016)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1016)'
- en: '[PRE19]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)）-
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: LayoutLMv3 Model with a token classification head on top (a linear layer on
    top of the final hidden states) e.g. for sequence labeling (information extraction)
    tasks such as [FUNSD](https://guillaumejaume.github.io/FUNSD/), [SROIE](https://rrc.cvc.uab.es/?ch=13),
    [CORD](https://github.com/clovaai/cord) and [Kleister-NDA](https://github.com/applicaai/kleister-nda).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: LayoutLMv3模型，顶部带有一个标记分类头（最终隐藏状态之上的线性层），例如用于序列标记（信息提取）任务的[FUNSD](https://guillaumejaume.github.io/FUNSD/)、[SROIE](https://rrc.cvc.uab.es/?ch=13)、[CORD](https://github.com/clovaai/cord)和[Kleister-NDA](https://github.com/applicaai/kleister-nda)。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有信息。
- en: '#### `forward`'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `前向传播`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1039)'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1039)'
- en: '[PRE20]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）- 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。查看[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)获取详细信息。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    — Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Batch of document images. Each image is divided into patches of shape
    `(num_channels, config.patch_size, config.patch_size)` and the total number of
    patches (=`patch_sequence_length`) equals to `((height / config.patch_size) *
    (width / config.patch_size))`.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-396
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-400
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-406
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-407
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the token classification loss. Indices should be in `[0,
    ..., config.num_labels - 1]`.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    and inputs.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification loss.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_labels)`)
    — Classification scores (before SoftMax).'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: LayoutLMv3ForQuestionAnswering
  id: totrans-426
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.LayoutLMv3ForQuestionAnswering`'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1129)'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LayoutLMv3 Model with a span classification head on top for extractive question-answering
    tasks such as [DocVQA](https://rrc.cvc.uab.es/?ch=17) (a linear layer on top of
    the text part of the hidden-states output to compute `span start logits` and `span
    end logits`).
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_layoutlmv3.py#L1147)'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`torch.LongTensor` of shape `(batch_size, sequence_length, 4)`, *optional*)
    — Bounding boxes of each input sequence tokens. Selected in the range `[0, config.max_2d_position_embeddings-1]`.
    Each bounding box should be a normalized version in (x0, y0, x1, y1) format, where
    (x0, y0) corresponds to the position of the upper left corner in the bounding
    box, and (x1, y1) represents the position of the lower right corner.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Batch of document images. Each image is divided into patches of shape
    `(num_channels, config.patch_size, config.patch_size)` and the total number of
    patches (=`patch_sequence_length`) equals to `((height / config.patch_size) *
    (width / config.patch_size))`.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-444
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-445
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-448
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-449
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-454
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-455
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*)
    — Labels for position (index) of the start of the labelled span for computing
    the token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) —
    Labels for position (index) of the end of the labelled span for computing the
    token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    and inputs.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Total span extraction loss is the sum of a Cross-Entropy for the
    start and end positions.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Span-start scores (before SoftMax).'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Span-end scores (before SoftMax).'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: TensorFlowHide TensorFlow content
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: TFLayoutLMv3Model
  id: totrans-477
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFLayoutLMv3Model`'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1257)'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bare LayoutLMv3 Model transformer outputting raw hidden-states without any
    specific head on top. This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should “just work” for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you don’t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1269)'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-498
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-499
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length,
    4)`, *optional*) — Bounding boxes of each input sequence tokens. Selected in the
    range `[0, config.max_2d_position_embeddings-1]`. Each bounding box should be
    a normalized version in (x0, y0, x1, y1) format, where (x0, y0) corresponds to
    the position of the upper left corner in the bounding box, and (x1, y1) represents
    the position of the lower right corner.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    — Batch of document images. Each image is divided into patches of shape `(num_channels,
    config.patch_size, config.patch_size)` and the total number of patches (=`patch_sequence_length`)
    equals to `((height / config.patch_size) * (width / config.patch_size))`.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-505
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-506
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-508
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-510
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-511
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-516
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-518
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-519
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) — Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert *input_ids* indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFBaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    and inputs.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    — Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-529
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-531
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model)
    forward method, overrides the `__call__` special method.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: TFLayoutLMv3ForSequenceClassification
  id: totrans-536
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFLayoutLMv3ForSequenceClassification`'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1391)'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LayoutLMv3 Model with a sequence classification head on top (a linear layer
    on top of the final hidden state of the [CLS] token) e.g. for document image classification
    tasks such as the [RVL-CDIP](https://www.cs.cmu.edu/~aharley/rvl-cdip/) dataset.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should “just work” for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you don’t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1409)'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-555
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-558
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-560
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length,
    4)`, *optional*) — Bounding boxes of each input sequence tokens. Selected in the
    range `[0, config.max_2d_position_embeddings-1]`. Each bounding box should be
    a normalized version in (x0, y0, x1, y1) format, where (x0, y0) corresponds to
    the position of the upper left corner in the bounding box, and (x1, y1) represents
    the position of the lower right corner.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-562
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    — Batch of document images. Each image is divided into patches of shape `(num_channels,
    config.patch_size, config.patch_size)` and the total number of patches (=`patch_sequence_length`)
    equals to `((height / config.patch_size) * (width / config.patch_size))`.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-565
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-566
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-567
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-568
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-570
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-571
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-572
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-573
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-575
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-576
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-578
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-579
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) — Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert *input_ids* indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    and inputs.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`tf.Tensor` of shape `(batch_size, )`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`) — Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-590
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-592
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-596
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: TFLayoutLMv3ForTokenClassification
  id: totrans-597
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFLayoutLMv3ForTokenClassification`'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1505)'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-600
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LayoutLMv3 Model with a token classification head on top (a linear layer on
    top of the final hidden states) e.g. for sequence labeling (information extraction)
    tasks such as [FUNSD](https://guillaumejaume.github.io/FUNSD/), [SROIE](https://rrc.cvc.uab.es/?ch=13),
    [CORD](https://github.com/clovaai/cord) and [Kleister-NDA](https://github.com/applicaai/kleister-nda).
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should “just work” for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you don’t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1534)'
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-616
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-619
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-620
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-621
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length,
    4)`, *optional*) — Bounding boxes of each input sequence tokens. Selected in the
    range `[0, config.max_2d_position_embeddings-1]`. Each bounding box should be
    a normalized version in (x0, y0, x1, y1) format, where (x0, y0) corresponds to
    the position of the upper left corner in the bounding box, and (x1, y1) represents
    the position of the lower right corner.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-623
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    — Batch of document images. Each image is divided into patches of shape `(num_channels,
    config.patch_size, config.patch_size)` and the total number of patches (=`patch_sequence_length`)
    equals to `((height / config.patch_size) * (width / config.patch_size))`.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-626
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-627
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-628
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-629
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-631
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-632
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-633
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-634
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-636
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-637
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-639
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-640
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) — Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert *input_ids* indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the token classification loss. Indices should be in `[0,
    ..., config.num_labels - 1]`.'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFTokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFTokenClassifierOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFTokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFTokenClassifierOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    and inputs.
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`tf.Tensor` of shape `(n,)`, *optional*, where n is the number of unmasked
    labels, returned when `labels` is provided) — Classification loss.'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.num_labels)`)
    — Classification scores (before SoftMax).'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-652
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-654
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFLayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-658
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: TFLayoutLMv3ForQuestionAnswering
  id: totrans-659
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.TFLayoutLMv3ForQuestionAnswering`'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1643)'
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-662
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Parameters
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LayoutLMv3 Model with a span classification head on top for extractive question-answering
    tasks such as [DocVQA](https://rrc.cvc.uab.es/?ch=17) (a linear layer on top of
    the text part of the hidden-states output to compute `span start logits` and `span
    end logits`).
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow models and layers in `transformers` accept two formats as input:'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
- en: having all inputs as keyword arguments (like PyTorch models), or
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: having all inputs as a list, tuple or dict in the first positional argument.
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The reason the second format is supported is that Keras methods prefer this
    format when passing inputs to models and layers. Because of this support, when
    using methods like `model.fit()` things should “just work” for you - just pass
    your inputs and labels in any format that `model.fit()` supports! If, however,
    you want to use the second format outside of Keras methods like `fit()` and `predict()`,
    such as when creating your own layers or models with the Keras `Functional` API,
    there are three possibilities you can use to gather all the input Tensors in the
    first positional argument:'
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
- en: 'a single Tensor with `input_ids` only and nothing else: `model(input_ids)`'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a list of varying length with one or several input Tensors IN THE ORDER given
    in the docstring: `model([input_ids, attention_mask])` or `model([input_ids, attention_mask,
    token_type_ids])`'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a dictionary with one or several input Tensors associated to the input names
    given in the docstring: `model({"input_ids": input_ids, "token_type_ids": token_type_ids})`'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when creating models and layers with [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)
    then you don’t need to worry about any of this, as you can just pass inputs like
    you would to any other Python function!
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
- en: '#### `call`'
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py#L1663)'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-678
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-681
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-682
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-683
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bbox` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length,
    4)`, *optional*) — Bounding boxes of each input sequence tokens. Selected in the
    range `[0, config.max_2d_position_embeddings-1]`. Each bounding box should be
    a normalized version in (x0, y0, x1, y1) format, where (x0, y0) corresponds to
    the position of the upper left corner in the bounding box, and (x1, y1) represents
    the position of the lower right corner.'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-685
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    — Batch of document images. Each image is divided into patches of shape `(num_channels,
    config.patch_size, config.patch_size)` and the total number of patches (=`patch_sequence_length`)
    equals to `((height / config.patch_size) * (width / config.patch_size))`.'
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_mask` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Mask to avoid performing attention on padding token indices. Mask values selected
    in `[0, 1]`:'
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-688
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-689
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-690
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-691
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-693
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-694
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-695
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-696
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`Numpy array` or `tf.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that `sequence_length = token_sequence_length + patch_sequence_length +
    1` where `1` is for [CLS] token. See `pixel_values` for `patch_sequence_length`.
  id: totrans-698
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-699
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`,
    *optional*) — Mask to nullify selected heads of the self-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-701
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-702
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`,
    *optional*) — Optionally, instead of passing `input_ids` you can choose to directly
    pass an embedded representation. This is useful if you want more control over
    how to convert *input_ids* indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_positions` (`tf.Tensor` of shape `(batch_size,)`, *optional*) — Labels
    for position (index) of the start of the labelled span for computing the token
    classification loss. Positions are clamped to the length of the sequence (`sequence_length`).
    Position outside of the sequence are not taken into account for computing the
    loss.'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_positions` (`tf.Tensor` of shape `(batch_size,)`, *optional*) — Labels
    for position (index) of the end of the labelled span for computing the token classification
    loss. Positions are clamped to the length of the sequence (`sequence_length`).
    Position outside of the sequence are not taken into account for computing the
    loss.'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config))
    and inputs.
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`tf.Tensor` of shape `(batch_size, )`, *optional*, returned when `start_positions`
    and `end_positions` are provided) — Total span extraction loss is the sum of a
    Cross-Entropy for the start and end positions.'
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_logits` (`tf.Tensor` of shape `(batch_size, sequence_length)`) — Span-start
    scores (before SoftMax).'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_logits` (`tf.Tensor` of shape `(batch_size, sequence_length)`) — Span-end
    scores (before SoftMax).'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-716
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-718
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-722
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
