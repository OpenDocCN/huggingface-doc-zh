["```py\naccelerator.wait_for_everyone()\n```", "```py\nwith accelerator.main_process_first():\n    datasets = load_dataset(\"glue\", \"mrpc\")\n```", "```py\n# First do something on the main process\nif accelerator.is_main_process:\n    datasets = load_dataset(\"glue\", \"mrpc\")\nelse:\n    accelerator.wait_for_everyone()\n\n# And then send it to the rest of them\nif not accelerator.is_main_process:\n    datasets = load_dataset(\"glue\", \"mrpc\")\nelse:\n    accelerator.wait_for_everyone()\n```", "```py\nif accelerator.is_main_process:\n    model = accelerator.unwrap_model(model)\n    torch.save(model.state_dict(), \"weights.pth\")\n```", "```py\nwith accelerator.main_process_first():\n    state = torch.load(\"weights.pth\")\n    model.load_state_dict(state)\n```", "```py\ndatasets = load_dataset(\"glue\", \"mrpc\")\n\nwith accelerator.main_process_first():\n    tokenized_datasets = datasets.map(\n        tokenize_function,\n        batched=True,\n        remove_columns=[\"idx\", \"sentence1\", \"sentence2\"],\n    )\n```", "```py\nfor (x,y) in data_loader:\n    logits = model(x)\n    loss = loss_func(logits, y)\n    # Assume `should_do_early_stopping` is a custom defined function that returns a conditional\n    if should_do_early_stopping(loss):\n        accelerator.set_trigger()\n\n    # Later in the training script when we need to check for the breakpoint\n    if accelerator.check_trigger():\n        break\n```"]