# DDIM

> 原文链接：[https://huggingface.co/docs/diffusers/api/pipelines/ddim](https://huggingface.co/docs/diffusers/api/pipelines/ddim)

[Jiaming Song, Chenlin Meng和Stefano Ermon撰写的去噪扩散隐式模型](https://huggingface.co/papers/2010.02502)（DDIM）。

论文摘要如下：

*去噪扩散概率模型（DDPMs）在没有对抗训练的情况下实现了高质量的图像生成，但是它们需要模拟一个马尔可夫链多步才能生成样本。为了加速采样，我们提出了去噪扩散隐式模型（DDIMs），这是一种更高效的迭代隐式概率模型类，其训练过程与DDPMs相同。在DDPMs中，生成过程被定义为马尔可夫扩散过程的反向过程。我们构建了一类非马尔可夫扩散过程，这些过程导致相同的训练目标，但其反向过程可以更快地进行采样。我们经验性地证明，与DDPMs相比，DDIMs在墙钟时间方面可以以10倍至50倍的速度生成高质量样本，使我们能够在计算和样本质量之间进行权衡，并且可以直接在潜在空间中执行语义有意义的图像插值。*

原始代码库可以在[ermongroup/ddim](https://github.com/ermongroup/ddim)找到。

## DDIM管道

### `class diffusers.DDIMPipeline`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/ddim/pipeline_ddim.py#L24)

```py
( unet scheduler )
```

参数

+   `unet` ([UNet2DModel](/docs/diffusers/v0.26.3/en/api/models/unet2d#diffusers.UNet2DModel)) — 用于去噪编码图像潜在的`UNet2DModel`。

+   `scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)) — 与`unet`结合使用以去噪编码图像的调度器。可以是[DDPMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.DDPMScheduler)之一，或[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)之一。

图像生成的管道。

该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。检查超类文档以获取所有管道实现的通用方法（下载、保存、在特定设备上运行等）。

#### `__call__`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/ddim/pipeline_ddim.py#L49)

```py
( batch_size: int = 1 generator: Union = None eta: float = 0.0 num_inference_steps: int = 50 use_clipped_model_output: Optional = None output_type: Optional = 'pil' return_dict: bool = True ) → export const metadata = 'undefined';ImagePipelineOutput or tuple
```

参数

+   `batch_size` (`int`, *可选*, 默认为1) — 生成图像的数量。

+   `generator` (`torch.Generator`, *可选*) — 用于使生成过程确定性的[`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)。

+   `eta` (`float`, *可选*, 默认为0.0) — 对应于[DDIM](https://arxiv.org/abs/2010.02502)论文中的参数eta（η）。仅适用于[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)，在其他调度器中被忽略。值为`0`对应于DDIM，值为`1`对应于DDPM。

+   `num_inference_steps` (`int`, *可选*, 默认为50) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。

+   `use_clipped_model_output` (`bool`, *可选*, 默认为`None`) — 如果为`True`或`False`，请参阅[DDIMScheduler.step()](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler.step)的文档。如果为`None`，则不会将任何内容传递给调度器（对于不支持此参数的调度器，请使用`None`）。

+   `output_type` (`str`, *可选*, 默认为`"pil"`) — 生成图像的输出格式。选择`PIL.Image`或`np.array`之间。

+   `return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。

返回

[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput) 或 `tuple`

如果 `return_dict` 为 `True`，则返回 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)，否则返回一个 `tuple`，其中第一个元素是生成的图像列表

用于生成的管道的调用函数。

示例:

```py
>>> from diffusers import DDIMPipeline
>>> import PIL.Image
>>> import numpy as np

>>> # load model and scheduler
>>> pipe = DDIMPipeline.from_pretrained("fusing/ddim-lsun-bedroom")

>>> # run pipeline in inference (sample random noise and denoise)
>>> image = pipe(eta=0.0, num_inference_steps=50)

>>> # process image to PIL
>>> image_processed = image.cpu().permute(0, 2, 3, 1)
>>> image_processed = (image_processed + 1.0) * 127.5
>>> image_processed = image_processed.numpy().astype(np.uint8)
>>> image_pil = PIL.Image.fromarray(image_processed[0])

>>> # save image
>>> image_pil.save("test.png")
```

## ImagePipelineOutput

### `class diffusers.ImagePipelineOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/pipeline_utils.py#L116)

```py
( images: Union )
```

参数

+   `images` (`List[PIL.Image.Image]` 或 `np.ndarray`) — 长度为 `batch_size` 的去噪 PIL 图像列表或形状为 `(batch_size, height, width, num_channels)` 的 NumPy 数组。

图像管道的输出类。
