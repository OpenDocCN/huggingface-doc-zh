- en: Examples
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹
- en: 'Original text: [https://huggingface.co/docs/trl/example_overview](https://huggingface.co/docs/trl/example_overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/trl/example_overview](https://huggingface.co/docs/trl/example_overview)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: 'The examples should work in any of the following settings (with the same script):'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç¤ºä¾‹åº”è¯¥åœ¨ä»¥ä¸‹ä»»ä½•è®¾ç½®ä¸­è¿è¡Œï¼ˆä½¿ç”¨ç›¸åŒçš„è„šæœ¬ï¼‰ï¼š
- en: single GPU
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•GPU
- en: multi GPUS (using PyTorch distributed mode)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šGPUï¼ˆä½¿ç”¨PyTorchåˆ†å¸ƒå¼æ¨¡å¼ï¼‰
- en: multi GPUS (using DeepSpeed ZeRO-Offload stages 1, 2, & 3)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šGPUï¼ˆä½¿ç”¨DeepSpeed ZeRO-Offloadé˜¶æ®µ1ã€2å’Œ3ï¼‰
- en: fp16 (mixed-precision), fp32 (normal precision), or bf16 (bfloat16 precision)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fp16ï¼ˆæ··åˆç²¾åº¦ï¼‰ï¼Œfp32ï¼ˆæ­£å¸¸ç²¾åº¦ï¼‰æˆ–bf16ï¼ˆbfloat16ç²¾åº¦ï¼‰
- en: To run it in each of these various modes, first initialize the accelerate configuration
    with `accelerate config`
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åœ¨è¿™äº›ä¸åŒæ¨¡å¼ä¸­è¿è¡Œå®ƒï¼Œè¯·é¦–å…ˆä½¿ç”¨`accelerate config`åˆå§‹åŒ–åŠ é€Ÿé…ç½®
- en: '**NOTE to train with a 4-bit or 8-bit model**, please run'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼šè¦è®­ç»ƒ4ä½æˆ–8ä½æ¨¡å‹ï¼Œè¯·è¿è¡Œ**'
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Accelerate Config
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ é€Ÿé…ç½®
- en: 'For all the examples, youâ€™ll need to generate a ğŸ¤— Accelerate config file with:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ‰€æœ‰ç¤ºä¾‹ï¼Œæ‚¨éœ€è¦ç”Ÿæˆä¸€ä¸ªğŸ¤— Accelerateé…ç½®æ–‡ä»¶ï¼š
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then, it is encouraged to launch jobs with `accelerate launch`!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œé¼“åŠ±ä½¿ç”¨`accelerate launch`å¯åŠ¨ä½œä¸šï¼
- en: Maintained Examples
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»´æŠ¤çš„ç¤ºä¾‹
- en: '| File | Description |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| æ–‡ä»¶ | æè¿° |'
- en: '| --- | --- |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| [`examples/scripts/sft.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)
    | This script shows how to use the `SFTTrainer` to fine tune a model or adapters
    into a target dataset. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/sft.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)
    | æ­¤è„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨`SFTTrainer`æ¥å¾®è°ƒæ¨¡å‹æˆ–é€‚é…å™¨ä»¥é€‚åº”ç›®æ ‡æ•°æ®é›†ã€‚ |'
- en: '| [`examples/scripts/reward_modeling.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/reward_modeling.py)
    | This script shows how to use the `RewardTrainer` to train a reward model on
    your own dataset. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/reward_modeling.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/reward_modeling.py)
    | æ­¤è„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨`RewardTrainer`æ¥åœ¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒå¥–åŠ±æ¨¡å‹ã€‚ |'
- en: '| [`examples/scripts/ppo.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/ppo.py)
    | This script shows how to use the `PPOTrainer` to fine-tune a sentiment analysis
    model using IMDB dataset |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/ppo.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/ppo.py)
    | æ­¤è„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨`PPOTrainer`æ¥ä½¿ç”¨IMDBæ•°æ®é›†å¾®è°ƒæƒ…æ„Ÿåˆ†ææ¨¡å‹ |'
- en: '| [`examples/scripts/ppo_multi_adapter.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/ppo_multi_adapter.py)
    | This script shows how to use the `PPOTrainer` to train a single base model with
    multiple adapters. Requires you to run the example script with the reward model
    training beforehand. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/ppo_multi_adapter.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/ppo_multi_adapter.py)
    | æ­¤è„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨`PPOTrainer`æ¥è®­ç»ƒä¸€ä¸ªå¸¦æœ‰å¤šä¸ªé€‚é…å™¨çš„å•ä¸ªåŸºç¡€æ¨¡å‹ã€‚éœ€è¦æ‚¨å…ˆè¿è¡Œå¥–åŠ±æ¨¡å‹è®­ç»ƒçš„ç¤ºä¾‹è„šæœ¬ã€‚ |'
- en: '| [`examples/scripts/stable_diffusion_tuning_example.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/stable_diffusion_tuning_example.py)
    | This script shows to use DDPOTrainer to fine-tune a stable diffusion model using
    reinforcement learning. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/scripts/stable_diffusion_tuning_example.py`](https://github.com/huggingface/trl/blob/main/examples/scripts/stable_diffusion_tuning_example.py)
    | æ­¤è„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨DDPOTraineræ¥ä½¿ç”¨å¼ºåŒ–å­¦ä¹ å¾®è°ƒç¨³å®šæ‰©æ•£æ¨¡å‹ã€‚ |'
- en: 'Here are also some easier-to-run colab notebooks that you can use to get started
    with TRL:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œè¿˜æœ‰ä¸€äº›æ›´å®¹æ˜“è¿è¡Œçš„colabç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ç”¨æ¥å¼€å§‹ä½¿ç”¨TRLï¼š
- en: '| File | Description |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| æ–‡ä»¶ | æè¿° |'
- en: '| --- | --- |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| [`examples/notebooks/best_of_n.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/best_of_n.ipynb)
    | This notebook demonstrates how to use the â€œBest of Nâ€ sampling strategy using
    TRL when fine-tuning your model with PPO. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/notebooks/best_of_n.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/best_of_n.ipynb)
    | è¯¥ç¬”è®°æœ¬æ¼”ç¤ºäº†åœ¨ä½¿ç”¨PPOå¾®è°ƒæ¨¡å‹æ—¶å¦‚ä½•ä½¿ç”¨TRLçš„â€œæœ€ä½³Nâ€æŠ½æ ·ç­–ç•¥ã€‚ |'
- en: '| [`examples/notebooks/gpt2-sentiment.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/gpt2-sentiment.ipynb)
    | This notebook demonstrates how to reproduce the GPT2 imdb sentiment tuning example
    on a jupyter notebook. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/notebooks/gpt2-sentiment.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/gpt2-sentiment.ipynb)
    | è¯¥ç¬”è®°æœ¬æ¼”ç¤ºäº†å¦‚ä½•åœ¨jupyterç¬”è®°æœ¬ä¸Šé‡ç°GPT2 imdbæƒ…æ„Ÿè°ƒæ•´ç¤ºä¾‹ã€‚ |'
- en: '| [`examples/notebooks/gpt2-control.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/gpt2-control.ipynb)
    | This notebook demonstrates how to reproduce the GPT2 sentiment control example
    on a jupyter notebook. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| [`examples/notebooks/gpt2-control.ipynb`](https://github.com/huggingface/trl/tree/main/examples/notebooks/gpt2-control.ipynb)
    | è¯¥ç¬”è®°æœ¬æ¼”ç¤ºäº†å¦‚ä½•åœ¨jupyterç¬”è®°æœ¬ä¸Šé‡ç°GPT2æƒ…æ„Ÿæ§åˆ¶ç¤ºä¾‹ã€‚ |'
- en: 'We also have some other examples that are less maintained but can be used as
    a reference:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜æœ‰ä¸€äº›å…¶ä»–ç¤ºä¾‹ï¼Œè™½ç„¶ç»´æŠ¤è¾ƒå°‘ï¼Œä½†å¯ä»¥ç”¨ä½œå‚è€ƒï¼š
- en: '**[research_projects](https://github.com/huggingface/trl/tree/main/examples/research_projects)**:
    Check out this folder to find the scripts used for some research projects that
    used TRL (LM de-toxification, Stack-Llama, etc.)'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[research_projects](https://github.com/huggingface/trl/tree/main/examples/research_projects)ï¼šæŸ¥çœ‹æ­¤æ–‡ä»¶å¤¹ä»¥æ‰¾åˆ°ç”¨äºä½¿ç”¨TRLçš„ä¸€äº›ç ”ç©¶é¡¹ç›®çš„è„šæœ¬ï¼ˆLMå»æ¯’åŒ–ï¼ŒStack-Llamaç­‰ï¼‰'
- en: Distributed training
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ†å¸ƒå¼è®­ç»ƒ
- en: All of the scripts can be run on multiple GPUs by providing the path of an ğŸ¤—
    Accelerate config file when calling `accelerate launch`. To launch one of them
    on one or multiple GPUs, run the following command (swapping `{NUM_GPUS}` with
    the number of GPUs in your machine and `--all_arguments_of_the_script` with your
    arguments.)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åœ¨è°ƒç”¨`accelerate launch`æ—¶æä¾›ğŸ¤— Accelerateé…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œæ‰€æœ‰è„šæœ¬éƒ½å¯ä»¥åœ¨å¤šä¸ªGPUä¸Šè¿è¡Œã€‚è¦åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªGPUä¸Šå¯åŠ¨å…¶ä¸­ä¸€ä¸ªï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆå°†`{NUM_GPUS}`æ›¿æ¢ä¸ºæ‚¨æœºå™¨ä¸Šçš„GPUæ•°é‡ï¼Œå°†`--all_arguments_of_the_script`æ›¿æ¢ä¸ºæ‚¨çš„å‚æ•°ã€‚ï¼‰
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can also adjust the parameters of the ğŸ¤— Accelerate config file to suit your
    needs (e.g. training in mixed precision).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜å¯ä»¥è°ƒæ•´ğŸ¤— Accelerateé…ç½®æ–‡ä»¶çš„å‚æ•°ä»¥æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼ˆä¾‹å¦‚åœ¨æ··åˆç²¾åº¦ä¸‹è®­ç»ƒï¼‰ã€‚
- en: Distributed training with DeepSpeed
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨DeepSpeedè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
- en: 'Most of the scripts can be run on multiple GPUs together with DeepSpeed ZeRO-{1,2,3}
    for efficient sharding of the optimizer states, gradients, and model weights.
    To do so, run following command (swapping `{NUM_GPUS}` with the number of GPUs
    in your machine, `--all_arguments_of_the_script` with your arguments, and `--deepspeed_config`
    with the path to the DeepSpeed config file such as `examples/deepspeed_configs/deepspeed_zero1.yaml`):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°è„šæœ¬å¯ä»¥ä¸DeepSpeed ZeRO-{1,2,3}ä¸€èµ·åœ¨å¤šä¸ªGPUä¸Šè¿è¡Œï¼Œä»¥å®ç°ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦å’Œæ¨¡å‹æƒé‡çš„æœ‰æ•ˆåˆ†ç‰‡ã€‚è¦è¿™æ ·åšï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆå°†`{NUM_GPUS}`æ›¿æ¢ä¸ºæ‚¨æœºå™¨ä¸Šçš„GPUæ•°é‡ï¼Œå°†`--all_arguments_of_the_script`æ›¿æ¢ä¸ºæ‚¨çš„å‚æ•°ï¼Œå°†`--deepspeed_config`æ›¿æ¢ä¸ºDeepSpeedé…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œä¾‹å¦‚`examples/deepspeed_configs/deepspeed_zero1.yaml`ï¼‰ï¼š
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
