# 在 Apple 硅上进行 PyTorch 训练

> 原始文本：[`huggingface.co/docs/transformers/v4.37.2/en/perf_train_special`](https://huggingface.co/docs/transformers/v4.37.2/en/perf_train_special)

以前，在 Mac 上训练模型仅限于 CPU。随着 PyTorch v1.12 的发布，您可以利用使用 Apple 的硅 GPU 训练模型，以获得更快的性能和训练速度。在 PyTorch 中，这是通过将 Apple 的 Metal Performance Shaders（MPS）集成为后端来实现的。[MPS 后端](https://pytorch.org/docs/stable/notes/mps.html)将 PyTorch 操作实现为自定义的 Metal 着色器，并将这些模块放置在`mps`设备上。

一些 PyTorch 操作尚未在 MPS 中实现，将会引发错误。为了避免这种情况，您应该设置环境变量`PYTORCH_ENABLE_MPS_FALLBACK=1`来使用 CPU 内核（仍会看到`UserWarning`）。

如果遇到其他错误，请在[PyTorch](https://github.com/pytorch/pytorch/issues)存储库中打开问题，因为 Trainer 仅集成了 MPS 后端。

设置`mps`设备后，您可以：

+   在本地训练更大的网络或批量大小

+   减少数据检索延迟，因为 GPU 的统一内存架构允许直接访问完整的内存存储

+   减少成本，因为您不需要在基于云的 GPU 上进行训练或添加额外的本地 GPU

首先确保您已安装 PyTorch。MPS 加速支持 macOS 12.3+。

```py
pip install torch torchvision torchaudio
```

TrainingArguments 默认使用`mps`设备，如果可用的话，这意味着您不需要显式设置设备。例如，您可以在不进行任何更改的情况下自动启用 MPS 后端运行[run_glue.py](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py)脚本。

```py
export TASK_NAME=mrpc

python examples/pytorch/text-classification/run_glue.py \
  --model_name_or_path bert-base-cased \
  --task_name $TASK_NAME \
- --use_mps_device \
  --do_train \
  --do_eval \
  --max_seq_length 128 \
  --per_device_train_batch_size 32 \
  --learning_rate 2e-5 \
  --num_train_epochs 3 \
  --output_dir /tmp/$TASK_NAME/ \
  --overwrite_output_dir
```

像`gloo`和`nccl`这样的[分布式设置](https://pytorch.org/docs/stable/distributed.html#backends)的后端不受`mps`设备支持，这意味着您只能在具有 MPS 后端的单个 GPU 上进行训练。

您可以在[在 Mac 上介绍加速 PyTorch 训练](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)博客文章中了解更多关于 MPS 后端的信息。
