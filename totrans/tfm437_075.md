# 在Apple硅上进行PyTorch训练

> 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/perf_train_special](https://huggingface.co/docs/transformers/v4.37.2/en/perf_train_special)

以前，在Mac上训练模型仅限于CPU。随着PyTorch v1.12的发布，您可以利用使用Apple的硅GPU训练模型，以获得更快的性能和训练速度。在PyTorch中，这是通过将Apple的Metal Performance Shaders（MPS）集成为后端来实现的。[MPS后端](https://pytorch.org/docs/stable/notes/mps.html)将PyTorch操作实现为自定义的Metal着色器，并将这些模块放置在`mps`设备上。

一些PyTorch操作尚未在MPS中实现，将会引发错误。为了避免这种情况，您应该设置环境变量`PYTORCH_ENABLE_MPS_FALLBACK=1`来使用CPU内核（仍会看到`UserWarning`）。

如果遇到其他错误，请在[PyTorch](https://github.com/pytorch/pytorch/issues)存储库中打开问题，因为[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)仅集成了MPS后端。

设置`mps`设备后，您可以：

+   在本地训练更大的网络或批量大小

+   减少数据检索延迟，因为GPU的统一内存架构允许直接访问完整的内存存储

+   减少成本，因为您不需要在基于云的GPU上进行训练或添加额外的本地GPU

首先确保您已安装PyTorch。MPS加速支持macOS 12.3+。

```py
pip install torch torchvision torchaudio
```

[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)默认使用`mps`设备，如果可用的话，这意味着您不需要显式设置设备。例如，您可以在不进行任何更改的情况下自动启用MPS后端运行[run_glue.py](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py)脚本。

```py
export TASK_NAME=mrpc

python examples/pytorch/text-classification/run_glue.py \
  --model_name_or_path bert-base-cased \
  --task_name $TASK_NAME \
- --use_mps_device \
  --do_train \
  --do_eval \
  --max_seq_length 128 \
  --per_device_train_batch_size 32 \
  --learning_rate 2e-5 \
  --num_train_epochs 3 \
  --output_dir /tmp/$TASK_NAME/ \
  --overwrite_output_dir
```

像`gloo`和`nccl`这样的[分布式设置](https://pytorch.org/docs/stable/distributed.html#backends)的后端不受`mps`设备支持，这意味着您只能在具有MPS后端的单个GPU上进行训练。

您可以在[在Mac上介绍加速PyTorch训练](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)博客文章中了解更多关于MPS后端的信息。
