# 创建用于训练的数据集

> 原始文本：[`huggingface.co/docs/diffusers/training/create_dataset`](https://huggingface.co/docs/diffusers/training/create_dataset)

Hub 上有许多数据集可用于训练模型，但如果找不到您感兴趣的数据集或想使用自己的数据集，您可以使用🤗Datasets 库创建数据集。数据集结构取决于您想要训练模型的任务。最基本的数据集结构是图像目录，用于无条件图像生成等任务。另一个数据集结构可能是图像目录和包含相应文本标题的文本文件，用于文本到图像生成等任务。

此指南将向您展示两种创建数据集以进行微调的方法：

+   将图像文件夹提供给`--train_data_dir`参数

+   将数据集上传到 Hub，并将数据集存储库 ID 传递给`--dataset_name`参数

💡了解有关如何为训练创建图像数据集的更多信息，请参阅[创建图像数据集](https://huggingface.co/docs/datasets/image_dataset)指南。

## 提供一个作为文件夹的数据集

对于无条件生成，您可以提供自己的数据集作为图像文件夹。训练脚本使用🤗数据集中的[`ImageFolder`](https://huggingface.co/docs/datasets/en/image_dataset#imagefolder)构建器，自动从文件夹构建数据集。您的目录结构应如下所示：

```py
data_dir/xxx.png
data_dir/xxy.png
data_dir/[...]/xxz.png
```

将数据集目录路径传递给`--train_data_dir`参数，然后您可以开始训练：

```py
accelerate launch train_unconditional.py \
    --train_data_dir <path-to-train-directory> \
    <other-arguments>
```

## 将数据上传到 Hub

💡有关在 Hub 上创建和上传数据集的更多详细信息和背景，请查看[使用🤗数据集进行图像搜索](https://huggingface.co/blog/image-search-datasets)帖子。

首先使用[`ImageFolder`](https://huggingface.co/docs/datasets/image_load#imagefolder)功能创建一个数据集，该功能创建一个包含 PIL 编码图像的`image`列。

您可以使用`data_dir`或`data_files`参数指定数据集的位置。`data_files`参数支持将特定文件映射到数据集拆分，如`train`或`test`：

```py
from datasets import load_dataset

# example 1: local folder
dataset = load_dataset("imagefolder", data_dir="path_to_your_folder")

# example 2: local files (supported formats are tar, gzip, zip, xz, rar, zstd)
dataset = load_dataset("imagefolder", data_files="path_to_zip_file")

# example 3: remote files (supported formats are tar, gzip, zip, xz, rar, zstd)
dataset = load_dataset(
    "imagefolder",
    data_files="https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip",
)

# example 4: providing several splits
dataset = load_dataset(
    "imagefolder", data_files={"train": ["path/to/file1", "path/to/file2"], "test": ["path/to/file3", "path/to/file4"]}
)
```

然后使用[push_to_hub](https://huggingface.co/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)方法将数据集上传到 Hub：

```py
# assuming you have ran the huggingface-cli login command in a terminal
dataset.push_to_hub("name_of_your_dataset")

# if you want to push to a private repo, simply pass private=True:
dataset.push_to_hub("name_of_your_dataset", private=True)
```

现在数据集可供训练，通过将数据集名称传递给`--dataset_name`参数：

```py
accelerate launch --mixed_precision="fp16"  train_text_to_image.py \
  --pretrained_model_name_or_path="runwayml/stable-diffusion-v1-5" \
  --dataset_name="name_of_your_dataset" \
  <other-arguments>
```

## 下一步

现在您已经创建了一个数据集，您可以将其插入到训练脚本的`train_data_dir`（如果您的数据集是本地的）或`dataset_name`（如果您的数据集在 Hub 上）参数中。

在您的下一步中，随时尝试使用您的数据集来训练一个模型，用于无条件生成或文本到图像生成！
