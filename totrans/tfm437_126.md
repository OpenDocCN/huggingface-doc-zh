# DeepSpeed é›†æˆ

> åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/deepspeed](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/deepspeed)

[DeepSpeed](https://github.com/microsoft/DeepSpeed) å®ç°äº† [ZeRO è®ºæ–‡](https://arxiv.org/abs/1910.02054) ä¸­æè¿°çš„æ‰€æœ‰å†…å®¹ã€‚ç›®å‰ï¼Œå®ƒå®Œå…¨æ”¯æŒï¼š

1.  ä¼˜åŒ–å™¨çŠ¶æ€åˆ†åŒºï¼ˆZeRO é˜¶æ®µ 1ï¼‰

1.  æ¢¯åº¦åˆ†åŒºï¼ˆZeRO é˜¶æ®µ 2ï¼‰

1.  å‚æ•°åˆ†åŒºï¼ˆZeRO é˜¶æ®µ 3ï¼‰

1.  è‡ªå®šä¹‰æ··åˆç²¾åº¦è®­ç»ƒå¤„ç†

1.  ä¸€ç³»åˆ—åŸºäºå¿«é€Ÿ CUDA æ‰©å±•çš„ä¼˜åŒ–å™¨

1.  ZeRO-Offload åˆ° CPU å’Œ NVMe

ZeRO-Offload æœ‰è‡ªå·±çš„ä¸“ç”¨è®ºæ–‡ï¼š[ZeRO-Offload: Democratizing Billion-Scale Model Training](https://arxiv.org/abs/2101.06840)ã€‚NVMe æ”¯æŒåœ¨è®ºæ–‡ [ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning](https://arxiv.org/abs/2104.07857) ä¸­æœ‰æè¿°ã€‚

DeepSpeed ZeRO-2 ä¸»è¦ä»…ç”¨äºè®­ç»ƒï¼Œå› ä¸ºå…¶ç‰¹æ€§å¯¹æ¨æ–­æ— ç”¨ã€‚

DeepSpeed ZeRO-3 ä¹Ÿå¯ä»¥ç”¨äºæ¨æ–­ï¼Œå› ä¸ºå®ƒå…è®¸å°†åºå¤§çš„æ¨¡å‹åŠ è½½åˆ°å¤šä¸ª GPU ä¸Šï¼Œè¿™åœ¨å•ä¸ª GPU ä¸Šæ˜¯ä¸å¯èƒ½çš„ã€‚

ğŸ¤— Transformers é€šè¿‡ 2 ä¸ªé€‰é¡¹é›†æˆäº† [DeepSpeed](https://github.com/microsoft/DeepSpeed)ï¼š

1.  é€šè¿‡ [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) é›†æˆæ ¸å¿ƒ DeepSpeed åŠŸèƒ½ã€‚è¿™æ˜¯ä¸€ç§ä¸€åˆ‡éƒ½ä¸ºæ‚¨å®Œæˆçš„é›†æˆæ–¹å¼ - åªéœ€æä¾›æ‚¨çš„è‡ªå®šä¹‰é…ç½®æ–‡ä»¶æˆ–ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡æ¿ï¼Œæ‚¨å°±æ— éœ€åšå…¶ä»–äº‹æƒ…ã€‚æœ¬æ–‡æ¡£çš„å¤§éƒ¨åˆ†å†…å®¹éƒ½é›†ä¸­åœ¨è¿™ä¸ªåŠŸèƒ½ä¸Šã€‚

1.  å¦‚æœæ‚¨ä¸ä½¿ç”¨ [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) å¹¶å¸Œæœ›ä½¿ç”¨è‡ªå·±é›†æˆäº† DeepSpeed çš„ Trainerï¼Œæ ¸å¿ƒåŠŸèƒ½å‡½æ•°å¦‚ `from_pretrained` å’Œ `from_config` åŒ…æ‹¬ DeepSpeed çš„å…³é”®éƒ¨åˆ†é›†æˆï¼Œå¦‚ ZeRO é˜¶æ®µ 3 åŠæ›´é«˜ç‰ˆæœ¬çš„ `zero.Init`ã€‚è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·é˜…è¯»å…³äº [é Trainer DeepSpeed é›†æˆ](#nontrainer-deepspeed-integration) çš„æ–‡æ¡£ã€‚

é›†æˆå†…å®¹ï¼š

è®­ç»ƒï¼š

1.  DeepSpeed ZeRO è®­ç»ƒæ”¯æŒå®Œæ•´çš„ ZeRO é˜¶æ®µ 1ã€2 å’Œ 3ï¼Œå¸¦æœ‰ ZeRO-Infinityï¼ˆCPU å’Œ NVME å¸è½½ï¼‰ã€‚

æ¨æ–­ï¼š

1.  DeepSpeed ZeRO æ¨æ–­æ”¯æŒå¸¦æœ‰ ZeRO-Infinity çš„ ZeRO é˜¶æ®µ 3ã€‚å®ƒä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ ZeRO åè®®ï¼Œä½†ä¸ä½¿ç”¨ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåªæœ‰é˜¶æ®µ 3 ä¸æ¨æ–­ç›¸å…³ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ï¼š[zero-inference](#zero-inference)ã€‚

è¿˜æœ‰ DeepSpeed æ¨æ–­ - è¿™æ˜¯ä¸€ç§å®Œå…¨ä¸åŒçš„æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨å¼ é‡å¹¶è¡Œè€Œä¸æ˜¯ ZeROï¼ˆå³å°†æ¨å‡ºï¼‰ã€‚

## Trainer Deepspeed é›†æˆ

### å®‰è£…

é€šè¿‡ pypi å®‰è£…åº“ï¼š

```py
pip install deepspeed
```

æˆ–é€šè¿‡ `transformers` çš„ `extras`ï¼š

```py
pip install transformers[deepspeed]
```

æˆ–åœ¨ [DeepSpeed çš„ GitHub é¡µé¢](https://github.com/microsoft/deepspeed#installation) å’Œ [é«˜çº§å®‰è£…](https://www.deepspeed.ai/tutorials/advanced-install/) ä¸Šæ‰¾åˆ°æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

å¦‚æœæ‚¨ä»åœ¨åŠªåŠ›æ„å»ºï¼Œè¯·é¦–å…ˆç¡®ä¿é˜…è¯» [CUDA æ‰©å±•å®‰è£…è¯´æ˜](trainer#cuda-extension-installation-notes)ã€‚

å¦‚æœæ‚¨æ²¡æœ‰é¢„å…ˆæ„å»ºæ‰©å±•å¹¶ä¾èµ–äºè¿è¡Œæ—¶æ„å»ºå®ƒä»¬ï¼Œå¹¶ä¸”å°è¯•äº†ä»¥ä¸Šæ‰€æœ‰è§£å†³æ–¹æ¡ˆä»æ— æ•ˆï¼Œä¸‹ä¸€æ­¥å°è¯•çš„æ˜¯åœ¨å®‰è£…ä¹‹å‰é¢„å…ˆæ„å»ºæ¨¡å—ã€‚

è¦ä¸º DeepSpeed è¿›è¡Œæœ¬åœ°æ„å»ºï¼š

```py
git clone https://github.com/microsoft/DeepSpeed/
cd DeepSpeed
rm -rf build
TORCH_CUDA_ARCH_LIST="8.6" DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1 pip install . \
--global-option="build_ext" --global-option="-j8" --no-cache -v \
--disable-pip-version-check 2>&1 | tee build.log
```

å¦‚æœæ‚¨æ‰“ç®—ä½¿ç”¨ NVMe å¸è½½ï¼Œè¿˜éœ€è¦åœ¨ä¸Šè¿°è¯´æ˜ä¸­åŒ…å« `DS_BUILD_AIO=1`ï¼ˆå¹¶åœ¨ç³»ç»ŸèŒƒå›´å†…å®‰è£… *libaio-dev*ï¼‰ã€‚

ç¼–è¾‘ `TORCH_CUDA_ARCH_LIST`ï¼Œæ’å…¥æ‚¨æ‰“ç®—ä½¿ç”¨çš„ GPU æ˜¾å¡çš„æ¶æ„ä»£ç ã€‚å‡è®¾æ‰€æœ‰æ˜¾å¡éƒ½ç›¸åŒï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–æ¶æ„ï¼š

```py
CUDA_VISIBLE_DEVICES=0 python -c "import torch; print(torch.cuda.get_device_capability())"
```

å¦‚æœæ‚¨è·å¾—`8, 6`ï¼Œé‚£ä¹ˆè¯·ä½¿ç”¨`TORCH_CUDA_ARCH_LIST="8.6"`ã€‚å¦‚æœæ‚¨æœ‰å¤šå¼ ä¸åŒçš„æ˜¾å¡ï¼Œå¯ä»¥åˆ—å‡ºæ‰€æœ‰æ˜¾å¡ï¼Œä¾‹å¦‚`TORCH_CUDA_ARCH_LIST="6.1;8.6"`ã€‚

å¦‚æœæ‚¨éœ€è¦åœ¨å¤šå°æœºå™¨ä¸Šä½¿ç”¨ç›¸åŒçš„è®¾ç½®ï¼Œè¯·åˆ¶ä½œä¸€ä¸ªäºŒè¿›åˆ¶ wheelï¼š

```py
git clone https://github.com/microsoft/DeepSpeed/
cd DeepSpeed
rm -rf build
TORCH_CUDA_ARCH_LIST="8.6" DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1 \
python setup.py build_ext -j8 bdist_wheel
```

å®ƒå°†ç”Ÿæˆç±»ä¼¼äº`dist/deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl`çš„å†…å®¹ï¼Œç°åœ¨æ‚¨å¯ä»¥åœ¨æœ¬åœ°æˆ–ä»»ä½•å…¶ä»–æœºå™¨ä¸Šå®‰è£…ä¸º`pip install deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl`ã€‚

å†æ¬¡æé†’ç¡®ä¿è°ƒæ•´`TORCH_CUDA_ARCH_LIST`ä»¥åŒ¹é…ç›®æ ‡æ¶æ„ã€‚

æ‚¨å¯ä»¥åœ¨[æ­¤å¤„](https://developer.nvidia.com/cuda-gpus)æ‰¾åˆ°NVIDIA GPUçš„å®Œæ•´åˆ—è¡¨åŠå…¶å¯¹åº”çš„**è®¡ç®—èƒ½åŠ›**ï¼ˆåœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­ä¸æ¶æ„ç›¸åŒï¼‰ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ£€æŸ¥PyTorchæ„å»ºæ—¶ä½¿ç”¨çš„æ¶æ„ï¼š

```py
python -c "import torch; print(torch.cuda.get_arch_list())"
```

ä»¥ä¸‹æ˜¯å¦‚ä½•æŸ¥æ‰¾å·²å®‰è£…GPUä¹‹ä¸€çš„æ¶æ„ã€‚ä¾‹å¦‚ï¼Œå¯¹äºGPU 0ï¼š

```py
CUDA_VISIBLE_DEVICES=0 python -c "import torch; \
print(torch.cuda.get_device_properties(torch.device('cuda')))"
```

å¦‚æœè¾“å‡ºæ˜¯ï¼š

```py
_CudaDeviceProperties(name='GeForce RTX 3090', major=8, minor=6, total_memory=24268MB, multi_processor_count=82)
```

é‚£ä¹ˆæ‚¨å°±çŸ¥é“è¿™å¼ å¡çš„æ¶æ„æ˜¯`8.6`ã€‚

æ‚¨ä¹Ÿå¯ä»¥å®Œå…¨ä¸ä½¿ç”¨`TORCH_CUDA_ARCH_LIST`ï¼Œç„¶åæ„å»ºç¨‹åºå°†è‡ªåŠ¨æŸ¥è¯¢æ„å»ºæ‰€åœ¨çš„GPUçš„æ¶æ„ã€‚è¿™å¯èƒ½ä¸ç›®æ ‡æœºå™¨ä¸Šçš„GPUä¸åŒ¹é…ï¼Œå› æ­¤æœ€å¥½æ˜ç¡®æŒ‡å®šæ‰€éœ€çš„æ¶æ„ã€‚

å¦‚æœå°è¯•äº†æ‰€æœ‰å»ºè®®çš„æ–¹æ³•ä»ç„¶é‡åˆ°æ„å»ºé—®é¢˜ï¼Œè¯·ç»§ç»­è¿›è¡Œ[Deepspeed](https://github.com/microsoft/DeepSpeed/issues)çš„GitHubé—®é¢˜å¤„ç†ï¼Œ

### ä½¿ç”¨å¤šä¸ªGPUè¿›è¡Œéƒ¨ç½²

è¦éƒ¨ç½²DeepSpeedé›†æˆï¼Œè¯·è°ƒæ•´[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°ï¼ŒåŒ…æ‹¬ä¸€ä¸ªæ–°å‚æ•°`--deepspeed ds_config.json`ï¼Œå…¶ä¸­`ds_config.json`æ˜¯DeepSpeedé…ç½®æ–‡ä»¶ï¼Œå¦‚[æ­¤å¤„](https://www.deepspeed.ai/docs/config-json/)æ‰€è¿°ã€‚æ–‡ä»¶å‘½åç”±æ‚¨å†³å®šã€‚å»ºè®®ä½¿ç”¨DeepSpeedçš„`add_config_arguments`å®ç”¨ç¨‹åºå‘æ‚¨çš„ä»£ç æ·»åŠ å¿…è¦çš„å‘½ä»¤è¡Œå‚æ•°ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[DeepSpeedçš„å‚æ•°è§£æ](https://deepspeed.readthedocs.io/en/latest/initialize.html#argument-parsing)æ–‡æ¡£ã€‚

æ‚¨å¯ä»¥åœ¨æ­¤å¤„ä½¿ç”¨æ‚¨é€‰æ‹©çš„å¯åŠ¨å™¨ã€‚æ‚¨å¯ä»¥ç»§ç»­ä½¿ç”¨pytorchå¯åŠ¨å™¨ï¼š

```py
torch.distributed.run --nproc_per_node=2 your_program.py <normal cl args> --deepspeed ds_config.json
```

æˆ–è€…ä½¿ç”¨`deepspeed`æä¾›çš„å¯åŠ¨å™¨ï¼š

```py
deepspeed --num_gpus=2 your_program.py <normal cl args> --deepspeed ds_config.json
```

æ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„å‚æ•°ä¸åŒï¼Œä½†å¯¹äºå¤§å¤šæ•°éœ€æ±‚ï¼Œä»»ä½•ä¸€ä¸ªéƒ½å¯ä»¥ã€‚æœ‰å…³å¦‚ä½•é…ç½®å„ä¸ªèŠ‚ç‚¹å’ŒGPUçš„å®Œæ•´è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[æ­¤å¤„](https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node)ã€‚

å½“æ‚¨ä½¿ç”¨`deepspeed`å¯åŠ¨å™¨å¹¶ä¸”å¸Œæœ›ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„GPUæ—¶ï¼Œæ‚¨å¯ä»¥åªçœç•¥`--num_gpus`æ ‡å¿—ã€‚

ä»¥ä¸‹æ˜¯åœ¨DeepSpeedä¸‹éƒ¨ç½²æ‰€æœ‰å¯ç”¨GPUè¿è¡Œ`run_translation.py`çš„ç¤ºä¾‹ï¼š

```py
deepspeed examples/pytorch/translation/run_translation.py \
--deepspeed tests/deepspeed/ds_config_zero3.json \
--model_name_or_path t5-small --per_device_train_batch_size 1 \
--output_dir output_dir --overwrite_output_dir --fp16 \
--do_train --max_train_samples 500 --num_train_epochs 1 \
--dataset_name wmt16 --dataset_config "ro-en" \
--source_lang en --target_lang ro
```

è¯·æ³¨æ„ï¼Œåœ¨DeepSpeedæ–‡æ¡£ä¸­ï¼Œæ‚¨å¯èƒ½ä¼šçœ‹åˆ°`--deepspeed --deepspeed_config ds_config.json` - å³ä¸¤ä¸ªä¸DeepSpeedç›¸å…³çš„å‚æ•°ï¼Œä½†ä¸ºäº†ç®€å•èµ·è§ï¼Œå¹¶ä¸”å·²ç»æœ‰å¾ˆå¤šå‚æ•°è¦å¤„ç†ï¼Œæˆ‘ä»¬å°†ä¸¤è€…åˆå¹¶ä¸ºä¸€ä¸ªå‚æ•°ã€‚

æœ‰å…³ä¸€äº›å®é™…ç”¨ä¾‹ç¤ºä¾‹ï¼Œè¯·å‚é˜…æ­¤[å¸–å­](https://github.com/huggingface/transformers/issues/8771#issuecomment-759248400)ã€‚

### ä½¿ç”¨å•ä¸ªGPUè¿›è¡Œéƒ¨ç½²

ä½¿ç”¨å•ä¸ªGPUéƒ¨ç½²DeepSpeedæ—¶ï¼Œè¯·è°ƒæ•´[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°å¦‚ä¸‹ï¼š

```py
deepspeed --num_gpus=1 examples/pytorch/translation/run_translation.py \
--deepspeed tests/deepspeed/ds_config_zero2.json \
--model_name_or_path t5-small --per_device_train_batch_size 1 \
--output_dir output_dir --overwrite_output_dir --fp16 \
--do_train --max_train_samples 500 --num_train_epochs 1 \
--dataset_name wmt16 --dataset_config "ro-en" \
--source_lang en --target_lang ro
```

è¿™ä¸å¤šGPUå‡ ä¹ç›¸åŒï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬æ˜ç¡®å‘Šè¯‰DeepSpeedä»…ä½¿ç”¨ä¸€ä¸ªGPUé€šè¿‡`--num_gpus=1`ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒDeepSpeedéƒ¨ç½²ç»™å®šèŠ‚ç‚¹ä¸Šå¯ä»¥çœ‹åˆ°çš„æ‰€æœ‰GPUã€‚å¦‚æœæ‚¨ä¸€å¼€å§‹åªæœ‰1ä¸ªGPUï¼Œåˆ™ä¸éœ€è¦æ­¤å‚æ•°ã€‚ä»¥ä¸‹[æ–‡æ¡£](https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node)è®¨è®ºäº†å¯åŠ¨å™¨é€‰é¡¹ã€‚

ä¸ºä»€ä¹ˆè¦ä»…ä½¿ç”¨ä¸€ä¸ªGPUæ¥ä½¿ç”¨DeepSpeedï¼Ÿ

1.  å®ƒå…·æœ‰ZeRO-offloadåŠŸèƒ½ï¼Œå¯ä»¥å°†ä¸€äº›è®¡ç®—å’Œå†…å­˜å§”æ‰˜ç»™ä¸»æœºçš„CPUå’ŒRAMï¼Œä»è€Œä¸ºæ¨¡å‹çš„éœ€æ±‚ç•™ä¸‹æ›´å¤šçš„GPUèµ„æº - ä¾‹å¦‚æ›´å¤§çš„æ‰¹é‡å¤§å°ï¼Œæˆ–è€…å¯ç”¨ä¸€ä¸ªé€šå¸¸æ— æ³•é€‚åº”çš„éå¸¸å¤§çš„æ¨¡å‹ã€‚

1.  å®ƒæä¾›äº†ä¸€ä¸ªæ™ºèƒ½çš„GPUå†…å­˜ç®¡ç†ç³»ç»Ÿï¼Œå¯ä»¥æœ€å°åŒ–å†…å­˜ç¢ç‰‡åŒ–ï¼Œè¿™æ ·å¯ä»¥ä½¿æ‚¨é€‚åº”æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®æ‰¹æ¬¡ã€‚

è™½ç„¶æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥è¯¦ç»†è®¨è®ºé…ç½®ï¼Œä½†åœ¨DeepSpeedä¸­è·å¾—å•ä¸ªGPUä¸Šçš„å·¨å¤§æ”¹è¿›çš„å…³é”®æ˜¯è‡³å°‘åœ¨é…ç½®æ–‡ä»¶ä¸­å…·æœ‰ä»¥ä¸‹é…ç½®ï¼š

```py
{
  "zero_optimization": {
     "stage": 2,
     "offload_optimizer": {
         "device": "cpu",
         "pin_memory": true
     },
     "allgather_partitions": true,
     "allgather_bucket_size": 2e8,
     "reduce_scatter": true,
     "reduce_bucket_size": 2e8,
     "overlap_comm": true,
     "contiguous_gradients": true
  }
}
```

å®ƒå¯ä»¥å¯ç”¨ä¼˜åŒ–å™¨å¸è½½å’Œä¸€äº›å…¶ä»–é‡è¦åŠŸèƒ½ã€‚æ‚¨å¯ä»¥å°è¯•ä¸åŒçš„ç¼“å†²åŒºå¤§å°ï¼Œåœ¨ä¸‹é¢çš„è®¨è®ºä¸­ä¼šæ‰¾åˆ°æ›´å¤šç»†èŠ‚ã€‚

æœ‰å…³æ­¤ç±»å‹éƒ¨ç½²çš„å®é™…ä½¿ç”¨ç¤ºä¾‹ï¼Œè¯·å‚è§æ­¤[å¸–å­](https://github.com/huggingface/transformers/issues/8771#issuecomment-759176685)ã€‚

æ‚¨è¿˜å¯ä»¥å°è¯•ä½¿ç”¨CPUå’ŒNVMeå¸è½½çš„ZeRO-3ï¼Œå¦‚æœ¬æ–‡æ¡£ä¸­è¿›ä¸€æ­¥è§£é‡Šçš„é‚£æ ·ã€‚

æ³¨ï¼š

+   å¦‚æœéœ€è¦åœ¨ç‰¹å®šGPUä¸Šè¿è¡Œï¼Œè€Œä¸æ˜¯GPU 0ï¼Œæ‚¨ä¸èƒ½ä½¿ç”¨`CUDA_VISIBLE_DEVICES`æ¥é™åˆ¶å¯ç”¨GPUçš„å¯è§èŒƒå›´ã€‚ç›¸åï¼Œæ‚¨å¿…é¡»ä½¿ç”¨ä»¥ä¸‹è¯­æ³•ï¼š

    ```py
    deepspeed --include localhost:1 examples/pytorch/translation/run_translation.py ...
    ```

    åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å‘Šè¯‰DeepSpeedä½¿ç”¨GPU 1ï¼ˆç¬¬äºŒä¸ªGPUï¼‰ã€‚

### å¤šèŠ‚ç‚¹éƒ¨ç½²

æœ¬èŠ‚ä¸­çš„ä¿¡æ¯ä¸æ˜¯ç‰¹å®šäºDeepSpeedé›†æˆçš„ï¼Œé€‚ç”¨äºä»»ä½•å¤šèŠ‚ç‚¹ç¨‹åºã€‚ä½†DeepSpeedæä¾›äº†ä¸€ä¸ªæ¯”å…¶ä»–å¯åŠ¨å™¨æ›´å®¹æ˜“ä½¿ç”¨çš„`deepspeed`å¯åŠ¨å™¨ï¼Œé™¤éæ‚¨åœ¨SLURMç¯å¢ƒä¸­ã€‚

åœ¨æœ¬èŠ‚çš„æŒç»­æ—¶é—´å†…ï¼Œè®©æˆ‘ä»¬å‡è®¾æ‚¨æœ‰2ä¸ªæ¯ä¸ª8ä¸ªGPUçš„èŠ‚ç‚¹ã€‚æ‚¨å¯ä»¥é€šè¿‡`ssh hostname1`åˆ°è¾¾ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼Œé€šè¿‡`ssh hostname2`åˆ°è¾¾ç¬¬äºŒä¸ªèŠ‚ç‚¹ï¼Œå¹¶ä¸”ä¸¤ä¸ªèŠ‚ç‚¹å¿…é¡»èƒ½å¤Ÿé€šè¿‡æœ¬åœ°sshæ— å¯†ç åœ°ç›¸äº’åˆ°è¾¾ã€‚å½“ç„¶ï¼Œæ‚¨éœ€è¦å°†è¿™äº›ä¸»æœºï¼ˆèŠ‚ç‚¹ï¼‰åç§°é‡å‘½åä¸ºæ‚¨æ­£åœ¨ä½¿ç”¨çš„å®é™…ä¸»æœºåç§°ã€‚

#### torch.distributed.run(torchrun)å¯åŠ¨å™¨

ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨`torch.distributed.run`ï¼Œæ‚¨å¯ä»¥è¿™æ ·åšï¼š

```py
python -m torch.distributed.run --nproc_per_node=8 --nnode=2 --node_rank=0 --master_addr=hostname1 \
--master_port=9901 your_program.py <normal cl args> --deepspeed ds_config.json
```

æ‚¨å¿…é¡»sshåˆ°æ¯ä¸ªèŠ‚ç‚¹å¹¶åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œç›¸åŒçš„å‘½ä»¤ï¼ä¸ç”¨ç€æ€¥ï¼Œå¯åŠ¨å™¨ä¼šç­‰å¾…ç›´åˆ°ä¸¤ä¸ªèŠ‚ç‚¹åŒæ­¥ã€‚

æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§[torchrun](https://pytorch.org/docs/stable/elastic/run.html)ã€‚é¡ºä¾¿è¯´ä¸€å¥ï¼Œè¿™ä¹Ÿæ˜¯å‡ ä¸ªpytorchç‰ˆæœ¬å‰æ›¿ä»£äº†`torch.distributed.launch`çš„å¯åŠ¨å™¨ã€‚

#### deepspeedå¯åŠ¨å™¨

è¦ä½¿ç”¨`deepspeed`å¯åŠ¨å™¨ï¼Œæ‚¨é¦–å…ˆéœ€è¦åˆ›å»ºä¸€ä¸ª`hostfile`æ–‡ä»¶ï¼š

```py
hostname1 slots=8
hostname2 slots=8
```

ç„¶åæ‚¨å¯ä»¥è¿™æ ·å¯åŠ¨ï¼š

```py
deepspeed --num_gpus 8 --num_nodes 2 --hostfile hostfile --master_addr hostname1 --master_port=9901 \
your_program.py <normal cl args> --deepspeed ds_config.json
```

ä¸`torch.distributed.run`å¯åŠ¨å™¨ä¸åŒï¼Œ`deepspeed`å°†è‡ªåŠ¨åœ¨ä¸¤ä¸ªèŠ‚ç‚¹ä¸Šå¯åŠ¨æ­¤å‘½ä»¤ï¼

æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§[èµ„æºé…ç½®ï¼ˆå¤šèŠ‚ç‚¹ï¼‰](https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node)ã€‚

#### åœ¨SLURMç¯å¢ƒä¸­å¯åŠ¨

åœ¨SLURMç¯å¢ƒä¸­å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªslurmè„šæœ¬`launch.slurm`ï¼Œæ‚¨éœ€è¦æ ¹æ®æ‚¨ç‰¹å®šçš„SLURMç¯å¢ƒè¿›è¡Œè°ƒæ•´ã€‚

```py
#SBATCH --job-name=test-nodes        # name
#SBATCH --nodes=2                    # nodes
#SBATCH --ntasks-per-node=1          # crucial - only 1 task per dist per node!
#SBATCH --cpus-per-task=10           # number of cores per tasks
#SBATCH --gres=gpu:8                 # number of gpus
#SBATCH --time 20:00:00              # maximum execution time (HH:MM:SS)
#SBATCH --output=%x-%j.out           # output file name

export GPUS_PER_NODE=8
export MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=9901

srun --jobid $SLURM_JOBID bash -c 'python -m torch.distributed.run \
 --nproc_per_node $GPUS_PER_NODE --nnodes $SLURM_NNODES --node_rank $SLURM_PROCID \
 --master_addr $MASTER_ADDR --master_port $MASTER_PORT \
your_program.py <normal cl args> --deepspeed ds_config.json'
```

å‰©ä¸‹çš„å°±æ˜¯å®‰æ’å®ƒè¿è¡Œï¼š

```py
sbatch launch.slurm
```

`srun`å°†è´Ÿè´£åŒæ—¶åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šå¯åŠ¨ç¨‹åºã€‚

#### éå…±äº«æ–‡ä»¶ç³»ç»Ÿçš„ä½¿ç”¨

é»˜è®¤æƒ…å†µä¸‹ï¼ŒDeepSpeedæœŸæœ›å¤šèŠ‚ç‚¹ç¯å¢ƒä½¿ç”¨å…±äº«å­˜å‚¨ã€‚å¦‚æœä¸æ˜¯è¿™ç§æƒ…å†µï¼Œæ¯ä¸ªèŠ‚ç‚¹åªèƒ½çœ‹åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼Œæ‚¨éœ€è¦è°ƒæ•´é…ç½®æ–‡ä»¶ä»¥åŒ…å«ä¸€ä¸ª[`checkpoint`_section](https://www.deepspeed.ai/docs/config-json/#checkpoint-options)ï¼Œè®¾ç½®å¦‚ä¸‹ï¼š

```py
{
  "checkpoint": {
    "use_node_local_storage": true
  }
}
```

æˆ–è€…ï¼Œæ‚¨è¿˜å¯ä»¥ä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)çš„`--save_on_each_node`å‚æ•°ï¼Œä¸Šè¿°é…ç½®å°†è‡ªåŠ¨æ·»åŠ ç»™æ‚¨ã€‚

### ç¬”è®°æœ¬ä¸­çš„éƒ¨ç½²

å°†ç¬”è®°æœ¬å•å…ƒæ ¼ä½œä¸ºè„šæœ¬è¿è¡Œçš„é—®é¢˜åœ¨äºæ²¡æœ‰æ­£å¸¸çš„`deepspeed`å¯åŠ¨å™¨å¯ä¾›ä¾èµ–ï¼Œå› æ­¤åœ¨æŸäº›è®¾ç½®ä¸‹ï¼Œæˆ‘ä»¬å¿…é¡»æ¨¡æ‹Ÿå®ƒã€‚

å¦‚æœæ‚¨åªä½¿ç”¨1ä¸ªGPUï¼Œä»¥ä¸‹æ˜¯æ‚¨å¿…é¡»è°ƒæ•´ç¬”è®°æœ¬ä¸­çš„è®­ç»ƒä»£ç ä»¥ä½¿ç”¨DeepSpeedçš„æ–¹å¼ã€‚

```py
# DeepSpeed requires a distributed environment even when only one process is used.
# This emulates a launcher in the notebook
import os

os.environ["MASTER_ADDR"] = "localhost"
os.environ["MASTER_PORT"] = "9994"  # modify if RuntimeError: Address already in use
os.environ["RANK"] = "0"
os.environ["LOCAL_RANK"] = "0"
os.environ["WORLD_SIZE"] = "1"

# Now proceed as normal, plus pass the deepspeed config file
training_args = TrainingArguments(..., deepspeed="ds_config_zero3.json")
trainer = Trainer(...)
trainer.train()
```

æ³¨æ„ï¼š`...`ä»£è¡¨æ‚¨å°†ä¼ é€’ç»™å‡½æ•°çš„å¸¸è§„å‚æ•°ã€‚

å¦‚æœè¦ä½¿ç”¨å¤šä¸ªGPUï¼Œå¿…é¡»ä½¿ç”¨å¤šè¿›ç¨‹ç¯å¢ƒæ‰èƒ½ä½¿DeepSpeedæ­£å¸¸å·¥ä½œã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ‚¨å¿…é¡»ä½¿ç”¨è¯¥ç›®çš„çš„å¯åŠ¨å™¨ï¼Œè€Œä¸èƒ½é€šè¿‡æ¨¡æ‹Ÿæœ¬èŠ‚å¼€å¤´ä»‹ç»çš„åˆ†å¸ƒå¼ç¯å¢ƒæ¥å®ç°ã€‚

å¦‚æœæ‚¨æƒ³åœ¨å½“å‰ç›®å½•çš„ç¬”è®°æœ¬ä¸­å³æ—¶åˆ›å»ºé…ç½®æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨ä¸“ç”¨å•å…ƒæ ¼ï¼š

```py
%%bash
cat <<'EOT' > ds_config_zero3.json
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
EOT
```

å¦‚æœè®­ç»ƒè„šæœ¬åœ¨æ™®é€šæ–‡ä»¶ä¸­è€Œä¸æ˜¯åœ¨ç¬”è®°æœ¬å•å…ƒæ ¼ä¸­ï¼Œæ‚¨å¯ä»¥ä»å•å…ƒæ ¼ä¸­æ­£å¸¸å¯åŠ¨`deepspeed`ã€‚ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨`run_translation.py`ï¼Œæ‚¨å¯ä»¥è¿™æ ·å¯åŠ¨å®ƒï¼š

```py
!git clone https://github.com/huggingface/transformers
!cd transformers; deepspeed examples/pytorch/translation/run_translation.py ...
```

æˆ–è€…ä½¿ç”¨`%%bash`é­”æœ¯ï¼Œæ‚¨å¯ä»¥ç¼–å†™å¤šè¡Œä»£ç ä¾›shellç¨‹åºè¿è¡Œï¼š

```py
%%bash

git clone https://github.com/huggingface/transformers
cd transformers
deepspeed examples/pytorch/translation/run_translation.py ...
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨ä¸éœ€è¦æœ¬èŠ‚å¼€å¤´å‘ˆç°çš„ä»»ä½•ä»£ç ã€‚

æ³¨æ„ï¼šè™½ç„¶`%%bash`é­”æœ¯å¾ˆå¥½ï¼Œä½†ç›®å‰å®ƒä¼šç¼“å†²è¾“å‡ºï¼Œå› æ­¤åœ¨è¿›ç¨‹å®Œæˆä¹‹å‰æ‚¨çœ‹ä¸åˆ°æ—¥å¿—ã€‚

### é…ç½®

æœ‰å…³DeepSpeedé…ç½®æ–‡ä»¶ä¸­å¯ç”¨çš„DeepSpeedé…ç½®é€‰é¡¹çš„å®Œæ•´æŒ‡å—ï¼Œè¯·å‚é˜…[ä»¥ä¸‹æ–‡æ¡£](https://www.deepspeed.ai/docs/config-json/)ã€‚

æ‚¨å¯ä»¥åœ¨[DeepSpeedExampleså­˜å‚¨åº“](https://github.com/microsoft/DeepSpeedExamples)ä¸­æ‰¾åˆ°æ•°åä¸ªè§£å†³å„ç§å®é™…éœ€æ±‚çš„DeepSpeedé…ç½®ç¤ºä¾‹ï¼š

```py
git clone https://github.com/microsoft/DeepSpeedExamples
cd DeepSpeedExamples
find . -name '*json'
```

ç»§ç»­ä¸Šé¢çš„ä»£ç ï¼Œå‡è®¾æ‚¨æƒ³é…ç½®Lambä¼˜åŒ–å™¨ã€‚å› æ­¤ï¼Œæ‚¨å¯ä»¥æœç´¢ç¤ºä¾‹`.json`æ–‡ä»¶ï¼š 

```py
grep -i Lamb $(find . -name '*json')
```

åœ¨[ä¸»å­˜å‚¨åº“](https://github.com/microsoft/DeepSpeed)ä¸­è¿˜å¯ä»¥æ‰¾åˆ°æ›´å¤šç¤ºä¾‹ã€‚

ä½¿ç”¨DeepSpeedæ—¶ï¼Œæ‚¨å§‹ç»ˆéœ€è¦æä¾›ä¸€ä¸ªDeepSpeedé…ç½®æ–‡ä»¶ï¼Œä½†æ˜¯æŸäº›é…ç½®å‚æ•°å¿…é¡»é€šè¿‡å‘½ä»¤è¡Œè¿›è¡Œé…ç½®ã€‚æ‚¨å°†åœ¨æœ¬æŒ‡å—çš„å…¶ä½™éƒ¨åˆ†ä¸­æ‰¾åˆ°ç»†å¾®å·®åˆ«ã€‚

è¦äº†è§£DeepSpeedé…ç½®æ–‡ä»¶çš„å¤–è§‚ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªæ¿€æ´»ZeROé˜¶æ®µ2åŠŸèƒ½çš„ç¤ºä¾‹ï¼ŒåŒ…æ‹¬ä¼˜åŒ–å™¨çŠ¶æ€cpuå¸è½½ï¼Œä½¿ç”¨`AdamW`ä¼˜åŒ–å™¨å’Œ`WarmupLR`è°ƒåº¦ç¨‹åºï¼Œå¹¶ä¸”å¦‚æœä¼ é€’äº†`--fp16`ï¼Œå°†å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼š

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "contiguous_gradients": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
}
```

å½“æ‚¨æ‰§è¡Œç¨‹åºæ—¶ï¼ŒDeepSpeedå°†è®°å½•ä»[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)æ¥æ”¶åˆ°çš„é…ç½®åˆ°æ§åˆ¶å°ï¼Œå› æ­¤æ‚¨å¯ä»¥çœ‹åˆ°æœ€ç»ˆä¼ é€’ç»™å®ƒçš„é…ç½®ã€‚

### ä¼ é€’é…ç½®

å¦‚æœ¬æ–‡æ‰€è¿°ï¼Œé€šå¸¸å°†DeepSpeedé…ç½®ä½œä¸ºjsonæ–‡ä»¶çš„è·¯å¾„ä¼ é€’ï¼Œä½†å¦‚æœæ‚¨ä¸ä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢é…ç½®è®­ç»ƒï¼Œè€Œæ˜¯é€šè¿‡[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)å®ä¾‹åŒ–[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼Œé‚£ä¹ˆå¯¹äº`deepspeed`å‚æ•°ï¼Œæ‚¨å¯ä»¥ä¼ é€’ä¸€ä¸ªåµŒå¥—çš„`dict`ã€‚è¿™å…è®¸æ‚¨å³æ—¶åˆ›å»ºé…ç½®ï¼Œè€Œæ— éœ€å°†å…¶å†™å…¥æ–‡ä»¶ç³»ç»Ÿåå†ä¼ é€’ç»™[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ã€‚

æ€»ç»“ä¸€ä¸‹ï¼Œæ‚¨å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

```py
TrainingArguments(..., deepspeed="/path/to/ds_config.json")
```

æˆ–è€…ï¼š

```py
ds_config_dict = dict(scheduler=scheduler_params, optimizer=optimizer_params)
TrainingArguments(..., deepspeed=ds_config_dict)
```

### å…±äº«é…ç½®

è¿™ä¸€éƒ¨åˆ†æ˜¯å¿…è¯»çš„

æŸäº›é…ç½®å€¼å¯¹äº[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å’ŒDeepSpeedçš„æ­£ç¡®è¿è¡Œéƒ½æ˜¯å¿…éœ€çš„ï¼Œå› æ­¤ï¼Œä¸ºäº†é˜²æ­¢å†²çªçš„å®šä¹‰ï¼Œå¯èƒ½å¯¼è‡´éš¾ä»¥æ£€æµ‹çš„é”™è¯¯ï¼Œæˆ‘ä»¬é€‰æ‹©é€šè¿‡[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°è¿›è¡Œé…ç½®ã€‚

æ­¤å¤–ï¼Œä¸€äº›é…ç½®å€¼æ˜¯æ ¹æ®æ¨¡å‹çš„é…ç½®è‡ªåŠ¨æ´¾ç”Ÿçš„ï¼Œå› æ­¤ï¼Œä¸å…¶è®°ä½æ‰‹åŠ¨è°ƒæ•´å¤šä¸ªå€¼ï¼Œä¸å¦‚è®©[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ä¸ºæ‚¨å®Œæˆå¤§éƒ¨åˆ†é…ç½®ã€‚

å› æ­¤ï¼Œåœ¨æœ¬æŒ‡å—çš„å…¶ä½™éƒ¨åˆ†ä¸­ï¼Œæ‚¨å°†æ‰¾åˆ°ä¸€ä¸ªç‰¹æ®Šçš„é…ç½®å€¼ï¼š`auto`ï¼Œè®¾ç½®åå°†è‡ªåŠ¨æ›¿æ¢ä¸ºæ­£ç¡®æˆ–æœ€æœ‰æ•ˆçš„å€¼ã€‚è¯·éšæ„é€‰æ‹©å¿½ç•¥æ­¤å»ºè®®å¹¶æ˜¾å¼è®¾ç½®å€¼ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯·éå¸¸å°å¿ƒï¼Œç¡®ä¿æ‚¨çš„[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‚æ•°å’ŒDeepSpeedé…ç½®ä¸€è‡´ã€‚ä¾‹å¦‚ï¼Œæ‚¨æ˜¯å¦ä½¿ç”¨ç›¸åŒçš„å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°æˆ–æ¢¯åº¦ç´¯ç§¯è®¾ç½®ï¼Ÿå¦‚æœè¿™äº›ä¸åŒ¹é…ï¼Œè®­ç»ƒå¯èƒ½ä¼šä»¥éå¸¸éš¾ä»¥æ£€æµ‹çš„æ–¹å¼å¤±è´¥ã€‚æ‚¨å·²ç»è¢«è­¦å‘Šäº†ã€‚

è¿˜æœ‰å¤šä¸ªå…¶ä»–å€¼æ˜¯ä¸“é—¨é’ˆå¯¹DeepSpeedçš„ï¼Œæ‚¨å°†éœ€è¦æ‰‹åŠ¨è®¾ç½®ä»¥æ»¡è¶³æ‚¨çš„éœ€æ±‚ã€‚

åœ¨æ‚¨è‡ªå·±çš„ç¨‹åºä¸­ï¼Œå¦‚æœæ‚¨æƒ³è¦ä»¥ä¸»æ§çš„æ–¹å¼ä¿®æ”¹DeepSpeedé…ç½®å¹¶åŸºäºæ­¤é…ç½®[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments) ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ã€‚æ­¥éª¤å¦‚ä¸‹ï¼š

1.  åˆ›å»ºæˆ–åŠ è½½è¦ç”¨ä½œä¸»é…ç½®çš„DeepSpeedé…ç½®

1.  åŸºäºè¿™äº›å€¼åˆ›å»º[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)å¯¹è±¡

è¯·æ³¨æ„ï¼Œä¸€äº›å€¼ï¼Œä¾‹å¦‚`scheduler.params.total_num_steps`æ˜¯ç”±[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)åœ¨`train`æœŸé—´è®¡ç®—çš„ï¼Œä½†æ‚¨å½“ç„¶ä¹Ÿå¯ä»¥è‡ªå·±è¿›è¡Œè®¡ç®—ã€‚

### ZeRO

[Zero Redundancy Optimizer (ZeRO)](https://www.deepspeed.ai/tutorials/zero/) æ˜¯DeepSpeedçš„ä¸»è¦å·¥å…·ã€‚å®ƒæ”¯æŒ3ä¸ªä¸åŒçº§åˆ«ï¼ˆé˜¶æ®µï¼‰çš„ä¼˜åŒ–ã€‚ç¬¬ä¸€ä¸ªå¯¹äºå¯ä¼¸ç¼©æ€§ç›®çš„å¹¶ä¸å¤ªæœ‰è¶£ï¼Œå› æ­¤æœ¬æ–‡æ¡£ä¾§é‡äºé˜¶æ®µ2å’Œ3ã€‚é˜¶æ®µ3é€šè¿‡æœ€æ–°çš„ZeRO-Infinityè¿›ä¸€æ­¥æ”¹è¿›ã€‚æ‚¨å¯ä»¥åœ¨DeepSpeedæ–‡æ¡£ä¸­æ‰¾åˆ°æ›´è¯¦ç»†çš„ä¿¡æ¯ã€‚

é…ç½®æ–‡ä»¶ä¸­çš„`zero_optimization`éƒ¨åˆ†æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†ï¼ˆ[æ–‡æ¡£](https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training)ï¼‰ï¼Œå› ä¸ºåœ¨é‚£é‡Œæ‚¨å®šä¹‰äº†è¦å¯ç”¨å“ªäº›ZeROé˜¶æ®µä»¥åŠå¦‚ä½•é…ç½®å®ƒä»¬ã€‚æ‚¨å¯ä»¥åœ¨DeepSpeedæ–‡æ¡£ä¸­æ‰¾åˆ°æ¯ä¸ªå‚æ•°çš„è§£é‡Šã€‚

æ­¤éƒ¨åˆ†å¿…é¡»é€šè¿‡DeepSpeedé…ç½®è¿›è¡Œç‹¬å é…ç½® - [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) ä¸æä¾›ç­‰æ•ˆçš„å‘½ä»¤è¡Œå‚æ•°ã€‚

æ³¨æ„ï¼šç›®å‰DeepSpeedä¸éªŒè¯å‚æ•°åç§°ï¼Œå› æ­¤å¦‚æœæ‚¨æ‹¼å†™é”™è¯¯ï¼Œå®ƒå°†ä½¿ç”¨æ‹¼å†™é”™è¯¯çš„å‚æ•°çš„é»˜è®¤è®¾ç½®ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹DeepSpeedå¼•æ“å¯åŠ¨æ—¥å¿—æ¶ˆæ¯ï¼Œä»¥æŸ¥çœ‹å®ƒå°†ä½¿ç”¨å“ªäº›å€¼ã€‚

#### ZeRO-2é…ç½®

ä»¥ä¸‹æ˜¯ZeROé˜¶æ®µ2çš„é…ç½®ç¤ºä¾‹ï¼š

```py
{
    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 5e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 5e8,
        "contiguous_gradients": true
    }
}
```

**æ€§èƒ½è°ƒä¼˜ï¼š**

+   å¯ç”¨`offload_optimizer`åº”è¯¥å‡å°‘GPU RAMçš„ä½¿ç”¨ï¼ˆéœ€è¦`"stage": 2`ï¼‰

+   `"overlap_comm": true` é€šè¿‡å¢åŠ GPU RAMä½¿ç”¨é‡æ¥é™ä½å…¨å±€å½’çº¦å»¶è¿Ÿã€‚`overlap_comm` ä½¿ç”¨4.5å€çš„`allgather_bucket_size`å’Œ`reduce_bucket_size`å€¼ã€‚å› æ­¤ï¼Œå¦‚æœå®ƒä»¬è®¾ç½®ä¸º5e8ï¼Œè¿™å°†éœ€è¦9GBçš„å ç”¨ç©ºé—´ï¼ˆ`5e8 x 2å­—èŠ‚ x 2 x 4.5`ï¼‰ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨çš„GPUå…·æœ‰8GBæˆ–æ›´å°‘çš„RAMï¼Œä¸ºäº†é¿å…å‡ºç°OOMé”™è¯¯ï¼Œæ‚¨éœ€è¦å°†è¿™äº›å‚æ•°å‡å°‘åˆ°çº¦`2e8`ï¼Œè¿™å°†éœ€è¦3.6GBã€‚å¦‚æœæ‚¨çš„GPUå®¹é‡æ›´å¤§ï¼Œä½†å¼€å§‹å‡ºç°OOMé”™è¯¯ï¼Œæ‚¨ä¹Ÿéœ€è¦åšåŒæ ·çš„æ“ä½œã€‚

+   å½“å‡å°‘è¿™äº›ç¼“å†²åŒºæ—¶ï¼Œæ‚¨æ­£åœ¨äº¤æ¢é€šä¿¡é€Ÿåº¦ä»¥è·å¾—æ›´å¤šçš„GPU RAMã€‚ç¼“å†²åŒºå¤§å°è¶Šå°ï¼Œé€šä¿¡é€Ÿåº¦è¶Šæ…¢ï¼Œå¯ç”¨äºå…¶ä»–ä»»åŠ¡çš„GPU RAMå°±è¶Šå¤šã€‚å› æ­¤ï¼Œå¦‚æœæ›´å¤§çš„æ‰¹é‡å¤§å°å¾ˆé‡è¦ï¼Œç¨å¾®å‡æ…¢è®­ç»ƒæ—¶é—´å¯èƒ½æ˜¯ä¸€ä¸ªä¸é”™çš„äº¤æ˜“ã€‚

æ­¤å¤–ï¼Œ`deepspeed==0.4.4`æ·»åŠ äº†ä¸€ä¸ªæ–°é€‰é¡¹`round_robin_gradients`ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ç”¨ï¼š

```py
{
    "zero_optimization": {
        "round_robin_gradients": true
    }
}
```

è¿™æ˜¯ç”¨äºCPUå¸è½½çš„é˜¶æ®µ2ä¼˜åŒ–ï¼Œé€šè¿‡ç»†ç²’åº¦æ¢¯åº¦åˆ†åŒºå°†æ¢¯åº¦å¤åˆ¶åˆ°CPUå†…å­˜ä¸­ï¼Œä»¥åœ¨ç­‰çº§ä¹‹é—´å¹¶è¡ŒåŒ–ã€‚æ€§èƒ½æ”¶ç›Šéšç€æ¢¯åº¦ç´¯ç§¯æ­¥éª¤ï¼ˆåœ¨ä¼˜åŒ–å™¨æ­¥éª¤ä¹‹é—´çš„æ›´å¤šå¤åˆ¶ï¼‰æˆ–GPUæ•°é‡ï¼ˆå¢åŠ å¹¶è¡Œæ€§ï¼‰è€Œå¢åŠ ã€‚

#### ZeRO-3é…ç½®

ä»¥ä¸‹æ˜¯ZeROé˜¶æ®µ3çš„é…ç½®ç¤ºä¾‹ï¼š

```py
{
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    }
}
```

å¦‚æœæ‚¨é‡åˆ°OOMï¼Œå› ä¸ºæ‚¨çš„æ¨¡å‹æˆ–æ¿€æ´»ä¸é€‚åˆGPUå†…å­˜ï¼Œå¹¶ä¸”æ‚¨æœ‰æœªä½¿ç”¨çš„CPUå†…å­˜ï¼Œå°†ä¼˜åŒ–å™¨çŠ¶æ€å’Œå‚æ•°å¸è½½åˆ°CPUå†…å­˜å¹¶ä½¿ç”¨`"device": "cpu"`å¯èƒ½è§£å†³æ­¤é™åˆ¶ã€‚å¦‚æœæ‚¨ä¸æƒ³å¸è½½åˆ°CPUå†…å­˜ï¼Œè¯·åœ¨`device`æ¡ç›®ä¸­ä½¿ç”¨`none`è€Œä¸æ˜¯`cpu`ã€‚æœ‰å…³å¸è½½åˆ°NVMeçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…ä¸‹æ–‡ã€‚

é€šè¿‡å°†`pin_memory`è®¾ç½®ä¸º`true`å¯ç”¨äº†å›ºå®šå†…å­˜ã€‚è¿™ä¸ªåŠŸèƒ½å¯ä»¥æé«˜ååé‡ï¼Œä½†ä¼šå‡å°‘å…¶ä»–è¿›ç¨‹å¯ç”¨çš„å†…å­˜ã€‚å›ºå®šå†…å­˜è¢«ä¿ç•™ç»™è¯·æ±‚å®ƒçš„ç‰¹å®šè¿›ç¨‹ï¼Œé€šå¸¸æ¯”æ™®é€šCPUå†…å­˜è®¿é—®é€Ÿåº¦å¿«å¾—å¤šã€‚

**æ€§èƒ½è°ƒä¼˜ï¼š**

+   `stage3_max_live_parameters`ï¼š`1e9`

+   `stage3_max_reuse_distance`ï¼š`1e9`

å¦‚æœé‡åˆ°OOMï¼Œè¯·å‡å°‘`stage3_max_live_parameters`å’Œ`stage3_max_reuse_distance`ã€‚é™¤éè¿›è¡Œæ¿€æ´»æ£€æŸ¥ç‚¹ï¼Œå¦åˆ™å®ƒä»¬å¯¹æ€§èƒ½å½±å“å¾ˆå°ã€‚`1e9`å°†æ¶ˆè€—çº¦2GBã€‚å†…å­˜ç”±`stage3_max_live_parameters`å’Œ`stage3_max_reuse_distance`å…±äº«ï¼Œå› æ­¤ä¸æ˜¯ç´¯åŠ çš„ï¼Œè€Œæ˜¯æ€»å…±2GBã€‚

`stage3_max_live_parameters`æ˜¯æ‚¨å¸Œæœ›åœ¨ä»»ä½•ç»™å®šæ—¶é—´ä¿ç•™åœ¨GPUä¸Šçš„å®Œæ•´å‚æ•°çš„ä¸Šé™ã€‚"é‡ç”¨è·ç¦»"æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„åº¦é‡æ ‡å‡†ï¼Œç”¨äºç¡®å®šå‚æ•°åœ¨æœªæ¥ä½•æ—¶å†æ¬¡ä½¿ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨`stage3_max_reuse_distance`æ¥å†³å®šæ˜¯ä¸¢å¼ƒå‚æ•°è¿˜æ˜¯ä¿ç•™å‚æ•°ã€‚å¦‚æœå‚æ•°å°†åœ¨ä¸ä¹…çš„å°†æ¥ï¼ˆå°äº`stage3_max_reuse_distance`ï¼‰å†æ¬¡ä½¿ç”¨ï¼Œåˆ™æˆ‘ä»¬ä¿ç•™å®ƒä»¥å‡å°‘é€šä¿¡å¼€é”€ã€‚å½“å¯ç”¨æ¿€æ´»æ£€æŸ¥ç‚¹æ—¶ï¼Œè¿™éå¸¸æœ‰å¸®åŠ©ï¼Œæˆ‘ä»¬åœ¨å‰å‘é‡è®¡ç®—å’Œåå‘ä¼ é€’ä¸­ä»¥å•å±‚ç²’åº¦æ‰§è¡Œæ“ä½œï¼Œå¹¶å¸Œæœ›åœ¨å‰å‘é‡è®¡ç®—ä¸­ä¿ç•™å‚æ•°ç›´åˆ°åå‘ä¼ é€’ã€‚

ä»¥ä¸‹é…ç½®å€¼å–å†³äºæ¨¡å‹çš„éšè—å¤§å°ï¼š

+   `reduce_bucket_size`ï¼š`hidden_size*hidden_size`

+   `stage3_prefetch_bucket_size`ï¼š`0.9 * hidden_size * hidden_size`

+   `stage3_param_persistence_threshold`ï¼š`10 * hidden_size`

å› æ­¤å°†è¿™äº›å€¼è®¾ç½®ä¸º`auto`ï¼Œ[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å°†è‡ªåŠ¨åˆ†é…æ¨èå€¼ã€‚å½“ç„¶ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼è®¾ç½®è¿™äº›å€¼ã€‚

`stage3_gather_16bit_weights_on_model_save`åœ¨æ¨¡å‹ä¿å­˜æ—¶å¯ç”¨æ¨¡å‹fp16æƒé‡åˆå¹¶ã€‚å¯¹äºå¤§å‹æ¨¡å‹å’Œå¤šä¸ªGPUï¼Œè¿™æ˜¯ä¸€é¡¹æ˜‚è´µçš„æ“ä½œï¼Œæ— è®ºæ˜¯åœ¨å†…å­˜è¿˜æ˜¯é€Ÿåº¦æ–¹é¢ã€‚å¦‚æœæ‚¨è®¡åˆ’æ¢å¤è®­ç»ƒï¼Œåˆ™ç›®å‰éœ€è¦è¿™æ ·åšã€‚è¯·æ³¨æ„æœªæ¥çš„æ›´æ–°å°†æ¶ˆé™¤æ­¤é™åˆ¶å¹¶ä½¿äº‹æƒ…æ›´åŠ çµæ´»ã€‚

å¦‚æœæ‚¨æ­£åœ¨ä»ZeRO-2é…ç½®è¿ç§»ï¼Œè¯·æ³¨æ„`allgather_partitions`ã€`allgather_bucket_size`å’Œ`reduce_scatter`é…ç½®å‚æ•°åœ¨ZeRO-3ä¸­ä¸ä½¿ç”¨ã€‚å¦‚æœæ‚¨å°†è¿™äº›ä¿ç•™åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼Œå®ƒä»¬å°†è¢«å¿½ç•¥ã€‚

+   `sub_group_size`ï¼š`1e9`

`sub_group_size`æ§åˆ¶å‚æ•°åœ¨ä¼˜åŒ–å™¨æ­¥éª¤ä¸­æ›´æ–°çš„ç²’åº¦ã€‚å‚æ•°è¢«åˆ†ç»„åˆ°`sub_group_size`çš„æ¡¶ä¸­ï¼Œæ¯ä¸ªæ¡¶ä¾æ¬¡æ›´æ–°ã€‚åœ¨ZeRO-Infinityä¸­ä¸NVMeå¸è½½ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œ`sub_group_size`å› æ­¤æ§åˆ¶æ¨¡å‹çŠ¶æ€åœ¨ä¼˜åŒ–å™¨æ­¥éª¤æœŸé—´ä»NVMeç§»å…¥å’Œç§»å‡ºCPUå†…å­˜çš„ç²’åº¦ã€‚è¿™å¯ä»¥é˜²æ­¢æå¤§å‹æ¨¡å‹è€—å°½CPUå†…å­˜ã€‚

å¦‚æœä¸ä½¿ç”¨NVMeå¸è½½ï¼Œå¯ä»¥å°†`sub_group_size`ä¿ç•™ä¸ºé»˜è®¤å€¼*1e9*ã€‚åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½éœ€è¦æ›´æ”¹å…¶é»˜è®¤å€¼ï¼š

1.  åœ¨ä¼˜åŒ–å™¨æ­¥éª¤ä¸­é‡åˆ°OOMï¼šå‡å°‘`sub_group_size`ä»¥å‡å°‘ä¸´æ—¶ç¼“å†²åŒºçš„å†…å­˜åˆ©ç”¨

1.  ä¼˜åŒ–å™¨æ­¥éª¤èŠ±è´¹å¾ˆé•¿æ—¶é—´ï¼šå¢åŠ `sub_group_size`ä»¥æé«˜å¸¦å®½åˆ©ç”¨ç‡ï¼Œå› ä¸ºæ•°æ®ç¼“å†²åŒºå¢åŠ ã€‚

#### ZeRO-0é…ç½®

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å°†é˜¶æ®µ0å’Œ1åˆ—åœ¨æœ€åï¼Œå› ä¸ºå®ƒä»¬å¾ˆå°‘è¢«ä½¿ç”¨ã€‚

é˜¶æ®µ0æ˜¯ç¦ç”¨æ‰€æœ‰ç±»å‹çš„åˆ†ç‰‡ï¼Œåªä½¿ç”¨DeepSpeedä½œä¸ºDDPã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ‰“å¼€å®ƒï¼š

```py
{
    "zero_optimization": {
        "stage": 0
    }
}
```

è¿™å°†åŸºæœ¬ä¸Šç¦ç”¨ZeROï¼Œè€Œæ— éœ€æ›´æ”¹å…¶ä»–ä»»ä½•å†…å®¹ã€‚

#### ZeRO-1é…ç½®

é˜¶æ®µ1æ˜¯é˜¶æ®µ2å‡å»æ¢¯åº¦åˆ†ç‰‡ã€‚æ‚¨å¯ä»¥å°è¯•å°†ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡ï¼Œä»¥åŠ å¿«é€Ÿåº¦ï¼š

```py
{
    "zero_optimization": {
        "stage": 1
    }
}
```

### NVMeæ”¯æŒ

ZeRO-Infinityé€šè¿‡ä½¿ç”¨NVMeå†…å­˜æ‰©å±•GPUå’ŒCPUå†…å­˜ï¼Œå…è®¸è®­ç»ƒéå¸¸å¤§çš„æ¨¡å‹ã€‚ç”±äºæ™ºèƒ½åˆ†åŒºå’Œå¹³é“ºç®—æ³•ï¼Œæ¯ä¸ªGPUåœ¨å¸è½½æœŸé—´éœ€è¦å‘é€å’Œæ¥æ”¶éå¸¸å°‘é‡çš„æ•°æ®ï¼Œå› æ­¤ç°ä»£NVMeè¢«è¯æ˜é€‚åˆå…è®¸æ›´å¤§çš„æ€»å†…å­˜æ± å¯ç”¨äºæ‚¨çš„è®­ç»ƒè¿‡ç¨‹ã€‚ZeRO-Infinityéœ€è¦å¯ç”¨ZeRO-3ã€‚

ä»¥ä¸‹é…ç½®ç¤ºä¾‹å¯ç”¨äº†NVMeä»¥å¸è½½ä¼˜åŒ–å™¨çŠ¶æ€å’Œå‚æ•°ï¼š

```py
{
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "nvme",
            "nvme_path": "/local_nvme",
            "pin_memory": true,
            "buffer_count": 4,
            "fast_init": false
        },
        "offload_param": {
            "device": "nvme",
            "nvme_path": "/local_nvme",
            "pin_memory": true,
            "buffer_count": 5,
            "buffer_size": 1e8,
            "max_in_cpu": 1e9
        },
        "aio": {
            "block_size": 262144,
            "queue_depth": 32,
            "thread_count": 1,
            "single_submit": false,
            "overlap_events": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },
}
```

æ‚¨å¯ä»¥é€‰æ‹©å°†ä¼˜åŒ–å™¨çŠ¶æ€å’Œå‚æ•°éƒ½å¸è½½åˆ°NVMeï¼Œæˆ–è€…åªå¸è½½å…¶ä¸­ä¸€ä¸ªæˆ–ä¸¤è€…éƒ½ä¸å¸è½½ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æœ‰å¤§é‡çš„CPUå†…å­˜å¯ç”¨ï¼Œå°½ç®¡å°†å…¶ä»…å¸è½½åˆ°CPUå†…å­˜ï¼Œå› ä¸ºè¿™æ ·ä¼šæ›´å¿«ï¼ˆæç¤ºï¼šâ€œdeviceâ€: â€œcpuâ€ï¼‰ã€‚

è¿™é‡Œæ˜¯æœ‰å…³å¸è½½[ä¼˜åŒ–å™¨çŠ¶æ€](https://www.deepspeed.ai/docs/config-json/#optimizer-offloading)å’Œ[å‚æ•°](https://www.deepspeed.ai/docs/config-json/#parameter-offloading)çš„å®Œæ•´æ–‡æ¡£ã€‚

ç¡®ä¿æ‚¨çš„`nvme_path`å®é™…ä¸Šæ˜¯ä¸€ä¸ªNVMeï¼Œå› ä¸ºå®ƒå¯ä»¥ä¸æ™®é€šç¡¬ç›˜æˆ–å›ºæ€ç¡¬ç›˜ä¸€èµ·ä½¿ç”¨ï¼Œä½†é€Ÿåº¦ä¼šæ…¢å¾—å¤šã€‚å¿«é€Ÿå¯æ‰©å±•çš„è®­ç»ƒæ˜¯æ ¹æ®ç°ä»£NVMeä¼ è¾“é€Ÿåº¦è®¾è®¡çš„ï¼ˆæˆªè‡³æœ¬æ–‡æ’°å†™æ—¶ï¼Œè¯»å–é€Ÿåº¦çº¦ä¸º3.5GB/sï¼Œå†™å…¥é€Ÿåº¦çº¦ä¸º3GB/sï¼‰ã€‚

ä¸ºäº†æ‰¾å‡ºæœ€ä½³çš„`aio`é…ç½®å—ï¼Œæ‚¨å¿…é¡»åœ¨ç›®æ ‡è®¾ç½®ä¸Šè¿è¡ŒåŸºå‡†æµ‹è¯•ï¼Œå¦‚[æ­¤å¤„æ‰€è¿°](https://github.com/microsoft/DeepSpeed/issues/998)ã€‚

#### ZeRO-2ä¸ZeRO-3æ€§èƒ½

å¦‚æœä¸€åˆ‡é…ç½®ç›¸åŒï¼ŒZeRO-3å¯èƒ½æ¯”ZeRO-2æ…¢ï¼Œå› ä¸ºå‰è€…éœ€è¦æ”¶é›†æ¨¡å‹æƒé‡ä»¥å¤–çš„å†…å®¹ã€‚å¦‚æœZeRO-2æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼Œå¹¶ä¸”æ‚¨ä¸éœ€è¦æ‰©å±•åˆ°å‡ ä¸ªGPUä¹‹å¤–ï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥é€‰æ‹©åšæŒä½¿ç”¨å®ƒã€‚é‡è¦çš„æ˜¯è¦äº†è§£ï¼ŒZeRO-3åœ¨é€Ÿåº¦ä¸Šçš„ä»£ä»·æ˜¯å®ç°æ›´é«˜çš„å¯ä¼¸ç¼©æ€§å®¹é‡ã€‚

å¯ä»¥è°ƒæ•´ZeRO-3é…ç½®ï¼Œä½¿å…¶æ€§èƒ½æ¥è¿‘ZeRO-2ï¼š

+   å°†`stage3_param_persistence_threshold`è®¾ç½®ä¸ºä¸€ä¸ªéå¸¸å¤§çš„æ•°å­— - å¤§äºæœ€å¤§å‚æ•°ï¼Œä¾‹å¦‚`6 * hidden_size * hidden_size`ã€‚è¿™å°†ä½¿å‚æ•°ä¿ç•™åœ¨GPUä¸Šã€‚

+   å…³é—­`offload_params`ï¼Œå› ä¸ºZeRO-2æ²¡æœ‰è¯¥é€‰é¡¹ã€‚

å³ä½¿æ‚¨ä¸æ›´æ”¹`stage3_param_persistence_threshold`ï¼Œåªè¦å…³é—­`offload_params`ï¼Œæ€§èƒ½å¯èƒ½ä¼šæ˜¾ç€æé«˜ã€‚å½“ç„¶ï¼Œè¿™äº›æ›´æ”¹å°†å½±å“æ‚¨å¯ä»¥è®­ç»ƒçš„æ¨¡å‹å¤§å°ã€‚å› æ­¤ï¼Œè¿™äº›å¸®åŠ©æ‚¨æ ¹æ®éœ€è¦åœ¨å¯ä¼¸ç¼©æ€§å’Œé€Ÿåº¦ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚

#### ZeRO-2ç¤ºä¾‹

è¿™é‡Œæ˜¯ä¸€ä¸ªå®Œæ•´çš„ZeRO-2è‡ªåŠ¨é…ç½®æ–‡ä»¶`ds_config_zero2.json`ï¼š

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "contiguous_gradients": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
```

è¿™é‡Œæ˜¯ä¸€ä¸ªå®Œæ•´çš„ZeRO-2å…¨å¯ç”¨æ‰‹åŠ¨è®¾ç½®çš„é…ç½®æ–‡ä»¶ã€‚è¿™é‡Œä¸»è¦æ˜¯è®©æ‚¨çœ‹çœ‹å…¸å‹å€¼æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œä½†æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½¿ç”¨å…¶ä¸­å¸¦æœ‰å¤šä¸ª`auto`è®¾ç½®çš„é…ç½®æ–‡ä»¶ã€‚

```py
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 3e-5,
            "betas": [0.8, 0.999],
            "eps": 1e-8,
            "weight_decay": 3e-7
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": 0,
            "warmup_max_lr": 3e-5,
            "warmup_num_steps": 500
        }
    },

    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "contiguous_gradients": true
    },

    "steps_per_print": 2000,
    "wall_clock_breakdown": false
}
```

#### ZeRO-3ç¤ºä¾‹

è¿™é‡Œæ˜¯ä¸€ä¸ªå®Œæ•´çš„ZeRO-3è‡ªåŠ¨é…ç½®æ–‡ä»¶`ds_config_zero3.json`ï¼š

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
```

è¿™é‡Œæ˜¯ä¸€ä¸ªå®Œæ•´çš„ZeRO-3å…¨å¯ç”¨æ‰‹åŠ¨è®¾ç½®çš„é…ç½®æ–‡ä»¶ã€‚è¿™é‡Œä¸»è¦æ˜¯è®©æ‚¨çœ‹çœ‹å…¸å‹å€¼æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œä½†æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½¿ç”¨å…¶ä¸­å¸¦æœ‰å¤šä¸ª`auto`è®¾ç½®çš„é…ç½®æ–‡ä»¶ã€‚

```py
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 3e-5,
            "betas": [0.8, 0.999],
            "eps": 1e-8,
            "weight_decay": 3e-7
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": 0,
            "warmup_max_lr": 3e-5,
            "warmup_num_steps": 500
        }
    },

    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": 1e6,
        "stage3_prefetch_bucket_size": 0.94e6,
        "stage3_param_persistence_threshold": 1e4,
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },

    "steps_per_print": 2000,
    "wall_clock_breakdown": false
}
```

#### å¦‚ä½•é€‰æ‹©æœ€ä½³æ€§èƒ½çš„ZeROé˜¶æ®µå’Œå¸è½½æ–¹å¼

ç°åœ¨æ‚¨çŸ¥é“æœ‰æ‰€æœ‰è¿™äº›ä¸åŒçš„é˜¶æ®µã€‚å¦‚ä½•å†³å®šä½¿ç”¨å…¶ä¸­å“ªä¸€ä¸ªï¼Ÿæœ¬èŠ‚å°†å°è¯•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œä»¥ä¸‹å†…å®¹é€‚ç”¨ï¼š

+   é€Ÿåº¦æ–¹é¢ï¼ˆå·¦è¾¹æ¯”å³è¾¹å¿«ï¼‰

é˜¶æ®µ0ï¼ˆDDPï¼‰> é˜¶æ®µ1 > é˜¶æ®µ2 > é˜¶æ®µ2 + å¸è½½ > é˜¶æ®µ3 > é˜¶æ®µ3 + å¸è½½

+   GPUå†…å­˜ä½¿ç”¨æ–¹é¢ï¼ˆå³ä¾§æ¯”å·¦ä¾§æ›´èŠ‚çœGPUå†…å­˜ï¼‰

é˜¶æ®µ0ï¼ˆDDPï¼‰<é˜¶æ®µ1<é˜¶æ®µ2<é˜¶æ®µ2 +å¸è½½<é˜¶æ®µ3<é˜¶æ®µ3 +å¸è½½

å› æ­¤ï¼Œå½“æ‚¨å¸Œæœ›åœ¨æœ€å°‘æ•°é‡çš„GPUä¸­è·å¾—æœ€å¿«çš„æ‰§è¡Œæ—¶ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹è¿‡ç¨‹è¿›è¡Œã€‚æˆ‘ä»¬ä»æœ€å¿«çš„æ–¹æ³•å¼€å§‹ï¼Œå¦‚æœé‡åˆ°GPU OOMï¼Œåˆ™è½¬å‘ä¸‹ä¸€ä¸ªè¾ƒæ…¢çš„æ–¹æ³•ï¼Œä½†å°†ä½¿ç”¨æ›´å°‘çš„GPUå†…å­˜ã€‚ä¾æ­¤ç±»æ¨ã€‚

é¦–å…ˆå°†æ‰¹å¤„ç†å¤§å°è®¾ç½®ä¸º1ï¼ˆæ‚¨å§‹ç»ˆå¯ä»¥ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¥è·å¾—ä»»ä½•æ‰€éœ€çš„æœ‰æ•ˆæ‰¹å¤„ç†å¤§å°ï¼‰ã€‚

1.  å¯ç”¨`--gradient_checkpointing 1`ï¼ˆHF Trainerï¼‰æˆ–ç›´æ¥`model.gradient_checkpointing_enable()`-å¦‚æœOOMï¼Œåˆ™

1.  é¦–å…ˆå°è¯•ZeROé˜¶æ®µ2ã€‚å¦‚æœOOMï¼Œåˆ™

1.  å°è¯•ZeROé˜¶æ®µ2 + `offload_optimizer`-å¦‚æœOOMï¼Œåˆ™

1.  åˆ‡æ¢åˆ°ZeROé˜¶æ®µ3-å¦‚æœOOMï¼Œåˆ™

1.  å¯ç”¨`offload_param`åˆ°`cpu`-å¦‚æœOOMï¼Œåˆ™

1.  å¯ç”¨`offload_optimizer`åˆ°`cpu`-å¦‚æœOOMï¼Œåˆ™

1.  å¦‚æœæ‚¨ä»ç„¶æ— æ³•é€‚åº”æ‰¹å¤„ç†å¤§å°ä¸º1ï¼Œè¯·é¦–å…ˆæ£€æŸ¥å„ç§é»˜è®¤å€¼ï¼Œå¹¶åœ¨å¯èƒ½çš„æƒ…å†µä¸‹å°†å…¶é™ä½ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä½¿ç”¨`generate`ï¼Œå¹¶ä¸”ä¸ä½¿ç”¨å®½æœç´¢å…‰æŸï¼Œè¯·å°†å…¶å˜çª„ï¼Œå› ä¸ºè¿™å°†å ç”¨å¤§é‡å†…å­˜ã€‚

1.  ç»å¯¹ä½¿ç”¨æ··åˆåŠç²¾åº¦è€Œä¸æ˜¯fp32-å› æ­¤åœ¨AmpereåŠæ›´é«˜GPUä¸Šä½¿ç”¨bf16ï¼Œåœ¨æ—§çš„GPUæ¶æ„ä¸Šä½¿ç”¨fp16ã€‚

1.  å¦‚æœæ‚¨ä»ç„¶OOMï¼Œæ‚¨å¯ä»¥æ·»åŠ æ›´å¤šç¡¬ä»¶æˆ–å¯ç”¨ZeRO-Infinity-å³åˆ‡æ¢å¸è½½`offload_param`å’Œ`offload_optimizer`åˆ°`nvme`ã€‚æ‚¨éœ€è¦ç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªéå¸¸å¿«é€Ÿçš„nvmeã€‚ä½œä¸ºä¸€ä¸ªè½¶äº‹ï¼Œæˆ‘èƒ½å¤Ÿåœ¨ä¸€ä¸ªå°å‹GPUä¸Šæ¨æ–­BLOOM-176Bï¼Œä½¿ç”¨ZeRO-Infinityï¼Œåªæ˜¯é€Ÿåº¦ææ…¢ã€‚ä½†å®ƒæœ‰æ•ˆï¼

å½“ç„¶ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»æœ€GPUå†…å­˜é«˜æ•ˆçš„é…ç½®å¼€å§‹ï¼Œç„¶åå‘åè¿›è¡Œï¼Œæˆ–è€…å°è¯•äºŒåˆ†æ³•æ¥é€†å‘æ‰§è¡Œè¿™äº›æ­¥éª¤ã€‚

ä¸€æ—¦æ‚¨çš„æ‰¹å¤„ç†å¤§å°ä¸º1ä¸ä¼šå¯¼è‡´OOMï¼Œè¯·æµ‹é‡æ‚¨çš„æœ‰æ•ˆååé‡ã€‚

æ¥ä¸‹æ¥å°è¯•å°†æ‰¹å¤„ç†å¤§å°å¢åŠ åˆ°å°½å¯èƒ½å¤§ï¼Œå› ä¸ºæ‰¹å¤„ç†å¤§å°è¶Šå¤§ï¼ŒGPUçš„æ•ˆç‡å°±è¶Šé«˜ï¼Œå› ä¸ºå®ƒä»¬åœ¨ä¹˜æ³•çŸ©é˜µå¾ˆå¤§æ—¶è¡¨ç°æœ€ä½³ã€‚

ç°åœ¨æ€§èƒ½ä¼˜åŒ–æ¸¸æˆå¼€å§‹äº†ã€‚æ‚¨å¯ä»¥å…³é—­ä¸€äº›å¸è½½åŠŸèƒ½æˆ–é™ä½ZeROé˜¶æ®µï¼Œå¹¶å¢åŠ /å‡å°‘æ‰¹å¤„ç†å¤§å°ï¼Œç„¶åå†æµ‹é‡æ‚¨çš„æœ‰æ•ˆååé‡ã€‚åå¤è¿›è¡Œï¼Œç›´åˆ°æ»¡æ„ä¸ºæ­¢ã€‚

ä¸è¦èŠ±å¤ªå¤šæ—¶é—´åœ¨ä¸Šé¢ï¼Œä½†å¦‚æœæ‚¨å³å°†å¼€å§‹ä¸ºæœŸ3ä¸ªæœˆçš„åŸ¹è®­-è¯·èŠ±å‡ å¤©æ—¶é—´æ‰¾åˆ°æœ€æœ‰æ•ˆçš„ååé‡è®¾ç½®ã€‚è¿™æ ·ï¼Œæ‚¨çš„åŸ¹è®­æˆæœ¬å°†æœ€ä½ï¼Œæ‚¨å°†æ›´å¿«åœ°å®ŒæˆåŸ¹è®­ã€‚åœ¨å½“å‰å¿«èŠ‚å¥çš„MLä¸–ç•Œä¸­ï¼Œå¦‚æœæ‚¨éœ€è¦é¢å¤–ä¸€ä¸ªæœˆæ¥è®­ç»ƒæŸäº›å†…å®¹ï¼Œæ‚¨å¾ˆå¯èƒ½ä¼šé”™è¿‡ä¸€ä¸ªç»ä½³çš„æœºä¼šã€‚å½“ç„¶ï¼Œè¿™åªæ˜¯æˆ‘åˆ†äº«çš„ä¸€ä¸ªè§‚å¯Ÿï¼Œæˆ‘ç»ä¸ä¼šå‚¬ä¿ƒæ‚¨ã€‚åœ¨å¼€å§‹è®­ç»ƒBLOOM-176Bä¹‹å‰ï¼Œæˆ‘èŠ±äº†2å¤©æ—¶é—´è¿›è¡Œè¿™ä¸ªè¿‡ç¨‹ï¼Œå¹¶ä¸”èƒ½å¤Ÿå°†ååé‡ä»90æé«˜åˆ°150 TFLOPsï¼è¿™ä¸€åŠªåŠ›ä¸ºæˆ‘ä»¬èŠ‚çœäº†ä¸€ä¸ªå¤šæœˆçš„åŸ¹è®­æ—¶é—´ã€‚

è¿™äº›æ³¨æ„äº‹é¡¹ä¸»è¦æ˜¯é’ˆå¯¹è®­ç»ƒæ¨¡å¼ç¼–å†™çš„ï¼Œä½†å®ƒä»¬åœ¨æ¨æ–­æ–¹é¢ä¹Ÿåº”è¯¥å¤§å¤šé€‚ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨æ¨æ–­æœŸé—´ï¼Œæ¢¯åº¦æ£€æŸ¥ç‚¹æ˜¯æ— æ•ˆçš„ï¼Œå› ä¸ºå®ƒåªåœ¨è®­ç»ƒæœŸé—´æœ‰ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ï¼Œå¦‚æœæ‚¨æ­£åœ¨è¿›è¡Œå¤šGPUæ¨æ–­å¹¶ä¸”ä¸ä½¿ç”¨[DeepSpeed-Inference](https://www.deepspeed.ai/tutorials/inference-tutorial/)ï¼Œ[Accelerate](https://huggingface.co/blog/bloom-inference-pytorch-scripts)åº”è¯¥æä¾›æ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚

å…¶ä»–å¿«é€Ÿç›¸å…³çš„æ€§èƒ½æ³¨æ„äº‹é¡¹ï¼š

+   å¦‚æœæ‚¨æ­£åœ¨ä»å¤´å¼€å§‹è®­ç»ƒæŸäº›å†…å®¹ï¼Œè¯·å§‹ç»ˆå°è¯•å…·æœ‰å¯è¢«16æ•´é™¤çš„å¼ é‡å½¢çŠ¶ï¼ˆä¾‹å¦‚éšè—å¤§å°ï¼‰ã€‚å¯¹äºæ‰¹å¤„ç†å¤§å°ï¼Œè¯·è‡³å°‘å°è¯•å¯è¢«2æ•´é™¤ã€‚å¦‚æœæ‚¨æƒ³ä»GPUä¸­æŒ¤å–æ›´é«˜çš„æ€§èƒ½ï¼Œåˆ™æœ‰ç¡¬ä»¶ç‰¹å®šçš„[æ³¢å’Œç“·ç –é‡åŒ–](https://developer.nvidia.com/blog/optimizing-gpu-performance-tensor-cores/)å¯è¢«æ•´é™¤ã€‚

### æ¿€æ´»æ£€æŸ¥ç‚¹æˆ–æ¢¯åº¦æ£€æŸ¥ç‚¹

æ¿€æ´»æ£€æŸ¥ç‚¹å’Œæ¢¯åº¦æ£€æŸ¥ç‚¹æ˜¯æŒ‡åŒä¸€æ–¹æ³•çš„ä¸¤ä¸ªä¸åŒæœ¯è¯­ã€‚è¿™å¾ˆä»¤äººå›°æƒ‘ï¼Œä½†äº‹å®å°±æ˜¯å¦‚æ­¤ã€‚

æ¢¯åº¦æ£€æŸ¥ç‚¹å…è®¸å°†é€Ÿåº¦æ¢æˆ GPU å†…å­˜ï¼Œè¿™æ ·å¯ä»¥å…‹æœ GPU OOMï¼Œæˆ–è€…å¢åŠ æ‰¹é‡å¤§å°ï¼Œé€šå¸¸ä¼šå¸¦æ¥æ›´å¥½çš„æ€§èƒ½ã€‚

HF Transformers æ¨¡å‹å¯¹ DeepSpeed çš„æ¿€æ´»æ£€æŸ¥ç‚¹ä¸€æ— æ‰€çŸ¥ï¼Œå› æ­¤å¦‚æœæ‚¨å°è¯•åœ¨ DeepSpeed é…ç½®æ–‡ä»¶ä¸­å¯ç”¨è¯¥åŠŸèƒ½ï¼Œå°†ä¸ä¼šå‘ç”Ÿä»»ä½•äº‹æƒ…ã€‚

å› æ­¤ï¼Œæ‚¨æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥åˆ©ç”¨è¿™ä¸ªéå¸¸æœ‰ç›Šçš„åŠŸèƒ½ï¼š

1.  å¦‚æœæ‚¨æƒ³ä½¿ç”¨ HF Transformers æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨ `model.gradient_checkpointing_enable()` æˆ–åœ¨ HF Trainer ä¸­ä½¿ç”¨ `--gradient_checkpointing`ï¼Œè¿™å°†è‡ªåŠ¨ä¸ºæ‚¨å¯ç”¨æ­¤åŠŸèƒ½ã€‚åœ¨é‚£é‡Œä½¿ç”¨ `torch.utils.checkpoint`ã€‚

1.  å¦‚æœæ‚¨ç¼–å†™è‡ªå·±çš„æ¨¡å‹å¹¶å¸Œæœ›ä½¿ç”¨ DeepSpeed çš„æ¿€æ´»æ£€æŸ¥ç‚¹ï¼Œå¯ä»¥ä½¿ç”¨[é‚£é‡Œè§„å®šçš„ API](https://deepspeed.readthedocs.io/en/latest/activation-checkpointing.html)ã€‚æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ HF Transformers å»ºæ¨¡ä»£ç ï¼Œå¹¶å°† `torch.utils.checkpoint` æ›¿æ¢ä¸º DeepSpeed çš„ APIã€‚åè€…æ›´çµæ´»ï¼Œå› ä¸ºå®ƒå…è®¸æ‚¨å°†å‰å‘æ¿€æ´»å¸è½½åˆ° CPU å†…å­˜ï¼Œè€Œä¸æ˜¯é‡æ–°è®¡ç®—å®ƒä»¬ã€‚

### ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨

åªè¦ä¸å¯ç”¨ `offload_optimizer`ï¼Œæ‚¨å¯ä»¥æ··åˆä½¿ç”¨ DeepSpeed å’Œ HuggingFace è°ƒåº¦å™¨å’Œä¼˜åŒ–å™¨ã€‚

åœ¨å¯ç”¨ `offload_optimizer` æ—¶ï¼Œå¯ä»¥ä½¿ç”¨é DeepSpeed ä¼˜åŒ–å™¨ï¼Œåªè¦å®ƒå…·æœ‰ CPU å’Œ GPU å®ç°ï¼ˆé™¤äº† LAMBï¼‰ã€‚

#### ä¼˜åŒ–å™¨

DeepSpeed çš„ä¸»è¦ä¼˜åŒ–å™¨æ˜¯ Adamã€AdamWã€OneBitAdam å’Œ Lambã€‚è¿™äº›å·²ç»é€šè¿‡ ZeRO è¿›è¡Œäº†å½»åº•æµ‹è¯•ï¼Œå› æ­¤å»ºè®®ä½¿ç”¨å®ƒä»¬ã€‚ä½†æ˜¯ï¼Œå®ƒå¯ä»¥ä» `torch` å¯¼å…¥å…¶ä»–ä¼˜åŒ–å™¨ã€‚å®Œæ•´æ–‡æ¡£åœ¨[è¿™é‡Œ](https://www.deepspeed.ai/docs/config-json/#optimizer-parameters)ã€‚

å¦‚æœæ‚¨åœ¨é…ç½®æ–‡ä»¶ä¸­ä¸é…ç½® `optimizer` æ¡ç›®ï¼Œ[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) å°†è‡ªåŠ¨å°†å…¶è®¾ç½®ä¸º `AdamW`ï¼Œå¹¶å°†ä½¿ç”¨æä¾›çš„å€¼æˆ–ä»¥ä¸‹å‘½ä»¤è¡Œå‚æ•°çš„é»˜è®¤å€¼ï¼š`--learning_rate`ã€`--adam_beta1`ã€`--adam_beta2`ã€`--adam_epsilon` å’Œ `--weight_decay`ã€‚

è¿™æ˜¯ `AdamW` çš„è‡ªåŠ¨é…ç½®çš„ `optimizer` æ¡ç›®çš„ç¤ºä¾‹ï¼š

```py
{
   "optimizer": {
       "type": "AdamW",
       "params": {
         "lr": "auto",
         "betas": "auto",
         "eps": "auto",
         "weight_decay": "auto"
       }
   }
}
```

è¯·æ³¨æ„ï¼Œå‘½ä»¤è¡Œå‚æ•°å°†è®¾ç½®é…ç½®æ–‡ä»¶ä¸­çš„å€¼ã€‚è¿™æ ·ä¸€æ¥ï¼Œå°±æœ‰äº†ä¸€ä¸ªæ˜ç¡®çš„å€¼æ¥æºï¼Œé¿å…äº†ä¾‹å¦‚å­¦ä¹ ç‡åœ¨ä¸åŒåœ°æ–¹è®¾ç½®ä¸ºä¸åŒå€¼æ—¶éš¾ä»¥æ‰¾åˆ°çš„é”™è¯¯ã€‚å‘½ä»¤è¡Œè§„åˆ™ã€‚è¢«è¦†ç›–çš„å€¼åŒ…æ‹¬ï¼š

+   `lr` çš„å€¼ä¸º `--learning_rate`

+   `betas` çš„å€¼ä¸º `--adam_beta1 --adam_beta2`

+   `eps` çš„å€¼ä¸º `--adam_epsilon`

+   `weight_decay` çš„å€¼ä¸º `--weight_decay`

å› æ­¤ï¼Œè¯·è®°ä½åœ¨å‘½ä»¤è¡Œä¸Šè°ƒæ•´å…±äº«çš„è¶…å‚æ•°ã€‚

æ‚¨è¿˜å¯ä»¥æ˜¾å¼è®¾ç½®è¿™äº›å€¼ï¼š

```py
{
   "optimizer": {
       "type": "AdamW",
       "params": {
         "lr": 0.001,
         "betas": [0.8, 0.999],
         "eps": 1e-8,
         "weight_decay": 3e-7
       }
   }
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªè¡ŒåŒæ­¥[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°å’Œ DeepSpeed é…ç½®ã€‚

å¦‚æœè¦ä½¿ç”¨ä¸Šé¢æœªåˆ—å‡ºçš„å…¶ä»–ä¼˜åŒ–å™¨ï¼Œåˆ™å¿…é¡»æ·»åŠ åˆ°é¡¶çº§é…ç½®ã€‚

```py
{
   "zero_allow_untested_optimizer": true
}
```

ä¸ `AdamW` ç±»ä¼¼ï¼Œæ‚¨å¯ä»¥é…ç½®å…¶ä»–å®˜æ–¹æ”¯æŒçš„ä¼˜åŒ–å™¨ã€‚åªéœ€è®°ä½ï¼Œè¿™äº›å¯èƒ½å…·æœ‰ä¸åŒçš„é…ç½®å€¼ã€‚ä¾‹å¦‚ï¼Œå¯¹äº Adamï¼Œæ‚¨å°†å¸Œæœ› `weight_decay` å¤§çº¦ä¸º `0.01`ã€‚

æ­¤å¤–ï¼Œå½“ä¸ Deepspeed çš„ CPU Adam ä¼˜åŒ–å™¨ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œå¸è½½æ•ˆæœæœ€ä½³ã€‚å¦‚æœè¦ä½¿ç”¨ä¸åŒçš„ä¼˜åŒ–å™¨è¿›è¡Œå¸è½½ï¼Œè‡ª `deepspeed==0.8.3` ä»¥æ¥ï¼Œæ‚¨è¿˜éœ€è¦æ·»åŠ ï¼š

```py
{
   "zero_force_ds_cpu_optimizer": false
}
```

åˆ°é¡¶çº§é…ç½®ã€‚

#### è°ƒåº¦å™¨

DeepSpeed æ”¯æŒ `LRRangeTest`ã€`OneCycle`ã€`WarmupLR` å’Œ `WarmupDecayLR` å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚å®Œæ•´æ–‡æ¡£åœ¨[è¿™é‡Œ](https://www.deepspeed.ai/docs/config-json/#scheduler-parameters)ã€‚

è¿™æ˜¯ğŸ¤— Transformers å’Œ DeepSpeed ä¹‹é—´è°ƒåº¦å™¨é‡å çš„åœ°æ–¹ï¼š

+   é€šè¿‡ `--lr_scheduler_type constant_with_warmup` å®ç°çš„ `WarmupLR`

+   é€šè¿‡`--lr_scheduler_type linear`é…ç½®`WarmupDecayLR`ã€‚è¿™ä¹Ÿæ˜¯`--lr_scheduler_type`çš„é»˜è®¤å€¼ï¼Œå› æ­¤ï¼Œå¦‚æœæ‚¨æ²¡æœ‰é…ç½®è°ƒåº¦ç¨‹åºï¼Œåˆ™é»˜è®¤å°†é…ç½®æ­¤è°ƒåº¦ç¨‹åºã€‚

å¦‚æœæ‚¨æ²¡æœ‰åœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½®`scheduler`æ¡ç›®ï¼Œ[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å°†ä½¿ç”¨`--lr_scheduler_type`ã€`--learning_rate`å’Œ`--warmup_steps`æˆ–`--warmup_ratio`çš„å€¼æ¥é…ç½®å…¶ğŸ¤— Transformersç‰ˆæœ¬ã€‚

ä»¥ä¸‹æ˜¯`WarmupLR`çš„è‡ªåŠ¨é…ç½®`scheduler`æ¡ç›®ç¤ºä¾‹ï¼š

```py
{
   "scheduler": {
         "type": "WarmupLR",
         "params": {
             "warmup_min_lr": "auto",
             "warmup_max_lr": "auto",
             "warmup_num_steps": "auto"
         }
     }
}
```

ç”±äºä½¿ç”¨äº†*â€œautoâ€*ï¼Œ[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‚æ•°å°†åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„å€¼ã€‚è¿™æ ·ä¸€æ¥ï¼Œæ•°å€¼å°±æœ‰äº†ä¸€ä¸ªæ˜ç¡®çš„æ¥æºï¼Œé¿å…äº†ä¾‹å¦‚å­¦ä¹ ç‡åœ¨ä¸åŒåœ°æ–¹è®¾ç½®ä¸ºä¸åŒå€¼æ—¶éš¾ä»¥æ‰¾åˆ°çš„é”™è¯¯ã€‚å‘½ä»¤è¡Œè§„åˆ™ã€‚è®¾ç½®çš„å€¼åŒ…æ‹¬ï¼š

+   `warmup_min_lr`ï¼Œå…¶å€¼ä¸º`0`ã€‚

+   `warmup_max_lr`ï¼Œå…¶å€¼ä¸º`--learning_rate`ã€‚

+   å¦‚æœæä¾›äº†`--warmup_steps`ï¼Œåˆ™`warmup_num_steps`çš„å€¼ä¸º`--warmup_steps`ã€‚å¦åˆ™ï¼Œå°†ä½¿ç”¨`--warmup_ratio`ä¹˜ä»¥è®­ç»ƒæ­¥æ•°å¹¶å››èˆäº”å…¥ã€‚

+   `total_num_steps`ï¼Œå…¶å€¼ä¸º`--max_steps`æˆ–è€…å¦‚æœæœªæä¾›ï¼Œåˆ™åœ¨è¿è¡Œæ—¶æ ¹æ®ç¯å¢ƒå’Œæ•°æ®é›†å¤§å°ä»¥åŠå…¶ä»–å‘½ä»¤è¡Œå‚æ•°è‡ªåŠ¨æ¨å¯¼ï¼ˆå¯¹äº`WarmupDecayLR`æ˜¯å¿…éœ€çš„ï¼‰ã€‚

å½“ç„¶ï¼Œæ‚¨å¯ä»¥æ¥ç®¡ä»»ä½•æˆ–æ‰€æœ‰é…ç½®å€¼ï¼Œå¹¶è‡ªè¡Œè®¾ç½®ï¼š

```py
{
   "scheduler": {
         "type": "WarmupLR",
         "params": {
             "warmup_min_lr": 0,
             "warmup_max_lr": 0.001,
             "warmup_num_steps": 1000
         }
     }
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªè¡ŒåŒæ­¥[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚

ä¾‹å¦‚ï¼Œå¯¹äº`WarmupDecayLR`ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ¡ç›®ï¼š

```py
{
   "scheduler": {
         "type": "WarmupDecayLR",
         "params": {
             "last_batch_iteration": -1,
             "total_num_steps": "auto",
             "warmup_min_lr": "auto",
             "warmup_max_lr": "auto",
             "warmup_num_steps": "auto"
         }
     }
}
```

`total_num_steps`ã€`warmup_max_lr`ã€`warmup_num_steps`å’Œ`total_num_steps`å°†åœ¨åŠ è½½æ—¶è®¾ç½®ã€‚

### fp32ç²¾åº¦

Deepspeedæ”¯æŒå®Œæ•´çš„fp32å’Œfp16æ··åˆç²¾åº¦ã€‚

ç”±äºä½¿ç”¨fp16æ··åˆç²¾åº¦å¯ä»¥å¤§å¤§å‡å°‘å†…å­˜éœ€æ±‚å¹¶æé«˜é€Ÿåº¦ï¼Œå”¯ä¸€ä¸ä½¿ç”¨å®ƒçš„æƒ…å†µæ˜¯å½“æ‚¨ä½¿ç”¨çš„æ¨¡å‹åœ¨è¿™ç§è®­ç»ƒæ¨¡å¼ä¸‹è¡¨ç°ä¸ä½³æ—¶ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œè¿™ç§æƒ…å†µå‘ç”Ÿåœ¨æ¨¡å‹æ²¡æœ‰åœ¨fp16æ··åˆç²¾åº¦ä¸‹è¿›è¡Œé¢„è®­ç»ƒæ—¶ï¼ˆä¾‹å¦‚ï¼Œbf16é¢„è®­ç»ƒæ¨¡å‹ç»å¸¸å‡ºç°è¿™ç§æƒ…å†µï¼‰ã€‚è¿™æ ·çš„æ¨¡å‹å¯èƒ½ä¼šæº¢å‡ºæˆ–ä¸‹æº¢ï¼Œå¯¼è‡´`NaN`æŸå¤±ã€‚å¦‚æœæ‚¨é‡åˆ°è¿™ç§æƒ…å†µï¼Œé‚£ä¹ˆæ‚¨éœ€è¦ä½¿ç”¨å®Œæ•´çš„fp32æ¨¡å¼ï¼Œé€šè¿‡æ˜¾å¼ç¦ç”¨é»˜è®¤çš„fp16æ··åˆç²¾åº¦æ¨¡å¼ï¼š

```py
{
    "fp16": {
        "enabled": false,
    }
}
```

å¦‚æœæ‚¨ä½¿ç”¨åŸºäºAmpereæ¶æ„çš„GPUï¼Œpytorchç‰ˆæœ¬1.7åŠæ›´é«˜ç‰ˆæœ¬å°†è‡ªåŠ¨åˆ‡æ¢åˆ°ä½¿ç”¨æ›´é«˜æ•ˆçš„tf32æ ¼å¼è¿›è¡ŒæŸäº›æ“ä½œï¼Œä½†ç»“æœä»å°†æ˜¯fp32ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯å’ŒåŸºå‡†ï¼Œè¯·å‚é˜…[TensorFloat-32(TF32) on Ampere devices](https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)ã€‚è¯¥æ–‡æ¡£åŒ…æ‹¬å¦‚ä½•åœ¨æŸç§æƒ…å†µä¸‹ç¦ç”¨æ­¤è‡ªåŠ¨è½¬æ¢çš„è¯´æ˜ã€‚

ä½¿ç”¨ğŸ¤— Trainerï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`--tf32`æ¥å¯ç”¨å®ƒï¼Œæˆ–è€…ä½¿ç”¨`--tf32 0`æˆ–`--no_tf32`æ¥ç¦ç”¨å®ƒã€‚é»˜è®¤æƒ…å†µä¸‹ä½¿ç”¨PyTorché»˜è®¤å€¼ã€‚

### è‡ªåŠ¨æ··åˆç²¾åº¦

æ‚¨å¯ä»¥ä½¿ç”¨ç±»ä¼¼äºpytorchçš„AMPæ–¹å¼æˆ–ç±»ä¼¼äºapexçš„æ–¹å¼è¿›è¡Œè‡ªåŠ¨æ··åˆç²¾åº¦ï¼š

### fp16

è¦é…ç½®å¸¦æœ‰fp16ï¼ˆfloat16ï¼‰çš„pytorch AMPæ¨¡å¼ï¼Œè¯·è®¾ç½®ï¼š

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    }
}
```

[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å°†æ ¹æ®`args.fp16_backend`çš„å€¼è‡ªåŠ¨å¯ç”¨æˆ–ç¦ç”¨å®ƒã€‚å…¶ä½™çš„é…ç½®å€¼ç”±æ‚¨å†³å®šã€‚

å½“ä¼ é€’`--fp16 --fp16_backend amp`æˆ–`--fp16_full_eval`å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œæ­¤æ¨¡å¼å°†è¢«å¯ç”¨ã€‚

æ‚¨è¿˜å¯ä»¥æ˜¾å¼å¯ç”¨/ç¦ç”¨æ­¤æ¨¡å¼ï¼š

```py
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    }
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªè¡ŒåŒæ­¥[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚

è¿™æ˜¯[æ–‡æ¡£](https://www.deepspeed.ai/docs/config-json/#fp16-training-options)ã€‚

### bf16

å¦‚æœå¸Œæœ›ä½¿ç”¨bf16ï¼ˆbfloat16ï¼‰è€Œä¸æ˜¯fp16ï¼Œåˆ™åº”ä½¿ç”¨ä»¥ä¸‹é…ç½®éƒ¨åˆ†ï¼š

```py
{
    "bf16": {
        "enabled": "auto"
    }
}
```

bf16å…·æœ‰ä¸fp32ç›¸åŒçš„åŠ¨æ€èŒƒå›´ï¼Œå› æ­¤ä¸éœ€è¦æŸå¤±ç¼©æ”¾ã€‚

å½“ä¼ é€’`--bf16`æˆ–`--bf16_full_eval`å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œå°†å¯ç”¨æ­¤æ¨¡å¼ã€‚

æ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼å¯ç”¨/ç¦ç”¨æ­¤æ¨¡å¼ï¼š

```py
{
    "bf16": {
        "enabled": true
    }
}
```

æˆªè‡³`deepspeed==0.6.0`ï¼Œbf16æ”¯æŒæ˜¯æ–°çš„å®éªŒæ€§åŠŸèƒ½ã€‚

å¦‚æœæ‚¨åœ¨å¯ç”¨bf16çš„æƒ…å†µä¸‹ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼Œæ‚¨éœ€è¦æ³¨æ„å®ƒå°†åœ¨bf16ä¸­ç´¯ç§¯æ¢¯åº¦ï¼Œè¿™å¯èƒ½ä¸æ˜¯æ‚¨æƒ³è¦çš„ï¼Œå› ä¸ºè¿™ç§æ ¼å¼çš„ä½ç²¾åº¦å¯èƒ½å¯¼è‡´æŸå¤±çš„ç´¯ç§¯ã€‚

æ­£åœ¨è¿›è¡Œä¿®å¤å·¥ä½œï¼Œå¹¶æä¾›ä½¿ç”¨æ›´é«˜ç²¾åº¦`dtype`ï¼ˆfp16æˆ–fp32ï¼‰çš„é€‰é¡¹ã€‚

### NCCLé›†åˆ

è¿™æ˜¯è®­ç»ƒåˆ¶åº¦çš„`dtype`ï¼Œè¿˜æœ‰ä¸€ä¸ªç”¨äºé€šä¿¡é›†åˆçš„`dtype`ã€‚

æ‰€æœ‰æ”¶é›†/æ•£å¸ƒæ“ä½œéƒ½ä»¥ç›¸åŒçš„`dtype`æ‰§è¡Œï¼Œå› æ­¤å¦‚æœæ‚¨ä½¿ç”¨bf16è®­ç»ƒåˆ¶åº¦ï¼Œåˆ™ä¼šä»¥bf16è¿›è¡Œæ”¶é›†-æ”¶é›†æ˜¯ä¸€ä¸ªéæŸå¤±æ“ä½œã€‚

å„ç§å‡å°‘æ“ä½œå¯èƒ½ä¼šå¯¼è‡´å¾ˆå¤§çš„æŸå¤±ï¼Œä¾‹å¦‚å½“æ¢¯åº¦åœ¨å¤šä¸ªGPUä¸Šå¹³å‡æ—¶ï¼Œå¦‚æœé€šä¿¡ä½¿ç”¨fp16æˆ–bf16ï¼Œåˆ™ç»“æœå¯èƒ½ä¼šæœ‰æŸå¤±-å› ä¸ºåœ¨ä½ç²¾åº¦ä¸‹ç›¸åŠ å¤šä¸ªæ•°å­—æ—¶ç»“æœå¹¶ä¸ç²¾ç¡®ã€‚bf16çš„ç²¾åº¦æ¯”fp16ä½ï¼Œå› æ­¤æ›´å®¹æ˜“å‡ºç°è¿™ç§æƒ…å†µã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œfp16è¶³å¤Ÿå¥½ï¼Œå› ä¸ºåœ¨å¹³å‡æ¢¯åº¦æ—¶æŸå¤±å¾ˆå°ã€‚å› æ­¤ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œå¯¹äºåŠç²¾åº¦è®­ç»ƒï¼Œå‡å°‘æ“ä½œçš„é»˜è®¤å€¼æ˜¯ä½¿ç”¨fp16ã€‚ä½†æ˜¯æ‚¨å¯ä»¥å®Œå…¨æ§åˆ¶æ­¤åŠŸèƒ½ï¼Œå¦‚æœé€‰æ‹©ï¼Œå¯ä»¥å¢åŠ ä¸€äº›å¼€é”€ï¼Œå¹¶ç¡®ä¿å‡å°‘æ“ä½œå°†ä½¿ç”¨fp32ä½œä¸ºç´¯ç§¯dtypeï¼Œä»…å½“ç»“æœå‡†å¤‡å°±ç»ªæ—¶æ‰ä¼šå°†å…¶é™çº§ä¸ºæ‚¨æ­£åœ¨è®­ç»ƒçš„åŠç²¾åº¦`dtype`ã€‚

è¦è¦†ç›–é»˜è®¤è®¾ç½®ï¼Œåªéœ€æ·»åŠ ä¸€ä¸ªæ–°çš„é…ç½®æ¡ç›®ï¼š

```py
{
    "communication_data_type": "fp32"
}
```

æˆªè‡³ç›®å‰ï¼Œæœ‰æ•ˆå€¼ä¸ºâ€œfp16â€ï¼Œâ€œbfp16â€ï¼Œâ€œfp32â€ã€‚

æ³¨æ„ï¼šstage zero 3å­˜åœ¨å…³äºbf16 comm dtypeçš„é”™è¯¯ï¼Œå·²åœ¨`deepspeed==0.8.1`ä¸­ä¿®å¤ã€‚

### apex

è¦é…ç½®apex AMPç±»ä¼¼æ¨¡å¼ï¼Œè¯·è®¾ç½®ï¼š

```py
"amp": {
    "enabled": "auto",
    "opt_level": "auto"
}
```

è®­ç»ƒå™¨å°†æ ¹æ®`args.fp16_backend`å’Œ`args.fp16_opt_level`çš„å€¼è‡ªåŠ¨é…ç½®ã€‚

å½“ä¼ é€’`--fp16 --fp16_backend apex --fp16_opt_level 01`å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œå°†å¯ç”¨æ­¤æ¨¡å¼ã€‚

æ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼é…ç½®æ­¤æ¨¡å¼ï¼š

```py
{
    "amp": {
        "enabled": true,
        "opt_level": "O1"
    }
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªè¡ŒåŒæ­¥[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚

è¿™æ˜¯[æ–‡æ¡£](https://www.deepspeed.ai/docs/config-json/#automatic-mixed-precision-amp-training-options)ã€‚

### æ‰¹é‡å¤§å°

è¦é…ç½®æ‰¹é‡å¤§å°ï¼Œè¯·ä½¿ç”¨ï¼š

```py
{
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto"
}
```

è®­ç»ƒå™¨å°†è‡ªåŠ¨å°†`train_micro_batch_size_per_gpu`è®¾ç½®ä¸º`args.per_device_train_batch_size`çš„å€¼ï¼Œå°†`train_batch_size`è®¾ç½®ä¸º`args.world_size * args.per_device_train_batch_size * args.gradient_accumulation_steps`çš„å€¼ã€‚

æ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼è®¾ç½®è¿™äº›å€¼ï¼š

```py
{
    "train_batch_size": 12,
    "train_micro_batch_size_per_gpu": 4
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªè¡ŒåŒæ­¥[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚

### æ¢¯åº¦ç´¯ç§¯

è¦é…ç½®æ¢¯åº¦ç´¯ç§¯ï¼Œè¯·è®¾ç½®ï¼š

```py
{
    "gradient_accumulation_steps": "auto"
}
```

è®­ç»ƒå™¨å°†è‡ªåŠ¨å°†å…¶è®¾ç½®ä¸º`args.gradient_accumulation_steps`çš„å€¼ã€‚

æ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼è®¾ç½®å€¼ï¼š

```py
{
    "gradient_accumulation_steps": 3
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªè¡ŒåŒæ­¥[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚

### æ¢¯åº¦è£å‰ª

é…ç½®æ¢¯åº¦è£å‰ªè®¾ç½®ï¼š

```py
{
    "gradient_clipping": "auto"
}
```

[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å°†è‡ªåŠ¨å°†å…¶è®¾ç½®ä¸º`args.max_grad_norm`çš„å€¼ã€‚

æ‚¨è¿˜å¯ä»¥æ˜¾å¼è®¾ç½®è¯¥å€¼ï¼š

```py
{
    "gradient_clipping": 1.0
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªè¡ŒåŒæ­¥[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚

### è·å–æ¨¡å‹æƒé‡

åªè¦æ‚¨ç»§ç»­ä½¿ç”¨DeepSpeedè¿›è¡Œè®­ç»ƒå’Œæ¢å¤ï¼Œæ‚¨å°±ä¸å¿…æ‹…å¿ƒä»»ä½•äº‹æƒ…ã€‚DeepSpeedå°†fp32ä¸»æƒé‡å­˜å‚¨åœ¨å…¶è‡ªå®šä¹‰æ£€æŸ¥ç‚¹ä¼˜åŒ–å™¨æ–‡ä»¶ä¸­ï¼Œè¿™äº›æ–‡ä»¶æ˜¯`global_step*/*optim_states.pt`ï¼ˆè¿™æ˜¯é€šé…ç¬¦ï¼‰ï¼Œå¹¶ä¿å­˜åœ¨æ­£å¸¸æ£€æŸ¥ç‚¹ä¸‹ã€‚

**FP16æƒé‡ï¼š**

å½“æ¨¡å‹ä¿å­˜åœ¨ZeRO-2ä¸‹æ—¶ï¼Œæ‚¨æœ€ç»ˆä¼šå¾—åˆ°å¸¦æœ‰æ¨¡å‹æƒé‡çš„æ­£å¸¸`pytorch_model.bin`æ–‡ä»¶ï¼Œä½†å®ƒä»¬åªæ˜¯æƒé‡çš„fp16ç‰ˆæœ¬ã€‚

åœ¨ZeRO-3ä¸‹ï¼Œæƒ…å†µè¦å¤æ‚å¾—å¤šï¼Œå› ä¸ºæ¨¡å‹æƒé‡è¢«åˆ†åŒºåˆ°å¤šä¸ªGPUä¸Šï¼Œå› æ­¤éœ€è¦`"stage3_gather_16bit_weights_on_model_save": true`æ¥è®©`Trainer`ä¿å­˜æƒé‡çš„fp16ç‰ˆæœ¬ã€‚å¦‚æœæ­¤è®¾ç½®ä¸º`False`ï¼Œå°†ä¸ä¼šåˆ›å»º`pytorch_model.bin`ã€‚è¿™æ˜¯å› ä¸ºé»˜è®¤æƒ…å†µä¸‹DeepSpeedçš„`state_dict`åŒ…å«ä¸€ä¸ªå ä½ç¬¦è€Œä¸æ˜¯çœŸæ­£çš„æƒé‡ã€‚å¦‚æœæˆ‘ä»¬ä¿å­˜è¿™ä¸ª`state_dict`ï¼Œå°†æ— æ³•åŠ è½½å›æ¥ã€‚

```py
{
    "zero_optimization": {
        "stage3_gather_16bit_weights_on_model_save": true
    }
}
```

**FP32æƒé‡ï¼š**

è™½ç„¶fp16æƒé‡é€‚ç”¨äºæ¢å¤è®­ç»ƒï¼Œä½†å¦‚æœæ‚¨å®Œæˆäº†å¾®è°ƒæ¨¡å‹å¹¶å¸Œæœ›å°†å…¶ä¸Šä¼ åˆ°[models hub](https://huggingface.co/models)æˆ–ä¼ é€’ç»™å…¶ä»–äººï¼Œæ‚¨å¾ˆå¯èƒ½å¸Œæœ›è·å–fp32æƒé‡ã€‚æœ€å¥½ä¸è¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰§è¡Œæ­¤æ“ä½œï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªéœ€è¦å¤§é‡å†…å­˜çš„è¿‡ç¨‹ï¼Œå› æ­¤æœ€å¥½åœ¨è®­ç»ƒå®Œæˆåç¦»çº¿æ‰§è¡Œã€‚ä½†å¦‚æœéœ€è¦å¹¶ä¸”æ‚¨æœ‰è¶³å¤Ÿçš„ç©ºé—²CPUå†…å­˜ï¼Œå¯ä»¥åœ¨ç›¸åŒçš„è®­ç»ƒè„šæœ¬ä¸­æ‰§è¡Œã€‚ä»¥ä¸‹éƒ¨åˆ†å°†è®¨è®ºè¿™ä¸¤ç§æ–¹æ³•ã€‚

**åœ¨çº¿FP32æƒé‡æ¢å¤ï¼š**

å¦‚æœæ‚¨çš„æ¨¡å‹å¾ˆå¤§ä¸”å‰©ä½™çš„CPUå†…å­˜å¾ˆå°‘ï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¸èµ·ä½œç”¨ã€‚

å¦‚æœæ‚¨è‡³å°‘ä¿å­˜äº†ä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼Œå¹¶ä¸”æƒ³è¦ä½¿ç”¨æœ€æ–°çš„æ£€æŸ¥ç‚¹ï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

```py
from transformers.trainer_utils import get_last_checkpoint
from deepspeed.utils.zero_to_fp32 import load_state_dict_from_zero_checkpoint

checkpoint_dir = get_last_checkpoint(trainer.args.output_dir)
fp32_model = load_state_dict_from_zero_checkpoint(trainer.model, checkpoint_dir)
```

å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨`--load_best_model_at_end`ç±»ï¼š*~transformers.TrainingArguments*å‚æ•°ï¼ˆç”¨äºè·Ÿè¸ªæœ€ä½³æ£€æŸ¥ç‚¹ï¼‰ï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥é€šè¿‡é¦–å…ˆæ˜¾å¼ä¿å­˜æœ€ç»ˆæ¨¡å‹ï¼Œç„¶åæ‰§è¡Œä¸ä¸Šè¿°ç›¸åŒçš„æ“ä½œæ¥å®Œæˆè®­ç»ƒï¼š

```py
from deepspeed.utils.zero_to_fp32 import load_state_dict_from_zero_checkpoint

checkpoint_dir = os.path.join(trainer.args.output_dir, "checkpoint-final")
trainer.deepspeed.save_checkpoint(checkpoint_dir)
fp32_model = load_state_dict_from_zero_checkpoint(trainer.model, checkpoint_dir)
```

è¯·æ³¨æ„ï¼Œä¸€æ—¦è¿è¡Œäº†`load_state_dict_from_zero_checkpoint`ï¼Œ`model`å°†ä¸å†åœ¨ç›¸åŒåº”ç”¨ç¨‹åºçš„DeepSpeedä¸Šä¸‹æ–‡ä¸­å¯ç”¨ã€‚å³æ‚¨éœ€è¦é‡æ–°åˆå§‹åŒ–deepspeedå¼•æ“ï¼Œå› ä¸º`model.load_state_dict(state_dict)`å°†ä»ä¸­åˆ é™¤æ‰€æœ‰DeepSpeedçš„é­”æ³•ã€‚å› æ­¤ï¼Œåªåœ¨è®­ç»ƒçš„æœ€åé˜¶æ®µæ‰§è¡Œæ­¤æ“ä½œã€‚

å½“ç„¶ï¼Œæ‚¨ä¸å¿…ä½¿ç”¨ç±»ï¼š*~transformers.Trainer*ï¼Œæ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„è®­ç»ƒå™¨è°ƒæ•´ä¸Šé¢çš„ç¤ºä¾‹ã€‚

å¦‚æœå‡ºäºæŸç§åŸå› æ‚¨æƒ³è¦æ›´å¤šçš„ç»†åŒ–ï¼Œæ‚¨è¿˜å¯ä»¥æå–æƒé‡çš„fp32`state_dict`å¹¶æŒ‰ç…§ä»¥ä¸‹ç¤ºä¾‹è‡ªè¡Œåº”ç”¨ï¼š

```py
from deepspeed.utils.zero_to_fp32 import get_fp32_state_dict_from_zero_checkpoint

state_dict = get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir)  # already on cpu
model = model.cpu()
model.load_state_dict(state_dict)
```

**ç¦»çº¿FP32æƒé‡æ¢å¤ï¼š**

DeepSpeedåˆ›å»ºäº†ä¸€ä¸ªç‰¹æ®Šçš„è½¬æ¢è„šæœ¬`zero_to_fp32.py`ï¼Œå¹¶å°†å…¶æ”¾åœ¨æ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹çš„é¡¶å±‚ã€‚ä½¿ç”¨æ­¤è„šæœ¬ï¼Œæ‚¨å¯ä»¥åœ¨ä»»ä½•æ—¶å€™æå–æƒé‡ã€‚è¯¥è„šæœ¬æ˜¯ç‹¬ç«‹çš„ï¼Œæ‚¨ä¸å†éœ€è¦é…ç½®æ–‡ä»¶æˆ–`Trainer`æ¥æ‰§è¡Œæå–ã€‚

å‡è®¾æ‚¨çš„æ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹å¦‚ä¸‹æ‰€ç¤ºï¼š

```py
$ ls -l output_dir/checkpoint-1/
-rw-rw-r-- 1 stas stas 1.4K Mar 27 20:42 config.json
drwxrwxr-x 2 stas stas 4.0K Mar 25 19:52 global_step1/
-rw-rw-r-- 1 stas stas   12 Mar 27 13:16 latest
-rw-rw-r-- 1 stas stas 827K Mar 27 20:42 optimizer.pt
-rw-rw-r-- 1 stas stas 231M Mar 27 20:42 pytorch_model.bin
-rw-rw-r-- 1 stas stas  623 Mar 27 20:42 scheduler.pt
-rw-rw-r-- 1 stas stas 1.8K Mar 27 20:42 special_tokens_map.json
-rw-rw-r-- 1 stas stas 774K Mar 27 20:42 spiece.model
-rw-rw-r-- 1 stas stas 1.9K Mar 27 20:42 tokenizer_config.json
-rw-rw-r-- 1 stas stas  339 Mar 27 20:42 trainer_state.json
-rw-rw-r-- 1 stas stas 2.3K Mar 27 20:42 training_args.bin
-rwxrw-r-- 1 stas stas 5.5K Mar 27 13:16 zero_to_fp32.py*
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­åªæœ‰ä¸€ä¸ªDeepSpeedæ£€æŸ¥ç‚¹å­æ–‡ä»¶å¤¹*global_step1*ã€‚å› æ­¤ï¼Œè¦é‡å»ºfp32æƒé‡ï¼Œåªéœ€è¿è¡Œï¼š

```py
python zero_to_fp32.py . pytorch_model.bin
```

å°±æ˜¯è¿™æ ·ã€‚`pytorch_model.bin`ç°åœ¨å°†åŒ…å«ä»å¤šä¸ªGPUä¸­æ•´åˆçš„å®Œæ•´fp32æ¨¡å‹æƒé‡ã€‚

è„šæœ¬å°†è‡ªåŠ¨å¤„ç†ZeRO-2æˆ–ZeRO-3æ£€æŸ¥ç‚¹ã€‚

`python zero_to_fp32.py -h`å°†ä¸ºæ‚¨æä¾›ä½¿ç”¨è¯¦ç»†ä¿¡æ¯ã€‚

è„šæœ¬å°†ä½¿ç”¨æ–‡ä»¶`latest`çš„å†…å®¹è‡ªåŠ¨å‘ç°deepspeedå­æ–‡ä»¶å¤¹ï¼Œå½“å‰ç¤ºä¾‹ä¸­å°†åŒ…å«`global_step1`ã€‚

æ³¨æ„ï¼šå½“å‰è„šæœ¬éœ€è¦æœ€ç»ˆfp32æ¨¡å‹æƒé‡çš„2å€é€šç”¨RAMã€‚

### ZeRO-3å’ŒInfinityç»†å¾®å·®åˆ«

ZeRO-3ä¸ZeRO-2éå¸¸ä¸åŒï¼Œå› ä¸ºå®ƒå…·æœ‰å‚æ•°åˆ†ç‰‡åŠŸèƒ½ã€‚

ZeRO-Infinityè¿›ä¸€æ­¥æ‰©å±•äº†ZeRO-3ï¼Œä»¥æ”¯æŒNVMeå†…å­˜å’Œå¤šé¡¹å…¶ä»–é€Ÿåº¦å’Œå¯ä¼¸ç¼©æ€§æ”¹è¿›ã€‚

å°½ç®¡æˆ‘ä»¬å·²ç»å°½åŠ›ä½¿äº‹æƒ…èƒ½å¤Ÿæ­£å¸¸å·¥ä½œï¼Œè€Œæ— éœ€å¯¹æ‚¨çš„æ¨¡å‹è¿›è¡Œä»»ä½•ç‰¹æ®Šæ›´æ”¹ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½ä¼šå‘ç°éœ€è¦ä»¥ä¸‹ä¿¡æ¯ã€‚

#### æ„å»ºå¤§å‹æ¨¡å‹

DeepSpeed/ZeRO-3å¯ä»¥å¤„ç†å…·æœ‰æ•°ä¸‡äº¿å‚æ•°çš„æ¨¡å‹ï¼Œè¿™äº›å‚æ•°å¯èƒ½æ— æ³•é€‚åº”ç°æœ‰çš„RAMã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½†ä¹Ÿå¦‚æœæ‚¨å¸Œæœ›åˆå§‹åŒ–é€Ÿåº¦æ›´å¿«ï¼Œè¯·ä½¿ç”¨*deepspeed.zero.Init()*ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆä¹Ÿæ˜¯å‡½æ•°è£…é¥°å™¨ï¼‰åˆå§‹åŒ–æ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
from transformers import T5ForConditionalGeneration, T5Config
import deepspeed

with deepspeed.zero.Init():
    config = T5Config.from_pretrained("t5-small")
    model = T5ForConditionalGeneration(config)
```

æ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„ï¼Œè¿™ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„æ¨¡å‹ã€‚

å¦‚æœè¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œåªè¦`is_deepspeed_zero3_enabled()`è¿”å›`True`ï¼Œ`model_class.from_pretrained`å°†æ¿€æ´»æ­¤åŠŸèƒ½ï¼Œå½“å‰æƒ…å†µä¸‹ï¼Œè¿™æ˜¯ç”±[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)å¯¹è±¡è®¾ç½®çš„ï¼Œå¦‚æœä¼ é€’çš„DeepSpeedé…ç½®æ–‡ä»¶åŒ…å«ZeRO-3é…ç½®éƒ¨åˆ†ã€‚å› æ­¤ï¼Œæ‚¨å¿…é¡»åœ¨è°ƒç”¨`from_pretrained`ä¹‹å‰åˆ›å»º[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)å¯¹è±¡**ä¹‹å‰**ã€‚ä»¥ä¸‹æ˜¯å¯èƒ½çš„é¡ºåºç¤ºä¾‹ï¼š

```py
from transformers import AutoModel, Trainer, TrainingArguments

training_args = TrainingArguments(..., deepspeed=ds_config)
model = AutoModel.from_pretrained("t5-small")
trainer = Trainer(model=model, args=training_args, ...)
```

å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨å®˜æ–¹ç¤ºä¾‹è„šæœ¬ï¼Œå¹¶ä¸”æ‚¨çš„å‘½ä»¤è¡Œå‚æ•°åŒ…æ‹¬`--deepspeed ds_config.json`å¹¶å¯ç”¨äº†ZeRO-3é…ç½®ï¼Œåˆ™ä¸€åˆ‡éƒ½å·²ç»ä¸ºæ‚¨å®Œæˆï¼Œå› ä¸ºç¤ºä¾‹è„šæœ¬æ˜¯è¿™æ ·ç¼–å†™çš„ã€‚

æ³¨æ„ï¼šå¦‚æœæ¨¡å‹çš„fp16æƒé‡æ— æ³•é€‚åº”å•ä¸ªGPUçš„å†…å­˜ï¼Œåˆ™å¿…é¡»ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚

æœ‰å…³æ­¤æ–¹æ³•å’Œå…¶ä»–ç›¸å…³åŠŸèƒ½çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[æ„å»ºå¤§å‹æ¨¡å‹](https://deepspeed.readthedocs.io/en/latest/zero3.html#constructing-massive-models)ã€‚

æ­¤å¤–ï¼Œå½“åŠ è½½fp16é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæ‚¨å°†å¸Œæœ›å‘Šè¯‰`from_pretrained`ä½¿ç”¨`torch_dtype=torch.float16`ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[from_pretrained-torch-dtype](#from_pretrained-torch-dtype)ã€‚

#### æ”¶é›†å‚æ•°

åœ¨å¤šä¸ªGPUä¸Šçš„ZeRO-3ä¸­ï¼Œé™¤äº†å½“å‰æ‰§è¡Œå±‚çš„å‚æ•°å¤–ï¼Œæ²¡æœ‰å•ä¸ªGPUæ‹¥æœ‰æ‰€æœ‰å‚æ•°ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨éœ€è¦ä¸€æ¬¡è®¿é—®æ‰€æœ‰å±‚çš„æ‰€æœ‰å‚æ•°ï¼Œæœ‰ä¸€ç§ç‰¹å®šçš„æ–¹æ³•å¯ä»¥åšåˆ°ã€‚æ‚¨å¾ˆå¯èƒ½ä¸éœ€è¦å®ƒï¼Œä½†å¦‚æœéœ€è¦ï¼Œè¯·å‚é˜…[æ”¶é›†å‚æ•°](https://deepspeed.readthedocs.io/en/latest/zero3.html#manual-parameter-coordination)ã€‚

ç„¶è€Œï¼Œæˆ‘ä»¬åœ¨å‡ ä¸ªåœ°æ–¹å†…éƒ¨ä½¿ç”¨å®ƒï¼Œä¸€ä¸ªä¾‹å­æ˜¯åœ¨`from_pretrained`ä¸­åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡æ—¶ã€‚æˆ‘ä»¬ä¸€æ¬¡åŠ è½½ä¸€å±‚ï¼Œç„¶åç«‹å³å°†å…¶åˆ†åŒºåˆ°æ‰€æœ‰å‚ä¸çš„GPUä¸Šï¼Œå› ä¸ºå¯¹äºéå¸¸å¤§çš„æ¨¡å‹ï¼Œå°†å…¶åŠ è½½åˆ°ä¸€ä¸ªGPUä¸Šç„¶ååˆ†æ•£åˆ°å¤šä¸ªGPUä¸Šæ˜¯ä¸å¯èƒ½çš„ï¼Œç”±äºå†…å­˜é™åˆ¶ã€‚

æ­¤å¤–ï¼Œåœ¨ZeRO-3ä¸‹ï¼Œå¦‚æœæ‚¨ç¼–å†™è‡ªå·±çš„ä»£ç å¹¶é‡åˆ°çœ‹èµ·æ¥åƒæ¨¡å‹å‚æ•°æƒé‡çš„é—®é¢˜ï¼š

```py
tensor([1.0], device="cuda:0", dtype=torch.float16, requires_grad=True)
```

å¼ºè°ƒ`tensor([1.])`ï¼Œæˆ–è€…å¦‚æœå‡ºç°é”™è¯¯ï¼ŒæŒ‡å‡ºå‚æ•°å¤§å°ä¸º`1`ï¼Œè€Œä¸æ˜¯æŸä¸ªæ›´å¤§çš„å¤šç»´å½¢çŠ¶ï¼Œè¿™æ„å‘³ç€å‚æ•°è¢«åˆ†åŒºï¼Œæ‚¨çœ‹åˆ°çš„æ˜¯ZeRO-3å ä½ç¬¦ã€‚

### ZeROæ¨ç†

ZeROæ¨ç†ä½¿ç”¨ä¸ZeRO-3è®­ç»ƒç›¸åŒçš„é…ç½®ã€‚æ‚¨åªéœ€è¦ä¸éœ€è¦ä¼˜åŒ–å™¨å’Œè°ƒåº¦ç¨‹åºéƒ¨åˆ†ã€‚å®é™…ä¸Šï¼Œå¦‚æœè¦ä¸è®­ç»ƒå…±äº«ç›¸åŒçš„é…ç½®æ–‡ä»¶ï¼Œå¯ä»¥å°†è¿™äº›éƒ¨åˆ†ä¿ç•™åœ¨é…ç½®æ–‡ä»¶ä¸­ã€‚å®ƒä»¬å°†è¢«å¿½ç•¥ã€‚

å¦åˆ™ï¼Œæ‚¨åªéœ€è¦ä¼ é€’é€šå¸¸çš„[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)å‚æ•°ã€‚ä¾‹å¦‚ï¼š

```py
deepspeed --num_gpus=2 your_program.py <normal cl args> --do_eval --deepspeed ds_config.json
```

å”¯ä¸€é‡è¦çš„æ˜¯æ‚¨éœ€è¦ä½¿ç”¨ZeRO-3é…ç½®ï¼Œå› ä¸ºZeRO-2å¯¹æ¨ç†æ²¡æœ‰ä»»ä½•å¥½å¤„ï¼Œå› ä¸ºåªæœ‰ZeRO-3æ‰§è¡Œå‚æ•°åˆ†ç‰‡ï¼Œè€ŒZeRO-1æ‰§è¡Œæ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€çš„åˆ†ç‰‡ã€‚

ä»¥ä¸‹æ˜¯åœ¨ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPUéƒ¨ç½²DeepSpeedæ—¶è¿è¡Œ`run_translation.py`çš„ç¤ºä¾‹ï¼š

```py
deepspeed examples/pytorch/translation/run_translation.py \
--deepspeed tests/deepspeed/ds_config_zero3.json \
--model_name_or_path t5-small --output_dir output_dir \
--do_eval --max_eval_samples 50 --warmup_steps 50  \
--max_source_length 128 --val_max_target_length 128 \
--overwrite_output_dir --per_device_eval_batch_size 4 \
--predict_with_generate --dataset_config "ro-en" --fp16 \
--source_lang en --target_lang ro --dataset_name wmt16 \
--source_prefix "translate English to Romanian: "
```

ç”±äºåœ¨æ¨ç†ä¸­ä¸éœ€è¦é¢å¤–å¤§å†…å­˜ç”¨äºä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿåœ¨ç›¸åŒçš„ç¡¬ä»¶ä¸Šé€‚åº”æ›´å¤§çš„æ‰¹æ¬¡å’Œ/æˆ–åºåˆ—é•¿åº¦ã€‚

æ­¤å¤–ï¼ŒDeepSpeedç›®å‰æ­£åœ¨å¼€å‘ä¸€ä¸ªåä¸ºDeepspeed-Inferenceçš„ç›¸å…³äº§å“ï¼Œå®ƒä¸ZeROæŠ€æœ¯æ²¡æœ‰å…³ç³»ï¼Œè€Œæ˜¯ä½¿ç”¨å¼ é‡å¹¶è¡Œæ€§æ¥æ‰©å±•æ— æ³•é€‚åº”å•ä¸ªGPUçš„æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªæ­£åœ¨è¿›è¡Œçš„å·¥ä½œï¼Œä¸€æ—¦è¯¥äº§å“å®Œæˆï¼Œæˆ‘ä»¬å°†æä¾›é›†æˆã€‚

### å†…å­˜è¦æ±‚

ç”±äºDeepspeed ZeROå¯ä»¥å°†å†…å­˜å¸è½½åˆ°CPUï¼ˆå’ŒNVMeï¼‰ï¼Œè¯¥æ¡†æ¶æä¾›äº†ä¸€äº›å®ç”¨ç¨‹åºï¼Œå…è®¸æ‚¨æ ¹æ®ä½¿ç”¨çš„GPUæ•°é‡å‘Šè¯‰éœ€è¦å¤šå°‘CPUå’ŒGPUå†…å­˜ã€‚

è®©æˆ‘ä»¬ä¼°è®¡åœ¨å•ä¸ªGPUä¸Šå¯¹â€œbigscience/T0_3Bâ€è¿›è¡Œå¾®è°ƒæ‰€éœ€çš„å†…å­˜ï¼š

```py
$ python -c 'from transformers import AutoModel; \
from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \
model = AutoModel.from_pretrained("bigscience/T0_3B"); \
estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=1, num_nodes=1)'
[...]
Estimated memory needed for params, optim states and gradients for a:
HW: Setup with 1 node, 1 GPU per node.
SW: Model with 2783M total params, 65M largest layer params.
  per CPU  |  per GPU |   Options
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0
   62.23GB |   5.43GB | offload_param=none, offload_optimizer=cpu , zero_init=1
   62.23GB |   5.43GB | offload_param=none, offload_optimizer=cpu , zero_init=0
    0.37GB |  46.91GB | offload_param=none, offload_optimizer=none, zero_init=1
   15.56GB |  46.91GB | offload_param=none, offload_optimizer=none, zero_init=0
```

å› æ­¤ï¼Œæ‚¨å¯ä»¥å°†å…¶æ”¾åœ¨å•ä¸ª80GB GPUä¸Šï¼Œä¸ä½¿ç”¨CPUå¸è½½ï¼Œæˆ–è€…ä½¿ç”¨ä¸€ä¸ªå°å‹çš„8GB GPUï¼Œä½†æ˜¯éœ€è¦å¤§çº¦60GBçš„CPUå†…å­˜ã€‚è¯·è®°ä½ï¼Œè¿™åªæ˜¯å‚æ•°ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦çš„å†…å­˜ - æ‚¨å°†éœ€è¦æ›´å¤šå†…å­˜ç”¨äºcudaå†…æ ¸ã€æ¿€æ´»å’Œä¸´æ—¶å­˜å‚¨ã€‚

ç„¶åå°±æ˜¯æˆæœ¬ä¸é€Ÿåº¦çš„æƒè¡¡ã€‚è´­ä¹°/ç§Ÿç”¨è¾ƒå°çš„GPUï¼ˆæˆ–è¾ƒå°‘çš„GPUï¼Œå› ä¸ºæ‚¨å¯ä»¥ä½¿ç”¨Deepspeed ZeROæ¥ä½¿ç”¨å¤šä¸ªGPUï¼‰ã€‚ä½†è¿™æ ·ä¼šæ›´æ…¢ï¼Œæ‰€ä»¥å³ä½¿æ‚¨ä¸å…³å¿ƒæŸä»¶äº‹æƒ…ä¼šå¤šå¿«å®Œæˆï¼Œå‡é€Ÿä¹Ÿä¼šç›´æ¥å½±å“ä½¿ç”¨GPUçš„æŒç»­æ—¶é—´ï¼Œä»è€Œå¢åŠ æˆæœ¬ã€‚å› æ­¤ï¼Œè¯·è¿›è¡Œå®éªŒå¹¶æ¯”è¾ƒå“ªç§æ–¹æ³•æœ€å¥½ã€‚

å¦‚æœæ‚¨æœ‰è¶³å¤Ÿçš„GPUå†…å­˜ï¼Œè¯·ç¡®ä¿ç¦ç”¨CPU/NVMeå¸è½½ï¼Œå› ä¸ºè¿™å°†ä½¿ä¸€åˆ‡æ›´å¿«ã€‚

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬é‡å¤ä½¿ç”¨2ä¸ªGPUï¼š

```py
$ python -c 'from transformers import AutoModel; \
from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \
model = AutoModel.from_pretrained("bigscience/T0_3B"); \
estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=2, num_nodes=1)'
[...]
Estimated memory needed for params, optim states and gradients for a:
HW: Setup with 1 node, 2 GPUs per node.
SW: Model with 2783M total params, 65M largest layer params.
  per CPU  |  per GPU |   Options
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0
   62.23GB |   2.84GB | offload_param=none, offload_optimizer=cpu , zero_init=1
   62.23GB |   2.84GB | offload_param=none, offload_optimizer=cpu , zero_init=0
    0.74GB |  23.58GB | offload_param=none, offload_optimizer=none, zero_init=1
   31.11GB |  23.58GB | offload_param=none, offload_optimizer=none, zero_init=0

```

å› æ­¤ï¼Œæ‚¨å¯èƒ½éœ€è¦2ä¸ª32GBæˆ–æ›´é«˜å†…å­˜çš„GPUï¼Œè€Œä¸éœ€è¦å°†å†…å­˜å¸è½½åˆ°CPUã€‚

æœ‰å…³å®Œæ•´ä¿¡æ¯ï¼Œè¯·å‚é˜…[memory estimators](https://deepspeed.readthedocs.io/en/latest/memory.html)ã€‚

### æäº¤é—®é¢˜

ä»¥ä¸‹æ˜¯å¦‚ä½•æäº¤é—®é¢˜ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å¿«é€Ÿæ‰¾åˆ°é—®é¢˜çš„æ ¹æºå¹¶å¸®åŠ©æ‚¨è§£é™¤å·¥ä½œé˜»å¡ã€‚

åœ¨æ‚¨çš„æŠ¥å‘Šä¸­ï¼Œè¯·å§‹ç»ˆåŒ…æ‹¬ï¼š

1.  åœ¨æŠ¥å‘Šä¸­æä¾›å®Œæ•´çš„Deepspeedé…ç½®æ–‡ä»¶

1.  å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)çš„å‘½ä»¤è¡Œå‚æ•°ï¼Œæˆ–è€…å¦‚æœæ‚¨è‡ªå·±ç¼–å†™äº†Trainerè®¾ç½®ï¼Œåˆ™ä½¿ç”¨[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)å‚æ•°ã€‚è¯·ä¸è¦è½¬å‚¨[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ï¼Œå› ä¸ºå®ƒæœ‰æ•°åä¸ªä¸é—®é¢˜æ— å…³çš„æ¡ç›®ã€‚

1.  è¾“å‡ºï¼š

    ```py
    python -c 'import torch; print(f"torch: {torch.__version__}")'
    python -c 'import transformers; print(f"transformers: {transformers.__version__}")'
    python -c 'import deepspeed; print(f"deepspeed: {deepspeed.__version__}")'
    ```

1.  å¦‚æœå¯èƒ½çš„è¯ï¼Œè¯·åŒ…å«ä¸€ä¸ªé“¾æ¥åˆ°ä¸€ä¸ªGoogle Colabç¬”è®°æœ¬ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥é‡ç°é—®é¢˜ã€‚æ‚¨å¯ä»¥ä½¿ç”¨è¿™ä¸ª[notebook](https://github.com/stas00/porting/blob/master/transformers/deepspeed/DeepSpeed_on_colab_CLI.ipynb)ä½œä¸ºèµ·ç‚¹ã€‚

1.  é™¤éä¸å¯èƒ½ï¼Œè¯·å§‹ç»ˆä½¿ç”¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„æ ‡å‡†æ•°æ®é›†ï¼Œè€Œä¸æ˜¯è‡ªå®šä¹‰æ•°æ®é›†ã€‚

1.  å¦‚æœå¯èƒ½ï¼Œè¯·å°è¯•ä½¿ç”¨ç°æœ‰çš„[examples](https://github.com/huggingface/transformers/tree/main/examples/pytorch)ä¹‹ä¸€æ¥é‡ç°é—®é¢˜ã€‚

éœ€è¦è€ƒè™‘çš„äº‹é¡¹ï¼š

+   Deepspeedé€šå¸¸ä¸æ˜¯é—®é¢˜çš„åŸå› ã€‚

    ä¸€äº›æäº¤çš„é—®é¢˜è¢«è¯æ˜ä¸Deepspeedæ— å…³ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€æ—¦ä»è®¾ç½®ä¸­ç§»é™¤äº†Deepspeedï¼Œé—®é¢˜ä»ç„¶å­˜åœ¨ã€‚

    å› æ­¤ï¼Œå¦‚æœä¸æ˜¯ç»å¯¹æ˜æ˜¾æ˜¯Deepspeedç›¸å…³çš„é—®é¢˜ï¼Œä¾‹å¦‚æ‚¨å¯ä»¥çœ‹åˆ°æœ‰å¼‚å¸¸å¹¶ä¸”å¯ä»¥çœ‹åˆ°æ¶‰åŠDeepspeedæ¨¡å—ï¼Œé¦–å…ˆåœ¨æ²¡æœ‰Deepspeedçš„è®¾ç½®ä¸­é‡æ–°æµ‹è¯•æ‚¨çš„è®¾ç½®ã€‚åªæœ‰åœ¨é—®é¢˜ä»ç„¶å­˜åœ¨æ—¶æ‰æåˆ°Deepspeedå¹¶æä¾›æ‰€æœ‰å¿…è¦çš„ç»†èŠ‚ã€‚

+   å¦‚æœæ‚¨æ˜ç¡®çŸ¥é“é—®é¢˜å‡ºåœ¨DeepSpeedæ ¸å¿ƒè€Œä¸æ˜¯é›†æˆéƒ¨åˆ†ï¼Œè¯·ç›´æ¥å‘[Deepspeed](https://github.com/microsoft/DeepSpeed/) æäº¤é—®é¢˜ã€‚å¦‚æœæ‚¨ä¸ç¡®å®šï¼Œè¯·ä¸è¦æ‹…å¿ƒï¼Œä»»ä½•ä¸€ä¸ªé—®é¢˜è·Ÿè¸ªå™¨éƒ½å¯ä»¥ï¼Œæˆ‘ä»¬ä¼šåœ¨æ‚¨å‘å¸ƒåæ‰¾å‡ºé—®é¢˜ï¼Œå¹¶åœ¨éœ€è¦æ—¶å°†æ‚¨é‡å®šå‘åˆ°å¦ä¸€ä¸ªé—®é¢˜è·Ÿè¸ªå™¨ã€‚

### æ•…éšœæ’é™¤

#### æ·±åº¦é€Ÿåº¦è¿›ç¨‹åœ¨å¯åŠ¨æ—¶è¢«ç»ˆæ­¢ï¼Œæ²¡æœ‰å›æº¯

å¦‚æœ`deepspeed`è¿›ç¨‹åœ¨å¯åŠ¨æ—¶è¢«ç»ˆæ­¢ï¼Œæ²¡æœ‰å›æº¯ï¼Œé€šå¸¸æ„å‘³ç€ç¨‹åºå°è¯•åˆ†é…æ¯”æ‚¨çš„ç³»ç»Ÿå…·æœ‰çš„CPUå†…å­˜æ›´å¤šçš„å†…å­˜ï¼Œæˆ–è€…æ‚¨çš„è¿›ç¨‹è¢«å…è®¸åˆ†é…çš„å†…å­˜ï¼Œè€Œæ“ä½œç³»ç»Ÿå†…æ ¸ç»ˆæ­¢äº†è¯¥è¿›ç¨‹ã€‚è¿™æ˜¯å› ä¸ºæ‚¨çš„é…ç½®æ–‡ä»¶å¾ˆå¯èƒ½å·²ç»é…ç½®äº†`offload_optimizer`æˆ–`offload_param`æˆ–ä¸¤è€…éƒ½é…ç½®ä¸ºè½¬ç§»åˆ°`cpu`ã€‚å¦‚æœæ‚¨æœ‰NVMeï¼Œå°è¯•å°†å…¶è½¬ç§»åˆ°NVMeï¼Œå¦‚æœæ‚¨æ­£åœ¨è¿è¡ŒZeRO-3ã€‚è¿™æ˜¯å¦‚ä½•[ä¼°ç®—ç‰¹å®šæ¨¡å‹æ‰€éœ€å†…å­˜é‡](https://deepspeed.readthedocs.io/en/latest/memory.html)çš„æ–¹æ³•ã€‚

#### è®­ç»ƒå’Œ/æˆ–è¯„ä¼°/é¢„æµ‹æŸå¤±ä¸ºNaN

å½“ä¸€ä¸ªä»¥bf16æ··åˆç²¾åº¦æ¨¡å¼é¢„è®­ç»ƒçš„æ¨¡å‹å°è¯•åœ¨fp16ä¸‹ä½¿ç”¨æ—¶ï¼Œé€šå¸¸ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼ˆæ— è®ºæ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦ï¼‰ã€‚å¤§å¤šæ•°åœ¨TPUä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œé€šå¸¸æ˜¯ç”±Googleå‘å¸ƒçš„æ¨¡å‹éƒ½å±äºè¿™ä¸€ç±»ï¼ˆä¾‹å¦‚ï¼Œå‡ ä¹æ‰€æœ‰åŸºäºt5çš„æ¨¡å‹ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè§£å†³æ–¹æ¡ˆæ˜¯è¦ä¹ˆä½¿ç”¨fp32ï¼Œè¦ä¹ˆä½¿ç”¨bf16ï¼Œå¦‚æœæ‚¨çš„ç¡¬ä»¶æ”¯æŒçš„è¯ï¼ˆTPUã€Ampere GPUæˆ–æ›´æ–°ï¼‰ã€‚

å¦ä¸€ä¸ªé—®é¢˜å¯èƒ½ä¸ä½¿ç”¨fp16æœ‰å…³ã€‚å½“æ‚¨é…ç½®æ­¤éƒ¨åˆ†æ—¶ï¼š

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    }
}
```

å¹¶ä¸”æ‚¨åœ¨æ—¥å¿—ä¸­çœ‹åˆ°DeepspeedæŠ¥å‘Š`OVERFLOW!`å¦‚ä¸‹ï¼š

```py
0%|                                                                                                                             | 0/189 [00:00<?, ?it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 262144
  1%|â–Œ                                                                                                                    | 1/189 [00:00<01:26,  2.17it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072.0
  1%|â–ˆâ–
 [...]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                   | 27/189 [00:14<01:13,  2.21it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                  | 28/189 [00:14<01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                  | 29/189 [00:15<01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
[...]
```

è¿™æ„å‘³ç€DeepspeedæŸå¤±ç¼©æ”¾å™¨æ— æ³•æ‰¾åˆ°ä¸€ä¸ªç¼©æ”¾ç³»æ•°æ¥å…‹æœæŸå¤±æº¢å‡ºã€‚

ï¼ˆæ­¤å¤„çš„æ—¥å¿—å·²ç»è¿‡å¤„ç†ï¼Œä»¥ä¾¿æ›´æ˜“é˜…è¯»ã€‚ï¼‰

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€šå¸¸éœ€è¦æé«˜`initial_scale_power`çš„å€¼ã€‚å°†å…¶è®¾ç½®ä¸º`"initial_scale_power": 32`é€šå¸¸ä¼šè§£å†³é—®é¢˜ã€‚

### æ³¨

+   è™½ç„¶DeepSpeedæœ‰ä¸€ä¸ªå¯é€šè¿‡pipå®‰è£…çš„PyPIè½¯ä»¶åŒ…ï¼Œä½†å¼ºçƒˆå»ºè®®ä»[æº](https://github.com/microsoft/deepspeed#installation)å®‰è£…ï¼Œä»¥æœ€å¥½åœ°åŒ¹é…æ‚¨çš„ç¡¬ä»¶ï¼Œå¹¶ä¸”å¦‚æœæ‚¨éœ€è¦å¯ç”¨æŸäº›åŠŸèƒ½ï¼Œæ¯”å¦‚1æ¯”ç‰¹Adamï¼Œåœ¨pypiåˆ†å‘ä¸­æ˜¯ä¸å¯ç”¨çš„ã€‚

+   æ‚¨ä¸å¿…ä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)æ¥ä½¿ç”¨ğŸ¤— Transformersçš„DeepSpeed - æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•æ¨¡å‹ä¸æ‚¨è‡ªå·±çš„è®­ç»ƒå™¨ï¼Œå¹¶ä¸”æ‚¨å°†æ ¹æ®[DeepSpeedé›†æˆè¯´æ˜](https://www.deepspeed.ai/getting-started/#writing-deepspeed-models)æ¥è°ƒæ•´åè€…ã€‚

## éTrainer Deepspeedé›†æˆ

[HfDeepSpeedConfig](/docs/transformers/v4.37.2/en/main_classes/deepspeed#transformers.integrations.HfDeepSpeedConfig) ç”¨äºå°†Deepspeedé›†æˆåˆ°ğŸ¤— Transformersæ ¸å¿ƒåŠŸèƒ½ä¸­ï¼Œå½“æœªä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)æ—¶ã€‚å®ƒå”¯ä¸€è¦åšçš„å°±æ˜¯å¤„ç†Deepspeed ZeRO-3å‚æ•°æ”¶é›†ï¼Œå¹¶åœ¨`from_pretrained`è°ƒç”¨æœŸé—´è‡ªåŠ¨å°†æ¨¡å‹åˆ†å‰²åˆ°å¤šä¸ªGPUä¸Šã€‚å…¶ä»–æ‰€æœ‰äº‹æƒ…éƒ½éœ€è¦æ‚¨è‡ªå·±æ¥åšã€‚

ä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) æ—¶ï¼Œä¸€åˆ‡éƒ½ä¼šè‡ªåŠ¨å¤„ç†ã€‚

å½“ä¸ä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)æ—¶ï¼Œä¸ºäº†æœ‰æ•ˆéƒ¨ç½²DeepSpeed ZeRO-3ï¼Œæ‚¨å¿…é¡»åœ¨å®ä¾‹åŒ–æ¨¡å‹ä¹‹å‰å®ä¾‹åŒ–[HfDeepSpeedConfig](/docs/transformers/v4.37.2/en/main_classes/deepspeed#transformers.integrations.HfDeepSpeedConfig)å¯¹è±¡ï¼Œå¹¶ä¿æŒè¯¥å¯¹è±¡å¤„äºæ´»åŠ¨çŠ¶æ€ã€‚

å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨Deepspeed ZeRO-1æˆ–ZeRO-2ï¼Œåˆ™æ ¹æœ¬ä¸éœ€è¦ä½¿ç”¨`HfDeepSpeedConfig`ã€‚

ä¾‹å¦‚ï¼Œå¯¹äºé¢„è®­ç»ƒæ¨¡å‹ï¼š

```py
from transformers.integrations import HfDeepSpeedConfig
from transformers import AutoModel
import deepspeed

ds_config = {...}  # deepspeed config object or path to the file
# must run before instantiating the model to detect zero 3
dschf = HfDeepSpeedConfig(ds_config)  # keep this object alive
model = AutoModel.from_pretrained("gpt2")
engine = deepspeed.initialize(model=model, config_params=ds_config, ...)
```

æˆ–å¯¹äºéé¢„è®­ç»ƒæ¨¡å‹ï¼š

```py
from transformers.integrations import HfDeepSpeedConfig
from transformers import AutoModel, AutoConfig
import deepspeed

ds_config = {...}  # deepspeed config object or path to the file
# must run before instantiating the model to detect zero 3
dschf = HfDeepSpeedConfig(ds_config)  # keep this object alive
config = AutoConfig.from_pretrained("gpt2")
model = AutoModel.from_config(config)
engine = deepspeed.initialize(model=model, config_params=ds_config, ...)
```

è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨æ²¡æœ‰ä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)é›†æˆï¼Œæ‚¨å°†å®Œå…¨ç‹¬ç«‹ã€‚åŸºæœ¬ä¸Šéµå¾ª[Deepspeed](https://www.deepspeed.ai/)ç½‘ç«™ä¸Šçš„æ–‡æ¡£ã€‚æ­¤å¤–ï¼Œæ‚¨å¿…é¡»æ˜ç¡®é…ç½®é…ç½®æ–‡ä»¶ - ä¸èƒ½ä½¿ç”¨`"auto"`å€¼ï¼Œè€Œå¿…é¡»ä½¿ç”¨å®é™…å€¼ã€‚

## HfDeepSpeedConfig

### `class transformers.integrations.HfDeepSpeedConfig`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/deepspeed.py#L56)

```py
( config_file_or_dict )
```

å‚æ•°

+   `config_file_or_dict`ï¼ˆ`Union[str, Dict]`ï¼‰â€” DeepSpeedé…ç½®æ–‡ä»¶æˆ–å­—å…¸çš„è·¯å¾„ã€‚

æ­¤å¯¹è±¡åŒ…å«ä¸€ä¸ªDeepSpeedé…ç½®å­—å…¸ï¼Œå¯ä»¥å¿«é€ŸæŸ¥è¯¢è¯¸å¦‚é›¶é˜¶æ®µä¹‹ç±»çš„å†…å®¹ã€‚

æ­¤å¯¹è±¡çš„`weakref`å­˜å‚¨åœ¨æ¨¡å—çš„å…¨å±€å˜é‡ä¸­ï¼Œä»¥ä¾¿èƒ½å¤Ÿä»Trainerå¯¹è±¡ä¸å¯ç”¨çš„åŒºåŸŸè®¿é—®é…ç½®ï¼ˆä¾‹å¦‚`from_pretrained`å’Œ`_get_resized_embeddings`ï¼‰ã€‚å› æ­¤ï¼Œåœ¨ç¨‹åºä»åœ¨è¿è¡Œæ—¶ï¼Œè¿™ä¸ªå¯¹è±¡ä¿æŒæ´»åŠ¨æ˜¯å¾ˆé‡è¦çš„ã€‚

[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ä½¿ç”¨`HfTrainerDeepSpeedConfig`å­ç±»ã€‚è¯¥å­ç±»å…·æœ‰å°†é…ç½®ä¸[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)çš„å€¼åŒæ­¥çš„é€»è¾‘ï¼Œé€šè¿‡æ›¿æ¢ç‰¹æ®Šå ä½ç¬¦å€¼ï¼š`"auto"`ã€‚å¦‚æœæ²¡æœ‰è¿™ç§ç‰¹æ®Šé€»è¾‘ï¼ŒDeepSpeedé…ç½®å°†ä¸ä¼šä»¥ä»»ä½•æ–¹å¼ä¿®æ”¹ã€‚

### è‡ªå®šä¹‰DeepSpeed ZeROæ¨ç†

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œæ¼”ç¤ºå¦‚ä½•åœ¨æ— æ³•å°†æ¨¡å‹æ”¾å…¥å•ä¸ªGPUçš„æƒ…å†µä¸‹è¿›è¡ŒDeepSpeed ZeROæ¨ç†ï¼Œè€Œä¸ä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ã€‚è§£å†³æ–¹æ¡ˆåŒ…æ‹¬ä½¿ç”¨é¢å¤–çš„GPUå’Œ/æˆ–å°†GPUå†…å­˜è½¬ç§»åˆ°CPUå†…å­˜ã€‚

è¿™é‡Œéœ€è¦ç†è§£çš„é‡è¦ç»†å¾®å·®åˆ«æ˜¯ï¼ŒZeROçš„è®¾è®¡æ–¹å¼ä½¿æ‚¨å¯ä»¥å¹¶è¡Œå¤„ç†ä¸åŒGPUä¸Šçš„ä¸åŒè¾“å…¥ã€‚

ç¤ºä¾‹æœ‰å¤§é‡æ³¨é‡Šå¹¶ä¸”æ˜¯è‡ªæˆ‘è®°å½•çš„ã€‚

ç¡®ä¿ï¼š

1.  å¦‚æœæ‚¨æœ‰è¶³å¤Ÿçš„GPUå†…å­˜ï¼Œè¯·ç¦ç”¨CPUå¸è½½ï¼ˆå› ä¸ºå®ƒä¼šå‡æ…¢é€Ÿåº¦ï¼‰

1.  å¦‚æœæ‚¨æ‹¥æœ‰Ampereæˆ–æ›´æ–°çš„GPUï¼Œè¯·å¯ç”¨bf16ä»¥åŠ å¿«é€Ÿåº¦ã€‚å¦‚æœæ‚¨æ²¡æœ‰è¯¥ç¡¬ä»¶ï¼Œå¯ä»¥å¯ç”¨fp16ï¼Œåªè¦ä¸ä½¿ç”¨åœ¨bf16æ··åˆç²¾åº¦ï¼ˆä¾‹å¦‚å¤§å¤šæ•°t5æ¨¡å‹ï¼‰ä¸­é¢„è®­ç»ƒçš„æ¨¡å‹ã€‚è¿™äº›é€šå¸¸åœ¨fp16ä¸­æº¢å‡ºï¼Œæ‚¨å°†çœ‹åˆ°åƒåœ¾è¾“å‡ºã€‚

```py
#!/usr/bin/env python

# This script demonstrates how to use Deepspeed ZeRO in an inference mode when one can't fit a model
# into a single GPU
#
# 1\. Use 1 GPU with CPU offload
# 2\. Or use multiple GPUs instead
#
# First you need to install deepspeed: pip install deepspeed
#
# Here we use a 3B "bigscience/T0_3B" model which needs about 15GB GPU RAM - so 1 largish or 2
# small GPUs can handle it. or 1 small GPU and a lot of CPU memory.
#
# To use a larger model like "bigscience/T0" which needs about 50GB, unless you have an 80GB GPU -
# you will need 2-4 gpus. And then you can adapt the script to handle more gpus if you want to
# process multiple inputs at once.
#
# The provided deepspeed config also activates CPU memory offloading, so chances are that if you
# have a lot of available CPU memory and you don't mind a slowdown you should be able to load a
# model that doesn't normally fit into a single GPU. If you have enough GPU memory the program will
# run faster if you don't want offload to CPU - so disable that section then.
#
# To deploy on 1 gpu:
#
# deepspeed --num_gpus 1 t0.py
# or:
# python -m torch.distributed.run --nproc_per_node=1 t0.py
#
# To deploy on 2 gpus:
#
# deepspeed --num_gpus 2 t0.py
# or:
# python -m torch.distributed.run --nproc_per_node=2 t0.py

from transformers import AutoTokenizer, AutoConfig, AutoModelForSeq2SeqLM
from transformers.integrations import HfDeepSpeedConfig
import deepspeed
import os
import torch

os.environ["TOKENIZERS_PARALLELISM"] = "false"  # To avoid warnings about parallelism in tokenizers

# distributed setup
local_rank = int(os.getenv("LOCAL_RANK", "0"))
world_size = int(os.getenv("WORLD_SIZE", "1"))
torch.cuda.set_device(local_rank)
deepspeed.init_distributed()

model_name = "bigscience/T0_3B"

config = AutoConfig.from_pretrained(model_name)
model_hidden_size = config.d_model

# batch size has to be divisible by world_size, but can be bigger than world_size
train_batch_size = 1 * world_size

# ds_config notes
#
# - enable bf16 if you use Ampere or higher GPU - this will run in mixed precision and will be
# faster.
#
# - for older GPUs you can enable fp16, but it'll only work for non-bf16 pretrained models - e.g.
# all official t5 models are bf16-pretrained
#
# - set offload_param.device to "none" or completely remove the `offload_param` section if you don't
# - want CPU offload
#
# - if using `offload_param` you can manually finetune stage3_param_persistence_threshold to control
# - which params should remain on gpus - the larger the value the smaller the offload size
#
# For indepth info on Deepspeed config see
# https://huggingface.co/docs/transformers/main/main_classes/deepspeed

# keeping the same format as json for consistency, except it uses lower case for true/false
# fmt: off
ds_config = {
    "fp16": {
        "enabled": False
    },
    "bf16": {
        "enabled": False
    },
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu",
            "pin_memory": True
        },
        "overlap_comm": True,
        "contiguous_gradients": True,
        "reduce_bucket_size": model_hidden_size * model_hidden_size,
        "stage3_prefetch_bucket_size": 0.9 * model_hidden_size * model_hidden_size,
        "stage3_param_persistence_threshold": 10 * model_hidden_size
    },
    "steps_per_print": 2000,
    "train_batch_size": train_batch_size,
    "train_micro_batch_size_per_gpu": 1,
    "wall_clock_breakdown": False
}
# fmt: on

# next line instructs transformers to partition the model directly over multiple gpus using
# deepspeed.zero.Init when model's `from_pretrained` method is called.
#
# **it has to be run before loading the model AutoModelForSeq2SeqLM.from_pretrained(model_name)**
#
# otherwise the model will first be loaded normally and only partitioned at forward time which is
# less efficient and when there is little CPU RAM may fail
dschf = HfDeepSpeedConfig(ds_config)  # keep this object alive

# now a model can be loaded.
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# initialise Deepspeed ZeRO and store only the engine object
ds_engine = deepspeed.initialize(model=model, config_params=ds_config)[0]
ds_engine.module.eval()  # inference

# Deepspeed ZeRO can process unrelated inputs on each GPU. So for 2 gpus you process 2 inputs at once.
# If you use more GPUs adjust for more.
# And of course if you have just one input to process you then need to pass the same string to both gpus
# If you use only one GPU, then you will have only rank 0.
rank = torch.distributed.get_rank()
if rank == 0:
    text_in = "Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy"
elif rank == 1:
    text_in = "Is this review positive or negative? Review: this is the worst restaurant ever"

tokenizer = AutoTokenizer.from_pretrained(model_name)
inputs = tokenizer.encode(text_in, return_tensors="pt").to(device=local_rank)
with torch.no_grad():
    outputs = ds_engine.module.generate(inputs, synced_gpus=True)
text_out = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(f"rank{rank}:\n   in={text_in}\n  out={text_out}")
```

è®©æˆ‘ä»¬å°†å…¶ä¿å­˜ä¸º`t0.py`å¹¶è¿è¡Œï¼š

```py
$ deepspeed --num_gpus 2 t0.py
rank0:
   in=Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy
  out=Positive
rank1:
   in=Is this review positive or negative? Review: this is the worst restaurant ever
  out=negative
```

è¿™æ˜¯ä¸€ä¸ªéå¸¸åŸºæœ¬çš„ç¤ºä¾‹ï¼Œæ‚¨å°†å¸Œæœ›æ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œè°ƒæ•´ã€‚

### ç”Ÿæˆç»†å¾®å·®åˆ«

ä½¿ç”¨å¤šä¸ªGPUä¸ZeRO Stage-3ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œå¿…é¡»é€šè¿‡è°ƒç”¨`generate(..., synced_gpus=True)`æ¥åŒæ­¥GPUã€‚å¦‚æœä¸è¿™æ ·åšï¼Œå¦‚æœä¸€ä¸ªGPUåœ¨å…¶ä»–GPUä¹‹å‰å®Œæˆç”Ÿæˆï¼Œæ•´ä¸ªç³»ç»Ÿå°†æŒ‚èµ·ï¼Œå› ä¸ºå…¶ä»–GPUå°†æ— æ³•æ¥æ”¶åœæ­¢ç”Ÿæˆçš„GPUçš„æƒé‡ç‰‡æ®µã€‚

ä»`transformers>=4.28`å¼€å§‹ï¼Œå¦‚æœæœªæ˜ç¡®æŒ‡å®š`synced_gpus`ï¼Œåˆ™åœ¨æ£€æµ‹åˆ°è¿™äº›æ¡ä»¶æ—¶ï¼Œå®ƒå°†è‡ªåŠ¨è®¾ç½®ä¸º`True`ã€‚ä½†æ˜¯ï¼Œå¦‚æœéœ€è¦ï¼Œä»ç„¶å¯ä»¥è¦†ç›–`synced_gpus`çš„å€¼ã€‚

## æµ‹è¯•Deepspeedé›†æˆ

å¦‚æœæ‚¨æäº¤æ¶‰åŠDeepSpeedé›†æˆçš„PRï¼Œè¯·æ³¨æ„æˆ‘ä»¬çš„CircleCI PR CIè®¾ç½®æ²¡æœ‰GPUï¼Œå› æ­¤æˆ‘ä»¬åªåœ¨å¦ä¸€ä¸ªCIæ¯æ™šè¿è¡Œéœ€è¦GPUçš„æµ‹è¯•ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨åœ¨PRä¸­æ”¶åˆ°ç»¿è‰²CIæŠ¥å‘Šï¼Œè¿™å¹¶ä¸æ„å‘³ç€DeepSpeedæµ‹è¯•é€šè¿‡ã€‚

è¦è¿è¡ŒDeepSpeedæµ‹è¯•ï¼Œè¯·è‡³å°‘è¿è¡Œï¼š

```py
RUN_SLOW=1 pytest tests/deepspeed/test_deepspeed.py
```

å¦‚æœæ›´æ”¹äº†å»ºæ¨¡æˆ–pytorchç¤ºä¾‹ä»£ç ä¸­çš„ä»»ä½•å†…å®¹ï¼Œåˆ™è¿˜è¦è¿è¡Œæ¨¡å‹åŠ¨ç‰©å›­æµ‹è¯•ã€‚ä»¥ä¸‹å°†è¿è¡Œæ‰€æœ‰DeepSpeedæµ‹è¯•ï¼š

```py
RUN_SLOW=1 pytest tests/deepspeed
```

## ä¸»DeepSpeedèµ„æº

+   [é¡¹ç›®çš„github](https://github.com/microsoft/deepspeed)

+   [ä½¿ç”¨æ–‡æ¡£](https://www.deepspeed.ai/getting-started/)

+   [APIæ–‡æ¡£](https://deepspeed.readthedocs.io/en/latest/index.html)

+   [åšå®¢æ–‡ç« ](https://www.microsoft.com/en-us/research/search/?q=deepspeed)

è®ºæ–‡ï¼š

+   [ZeROï¼šé¢å‘è®­ç»ƒä¸‡äº¿å‚æ•°æ¨¡å‹çš„å†…å­˜ä¼˜åŒ–](https://arxiv.org/abs/1910.02054)

+   [ZeRO-Offload: æ°‘ä¸»åŒ–åäº¿è§„æ¨¡çš„æ¨¡å‹è®­ç»ƒ](https://arxiv.org/abs/2101.06840)

+   [ZeRO-Infinity: æ‰“ç ´ GPU å†…å­˜å£ï¼Œå®ç°æç«¯è§„æ¨¡çš„æ·±åº¦å­¦ä¹ ](https://arxiv.org/abs/2104.07857)

æœ€åï¼Œè¯·è®°ä½ï¼ŒHuggingFace [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) åªé›†æˆäº† DeepSpeedï¼Œå› æ­¤å¦‚æœæ‚¨åœ¨ä½¿ç”¨ DeepSpeed æ–¹é¢é‡åˆ°ä»»ä½•é—®é¢˜æˆ–ç–‘é—®ï¼Œè¯·åœ¨ [DeepSpeed GitHub](https://github.com/microsoft/DeepSpeed/issues) ä¸Šæäº¤é—®é¢˜ã€‚
