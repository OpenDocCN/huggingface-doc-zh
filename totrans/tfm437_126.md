# DeepSpeed 集成

> 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/deepspeed](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/deepspeed)

[DeepSpeed](https://github.com/microsoft/DeepSpeed) 实现了 [ZeRO 论文](https://arxiv.org/abs/1910.02054) 中描述的所有内容。目前，它完全支持：

1.  优化器状态分区（ZeRO 阶段 1）

1.  梯度分区（ZeRO 阶段 2）

1.  参数分区（ZeRO 阶段 3）

1.  自定义混合精度训练处理

1.  一系列基于快速 CUDA 扩展的优化器

1.  ZeRO-Offload 到 CPU 和 NVMe

ZeRO-Offload 有自己的专用论文：[ZeRO-Offload: Democratizing Billion-Scale Model Training](https://arxiv.org/abs/2101.06840)。NVMe 支持在论文 [ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning](https://arxiv.org/abs/2104.07857) 中有描述。

DeepSpeed ZeRO-2 主要仅用于训练，因为其特性对推断无用。

DeepSpeed ZeRO-3 也可以用于推断，因为它允许将庞大的模型加载到多个 GPU 上，这在单个 GPU 上是不可能的。

🤗 Transformers 通过 2 个选项集成了 [DeepSpeed](https://github.com/microsoft/DeepSpeed)：

1.  通过 [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) 集成核心 DeepSpeed 功能。这是一种一切都为您完成的集成方式 - 只需提供您的自定义配置文件或使用我们的模板，您就无需做其他事情。本文档的大部分内容都集中在这个功能上。

1.  如果您不使用 [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) 并希望使用自己集成了 DeepSpeed 的 Trainer，核心功能函数如 `from_pretrained` 和 `from_config` 包括 DeepSpeed 的关键部分集成，如 ZeRO 阶段 3 及更高版本的 `zero.Init`。要使用此功能，请阅读关于 [非 Trainer DeepSpeed 集成](#nontrainer-deepspeed-integration) 的文档。

集成内容：

训练：

1.  DeepSpeed ZeRO 训练支持完整的 ZeRO 阶段 1、2 和 3，带有 ZeRO-Infinity（CPU 和 NVME 卸载）。

推断：

1.  DeepSpeed ZeRO 推断支持带有 ZeRO-Infinity 的 ZeRO 阶段 3。它使用与训练相同的 ZeRO 协议，但不使用优化器和学习率调度器，只有阶段 3 与推断相关。有关更多详细信息，请参阅：[zero-inference](#zero-inference)。

还有 DeepSpeed 推断 - 这是一种完全不同的技术，它使用张量并行而不是 ZeRO（即将推出）。

## Trainer Deepspeed 集成

### 安装

通过 pypi 安装库：

```py
pip install deepspeed
```

或通过 `transformers` 的 `extras`：

```py
pip install transformers[deepspeed]
```

或在 [DeepSpeed 的 GitHub 页面](https://github.com/microsoft/deepspeed#installation) 和 [高级安装](https://www.deepspeed.ai/tutorials/advanced-install/) 上找到更多详细信息。

如果您仍在努力构建，请首先确保阅读 [CUDA 扩展安装说明](trainer#cuda-extension-installation-notes)。

如果您没有预先构建扩展并依赖于运行时构建它们，并且尝试了以上所有解决方案仍无效，下一步尝试的是在安装之前预先构建模块。

要为 DeepSpeed 进行本地构建：

```py
git clone https://github.com/microsoft/DeepSpeed/
cd DeepSpeed
rm -rf build
TORCH_CUDA_ARCH_LIST="8.6" DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1 pip install . \
--global-option="build_ext" --global-option="-j8" --no-cache -v \
--disable-pip-version-check 2>&1 | tee build.log
```

如果您打算使用 NVMe 卸载，还需要在上述说明中包含 `DS_BUILD_AIO=1`（并在系统范围内安装 *libaio-dev*）。

编辑 `TORCH_CUDA_ARCH_LIST`，插入您打算使用的 GPU 显卡的架构代码。假设所有显卡都相同，您可以通过以下方式获取架构：

```py
CUDA_VISIBLE_DEVICES=0 python -c "import torch; print(torch.cuda.get_device_capability())"
```

如果您获得`8, 6`，那么请使用`TORCH_CUDA_ARCH_LIST="8.6"`。如果您有多张不同的显卡，可以列出所有显卡，例如`TORCH_CUDA_ARCH_LIST="6.1;8.6"`。

如果您需要在多台机器上使用相同的设置，请制作一个二进制 wheel：

```py
git clone https://github.com/microsoft/DeepSpeed/
cd DeepSpeed
rm -rf build
TORCH_CUDA_ARCH_LIST="8.6" DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1 \
python setup.py build_ext -j8 bdist_wheel
```

它将生成类似于`dist/deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl`的内容，现在您可以在本地或任何其他机器上安装为`pip install deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl`。

再次提醒确保调整`TORCH_CUDA_ARCH_LIST`以匹配目标架构。

您可以在[此处](https://developer.nvidia.com/cuda-gpus)找到NVIDIA GPU的完整列表及其对应的**计算能力**（在此上下文中与架构相同）。

您可以使用以下命令检查PyTorch构建时使用的架构：

```py
python -c "import torch; print(torch.cuda.get_arch_list())"
```

以下是如何查找已安装GPU之一的架构。例如，对于GPU 0：

```py
CUDA_VISIBLE_DEVICES=0 python -c "import torch; \
print(torch.cuda.get_device_properties(torch.device('cuda')))"
```

如果输出是：

```py
_CudaDeviceProperties(name='GeForce RTX 3090', major=8, minor=6, total_memory=24268MB, multi_processor_count=82)
```

那么您就知道这张卡的架构是`8.6`。

您也可以完全不使用`TORCH_CUDA_ARCH_LIST`，然后构建程序将自动查询构建所在的GPU的架构。这可能与目标机器上的GPU不匹配，因此最好明确指定所需的架构。

如果尝试了所有建议的方法仍然遇到构建问题，请继续进行[Deepspeed](https://github.com/microsoft/DeepSpeed/issues)的GitHub问题处理，

### 使用多个GPU进行部署

要部署DeepSpeed集成，请调整[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数，包括一个新参数`--deepspeed ds_config.json`，其中`ds_config.json`是DeepSpeed配置文件，如[此处](https://www.deepspeed.ai/docs/config-json/)所述。文件命名由您决定。建议使用DeepSpeed的`add_config_arguments`实用程序向您的代码添加必要的命令行参数。有关更多信息，请参阅[DeepSpeed的参数解析](https://deepspeed.readthedocs.io/en/latest/initialize.html#argument-parsing)文档。

您可以在此处使用您选择的启动器。您可以继续使用pytorch启动器：

```py
torch.distributed.run --nproc_per_node=2 your_program.py <normal cl args> --deepspeed ds_config.json
```

或者使用`deepspeed`提供的启动器：

```py
deepspeed --num_gpus=2 your_program.py <normal cl args> --deepspeed ds_config.json
```

正如您所看到的参数不同，但对于大多数需求，任何一个都可以。有关如何配置各个节点和GPU的完整详细信息，请参阅[此处](https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node)。

当您使用`deepspeed`启动器并且希望使用所有可用的GPU时，您可以只省略`--num_gpus`标志。

以下是在DeepSpeed下部署所有可用GPU运行`run_translation.py`的示例：

```py
deepspeed examples/pytorch/translation/run_translation.py \
--deepspeed tests/deepspeed/ds_config_zero3.json \
--model_name_or_path t5-small --per_device_train_batch_size 1 \
--output_dir output_dir --overwrite_output_dir --fp16 \
--do_train --max_train_samples 500 --num_train_epochs 1 \
--dataset_name wmt16 --dataset_config "ro-en" \
--source_lang en --target_lang ro
```

请注意，在DeepSpeed文档中，您可能会看到`--deepspeed --deepspeed_config ds_config.json` - 即两个与DeepSpeed相关的参数，但为了简单起见，并且已经有很多参数要处理，我们将两者合并为一个参数。

有关一些实际用例示例，请参阅此[帖子](https://github.com/huggingface/transformers/issues/8771#issuecomment-759248400)。

### 使用单个GPU进行部署

使用单个GPU部署DeepSpeed时，请调整[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数如下：

```py
deepspeed --num_gpus=1 examples/pytorch/translation/run_translation.py \
--deepspeed tests/deepspeed/ds_config_zero2.json \
--model_name_or_path t5-small --per_device_train_batch_size 1 \
--output_dir output_dir --overwrite_output_dir --fp16 \
--do_train --max_train_samples 500 --num_train_epochs 1 \
--dataset_name wmt16 --dataset_config "ro-en" \
--source_lang en --target_lang ro
```

这与多GPU几乎相同，但在这里我们明确告诉DeepSpeed仅使用一个GPU通过`--num_gpus=1`。默认情况下，DeepSpeed部署给定节点上可以看到的所有GPU。如果您一开始只有1个GPU，则不需要此参数。以下[文档](https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node)讨论了启动器选项。

为什么要仅使用一个GPU来使用DeepSpeed？

1.  它具有ZeRO-offload功能，可以将一些计算和内存委托给主机的CPU和RAM，从而为模型的需求留下更多的GPU资源 - 例如更大的批量大小，或者启用一个通常无法适应的非常大的模型。

1.  它提供了一个智能的GPU内存管理系统，可以最小化内存碎片化，这样可以使您适应更大的模型和数据批次。

虽然我们将在接下来详细讨论配置，但在DeepSpeed中获得单个GPU上的巨大改进的关键是至少在配置文件中具有以下配置：

```py
{
  "zero_optimization": {
     "stage": 2,
     "offload_optimizer": {
         "device": "cpu",
         "pin_memory": true
     },
     "allgather_partitions": true,
     "allgather_bucket_size": 2e8,
     "reduce_scatter": true,
     "reduce_bucket_size": 2e8,
     "overlap_comm": true,
     "contiguous_gradients": true
  }
}
```

它可以启用优化器卸载和一些其他重要功能。您可以尝试不同的缓冲区大小，在下面的讨论中会找到更多细节。

有关此类型部署的实际使用示例，请参见此[帖子](https://github.com/huggingface/transformers/issues/8771#issuecomment-759176685)。

您还可以尝试使用CPU和NVMe卸载的ZeRO-3，如本文档中进一步解释的那样。

注：

+   如果需要在特定GPU上运行，而不是GPU 0，您不能使用`CUDA_VISIBLE_DEVICES`来限制可用GPU的可见范围。相反，您必须使用以下语法：

    ```py
    deepspeed --include localhost:1 examples/pytorch/translation/run_translation.py ...
    ```

    在此示例中，我们告诉DeepSpeed使用GPU 1（第二个GPU）。

### 多节点部署

本节中的信息不是特定于DeepSpeed集成的，适用于任何多节点程序。但DeepSpeed提供了一个比其他启动器更容易使用的`deepspeed`启动器，除非您在SLURM环境中。

在本节的持续时间内，让我们假设您有2个每个8个GPU的节点。您可以通过`ssh hostname1`到达第一个节点，通过`ssh hostname2`到达第二个节点，并且两个节点必须能够通过本地ssh无密码地相互到达。当然，您需要将这些主机（节点）名称重命名为您正在使用的实际主机名称。

#### torch.distributed.run(torchrun)启动器

例如，要使用`torch.distributed.run`，您可以这样做：

```py
python -m torch.distributed.run --nproc_per_node=8 --nnode=2 --node_rank=0 --master_addr=hostname1 \
--master_port=9901 your_program.py <normal cl args> --deepspeed ds_config.json
```

您必须ssh到每个节点并在每个节点上运行相同的命令！不用着急，启动器会等待直到两个节点同步。

有关更多信息，请参见[torchrun](https://pytorch.org/docs/stable/elastic/run.html)。顺便说一句，这也是几个pytorch版本前替代了`torch.distributed.launch`的启动器。

#### deepspeed启动器

要使用`deepspeed`启动器，您首先需要创建一个`hostfile`文件：

```py
hostname1 slots=8
hostname2 slots=8
```

然后您可以这样启动：

```py
deepspeed --num_gpus 8 --num_nodes 2 --hostfile hostfile --master_addr hostname1 --master_port=9901 \
your_program.py <normal cl args> --deepspeed ds_config.json
```

与`torch.distributed.run`启动器不同，`deepspeed`将自动在两个节点上启动此命令！

有关更多信息，请参见[资源配置（多节点）](https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node)。

#### 在SLURM环境中启动

在SLURM环境中可以使用以下方法。以下是一个slurm脚本`launch.slurm`，您需要根据您特定的SLURM环境进行调整。

```py
#SBATCH --job-name=test-nodes        # name
#SBATCH --nodes=2                    # nodes
#SBATCH --ntasks-per-node=1          # crucial - only 1 task per dist per node!
#SBATCH --cpus-per-task=10           # number of cores per tasks
#SBATCH --gres=gpu:8                 # number of gpus
#SBATCH --time 20:00:00              # maximum execution time (HH:MM:SS)
#SBATCH --output=%x-%j.out           # output file name

export GPUS_PER_NODE=8
export MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=9901

srun --jobid $SLURM_JOBID bash -c 'python -m torch.distributed.run \
 --nproc_per_node $GPUS_PER_NODE --nnodes $SLURM_NNODES --node_rank $SLURM_PROCID \
 --master_addr $MASTER_ADDR --master_port $MASTER_PORT \
your_program.py <normal cl args> --deepspeed ds_config.json'
```

剩下的就是安排它运行：

```py
sbatch launch.slurm
```

`srun`将负责同时在所有节点上启动程序。

#### 非共享文件系统的使用

默认情况下，DeepSpeed期望多节点环境使用共享存储。如果不是这种情况，每个节点只能看到本地文件系统，您需要调整配置文件以包含一个[`checkpoint`_section](https://www.deepspeed.ai/docs/config-json/#checkpoint-options)，设置如下：

```py
{
  "checkpoint": {
    "use_node_local_storage": true
  }
}
```

或者，您还可以使用[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)的`--save_on_each_node`参数，上述配置将自动添加给您。

### 笔记本中的部署

将笔记本单元格作为脚本运行的问题在于没有正常的`deepspeed`启动器可供依赖，因此在某些设置下，我们必须模拟它。

如果您只使用1个GPU，以下是您必须调整笔记本中的训练代码以使用DeepSpeed的方式。

```py
# DeepSpeed requires a distributed environment even when only one process is used.
# This emulates a launcher in the notebook
import os

os.environ["MASTER_ADDR"] = "localhost"
os.environ["MASTER_PORT"] = "9994"  # modify if RuntimeError: Address already in use
os.environ["RANK"] = "0"
os.environ["LOCAL_RANK"] = "0"
os.environ["WORLD_SIZE"] = "1"

# Now proceed as normal, plus pass the deepspeed config file
training_args = TrainingArguments(..., deepspeed="ds_config_zero3.json")
trainer = Trainer(...)
trainer.train()
```

注意：`...`代表您将传递给函数的常规参数。

如果要使用多个GPU，必须使用多进程环境才能使DeepSpeed正常工作。也就是说，您必须使用该目的的启动器，而不能通过模拟本节开头介绍的分布式环境来实现。

如果您想在当前目录的笔记本中即时创建配置文件，可以使用专用单元格：

```py
%%bash
cat <<'EOT' > ds_config_zero3.json
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
EOT
```

如果训练脚本在普通文件中而不是在笔记本单元格中，您可以从单元格中正常启动`deepspeed`。例如，要使用`run_translation.py`，您可以这样启动它：

```py
!git clone https://github.com/huggingface/transformers
!cd transformers; deepspeed examples/pytorch/translation/run_translation.py ...
```

或者使用`%%bash`魔术，您可以编写多行代码供shell程序运行：

```py
%%bash

git clone https://github.com/huggingface/transformers
cd transformers
deepspeed examples/pytorch/translation/run_translation.py ...
```

在这种情况下，您不需要本节开头呈现的任何代码。

注意：虽然`%%bash`魔术很好，但目前它会缓冲输出，因此在进程完成之前您看不到日志。

### 配置

有关DeepSpeed配置文件中可用的DeepSpeed配置选项的完整指南，请参阅[以下文档](https://www.deepspeed.ai/docs/config-json/)。

您可以在[DeepSpeedExamples存储库](https://github.com/microsoft/DeepSpeedExamples)中找到数十个解决各种实际需求的DeepSpeed配置示例：

```py
git clone https://github.com/microsoft/DeepSpeedExamples
cd DeepSpeedExamples
find . -name '*json'
```

继续上面的代码，假设您想配置Lamb优化器。因此，您可以搜索示例`.json`文件： 

```py
grep -i Lamb $(find . -name '*json')
```

在[主存储库](https://github.com/microsoft/DeepSpeed)中还可以找到更多示例。

使用DeepSpeed时，您始终需要提供一个DeepSpeed配置文件，但是某些配置参数必须通过命令行进行配置。您将在本指南的其余部分中找到细微差别。

要了解DeepSpeed配置文件的外观，这里有一个激活ZeRO阶段2功能的示例，包括优化器状态cpu卸载，使用`AdamW`优化器和`WarmupLR`调度程序，并且如果传递了`--fp16`，将启用混合精度训练：

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "contiguous_gradients": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
}
```

当您执行程序时，DeepSpeed将记录从[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)接收到的配置到控制台，因此您可以看到最终传递给它的配置。

### 传递配置

如本文所述，通常将DeepSpeed配置作为json文件的路径传递，但如果您不使用命令行界面配置训练，而是通过[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)实例化[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)，那么对于`deepspeed`参数，您可以传递一个嵌套的`dict`。这允许您即时创建配置，而无需将其写入文件系统后再传递给[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)。

总结一下，您可以执行以下操作：

```py
TrainingArguments(..., deepspeed="/path/to/ds_config.json")
```

或者：

```py
ds_config_dict = dict(scheduler=scheduler_params, optimizer=optimizer_params)
TrainingArguments(..., deepspeed=ds_config_dict)
```

### 共享配置

这一部分是必读的

某些配置值对于[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)和DeepSpeed的正确运行都是必需的，因此，为了防止冲突的定义，可能导致难以检测的错误，我们选择通过[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数进行配置。

此外，一些配置值是根据模型的配置自动派生的，因此，与其记住手动调整多个值，不如让[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)为您完成大部分配置。

因此，在本指南的其余部分中，您将找到一个特殊的配置值：`auto`，设置后将自动替换为正确或最有效的值。请随意选择忽略此建议并显式设置值，在这种情况下，请非常小心，确保您的[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)参数和DeepSpeed配置一致。例如，您是否使用相同的学习率、批量大小或梯度累积设置？如果这些不匹配，训练可能会以非常难以检测的方式失败。您已经被警告了。

还有多个其他值是专门针对DeepSpeed的，您将需要手动设置以满足您的需求。

在您自己的程序中，如果您想要以主控的方式修改DeepSpeed配置并基于此配置[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments) ，您也可以使用以下方法。步骤如下：

1.  创建或加载要用作主配置的DeepSpeed配置

1.  基于这些值创建[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)对象

请注意，一些值，例如`scheduler.params.total_num_steps`是由[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)在`train`期间计算的，但您当然也可以自己进行计算。

### ZeRO

[Zero Redundancy Optimizer (ZeRO)](https://www.deepspeed.ai/tutorials/zero/) 是DeepSpeed的主要工具。它支持3个不同级别（阶段）的优化。第一个对于可伸缩性目的并不太有趣，因此本文档侧重于阶段2和3。阶段3通过最新的ZeRO-Infinity进一步改进。您可以在DeepSpeed文档中找到更详细的信息。

配置文件中的`zero_optimization`部分是最重要的部分（[文档](https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training)），因为在那里您定义了要启用哪些ZeRO阶段以及如何配置它们。您可以在DeepSpeed文档中找到每个参数的解释。

此部分必须通过DeepSpeed配置进行独占配置 - [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) 不提供等效的命令行参数。

注意：目前DeepSpeed不验证参数名称，因此如果您拼写错误，它将使用拼写错误的参数的默认设置。您可以查看DeepSpeed引擎启动日志消息，以查看它将使用哪些值。

#### ZeRO-2配置

以下是ZeRO阶段2的配置示例：

```py
{
    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 5e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 5e8,
        "contiguous_gradients": true
    }
}
```

**性能调优：**

+   启用`offload_optimizer`应该减少GPU RAM的使用（需要`"stage": 2`）

+   `"overlap_comm": true` 通过增加GPU RAM使用量来降低全局归约延迟。`overlap_comm` 使用4.5倍的`allgather_bucket_size`和`reduce_bucket_size`值。因此，如果它们设置为5e8，这将需要9GB的占用空间（`5e8 x 2字节 x 2 x 4.5`）。因此，如果您的GPU具有8GB或更少的RAM，为了避免出现OOM错误，您需要将这些参数减少到约`2e8`，这将需要3.6GB。如果您的GPU容量更大，但开始出现OOM错误，您也需要做同样的操作。

+   当减少这些缓冲区时，您正在交换通信速度以获得更多的GPU RAM。缓冲区大小越小，通信速度越慢，可用于其他任务的GPU RAM就越多。因此，如果更大的批量大小很重要，稍微减慢训练时间可能是一个不错的交易。

此外，`deepspeed==0.4.4`添加了一个新选项`round_robin_gradients`，您可以通过以下方式启用：

```py
{
    "zero_optimization": {
        "round_robin_gradients": true
    }
}
```

这是用于CPU卸载的阶段2优化，通过细粒度梯度分区将梯度复制到CPU内存中，以在等级之间并行化。性能收益随着梯度累积步骤（在优化器步骤之间的更多复制）或GPU数量（增加并行性）而增加。

#### ZeRO-3配置

以下是ZeRO阶段3的配置示例：

```py
{
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    }
}
```

如果您遇到OOM，因为您的模型或激活不适合GPU内存，并且您有未使用的CPU内存，将优化器状态和参数卸载到CPU内存并使用`"device": "cpu"`可能解决此限制。如果您不想卸载到CPU内存，请在`device`条目中使用`none`而不是`cpu`。有关卸载到NVMe的更多信息，请参阅下文。

通过将`pin_memory`设置为`true`启用了固定内存。这个功能可以提高吞吐量，但会减少其他进程可用的内存。固定内存被保留给请求它的特定进程，通常比普通CPU内存访问速度快得多。

**性能调优：**

+   `stage3_max_live_parameters`：`1e9`

+   `stage3_max_reuse_distance`：`1e9`

如果遇到OOM，请减少`stage3_max_live_parameters`和`stage3_max_reuse_distance`。除非进行激活检查点，否则它们对性能影响很小。`1e9`将消耗约2GB。内存由`stage3_max_live_parameters`和`stage3_max_reuse_distance`共享，因此不是累加的，而是总共2GB。

`stage3_max_live_parameters`是您希望在任何给定时间保留在GPU上的完整参数的上限。"重用距离"是我们使用的度量标准，用于确定参数在未来何时再次使用，我们使用`stage3_max_reuse_distance`来决定是丢弃参数还是保留参数。如果参数将在不久的将来（小于`stage3_max_reuse_distance`）再次使用，则我们保留它以减少通信开销。当启用激活检查点时，这非常有帮助，我们在前向重计算和反向传递中以单层粒度执行操作，并希望在前向重计算中保留参数直到反向传递。

以下配置值取决于模型的隐藏大小：

+   `reduce_bucket_size`：`hidden_size*hidden_size`

+   `stage3_prefetch_bucket_size`：`0.9 * hidden_size * hidden_size`

+   `stage3_param_persistence_threshold`：`10 * hidden_size`

因此将这些值设置为`auto`，[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)将自动分配推荐值。当然，您也可以显式设置这些值。

`stage3_gather_16bit_weights_on_model_save`在模型保存时启用模型fp16权重合并。对于大型模型和多个GPU，这是一项昂贵的操作，无论是在内存还是速度方面。如果您计划恢复训练，则目前需要这样做。请注意未来的更新将消除此限制并使事情更加灵活。

如果您正在从ZeRO-2配置迁移，请注意`allgather_partitions`、`allgather_bucket_size`和`reduce_scatter`配置参数在ZeRO-3中不使用。如果您将这些保留在配置文件中，它们将被忽略。

+   `sub_group_size`：`1e9`

`sub_group_size`控制参数在优化器步骤中更新的粒度。参数被分组到`sub_group_size`的桶中，每个桶依次更新。在ZeRO-Infinity中与NVMe卸载一起使用时，`sub_group_size`因此控制模型状态在优化器步骤期间从NVMe移入和移出CPU内存的粒度。这可以防止极大型模型耗尽CPU内存。

如果不使用NVMe卸载，可以将`sub_group_size`保留为默认值*1e9*。在以下情况下，您可能需要更改其默认值：

1.  在优化器步骤中遇到OOM：减少`sub_group_size`以减少临时缓冲区的内存利用

1.  优化器步骤花费很长时间：增加`sub_group_size`以提高带宽利用率，因为数据缓冲区增加。

#### ZeRO-0配置

请注意，我们将阶段0和1列在最后，因为它们很少被使用。

阶段0是禁用所有类型的分片，只使用DeepSpeed作为DDP。您可以通过以下方式打开它：

```py
{
    "zero_optimization": {
        "stage": 0
    }
}
```

这将基本上禁用ZeRO，而无需更改其他任何内容。

#### ZeRO-1配置

阶段1是阶段2减去梯度分片。您可以尝试将优化器状态分片，以加快速度：

```py
{
    "zero_optimization": {
        "stage": 1
    }
}
```

### NVMe支持

ZeRO-Infinity通过使用NVMe内存扩展GPU和CPU内存，允许训练非常大的模型。由于智能分区和平铺算法，每个GPU在卸载期间需要发送和接收非常少量的数据，因此现代NVMe被证明适合允许更大的总内存池可用于您的训练过程。ZeRO-Infinity需要启用ZeRO-3。

以下配置示例启用了NVMe以卸载优化器状态和参数：

```py
{
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "nvme",
            "nvme_path": "/local_nvme",
            "pin_memory": true,
            "buffer_count": 4,
            "fast_init": false
        },
        "offload_param": {
            "device": "nvme",
            "nvme_path": "/local_nvme",
            "pin_memory": true,
            "buffer_count": 5,
            "buffer_size": 1e8,
            "max_in_cpu": 1e9
        },
        "aio": {
            "block_size": 262144,
            "queue_depth": 32,
            "thread_count": 1,
            "single_submit": false,
            "overlap_events": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },
}
```

您可以选择将优化器状态和参数都卸载到NVMe，或者只卸载其中一个或两者都不卸载。例如，如果您有大量的CPU内存可用，尽管将其仅卸载到CPU内存，因为这样会更快（提示：“device”: “cpu”）。

这里是有关卸载[优化器状态](https://www.deepspeed.ai/docs/config-json/#optimizer-offloading)和[参数](https://www.deepspeed.ai/docs/config-json/#parameter-offloading)的完整文档。

确保您的`nvme_path`实际上是一个NVMe，因为它可以与普通硬盘或固态硬盘一起使用，但速度会慢得多。快速可扩展的训练是根据现代NVMe传输速度设计的（截至本文撰写时，读取速度约为3.5GB/s，写入速度约为3GB/s）。

为了找出最佳的`aio`配置块，您必须在目标设置上运行基准测试，如[此处所述](https://github.com/microsoft/DeepSpeed/issues/998)。

#### ZeRO-2与ZeRO-3性能

如果一切配置相同，ZeRO-3可能比ZeRO-2慢，因为前者需要收集模型权重以外的内容。如果ZeRO-2满足您的需求，并且您不需要扩展到几个GPU之外，那么您可以选择坚持使用它。重要的是要了解，ZeRO-3在速度上的代价是实现更高的可伸缩性容量。

可以调整ZeRO-3配置，使其性能接近ZeRO-2：

+   将`stage3_param_persistence_threshold`设置为一个非常大的数字 - 大于最大参数，例如`6 * hidden_size * hidden_size`。这将使参数保留在GPU上。

+   关闭`offload_params`，因为ZeRO-2没有该选项。

即使您不更改`stage3_param_persistence_threshold`，只要关闭`offload_params`，性能可能会显着提高。当然，这些更改将影响您可以训练的模型大小。因此，这些帮助您根据需要在可伸缩性和速度之间进行权衡。

#### ZeRO-2示例

这里是一个完整的ZeRO-2自动配置文件`ds_config_zero2.json`：

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "contiguous_gradients": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
```

这里是一个完整的ZeRO-2全启用手动设置的配置文件。这里主要是让您看看典型值是什么样的，但我们强烈建议使用其中带有多个`auto`设置的配置文件。

```py
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 3e-5,
            "betas": [0.8, 0.999],
            "eps": 1e-8,
            "weight_decay": 3e-7
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": 0,
            "warmup_max_lr": 3e-5,
            "warmup_num_steps": 500
        }
    },

    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "contiguous_gradients": true
    },

    "steps_per_print": 2000,
    "wall_clock_breakdown": false
}
```

#### ZeRO-3示例

这里是一个完整的ZeRO-3自动配置文件`ds_config_zero3.json`：

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
```

这里是一个完整的ZeRO-3全启用手动设置的配置文件。这里主要是让您看看典型值是什么样的，但我们强烈建议使用其中带有多个`auto`设置的配置文件。

```py
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 3e-5,
            "betas": [0.8, 0.999],
            "eps": 1e-8,
            "weight_decay": 3e-7
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": 0,
            "warmup_max_lr": 3e-5,
            "warmup_num_steps": 500
        }
    },

    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": 1e6,
        "stage3_prefetch_bucket_size": 0.94e6,
        "stage3_param_persistence_threshold": 1e4,
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },

    "steps_per_print": 2000,
    "wall_clock_breakdown": false
}
```

#### 如何选择最佳性能的ZeRO阶段和卸载方式

现在您知道有所有这些不同的阶段。如何决定使用其中哪一个？本节将尝试回答这个问题。

一般来说，以下内容适用：

+   速度方面（左边比右边快）

阶段0（DDP）> 阶段1 > 阶段2 > 阶段2 + 卸载 > 阶段3 > 阶段3 + 卸载

+   GPU内存使用方面（右侧比左侧更节省GPU内存）

阶段0（DDP）<阶段1<阶段2<阶段2 +卸载<阶段3<阶段3 +卸载

因此，当您希望在最少数量的GPU中获得最快的执行时，请按照以下过程进行。我们从最快的方法开始，如果遇到GPU OOM，则转向下一个较慢的方法，但将使用更少的GPU内存。依此类推。

首先将批处理大小设置为1（您始终可以使用梯度累积来获得任何所需的有效批处理大小）。

1.  启用`--gradient_checkpointing 1`（HF Trainer）或直接`model.gradient_checkpointing_enable()`-如果OOM，则

1.  首先尝试ZeRO阶段2。如果OOM，则

1.  尝试ZeRO阶段2 + `offload_optimizer`-如果OOM，则

1.  切换到ZeRO阶段3-如果OOM，则

1.  启用`offload_param`到`cpu`-如果OOM，则

1.  启用`offload_optimizer`到`cpu`-如果OOM，则

1.  如果您仍然无法适应批处理大小为1，请首先检查各种默认值，并在可能的情况下将其降低。例如，如果您使用`generate`，并且不使用宽搜索光束，请将其变窄，因为这将占用大量内存。

1.  绝对使用混合半精度而不是fp32-因此在Ampere及更高GPU上使用bf16，在旧的GPU架构上使用fp16。

1.  如果您仍然OOM，您可以添加更多硬件或启用ZeRO-Infinity-即切换卸载`offload_param`和`offload_optimizer`到`nvme`。您需要确保它是一个非常快速的nvme。作为一个轶事，我能够在一个小型GPU上推断BLOOM-176B，使用ZeRO-Infinity，只是速度极慢。但它有效！

当然，您可以通过从最GPU内存高效的配置开始，然后向后进行，或者尝试二分法来逆向执行这些步骤。

一旦您的批处理大小为1不会导致OOM，请测量您的有效吞吐量。

接下来尝试将批处理大小增加到尽可能大，因为批处理大小越大，GPU的效率就越高，因为它们在乘法矩阵很大时表现最佳。

现在性能优化游戏开始了。您可以关闭一些卸载功能或降低ZeRO阶段，并增加/减少批处理大小，然后再测量您的有效吞吐量。反复进行，直到满意为止。

不要花太多时间在上面，但如果您即将开始为期3个月的培训-请花几天时间找到最有效的吞吐量设置。这样，您的培训成本将最低，您将更快地完成培训。在当前快节奏的ML世界中，如果您需要额外一个月来训练某些内容，您很可能会错过一个绝佳的机会。当然，这只是我分享的一个观察，我绝不会催促您。在开始训练BLOOM-176B之前，我花了2天时间进行这个过程，并且能够将吞吐量从90提高到150 TFLOPs！这一努力为我们节省了一个多月的培训时间。

这些注意事项主要是针对训练模式编写的，但它们在推断方面也应该大多适用。例如，在推断期间，梯度检查点是无效的，因为它只在训练期间有用。此外，我们发现，如果您正在进行多GPU推断并且不使用[DeepSpeed-Inference](https://www.deepspeed.ai/tutorials/inference-tutorial/)，[Accelerate](https://huggingface.co/blog/bloom-inference-pytorch-scripts)应该提供更优越的性能。

其他快速相关的性能注意事项：

+   如果您正在从头开始训练某些内容，请始终尝试具有可被16整除的张量形状（例如隐藏大小）。对于批处理大小，请至少尝试可被2整除。如果您想从GPU中挤取更高的性能，则有硬件特定的[波和瓷砖量化](https://developer.nvidia.com/blog/optimizing-gpu-performance-tensor-cores/)可被整除。

### 激活检查点或梯度检查点

激活检查点和梯度检查点是指同一方法的两个不同术语。这很令人困惑，但事实就是如此。

梯度检查点允许将速度换成 GPU 内存，这样可以克服 GPU OOM，或者增加批量大小，通常会带来更好的性能。

HF Transformers 模型对 DeepSpeed 的激活检查点一无所知，因此如果您尝试在 DeepSpeed 配置文件中启用该功能，将不会发生任何事情。

因此，您有两种方法可以利用这个非常有益的功能：

1.  如果您想使用 HF Transformers 模型，可以使用 `model.gradient_checkpointing_enable()` 或在 HF Trainer 中使用 `--gradient_checkpointing`，这将自动为您启用此功能。在那里使用 `torch.utils.checkpoint`。

1.  如果您编写自己的模型并希望使用 DeepSpeed 的激活检查点，可以使用[那里规定的 API](https://deepspeed.readthedocs.io/en/latest/activation-checkpointing.html)。您还可以使用 HF Transformers 建模代码，并将 `torch.utils.checkpoint` 替换为 DeepSpeed 的 API。后者更灵活，因为它允许您将前向激活卸载到 CPU 内存，而不是重新计算它们。

### 优化器和调度器

只要不启用 `offload_optimizer`，您可以混合使用 DeepSpeed 和 HuggingFace 调度器和优化器。

在启用 `offload_optimizer` 时，可以使用非 DeepSpeed 优化器，只要它具有 CPU 和 GPU 实现（除了 LAMB）。

#### 优化器

DeepSpeed 的主要优化器是 Adam、AdamW、OneBitAdam 和 Lamb。这些已经通过 ZeRO 进行了彻底测试，因此建议使用它们。但是，它可以从 `torch` 导入其他优化器。完整文档在[这里](https://www.deepspeed.ai/docs/config-json/#optimizer-parameters)。

如果您在配置文件中不配置 `optimizer` 条目，[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) 将自动将其设置为 `AdamW`，并将使用提供的值或以下命令行参数的默认值：`--learning_rate`、`--adam_beta1`、`--adam_beta2`、`--adam_epsilon` 和 `--weight_decay`。

这是 `AdamW` 的自动配置的 `optimizer` 条目的示例：

```py
{
   "optimizer": {
       "type": "AdamW",
       "params": {
         "lr": "auto",
         "betas": "auto",
         "eps": "auto",
         "weight_decay": "auto"
       }
   }
}
```

请注意，命令行参数将设置配置文件中的值。这样一来，就有了一个明确的值来源，避免了例如学习率在不同地方设置为不同值时难以找到的错误。命令行规则。被覆盖的值包括：

+   `lr` 的值为 `--learning_rate`

+   `betas` 的值为 `--adam_beta1 --adam_beta2`

+   `eps` 的值为 `--adam_epsilon`

+   `weight_decay` 的值为 `--weight_decay`

因此，请记住在命令行上调整共享的超参数。

您还可以显式设置这些值：

```py
{
   "optimizer": {
       "type": "AdamW",
       "params": {
         "lr": 0.001,
         "betas": [0.8, 0.999],
         "eps": 1e-8,
         "weight_decay": 3e-7
       }
   }
}
```

但是，您需要自行同步[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数和 DeepSpeed 配置。

如果要使用上面未列出的其他优化器，则必须添加到顶级配置。

```py
{
   "zero_allow_untested_optimizer": true
}
```

与 `AdamW` 类似，您可以配置其他官方支持的优化器。只需记住，这些可能具有不同的配置值。例如，对于 Adam，您将希望 `weight_decay` 大约为 `0.01`。

此外，当与 Deepspeed 的 CPU Adam 优化器一起使用时，卸载效果最佳。如果要使用不同的优化器进行卸载，自 `deepspeed==0.8.3` 以来，您还需要添加：

```py
{
   "zero_force_ds_cpu_optimizer": false
}
```

到顶级配置。

#### 调度器

DeepSpeed 支持 `LRRangeTest`、`OneCycle`、`WarmupLR` 和 `WarmupDecayLR` 学习率调度器。完整文档在[这里](https://www.deepspeed.ai/docs/config-json/#scheduler-parameters)。

这是🤗 Transformers 和 DeepSpeed 之间调度器重叠的地方：

+   通过 `--lr_scheduler_type constant_with_warmup` 实现的 `WarmupLR`

+   通过`--lr_scheduler_type linear`配置`WarmupDecayLR`。这也是`--lr_scheduler_type`的默认值，因此，如果您没有配置调度程序，则默认将配置此调度程序。

如果您没有在配置文件中配置`scheduler`条目，[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)将使用`--lr_scheduler_type`、`--learning_rate`和`--warmup_steps`或`--warmup_ratio`的值来配置其🤗 Transformers版本。

以下是`WarmupLR`的自动配置`scheduler`条目示例：

```py
{
   "scheduler": {
         "type": "WarmupLR",
         "params": {
             "warmup_min_lr": "auto",
             "warmup_max_lr": "auto",
             "warmup_num_steps": "auto"
         }
     }
}
```

由于使用了*“auto”*，[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)参数将在配置文件中设置正确的值。这样一来，数值就有了一个明确的来源，避免了例如学习率在不同地方设置为不同值时难以找到的错误。命令行规则。设置的值包括：

+   `warmup_min_lr`，其值为`0`。

+   `warmup_max_lr`，其值为`--learning_rate`。

+   如果提供了`--warmup_steps`，则`warmup_num_steps`的值为`--warmup_steps`。否则，将使用`--warmup_ratio`乘以训练步数并四舍五入。

+   `total_num_steps`，其值为`--max_steps`或者如果未提供，则在运行时根据环境和数据集大小以及其他命令行参数自动推导（对于`WarmupDecayLR`是必需的）。

当然，您可以接管任何或所有配置值，并自行设置：

```py
{
   "scheduler": {
         "type": "WarmupLR",
         "params": {
             "warmup_min_lr": 0,
             "warmup_max_lr": 0.001,
             "warmup_num_steps": 1000
         }
     }
}
```

但是，您需要自行同步[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数和DeepSpeed配置。

例如，对于`WarmupDecayLR`，您可以使用以下条目：

```py
{
   "scheduler": {
         "type": "WarmupDecayLR",
         "params": {
             "last_batch_iteration": -1,
             "total_num_steps": "auto",
             "warmup_min_lr": "auto",
             "warmup_max_lr": "auto",
             "warmup_num_steps": "auto"
         }
     }
}
```

`total_num_steps`、`warmup_max_lr`、`warmup_num_steps`和`total_num_steps`将在加载时设置。

### fp32精度

Deepspeed支持完整的fp32和fp16混合精度。

由于使用fp16混合精度可以大大减少内存需求并提高速度，唯一不使用它的情况是当您使用的模型在这种训练模式下表现不佳时。通常情况下，这种情况发生在模型没有在fp16混合精度下进行预训练时（例如，bf16预训练模型经常出现这种情况）。这样的模型可能会溢出或下溢，导致`NaN`损失。如果您遇到这种情况，那么您需要使用完整的fp32模式，通过显式禁用默认的fp16混合精度模式：

```py
{
    "fp16": {
        "enabled": false,
    }
}
```

如果您使用基于Ampere架构的GPU，pytorch版本1.7及更高版本将自动切换到使用更高效的tf32格式进行某些操作，但结果仍将是fp32。有关详细信息和基准，请参阅[TensorFloat-32(TF32) on Ampere devices](https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)。该文档包括如何在某种情况下禁用此自动转换的说明。

使用🤗 Trainer，您可以使用`--tf32`来启用它，或者使用`--tf32 0`或`--no_tf32`来禁用它。默认情况下使用PyTorch默认值。

### 自动混合精度

您可以使用类似于pytorch的AMP方式或类似于apex的方式进行自动混合精度：

### fp16

要配置带有fp16（float16）的pytorch AMP模式，请设置：

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    }
}
```

[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)将根据`args.fp16_backend`的值自动启用或禁用它。其余的配置值由您决定。

当传递`--fp16 --fp16_backend amp`或`--fp16_full_eval`命令行参数时，此模式将被启用。

您还可以显式启用/禁用此模式：

```py
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    }
}
```

但是，您需要自行同步[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数和DeepSpeed配置。

这是[文档](https://www.deepspeed.ai/docs/config-json/#fp16-training-options)。

### bf16

如果希望使用bf16（bfloat16）而不是fp16，则应使用以下配置部分：

```py
{
    "bf16": {
        "enabled": "auto"
    }
}
```

bf16具有与fp32相同的动态范围，因此不需要损失缩放。

当传递`--bf16`或`--bf16_full_eval`命令行参数时，将启用此模式。

您也可以显式启用/禁用此模式：

```py
{
    "bf16": {
        "enabled": true
    }
}
```

截至`deepspeed==0.6.0`，bf16支持是新的实验性功能。

如果您在启用bf16的情况下使用梯度累积，您需要注意它将在bf16中累积梯度，这可能不是您想要的，因为这种格式的低精度可能导致损失的累积。

正在进行修复工作，并提供使用更高精度`dtype`（fp16或fp32）的选项。

### NCCL集合

这是训练制度的`dtype`，还有一个用于通信集合的`dtype`。

所有收集/散布操作都以相同的`dtype`执行，因此如果您使用bf16训练制度，则会以bf16进行收集-收集是一个非损失操作。

各种减少操作可能会导致很大的损失，例如当梯度在多个GPU上平均时，如果通信使用fp16或bf16，则结果可能会有损失-因为在低精度下相加多个数字时结果并不精确。bf16的精度比fp16低，因此更容易出现这种情况。通常情况下，fp16足够好，因为在平均梯度时损失很小。因此，默认情况下，对于半精度训练，减少操作的默认值是使用fp16。但是您可以完全控制此功能，如果选择，可以增加一些开销，并确保减少操作将使用fp32作为累积dtype，仅当结果准备就绪时才会将其降级为您正在训练的半精度`dtype`。

要覆盖默认设置，只需添加一个新的配置条目：

```py
{
    "communication_data_type": "fp32"
}
```

截至目前，有效值为“fp16”，“bfp16”，“fp32”。

注意：stage zero 3存在关于bf16 comm dtype的错误，已在`deepspeed==0.8.1`中修复。

### apex

要配置apex AMP类似模式，请设置：

```py
"amp": {
    "enabled": "auto",
    "opt_level": "auto"
}
```

训练器将根据`args.fp16_backend`和`args.fp16_opt_level`的值自动配置。

当传递`--fp16 --fp16_backend apex --fp16_opt_level 01`命令行参数时，将启用此模式。

您也可以显式配置此模式：

```py
{
    "amp": {
        "enabled": true,
        "opt_level": "O1"
    }
}
```

但是，您需要自行同步[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数和DeepSpeed配置。

这是[文档](https://www.deepspeed.ai/docs/config-json/#automatic-mixed-precision-amp-training-options)。

### 批量大小

要配置批量大小，请使用：

```py
{
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto"
}
```

训练器将自动将`train_micro_batch_size_per_gpu`设置为`args.per_device_train_batch_size`的值，将`train_batch_size`设置为`args.world_size * args.per_device_train_batch_size * args.gradient_accumulation_steps`的值。

您也可以显式设置这些值：

```py
{
    "train_batch_size": 12,
    "train_micro_batch_size_per_gpu": 4
}
```

但是，您需要自行同步[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数和DeepSpeed配置。

### 梯度累积

要配置梯度累积，请设置：

```py
{
    "gradient_accumulation_steps": "auto"
}
```

训练器将自动将其设置为`args.gradient_accumulation_steps`的值。

您也可以显式设置值：

```py
{
    "gradient_accumulation_steps": 3
}
```

但是，您需要自行同步[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数和DeepSpeed配置。

### 梯度裁剪

配置梯度裁剪设置：

```py
{
    "gradient_clipping": "auto"
}
```

[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)将自动将其设置为`args.max_grad_norm`的值。

您还可以显式设置该值：

```py
{
    "gradient_clipping": 1.0
}
```

但是，您需要自行同步[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)命令行参数和DeepSpeed配置。

### 获取模型权重

只要您继续使用DeepSpeed进行训练和恢复，您就不必担心任何事情。DeepSpeed将fp32主权重存储在其自定义检查点优化器文件中，这些文件是`global_step*/*optim_states.pt`（这是通配符），并保存在正常检查点下。

**FP16权重：**

当模型保存在ZeRO-2下时，您最终会得到带有模型权重的正常`pytorch_model.bin`文件，但它们只是权重的fp16版本。

在ZeRO-3下，情况要复杂得多，因为模型权重被分区到多个GPU上，因此需要`"stage3_gather_16bit_weights_on_model_save": true`来让`Trainer`保存权重的fp16版本。如果此设置为`False`，将不会创建`pytorch_model.bin`。这是因为默认情况下DeepSpeed的`state_dict`包含一个占位符而不是真正的权重。如果我们保存这个`state_dict`，将无法加载回来。

```py
{
    "zero_optimization": {
        "stage3_gather_16bit_weights_on_model_save": true
    }
}
```

**FP32权重：**

虽然fp16权重适用于恢复训练，但如果您完成了微调模型并希望将其上传到[models hub](https://huggingface.co/models)或传递给其他人，您很可能希望获取fp32权重。最好不要在训练过程中执行此操作，因为这是一个需要大量内存的过程，因此最好在训练完成后离线执行。但如果需要并且您有足够的空闲CPU内存，可以在相同的训练脚本中执行。以下部分将讨论这两种方法。

**在线FP32权重恢复：**

如果您的模型很大且剩余的CPU内存很少，这种方法可能不起作用。

如果您至少保存了一个检查点，并且想要使用最新的检查点，可以执行以下操作：

```py
from transformers.trainer_utils import get_last_checkpoint
from deepspeed.utils.zero_to_fp32 import load_state_dict_from_zero_checkpoint

checkpoint_dir = get_last_checkpoint(trainer.args.output_dir)
fp32_model = load_state_dict_from_zero_checkpoint(trainer.model, checkpoint_dir)
```

如果您正在使用`--load_best_model_at_end`类：*~transformers.TrainingArguments*参数（用于跟踪最佳检查点），那么您可以通过首先显式保存最终模型，然后执行与上述相同的操作来完成训练：

```py
from deepspeed.utils.zero_to_fp32 import load_state_dict_from_zero_checkpoint

checkpoint_dir = os.path.join(trainer.args.output_dir, "checkpoint-final")
trainer.deepspeed.save_checkpoint(checkpoint_dir)
fp32_model = load_state_dict_from_zero_checkpoint(trainer.model, checkpoint_dir)
```

请注意，一旦运行了`load_state_dict_from_zero_checkpoint`，`model`将不再在相同应用程序的DeepSpeed上下文中可用。即您需要重新初始化deepspeed引擎，因为`model.load_state_dict(state_dict)`将从中删除所有DeepSpeed的魔法。因此，只在训练的最后阶段执行此操作。

当然，您不必使用类：*~transformers.Trainer*，您可以根据自己的训练器调整上面的示例。

如果出于某种原因您想要更多的细化，您还可以提取权重的fp32`state_dict`并按照以下示例自行应用：

```py
from deepspeed.utils.zero_to_fp32 import get_fp32_state_dict_from_zero_checkpoint

state_dict = get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir)  # already on cpu
model = model.cpu()
model.load_state_dict(state_dict)
```

**离线FP32权重恢复：**

DeepSpeed创建了一个特殊的转换脚本`zero_to_fp32.py`，并将其放在检查点文件夹的顶层。使用此脚本，您可以在任何时候提取权重。该脚本是独立的，您不再需要配置文件或`Trainer`来执行提取。

假设您的检查点文件夹如下所示：

```py
$ ls -l output_dir/checkpoint-1/
-rw-rw-r-- 1 stas stas 1.4K Mar 27 20:42 config.json
drwxrwxr-x 2 stas stas 4.0K Mar 25 19:52 global_step1/
-rw-rw-r-- 1 stas stas   12 Mar 27 13:16 latest
-rw-rw-r-- 1 stas stas 827K Mar 27 20:42 optimizer.pt
-rw-rw-r-- 1 stas stas 231M Mar 27 20:42 pytorch_model.bin
-rw-rw-r-- 1 stas stas  623 Mar 27 20:42 scheduler.pt
-rw-rw-r-- 1 stas stas 1.8K Mar 27 20:42 special_tokens_map.json
-rw-rw-r-- 1 stas stas 774K Mar 27 20:42 spiece.model
-rw-rw-r-- 1 stas stas 1.9K Mar 27 20:42 tokenizer_config.json
-rw-rw-r-- 1 stas stas  339 Mar 27 20:42 trainer_state.json
-rw-rw-r-- 1 stas stas 2.3K Mar 27 20:42 training_args.bin
-rwxrw-r-- 1 stas stas 5.5K Mar 27 13:16 zero_to_fp32.py*
```

在这个例子中只有一个DeepSpeed检查点子文件夹*global_step1*。因此，要重建fp32权重，只需运行：

```py
python zero_to_fp32.py . pytorch_model.bin
```

就是这样。`pytorch_model.bin`现在将包含从多个GPU中整合的完整fp32模型权重。

脚本将自动处理ZeRO-2或ZeRO-3检查点。

`python zero_to_fp32.py -h`将为您提供使用详细信息。

脚本将使用文件`latest`的内容自动发现deepspeed子文件夹，当前示例中将包含`global_step1`。

注意：当前脚本需要最终fp32模型权重的2倍通用RAM。

### ZeRO-3和Infinity细微差别

ZeRO-3与ZeRO-2非常不同，因为它具有参数分片功能。

ZeRO-Infinity进一步扩展了ZeRO-3，以支持NVMe内存和多项其他速度和可伸缩性改进。

尽管我们已经尽力使事情能够正常工作，而无需对您的模型进行任何特殊更改，但在某些情况下，您可能会发现需要以下信息。

#### 构建大型模型

DeepSpeed/ZeRO-3可以处理具有数万亿参数的模型，这些参数可能无法适应现有的RAM。在这种情况下，但也如果您希望初始化速度更快，请使用*deepspeed.zero.Init()*上下文管理器（也是函数装饰器）初始化模型，如下所示：

```py
from transformers import T5ForConditionalGeneration, T5Config
import deepspeed

with deepspeed.zero.Init():
    config = T5Config.from_pretrained("t5-small")
    model = T5ForConditionalGeneration(config)
```

正如您所看到的，这为您提供了一个随机初始化的模型。

如果要使用预训练模型，只要`is_deepspeed_zero3_enabled()`返回`True`，`model_class.from_pretrained`将激活此功能，当前情况下，这是由[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)对象设置的，如果传递的DeepSpeed配置文件包含ZeRO-3配置部分。因此，您必须在调用`from_pretrained`之前创建[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)对象**之前**。以下是可能的顺序示例：

```py
from transformers import AutoModel, Trainer, TrainingArguments

training_args = TrainingArguments(..., deepspeed=ds_config)
model = AutoModel.from_pretrained("t5-small")
trainer = Trainer(model=model, args=training_args, ...)
```

如果您正在使用官方示例脚本，并且您的命令行参数包括`--deepspeed ds_config.json`并启用了ZeRO-3配置，则一切都已经为您完成，因为示例脚本是这样编写的。

注意：如果模型的fp16权重无法适应单个GPU的内存，则必须使用此功能。

有关此方法和其他相关功能的详细信息，请参阅[构建大型模型](https://deepspeed.readthedocs.io/en/latest/zero3.html#constructing-massive-models)。

此外，当加载fp16预训练模型时，您将希望告诉`from_pretrained`使用`torch_dtype=torch.float16`。有关详细信息，请参见[from_pretrained-torch-dtype](#from_pretrained-torch-dtype)。

#### 收集参数

在多个GPU上的ZeRO-3中，除了当前执行层的参数外，没有单个GPU拥有所有参数。因此，如果您需要一次访问所有层的所有参数，有一种特定的方法可以做到。您很可能不需要它，但如果需要，请参阅[收集参数](https://deepspeed.readthedocs.io/en/latest/zero3.html#manual-parameter-coordination)。

然而，我们在几个地方内部使用它，一个例子是在`from_pretrained`中加载预训练模型权重时。我们一次加载一层，然后立即将其分区到所有参与的GPU上，因为对于非常大的模型，将其加载到一个GPU上然后分散到多个GPU上是不可能的，由于内存限制。

此外，在ZeRO-3下，如果您编写自己的代码并遇到看起来像模型参数权重的问题：

```py
tensor([1.0], device="cuda:0", dtype=torch.float16, requires_grad=True)
```

强调`tensor([1.])`，或者如果出现错误，指出参数大小为`1`，而不是某个更大的多维形状，这意味着参数被分区，您看到的是ZeRO-3占位符。

### ZeRO推理

ZeRO推理使用与ZeRO-3训练相同的配置。您只需要不需要优化器和调度程序部分。实际上，如果要与训练共享相同的配置文件，可以将这些部分保留在配置文件中。它们将被忽略。

否则，您只需要传递通常的[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)参数。例如：

```py
deepspeed --num_gpus=2 your_program.py <normal cl args> --do_eval --deepspeed ds_config.json
```

唯一重要的是您需要使用ZeRO-3配置，因为ZeRO-2对推理没有任何好处，因为只有ZeRO-3执行参数分片，而ZeRO-1执行梯度和优化器状态的分片。

以下是在使用所有可用GPU部署DeepSpeed时运行`run_translation.py`的示例：

```py
deepspeed examples/pytorch/translation/run_translation.py \
--deepspeed tests/deepspeed/ds_config_zero3.json \
--model_name_or_path t5-small --output_dir output_dir \
--do_eval --max_eval_samples 50 --warmup_steps 50  \
--max_source_length 128 --val_max_target_length 128 \
--overwrite_output_dir --per_device_eval_batch_size 4 \
--predict_with_generate --dataset_config "ro-en" --fp16 \
--source_lang en --target_lang ro --dataset_name wmt16 \
--source_prefix "translate English to Romanian: "
```

由于在推理中不需要额外大内存用于优化器状态和梯度，您应该能够在相同的硬件上适应更大的批次和/或序列长度。

此外，DeepSpeed目前正在开发一个名为Deepspeed-Inference的相关产品，它与ZeRO技术没有关系，而是使用张量并行性来扩展无法适应单个GPU的模型。这是一个正在进行的工作，一旦该产品完成，我们将提供集成。

### 内存要求

由于Deepspeed ZeRO可以将内存卸载到CPU（和NVMe），该框架提供了一些实用程序，允许您根据使用的GPU数量告诉需要多少CPU和GPU内存。

让我们估计在单个GPU上对“bigscience/T0_3B”进行微调所需的内存：

```py
$ python -c 'from transformers import AutoModel; \
from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \
model = AutoModel.from_pretrained("bigscience/T0_3B"); \
estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=1, num_nodes=1)'
[...]
Estimated memory needed for params, optim states and gradients for a:
HW: Setup with 1 node, 1 GPU per node.
SW: Model with 2783M total params, 65M largest layer params.
  per CPU  |  per GPU |   Options
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0
   62.23GB |   5.43GB | offload_param=none, offload_optimizer=cpu , zero_init=1
   62.23GB |   5.43GB | offload_param=none, offload_optimizer=cpu , zero_init=0
    0.37GB |  46.91GB | offload_param=none, offload_optimizer=none, zero_init=1
   15.56GB |  46.91GB | offload_param=none, offload_optimizer=none, zero_init=0
```

因此，您可以将其放在单个80GB GPU上，不使用CPU卸载，或者使用一个小型的8GB GPU，但是需要大约60GB的CPU内存。请记住，这只是参数、优化器状态和梯度的内存 - 您将需要更多内存用于cuda内核、激活和临时存储。

然后就是成本与速度的权衡。购买/租用较小的GPU（或较少的GPU，因为您可以使用Deepspeed ZeRO来使用多个GPU）。但这样会更慢，所以即使您不关心某件事情会多快完成，减速也会直接影响使用GPU的持续时间，从而增加成本。因此，请进行实验并比较哪种方法最好。

如果您有足够的GPU内存，请确保禁用CPU/NVMe卸载，因为这将使一切更快。

例如，让我们重复使用2个GPU：

```py
$ python -c 'from transformers import AutoModel; \
from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \
model = AutoModel.from_pretrained("bigscience/T0_3B"); \
estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=2, num_nodes=1)'
[...]
Estimated memory needed for params, optim states and gradients for a:
HW: Setup with 1 node, 2 GPUs per node.
SW: Model with 2783M total params, 65M largest layer params.
  per CPU  |  per GPU |   Options
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0
   62.23GB |   2.84GB | offload_param=none, offload_optimizer=cpu , zero_init=1
   62.23GB |   2.84GB | offload_param=none, offload_optimizer=cpu , zero_init=0
    0.74GB |  23.58GB | offload_param=none, offload_optimizer=none, zero_init=1
   31.11GB |  23.58GB | offload_param=none, offload_optimizer=none, zero_init=0

```

因此，您可能需要2个32GB或更高内存的GPU，而不需要将内存卸载到CPU。

有关完整信息，请参阅[memory estimators](https://deepspeed.readthedocs.io/en/latest/memory.html)。

### 提交问题

以下是如何提交问题，以便我们可以快速找到问题的根源并帮助您解除工作阻塞。

在您的报告中，请始终包括：

1.  在报告中提供完整的Deepspeed配置文件

1.  如果您使用的是[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)的命令行参数，或者如果您自己编写了Trainer设置，则使用[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)参数。请不要转储[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)，因为它有数十个与问题无关的条目。

1.  输出：

    ```py
    python -c 'import torch; print(f"torch: {torch.__version__}")'
    python -c 'import transformers; print(f"transformers: {transformers.__version__}")'
    python -c 'import deepspeed; print(f"deepspeed: {deepspeed.__version__}")'
    ```

1.  如果可能的话，请包含一个链接到一个Google Colab笔记本，我们可以用它来重现问题。您可以使用这个[notebook](https://github.com/stas00/porting/blob/master/transformers/deepspeed/DeepSpeed_on_colab_CLI.ipynb)作为起点。

1.  除非不可能，请始终使用我们可以使用的标准数据集，而不是自定义数据集。

1.  如果可能，请尝试使用现有的[examples](https://github.com/huggingface/transformers/tree/main/examples/pytorch)之一来重现问题。

需要考虑的事项：

+   Deepspeed通常不是问题的原因。

    一些提交的问题被证明与Deepspeed无关。也就是说，一旦从设置中移除了Deepspeed，问题仍然存在。

    因此，如果不是绝对明显是Deepspeed相关的问题，例如您可以看到有异常并且可以看到涉及Deepspeed模块，首先在没有Deepspeed的设置中重新测试您的设置。只有在问题仍然存在时才提到Deepspeed并提供所有必要的细节。

+   如果您明确知道问题出在DeepSpeed核心而不是集成部分，请直接向[Deepspeed](https://github.com/microsoft/DeepSpeed/) 提交问题。如果您不确定，请不要担心，任何一个问题跟踪器都可以，我们会在您发布后找出问题，并在需要时将您重定向到另一个问题跟踪器。

### 故障排除

#### 深度速度进程在启动时被终止，没有回溯

如果`deepspeed`进程在启动时被终止，没有回溯，通常意味着程序尝试分配比您的系统具有的CPU内存更多的内存，或者您的进程被允许分配的内存，而操作系统内核终止了该进程。这是因为您的配置文件很可能已经配置了`offload_optimizer`或`offload_param`或两者都配置为转移到`cpu`。如果您有NVMe，尝试将其转移到NVMe，如果您正在运行ZeRO-3。这是如何[估算特定模型所需内存量](https://deepspeed.readthedocs.io/en/latest/memory.html)的方法。

#### 训练和/或评估/预测损失为NaN

当一个以bf16混合精度模式预训练的模型尝试在fp16下使用时，通常会发生这种情况（无论是否使用混合精度）。大多数在TPU上训练的模型，通常是由Google发布的模型都属于这一类（例如，几乎所有基于t5的模型）。在这种情况下，解决方案是要么使用fp32，要么使用bf16，如果您的硬件支持的话（TPU、Ampere GPU或更新）。

另一个问题可能与使用fp16有关。当您配置此部分时：

```py
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    }
}
```

并且您在日志中看到Deepspeed报告`OVERFLOW!`如下：

```py
0%|                                                                                                                             | 0/189 [00:00<?, ?it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 262144
  1%|▌                                                                                                                    | 1/189 [00:00<01:26,  2.17it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072.0
  1%|█▏
 [...]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 14%|████████████████▌                                                                                                   | 27/189 [00:14<01:13,  2.21it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|█████████████████▏                                                                                                  | 28/189 [00:14<01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|█████████████████▊                                                                                                  | 29/189 [00:15<01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
[...]
```

这意味着Deepspeed损失缩放器无法找到一个缩放系数来克服损失溢出。

（此处的日志已经过处理，以便更易阅读。）

在这种情况下，通常需要提高`initial_scale_power`的值。将其设置为`"initial_scale_power": 32`通常会解决问题。

### 注

+   虽然DeepSpeed有一个可通过pip安装的PyPI软件包，但强烈建议从[源](https://github.com/microsoft/deepspeed#installation)安装，以最好地匹配您的硬件，并且如果您需要启用某些功能，比如1比特Adam，在pypi分发中是不可用的。

+   您不必使用[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)来使用🤗 Transformers的DeepSpeed - 您可以使用任何模型与您自己的训练器，并且您将根据[DeepSpeed集成说明](https://www.deepspeed.ai/getting-started/#writing-deepspeed-models)来调整后者。

## 非Trainer Deepspeed集成

[HfDeepSpeedConfig](/docs/transformers/v4.37.2/en/main_classes/deepspeed#transformers.integrations.HfDeepSpeedConfig) 用于将Deepspeed集成到🤗 Transformers核心功能中，当未使用[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)时。它唯一要做的就是处理Deepspeed ZeRO-3参数收集，并在`from_pretrained`调用期间自动将模型分割到多个GPU上。其他所有事情都需要您自己来做。

使用[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) 时，一切都会自动处理。

当不使用[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)时，为了有效部署DeepSpeed ZeRO-3，您必须在实例化模型之前实例化[HfDeepSpeedConfig](/docs/transformers/v4.37.2/en/main_classes/deepspeed#transformers.integrations.HfDeepSpeedConfig)对象，并保持该对象处于活动状态。

如果您正在使用Deepspeed ZeRO-1或ZeRO-2，则根本不需要使用`HfDeepSpeedConfig`。

例如，对于预训练模型：

```py
from transformers.integrations import HfDeepSpeedConfig
from transformers import AutoModel
import deepspeed

ds_config = {...}  # deepspeed config object or path to the file
# must run before instantiating the model to detect zero 3
dschf = HfDeepSpeedConfig(ds_config)  # keep this object alive
model = AutoModel.from_pretrained("gpt2")
engine = deepspeed.initialize(model=model, config_params=ds_config, ...)
```

或对于非预训练模型：

```py
from transformers.integrations import HfDeepSpeedConfig
from transformers import AutoModel, AutoConfig
import deepspeed

ds_config = {...}  # deepspeed config object or path to the file
# must run before instantiating the model to detect zero 3
dschf = HfDeepSpeedConfig(ds_config)  # keep this object alive
config = AutoConfig.from_pretrained("gpt2")
model = AutoModel.from_config(config)
engine = deepspeed.initialize(model=model, config_params=ds_config, ...)
```

请注意，如果您没有使用[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)集成，您将完全独立。基本上遵循[Deepspeed](https://www.deepspeed.ai/)网站上的文档。此外，您必须明确配置配置文件 - 不能使用`"auto"`值，而必须使用实际值。

## HfDeepSpeedConfig

### `class transformers.integrations.HfDeepSpeedConfig`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/integrations/deepspeed.py#L56)

```py
( config_file_or_dict )
```

参数

+   `config_file_or_dict`（`Union[str, Dict]`）— DeepSpeed配置文件或字典的路径。

此对象包含一个DeepSpeed配置字典，可以快速查询诸如零阶段之类的内容。

此对象的`weakref`存储在模块的全局变量中，以便能够从Trainer对象不可用的区域访问配置（例如`from_pretrained`和`_get_resized_embeddings`）。因此，在程序仍在运行时，这个对象保持活动是很重要的。

[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)使用`HfTrainerDeepSpeedConfig`子类。该子类具有将配置与[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)的值同步的逻辑，通过替换特殊占位符值：`"auto"`。如果没有这种特殊逻辑，DeepSpeed配置将不会以任何方式修改。

### 自定义DeepSpeed ZeRO推理

以下是一个示例，演示如何在无法将模型放入单个GPU的情况下进行DeepSpeed ZeRO推理，而不使用[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)。解决方案包括使用额外的GPU和/或将GPU内存转移到CPU内存。

这里需要理解的重要细微差别是，ZeRO的设计方式使您可以并行处理不同GPU上的不同输入。

示例有大量注释并且是自我记录的。

确保：

1.  如果您有足够的GPU内存，请禁用CPU卸载（因为它会减慢速度）

1.  如果您拥有Ampere或更新的GPU，请启用bf16以加快速度。如果您没有该硬件，可以启用fp16，只要不使用在bf16混合精度（例如大多数t5模型）中预训练的模型。这些通常在fp16中溢出，您将看到垃圾输出。

```py
#!/usr/bin/env python

# This script demonstrates how to use Deepspeed ZeRO in an inference mode when one can't fit a model
# into a single GPU
#
# 1\. Use 1 GPU with CPU offload
# 2\. Or use multiple GPUs instead
#
# First you need to install deepspeed: pip install deepspeed
#
# Here we use a 3B "bigscience/T0_3B" model which needs about 15GB GPU RAM - so 1 largish or 2
# small GPUs can handle it. or 1 small GPU and a lot of CPU memory.
#
# To use a larger model like "bigscience/T0" which needs about 50GB, unless you have an 80GB GPU -
# you will need 2-4 gpus. And then you can adapt the script to handle more gpus if you want to
# process multiple inputs at once.
#
# The provided deepspeed config also activates CPU memory offloading, so chances are that if you
# have a lot of available CPU memory and you don't mind a slowdown you should be able to load a
# model that doesn't normally fit into a single GPU. If you have enough GPU memory the program will
# run faster if you don't want offload to CPU - so disable that section then.
#
# To deploy on 1 gpu:
#
# deepspeed --num_gpus 1 t0.py
# or:
# python -m torch.distributed.run --nproc_per_node=1 t0.py
#
# To deploy on 2 gpus:
#
# deepspeed --num_gpus 2 t0.py
# or:
# python -m torch.distributed.run --nproc_per_node=2 t0.py

from transformers import AutoTokenizer, AutoConfig, AutoModelForSeq2SeqLM
from transformers.integrations import HfDeepSpeedConfig
import deepspeed
import os
import torch

os.environ["TOKENIZERS_PARALLELISM"] = "false"  # To avoid warnings about parallelism in tokenizers

# distributed setup
local_rank = int(os.getenv("LOCAL_RANK", "0"))
world_size = int(os.getenv("WORLD_SIZE", "1"))
torch.cuda.set_device(local_rank)
deepspeed.init_distributed()

model_name = "bigscience/T0_3B"

config = AutoConfig.from_pretrained(model_name)
model_hidden_size = config.d_model

# batch size has to be divisible by world_size, but can be bigger than world_size
train_batch_size = 1 * world_size

# ds_config notes
#
# - enable bf16 if you use Ampere or higher GPU - this will run in mixed precision and will be
# faster.
#
# - for older GPUs you can enable fp16, but it'll only work for non-bf16 pretrained models - e.g.
# all official t5 models are bf16-pretrained
#
# - set offload_param.device to "none" or completely remove the `offload_param` section if you don't
# - want CPU offload
#
# - if using `offload_param` you can manually finetune stage3_param_persistence_threshold to control
# - which params should remain on gpus - the larger the value the smaller the offload size
#
# For indepth info on Deepspeed config see
# https://huggingface.co/docs/transformers/main/main_classes/deepspeed

# keeping the same format as json for consistency, except it uses lower case for true/false
# fmt: off
ds_config = {
    "fp16": {
        "enabled": False
    },
    "bf16": {
        "enabled": False
    },
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu",
            "pin_memory": True
        },
        "overlap_comm": True,
        "contiguous_gradients": True,
        "reduce_bucket_size": model_hidden_size * model_hidden_size,
        "stage3_prefetch_bucket_size": 0.9 * model_hidden_size * model_hidden_size,
        "stage3_param_persistence_threshold": 10 * model_hidden_size
    },
    "steps_per_print": 2000,
    "train_batch_size": train_batch_size,
    "train_micro_batch_size_per_gpu": 1,
    "wall_clock_breakdown": False
}
# fmt: on

# next line instructs transformers to partition the model directly over multiple gpus using
# deepspeed.zero.Init when model's `from_pretrained` method is called.
#
# **it has to be run before loading the model AutoModelForSeq2SeqLM.from_pretrained(model_name)**
#
# otherwise the model will first be loaded normally and only partitioned at forward time which is
# less efficient and when there is little CPU RAM may fail
dschf = HfDeepSpeedConfig(ds_config)  # keep this object alive

# now a model can be loaded.
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# initialise Deepspeed ZeRO and store only the engine object
ds_engine = deepspeed.initialize(model=model, config_params=ds_config)[0]
ds_engine.module.eval()  # inference

# Deepspeed ZeRO can process unrelated inputs on each GPU. So for 2 gpus you process 2 inputs at once.
# If you use more GPUs adjust for more.
# And of course if you have just one input to process you then need to pass the same string to both gpus
# If you use only one GPU, then you will have only rank 0.
rank = torch.distributed.get_rank()
if rank == 0:
    text_in = "Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy"
elif rank == 1:
    text_in = "Is this review positive or negative? Review: this is the worst restaurant ever"

tokenizer = AutoTokenizer.from_pretrained(model_name)
inputs = tokenizer.encode(text_in, return_tensors="pt").to(device=local_rank)
with torch.no_grad():
    outputs = ds_engine.module.generate(inputs, synced_gpus=True)
text_out = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(f"rank{rank}:\n   in={text_in}\n  out={text_out}")
```

让我们将其保存为`t0.py`并运行：

```py
$ deepspeed --num_gpus 2 t0.py
rank0:
   in=Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy
  out=Positive
rank1:
   in=Is this review positive or negative? Review: this is the worst restaurant ever
  out=negative
```

这是一个非常基本的示例，您将希望根据自己的需求进行调整。

### 生成细微差别

使用多个GPU与ZeRO Stage-3一起使用时，必须通过调用`generate(..., synced_gpus=True)`来同步GPU。如果不这样做，如果一个GPU在其他GPU之前完成生成，整个系统将挂起，因为其他GPU将无法接收停止生成的GPU的权重片段。

从`transformers>=4.28`开始，如果未明确指定`synced_gpus`，则在检测到这些条件时，它将自动设置为`True`。但是，如果需要，仍然可以覆盖`synced_gpus`的值。

## 测试Deepspeed集成

如果您提交涉及DeepSpeed集成的PR，请注意我们的CircleCI PR CI设置没有GPU，因此我们只在另一个CI每晚运行需要GPU的测试。因此，如果您在PR中收到绿色CI报告，这并不意味着DeepSpeed测试通过。

要运行DeepSpeed测试，请至少运行：

```py
RUN_SLOW=1 pytest tests/deepspeed/test_deepspeed.py
```

如果更改了建模或pytorch示例代码中的任何内容，则还要运行模型动物园测试。以下将运行所有DeepSpeed测试：

```py
RUN_SLOW=1 pytest tests/deepspeed
```

## 主DeepSpeed资源

+   [项目的github](https://github.com/microsoft/deepspeed)

+   [使用文档](https://www.deepspeed.ai/getting-started/)

+   [API文档](https://deepspeed.readthedocs.io/en/latest/index.html)

+   [博客文章](https://www.microsoft.com/en-us/research/search/?q=deepspeed)

论文：

+   [ZeRO：面向训练万亿参数模型的内存优化](https://arxiv.org/abs/1910.02054)

+   [ZeRO-Offload: 民主化十亿规模的模型训练](https://arxiv.org/abs/2101.06840)

+   [ZeRO-Infinity: 打破 GPU 内存壁，实现极端规模的深度学习](https://arxiv.org/abs/2104.07857)

最后，请记住，HuggingFace [Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer) 只集成了 DeepSpeed，因此如果您在使用 DeepSpeed 方面遇到任何问题或疑问，请在 [DeepSpeed GitHub](https://github.com/microsoft/DeepSpeed/issues) 上提交问题。
