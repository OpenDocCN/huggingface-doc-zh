- en: Autoformer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Autoformer
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/autoformer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/autoformer)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/autoformer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/autoformer)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: 'The Autoformer model was proposed in [Autoformer: Decomposition Transformers
    with Auto-Correlation for Long-Term Series Forecasting](https://arxiv.org/abs/2106.13008)
    by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'Autoformeræ¨¡å‹æ˜¯ç”±Haixu Wuï¼ŒJiehui Xuï¼ŒJianmin Wangï¼ŒMingsheng Longåœ¨[Autoformer: Decomposition
    Transformers with Auto-Correlation for Long-Term Series Forecasting](https://arxiv.org/abs/2106.13008)ä¸­æå‡ºçš„ã€‚'
- en: This model augments the Transformer as a deep decomposition architecture, which
    can progressively decompose the trend and seasonal components during the forecasting
    process.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹å°†Transformerä½œä¸ºæ·±åº¦åˆ†è§£æ¶æ„ï¼Œå¯ä»¥åœ¨é¢„æµ‹è¿‡ç¨‹ä¸­é€æ­¥åˆ†è§£è¶‹åŠ¿å’Œå­£èŠ‚æ€§ç»„ä»¶ã€‚
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š
- en: '*Extending the forecasting time is a critical demand for real applications,
    such as extreme weather early warning and long-term energy consumption planning.
    This paper studies the long-term forecasting problem of time series. Prior Transformer-based
    models adopt various self-attention mechanisms to discover the long-range dependencies.
    However, intricate temporal patterns of the long-term future prohibit the model
    from finding reliable dependencies. Also, Transformers have to adopt the sparse
    versions of point-wise self-attentions for long series efficiency, resulting in
    the information utilization bottleneck. Going beyond Transformers, we design Autoformer
    as a novel decomposition architecture with an Auto-Correlation mechanism. We break
    with the pre-processing convention of series decomposition and renovate it as
    a basic inner block of deep models. This design empowers Autoformer with progressive
    decomposition capacities for complex time series. Further, inspired by the stochastic
    process theory, we design the Auto-Correlation mechanism based on the series periodicity,
    which conducts the dependencies discovery and representation aggregation at the
    sub-series level. Auto-Correlation outperforms self-attention in both efficiency
    and accuracy. In long-term forecasting, Autoformer yields state-of-the-art accuracy,
    with a 38% relative improvement on six benchmarks, covering five practical applications:
    energy, traffic, economics, weather and disease.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*å»¶é•¿é¢„æµ‹æ—¶é—´æ˜¯çœŸå®åº”ç”¨çš„å…³é”®éœ€æ±‚ï¼Œä¾‹å¦‚æç«¯å¤©æ°”é¢„è­¦å’Œé•¿æœŸèƒ½æºæ¶ˆè€—è§„åˆ’ã€‚æœ¬æ–‡ç ”ç©¶äº†æ—¶é—´åºåˆ—çš„é•¿æœŸé¢„æµ‹é—®é¢˜ã€‚ä¹‹å‰åŸºäºTransformerçš„æ¨¡å‹é‡‡ç”¨å„ç§è‡ªæ³¨æ„æœºåˆ¶æ¥å‘ç°é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚ç„¶è€Œï¼Œé•¿æœŸæœªæ¥çš„å¤æ‚æ—¶é—´æ¨¡å¼é˜»ç¢äº†æ¨¡å‹æ‰¾åˆ°å¯é çš„ä¾èµ–å…³ç³»ã€‚æ­¤å¤–ï¼Œä¸ºäº†é•¿åºåˆ—çš„æ•ˆç‡ï¼ŒTransformerå¿…é¡»é‡‡ç”¨ç¨€ç–ç‰ˆæœ¬çš„ç‚¹å¯¹ç‚¹è‡ªæ³¨æ„åŠ›ï¼Œå¯¼è‡´ä¿¡æ¯åˆ©ç”¨ç“¶é¢ˆã€‚è¶…è¶ŠTransformerï¼Œæˆ‘ä»¬è®¾è®¡Autoformerä½œä¸ºä¸€ç§å…·æœ‰è‡ªç›¸å…³æœºåˆ¶çš„æ–°å‹åˆ†è§£æ¶æ„ã€‚æˆ‘ä»¬æ‰“ç ´äº†ç³»åˆ—åˆ†è§£çš„é¢„å¤„ç†æƒ¯ä¾‹ï¼Œå¹¶å°†å…¶æ”¹é€ ä¸ºæ·±åº¦æ¨¡å‹çš„åŸºæœ¬å†…éƒ¨å—ã€‚è¿™ç§è®¾è®¡èµ‹äºˆAutoformerå¯¹å¤æ‚æ—¶é—´åºåˆ—çš„æ¸è¿›åˆ†è§£èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå—éšæœºè¿‡ç¨‹ç†è®ºå¯å‘ï¼Œæˆ‘ä»¬è®¾è®¡äº†åŸºäºç³»åˆ—å‘¨æœŸæ€§çš„è‡ªç›¸å…³æœºåˆ¶ï¼Œå®ƒåœ¨å­ç³»åˆ—çº§åˆ«è¿›è¡Œä¾èµ–å…³ç³»å‘ç°å’Œè¡¨ç¤ºèšåˆã€‚è‡ªç›¸å…³åœ¨æ•ˆç‡å’Œå‡†ç¡®æ€§æ–¹é¢ä¼˜äºè‡ªæ³¨æ„åŠ›ã€‚åœ¨é•¿æœŸé¢„æµ‹ä¸­ï¼ŒAutoformerå–å¾—äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œåœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸­ç›¸å¯¹æé«˜äº†38ï¼…ï¼Œæ¶µç›–äº†äº”ä¸ªå®é™…åº”ç”¨ï¼šèƒ½æºï¼Œäº¤é€šï¼Œç»æµï¼Œå¤©æ°”å’Œç–¾ç—…ã€‚*'
- en: This model was contributed by [elisim](https://huggingface.co/elisim) and [kashif](https://huggingface.co/kashif).
    The original code can be found [here](https://github.com/thuml/Autoformer).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç”±[elisim](https://huggingface.co/elisim)å’Œ[kashif](https://huggingface.co/kashif)è´¡çŒ®ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[æ­¤å¤„](https://github.com/thuml/Autoformer)æ‰¾åˆ°ã€‚
- en: Resources
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èµ„æº
- en: A list of official Hugging Face and community (indicated by ğŸŒ) resources to
    help you get started. If youâ€™re interested in submitting a resource to be included
    here, please feel free to open a Pull Request and weâ€™ll review it! The resource
    should ideally demonstrate something new instead of duplicating an existing resource.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç³»åˆ—å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºï¼Œå¯å¸®åŠ©æ‚¨å…¥é—¨ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€Pull Requestï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥ç†æƒ³åœ°å±•ç¤ºä¸€äº›æ–°ä¸œè¥¿ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚
- en: 'Check out the Autoformer blog-post in HuggingFace blog: [Yes, Transformers
    are Effective for Time Series Forecasting (+ Autoformer)](https://huggingface.co/blog/autoformer)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨HuggingFaceåšå®¢ä¸­æŸ¥çœ‹Autoformeråšæ–‡ï¼š[æ˜¯çš„ï¼ŒTransformerså¯¹æ—¶é—´åºåˆ—é¢„æµ‹æœ‰æ•ˆï¼ˆ+ Autoformerï¼‰](https://huggingface.co/blog/autoformer)
- en: AutoformerConfig
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoformerConfig
- en: '### `class transformers.AutoformerConfig`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoformerConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/configuration_autoformer.py#L30)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/configuration_autoformer.py#L30)'
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prediction_length` (`int`) â€” The prediction length for the decoder. In other
    words, the prediction horizon of the model.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_length`ï¼ˆ`int`ï¼‰â€” è§£ç å™¨çš„é¢„æµ‹é•¿åº¦ã€‚æ¢å¥è¯è¯´ï¼Œæ¨¡å‹çš„é¢„æµ‹æ—¶é—´èŒƒå›´ã€‚'
- en: '`context_length` (`int`, *optional*, defaults to `prediction_length`) â€” The
    context length for the encoder. If unset, the context length will be the same
    as the `prediction_length`.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`context_length`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`prediction_length`ï¼‰â€” ç¼–ç å™¨çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚å¦‚æœæœªè®¾ç½®ï¼Œä¸Šä¸‹æ–‡é•¿åº¦å°†ä¸`prediction_length`ç›¸åŒã€‚'
- en: '`distribution_output` (`string`, *optional*, defaults to `"student_t"`) â€” The
    distribution emission head for the model. Could be either â€œstudent_tâ€, â€œnormalâ€
    or â€œnegative_binomialâ€.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distribution_output`ï¼ˆ`string`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"student_t"`ï¼‰â€” æ¨¡å‹çš„åˆ†å¸ƒå‘å°„å¤´ã€‚å¯ä»¥æ˜¯â€œstudent_tâ€ï¼Œâ€œnormalâ€æˆ–â€œnegative_binomialâ€ã€‚'
- en: '`loss` (`string`, *optional*, defaults to `"nll"`) â€” The loss function for
    the model corresponding to the `distribution_output` head. For parametric distributions
    it is the negative log likelihood (nll) - which currently is the only supported
    one.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`ï¼ˆ`string`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"nll"`ï¼‰â€” ä¸`distribution_output`å¤´éƒ¨å¯¹åº”çš„æ¨¡å‹çš„æŸå¤±å‡½æ•°ã€‚å¯¹äºå‚æ•°åˆ†å¸ƒï¼Œå®ƒæ˜¯è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆnllï¼‰-
    ç›®å‰æ˜¯å”¯ä¸€æ”¯æŒçš„ã€‚'
- en: '`input_size` (`int`, *optional*, defaults to 1) â€” The size of the target variable
    which by default is 1 for univariate targets. Would be > 1 in case of multivariate
    targets.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º1ï¼‰â€” ç›®æ ‡å˜é‡çš„å¤§å°ï¼Œé»˜è®¤æƒ…å†µä¸‹å¯¹äºå•å˜é‡ç›®æ ‡ä¸º1ã€‚åœ¨å¤šå˜é‡ç›®æ ‡çš„æƒ…å†µä¸‹ä¼šå¤§äº1ã€‚'
- en: '`lags_sequence` (`list[int]`, *optional*, defaults to `[1, 2, 3, 4, 5, 6, 7]`)
    â€” The lags of the input time series as covariates often dictated by the frequency.
    Default is `[1, 2, 3, 4, 5, 6, 7]`.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lags_sequence` (`list[int]`, *optional*, defaults to `[1, 2, 3, 4, 5, 6, 7]`)
    â€” è¾“å…¥æ—¶é—´åºåˆ—çš„æ»åä½œä¸ºåå˜é‡ï¼Œé€šå¸¸ç”±é¢‘ç‡å†³å®šã€‚é»˜è®¤ä¸º`[1, 2, 3, 4, 5, 6, 7]`ã€‚'
- en: '`scaling` (`bool`, *optional* defaults to `True`) â€” Whether to scale the input
    targets.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scaling` (`bool`, *optional* defaults to `True`) â€” æ˜¯å¦å¯¹è¾“å…¥ç›®æ ‡è¿›è¡Œç¼©æ”¾ã€‚'
- en: '`num_time_features` (`int`, *optional*, defaults to 0) â€” The number of time
    features in the input time series.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_time_features` (`int`, *optional*, defaults to 0) â€” è¾“å…¥æ—¶é—´åºåˆ—ä¸­çš„æ—¶é—´ç‰¹å¾æ•°é‡ã€‚'
- en: '`num_dynamic_real_features` (`int`, *optional*, defaults to 0) â€” The number
    of dynamic real valued features.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_dynamic_real_features` (`int`, *optional*, defaults to 0) â€” åŠ¨æ€å®å€¼ç‰¹å¾çš„æ•°é‡ã€‚'
- en: '`num_static_categorical_features` (`int`, *optional*, defaults to 0) â€” The
    number of static categorical features.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_static_categorical_features` (`int`, *optional*, defaults to 0) â€” é™æ€åˆ†ç±»ç‰¹å¾çš„æ•°é‡ã€‚'
- en: '`num_static_real_features` (`int`, *optional*, defaults to 0) â€” The number
    of static real valued features.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_static_real_features` (`int`, *optional*, defaults to 0) â€” é™æ€å®å€¼ç‰¹å¾çš„æ•°é‡ã€‚'
- en: '`cardinality` (`list[int]`, *optional*) â€” The cardinality (number of different
    values) for each of the static categorical features. Should be a list of integers,
    having the same length as `num_static_categorical_features`. Cannot be `None`
    if `num_static_categorical_features` is > 0.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cardinality` (`list[int]`, *optional*) â€” æ¯ä¸ªé™æ€åˆ†ç±»ç‰¹å¾çš„åŸºæ•°ï¼ˆä¸åŒå€¼çš„æ•°é‡ï¼‰ã€‚åº”è¯¥æ˜¯ä¸€ä¸ªæ•´æ•°åˆ—è¡¨ï¼Œé•¿åº¦ä¸`num_static_categorical_features`ç›¸åŒã€‚å¦‚æœ`num_static_categorical_features`å¤§äº0ï¼Œåˆ™ä¸èƒ½ä¸º`None`ã€‚'
- en: '`embedding_dimension` (`list[int]`, *optional*) â€” The dimension of the embedding
    for each of the static categorical features. Should be a list of integers, having
    the same length as `num_static_categorical_features`. Cannot be `None` if `num_static_categorical_features`
    is > 0.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_dimension` (`list[int]`, *optional*) â€” æ¯ä¸ªé™æ€åˆ†ç±»ç‰¹å¾çš„åµŒå…¥ç»´åº¦ã€‚åº”è¯¥æ˜¯ä¸€ä¸ªæ•´æ•°åˆ—è¡¨ï¼Œé•¿åº¦ä¸`num_static_categorical_features`ç›¸åŒã€‚å¦‚æœ`num_static_categorical_features`å¤§äº0ï¼Œåˆ™ä¸èƒ½ä¸º`None`ã€‚'
- en: '`d_model` (`int`, *optional*, defaults to 64) â€” Dimensionality of the transformer
    layers.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_model` (`int`, *optional*, defaults to 64) â€” Transformerå±‚çš„ç»´åº¦ã€‚'
- en: '`encoder_layers` (`int`, *optional*, defaults to 2) â€” Number of encoder layers.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layers` (`int`, *optional*, defaults to 2) â€” ç¼–ç å™¨å±‚çš„æ•°é‡ã€‚'
- en: '`decoder_layers` (`int`, *optional*, defaults to 2) â€” Number of decoder layers.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers` (`int`, *optional*, defaults to 2) â€” è§£ç å™¨å±‚çš„æ•°é‡ã€‚'
- en: '`encoder_attention_heads` (`int`, *optional*, defaults to 2) â€” Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_heads` (`int`, *optional*, defaults to 2) â€” Transformerç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚'
- en: '`decoder_attention_heads` (`int`, *optional*, defaults to 2) â€” Number of attention
    heads for each attention layer in the Transformer decoder.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_heads` (`int`, *optional*, defaults to 2) â€” Transformerè§£ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚'
- en: '`encoder_ffn_dim` (`int`, *optional*, defaults to 32) â€” Dimension of the â€œintermediateâ€
    (often named feed-forward) layer in encoder.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_ffn_dim` (`int`, *optional*, defaults to 32) â€” ç¼–ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚'
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 32) â€” Dimension of the â€œintermediateâ€
    (often named feed-forward) layer in decoder.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ffn_dim` (`int`, *optional*, defaults to 32) â€” è§£ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚'
- en: '`activation_function` (`str` or `function`, *optional*, defaults to `"gelu"`)
    â€” The non-linear activation function (function or string) in the encoder and decoder.
    If string, `"gelu"` and `"relu"` are supported.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_function` (`str` or `function`, *optional*, defaults to `"gelu"`)
    â€” ç¼–ç å™¨å’Œè§£ç å™¨ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ`"gelu"`å’Œ`"relu"`ã€‚'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    for all fully connected layers in the encoder, and decoder.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, defaults to 0.1) â€” ç¼–ç å™¨å’Œè§£ç å™¨ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„ä¸¢å¼ƒæ¦‚ç‡ã€‚'
- en: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    for the attention and fully connected layers for each encoder layer.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.1) â€” æ¯ä¸ªç¼–ç å™¨å±‚çš„æ³¨æ„åŠ›å’Œå…¨è¿æ¥å±‚çš„ä¸¢å¼ƒæ¦‚ç‡ã€‚'
- en: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    for the attention and fully connected layers for each decoder layer.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.1) â€” æ¯ä¸ªè§£ç å™¨å±‚çš„æ³¨æ„åŠ›å’Œå…¨è¿æ¥å±‚çš„ä¸¢å¼ƒæ¦‚ç‡ã€‚'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    for the attention probabilities.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout` (`float`, *optional*, defaults to 0.1) â€” æ³¨æ„åŠ›æ¦‚ç‡çš„ä¸¢å¼ƒæ¦‚ç‡ã€‚'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.1) â€” The dropout probability
    used between the two layers of the feed-forward networks.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout` (`float`, *optional*, defaults to 0.1) â€” åœ¨å‰é¦ˆç½‘ç»œçš„ä¸¤å±‚ä¹‹é—´ä½¿ç”¨çš„ä¸¢å¼ƒæ¦‚ç‡ã€‚'
- en: '`num_parallel_samples` (`int`, *optional*, defaults to 100) â€” The number of
    samples to generate in parallel for each time step of inference.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_parallel_samples` (`int`, *optional*, defaults to 100) â€” æ¯ä¸ªæ¨æ–­æ—¶é—´æ­¥ç”Ÿæˆçš„å¹¶è¡Œæ ·æœ¬æ•°é‡ã€‚'
- en: '`init_std` (`float`, *optional*, defaults to 0.02) â€” The standard deviation
    of the truncated normal weight initialization distribution.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_std` (`float`, *optional*, defaults to 0.02) â€” æˆªæ–­æ­£æ€æƒé‡åˆå§‹åŒ–åˆ†å¸ƒçš„æ ‡å‡†å·®ã€‚'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” Whether to use the past
    key/values attentions (if applicable to the model) to speed up decoding.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦ä½¿ç”¨è¿‡å»çš„é”®/å€¼æ³¨æ„åŠ›ï¼ˆå¦‚æœé€‚ç”¨äºæ¨¡å‹ï¼‰ä»¥åŠ é€Ÿè§£ç ã€‚'
- en: '`label_length` (`int`, *optional*, defaults to 10) â€” Start token length of
    the Autoformer decoder, which is used for direct multi-step prediction (i.e. non-autoregressive
    generation).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_length` (`int`, *optional*, defaults to 10) â€” Autoformerè§£ç å™¨çš„èµ·å§‹æ ‡è®°é•¿åº¦ï¼Œç”¨äºç›´æ¥å¤šæ­¥é¢„æµ‹ï¼ˆå³éè‡ªå›å½’ç”Ÿæˆï¼‰ã€‚'
- en: '`moving_average` (`int`, defaults to 25) â€” The window size of the moving average.
    In practice, itâ€™s the kernel size in AvgPool1d of the Decomposition Layer.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`moving_average` (`int`, defaults to 25) â€” ç§»åŠ¨å¹³å‡çš„çª—å£å¤§å°ã€‚åœ¨å®è·µä¸­ï¼Œå®ƒæ˜¯åˆ†è§£å±‚çš„AvgPool1dä¸­çš„æ ¸å¤§å°ã€‚'
- en: '`autocorrelation_factor` (`int`, defaults to 3) â€” â€œAttentionâ€ (i.e. AutoCorrelation
    mechanism) factor which is used to find top k autocorrelations delays. Itâ€™s recommended
    in the paper to set it to a number between 1 and 5.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autocorrelation_factor` (`int`, defaults to 3) â€” â€œæ³¨æ„åŠ›â€ï¼ˆå³è‡ªç›¸å…³æœºåˆ¶ï¼‰å› å­ï¼Œç”¨äºæ‰¾åˆ°å‰kä¸ªè‡ªç›¸å…³å»¶è¿Ÿã€‚å»ºè®®åœ¨è®ºæ–‡ä¸­å°†å…¶è®¾ç½®ä¸º1åˆ°5ä¹‹é—´çš„æ•°å­—ã€‚'
- en: This is the configuration class to store the configuration of an [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel).
    It is used to instantiate an Autoformer model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the Autoformer [huggingface/autoformer-tourism-monthly](https://huggingface.co/huggingface/autoformer-tourism-monthly)
    architecture.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç”¨äºå­˜å‚¨[AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel)é…ç½®çš„é…ç½®ç±»ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–Autoformeræ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äºAutoformer
    [huggingface/autoformer-tourism-monthly](https://huggingface.co/huggingface/autoformer-tourism-monthly)æ¶æ„çš„é…ç½®ã€‚
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: AutoformerModel
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoformerModel
- en: '### `class transformers.AutoformerModel`'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoformerModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/modeling_autoformer.py#L1429)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/modeling_autoformer.py#L1429)'
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)ï¼‰â€”
    æ¨¡å‹çš„æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare Autoformer Model outputting raw hidden-states without any specific
    head on top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸Autoformeræ¨¡å‹è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹è¿˜æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚
- en: '#### `forward`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/modeling_autoformer.py#L1607)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/modeling_autoformer.py#L1607)'
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`past_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    â€” Past values of the time series, that serve as context in order to predict the
    future. These values may contain lags, i.e. additional values from the past which
    are added in order to serve as â€œextra contextâ€. The `past_values` is what the
    Transformer encoder gets as input (with optional additional features, such as
    `static_categorical_features`, `static_real_features`, `past_time_features`).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    â€” æ—¶é—´åºåˆ—çš„è¿‡å»å€¼ï¼Œç”¨ä½œä¸Šä¸‹æ–‡ä»¥é¢„æµ‹æœªæ¥ã€‚è¿™äº›å€¼å¯èƒ½åŒ…å«æ»åï¼Œå³è¿‡å»çš„é™„åŠ å€¼ï¼Œè¿™äº›å€¼è¢«æ·»åŠ ä»¥å……å½“â€œé¢å¤–ä¸Šä¸‹æ–‡â€ã€‚`past_values` æ˜¯Transformerç¼–ç å™¨æ¥æ”¶çš„è¾“å…¥ï¼ˆè¿˜å¯ä»¥åŒ…æ‹¬å¯é€‰çš„å…¶ä»–ç‰¹å¾ï¼Œå¦‚`static_categorical_features`ã€`static_real_features`ã€`past_time_features`ï¼‰ã€‚'
- en: The sequence length here is equal to `context_length` + `max(config.lags_sequence)`.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„åºåˆ—é•¿åº¦ç­‰äº`context_length` + `max(config.lags_sequence)`ã€‚
- en: Missing values need to be replaced with zeros.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼ºå¤±å€¼éœ€è¦ç”¨é›¶æ›¿æ¢ã€‚
- en: '`past_time_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_features)`, *optional*) â€” Optional time features, which the model internally
    will add to `past_values`. These could be things like â€œmonth of yearâ€, â€œday of
    the monthâ€, etc. encoded as vectors (for instance as Fourier features). These
    could also be so-called â€œageâ€ features, which basically help the model know â€œat
    which point in lifeâ€ a time-series is. Age features have small values for distant
    past time steps and increase monotonically the more we approach the current time
    step.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_time_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_features)`, *å¯é€‰*) â€” å¯é€‰çš„æ—¶é—´ç‰¹å¾ï¼Œæ¨¡å‹å†…éƒ¨å°†æ·»åŠ åˆ°`past_values`ä¸­ã€‚è¿™äº›å¯èƒ½æ˜¯è¯¸å¦‚â€œå¹´ä»½ä¸­çš„æœˆä»½â€ã€â€œæœˆä»½ä¸­çš„æ—¥æœŸâ€ç­‰ç¼–ç ä¸ºå‘é‡ï¼ˆä¾‹å¦‚ä½œä¸ºå‚…ç«‹å¶ç‰¹å¾ï¼‰çš„å†…å®¹ã€‚è¿™äº›ä¹Ÿå¯ä»¥æ˜¯æ‰€è°“çš„â€œå¹´é¾„â€ç‰¹å¾ï¼ŒåŸºæœ¬ä¸Šå¸®åŠ©æ¨¡å‹çŸ¥é“æ—¶é—´åºåˆ—å¤„äºâ€œç”Ÿå‘½ä¸­çš„å“ªä¸ªé˜¶æ®µâ€ã€‚å¹´é¾„ç‰¹å¾å¯¹äºè¿œå¤„çš„è¿‡å»æ—¶é—´æ­¥å…·æœ‰è¾ƒå°çš„å€¼ï¼Œå¹¶ä¸”éšç€æˆ‘ä»¬æ¥è¿‘å½“å‰æ—¶é—´æ­¥è€Œå•è°ƒå¢åŠ ã€‚'
- en: These features serve as the â€œpositional encodingsâ€ of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰¹å¾å……å½“è¾“å…¥çš„â€œä½ç½®ç¼–ç â€ã€‚å› æ­¤ï¼Œä¸BERTè¿™æ ·çš„æ¨¡å‹ä¸åŒï¼ŒBERTçš„ä½ç½®ç¼–ç æ˜¯ä»å¤´å¼€å§‹å†…éƒ¨ä½œä¸ºæ¨¡å‹çš„å‚æ•°å­¦ä¹ çš„ï¼Œæ—¶é—´åºåˆ—Transformeréœ€è¦æä¾›é¢å¤–çš„æ—¶é—´ç‰¹å¾ã€‚
- en: The Autoformer only learns additional embeddings for `static_categorical_features`.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Autoformerä»…ä¸º`static_categorical_features`å­¦ä¹ é¢å¤–çš„åµŒå…¥ã€‚
- en: '`past_observed_mask` (`torch.BoolTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Boolean mask to indicate which `past_values` were observed and which
    were missing. Mask values selected in `[0, 1]`:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_observed_mask` (`torch.BoolTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” å¸ƒå°”æ©ç ï¼ŒæŒ‡ç¤ºå“ªäº› `past_values` è¢«è§‚å¯Ÿåˆ°ï¼Œå“ªäº›æ˜¯ç¼ºå¤±çš„ã€‚æ©ç å€¼é€‰åœ¨ `[0, 1]` ä¹‹é—´ï¼š'
- en: 1 for values that are `observed`,
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå€¼ä¸º `observed`,
- en: 0 for values that are `missing` (i.e. NaNs that were replaced by zeros).
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå€¼ä¸º `missing`ï¼ˆå³è¢«é›¶æ›¿æ¢çš„ NaNï¼‰ã€‚
- en: '`static_categorical_features` (`torch.LongTensor` of shape `(batch_size, number
    of static categorical features)`, *optional*) â€” Optional static categorical features
    for which the model will learn an embedding, which it will add to the values of
    the time series.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_categorical_features` (`torch.LongTensor` of shape `(batch_size, number
    of static categorical features)`, *optional*) â€” æ¨¡å‹å°†å­¦ä¹ çš„å¯é€‰é™æ€åˆ†ç±»ç‰¹å¾çš„åµŒå…¥ï¼Œå°†å…¶æ·»åŠ åˆ°æ—¶é—´åºåˆ—çš„å€¼ä¸­ã€‚'
- en: Static categorical features are features which have the same value for all time
    steps (static over time).
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€åˆ†ç±»ç‰¹å¾æ˜¯æ‰€æœ‰æ—¶é—´æ­¥é•¿å…·æœ‰ç›¸åŒå€¼çš„ç‰¹å¾ï¼ˆéšæ—¶é—´ä¿æŒä¸å˜ï¼‰ã€‚
- en: A typical example of a static categorical feature is a time series ID.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€åˆ†ç±»ç‰¹å¾çš„å…¸å‹ç¤ºä¾‹æ˜¯æ—¶é—´åºåˆ— IDã€‚
- en: '`static_real_features` (`torch.FloatTensor` of shape `(batch_size, number of
    static real features)`, *optional*) â€” Optional static real features which the
    model will add to the values of the time series.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_real_features` (`torch.FloatTensor` of shape `(batch_size, number of
    static real features)`, *optional*) â€” å¯é€‰çš„é™æ€å®æ•°ç‰¹å¾ï¼Œæ¨¡å‹å°†å°†å…¶æ·»åŠ åˆ°æ—¶é—´åºåˆ—çš„å€¼ä¸­ã€‚'
- en: Static real features are features which have the same value for all time steps
    (static over time).
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€å®æ•°ç‰¹å¾æ˜¯æ‰€æœ‰æ—¶é—´æ­¥é•¿å…·æœ‰ç›¸åŒå€¼çš„ç‰¹å¾ï¼ˆéšæ—¶é—´ä¿æŒä¸å˜ï¼‰ã€‚
- en: A typical example of a static real feature is promotion information.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€å®æ•°ç‰¹å¾çš„å…¸å‹ç¤ºä¾‹æ˜¯ä¿ƒé”€ä¿¡æ¯ã€‚
- en: '`future_values` (`torch.FloatTensor` of shape `(batch_size, prediction_length)`)
    â€” Future values of the time series, that serve as labels for the model. The `future_values`
    is what the Transformer needs to learn to output, given the `past_values`.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_values` (`torch.FloatTensor` of shape `(batch_size, prediction_length)`)
    â€” æ—¶é—´åºåˆ—çš„æœªæ¥å€¼ï¼Œä½œä¸ºæ¨¡å‹çš„æ ‡ç­¾ã€‚`future_values` æ˜¯ Transformer éœ€è¦å­¦ä¹ è¾“å‡ºçš„å†…å®¹ï¼Œç»™å®š `past_values`ã€‚'
- en: See the demo notebook and code snippets for details.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ¼”ç¤ºç¬”è®°æœ¬å’Œä»£ç ç‰‡æ®µã€‚
- en: Missing values need to be replaced with zeros.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼ºå¤±å€¼éœ€è¦ç”¨é›¶æ›¿æ¢ã€‚
- en: '`future_time_features` (`torch.FloatTensor` of shape `(batch_size, prediction_length,
    num_features)`, *optional*) â€” Optional time features, which the model internally
    will add to `future_values`. These could be things like â€œmonth of yearâ€, â€œday
    of the monthâ€, etc. encoded as vectors (for instance as Fourier features). These
    could also be so-called â€œageâ€ features, which basically help the model know â€œat
    which point in lifeâ€ a time-series is. Age features have small values for distant
    past time steps and increase monotonically the more we approach the current time
    step.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_time_features` (`torch.FloatTensor` of shape `(batch_size, prediction_length,
    num_features)`, *optional*) â€” å¯é€‰çš„æ—¶é—´ç‰¹å¾ï¼Œæ¨¡å‹å°†å†…éƒ¨æ·»åŠ åˆ° `future_values` ä¸­ã€‚è¿™äº›å¯èƒ½æ˜¯åƒâ€œå¹´ä»½çš„æœˆä»½â€ï¼Œâ€œæœˆä»½çš„æ—¥æœŸâ€ç­‰ç¼–ç ä¸ºå‘é‡ï¼ˆä¾‹å¦‚å‚…ç«‹å¶ç‰¹å¾ï¼‰çš„å†…å®¹ã€‚è¿™ä¹Ÿå¯èƒ½æ˜¯æ‰€è°“çš„â€œå¹´é¾„â€ç‰¹å¾ï¼ŒåŸºæœ¬ä¸Šå¸®åŠ©æ¨¡å‹çŸ¥é“æ—¶é—´åºåˆ—å¤„äºâ€œç”Ÿå‘½ä¸­çš„å“ªä¸ªé˜¶æ®µâ€ã€‚å¹´é¾„ç‰¹å¾å¯¹äºè¿œå¤„çš„è¿‡å»æ—¶é—´æ­¥å…·æœ‰è¾ƒå°çš„å€¼ï¼Œå¹¶ä¸”éšç€æˆ‘ä»¬æ¥è¿‘å½“å‰æ—¶é—´æ­¥è€Œå•è°ƒå¢åŠ ã€‚'
- en: These features serve as the â€œpositional encodingsâ€ of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    features.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰¹å¾ä½œä¸ºè¾“å…¥çš„â€œä½ç½®ç¼–ç â€ã€‚ä¸åƒ BERT è¿™æ ·çš„æ¨¡å‹ä¸åŒï¼ŒBERT çš„ä½ç½®ç¼–ç æ˜¯ä»å¤´å¼€å§‹å†…éƒ¨ä½œä¸ºæ¨¡å‹çš„å‚æ•°å­¦ä¹ çš„ï¼Œæ—¶é—´åºåˆ— Transformer
    éœ€è¦æä¾›é¢å¤–çš„ç‰¹å¾ã€‚
- en: The Autoformer only learns additional embeddings for `static_categorical_features`.
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Autoformer ä»…ä¸º `static_categorical_features` å­¦ä¹ é¢å¤–çš„åµŒå…¥ã€‚
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on certain token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” ç”¨äºé¿å…åœ¨æŸäº›æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨ `[0, 1]` ä¹‹é—´ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºæ ‡è®°æœªè¢«æ©ç ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºæ ‡è®°è¢«æ©ç ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on certain token indices. By
    default, a causal mask will be used, to make sure the model can only look at previous
    inputs in order to predict the future.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” ç”¨äºé¿å…åœ¨æŸäº›æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå°†ä½¿ç”¨å› æœæ©ç ï¼Œä»¥ç¡®ä¿æ¨¡å‹åªèƒ½æŸ¥çœ‹ä»¥å‰çš„è¾“å…¥ä»¥é¢„æµ‹æœªæ¥ã€‚'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) â€” ç”¨äºåœ¨ç¼–ç å™¨ä¸­ä½¿æ³¨æ„åŠ›æ¨¡å—çš„ç‰¹å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨ `[0, 1]` ä¹‹é—´ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«æ©ç ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«æ©ç ã€‚
- en: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” ç”¨äºåœ¨è§£ç å™¨ä¸­ä½¿æ³¨æ„åŠ›æ¨¡å—çš„ç‰¹å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨ `[0, 1]` ä¹‹é—´ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«æ©ç ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«æ©ç ã€‚
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” ç”¨äºä½¿äº¤å‰æ³¨æ„åŠ›æ¨¡å—çš„ç‰¹å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨ `[0, 1]` ä¹‹é—´ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«æ©ç ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºå¤´éƒ¨è¢«æ©ç ã€‚
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” Tuple consists
    of `last_hidden_state`, `hidden_states` (*optional*) and `attentions` (*optional*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` (*optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” å…ƒç»„åŒ…æ‹¬`last_hidden_state`ã€`hidden_states`
    (*optional*) å’Œ `attentions` (*optional*)ã€‚`last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size,
    sequence_length, hidden_size)` (*optional*)ï¼Œæ˜¯ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, å½“ä¼ é€’`use_cache=True`æˆ–`config.use_cache=True`æ—¶è¿”å›
    â€” é•¿åº¦ä¸º`config.n_layers`çš„å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰2ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length,
    embed_size_per_head)`çš„å¼ é‡ï¼Œä»¥åŠ2ä¸ªé¢å¤–çš„å½¢çŠ¶ä¸º`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—å’Œäº¤å‰æ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆå‚è§`past_key_values`è¾“å…¥ï¼‰ã€‚
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨`past_key_values`ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åä¸€ä¸ª`decoder_input_ids`ï¼ˆè¿™äº›æ²¡æœ‰ç»™å‡ºå…¶è¿‡å»é”®å€¼çŠ¶æ€çš„æ¨¡å‹ï¼‰çš„å½¢çŠ¶ä¸º`(batch_size,
    1)`ï¼Œè€Œä¸æ˜¯æ‰€æœ‰å½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„`decoder_input_ids`ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`çš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*optional*)
    â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œåˆ™è¿™å¾ˆæœ‰ç”¨ã€‚'
- en: '`use_cache` (`bool`, *optional*) â€” If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œå°†è¿”å›`past_key_values`é”®å€¼çŠ¶æ€ï¼Œå¯ç”¨äºåŠ é€Ÿè§£ç ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`transformers.models.autoformer.modeling_autoformer.AutoformerModelOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.autoformer.modeling_autoformer.AutoformerModelOutput`æˆ–`tuple(torch.FloatTensor)`'
- en: A `transformers.models.autoformer.modeling_autoformer.AutoformerModelOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig))
    and inputs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª`transformers.models.autoformer.modeling_autoformer.AutoformerModelOutput`æˆ–ä¸€ä¸ª`torch.FloatTensor`çš„å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor`çš„å½¢çŠ¶ä¸º`(batch_size, sequence_length,
    hidden_size)`) â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä»…ä½¿ç”¨`past_key_values`ï¼Œåˆ™è¾“å‡ºå½¢çŠ¶ä¸º`(batch_size, 1, hidden_size)`çš„åºåˆ—çš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€ã€‚
- en: '`trend` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`)
    â€” Trend tensor for each time series.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trend` (`torch.FloatTensor`çš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`)
    â€” æ¯ä¸ªæ—¶é—´åºåˆ—çš„è¶‹åŠ¿å¼ é‡ã€‚'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, å½“ä¼ é€’`use_cache=True`æˆ–`config.use_cache=True`æ—¶è¿”å›
    â€” é•¿åº¦ä¸º`config.n_layers`çš„å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰2ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length,
    embed_size_per_head)`çš„å¼ é‡ï¼Œä»¥åŠ2ä¸ªé¢å¤–çš„å½¢çŠ¶ä¸º`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—å’Œäº¤å‰æ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆå‚è§`past_key_values`è¾“å…¥ï¼‰ã€‚
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡ºåŠ ä¸Šæ¯å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the decoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length,
    hidden_size)`ï¼Œ*å¯é€‰*ï¼‰- æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡ºåŠ ä¸Šæ¯å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the encoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`loc` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) â€” Shift values of each time seriesâ€™ context window which is used to
    give the model inputs of the same magnitude and then used to shift back to the
    original magnitude.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loc`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size,)`æˆ–`(batch_size, input_size)`ï¼Œ*å¯é€‰*ï¼‰-
    æ¯ä¸ªæ—¶é—´åºåˆ—ä¸Šä¸‹æ–‡çª—å£çš„åç§»å€¼ï¼Œç”¨äºä½¿æ¨¡å‹è¾“å…¥å…·æœ‰ç›¸åŒçš„é‡çº§ï¼Œç„¶åç”¨äºå°†å…¶åç§»å›åŸå§‹é‡çº§ã€‚'
- en: '`scale` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) â€” Scaling values of each time seriesâ€™ context window which is used
    to give the model inputs of the same magnitude and then used to rescale back to
    the original magnitude.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size,)`æˆ–`(batch_size, input_size)`ï¼Œ*å¯é€‰*ï¼‰-
    æ¯ä¸ªæ—¶é—´åºåˆ—ä¸Šä¸‹æ–‡çª—å£çš„ç¼©æ”¾å€¼ï¼Œç”¨äºä½¿æ¨¡å‹è¾“å…¥å…·æœ‰ç›¸åŒçš„é‡çº§ï¼Œç„¶åç”¨äºå°†å…¶é‡æ–°ç¼©æ”¾å›åŸå§‹é‡çº§ã€‚'
- en: '`static_features:` (`torch.FloatTensor` of shape `(batch_size, feature size)`,
    *optional*) â€” Static features of each time seriesâ€™ in a batch which are copied
    to the covariates at inference time.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_features:`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, feature size)`ï¼Œ*å¯é€‰*ï¼‰-
    æ‰¹å¤„ç†ä¸­æ¯ä¸ªæ—¶é—´åºåˆ—çš„é™æ€ç‰¹å¾ï¼Œåœ¨æ¨æ–­æ—¶å¤åˆ¶åˆ°åå˜é‡ä¸­ã€‚'
- en: The [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel)
    forward method, overrides the `__call__` special method.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ–¹æ³•éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE4]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: AutoformerForPrediction
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoformerForPrediction
- en: '### `class transformers.AutoformerForPrediction`'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoformerForPrediction`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/modeling_autoformer.py#L1765)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/modeling_autoformer.py#L1765)'
- en: '[PRE5]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)ï¼‰â€”
    æ¨¡å‹é…ç½®ç±»ï¼ŒåŒ…å«æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The Autoformer Model with a distribution head on top for time-series forecasting.
    This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Autoformeræ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹çš„é¡¶éƒ¨å…·æœ‰ä¸€ä¸ªåˆ†å¸ƒå¤´ã€‚è¯¥æ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ï¼Œäº†è§£åº“ä¸ºå…¶æ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ä½¿ç”¨å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰ä¿¡æ¯ã€‚
- en: '#### `forward`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/modeling_autoformer.py#L1809)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/autoformer/modeling_autoformer.py#L1809)'
- en: '[PRE6]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`past_values` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    â€” Past values of the time series, that serve as context in order to predict the
    future. These values may contain lags, i.e. additional values from the past which
    are added in order to serve as â€œextra contextâ€. The `past_values` is what the
    Transformer encoder gets as input (with optional additional features, such as
    `static_categorical_features`, `static_real_features`, `past_time_features`).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_values`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼‰â€” æ—¶é—´åºåˆ—çš„è¿‡å»å€¼ï¼Œä½œä¸ºä¸Šä¸‹æ–‡ä»¥é¢„æµ‹æœªæ¥ã€‚è¿™äº›å€¼å¯èƒ½åŒ…å«æ»åï¼Œå³è¿‡å»çš„å…¶ä»–å€¼ï¼Œä»¥ä½œä¸ºâ€œé¢å¤–ä¸Šä¸‹æ–‡â€æ·»åŠ ã€‚`past_values`æ˜¯Transformerç¼–ç å™¨çš„è¾“å…¥ï¼ˆè¿˜å¯ä»¥åŒ…æ‹¬å¯é€‰çš„å…¶ä»–ç‰¹å¾ï¼Œå¦‚`static_categorical_features`ã€`static_real_features`ã€`past_time_features`ï¼‰ã€‚'
- en: The sequence length here is equal to `context_length` + `max(config.lags_sequence)`.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„åºåˆ—é•¿åº¦ç­‰äº`context_length` + `max(config.lags_sequence)`ã€‚
- en: Missing values need to be replaced with zeros.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼ºå¤±å€¼éœ€è¦ç”¨é›¶æ›¿æ¢ã€‚
- en: '`past_time_features` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_features)`, *optional*) â€” Optional time features, which the model internally
    will add to `past_values`. These could be things like â€œmonth of yearâ€, â€œday of
    the monthâ€, etc. encoded as vectors (for instance as Fourier features). These
    could also be so-called â€œageâ€ features, which basically help the model know â€œat
    which point in lifeâ€ a time-series is. Age features have small values for distant
    past time steps and increase monotonically the more we approach the current time
    step.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_time_features`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length,
    num_features)`ï¼Œ*å¯é€‰*ï¼‰â€” å¯é€‰çš„æ—¶é—´ç‰¹å¾ï¼Œæ¨¡å‹å†…éƒ¨å°†å…¶æ·»åŠ åˆ°`past_values`ä¸­ã€‚è¿™äº›å¯èƒ½æ˜¯è¯¸å¦‚â€œå¹´ä»½ä¸­çš„æœˆä»½â€ï¼Œâ€œæœˆä»½ä¸­çš„æ—¥æœŸâ€ç­‰ç¼–ç ä¸ºå‘é‡ï¼ˆä¾‹å¦‚å‚…ç«‹å¶ç‰¹å¾ï¼‰çš„å†…å®¹ã€‚è¿™äº›ä¹Ÿå¯ä»¥æ˜¯æ‰€è°“çš„â€œå¹´é¾„â€ç‰¹å¾ï¼ŒåŸºæœ¬ä¸Šå¸®åŠ©æ¨¡å‹äº†è§£æ—¶é—´åºåˆ—å¤„äºâ€œç”Ÿå‘½ä¸­çš„å“ªä¸ªé˜¶æ®µâ€ã€‚å¹´é¾„ç‰¹å¾å¯¹äºè¿‡å»çš„æ—¶é—´æ­¥å…·æœ‰è¾ƒå°çš„å€¼ï¼Œå¹¶ä¸”éšç€æˆ‘ä»¬æ¥è¿‘å½“å‰æ—¶é—´æ­¥è€Œå•è°ƒå¢åŠ ã€‚'
- en: These features serve as the â€œpositional encodingsâ€ of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰¹å¾ä½œä¸ºè¾“å…¥çš„â€œä½ç½®ç¼–ç â€ã€‚å› æ­¤ï¼Œä¸åƒBERTè¿™æ ·çš„æ¨¡å‹ç›¸åï¼ŒBERTçš„ä½ç½®ç¼–ç æ˜¯ä»å¤´å¼€å§‹å†…éƒ¨ä½œä¸ºæ¨¡å‹çš„å‚æ•°å­¦ä¹ çš„ï¼Œæ—¶é—´åºåˆ—Transformeréœ€è¦æä¾›é¢å¤–çš„æ—¶é—´ç‰¹å¾ã€‚
- en: The Autoformer only learns additional embeddings for `static_categorical_features`.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Autoformerä»…ä¸º`static_categorical_features`å­¦ä¹ é¢å¤–çš„åµŒå…¥ã€‚
- en: '`past_observed_mask` (`torch.BoolTensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Boolean mask to indicate which `past_values` were observed and which
    were missing. Mask values selected in `[0, 1]`:'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_observed_mask`ï¼ˆ`torch.BoolTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*å¯é€‰*ï¼‰â€”
    å¸ƒå°”æ©ç ï¼ŒæŒ‡ç¤ºå“ªäº›`past_values`æ˜¯è§‚å¯Ÿåˆ°çš„ï¼Œå“ªäº›æ˜¯ç¼ºå¤±çš„ã€‚æ©ç å€¼é€‰åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 for values that are `observed`,
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºâ€œè§‚å¯Ÿåˆ°â€çš„å€¼ï¼Œ
- en: 0 for values that are `missing` (i.e. NaNs that were replaced by zeros).
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºâ€œç¼ºå¤±â€çš„å€¼ï¼ˆå³ç”¨é›¶æ›¿æ¢çš„NaNï¼‰ã€‚
- en: '`static_categorical_features` (`torch.LongTensor` of shape `(batch_size, number
    of static categorical features)`, *optional*) â€” Optional static categorical features
    for which the model will learn an embedding, which it will add to the values of
    the time series.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_categorical_features`ï¼ˆ`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, number of
    static categorical features)`ï¼Œ*å¯é€‰*ï¼‰â€” æ¨¡å‹å°†å­¦ä¹ åµŒå…¥çš„å¯é€‰é™æ€åˆ†ç±»ç‰¹å¾ï¼Œå°†å…¶æ·»åŠ åˆ°æ—¶é—´åºåˆ—çš„å€¼ä¸­ã€‚'
- en: Static categorical features are features which have the same value for all time
    steps (static over time).
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€åˆ†ç±»ç‰¹å¾æ˜¯æ‰€æœ‰æ—¶é—´æ­¥é•¿å…·æœ‰ç›¸åŒå€¼çš„ç‰¹å¾ï¼ˆéšæ—¶é—´ä¿æŒé™æ€ï¼‰ã€‚
- en: A typical example of a static categorical feature is a time series ID.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€åˆ†ç±»ç‰¹å¾çš„å…¸å‹ç¤ºä¾‹æ˜¯æ—¶é—´åºåˆ—IDã€‚
- en: '`static_real_features` (`torch.FloatTensor` of shape `(batch_size, number of
    static real features)`, *optional*) â€” Optional static real features which the
    model will add to the values of the time series.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_real_features`ï¼ˆ`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, number of static
    real features)`ï¼Œ*å¯é€‰*ï¼‰â€” æ¨¡å‹å°†æ·»åŠ åˆ°æ—¶é—´åºåˆ—å€¼ä¸­çš„å¯é€‰é™æ€å®ç‰¹å¾ã€‚'
- en: Static real features are features which have the same value for all time steps
    (static over time).
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€å®ç‰¹å¾æ˜¯æ‰€æœ‰æ—¶é—´æ­¥é•¿å…·æœ‰ç›¸åŒå€¼çš„ç‰¹å¾ï¼ˆéšæ—¶é—´ä¿æŒé™æ€ï¼‰ã€‚
- en: A typical example of a static real feature is promotion information.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é™æ€å®ç‰¹å¾çš„å…¸å‹ç¤ºä¾‹æ˜¯ä¿ƒé”€ä¿¡æ¯ã€‚
- en: '`future_values` (`torch.FloatTensor` of shape `(batch_size, prediction_length)`)
    â€” Future values of the time series, that serve as labels for the model. The `future_values`
    is what the Transformer needs to learn to output, given the `past_values`.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_values` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, prediction_length)`)
    â€” æ—¶é—´åºåˆ—çš„æœªæ¥å€¼ï¼Œä½œä¸ºæ¨¡å‹çš„æ ‡ç­¾ã€‚Transformeréœ€è¦å­¦ä¹ è¾“å‡º`future_values`ï¼Œç»™å®š`past_values`ã€‚'
- en: See the demo notebook and code snippets for details.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ¼”ç¤ºç¬”è®°æœ¬å’Œä»£ç ç‰‡æ®µã€‚
- en: Missing values need to be replaced with zeros.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼ºå¤±å€¼éœ€è¦ç”¨é›¶æ›¿æ¢ã€‚
- en: '`future_time_features` (`torch.FloatTensor` of shape `(batch_size, prediction_length,
    num_features)`, *optional*) â€” Optional time features, which the model internally
    will add to `future_values`. These could be things like â€œmonth of yearâ€, â€œday
    of the monthâ€, etc. encoded as vectors (for instance as Fourier features). These
    could also be so-called â€œageâ€ features, which basically help the model know â€œat
    which point in lifeâ€ a time-series is. Age features have small values for distant
    past time steps and increase monotonically the more we approach the current time
    step.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`future_time_features` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, prediction_length,
    num_features)`ï¼Œ*optional*) â€” å¯é€‰çš„æ—¶é—´ç‰¹å¾ï¼Œæ¨¡å‹å†…éƒ¨å°†å…¶æ·»åŠ åˆ°`future_values`ä¸­ã€‚è¿™äº›å¯èƒ½æ˜¯è¯¸å¦‚â€œå¹´ä»½çš„æœˆä»½â€ï¼Œâ€œæœˆä»½çš„æ—¥æœŸâ€ç­‰ç¼–ç ä¸ºå‘é‡ï¼ˆä¾‹å¦‚ä½œä¸ºå‚…ç«‹å¶ç‰¹å¾ï¼‰çš„å†…å®¹ã€‚è¿™äº›ä¹Ÿå¯ä»¥æ˜¯æ‰€è°“çš„â€œå¹´é¾„â€ç‰¹å¾ï¼ŒåŸºæœ¬ä¸Šå¸®åŠ©æ¨¡å‹çŸ¥é“æ—¶é—´åºåˆ—å¤„äºâ€œç”Ÿå‘½ä¸­çš„å“ªä¸ªé˜¶æ®µâ€ã€‚å¹´é¾„ç‰¹å¾å¯¹äºè¿œå¤„çš„è¿‡å»æ—¶é—´æ­¥å…·æœ‰è¾ƒå°çš„å€¼ï¼Œå¹¶ä¸”éšç€æˆ‘ä»¬æ¥è¿‘å½“å‰æ—¶é—´æ­¥è€Œå•è°ƒå¢åŠ ã€‚'
- en: These features serve as the â€œpositional encodingsâ€ of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    features.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰¹å¾ä½œä¸ºè¾“å…¥çš„â€œä½ç½®ç¼–ç â€ã€‚ä¸BERTç­‰æ¨¡å‹ä¸åŒï¼ŒBERTç­‰æ¨¡å‹çš„ä½ç½®ç¼–ç æ˜¯ä»å¤´å¼€å§‹å†…éƒ¨ä½œä¸ºæ¨¡å‹çš„å‚æ•°å­¦ä¹ çš„ï¼Œæ—¶é—´åºåˆ—Transformeréœ€è¦æä¾›é¢å¤–çš„ç‰¹å¾ã€‚
- en: The Autoformer only learns additional embeddings for `static_categorical_features`.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Autoformerä»…ä¸º`static_categorical_features`å­¦ä¹ é¢å¤–çš„åµŒå…¥ã€‚
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on certain token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length)`ï¼Œ*optional*)
    â€” ç”¨äºé¿å…åœ¨æŸäº›æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 for tokens that are `not masked`,
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºæœªè¢«æ©ç›–çš„æ ‡è®°ï¼Œ
- en: 0 for tokens that are `masked`.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºè¢«æ©ç›–çš„æ ‡è®°ã€‚
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)'
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) â€” Mask to avoid performing attention on certain token indices. By
    default, a causal mask will be used, to make sure the model can only look at previous
    inputs in order to predict the future.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, target_sequence_length)`ï¼Œ*optional*)
    â€” ç”¨äºé¿å…åœ¨æŸäº›æ ‡è®°ç´¢å¼•ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå°†ä½¿ç”¨å› æœæ©ç ï¼Œä»¥ç¡®ä¿æ¨¡å‹åªèƒ½æŸ¥çœ‹ä»¥å‰çš„è¾“å…¥ä»¥é¢„æµ‹æœªæ¥ã€‚'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(encoder_layers, encoder_attention_heads)`ï¼Œ*optional*)
    â€” ç”¨äºä½¿ç¼–ç å™¨ä¸­çš„æ³¨æ„åŠ›æ¨¡å—ä¸­çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«æ©ç›–ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«æ©ç›–ã€‚
- en: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(decoder_layers, decoder_attention_heads)`ï¼Œ*optional*)
    â€” ç”¨äºä½¿è§£ç å™¨ä¸­çš„æ³¨æ„åŠ›æ¨¡å—ä¸­çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«æ©ç›–ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«æ©ç›–ã€‚
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) â€” Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`torch.Tensor`ï¼Œå½¢çŠ¶ä¸º`(decoder_layers, decoder_attention_heads)`ï¼Œ*optional*)
    â€” ç”¨äºä½¿äº¤å‰æ³¨æ„åŠ›æ¨¡å—ä¸­çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨`[0, 1]`ä¹‹é—´ï¼š'
- en: 1 indicates the head is `not masked`,
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1è¡¨ç¤ºå¤´éƒ¨æœªè¢«æ©ç›–ï¼Œ
- en: 0 indicates the head is `masked`.
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0è¡¨ç¤ºå¤´éƒ¨è¢«æ©ç›–ã€‚
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” Tuple consists
    of `last_hidden_state`, `hidden_states` (*optional*) and `attentions` (*optional*)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)` (*optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`ï¼Œ*optional*) â€” å…ƒç»„åŒ…æ‹¬`last_hidden_state`ï¼Œ`hidden_states`ï¼ˆ*optional*ï¼‰å’Œ`attentions`ï¼ˆ*optional*ï¼‰`last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size,
    sequence_length, hidden_size)`çš„éšè—çŠ¶æ€åºåˆ—æ˜¯ç¼–ç å™¨æœ€åä¸€å±‚çš„è¾“å‡ºã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, å½“ä¼ é€’`use_cache=True`æˆ–`config.use_cache=True`æ—¶è¿”å›)
    â€” é•¿åº¦ä¸º`config.n_layers`çš„å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰2ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length,
    embed_size_per_head)`çš„å¼ é‡å’Œ2ä¸ªé¢å¤–çš„å½¢çŠ¶ä¸º`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—å’Œäº¤å‰æ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆå‚è§`past_key_values`è¾“å…¥ï¼‰ã€‚
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that donâ€™t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨äº†`past_key_values`ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä»…è¾“å…¥æœ€åçš„`decoder_input_ids`ï¼ˆé‚£äº›æ²¡æœ‰å°†å…¶è¿‡å»é”®å€¼çŠ¶æ€æä¾›ç»™æ­¤æ¨¡å‹çš„ï¼‰çš„å½¢çŠ¶ä¸º`(batch_size,
    1)`çš„å¼ é‡ï¼Œè€Œä¸æ˜¯å½¢çŠ¶ä¸º`(batch_size, sequence_length)`çš„æ‰€æœ‰`decoder_input_ids`ã€‚
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the modelâ€™s internal embedding lookup matrix.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*)
    â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’`input_ids`ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¤šæ§åˆ¶å¦‚ä½•å°†`input_ids`ç´¢å¼•è½¬æ¢ä¸ºç›¸å…³å‘é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å‹çš„å†…éƒ¨åµŒå…¥æŸ¥æ‰¾çŸ©é˜µï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚'
- en: '`use_cache` (`bool`, *optional*) â€” If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *å¯é€‰*) â€” å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™è¿”å›`past_key_values`é”®å€¼çŠ¶æ€ï¼Œå¯ç”¨äºåŠ é€Ÿè§£ç ï¼ˆå‚è§`past_key_values`ï¼‰ã€‚'
- en: '`output_attentions` (`bool`, *optional*) â€” Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.Seq2SeqTSPredictionOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSPredictionOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqTSPredictionOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSPredictionOutput)æˆ–`torch.FloatTensor`å…ƒç»„'
- en: A [transformers.modeling_outputs.Seq2SeqTSPredictionOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSPredictionOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig))
    and inputs.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.Seq2SeqTSPredictionOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSPredictionOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå…·ä½“å–å†³äºé…ç½®ï¼ˆ[AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)ï¼‰å’Œè¾“å…¥ã€‚
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when a `future_values`
    is provided) â€” Distributional loss.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(1,)`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`future_values`æ—¶è¿”å›) â€” åˆ†å¸ƒæŸå¤±ã€‚'
- en: '`params` (`torch.FloatTensor` of shape `(batch_size, num_samples, num_params)`)
    â€” Parameters of the chosen distribution.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_samples, num_params)`) â€”
    æ‰€é€‰åˆ†å¸ƒçš„å‚æ•°ã€‚'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) â€” Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *å¯é€‰*, å½“ä¼ é€’`use_cache=True`æˆ–`config.use_cache=True`æ—¶è¿”å›)
    â€” é•¿åº¦ä¸º`config.n_layers`çš„`tuple(torch.FloatTensor)`å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„æœ‰2ä¸ªå½¢çŠ¶ä¸º`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`çš„å¼ é‡å’Œ2ä¸ªé¢å¤–çš„å½¢çŠ¶ä¸º`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`çš„å¼ é‡ã€‚'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…å«é¢„å…ˆè®¡ç®—çš„éšè—çŠ¶æ€ï¼ˆè‡ªæ³¨æ„åŠ›å—å’Œäº¤å‰æ³¨æ„åŠ›å—ä¸­çš„é”®å’Œå€¼ï¼‰ï¼Œå¯ç”¨äºåŠ é€Ÿé¡ºåºè§£ç ï¼ˆå‚è§`past_key_values`è¾“å…¥ï¼‰ã€‚
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥å±‚çš„è¾“å‡º+æ¯å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *å¯é€‰*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights of the decoderâ€™s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è§£ç å™¨äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) â€” Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length,
    hidden_size)`ï¼Œ*optional*) â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    â€” æ¯ä¸ªå±‚çš„è¾“å‡ºï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º+æ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰çš„`torch.FloatTensor`å…ƒç»„ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length,
    hidden_size)`ã€‚'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºä»¥åŠåˆå§‹åµŒå…¥è¾“å‡ºçš„éšè—çŠ¶æ€ã€‚
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) â€”
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`ï¼Œ*optional*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›)
    â€” `torch.FloatTensor`å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`ã€‚'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: '`loc` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) â€” Shift values of each time seriesâ€™ context window which is used to
    give the model inputs of the same magnitude and then used to shift back to the
    original magnitude.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loc` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size,)`æˆ–`(batch_size, input_size)`ï¼Œ*optional*)
    â€” æ¯ä¸ªæ—¶é—´åºåˆ—ä¸Šä¸‹æ–‡çª—å£çš„åç§»å€¼ï¼Œç”¨äºä½¿æ¨¡å‹è¾“å…¥å…·æœ‰ç›¸åŒçš„é‡çº§ï¼Œç„¶åç”¨äºå°†å…¶åç§»å›åŸå§‹é‡çº§ã€‚'
- en: '`scale` (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) â€” Scaling values of each time seriesâ€™ context window which is used
    to give the model inputs of the same magnitude and then used to rescale back to
    the original magnitude.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size,)`æˆ–`(batch_size, input_size)`ï¼Œ*optional*)
    â€” æ¯ä¸ªæ—¶é—´åºåˆ—ä¸Šä¸‹æ–‡çª—å£çš„ç¼©æ”¾å€¼ï¼Œç”¨äºä½¿æ¨¡å‹è¾“å…¥å…·æœ‰ç›¸åŒçš„é‡çº§ï¼Œç„¶åç”¨äºå°†å…¶é‡æ–°ç¼©æ”¾å›åŸå§‹é‡çº§ã€‚'
- en: '`static_features` (`torch.FloatTensor` of shape `(batch_size, feature size)`,
    *optional*) â€” Static features of each time seriesâ€™ in a batch which are copied
    to the covariates at inference time.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`static_features` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, feature size)`ï¼Œ*optional*)
    â€” æ¯ä¸ªæ—¶é—´åºåˆ—æ‰¹æ¬¡ä¸­çš„é™æ€ç‰¹å¾ï¼Œåœ¨æ¨æ–­æ—¶å¤åˆ¶åˆ°åå˜é‡ä¸­ã€‚'
- en: The [AutoformerForPrediction](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerForPrediction)
    forward method, overrides the `__call__` special method.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[AutoformerForPrediction](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerForPrediction)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE7]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
