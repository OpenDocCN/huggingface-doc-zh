# åŠ é€Ÿ

> åŸæ–‡ï¼š[https://huggingface.co/docs/accelerate/index](https://huggingface.co/docs/accelerate/index)

ğŸ¤—åŠ é€Ÿæ˜¯ä¸€ä¸ªåº“ï¼Œé€šè¿‡æ·»åŠ åªæœ‰å››è¡Œä»£ç ï¼Œä½¿ç›¸åŒçš„PyTorchä»£ç å¯ä»¥åœ¨ä»»ä½•åˆ†å¸ƒå¼é…ç½®ä¸Šè¿è¡Œï¼ç®€è€Œè¨€ä¹‹ï¼Œç®€å•ã€é«˜æ•ˆå’Œé€‚åº”æ€§çš„è§„æ¨¡è®­ç»ƒå’Œæ¨ç†ã€‚

```py
+ from accelerate import Accelerator
+ accelerator = Accelerator()

+ model, optimizer, training_dataloader, scheduler = accelerator.prepare(
+     model, optimizer, training_dataloader, scheduler
+ )

  for batch in training_dataloader:
      optimizer.zero_grad()
      inputs, targets = batch
      inputs = inputs.to(device)
      targets = targets.to(device)
      outputs = model(inputs)
      loss = loss_function(outputs, targets)
+     accelerator.backward(loss)
      optimizer.step()
      scheduler.step()
```

åŸºäº`torch_xla`å’Œ`torch.distributed`æ„å»ºï¼ŒğŸ¤—åŠ é€Ÿä¼šå¤„ç†ç¹é‡çš„å·¥ä½œï¼Œå› æ­¤æ‚¨æ— éœ€ç¼–å†™ä»»ä½•è‡ªå®šä¹‰ä»£ç æ¥é€‚åº”è¿™äº›å¹³å°ã€‚å°†ç°æœ‰ä»£ç åº“è½¬æ¢ä¸ºåˆ©ç”¨[DeepSpeed](usage_guides/deepspeed)ï¼Œæ‰§è¡Œ[å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œ](usage_guides/fsdp)ï¼Œå¹¶è‡ªåŠ¨æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼

è¦æ›´å¥½åœ°äº†è§£è¿™ä¸ªè¿‡ç¨‹ï¼Œè¯·ç¡®ä¿æŸ¥çœ‹[æ•™ç¨‹](basic_tutorials/overview)ï¼

ç„¶åï¼Œå¯ä»¥é€šè¿‡åŠ é€Ÿçš„CLIç•Œé¢åœ¨ä»»ä½•ç³»ç»Ÿä¸Šå¯åŠ¨æ­¤ä»£ç ï¼š

```py
accelerate launch {my_script.py}
```

[æ•™ç¨‹

å­¦ä¹ åŸºç¡€çŸ¥è¯†ï¼Œå¹¶ç†Ÿæ‚‰ä½¿ç”¨ğŸ¤—åŠ é€Ÿã€‚å¦‚æœæ‚¨æ˜¯ç¬¬ä¸€æ¬¡ä½¿ç”¨ğŸ¤—åŠ é€Ÿï¼Œè¯·ä»è¿™é‡Œå¼€å§‹ï¼](./basic_tutorials/overview) [æ“ä½œæŒ‡å—

å®ç”¨æŒ‡å—ï¼Œå¸®åŠ©æ‚¨å®ç°ç‰¹å®šç›®æ ‡ã€‚æŸ¥çœ‹è¿™äº›æŒ‡å—ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨ğŸ¤—åŠ é€Ÿè§£å†³ç°å®ä¸–ç•Œçš„é—®é¢˜ã€‚](./usage_guides/explore) [æ¦‚å¿µæŒ‡å—

é«˜å±‚æ¬¡çš„è§£é‡Šï¼Œä»¥å»ºç«‹å¯¹é‡è¦ä¸»é¢˜çš„æ›´å¥½ç†è§£ï¼Œä¾‹å¦‚é¿å…åœ¨åˆ†å¸ƒå¼è®­ç»ƒå’ŒDeepSpeedä¸­çš„å¾®å¦™ç»†å¾®å·®åˆ«å’Œé™·é˜±ã€‚](./concept_guides/gradient_synchronization) [å‚è€ƒ

å…³äºğŸ¤—åŠ é€Ÿç±»å’Œæ–¹æ³•å¦‚ä½•å·¥ä½œçš„æŠ€æœ¯æè¿°ã€‚](./package_reference/accelerator)
