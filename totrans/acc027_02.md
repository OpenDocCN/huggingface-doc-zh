# 加速

> 原文：[https://huggingface.co/docs/accelerate/index](https://huggingface.co/docs/accelerate/index)

🤗加速是一个库，通过添加只有四行代码，使相同的PyTorch代码可以在任何分布式配置上运行！简而言之，简单、高效和适应性的规模训练和推理。

```py
+ from accelerate import Accelerator
+ accelerator = Accelerator()

+ model, optimizer, training_dataloader, scheduler = accelerator.prepare(
+     model, optimizer, training_dataloader, scheduler
+ )

  for batch in training_dataloader:
      optimizer.zero_grad()
      inputs, targets = batch
      inputs = inputs.to(device)
      targets = targets.to(device)
      outputs = model(inputs)
      loss = loss_function(outputs, targets)
+     accelerator.backward(loss)
      optimizer.step()
      scheduler.step()
```

基于`torch_xla`和`torch.distributed`构建，🤗加速会处理繁重的工作，因此您无需编写任何自定义代码来适应这些平台。将现有代码库转换为利用[DeepSpeed](usage_guides/deepspeed)，执行[完全分片数据并行](usage_guides/fsdp)，并自动支持混合精度训练！

要更好地了解这个过程，请确保查看[教程](basic_tutorials/overview)！

然后，可以通过加速的CLI界面在任何系统上启动此代码：

```py
accelerate launch {my_script.py}
```

[教程

学习基础知识，并熟悉使用🤗加速。如果您是第一次使用🤗加速，请从这里开始！](./basic_tutorials/overview) [操作指南

实用指南，帮助您实现特定目标。查看这些指南，了解如何使用🤗加速解决现实世界的问题。](./usage_guides/explore) [概念指南

高层次的解释，以建立对重要主题的更好理解，例如避免在分布式训练和DeepSpeed中的微妙细微差别和陷阱。](./concept_guides/gradient_synchronization) [参考

关于🤗加速类和方法如何工作的技术描述。](./package_reference/accelerator)
