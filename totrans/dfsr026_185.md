# CMStochasticIterativeScheduler

> 原始文本：[https://huggingface.co/docs/diffusers/api/schedulers/cm_stochastic_iterative](https://huggingface.co/docs/diffusers/api/schedulers/cm_stochastic_iterative)

[一致性模型](https://huggingface.co/papers/2303.01469) 由杨松、Prafulla Dhariwal、Mark Chen 和 Ilya Sutskever 提出了一种多步和单步调度器（算法 1），能够在一步或少量步骤中生成良好的样本。

论文摘要为：

*扩散模型显著推进了图像、音频和视频生成领域，但它们依赖于导致生成速度缓慢的迭代采样过程。为了克服这一限制，我们提出了一致性模型，这是一种通过直接将噪声映射到数据来生成高质量样本的新型模型系列。它们通过设计支持快速一步生成，同时仍允许多步采样以在计算和样本质量之间进行交换。它们还支持零样本数据编辑，如图像修补、着色和超分辨率，而无需在这些任务上进行显式训练。一致性模型可以通过蒸馏预训练的扩散模型或作为独立的生成模型进行训练。通过大量实验，我们证明它们在一步和少步采样中优于现有的扩散模型蒸馏技术，实现了CIFAR-10上新的FID最佳值为3.55，ImageNet 64x64为6.20的一步生成。当单独训练时，一致性模型成为一种新的生成模型系列，可以在标准基准测试中优于现有的一步、非对抗性生成模型，如CIFAR-10、ImageNet 64x64 和 LSUN 256x256。*

原始代码库可在 [openai/consistency_models](https://github.com/openai/consistency_models) 找到。

## CMStochasticIterativeScheduler

### `class diffusers.CMStochasticIterativeScheduler`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L44)

```py
( num_train_timesteps: int = 40 sigma_min: float = 0.002 sigma_max: float = 80.0 sigma_data: float = 0.5 s_noise: float = 1.0 rho: float = 7.0 clip_denoised: bool = True )
```

参数

+   `num_train_timesteps` (`int`, 默认为 40) — 训练模型的扩散步数。

+   `sigma_min` (`float`, 默认为 0.002) — sigma调度中的最小噪声幅度。默认值为原始实现中的 0.002。

+   `sigma_max` (`float`, 默认为 80.0) — sigma调度中的最大噪声幅度。默认值为原始实现中的 80.0。

+   `sigma_data` (`float`, 默认为 0.5) — 来自EDM [论文](https://huggingface.co/papers/2206.00364) 的数据分布的标准差。默认值为原始实现中的 0.5。

+   `s_noise` (`float`, 默认为 1.0) — 用于抵消采样过程中细节丢失的额外噪声量。合理范围为 [1.000, 1.011]。默认值为原始实现中的 1.0。

+   `rho` (`float`, 默认为 7.0) — 用于从EDM [论文](https://huggingface.co/papers/2206.00364) 计算Karras sigma调度的参数。默认值为原始实现中的 7.0。

+   `clip_denoised` (`bool`, 默认为 `True`) — 是否将去噪输出剪裁到 `(-1, 1)`。

+   `timesteps` (`List` 或 `np.ndarray` 或 `torch.Tensor`, *可选*) — 可选指定的显式时间步骤表。预期时间步骤按递增顺序排列。

一致性模型的多步和单步采样。

该模型继承自 [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin) 和 [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)。查看超类文档以了解库实现的所有调度器通用方法，如加载和保存。

#### `get_scalings_for_boundary_condition`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L256)

```py
( sigma ) → export const metadata = 'undefined';tuple
```

参数

+   `sigma` (`torch.FloatTensor`) — Karras sigma计划中的当前sigma。

返回

`tuple`

一个包含两个元素的元组，其中`c_skip`（加权当前样本）是第一个元素，`c_out`（加权一致性模型输出）是第二个元素。

获取用于强制边界条件的一致性模型参数化中使用的缩放（来自[论文](https://huggingface.co/papers/2303.01469)的附录C）。

方程中的`epsilon`用于将`c_skip`和`c_out`设置为`sigma_min`。

#### `scale_model_input`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L117)

```py
( sample: FloatTensor timestep: Union ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample` (`torch.FloatTensor`) — 输入样本。

+   `timestep` (`float`或`torch.FloatTensor`) — 扩散链中的当前时间步长。

返回

`torch.FloatTensor`

缩放后的输入样本。

通过`(sigma**2 + sigma_data**2) ** 0.5`缩放一致性模型输入。

#### `set_timesteps`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L163)

```py
( num_inference_steps: Optional = None device: Union = None timesteps: Optional = None )
```

参数

+   `num_inference_steps` (`int`) — 在使用预训练模型生成样本时使用的扩散步骤数。

+   `device` (`str`或`torch.device`, *可选*) — 应将时间步长移动到的设备。如果为`None`，则不移动时间步长。

+   `timesteps` (`List[int]`, *可选*) — 用于支持时间步长之间任意间距的自定义时间步长。如果为`None`，则使用等间距时间步长策略。如果传递了`timesteps`，则`num_inference_steps`必须为`None`。

设置用于扩散链的时间步长（在推断之前运行）。

#### `sigma_to_t`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L144)

```py
( sigmas: Union ) → export const metadata = 'undefined';float or np.ndarray
```

参数

+   `sigmas` (`float`或`np.ndarray`) — 单个Karras sigma或Karras sigmas数组。

返回

`float`或`np.ndarray`

缩放后的输入时间步长或缩放后的输入时间步长数组。

从Karras sigmas获取缩放的时间步长，以输入一致性模型。

#### `step`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L301)

```py
( model_output: FloatTensor timestep: Union sample: FloatTensor generator: Optional = None return_dict: bool = True ) → export const metadata = 'undefined';CMStochasticIterativeSchedulerOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出的结果。

+   `timestep` (`float`) — 扩散链中的当前时间步长。

+   `样本` (`torch.FloatTensor`) — 由扩散过程创建的样本的当前实例。

+   `generator` (`torch.Generator`, *可选*) — 随机数生成器。

+   `return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回[CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)或`tuple`。

返回

[CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)或`tuple`

如果`return_dict`为`True`，则返回[CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)，否则返回一个元组，其中第一个元素是样本张量。

通过反转SDE从先前时间步长预测样本。此函数从学习模型输出（通常是预测的噪声）传播扩散过程。

## CMStochasticIterativeSchedulerOutput

### `class diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L30)

```py
( prev_sample: FloatTensor )
```

参数

+   `prev_sample`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`，用于图像）- 上一个时间步的计算样本`(x_{t-1})`。`prev_sample`应该在去噪循环中作为下一个模型输入使用。

调度程序的`step`函数的输出类。
