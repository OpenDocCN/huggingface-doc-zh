["```py\n>>> from transformers import TapasConfig, TapasForQuestionAnswering\n\n>>> # for example, the base sized model with default SQA configuration\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\")\n\n>>> # or, the base sized model with WTQ configuration\n>>> config = TapasConfig.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n\n>>> # or, the base sized model with WikiSQL configuration\n>>> config = TapasConfig(\"google-base-finetuned-wikisql-supervised\")\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n```", "```py\n>>> from transformers import TapasConfig, TapasForQuestionAnswering\n\n>>> # you can initialize the classification heads any way you want (see docs of TapasConfig)\n>>> config = TapasConfig(num_aggregation_labels=3, average_logits_per_cell=True)\n>>> # initializing the pre-trained base sized model with our custom classification heads\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n```", "```py\n>>> from transformers import TapasConfig, TFTapasForQuestionAnswering\n\n>>> # for example, the base sized model with default SQA configuration\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\")\n\n>>> # or, the base sized model with WTQ configuration\n>>> config = TapasConfig.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n\n>>> # or, the base sized model with WikiSQL configuration\n>>> config = TapasConfig(\"google-base-finetuned-wikisql-supervised\")\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n```", "```py\n>>> from transformers import TapasConfig, TFTapasForQuestionAnswering\n\n>>> # you can initialize the classification heads any way you want (see docs of TapasConfig)\n>>> config = TapasConfig(num_aggregation_labels=3, average_logits_per_cell=True)\n>>> # initializing the pre-trained base sized model with our custom classification heads\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n```", "```py\n>>> from transformers import TapasTokenizer\n>>> import pandas as pd\n\n>>> model_name = \"google/tapas-base\"\n>>> tokenizer = TapasTokenizer.from_pretrained(model_name)\n\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> queries = [\n...     \"What is the name of the first actor?\",\n...     \"How many movies has George Clooney played in?\",\n...     \"What is the total number of movies?\",\n... ]\n>>> answer_coordinates = [[(0, 0)], [(2, 1)], [(0, 1), (1, 1), (2, 1)]]\n>>> answer_text = [[\"Brad Pitt\"], [\"69\"], [\"209\"]]\n>>> table = pd.DataFrame.from_dict(data)\n>>> inputs = tokenizer(\n...     table=table,\n...     queries=queries,\n...     answer_coordinates=answer_coordinates,\n...     answer_text=answer_text,\n...     padding=\"max_length\",\n...     return_tensors=\"pt\",\n... )\n>>> inputs\n{'input_ids': tensor([[ ... ]]), 'attention_mask': tensor([[...]]), 'token_type_ids': tensor([[[...]]]),\n'numeric_values': tensor([[ ... ]]), 'numeric_values_scale: tensor([[ ... ]]), labels: tensor([[ ... ]])}\n```", "```py\n>>> import torch\n>>> import pandas as pd\n\n>>> tsv_path = \"your_path_to_the_tsv_file\"\n>>> table_csv_path = \"your_path_to_a_directory_containing_all_csv_files\"\n\n>>> class TableDataset(torch.utils.data.Dataset):\n...     def __init__(self, data, tokenizer):\n...         self.data = data\n...         self.tokenizer = tokenizer\n\n...     def __getitem__(self, idx):\n...         item = data.iloc[idx]\n...         table = pd.read_csv(table_csv_path + item.table_file).astype(\n...             str\n...         )  # be sure to make your table data text only\n...         encoding = self.tokenizer(\n...             table=table,\n...             queries=item.question,\n...             answer_coordinates=item.answer_coordinates,\n...             answer_text=item.answer_text,\n...             truncation=True,\n...             padding=\"max_length\",\n...             return_tensors=\"pt\",\n...         )\n...         # remove the batch dimension which the tokenizer adds by default\n...         encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n...         # add the float_answer which is also required (weak supervision for aggregation case)\n...         encoding[\"float_answer\"] = torch.tensor(item.float_answer)\n...         return encoding\n\n...     def __len__(self):\n...         return len(self.data)\n\n>>> data = pd.read_csv(tsv_path, sep=\"\\t\")\n>>> train_dataset = TableDataset(data, tokenizer)\n>>> train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n```", "```py\n>>> from transformers import TapasTokenizer\n>>> import pandas as pd\n\n>>> model_name = \"google/tapas-base\"\n>>> tokenizer = TapasTokenizer.from_pretrained(model_name)\n\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> queries = [\n...     \"What is the name of the first actor?\",\n...     \"How many movies has George Clooney played in?\",\n...     \"What is the total number of movies?\",\n... ]\n>>> answer_coordinates = [[(0, 0)], [(2, 1)], [(0, 1), (1, 1), (2, 1)]]\n>>> answer_text = [[\"Brad Pitt\"], [\"69\"], [\"209\"]]\n>>> table = pd.DataFrame.from_dict(data)\n>>> inputs = tokenizer(\n...     table=table,\n...     queries=queries,\n...     answer_coordinates=answer_coordinates,\n...     answer_text=answer_text,\n...     padding=\"max_length\",\n...     return_tensors=\"tf\",\n... )\n>>> inputs\n{'input_ids': tensor([[ ... ]]), 'attention_mask': tensor([[...]]), 'token_type_ids': tensor([[[...]]]),\n'numeric_values': tensor([[ ... ]]), 'numeric_values_scale: tensor([[ ... ]]), labels: tensor([[ ... ]])}\n```", "```py\n>>> import tensorflow as tf\n>>> import pandas as pd\n\n>>> tsv_path = \"your_path_to_the_tsv_file\"\n>>> table_csv_path = \"your_path_to_a_directory_containing_all_csv_files\"\n\n>>> class TableDataset:\n...     def __init__(self, data, tokenizer):\n...         self.data = data\n...         self.tokenizer = tokenizer\n\n...     def __iter__(self):\n...         for idx in range(self.__len__()):\n...             item = self.data.iloc[idx]\n...             table = pd.read_csv(table_csv_path + item.table_file).astype(\n...                 str\n...             )  # be sure to make your table data text only\n...             encoding = self.tokenizer(\n...                 table=table,\n...                 queries=item.question,\n...                 answer_coordinates=item.answer_coordinates,\n...                 answer_text=item.answer_text,\n...                 truncation=True,\n...                 padding=\"max_length\",\n...                 return_tensors=\"tf\",\n...             )\n...             # remove the batch dimension which the tokenizer adds by default\n...             encoding = {key: tf.squeeze(val, 0) for key, val in encoding.items()}\n...             # add the float_answer which is also required (weak supervision for aggregation case)\n...             encoding[\"float_answer\"] = tf.convert_to_tensor(item.float_answer, dtype=tf.float32)\n...             yield encoding[\"input_ids\"], encoding[\"attention_mask\"], encoding[\"numeric_values\"], encoding[\n...                 \"numeric_values_scale\"\n...             ], encoding[\"token_type_ids\"], encoding[\"labels\"], encoding[\"float_answer\"]\n\n...     def __len__(self):\n...         return len(self.data)\n\n>>> data = pd.read_csv(tsv_path, sep=\"\\t\")\n>>> train_dataset = TableDataset(data, tokenizer)\n>>> output_signature = (\n...     tf.TensorSpec(shape=(512,), dtype=tf.int32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.int32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.float32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.float32),\n...     tf.TensorSpec(shape=(512, 7), dtype=tf.int32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.int32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.float32),\n... )\n>>> train_dataloader = tf.data.Dataset.from_generator(train_dataset, output_signature=output_signature).batch(32)\n```", "```py\n>>> from transformers import TapasConfig, TapasForQuestionAnswering, AdamW\n\n>>> # this is the default WTQ configuration\n>>> config = TapasConfig(\n...     num_aggregation_labels=4,\n...     use_answer_as_supervision=True,\n...     answer_loss_cutoff=0.664694,\n...     cell_selection_preference=0.207951,\n...     huber_loss_delta=0.121194,\n...     init_cell_selection_weights_to_zero=True,\n...     select_one_column=True,\n...     allow_empty_column_selection=False,\n...     temperature=0.0352513,\n... )\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n\n>>> optimizer = AdamW(model.parameters(), lr=5e-5)\n\n>>> model.train()\n>>> for epoch in range(2):  # loop over the dataset multiple times\n...     for batch in train_dataloader:\n...         # get the inputs;\n...         input_ids = batch[\"input_ids\"]\n...         attention_mask = batch[\"attention_mask\"]\n...         token_type_ids = batch[\"token_type_ids\"]\n...         labels = batch[\"labels\"]\n...         numeric_values = batch[\"numeric_values\"]\n...         numeric_values_scale = batch[\"numeric_values_scale\"]\n...         float_answer = batch[\"float_answer\"]\n\n...         # zero the parameter gradients\n...         optimizer.zero_grad()\n\n...         # forward + backward + optimize\n...         outputs = model(\n...             input_ids=input_ids,\n...             attention_mask=attention_mask,\n...             token_type_ids=token_type_ids,\n...             labels=labels,\n...             numeric_values=numeric_values,\n...             numeric_values_scale=numeric_values_scale,\n...             float_answer=float_answer,\n...         )\n...         loss = outputs.loss\n...         loss.backward()\n...         optimizer.step()\n```", "```py\n>>> import tensorflow as tf\n>>> from transformers import TapasConfig, TFTapasForQuestionAnswering\n\n>>> # this is the default WTQ configuration\n>>> config = TapasConfig(\n...     num_aggregation_labels=4,\n...     use_answer_as_supervision=True,\n...     answer_loss_cutoff=0.664694,\n...     cell_selection_preference=0.207951,\n...     huber_loss_delta=0.121194,\n...     init_cell_selection_weights_to_zero=True,\n...     select_one_column=True,\n...     allow_empty_column_selection=False,\n...     temperature=0.0352513,\n... )\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n\n>>> optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n\n>>> for epoch in range(2):  # loop over the dataset multiple times\n...     for batch in train_dataloader:\n...         # get the inputs;\n...         input_ids = batch[0]\n...         attention_mask = batch[1]\n...         token_type_ids = batch[4]\n...         labels = batch[-1]\n...         numeric_values = batch[2]\n...         numeric_values_scale = batch[3]\n...         float_answer = batch[6]\n\n...         # forward + backward + optimize\n...         with tf.GradientTape() as tape:\n...             outputs = model(\n...                 input_ids=input_ids,\n...                 attention_mask=attention_mask,\n...                 token_type_ids=token_type_ids,\n...                 labels=labels,\n...                 numeric_values=numeric_values,\n...                 numeric_values_scale=numeric_values_scale,\n...                 float_answer=float_answer,\n...             )\n...         grads = tape.gradient(outputs.loss, model.trainable_weights)\n...         optimizer.apply_gradients(zip(grads, model.trainable_weights))\n```", "```py\n>>> from transformers import TapasTokenizer, TapasForQuestionAnswering\n>>> import pandas as pd\n\n>>> model_name = \"google/tapas-base-finetuned-wtq\"\n>>> model = TapasForQuestionAnswering.from_pretrained(model_name)\n>>> tokenizer = TapasTokenizer.from_pretrained(model_name)\n\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> queries = [\n...     \"What is the name of the first actor?\",\n...     \"How many movies has George Clooney played in?\",\n...     \"What is the total number of movies?\",\n... ]\n>>> table = pd.DataFrame.from_dict(data)\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n>>> predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n...     inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\n... )\n\n>>> # let's print out the results:\n>>> id2aggregation = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3: \"COUNT\"}\n>>> aggregation_predictions_string = [id2aggregation[x] for x in predicted_aggregation_indices]\n\n>>> answers = []\n>>> for coordinates in predicted_answer_coordinates:\n...     if len(coordinates) == 1:\n...         # only a single cell:\n...         answers.append(table.iat[coordinates[0]])\n...     else:\n...         # multiple cells\n...         cell_values = []\n...         for coordinate in coordinates:\n...             cell_values.append(table.iat[coordinate])\n...         answers.append(\", \".join(cell_values))\n\n>>> display(table)\n>>> print(\"\")\n>>> for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n...     print(query)\n...     if predicted_agg == \"NONE\":\n...         print(\"Predicted answer: \" + answer)\n...     else:\n...         print(\"Predicted answer: \" + predicted_agg + \" > \" + answer)\nWhat is the name of the first actor?\nPredicted answer: Brad Pitt\nHow many movies has George Clooney played in?\nPredicted answer: COUNT > 69\nWhat is the total number of movies?\nPredicted answer: SUM > 87, 53, 69\n```", "```py\n>>> from transformers import TapasTokenizer, TFTapasForQuestionAnswering\n>>> import pandas as pd\n\n>>> model_name = \"google/tapas-base-finetuned-wtq\"\n>>> model = TFTapasForQuestionAnswering.from_pretrained(model_name)\n>>> tokenizer = TapasTokenizer.from_pretrained(model_name)\n\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> queries = [\n...     \"What is the name of the first actor?\",\n...     \"How many movies has George Clooney played in?\",\n...     \"What is the total number of movies?\",\n... ]\n>>> table = pd.DataFrame.from_dict(data)\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"tf\")\n>>> outputs = model(**inputs)\n>>> predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n...     inputs, outputs.logits, outputs.logits_aggregation\n... )\n\n>>> # let's print out the results:\n>>> id2aggregation = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3: \"COUNT\"}\n>>> aggregation_predictions_string = [id2aggregation[x] for x in predicted_aggregation_indices]\n\n>>> answers = []\n>>> for coordinates in predicted_answer_coordinates:\n...     if len(coordinates) == 1:\n...         # only a single cell:\n...         answers.append(table.iat[coordinates[0]])\n...     else:\n...         # multiple cells\n...         cell_values = []\n...         for coordinate in coordinates:\n...             cell_values.append(table.iat[coordinate])\n...         answers.append(\", \".join(cell_values))\n\n>>> display(table)\n>>> print(\"\")\n>>> for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n...     print(query)\n...     if predicted_agg == \"NONE\":\n...         print(\"Predicted answer: \" + answer)\n...     else:\n...         print(\"Predicted answer: \" + predicted_agg + \" > \" + answer)\nWhat is the name of the first actor?\nPredicted answer: Brad Pitt\nHow many movies has George Clooney played in?\nPredicted answer: COUNT > 69\nWhat is the total number of movies?\nPredicted answer: SUM > 87, 53, 69\n```", "```py\n( loss: Optional = None logits: FloatTensor = None logits_aggregation: FloatTensor = None hidden_states: Optional = None attentions: Optional = None )\n```", "```py\n( vocab_size = 30522 hidden_size = 768 num_hidden_layers = 12 num_attention_heads = 12 intermediate_size = 3072 hidden_act = 'gelu' hidden_dropout_prob = 0.1 attention_probs_dropout_prob = 0.1 max_position_embeddings = 1024 type_vocab_sizes = [3, 256, 256, 2, 256, 256, 10] initializer_range = 0.02 layer_norm_eps = 1e-12 pad_token_id = 0 positive_label_weight = 10.0 num_aggregation_labels = 0 aggregation_loss_weight = 1.0 use_answer_as_supervision = None answer_loss_importance = 1.0 use_normalized_answer_loss = False huber_loss_delta = None temperature = 1.0 aggregation_temperature = 1.0 use_gumbel_for_cells = False use_gumbel_for_aggregation = False average_approximation_function = 'ratio' cell_selection_preference = None answer_loss_cutoff = None max_num_rows = 64 max_num_columns = 32 average_logits_per_cell = False select_one_column = True allow_empty_column_selection = False init_cell_selection_weights_to_zero = False reset_position_index_per_cell = True disable_per_token_loss = False aggregation_labels = None no_aggregation_label_index = None **kwargs )\n```", "```py\n>>> from transformers import TapasModel, TapasConfig\n\n>>> # Initializing a default (SQA) Tapas configuration\n>>> configuration = TapasConfig()\n>>> # Initializing a model from the configuration\n>>> model = TapasModel(configuration)\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( vocab_file do_lower_case = True do_basic_tokenize = True never_split = None unk_token = '[UNK]' sep_token = '[SEP]' pad_token = '[PAD]' cls_token = '[CLS]' mask_token = '[MASK]' empty_token = '[EMPTY]' tokenize_chinese_chars = True strip_accents = None cell_trim_length: int = -1 max_column_id: int = None max_row_id: int = None strip_column_names: bool = False update_answer_coordinates: bool = False min_question_length = None max_question_length = None model_max_length: int = 512 additional_special_tokens: Optional = None **kwargs )\n```", "```py\n( table: pd.DataFrame queries: Union = None answer_coordinates: Union = None answer_text: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = False max_length: Optional = None pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs )\n```", "```py\n( data logits logits_agg = None cell_classification_threshold = 0.5 ) \u2192 export const metadata = 'undefined';tuple comprising various elements depending on the inputs\n```", "```py\n( save_directory: str filename_prefix: Optional = None )\n```", "```py\n( config add_pooling_layer = True )\n```", "```py\n( input_ids: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None encoder_hidden_states: Optional = None encoder_attention_mask: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.BaseModelOutputWithPooling or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoTokenizer, TapasModel\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base\")\n>>> model = TapasModel.from_pretrained(\"google/tapas-base\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\"How many movies has George Clooney played in?\", \"How old is Brad Pitt?\"]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None encoder_hidden_states: Optional = None encoder_attention_mask: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None **kwargs ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.MaskedLMOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForMaskedLM\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base\")\n>>> model = TapasForMaskedLM.from_pretrained(\"google/tapas-base\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n\n>>> inputs = tokenizer(\n...     table=table, queries=\"How many [MASK] has George [MASK] played in?\", return_tensors=\"pt\"\n... )\n>>> labels = tokenizer(\n...     table=table, queries=\"How many movies has George Clooney played in?\", return_tensors=\"pt\"\n... )[\"input_ids\"]\n\n>>> outputs = model(**inputs, labels=labels)\n>>> logits = outputs.logits\n```", "```py\n( config )\n```", "```py\n( input_ids: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.SequenceClassifierOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForSequenceClassification\n>>> import torch\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-tabfact\")\n>>> model = TapasForSequenceClassification.from_pretrained(\"google/tapas-base-finetuned-tabfact\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\n...     \"There is only one actor who is 45 years old\",\n...     \"There are 3 actors which played in more than 60 movies\",\n... ]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n>>> labels = torch.tensor([1, 0])  # 1 means entailed, 0 means refuted\n\n>>> outputs = model(**inputs, labels=labels)\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n( config: TapasConfig )\n```", "```py\n( input_ids: Optional = None attention_mask: Optional = None token_type_ids: Optional = None position_ids: Optional = None head_mask: Optional = None inputs_embeds: Optional = None table_mask: Optional = None labels: Optional = None aggregation_labels: Optional = None float_answer: Optional = None numeric_values: Optional = None numeric_values_scale: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.tapas.modeling_tapas.TableQuestionAnsweringOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForQuestionAnswering\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\"How many movies has George Clooney played in?\", \"How old is Brad Pitt?\"]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> logits = outputs.logits\n>>> logits_aggregation = outputs.logits_aggregation\n```", "```py\n( config: TapasConfig *inputs **kwargs )\n```", "```py\n( input_ids: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None token_type_ids: np.ndarray | tf.Tensor | None = None position_ids: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: Optional[bool] = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoTokenizer, TapasModel\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base\")\n>>> model = TapasModel.from_pretrained(\"google/tapas-base\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\"How many movies has George Clooney played in?\", \"How old is Brad Pitt?\"]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"tf\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n( config: TapasConfig *inputs **kwargs )\n```", "```py\n( input_ids: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None token_type_ids: np.ndarray | tf.Tensor | None = None position_ids: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None labels: np.ndarray | tf.Tensor | None = None training: Optional[bool] = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFMaskedLMOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForMaskedLM\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base\")\n>>> model = TapasForMaskedLM.from_pretrained(\"google/tapas-base\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n\n>>> inputs = tokenizer(\n...     table=table, queries=\"How many [MASK] has George [MASK] played in?\", return_tensors=\"tf\"\n... )\n>>> labels = tokenizer(\n...     table=table, queries=\"How many movies has George Clooney played in?\", return_tensors=\"tf\"\n... )[\"input_ids\"]\n\n>>> outputs = model(**inputs, labels=labels)\n>>> logits = outputs.logits\n```", "```py\n( config: TapasConfig *inputs **kwargs )\n```", "```py\n( input_ids: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None token_type_ids: np.ndarray | tf.Tensor | None = None position_ids: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None labels: np.ndarray | tf.Tensor | None = None training: Optional[bool] = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFSequenceClassifierOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForSequenceClassification\n>>> import tensorflow as tf\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-tabfact\")\n>>> model = TapasForSequenceClassification.from_pretrained(\"google/tapas-base-finetuned-tabfact\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\n...     \"There is only one actor who is 45 years old\",\n...     \"There are 3 actors which played in more than 60 movies\",\n... ]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"tf\")\n>>> labels = tf.convert_to_tensor([1, 0])  # 1 means entailed, 0 means refuted\n\n>>> outputs = model(**inputs, labels=labels)\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n( config: TapasConfig *inputs **kwargs )\n```", "```py\n( input_ids: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None token_type_ids: np.ndarray | tf.Tensor | None = None position_ids: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None inputs_embeds: np.ndarray | tf.Tensor | None = None table_mask: np.ndarray | tf.Tensor | None = None aggregation_labels: np.ndarray | tf.Tensor | None = None float_answer: np.ndarray | tf.Tensor | None = None numeric_values: np.ndarray | tf.Tensor | None = None numeric_values_scale: np.ndarray | tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None labels: np.ndarray | tf.Tensor | None = None training: Optional[bool] = False ) \u2192 export const metadata = 'undefined';transformers.models.tapas.modeling_tf_tapas.TFTableQuestionAnsweringOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForQuestionAnswering\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\"How many movies has George Clooney played in?\", \"How old is Brad Pitt?\"]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"tf\")\n>>> outputs = model(**inputs)\n\n>>> logits = outputs.logits\n>>> logits_aggregation = outputs.logits_aggregation\n```"]