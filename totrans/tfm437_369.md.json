["```py\n>>> from transformers import TapasConfig, TapasForQuestionAnswering\n\n>>> # for example, the base sized model with default SQA configuration\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\")\n\n>>> # or, the base sized model with WTQ configuration\n>>> config = TapasConfig.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n\n>>> # or, the base sized model with WikiSQL configuration\n>>> config = TapasConfig(\"google-base-finetuned-wikisql-supervised\")\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n```", "```py\n>>> from transformers import TapasConfig, TapasForQuestionAnswering\n\n>>> # you can initialize the classification heads any way you want (see docs of TapasConfig)\n>>> config = TapasConfig(num_aggregation_labels=3, average_logits_per_cell=True)\n>>> # initializing the pre-trained base sized model with our custom classification heads\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n```", "```py\n>>> from transformers import TapasConfig, TFTapasForQuestionAnswering\n\n>>> # for example, the base sized model with default SQA configuration\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\")\n\n>>> # or, the base sized model with WTQ configuration\n>>> config = TapasConfig.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n\n>>> # or, the base sized model with WikiSQL configuration\n>>> config = TapasConfig(\"google-base-finetuned-wikisql-supervised\")\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n```", "```py\n>>> from transformers import TapasConfig, TFTapasForQuestionAnswering\n\n>>> # you can initialize the classification heads any way you want (see docs of TapasConfig)\n>>> config = TapasConfig(num_aggregation_labels=3, average_logits_per_cell=True)\n>>> # initializing the pre-trained base sized model with our custom classification heads\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n```", "```py\n>>> from transformers import TapasTokenizer\n>>> import pandas as pd\n\n>>> model_name = \"google/tapas-base\"\n>>> tokenizer = TapasTokenizer.from_pretrained(model_name)\n\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> queries = [\n...     \"What is the name of the first actor?\",\n...     \"How many movies has George Clooney played in?\",\n...     \"What is the total number of movies?\",\n... ]\n>>> answer_coordinates = [[(0, 0)], [(2, 1)], [(0, 1), (1, 1), (2, 1)]]\n>>> answer_text = [[\"Brad Pitt\"], [\"69\"], [\"209\"]]\n>>> table = pd.DataFrame.from_dict(data)\n>>> inputs = tokenizer(\n...     table=table,\n...     queries=queries,\n...     answer_coordinates=answer_coordinates,\n...     answer_text=answer_text,\n...     padding=\"max_length\",\n...     return_tensors=\"pt\",\n... )\n>>> inputs\n{'input_ids': tensor([[ ... ]]), 'attention_mask': tensor([[...]]), 'token_type_ids': tensor([[[...]]]),\n'numeric_values': tensor([[ ... ]]), 'numeric_values_scale: tensor([[ ... ]]), labels: tensor([[ ... ]])}\n```", "```py\n>>> import torch\n>>> import pandas as pd\n\n>>> tsv_path = \"your_path_to_the_tsv_file\"\n>>> table_csv_path = \"your_path_to_a_directory_containing_all_csv_files\"\n\n>>> class TableDataset(torch.utils.data.Dataset):\n...     def __init__(self, data, tokenizer):\n...         self.data = data\n...         self.tokenizer = tokenizer\n\n...     def __getitem__(self, idx):\n...         item = data.iloc[idx]\n...         table = pd.read_csv(table_csv_path + item.table_file).astype(\n...             str\n...         )  # be sure to make your table data text only\n...         encoding = self.tokenizer(\n...             table=table,\n...             queries=item.question,\n...             answer_coordinates=item.answer_coordinates,\n...             answer_text=item.answer_text,\n...             truncation=True,\n...             padding=\"max_length\",\n...             return_tensors=\"pt\",\n...         )\n...         # remove the batch dimension which the tokenizer adds by default\n...         encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n...         # add the float_answer which is also required (weak supervision for aggregation case)\n...         encoding[\"float_answer\"] = torch.tensor(item.float_answer)\n...         return encoding\n\n...     def __len__(self):\n...         return len(self.data)\n\n>>> data = pd.read_csv(tsv_path, sep=\"\\t\")\n>>> train_dataset = TableDataset(data, tokenizer)\n>>> train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n```", "```py\n>>> from transformers import TapasTokenizer\n>>> import pandas as pd\n\n>>> model_name = \"google/tapas-base\"\n>>> tokenizer = TapasTokenizer.from_pretrained(model_name)\n\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> queries = [\n...     \"What is the name of the first actor?\",\n...     \"How many movies has George Clooney played in?\",\n...     \"What is the total number of movies?\",\n... ]\n>>> answer_coordinates = [[(0, 0)], [(2, 1)], [(0, 1), (1, 1), (2, 1)]]\n>>> answer_text = [[\"Brad Pitt\"], [\"69\"], [\"209\"]]\n>>> table = pd.DataFrame.from_dict(data)\n>>> inputs = tokenizer(\n...     table=table,\n...     queries=queries,\n...     answer_coordinates=answer_coordinates,\n...     answer_text=answer_text,\n...     padding=\"max_length\",\n...     return_tensors=\"tf\",\n... )\n>>> inputs\n{'input_ids': tensor([[ ... ]]), 'attention_mask': tensor([[...]]), 'token_type_ids': tensor([[[...]]]),\n'numeric_values': tensor([[ ... ]]), 'numeric_values_scale: tensor([[ ... ]]), labels: tensor([[ ... ]])}\n```", "```py\n>>> import tensorflow as tf\n>>> import pandas as pd\n\n>>> tsv_path = \"your_path_to_the_tsv_file\"\n>>> table_csv_path = \"your_path_to_a_directory_containing_all_csv_files\"\n\n>>> class TableDataset:\n...     def __init__(self, data, tokenizer):\n...         self.data = data\n...         self.tokenizer = tokenizer\n\n...     def __iter__(self):\n...         for idx in range(self.__len__()):\n...             item = self.data.iloc[idx]\n...             table = pd.read_csv(table_csv_path + item.table_file).astype(\n...                 str\n...             )  # be sure to make your table data text only\n...             encoding = self.tokenizer(\n...                 table=table,\n...                 queries=item.question,\n...                 answer_coordinates=item.answer_coordinates,\n...                 answer_text=item.answer_text,\n...                 truncation=True,\n...                 padding=\"max_length\",\n...                 return_tensors=\"tf\",\n...             )\n...             # remove the batch dimension which the tokenizer adds by default\n...             encoding = {key: tf.squeeze(val, 0) for key, val in encoding.items()}\n...             # add the float_answer which is also required (weak supervision for aggregation case)\n...             encoding[\"float_answer\"] = tf.convert_to_tensor(item.float_answer, dtype=tf.float32)\n...             yield encoding[\"input_ids\"], encoding[\"attention_mask\"], encoding[\"numeric_values\"], encoding[\n...                 \"numeric_values_scale\"\n...             ], encoding[\"token_type_ids\"], encoding[\"labels\"], encoding[\"float_answer\"]\n\n...     def __len__(self):\n...         return len(self.data)\n\n>>> data = pd.read_csv(tsv_path, sep=\"\\t\")\n>>> train_dataset = TableDataset(data, tokenizer)\n>>> output_signature = (\n...     tf.TensorSpec(shape=(512,), dtype=tf.int32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.int32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.float32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.float32),\n...     tf.TensorSpec(shape=(512, 7), dtype=tf.int32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.int32),\n...     tf.TensorSpec(shape=(512,), dtype=tf.float32),\n... )\n>>> train_dataloader = tf.data.Dataset.from_generator(train_dataset, output_signature=output_signature).batch(32)\n```", "```py\n>>> from transformers import TapasConfig, TapasForQuestionAnswering, AdamW\n\n>>> # this is the default WTQ configuration\n>>> config = TapasConfig(\n...     num_aggregation_labels=4,\n...     use_answer_as_supervision=True,\n...     answer_loss_cutoff=0.664694,\n...     cell_selection_preference=0.207951,\n...     huber_loss_delta=0.121194,\n...     init_cell_selection_weights_to_zero=True,\n...     select_one_column=True,\n...     allow_empty_column_selection=False,\n...     temperature=0.0352513,\n... )\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n\n>>> optimizer = AdamW(model.parameters(), lr=5e-5)\n\n>>> model.train()\n>>> for epoch in range(2):  # loop over the dataset multiple times\n...     for batch in train_dataloader:\n...         # get the inputs;\n...         input_ids = batch[\"input_ids\"]\n...         attention_mask = batch[\"attention_mask\"]\n...         token_type_ids = batch[\"token_type_ids\"]\n...         labels = batch[\"labels\"]\n...         numeric_values = batch[\"numeric_values\"]\n...         numeric_values_scale = batch[\"numeric_values_scale\"]\n...         float_answer = batch[\"float_answer\"]\n\n...         # zero the parameter gradients\n...         optimizer.zero_grad()\n\n...         # forward + backward + optimize\n...         outputs = model(\n...             input_ids=input_ids,\n...             attention_mask=attention_mask,\n...             token_type_ids=token_type_ids,\n...             labels=labels,\n...             numeric_values=numeric_values,\n...             numeric_values_scale=numeric_values_scale,\n...             float_answer=float_answer,\n...         )\n...         loss = outputs.loss\n...         loss.backward()\n...         optimizer.step()\n```", "```py\n>>> import tensorflow as tf\n>>> from transformers import TapasConfig, TFTapasForQuestionAnswering\n\n>>> # this is the default WTQ configuration\n>>> config = TapasConfig(\n...     num_aggregation_labels=4,\n...     use_answer_as_supervision=True,\n...     answer_loss_cutoff=0.664694,\n...     cell_selection_preference=0.207951,\n...     huber_loss_delta=0.121194,\n...     init_cell_selection_weights_to_zero=True,\n...     select_one_column=True,\n...     allow_empty_column_selection=False,\n...     temperature=0.0352513,\n... )\n>>> model = TFTapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n\n>>> optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n\n>>> for epoch in range(2):  # loop over the dataset multiple times\n...     for batch in train_dataloader:\n...         # get the inputs;\n...         input_ids = batch[0]\n...         attention_mask = batch[1]\n...         token_type_ids = batch[4]\n...         labels = batch[-1]\n...         numeric_values = batch[2]\n...         numeric_values_scale = batch[3]\n...         float_answer = batch[6]\n\n...         # forward + backward + optimize\n...         with tf.GradientTape() as tape:\n...             outputs = model(\n...                 input_ids=input_ids,\n...                 attention_mask=attention_mask,\n...                 token_type_ids=token_type_ids,\n...                 labels=labels,\n...                 numeric_values=numeric_values,\n...                 numeric_values_scale=numeric_values_scale,\n...                 float_answer=float_answer,\n...             )\n...         grads = tape.gradient(outputs.loss, model.trainable_weights)\n...         optimizer.apply_gradients(zip(grads, model.trainable_weights))\n```", "```py\n>>> from transformers import TapasTokenizer, TapasForQuestionAnswering\n>>> import pandas as pd\n\n>>> model_name = \"google/tapas-base-finetuned-wtq\"\n>>> model = TapasForQuestionAnswering.from_pretrained(model_name)\n>>> tokenizer = TapasTokenizer.from_pretrained(model_name)\n\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> queries = [\n...     \"What is the name of the first actor?\",\n...     \"How many movies has George Clooney played in?\",\n...     \"What is the total number of movies?\",\n... ]\n>>> table = pd.DataFrame.from_dict(data)\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n>>> predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n...     inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\n... )\n\n>>> # let's print out the results:\n>>> id2aggregation = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3: \"COUNT\"}\n>>> aggregation_predictions_string = [id2aggregation[x] for x in predicted_aggregation_indices]\n\n>>> answers = []\n>>> for coordinates in predicted_answer_coordinates:\n...     if len(coordinates) == 1:\n...         # only a single cell:\n...         answers.append(table.iat[coordinates[0]])\n...     else:\n...         # multiple cells\n...         cell_values = []\n...         for coordinate in coordinates:\n...             cell_values.append(table.iat[coordinate])\n...         answers.append(\", \".join(cell_values))\n\n>>> display(table)\n>>> print(\"\")\n>>> for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n...     print(query)\n...     if predicted_agg == \"NONE\":\n...         print(\"Predicted answer: \" + answer)\n...     else:\n...         print(\"Predicted answer: \" + predicted_agg + \" > \" + answer)\nWhat is the name of the first actor?\nPredicted answer: Brad Pitt\nHow many movies has George Clooney played in?\nPredicted answer: COUNT > 69\nWhat is the total number of movies?\nPredicted answer: SUM > 87, 53, 69\n```", "```py\n>>> from transformers import TapasTokenizer, TFTapasForQuestionAnswering\n>>> import pandas as pd\n\n>>> model_name = \"google/tapas-base-finetuned-wtq\"\n>>> model = TFTapasForQuestionAnswering.from_pretrained(model_name)\n>>> tokenizer = TapasTokenizer.from_pretrained(model_name)\n\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> queries = [\n...     \"What is the name of the first actor?\",\n...     \"How many movies has George Clooney played in?\",\n...     \"What is the total number of movies?\",\n... ]\n>>> table = pd.DataFrame.from_dict(data)\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"tf\")\n>>> outputs = model(**inputs)\n>>> predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n...     inputs, outputs.logits, outputs.logits_aggregation\n... )\n\n>>> # let's print out the results:\n>>> id2aggregation = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3: \"COUNT\"}\n>>> aggregation_predictions_string = [id2aggregation[x] for x in predicted_aggregation_indices]\n\n>>> answers = []\n>>> for coordinates in predicted_answer_coordinates:\n...     if len(coordinates) == 1:\n...         # only a single cell:\n...         answers.append(table.iat[coordinates[0]])\n...     else:\n...         # multiple cells\n...         cell_values = []\n...         for coordinate in coordinates:\n...             cell_values.append(table.iat[coordinate])\n...         answers.append(\", \".join(cell_values))\n\n>>> display(table)\n>>> print(\"\")\n>>> for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n...     print(query)\n...     if predicted_agg == \"NONE\":\n...         print(\"Predicted answer: \" + answer)\n...     else:\n...         print(\"Predicted answer: \" + predicted_agg + \" > \" + answer)\nWhat is the name of the first actor?\nPredicted answer: Brad Pitt\nHow many movies has George Clooney played in?\nPredicted answer: COUNT > 69\nWhat is the total number of movies?\nPredicted answer: SUM > 87, 53, 69\n```", "```py\n>>> from transformers import TapasModel, TapasConfig\n\n>>> # Initializing a default (SQA) Tapas configuration\n>>> configuration = TapasConfig()\n>>> # Initializing a model from the configuration\n>>> model = TapasModel(configuration)\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import AutoTokenizer, TapasModel\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base\")\n>>> model = TapasModel.from_pretrained(\"google/tapas-base\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\"How many movies has George Clooney played in?\", \"How old is Brad Pitt?\"]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForMaskedLM\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base\")\n>>> model = TapasForMaskedLM.from_pretrained(\"google/tapas-base\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n\n>>> inputs = tokenizer(\n...     table=table, queries=\"How many [MASK] has George [MASK] played in?\", return_tensors=\"pt\"\n... )\n>>> labels = tokenizer(\n...     table=table, queries=\"How many movies has George Clooney played in?\", return_tensors=\"pt\"\n... )[\"input_ids\"]\n\n>>> outputs = model(**inputs, labels=labels)\n>>> logits = outputs.logits\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForSequenceClassification\n>>> import torch\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-tabfact\")\n>>> model = TapasForSequenceClassification.from_pretrained(\"google/tapas-base-finetuned-tabfact\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\n...     \"There is only one actor who is 45 years old\",\n...     \"There are 3 actors which played in more than 60 movies\",\n... ]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n>>> labels = torch.tensor([1, 0])  # 1 means entailed, 0 means refuted\n\n>>> outputs = model(**inputs, labels=labels)\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForQuestionAnswering\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\"How many movies has George Clooney played in?\", \"How old is Brad Pitt?\"]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> logits = outputs.logits\n>>> logits_aggregation = outputs.logits_aggregation\n```", "```py\n>>> from transformers import AutoTokenizer, TapasModel\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base\")\n>>> model = TapasModel.from_pretrained(\"google/tapas-base\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\"How many movies has George Clooney played in?\", \"How old is Brad Pitt?\"]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"tf\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForMaskedLM\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base\")\n>>> model = TapasForMaskedLM.from_pretrained(\"google/tapas-base\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n\n>>> inputs = tokenizer(\n...     table=table, queries=\"How many [MASK] has George [MASK] played in?\", return_tensors=\"tf\"\n... )\n>>> labels = tokenizer(\n...     table=table, queries=\"How many movies has George Clooney played in?\", return_tensors=\"tf\"\n... )[\"input_ids\"]\n\n>>> outputs = model(**inputs, labels=labels)\n>>> logits = outputs.logits\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForSequenceClassification\n>>> import tensorflow as tf\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-tabfact\")\n>>> model = TapasForSequenceClassification.from_pretrained(\"google/tapas-base-finetuned-tabfact\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\n...     \"There is only one actor who is 45 years old\",\n...     \"There are 3 actors which played in more than 60 movies\",\n... ]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"tf\")\n>>> labels = tf.convert_to_tensor([1, 0])  # 1 means entailed, 0 means refuted\n\n>>> outputs = model(**inputs, labels=labels)\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```", "```py\n>>> from transformers import AutoTokenizer, TapasForQuestionAnswering\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n\n>>> data = {\n...     \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n...     \"Age\": [\"56\", \"45\", \"59\"],\n...     \"Number of movies\": [\"87\", \"53\", \"69\"],\n... }\n>>> table = pd.DataFrame.from_dict(data)\n>>> queries = [\"How many movies has George Clooney played in?\", \"How old is Brad Pitt?\"]\n\n>>> inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"tf\")\n>>> outputs = model(**inputs)\n\n>>> logits = outputs.logits\n>>> logits_aggregation = outputs.logits_aggregation\n```"]