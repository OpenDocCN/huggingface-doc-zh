- en: Introduction to Q-Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/learn/deep-rl-course/unit2/introduction](https://huggingface.co/learn/deep-rl-course/unit2/introduction)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/deep-rl-course/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/start.c0547f01.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/scheduler.37c15a92.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/singletons.b4cd11ef.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.18351ede.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/paths.3cd722f3.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/app.41e0adab.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.7cb9c9b8.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/0.b906e680.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/26.5b5ab9d0.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Heading.d3928e2a.js">
  prefs: []
  type: TYPE_NORMAL
- en: '![Unit 2 thumbnail](../Images/0b9bbdbce6b297349ae6de9075b71340.png)'
  prefs: []
  type: TYPE_IMG
- en: In theÂ first unit of this class, we learned about Reinforcement Learning (RL),
    the RL process, and the different methods to solve an RL problem. We also **trained
    our first agents and uploaded them to the Hugging Face Hub.**
  prefs: []
  type: TYPE_NORMAL
- en: 'In this unit, weâ€™re going toÂ **dive deeper into one of the Reinforcement Learning
    methods: value-based methods**Â and study our first RL algorithm:Â **Q-Learning.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Weâ€™ll alsoÂ **implement our first RL agent from scratch**, a Q-Learning agent,
    and will train it in two environments:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Frozen-Lake-v1 (non-slippery version): where our agent will need toÂ **go from
    the starting state (S) to the goal state (G)**Â by walking only on frozen tiles
    (F) and avoiding holes (H).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'An autonomous taxi: where our agent will needÂ **to learn to navigate**Â a city
    toÂ **transport its passengers from point A to point B.**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Environments](../Images/10f0816329e6557bfe5cfedcbbc9c8e0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Concretely, we will:'
  prefs: []
  type: TYPE_NORMAL
- en: Learn about **value-based methods**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn about the **differences between Monte Carlo and Temporal Difference Learning**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Study and implement **our first RL algorithm**: Q-Learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This unit is **fundamental if you want to be able to work on Deep Q-Learning**:
    the first Deep RL algorithm that played Atari games and beat the human level on
    some of them (breakout, space invaders, etc).'
  prefs: []
  type: TYPE_NORMAL
- en: So letâ€™s get started! ðŸš€
  prefs: []
  type: TYPE_NORMAL
