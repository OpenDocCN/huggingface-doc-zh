# DDPMScheduler

> 原文链接：[`huggingface.co/docs/diffusers/api/schedulers/ddpm`](https://huggingface.co/docs/diffusers/api/schedulers/ddpm)

[去噪扩散概率模型](https://huggingface.co/papers/2006.11239)（DDPM）由 Jonathan Ho、Ajay Jain 和 Pieter Abbeel 提出了同名的基于扩散的模型。在 🤗 Diffusers 库的上下文中，DDPM 指的是论文中的离散去噪调度程序以及流水线。

论文摘要如下：

*我们使用扩散概率模型进行高质量图像合成，这是一类受非平衡热力学考虑启发的潜变量模型。我们通过根据扩散概率模型和使用 Langevin 动力学进行去噪得分匹配之间的新颖连接设计的加权变分界来训练，获得了最佳结果，我们的模型自然地采用了一种渐进的有损解压缩方案，可以解释为自回归解码的一般化。在无条件的 CIFAR10 数据集上，我们获得了 9.46 的 Inception 分数和 3.17 的最新 FID 分数。在 256x256 LSUN 上，我们获得了类似于 ProgressiveGAN 的样本质量。我们的实现可在 [此 https URL](https://github.com/hojonathanho/diffusion) 上找到。*

## DDPMScheduler

### `class diffusers.DDPMScheduler`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L129)

```py
( num_train_timesteps: int = 1000 beta_start: float = 0.0001 beta_end: float = 0.02 beta_schedule: str = 'linear' trained_betas: Union = None variance_type: str = 'fixed_small' clip_sample: bool = True prediction_type: str = 'epsilon' thresholding: bool = False dynamic_thresholding_ratio: float = 0.995 clip_sample_range: float = 1.0 sample_max_value: float = 1.0 timestep_spacing: str = 'leading' steps_offset: int = 0 rescale_betas_zero_snr: int = False )
```

参数

+   `num_train_timesteps` (`int`, 默认为 1000) — 训练模型的扩散步数。

+   `beta_start` (`float`, 默认为 0.0001) — 推断的起始 `beta` 值。

+   `beta_end` (`float`, 默认为 0.02) — 最终的 `beta` 值。

+   `beta_schedule` (`str`, 默认为 `"linear"`) — beta 计划，从 beta 范围到用于步进模型的一系列 beta 的映射。可选择 `linear`、`scaled_linear` 或 `squaredcos_cap_v2`。

+   `trained_betas` (`np.ndarray`, *可选*) — 一组 beta 数组，直接传递给构造函数，而不使用 `beta_start` 和 `beta_end`。

+   `variance_type` (`str`, 默认为 `"fixed_small"`) — 在向去噪样本添加噪声时剪切方差。可选择 `fixed_small`、`fixed_small_log`、`fixed_large`、`fixed_large_log`、`learned` 或 `learned_range`。

+   `clip_sample` (`bool`, 默认为 `True`) — 为了数值稳定性而剪切预测样本。

+   `clip_sample_range` (`float`, 默认为 1.0) — 样本剪切的最大幅度。仅在 `clip_sample=True` 时有效。

+   `prediction_type` (`str`, 默认为 `epsilon`, *可选*) — 调度器函数的预测类型；可以是 `epsilon`（预测扩散过程的噪声）、`sample`（直接预测有噪声的样本）或 `v_prediction`（参见[Imagen Video](https://imagen.research.google/video/paper.pdf)论文的第 2.4 节）。

+   `thresholding` (`bool`, 默认为 `False`) — 是否使用“动态阈值”方法。这不适用于稳定扩散等潜空间扩散模型。

+   `dynamic_thresholding_ratio` (`float`, 默认为 0.995) — 动态阈值方法的比率。仅在 `thresholding=True` 时有效。

+   `sample_max_value` (`float`, 默认为 1.0) — 动态阈值的阈值值。仅在 `thresholding=True` 时有效。

+   `timestep_spacing` (`str`, 默认为 `"leading"`) — 时间步长应该如何缩放。有关更多信息，请参考[Common Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891)的表 2。

+   `steps_offset` (`int`, 默认为 0) — 添加到推断步骤的偏移量。您可以使用 `offset=1` 和 `set_alpha_to_one=False` 的组合，使最后一步使用步骤 0 用于先前 alpha 产品，就像在 Stable Diffusion 中一样。

+   `rescale_betas_zero_snr`（默认为`False`的`bool`）- 是否重新缩放 beta 以使终端 SNR 为零。这使模型能够生成非常明亮和黑暗的样本，而不仅限于具有中等亮度的样本。与[`--offset_noise`](https://github.com/huggingface/diffusers/blob/74fd735eb073eb1d774b1ab4154a0876eb82f055/examples/dreambooth/train_dreambooth.py#L506) loosely 相关。

`DDPMScheduler`探索去噪得分匹配和朗之万动力学采样之间的联系。

此模型继承自 SchedulerMixin 和 ConfigMixin。检查超类文档以了解库为所有调度器实现的通用方法，例如加载和保存。

#### `scale_model_input`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L236)

```py
( sample: FloatTensor timestep: Optional = None ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample`（`torch.FloatTensor`）- 输入样本。

+   `timestep`（`int`，*可选*）- 扩散链中的当前时间步。

返回

`torch.FloatTensor`

一个经过缩放的输入样本。

确保与需要根据当前时间步缩放去噪模型输入的调度器可互换。

#### `set_timesteps`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L253)

```py
( num_inference_steps: Optional = None device: Union = None timesteps: Optional = None )
```

参数

+   `num_inference_steps`（`int`）- 使用预训练模型生成样本时使用的扩散步数。如果使用，则`timesteps`必须为`None`。

+   `device`（`str`或`torch.device`，*可选*）- 时间步应移动到的设备。如果为`None`，则不移动时间步。

+   `timesteps`（`List[int]`，*可选*）- 用于支持时间步之间任意间距的自定义时间步。如果为`None`，则使用时间步之间等距离的默认时间步间距策略。如果传递了`timesteps`，则`num_inference_steps`必须为`None`。

设置用于扩散链的离散时间步（在推理之前运行）。

#### `step`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L401)

```py
( model_output: FloatTensor timestep: int sample: FloatTensor generator = None return_dict: bool = True ) → export const metadata = 'undefined';DDPMSchedulerOutput or tuple
```

参数

+   `model_output`（`torch.FloatTensor`）- 从学习扩散模型的直接输出。

+   `timestep`（`float`）- 扩散链中的当前离散时间步。

+   `sample`（`torch.FloatTensor`）- 由扩散过程创建的样本的当前实例。

+   `generator`（`torch.Generator`，*可选*）- 随机数生成器。

+   `return_dict`（`bool`，*可选*，默认为`True`）- 是否返回 DDPMSchedulerOutput 或`tuple`。

返回

DDPMSchedulerOutput 或`tuple`

如果`return_dict`为`True`，则返回 DDPMSchedulerOutput，否则返回一个元组，其中第一个元素是样本张量。

通过反转 SDE 预测前一个时间步的样本。此函数从学习模型输出（通常是预测的噪声）传播扩散过程。

## DDPMSchedulerOutput

### `class diffusers.schedulers.scheduling_ddpm.DDPMSchedulerOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_ddpm.py#L30)

```py
( prev_sample: FloatTensor pred_original_sample: Optional = None )
```

参数

+   `prev_sample`（`torch.FloatTensor`，形状为`（batch_size，num_channels，height，width）`，用于图像）- 上一个时间步的计算样本`（x_{t-1}）`。`prev_sample`应该在去噪循环中作为下一个模型输入使用。

+   `pred_original_sample`（`torch.FloatTensor`，形状为`(batch_size, num_channels, height, width)`，用于图像）- 基于当前时间步的模型输出的预测去噪样本`(x_{0})`。`pred_original_sample`可用于预览进展或指导。

调度程序的`step`函数输出的输出类。
