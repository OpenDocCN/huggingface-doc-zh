["```py\nimport torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import load_image, make_image_grid\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16, use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n```", "```py\ninit_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\")\n```", "```py\nprompt = \"cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k\"\nimage = pipeline(prompt, image=init_image).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import make_image_grid, load_image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# prepare image\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png\"\ninit_image = load_image(url)\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import make_image_grid, load_image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# prepare image\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdxl-init.png\"\ninit_image = load_image(url)\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image, strength=0.5).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import make_image_grid, load_image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16, use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# prepare image\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png\"\ninit_image = load_image(url)\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import make_image_grid, load_image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# prepare image\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png\"\ninit_image = load_image(url)\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image, strength=0.8).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import make_image_grid, load_image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# prepare image\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png\"\ninit_image = load_image(url)\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image, guidance_scale=8.0).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import make_image_grid, load_image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# prepare image\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png\"\ninit_image = load_image(url)\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\nnegative_prompt = \"ugly, deformed, disfigured, poor details, bad anatomy\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, negative_prompt=negative_prompt, image=init_image).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nfrom diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image\nimport torch\nfrom diffusers.utils import make_image_grid\n\npipeline = AutoPipelineForText2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\ntext2image = pipeline(\"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\").images[0]\ntext2image\n```", "```py\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16, use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\nimage2image = pipeline(\"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\", image=text2image).images[0]\nmake_image_grid([text2image, image2image], rows=1, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import make_image_grid, load_image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# prepare image\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png\"\ninit_image = load_image(url)\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image, output_type=\"latent\").images[0]\n```", "```py\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"ogkalu/Comic-Diffusion\", torch_dtype=torch.float16\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# need to include the token \"charliebo artstyle\" in the prompt to use this checkpoint\nimage = pipeline(\"Astronaut in a jungle, charliebo artstyle\", image=image, output_type=\"latent\").images[0]\n```", "```py\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"kohbanye/pixel-art-style\", torch_dtype=torch.float16\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# need to include the token \"pixelartstyle\" in the prompt to use this checkpoint\nimage = pipeline(\"Astronaut in a jungle, pixelartstyle\", image=image).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)\n```", "```py\nimport torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import make_image_grid, load_image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\n# prepare image\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png\"\ninit_image = load_image(url)\n\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n\n# pass prompt and image to pipeline\nimage_1 = pipeline(prompt, image=init_image, output_type=\"latent\").images[0]\n```", "```py\nfrom diffusers import StableDiffusionLatentUpscalePipeline\n\nupscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(\n    \"stabilityai/sd-x2-latent-upscaler\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\nupscaler.enable_model_cpu_offload()\nupscaler.enable_xformers_memory_efficient_attention()\n\nimage_2 = upscaler(prompt, image=image_1, output_type=\"latent\").images[0]\n```", "```py\nfrom diffusers import StableDiffusionUpscalePipeline\n\nsuper_res = StableDiffusionUpscalePipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-x4-upscaler\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\nsuper_res.enable_model_cpu_offload()\nsuper_res.enable_xformers_memory_efficient_attention()\n\nimage_3 = super_res(prompt, image=image_2).images[0]\nmake_image_grid([init_image, image_3.resize((512, 512))], rows=1, cols=2)\n```", "```py\nfrom diffusers import AutoPipelineForImage2Image\nimport torch\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\nimage = pipeline(prompt_embeds=prompt_embeds, # generated from Compel\n    negative_prompt_embeds=negative_prompt_embeds, # generated from Compel\n    image=init_image,\n).images[0]\n```", "```py\nfrom diffusers.utils import load_image, make_image_grid\n\n# prepare image\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png\"\ninit_image = load_image(url)\ninit_image = init_image.resize((958, 960)) # resize to depth image dimensions\ndepth_image = load_image(\"https://huggingface.co/lllyasviel/control_v11f1p_sd15_depth/resolve/main/images/control.png\")\nmake_image_grid([init_image, depth_image], rows=1, cols=2)\n```", "```py\nfrom diffusers import ControlNetModel, AutoPipelineForImage2Image\nimport torch\n\ncontrolnet = ControlNetModel.from_pretrained(\"lllyasviel/control_v11f1p_sd15_depth\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True)\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n```", "```py\nprompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\nimage_control_net = pipeline(prompt, image=init_image, control_image=depth_image).images[0]\nmake_image_grid([init_image, depth_image, image_control_net], rows=1, cols=3)\n```", "```py\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"nitrosocke/elden-ring-diffusion\", torch_dtype=torch.float16,\n)\npipeline.enable_model_cpu_offload()\n# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\npipeline.enable_xformers_memory_efficient_attention()\n\nprompt = \"elden ring style astronaut in a jungle\" # include the token \"elden ring style\" in the prompt\nnegative_prompt = \"ugly, deformed, disfigured, poor details, bad anatomy\"\n\nimage_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image_control_net, strength=0.45, guidance_scale=10.5).images[0]\nmake_image_grid([init_image, depth_image, image_control_net, image_elden_ring], rows=2, cols=2)\n```", "```py\n+ pipeline.enable_model_cpu_offload()\n+ pipeline.enable_xformers_memory_efficient_attention()\n```", "```py\npipeline.unet = torch.compile(pipeline.unet, mode=\"reduce-overhead\", fullgraph=True)\n```"]