- en: Quickstart
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速入门
- en: 'Original text: [https://huggingface.co/docs/datasets/quickstart](https://huggingface.co/docs/datasets/quickstart)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/datasets/quickstart](https://huggingface.co/docs/datasets/quickstart)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This quickstart is intended for developers who are ready to dive into the code
    and see an example of how to integrate 🤗 Datasets into their model training workflow.
    If you’re a beginner, we recommend starting with our [tutorials](./tutorial),
    where you’ll get a more thorough introduction.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这个快速入门指南适用于准备深入代码并查看如何将🤗数据集集成到模型训练工作流程中的开发人员。如果您是初学者，我们建议从我们的[教程](./tutorial)开始，那里您将得到更全面的介绍。
- en: Each dataset is unique, and depending on the task, some datasets may require
    additional steps to prepare it for training. But you can always use 🤗 Datasets
    tools to load and process a dataset. The fastest and easiest way to get started
    is by loading an existing dataset from the [Hugging Face Hub](https://huggingface.co/datasets).
    There are thousands of datasets to choose from, spanning many tasks. Choose the
    type of dataset you want to work with, and let’s get started!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据集都是独特的，根据任务的不同，一些数据集可能需要额外的步骤来准备训练。但您始终可以使用🤗 数据集工具来加载和处理数据集。开始的最快最简单的方法是从[Hugging
    Face Hub](https://huggingface.co/datasets)加载现有数据集。有成千上万个数据集可供选择，涵盖许多任务。选择您想要处理的数据集类型，然后让我们开始吧！
- en: '[Audio'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[音频'
- en: Resample an audio dataset and get it ready for a model to classify what type
    of banking issue a speaker is calling about.](#audio) [Vision
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 对音频数据集进行重采样，并为模型准备好以分类说话者正在询问的银行问题类型。](#audio) [视觉
- en: Apply data augmentation to an image dataset and get it ready for a model to
    diagnose disease in bean plants.](#vision) [NLP
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对图像数据集应用数据增强，并为模型准备好以诊断豆类植物疾病。](#vision) [NLP
- en: Tokenize a dataset and get it ready for a model to determine whether a pair
    of sentences have the same meaning.](#nlp)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据集进行标记化处理，并为模型准备好以确定一对句子是否具有相同的含义。](#nlp)
- en: Check out [Chapter 5](https://huggingface.co/course/chapter5/1?fw=pt) of the
    Hugging Face course to learn more about other important topics such as loading
    remote or local datasets, tools for cleaning up a dataset, and creating your own
    dataset.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 [Hugging Face 课程](https://huggingface.co/course/chapter5/1?fw=pt) 的第 5 章，了解更多关于加载远程或本地数据集、清理数据集的工具以及创建自己的数据集等其他重要主题。
- en: 'Start by installing 🤗 Datasets:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先安装🤗 数据集：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '🤗 Datasets also support audio and image data formats:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 数据集还支持音频和图像数据格式：
- en: 'To work with audio datasets, install the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature:'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要处理音频数据集，请安装 [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    功能：
- en: '[PRE1]'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To work with image datasets, install the [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)
    feature:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要处理图像数据集，请安装 [Image](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Image)
    功能：
- en: '[PRE2]'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Besides 🤗 Datasets, make sure your preferred machine learning framework is
    installed:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 除了🤗 数据集之外，确保您喜欢的机器学习框架已安装：
- en: PytorchHide Pytorch content
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorch隐藏 Pytorch 内容
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: TensorFlowHide TensorFlow content
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow隐藏 TensorFlow 内容
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Audio
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音频
- en: Audio datasets are loaded just like text datasets. However, an audio dataset
    is preprocessed a bit differently. Instead of a tokenizer, you’ll need a [feature
    extractor](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor).
    An audio input may also require resampling its sampling rate to match the sampling
    rate of the pretrained model you’re using. In this quickstart, you’ll prepare
    the [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) dataset for a model
    train on and classify the banking issue a customer is having.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 音频数据集的加载方式与文本数据集相同。但是，音频数据集的预处理方式略有不同。您将需要一个 [特征提取器](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)
    而不是标记化器。音频输入可能还需要重新采样其采样率以匹配您正在使用的预训练模型的采样率。在这个快速入门中，您将准备[MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)
    数据集，用于训练模型并对客户遇到的银行问题进行分类。
- en: '**1**. Load the MInDS-14 dataset by providing the [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    function with the dataset name, dataset configuration (not all datasets will have
    a configuration), and a dataset split:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**. 通过向 [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    函数提供数据集名称、数据集配置（并非所有数据集都有配置）和数据集拆分来加载 MInDS-14 数据集：'
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**2**. Next, load a pretrained [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base)
    model and its corresponding feature extractor from the [🤗 Transformers](https://huggingface.co/transformers/)
    library. It is totally normal to see a warning after you load the model about
    some weights not being initialized. This is expected because you are loading this
    model checkpoint for training with another task.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**2**. 接下来，加载预训练的 [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base)
    模型及其对应的特征提取器，来自 [🤗 Transformers](https://huggingface.co/transformers/) 库。在加载模型后看到一些权重未初始化的警告是正常的。这是预期的，因为您正在加载此模型检查点以用于另一个任务的训练。'
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**3**. The [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) dataset
    card indicates the sampling rate is 8kHz, but the Wav2Vec2 model was pretrained
    on a sampling rate of 16kHZ. You’ll need to upsample the `audio` column with the
    [cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)
    function and [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature to match the model’s sampling rate.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**3**. [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) 数据集卡片显示采样率为
    8kHz，但 Wav2Vec2 模型是在 16kHZ 采样率上进行预训练的。您需要使用 [cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)
    函数和 [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    功能对 `audio` 列进行上采样，以匹配模型的采样率。'
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**4**. Create a function to preprocess the audio `array` with the feature extractor,
    and truncate and pad the sequences into tidy rectangular tensors. The most important
    thing to remember is to call the audio `array` in the feature extractor since
    the `array` - the actual speech signal - is the model input.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**4**. 创建一个函数，使用特征提取器预处理音频`array`，并将序列截断和填充为整洁的矩形张量。最重要的是要记住在特征提取器中调用音频`array`，因为`array`
    - 实际语音信号 - 是模型输入。'
- en: Once you have a preprocessing function, use the [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    function to speed up processing by applying the function to batches of examples
    in the dataset.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有一个预处理函数，使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)函数，通过将函数应用于数据集中的示例批次来加快处理速度。
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**5**. Use the [rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)
    function to rename the `intent_class` column to `labels`, which is the expected
    input name in [Wav2Vec2ForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**5**. 使用[rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)函数将`intent_class`列重命名为`labels`，这是[Wav2Vec2ForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)中预期的输入名称：'
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**6**. Set the dataset format according to the machine learning framework you’re
    using.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**6**. 根据您正在使用的机器学习框架设置数据集格式。'
- en: PytorchHide Pytorch content
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch content
- en: 'Use the [set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format)
    function to set the dataset format to `torch` and specify the columns you want
    to format. This function applies formatting on-the-fly. After converting to PyTorch
    tensors, wrap the dataset in [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format)函数将数据集格式设置为`torch`，并指定要格式化的列。此函数会实时应用格式。转换为PyTorch张量后，将数据集包装在[`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader)中：
- en: '[PRE10]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: TensorFlowHide TensorFlow content
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowHide TensorFlow content
- en: Use the [prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)
    method from 🤗 Transformers to prepare the dataset to be compatible with TensorFlow,
    and ready to train/fine-tune a model, as it wraps a HuggingFace [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    as a `tf.data.Dataset` with collation and batching, so one can pass it directly
    to Keras methods like `fit()` without further modification.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用🤗 Transformers的[prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)方法来准备数据集以与TensorFlow兼容，并准备好训练/微调模型，因为它将HuggingFace
    [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)包装为`tf.data.Dataset`，具有整理和批处理功能，因此可以直接将其传递给Keras方法，如`fit()`，无需进一步修改。
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**7**. Start training with your machine learning framework! Check out the 🤗
    Transformers [audio classification guide](https://huggingface.co/docs/transformers/tasks/audio_classification)
    for an end-to-end example of how to train a model on an audio dataset.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**7**. 使用您的机器学习框架开始训练！查看🤗 Transformers的[音频分类指南](https://huggingface.co/docs/transformers/tasks/audio_classification)
    ，了解如何在音频数据集上训练模型的端到端示例。'
- en: Vision
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视觉
- en: Image datasets are loaded just like text datasets. However, instead of a tokenizer,
    you’ll need a [feature extractor](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)
    to preprocess the dataset. Applying data augmentation to an image is common in
    computer vision to make the model more robust against overfitting. You’re free
    to use any data augmentation library you want, and then you can apply the augmentations
    with 🤗 Datasets. In this quickstart, you’ll load the [Beans](https://huggingface.co/datasets/beans)
    dataset and get it ready for the model to train on and identify disease from the
    leaf images.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图像数据集的加载方式与文本数据集相同。但是，您需要一个[特征提取器](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor)来预处理数据集，而不是一个分词器。在计算机视觉中对图像应用数据增强是常见的，以使模型更具抗过拟合能力。您可以自由选择任何数据增强库，然后可以使用🤗
    Datasets应用增强。在这个快速入门中，您将加载[Beans](https://huggingface.co/datasets/beans)数据集，并准备好让模型训练并从叶片图像中识别疾病。
- en: '**1**. Load the Beans dataset by providing the [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    function with the dataset name and a dataset split:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**. 通过提供数据集名称和数据集拆分，使用[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)函数加载Beans数据集：'
- en: '[PRE12]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**2**. Now you can add some data augmentations with any library ([Albumentations](https://albumentations.ai/),
    [imgaug](https://imgaug.readthedocs.io/en/latest/), [Kornia](https://kornia.readthedocs.io/en/latest/))
    you like. Here, you’ll use [torchvision](https://pytorch.org/vision/stable/transforms.html)
    to randomly change the color properties of an image:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**2**. 现在您可以使用任何库（[Albumentations](https://albumentations.ai/)、[imgaug](https://imgaug.readthedocs.io/en/latest/)、[Kornia](https://kornia.readthedocs.io/en/latest/)）添加一些数据增强。在这里，您将使用[torchvision](https://pytorch.org/vision/stable/transforms.html)随机更改图像的颜色属性：'
- en: '[PRE13]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**3**. Create a function to apply your transform to the dataset and generate
    the model input: `pixel_values`.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**3**. 创建一个函数，将您的转换应用于数据集并生成模型输入：`pixel_values`。'
- en: '[PRE14]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**4**. Use the [with_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_transform)
    function to apply the data augmentations on-the-fly:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**4**. 使用[with_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_transform)函数实时应用数据增强：'
- en: '[PRE15]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**5**. Set the dataset format according to the machine learning framework you’re
    using.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**5**. 根据您正在使用的机器学习框架设置数据集格式。'
- en: PytorchHide Pytorch content
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch content
- en: 'Wrap the dataset in [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader).
    You’ll also need to create a collate function to collate the samples into batches:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集包装在[`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader)中。您还需要创建一个整理函数，将样本整理成批次：
- en: '[PRE16]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: TensorFlowHide TensorFlow content
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowHide TensorFlow content
- en: Use the [prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)
    method from 🤗 Transformers to prepare the dataset to be compatible with TensorFlow,
    and ready to train/fine-tune a model, as it wraps a HuggingFace [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    as a `tf.data.Dataset` with collation and batching, so one can pass it directly
    to Keras methods like `fit()` without further modification.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用🤗 Transformers中的[prepare_tf_dataset](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset)方法来准备数据集以与TensorFlow兼容，并准备好训练/微调模型，因为它将HuggingFace的[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)包装为一个带有整理和批处理的`tf.data.Dataset`，因此可以直接将其传递给Keras方法，如`fit()`，而无需进一步修改。
- en: 'Before you start, make sure you have up-to-date versions of `albumentations`
    and `cv2` installed:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保已安装`albumentations`和`cv2`的最新版本：
- en: '[PRE17]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**6**. Start training with your machine learning framework! Check out the 🤗
    Transformers [image classification guide](https://huggingface.co/docs/transformers/tasks/image_classification)
    for an end-to-end example of how to train a model on an image dataset.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**6**. 使用您的机器学习框架开始训练！查看🤗 Transformers的[图像分类指南](https://huggingface.co/docs/transformers/tasks/image_classification)
    ，了解如何在图像数据集上训练模型的端到端示例。'
- en: NLP
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NLP
- en: Text needs to be tokenized into individual tokens by a [tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer).
    For the quickstart, you’ll load the [Microsoft Research Paraphrase Corpus (MRPC)](https://huggingface.co/datasets/glue/viewer/mrpc)
    training dataset to train a model to determine whether a pair of sentences mean
    the same thing.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 文本需要通过[分词器](https://huggingface.co/docs/transformers/main_classes/tokenizer)分词为单独的标记。在快速入门中，您将加载[Microsoft
    Research Paraphrase Corpus (MRPC)](https://huggingface.co/datasets/glue/viewer/mrpc)训练数据集，以训练模型来确定一对句子是否表示相同的含义。
- en: '**1**. Load the MRPC dataset by providing the [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    function with the dataset name, dataset configuration (not all datasets will have
    a configuration), and dataset split:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**. 通过向[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)函数提供数据集名称、数据集配置（并非所有数据集都有配置）和数据集拆分来加载MRPC数据集：'
- en: '[PRE19]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '**2**. Next, load a pretrained [BERT](https://huggingface.co/bert-base-uncased)
    model and its corresponding tokenizer from the [🤗 Transformers](https://huggingface.co/transformers/)
    library. It is totally normal to see a warning after you load the model about
    some weights not being initialized. This is expected because you are loading this
    model checkpoint for training with another task.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**2**. 接下来，从[🤗 Transformers](https://huggingface.co/transformers/)库中加载一个预训练的[BERT](https://huggingface.co/bert-base-uncased)模型及其对应的分词器。在加载模型后看到一些权重未初始化的警告是正常的。这是因为您正在加载此模型检查点以便用于另一个任务的训练。'
- en: '[PRE20]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '>>> def encode(examples):'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> def encode(examples):'
- en: '...     return tokenizer(examples["sentence1"], examples["sentence2"], truncation=True,
    padding="max_length")'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '...     return tokenizer(examples["sentence1"], examples["sentence2"], truncation=True,
    padding="max_length")'
- en: '>>> dataset = dataset.map(encode, batched=True)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataset = dataset.map(encode, batched=True)'
- en: '>>> dataset[0]'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataset[0]'
- en: '{''sentence1'': ''Amrozi accused his brother , whom he called " the witness
    " , of deliberately distorting his evidence .'','
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '{''sentence1'': ''Amrozi指控他的兄弟，称其为“证人”，故意歪曲证据。'','
- en: '''sentence2'': ''Referring to him as only " the witness " , Amrozi accused
    his brother of deliberately distorting his evidence .'','
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '''sentence2'': ''Amrozi指称他的兄弟为“证人”，指控他故意歪曲证据。'','
- en: '''label'': 1,'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '''label'': 1,'
- en: '''idx'': 0,'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '''idx'': 0,'
- en: '''input_ids'': array([  101,  7277,  2180,  5303,  4806,  1117,  1711,   117,  2292,
    1119,  1270,   107,  1103,  7737,   107,   117,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102,
    11336,  6732, 3384,  1106,  1140,  1112,  1178,   107,  1103,  7737,   107, 117,  7277,  2180,  5303,  4806,  1117,  1711,  1104,  9938,
    4267, 12223, 21811,  1117,  2554,   119,   102]),'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '''input_ids'': array([  101,  7277,  2180,  5303,  4806,  1117,  1711,   117,  2292,
    1119,  1270,   107,  1103,  7737,   107,   117,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102,
    11336,  6732, 3384,  1106,  1140,  1112,  1178,   107,  1103,  7737,   107, 117,  7277,  2180,  5303,  4806,  1117,  1711,  1104,  9938,
    4267, 12223, 21811,  1117,  2554,   119,   102]),'
- en: '''token_type_ids'': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '''token_type_ids'': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),'
- en: '''attention_mask'': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '''attention_mask'': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}'
- en: '[PRE21]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '>>> dataset = dataset.map(lambda examples: {"labels": examples["label"]}, batched=True)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataset = dataset.map(lambda examples: {"labels": examples["label"]}, batched=True)'
- en: '[PRE22]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '>>> import torch'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> import torch'
- en: '>>> dataset.set_format(type="torch", columns=["input_ids", "token_type_ids",
    "attention_mask", "labels"])'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataset.set_format(type="torch", columns=["input_ids", "token_type_ids",
    "attention_mask", "labels"])'
- en: '>>> dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)'
- en: '[PRE23]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '>>> import tensorflow as tf'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> import tensorflow as tf'
- en: '>>> tf_dataset = model.prepare_tf_dataset('
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> tf_dataset = model.prepare_tf_dataset('
- en: '...     dataset,'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '...     dataset,'
- en: '...     batch_size=4,'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '...     batch_size=4,'
- en: '...     shuffle=True,'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '...     shuffle=True,'
- en: '... )'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '... )'
- en: '[PRE24]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
