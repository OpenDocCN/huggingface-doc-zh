- en: DETA
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DETA
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deta](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deta)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deta](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deta)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The DETA model was proposed in [NMS Strikes Back](https://arxiv.org/abs/2212.06137)
    by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp Krähenbühl. DETA
    (short for Detection Transformers with Assignment) improves [Deformable DETR](deformable_detr)
    by replacing the one-to-one bipartite Hungarian matching loss with one-to-many
    label assignments used in traditional detectors with non-maximum suppression (NMS).
    This leads to significant gains of up to 2.5 mAP.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: DETA模型是由Jeffrey Ouyang-Zhang、Jang Hyun Cho、Xingyi Zhou、Philipp Krähenbühl在[NMS
    Strikes Back](https://arxiv.org/abs/2212.06137)中提出的。DETA（Detection Transformers
    with Assignment）通过将传统检测器中使用的一对一二部匹配损失替换为使用非极大值抑制（NMS）的一对多标签分配来改进[Deformable DETR](deformable_detr)，从而实现了高达2.5
    mAP的显着增益。
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*Detection Transformer (DETR) directly transforms queries to unique objects
    by using one-to-one bipartite matching during training and enables end-to-end
    object detection. Recently, these models have surpassed traditional detectors
    on COCO with undeniable elegance. However, they differ from traditional detectors
    in multiple designs, including model architecture and training schedules, and
    thus the effectiveness of one-to-one matching is not fully understood. In this
    work, we conduct a strict comparison between the one-to-one Hungarian matching
    in DETRs and the one-to-many label assignments in traditional detectors with non-maximum
    supervision (NMS). Surprisingly, we observe one-to-many assignments with NMS consistently
    outperform standard one-to-one matching under the same setting, with a significant
    gain of up to 2.5 mAP. Our detector that trains Deformable-DETR with traditional
    IoU-based label assignment achieved 50.2 COCO mAP within 12 epochs (1x schedule)
    with ResNet50 backbone, outperforming all existing traditional or transformer-based
    detectors in this setting. On multiple datasets, schedules, and architectures,
    we consistently show bipartite matching is unnecessary for performant detection
    transformers. Furthermore, we attribute the success of detection transformers
    to their expressive transformer architecture.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*检测变换器（DETR）在训练期间通过一对一的二部匹配直接将查询转换为唯一对象，并实现端到端的目标检测。最近，这些模型在COCO上超越了传统的检测器，具有不可否认的优雅。然而，它们在多个设计方面与传统检测器不同，包括模型架构和训练计划，因此一对一匹配的有效性尚未完全理解。在这项工作中，我们在DETR中进行了一项严格的比较，与传统检测器中的一对多标签分配相比，传统检测器使用非极大值抑制（NMS）。令人惊讶的是，我们观察到在相同设置下，NMS中的一对多分配始终优于标准的一对一匹配，获得了高达2.5
    mAP的显着增益。我们的检测器使用传统的IoU-based标签分配训练Deformable-DETR，在ResNet50骨干网络下在12个时期（1x计划）内实现了50.2的COCO
    mAP，优于此设置中的所有现有传统或基于变换器的检测器。在多个数据集、计划和架构上，我们始终表明二部匹配对于高性能检测变换器是不必要的。此外，我们将检测变换器的成功归因于其富有表现力的变换器架构。*'
- en: '![drawing](../Images/a8a832a7e12fee10abab0f5395417bf4.png) DETA overview. Taken
    from the [original paper](https://arxiv.org/abs/2212.06137).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![图示](../Images/a8a832a7e12fee10abab0f5395417bf4.png) DETA概述。摘自[原始论文](https://arxiv.org/abs/2212.06137)。'
- en: This model was contributed by [nielsr](https://huggingface.co/nielsr). The original
    code can be found [here](https://github.com/jozhang97/DETA).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[nielsr](https://huggingface.co/nielsr)贡献。原始代码可以在[这里](https://github.com/jozhang97/DETA)找到。
- en: Resources
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with DETA.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一个官方Hugging Face和社区（由🌎表示）资源列表，可帮助您开始使用DETA。
- en: Demo notebooks for DETA can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/DETA).
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DETA的演示笔记本可以在[这里](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/DETA)找到。
- en: 'See also: [Object detection task guide](../tasks/object_detection)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另请参阅：[目标检测任务指南](../tasks/object_detection)
- en: If you’re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and we’ll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣提交资源以包含在这里，请随时打开一个Pull Request，我们将进行审查！资源应该理想地展示一些新东西，而不是复制现有资源。
- en: DetaConfig
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DetaConfig
- en: '### `class transformers.DetaConfig`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DetaConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/configuration_deta.py#L30)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/configuration_deta.py#L30)'
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`backbone_config` (`PretrainedConfig` or `dict`, *optional*, defaults to `ResNetConfig()`)
    — The configuration of the backbone model.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone_config`（`PretrainedConfig`或`dict`，*可选*，默认为`ResNetConfig()`）—骨干模型的配置。'
- en: '`num_queries` (`int`, *optional*, defaults to 900) — Number of object queries,
    i.e. detection slots. This is the maximal number of objects [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)
    can detect in a single image. In case `two_stage` is set to `True`, we use `two_stage_num_proposals`
    instead.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_queries`（`int`，*可选*，默认为900）—对象查询的数量，即检测槽位。这是[DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)在单个图像中可以检测到的对象的最大数量。如果`two_stage`设置为`True`，则使用`two_stage_num_proposals`。'
- en: '`d_model` (`int`, *optional*, defaults to 256) — Dimension of the layers.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_model`（`int`，*可选*，默认为256）—层的维度。'
- en: '`encoder_layers` (`int`, *optional*, defaults to 6) — Number of encoder layers.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layers`（`int`，*可选*，默认为6）—编码器层数。'
- en: '`decoder_layers` (`int`, *optional*, defaults to 6) — Number of decoder layers.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers`（`int`，*可选*，默认为6）—解码器层数。'
- en: '`encoder_attention_heads` (`int`, *optional*, defaults to 8) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_heads`（`int`，*可选*，默认为8）—变换器编码器中每个注意力层的注意力头数。'
- en: '`decoder_attention_heads` (`int`, *optional*, defaults to 8) — Number of attention
    heads for each attention layer in the Transformer decoder.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_heads` (`int`, *optional*, defaults to 8) — Transformer解码器中每个注意力层的注意力头数。'
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 2048) — Dimension of the
    “intermediate” (often named feed-forward) layer in decoder.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ffn_dim` (`int`, *optional*, defaults to 2048) — 解码器中“中间”（通常称为前馈）层的维度。'
- en: '`encoder_ffn_dim` (`int`, *optional*, defaults to 2048) — Dimension of the
    “intermediate” (often named feed-forward) layer in decoder.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_ffn_dim` (`int`, *optional*, defaults to 2048) — 解码器中“中间”（通常称为前馈）层的维度。'
- en: '`activation_function` (`str` or `function`, *optional*, defaults to `"relu"`)
    — The non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_function` (`str` or `function`, *optional*, defaults to `"relu"`)
    — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，则支持`"gelu"`、`"relu"`、`"silu"`和`"gelu_new"`。'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, defaults to 0.1) — 嵌入、编码器和池化器中所有全连接层的dropout概率。'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for the attention probabilities.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — 注意力概率的dropout比率。'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for activations inside the fully connected layer.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — 全连接层内激活的dropout比率。'
- en: '`init_std` (`float`, *optional*, defaults to 0.02) — The standard deviation
    of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_std` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的truncated_normal_initializer的标准差。'
- en: '`init_xavier_std` (`float`, *optional*, defaults to 1) — The scaling factor
    used for the Xavier initialization gain in the HM Attention map module.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_xavier_std` (`float`, *optional*, defaults to 1) — 用于HM Attention map模块中Xavier初始化增益的缩放因子。'
- en: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.0) — The LayerDrop
    probability for the encoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.0) — 编码器的LayerDrop概率。有关更多详细信息，请参阅[LayerDrop
    paper](https://arxiv.org/abs/1909.11556)。'
- en: '`auxiliary_loss` (`bool`, *optional*, defaults to `False`) — Whether auxiliary
    decoding losses (loss at each decoder layer) are to be used.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auxiliary_loss` (`bool`, *optional*, defaults to `False`) — 是否使用辅助解码损失（每个解码器层的损失）。'
- en: '`position_embedding_type` (`str`, *optional*, defaults to `"sine"`) — Type
    of position embeddings to be used on top of the image features. One of `"sine"`
    or `"learned"`.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_embedding_type` (`str`, *optional*, defaults to `"sine"`) — 用于图像特征之上的位置嵌入的类型。可以是`"sine"`或`"learned"`之一。'
- en: '`class_cost` (`float`, *optional*, defaults to 1) — Relative weight of the
    classification error in the Hungarian matching cost.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_cost` (`float`, *optional*, defaults to 1) — 匈牙利匹配成本中分类错误的相对权重。'
- en: '`bbox_cost` (`float`, *optional*, defaults to 5) — Relative weight of the L1
    error of the bounding box coordinates in the Hungarian matching cost.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox_cost` (`float`, *optional*, defaults to 5) — 匈牙利匹配成本中边界框坐标的L1误差的相对权重。'
- en: '`giou_cost` (`float`, *optional*, defaults to 2) — Relative weight of the generalized
    IoU loss of the bounding box in the Hungarian matching cost.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`giou_cost` (`float`, *optional*, defaults to 2) — 匈牙利匹配成本中边界框广义IoU损失的相对权重。'
- en: '`mask_loss_coefficient` (`float`, *optional*, defaults to 1) — Relative weight
    of the Focal loss in the panoptic segmentation loss.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_loss_coefficient` (`float`, *optional*, defaults to 1) — Focal loss在全景分割损失中的相对权重。'
- en: '`dice_loss_coefficient` (`float`, *optional*, defaults to 1) — Relative weight
    of the DICE/F-1 loss in the panoptic segmentation loss.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dice_loss_coefficient` (`float`, *optional*, defaults to 1) — 全景分割损失中DICE/F-1损失的相对权重。'
- en: '`bbox_loss_coefficient` (`float`, *optional*, defaults to 5) — Relative weight
    of the L1 bounding box loss in the object detection loss.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bbox_loss_coefficient` (`float`, *optional*, defaults to 5) — 目标检测损失中L1边界框损失的相对权重。'
- en: '`giou_loss_coefficient` (`float`, *optional*, defaults to 2) — Relative weight
    of the generalized IoU loss in the object detection loss.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`giou_loss_coefficient` (`float`, *optional*, defaults to 2) — 目标检测损失中广义IoU损失的相对权重。'
- en: '`eos_coefficient` (`float`, *optional*, defaults to 0.1) — Relative classification
    weight of the ‘no-object’ class in the object detection loss.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_coefficient` (`float`, *optional*, defaults to 0.1) — 目标检测损失中“无对象”类的相对分类权重。'
- en: '`num_feature_levels` (`int`, *optional*, defaults to 5) — The number of input
    feature levels.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_feature_levels` (`int`, *optional*, defaults to 5) — 输入特征级别的数量。'
- en: '`encoder_n_points` (`int`, *optional*, defaults to 4) — The number of sampled
    keys in each feature level for each attention head in the encoder.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_n_points` (`int`, *optional*, defaults to 4) — 编码器中每个注意力头的每个特征级别中采样的键的数量。'
- en: '`decoder_n_points` (`int`, *optional*, defaults to 4) — The number of sampled
    keys in each feature level for each attention head in the decoder.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_n_points` (`int`, *optional*, defaults to 4) — 解码器中每个注意力头的每个特征级别中采样的键的数量。'
- en: '`two_stage` (`bool`, *optional*, defaults to `True`) — Whether to apply a two-stage
    deformable DETR, where the region proposals are also generated by a variant of
    DETA, which are further fed into the decoder for iterative bounding box refinement.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`two_stage` (`bool`, *optional*, defaults to `True`) — 是否应用两阶段可变形DETR，其中区域提议也是由DETA的变体生成的，然后进一步馈入解码器进行迭代边界框细化。'
- en: '`two_stage_num_proposals` (`int`, *optional*, defaults to 300) — The number
    of region proposals to be generated, in case `two_stage` is set to `True`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`two_stage_num_proposals` (`int`, *optional*, defaults to 300) — 要生成的区域提议数量，如果`two_stage`设置为`True`。'
- en: '`with_box_refine` (`bool`, *optional*, defaults to `True`) — Whether to apply
    iterative bounding box refinement, where each decoder layer refines the bounding
    boxes based on the predictions from the previous layer.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`with_box_refine` (`bool`, *optional*, defaults to `True`) — 是否应用迭代边界框细化，其中每个解码器层根据前一层的预测对边界框进行细化。'
- en: '`focal_alpha` (`float`, *optional*, defaults to 0.25) — Alpha parameter in
    the focal loss.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`focal_alpha` (`float`, *optional*, defaults to 0.25) — Focal loss 中的 Alpha
    参数。'
- en: '`assign_first_stage` (`bool`, *optional*, defaults to `True`) — Whether to
    assign each prediction i to the highest overlapping ground truth object if the
    overlap is larger than a threshold 0.7.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`assign_first_stage` (`bool`, *optional*, defaults to `True`) — 如果重叠大于阈值 0.7，则将每个预测
    i 分配给最高重叠的地面真实对象。'
- en: '`assign_second_stage` (`bool`, *optional*, defaults to `True`) — Whether to
    assign second assignment procedure in the second stage closely follows the first
    stage assignment procedure.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`assign_second_stage` (`bool`, *optional*, defaults to `True`) — 是否在第二阶段紧随第一阶段分配程序进行第二次分配。'
- en: This is the configuration class to store the configuration of a [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel).
    It is used to instantiate a DETA model according to the specified arguments, defining
    the model architecture. Instantiating a configuration with the defaults will yield
    a similar configuration to that of the DETA [SenseTime/deformable-detr](https://huggingface.co/SenseTime/deformable-detr)
    architecture.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个配置类，用于存储 [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)
    的配置。它用于根据指定的参数实例化一个 DETA 模型，定义模型架构。使用默认值实例化配置将产生与 DETA [SenseTime/deformable-detr](https://huggingface.co/SenseTime/deformable-detr)
    架构类似的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自 [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读来自
    [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    的文档以获取更多信息。
- en: 'Examples:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: DetaImageProcessor
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DetaImageProcessor
- en: '### `class transformers.DetaImageProcessor`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DetaImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/image_processing_deta.py#L465)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/image_processing_deta.py#L465)'
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`format` (`str`, *optional*, defaults to `"coco_detection"`) — Data format
    of the annotations. One of “coco_detection” or “coco_panoptic”.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`format` (`str`, *optional*, defaults to `"coco_detection"`) — 注释的数据格式。其中之一为“coco_detection”或“coco_panoptic”。'
- en: '`do_resize` (`bool`, *optional*, defaults to `True`) — Controls whether to
    resize the image’s (height, width) dimensions to the specified `size`. Can be
    overridden by the `do_resize` parameter in the `preprocess` method.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize` (`bool`, *optional*, defaults to `True`) — 控制是否将图像的（高度，宽度）尺寸调整为指定的
    `size`。可以被 `preprocess` 方法中的 `do_resize` 参数覆盖。'
- en: '`size` (`Dict[str, int]` *optional*, defaults to `{"shortest_edge" -- 800,
    "longest_edge": 1333}`): Size of the image’s (height, width) dimensions after
    resizing. Can be overridden by the `size` parameter in the `preprocess` method.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size` (`Dict[str, int]` *optional*, defaults to `{"shortest_edge" -- 800,
    "longest_edge": 1333}`): 调整大小后的图像（高度，宽度）尺寸。可以被 `preprocess` 方法中的 `size` 参数覆盖。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BILINEAR`)
    — Resampling filter to use if resizing the image.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample` (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BILINEAR`)
    — 如果调整图像大小，则使用的重采样滤波器。'
- en: '`do_rescale` (`bool`, *optional*, defaults to `True`) — Controls whether to
    rescale the image by the specified scale `rescale_factor`. Can be overridden by
    the `do_rescale` parameter in the `preprocess` method.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale` (`bool`, *optional*, defaults to `True`) — 控制是否按指定的比例 `rescale_factor`
    对图像进行重新缩放。可以被 `preprocess` 方法中的 `do_rescale` 参数覆盖。'
- en: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) — Scale
    factor to use if rescaling the image. Can be overridden by the `rescale_factor`
    parameter in the `preprocess` method. do_normalize — Controls whether to normalize
    the image. Can be overridden by the `do_normalize` parameter in the `preprocess`
    method.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor` (`int` or `float`, *optional*, defaults to `1/255`) — 如果重新缩放图像，则使用的比例因子。可以被
    `preprocess` 方法中的 `rescale_factor` 参数覆盖。 do_normalize — 控制是否对图像进行归一化。可以被 `preprocess`
    方法中的 `do_normalize` 参数覆盖。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_MEAN`)
    — Mean values to use when normalizing the image. Can be a single value or a list
    of values, one for each channel. Can be overridden by the `image_mean` parameter
    in the `preprocess` method.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_MEAN`)
    — 在归一化图像时使用的均值。可以是单个值或每个通道的值列表。可以被 `preprocess` 方法中的 `image_mean` 参数覆盖。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_STD`)
    — Standard deviation values to use when normalizing the image. Can be a single
    value or a list of values, one for each channel. Can be overridden by the `image_std`
    parameter in the `preprocess` method.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std` (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_STD`)
    — 在归一化图像时使用的标准差值。可以是单个值或每个通道的值列表。可以被 `preprocess` 方法中的 `image_std` 参数覆盖。'
- en: '`do_pad` (`bool`, *optional*, defaults to `True`) — Controls whether to pad
    the image to the largest image in a batch and create a pixel mask. Can be overridden
    by the `do_pad` parameter in the `preprocess` method.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad` (`bool`, *optional*, defaults to `True`) — 控制是否将图像填充到批处理中最大的图像并创建像素掩码。可以被
    `preprocess` 方法中的 `do_pad` 参数覆盖。'
- en: Constructs a Deformable DETR image processor.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个可变形 DETR 图像处理器。
- en: '#### `preprocess`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `preprocess`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/image_processing_deta.py#L771)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/image_processing_deta.py#L771)'
- en: '[PRE3]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images` (`ImageInput`) — Image or batch of images to preprocess. Expects a
    single or batch of images with pixel values ranging from 0 to 255\. If passing
    in images with pixel values between 0 and 1, set `do_rescale=False`.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images` (`ImageInput`) — 要预处理的图像或图像批处理。期望单个图像或像素值范围从 0 到 255 的图像批处理。如果传入像素值在
    0 到 1 之间的图像，请设置 `do_rescale=False`。'
- en: '`annotations` (`List[Dict]` or `List[List[Dict]]`, *optional*) — List of annotations
    associated with the image or batch of images. If annotation is for object detection,
    the annotations should be a dictionary with the following keys:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`annotations`（`List[Dict]`或`List[List[Dict]]`，*可选*）- 与图像或一批图像相关联的注释列表。如果注释用于目标检测，则注释应该是一个带有以下键的字典：'
- en: '“image_id” (`int`): The image id.'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “image_id”（`int`）：图像ID。
- en: '“annotations” (`List[Dict]`): List of annotations for an image. Each annotation
    should be a dictionary. An image can have no annotations, in which case the list
    should be empty. If annotation is for segmentation, the annotations should be
    a dictionary with the following keys:'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “annotations”（`List[Dict]`）：图像的注释列表。每个注释应该是一个字典。一个图像可能没有注释，此时列表应为空。如果注释用于分割，注释应该是一个带有以下键的字典：
- en: '“image_id” (`int`): The image id.'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “image_id”（`int`）：图像ID。
- en: '“segments_info” (`List[Dict]`): List of segments for an image. Each segment
    should be a dictionary. An image can have no segments, in which case the list
    should be empty.'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “segments_info”（`List[Dict]`）：图像的段列表。每个段应该是一个字典。一个图像可能没有段，此时列表应为空。
- en: '“file_name” (`str`): The file name of the image.'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “file_name”（`str`）：图像的文件名。
- en: '`return_segmentation_masks` (`bool`, *optional*, defaults to self.return_segmentation_masks)
    — Whether to return segmentation masks.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_segmentation_masks`（`bool`，*可选*，默认为self.return_segmentation_masks）-
    是否返回分割掩模。'
- en: '`masks_path` (`str` or `pathlib.Path`, *optional*) — Path to the directory
    containing the segmentation masks.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`masks_path`（`str`或`pathlib.Path`，*可选*）- 包含分割掩模的目录路径。'
- en: '`do_resize` (`bool`, *optional*, defaults to self.do_resize) — Whether to resize
    the image.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_resize`（`bool`，*可选*，默认为self.do_resize）- 是否调整图像大小。'
- en: '`size` (`Dict[str, int]`, *optional*, defaults to self.size) — Size of the
    image after resizing.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`（`Dict[str, int]`，*可选*，默认为self.size）- 调整大小后的图像大小。'
- en: '`resample` (`PILImageResampling`, *optional*, defaults to self.resample) —
    Resampling filter to use when resizing the image.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resample`（`PILImageResampling`，*可选*，默认为self.resample）- 调整图像大小时使用的重采样滤波器。'
- en: '`do_rescale` (`bool`, *optional*, defaults to self.do_rescale) — Whether to
    rescale the image.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_rescale`（`bool`，*可选*，默认为self.do_rescale）- 是否重新缩放图像。'
- en: '`rescale_factor` (`float`, *optional*, defaults to self.rescale_factor) — Rescale
    factor to use when rescaling the image.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale_factor`（`float`，*可选*，默认为self.rescale_factor）- 重新缩放图像时使用的重新缩放因子。'
- en: '`do_normalize` (`bool`, *optional*, defaults to self.do_normalize) — Whether
    to normalize the image.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize`（`bool`，*可选*，默认为self.do_normalize）- 是否对图像进行归一化。'
- en: '`image_mean` (`float` or `List[float]`, *optional*, defaults to self.image_mean)
    — Mean to use when normalizing the image.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_mean`（`float`或`List[float]`，*可选*，默认为self.image_mean）- 在归一化图像时使用的均值。'
- en: '`image_std` (`float` or `List[float]`, *optional*, defaults to self.image_std)
    — Standard deviation to use when normalizing the image.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_std`（`float`或`List[float]`，*可选*，默认为self.image_std）- 在归一化图像时使用的标准差。'
- en: '`do_pad` (`bool`, *optional*, defaults to self.do_pad) — Whether to pad the
    image.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_pad`（`bool`，*可选*，默认为self.do_pad）- 是否对图像进行填充。'
- en: '`format` (`str` or `AnnotationFormat`, *optional*, defaults to self.format)
    — Format of the annotations.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`format`（`str`或`AnnotationFormat`，*可选*，默认为self.format）- 注释的格式。'
- en: '`return_tensors` (`str` or `TensorType`, *optional*, defaults to self.return_tensors)
    — Type of tensors to return. If `None`, will return the list of images.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或`TensorType`，*可选*，默认为self.return_tensors）- 要返回的张量类型。如果为`None`，将返回图像列表。'
- en: '`data_format` (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`)
    — The channel dimension format for the output image. Can be one of:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format`（`ChannelDimension`或`str`，*可选*，默认为`ChannelDimension.FIRST`）- 输出图像的通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"`或`ChannelDimension.FIRST`：图像以（num_channels，height，width）格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"`或`ChannelDimension.LAST`：图像以（height，width，num_channels）格式。'
- en: 'Unset: Use the channel dimension format of the input image.'
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未设置：使用输入图像的通道维度格式。
- en: '`input_data_format` (`ChannelDimension` or `str`, *optional*) — The channel
    dimension format for the input image. If unset, the channel dimension format is
    inferred from the input image. Can be one of:'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data_format`（`ChannelDimension`或`str`，*可选*）- 输入图像的通道维度格式。如果未设置，将从输入图像中推断通道维度格式。可以是以下之一：'
- en: '`"channels_first"` or `ChannelDimension.FIRST`: image in (num_channels, height,
    width) format.'
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_first"`或`ChannelDimension.FIRST`：图像以（num_channels，height，width）格式。'
- en: '`"channels_last"` or `ChannelDimension.LAST`: image in (height, width, num_channels)
    format.'
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"channels_last"`或`ChannelDimension.LAST`：图像以（height，width，num_channels）格式。'
- en: '`"none"` or `ChannelDimension.NONE`: image in (height, width) format.'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"none"`或`ChannelDimension.NONE`：图像以（height，width）格式。'
- en: Preprocess an image or a batch of images so that it can be used by the model.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对图像或一批图像进行预处理，以便模型可以使用。
- en: '#### `post_process_object_detection`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post_process_object_detection`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/image_processing_deta.py#L993)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/image_processing_deta.py#L993)'
- en: '[PRE4]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`outputs` (`DetrObjectDetectionOutput`) — Raw outputs of the model.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs`（`DetrObjectDetectionOutput`）- 模型的原始输出。'
- en: '`threshold` (`float`, *optional*, defaults to 0.5) — Score threshold to keep
    object detection predictions.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold`（`float`，*可选*，默认为0.5）- 保留目标检测预测的分数阈值。'
- en: '`target_sizes` (`torch.Tensor` or `List[Tuple[int, int]]`, *optional*) — Tensor
    of shape `(batch_size, 2)` or list of tuples (`Tuple[int, int]`) containing the
    target size (height, width) of each image in the batch. If left to None, predictions
    will not be resized.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_sizes`（`torch.Tensor`或`List[Tuple[int, int]]`，*可选*）- 形状为`(batch_size,
    2)`的张量或包含每个图像批次中目标大小（高度，宽度）的元组列表（`Tuple[int, int]`）。如果设置为None，预测将不会被调整大小。'
- en: '`nms_threshold` (`float`, *optional*, defaults to 0.7) — NMS threshold.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nms_threshold`（`float`，*可选*，默认为0.7）- NMS阈值。'
- en: Returns
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: A list of dictionaries, each dictionary containing the scores, labels and boxes
    for an image in the batch as predicted by the model.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一个字典列表，每个字典包含模型预测的批次中图像的分数、标签和框。
- en: Converts the output of [DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)
    into final bounding boxes in (top_left_x, top_left_y, bottom_right_x, bottom_right_y)
    format. Only supports PyTorch.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 将[DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)的输出转换为最终的边界框，格式为(top_left_x,
    top_left_y, bottom_right_x, bottom_right_y)。仅支持PyTorch。
- en: DetaModel
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DetaModel
- en: '### `class transformers.DetaModel`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DetaModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/modeling_deta.py#L1345)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/modeling_deta.py#L1345)'
- en: '[PRE5]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig))
    — 模型配置类，包含模型的所有参数。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare DETA Model (consisting of a backbone and encoder-decoder Transformer)
    outputting raw hidden-states without any specific head on top.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的DETA模型（由骨干和编码器-解码器Transformer组成），输出原始隐藏状态，没有特定的头部。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型还是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/modeling_deta.py#L1515)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/modeling_deta.py#L1515)'
- en: '[PRE6]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Padding will be ignored by default should you provide
    it.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`) — 像素值。默认情况下将忽略填充。'
- en: Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See `AutoImageProcessor.__call__()` for details.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获得。有关详细信息，请参阅`AutoImageProcessor.__call__()`。
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask` (`torch.LongTensor`，形状为`(batch_size, height, width)`，*可选*) — 用于避免在填充像素值上执行注意力的掩码。掩码值选择在`[0,
    1]`范围内：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于真实像素（即`未屏蔽`）为1，
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于填充像素（即`屏蔽`）为0。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`,
    *optional*) — Not used by default. Can be used to mask object queries.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`torch.FloatTensor`，形状为`(batch_size, num_queries)`，*可选*)
    — 默认情况下不使用。可用于屏蔽对象查询。'
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *可选*) — 元组包含(`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`)
    `last_hidden_state`的形状为`(batch_size, sequence_length, hidden_size)`，*可选*) 是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing the flattened feature
    map (output of the backbone + projection layer), you can choose to directly pass
    a flattened representation of an image.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*)
    — 可选地，您可以选择直接传递图像的扁平化表示，而不是传递扁平化特征图（骨干网络和投影层的输出）。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — Optionally, instead of initializing the queries with
    a tensor of zeros, you can choose to directly pass an embedded representation.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size, num_queries,
    hidden_size)`，*可选*) — 可选地，您可以选择直接传递嵌入表示，而不是使用零张量初始化查询。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请查看返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: Returns
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '`transformers.models.deta.modeling_deta.DetaModelOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.deta.modeling_deta.DetaModelOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.deta.modeling_deta.DetaModelOutput` or a tuple of `torch.FloatTensor`
    (if `return_dict=False` is passed or when `config.return_dict=False`) comprising
    various elements depending on the configuration ([DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig))
    and inputs.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.deta.modeling_deta.DetaModelOutput`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包括根据配置（[DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)）和输入的不同元素。
- en: '`init_reference_points` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    4)`) — Initial reference points sent through the Transformer decoder.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_reference_points`（形状为`(batch_size, num_queries, 4)`的`torch.FloatTensor`）—
    通过Transformer解码器发送的初始参考点。'
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, num_queries, hidden_size)`的`torch.FloatTensor`）—
    模型解码器最后一层的隐藏状态序列。'
- en: '`intermediate_hidden_states` (`torch.FloatTensor` of shape `(batch_size, config.decoder_layers,
    num_queries, hidden_size)`) — Stacked intermediate hidden states (output of each
    layer of the decoder).'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_hidden_states`（形状为`(batch_size, config.decoder_layers, num_queries,
    hidden_size)`的`torch.FloatTensor`）— 堆叠的中间隐藏状态（解码器每层的输出）。'
- en: '`intermediate_reference_points` (`torch.FloatTensor` of shape `(batch_size,
    config.decoder_layers, num_queries, 4)`) — Stacked intermediate reference points
    (reference points of each layer of the decoder).'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_reference_points`（形状为`(batch_size, config.decoder_layers, num_queries,
    4)`的`torch.FloatTensor`）— 堆叠的中间参考点（解码器每层的参考点）。'
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, num_queries, hidden_size)`. Hidden-states
    of the decoder at the output of each layer plus the initial embedding outputs.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, num_queries, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出 +
    一个用于每层的输出）。解码器在每层输出的隐藏状态加上初始嵌入输出。'
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    num_queries, num_queries)`. Attentions weights of the decoder, after the attention
    softmax, used to compute the weighted average in the self-attention heads.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, num_queries, num_queries)`的`torch.FloatTensor`元组（每层一个）。解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。'
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_queries, num_heads, 4, 4)`. Attentions
    weights of the decoder’s cross-attention layer, after the attention softmax, used
    to compute the weighted average in the cross-attention heads.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_queries, num_heads, 4, 4)`的`torch.FloatTensor`元组（每层一个）。解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。'
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每层的输出）。编码器在每层输出的隐藏状态加上初始嵌入输出。'
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_queries,
    num_heads, 4, 4)`. Attentions weights of the encoder, after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_queries, num_heads, 4, 4)`的`torch.FloatTensor`元组（每层一个）。编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。'
- en: '`enc_outputs_class` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    config.num_labels)`, *optional*, returned when `config.with_box_refine=True` and
    `config.two_stage=True`) — Predicted bounding boxes scores where the top `config.two_stage_num_proposals`
    scoring bounding boxes are picked as region proposals in the first stage. Output
    of bounding box binary classification (i.e. foreground and background).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enc_outputs_class`（形状为`(batch_size, sequence_length, config.num_labels)`的`torch.FloatTensor`，*可选*，当`config.with_box_refine=True`和`config.two_stage=True`时返回）—
    预测的边界框分数，其中选择前`config.two_stage_num_proposals`个得分最高的边界框作为第一阶段的区域提议。边界框二元分类的输出（即前景和背景）。'
- en: '`enc_outputs_coord_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    4)`, *optional*, returned when `config.with_box_refine=True` and `config.two_stage=True`)
    — Logits of predicted bounding boxes coordinates in the first stage.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enc_outputs_coord_logits`（`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    4)`，*可选*，当`config.with_box_refine=True`和`config.two_stage=True`时返回）— 第一阶段中预测的边界框坐标的logits。'
- en: '`output_proposals` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    4)`, *optional*, returned when `config.two_stage=True`) — Logits of proposal bounding
    boxes coordinates in the gen_encoder_output_proposals.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_proposals`（`torch.FloatTensor`，形状为`(batch_size, sequence_length, 4)`，*可选*，当`config.two_stage=True`时返回）—
    在gen_encoder_output_proposals中提议边界框坐标的logits。'
- en: The [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)
    forward method, overrides the `__call__` special method.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)的前向方法覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: DetaForObjectDetection
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DetaForObjectDetection
- en: '### `class transformers.DetaForObjectDetection`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.DetaForObjectDetection`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/modeling_deta.py#L1762)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/modeling_deta.py#L1762)'
- en: '[PRE8]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)）—
    包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: DETA Model (consisting of a backbone and encoder-decoder Transformer) with object
    detection heads on top, for tasks such as COCO detection.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: DETA模型（由骨干和编码器-解码器Transformer组成），顶部带有目标检测头，用于诸如COCO检测之类的任务。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以了解库实现的所有模型的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/modeling_deta.py#L1827)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deta/modeling_deta.py#L1827)'
- en: '[PRE9]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Padding will be ignored by default should you provide
    it.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values`（`torch.FloatTensor`，形状为`(batch_size, num_channels, height, width)`）—
    像素值。默认情况下将忽略填充。'
- en: Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See `AutoImageProcessor.__call__()` for details.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获得。查看`AutoImageProcessor.__call__()`以获取详细信息。
- en: '`pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*)
    — Mask to avoid performing attention on padding pixel values. Mask values selected
    in `[0, 1]`:'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_mask`（`torch.LongTensor`，形状为`(batch_size, height, width)`，*可选*）— 用于避免在填充像素值上执行注意力的掩码。掩码值选在`[0,
    1]`之间：'
- en: 1 for pixels that are real (i.e. `not masked`),
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示真实像素（即`未被掩码`），
- en: 0 for pixels that are padding (i.e. `masked`).
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示填充像素（即`已掩码`）。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`,
    *optional*) — Not used by default. Can be used to mask object queries.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（`torch.FloatTensor`，形状为`(batch_size, num_queries)`，*可选*）—
    默认情况下不使用。可用于屏蔽对象查询。'
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs`（`tuple(tuple(torch.FloatTensor)`，*可选*）— 元组包含（`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`）`last_hidden_state`形状为`(batch_size,
    sequence_length, hidden_size)`，*可选*）是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing the flattened feature
    map (output of the backbone + projection layer), you can choose to directly pass
    a flattened representation of an image.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（`torch.FloatTensor`，形状为`(batch_size, sequence_length, hidden_size)`，*可选*）—
    可选地，可以直接传递图像的扁平特征图（骨干+投影层的输出），而不是传递图像的扁平表示。'
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — Optionally, instead of initializing the queries with
    a tensor of zeros, you can choose to directly pass an embedded representation.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — 可选，可以选择直接传递嵌入表示，而不是用零张量初始化查询。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`labels` (`List[Dict]` of len `(batch_size,)`, *optional*) — Labels for computing
    the bipartite matching loss. List of dicts, each dictionary containing at least
    the following 2 keys: ‘class_labels’ and ‘boxes’ (the class labels and bounding
    boxes of an image in the batch respectively). The class labels themselves should
    be a `torch.LongTensor` of len `(number of bounding boxes in the image,)` and
    the boxes a `torch.FloatTensor` of shape `(number of bounding boxes in the image,
    4)`.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`List[Dict]` of len `(batch_size,)`, *optional*) — 用于计算二分匹配损失的标签。字典列表，每个字典至少包含以下2个键：''class_labels''和''boxes''（分别是批处理中图像的类标签和边界框）。类标签本身应该是长度为`(图像中边界框数量,)`的`torch.LongTensor`，而边界框是形状为`(图像中边界框数量,
    4)`的`torch.FloatTensor`。'
- en: Returns
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.deta.modeling_deta.DetaObjectDetectionOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.deta.modeling_deta.DetaObjectDetectionOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.deta.modeling_deta.DetaObjectDetectionOutput` or a tuple
    of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig))
    and inputs.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.deta.modeling_deta.DetaObjectDetectionOutput`或`torch.FloatTensor`的元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包括各种元素，具体取决于配置（[DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)）和输入。'
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    are provided)) — Total loss as a linear combination of a negative log-likehood
    (cross-entropy) for class prediction and a bounding box loss. The latter is defined
    as a linear combination of the L1 loss and the generalized scale-invariant IoU
    loss.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) —
    总损失，作为负对数似然（交叉熵）和边界框损失的线性组合。后者被定义为L1损失和广义尺度不变IoU损失的线性组合。'
- en: '`loss_dict` (`Dict`, *optional*) — A dictionary containing the individual losses.
    Useful for logging.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss_dict` (`Dict`, *optional*) — 包含各个损失的字典。用于记录。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, num_queries, num_classes
    + 1)`) — Classification logits (including no-object) for all queries.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, num_queries, num_classes
    + 1)`) — 所有查询的分类logits（包括无对象）。'
- en: '`pred_boxes` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`)
    — Normalized boxes coordinates for all queries, represented as (center_x, center_y,
    width, height). These values are normalized in [0, 1], relative to the size of
    each individual image in the batch (disregarding possible padding). You can use
    `~DetaProcessor.post_process_object_detection` to retrieve the unnormalized bounding
    boxes.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pred_boxes` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`)
    — 所有查询的标准化框坐标，表示为（中心_x，中心_y，宽度，高度）。这些值在[0, 1]范围内标准化，相对于批处理中每个单独图像的大小（忽略可能的填充）。您可以使用`~DetaProcessor.post_process_object_detection`来检索未标准化的边界框。'
- en: '`auxiliary_outputs` (`list[Dict]`, *optional*) — Optional, only returned when
    auxilary losses are activated (i.e. `config.auxiliary_loss` is set to `True`)
    and labels are provided. It is a list of dictionaries containing the two above
    keys (`logits` and `pred_boxes`) for each decoder layer.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auxiliary_outputs` (`list[Dict]`, *optional*) — 可选，仅在辅助损失被激活时返回（即`config.auxiliary_loss`设置为`True`）并提供标签时返回。这是一个包含每个解码器层的上述两个键（`logits`和`pred_boxes`）的字典列表。'
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the decoder of the model.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    hidden_size)`, *optional*) — 模型解码器最后一层的隐藏状态序列的输出。'
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, num_queries, hidden_size)`. Hidden-states
    of the decoder at the output of each layer plus the initial embedding outputs.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_queries, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出
    + 一个用于每层的输出）。解码器在每层输出的隐藏状态加上初始嵌入输出。'
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    num_queries, num_queries)`. Attentions weights of the decoder, after the attention
    softmax, used to compute the weighted average in the self-attention heads.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, num_queries, num_queries)`的`torch.FloatTensor`元组（每层一个）。解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。'
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_queries, num_heads, 4, 4)`. Attentions
    weights of the decoder’s cross-attention layer, after the attention softmax, used
    to compute the weighted average in the cross-attention heads.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.
    Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, sequence_length,
    num_heads, 4, 4)`. Attentions weights of the encoder, after the attention softmax,
    used to compute the weighted average in the self-attention heads.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`intermediate_hidden_states` (`torch.FloatTensor` of shape `(batch_size, config.decoder_layers,
    num_queries, hidden_size)`) — Stacked intermediate hidden states (output of each
    layer of the decoder).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`intermediate_reference_points` (`torch.FloatTensor` of shape `(batch_size,
    config.decoder_layers, num_queries, 4)`) — Stacked intermediate reference points
    (reference points of each layer of the decoder).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`init_reference_points` (`torch.FloatTensor` of shape `(batch_size, num_queries,
    4)`) — Initial reference points sent through the Transformer decoder.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`enc_outputs_class` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    config.num_labels)`, *optional*, returned when `config.with_box_refine=True` and
    `config.two_stage=True`) — Predicted bounding boxes scores where the top `config.two_stage_num_proposals`
    scoring bounding boxes are picked as region proposals in the first stage. Output
    of bounding box binary classification (i.e. foreground and background).'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`enc_outputs_coord_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    4)`, *optional*, returned when `config.with_box_refine=True` and `config.two_stage=True`)
    — Logits of predicted bounding boxes coordinates in the first stage.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_proposals` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    4)`, *optional*, returned when `config.two_stage=True`) — Logits of proposal bounding
    boxes coordinates in the gen_encoder_output_proposals.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)
    forward method, overrides the `__call__` special method.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
