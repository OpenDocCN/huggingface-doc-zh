- en: Inferentia Exporter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/optimum-neuron/package_reference/export](https://huggingface.co/docs/optimum-neuron/package_reference/export)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/optimum.neuron/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/entry/start.abfe5599.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/scheduler.9039eef2.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/singletons.9144bb03.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/paths.e169ac99.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/entry/app.df8ec0a0.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/index.cdcc3d35.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/nodes/0.a52c6f40.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/nodes/16.d8cf3614.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/Tip.6f74db41.js">
    <link rel="modulepreload" href="/docs/optimum.neuron/main/en/_app/immutable/chunks/Heading.96ce3702.js">
  prefs: []
  type: TYPE_NORMAL
- en: You can export a PyTorch model to Neuron with ðŸ¤— Optimum to run inference on
    AWS [Inferntia 1](https://aws.amazon.com/ec2/instance-types/inf1/) and [Inferentia
    2](https://aws.amazon.com/ec2/instance-types/inf2/).
  prefs: []
  type: TYPE_NORMAL
- en: Export functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is an export function for each generation of the Inferentia accelerator,
    `export_neuron` for INF1 and `export_neuronx` on INF2, but you will be able to
    use directly the export function `export`, which will select the proper exporting
    function according to the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, you can check if the exported model is valid via `validate_model_outputs`,
    which compares the compiled modelâ€™s output on Neuron devices to the PyTorch modelâ€™s
    output on CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Supported architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Architecture | Task |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ALBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| BERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| BLOOM | text-generation |'
  prefs: []
  type: TYPE_TB
- en: '| CamemBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| ConvBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| DeBERTa (INF2 only) | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| DeBERTa-v2 (INF2 only) | feature-extraction, fill-mask, multiple-choice,
    question-answering, text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| DistilBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| ELECTRA | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| FlauBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| GPT2 | text-generation |'
  prefs: []
  type: TYPE_TB
- en: '| Llama, Llama 2 | text-generation |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral | text-generation |'
  prefs: []
  type: TYPE_TB
- en: '| MobileBERT | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| MPNet | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| OPT | text-generation |'
  prefs: []
  type: TYPE_TB
- en: '| RoBERTa | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| RoFormer | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| XLM | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| XLM-RoBERTa | feature-extraction, fill-mask, multiple-choice, question-answering,
    text-classification, token-classification |'
  prefs: []
  type: TYPE_TB
- en: '| Stable Diffusion | text-to-image, image-to-image, inpaint |'
  prefs: []
  type: TYPE_TB
- en: '| Stable Diffusion XL Base | text-to-image, image-to-image, inpaint |'
  prefs: []
  type: TYPE_TB
- en: '| Stable Diffusion XL Refiner | image-to-image, inpaint |'
  prefs: []
  type: TYPE_TB
- en: More details for checking supported tasks [here](https://huggingface.co/docs/optimum-neuron/guides/export_model#selecting-a-task).
  prefs: []
  type: TYPE_NORMAL
- en: More architectures coming soon, stay tuned! ðŸš€
  prefs: []
  type: TYPE_NORMAL
