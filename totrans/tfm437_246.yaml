- en: XLM-ProphetNet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[![Models](../Images/f8b81c134e491773ddd4f6059fa446e5.png)](https://huggingface.co/models?filter=xprophetnet)
    [![Spaces](../Images/61b85edcfdd50048184e2646e3f80d91.png)](https://huggingface.co/spaces/docs-demos/xprophetnet-large-wiki100-cased-xglue-ntg)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '**DISCLAIMER:** If you see something strange, file a [Github Issue](https://github.com/huggingface/transformers/issues/new?assignees=&labels=&template=bug-report.md&title)
    and assign @patrickvonplaten'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The XLM-ProphetNet model was proposed in [ProphetNet: Predicting Future N-gram
    for Sequence-to-Sequence Pre-training,](https://arxiv.org/abs/2001.04063) by Yu
    Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang,
    Ming Zhou on 13 Jan, 2020.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: XLM-ProphetNet is an encoder-decoder model and can predict n-future tokens for
    “ngram” language modeling instead of just the next token. Its architecture is
    identical to ProhpetNet, but the model was trained on the multi-lingual “wiki100”
    Wikipedia dump. XLM-ProphetNet’s model architecture and pretraining objective
    is same as ProphetNet, but XLM-ProphetNet was pre-trained on the cross-lingual
    dataset XGLUE.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '*In this paper, we present a new sequence-to-sequence pretraining model called
    ProphetNet, which introduces a novel self-supervised objective named future n-gram
    prediction and the proposed n-stream self-attention mechanism. Instead of the
    optimization of one-step ahead prediction in traditional sequence-to-sequence
    model, the ProphetNet is optimized by n-step ahead prediction which predicts the
    next n tokens simultaneously based on previous context tokens at each time step.
    The future n-gram prediction explicitly encourages the model to plan for the future
    tokens and prevent overfitting on strong local correlations. We pre-train ProphetNet
    using a base scale dataset (16GB) and a large scale dataset (160GB) respectively.
    Then we conduct experiments on CNN/DailyMail, Gigaword, and SQuAD 1.1 benchmarks
    for abstractive summarization and question generation tasks. Experimental results
    show that ProphetNet achieves new state-of-the-art results on all these datasets
    compared to the models using the same scale pretraining corpus.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: The Authors’ code can be found [here](https://github.com/microsoft/ProphetNet).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Causal language modeling task guide](../tasks/language_modeling)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Translation task guide](../tasks/translation)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Summarization task guide](../tasks/summarization)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XLMProphetNetConfig
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.XLMProphetNetConfig`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/configuration_xlm_prophetnet.py#L33)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.1) — The dropout ratio
    for activations inside the fully connected layer.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`activation_function` (`str` or `function`, *optional*, defaults to `"gelu"`)
    — The non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vocab_size` (`int`, *optional*, defaults to 30522) — Vocabulary size of the
    ProphetNET model. Defines the number of different tokens that can be represented
    by the `inputs_ids` passed when calling [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel).'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_size` (`int`, *optional*, defaults to 1024) — Dimensionality of the
    layers and the pooler layer.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_ffn_dim` (`int`, *optional*, defaults to 4096) — Dimensionality of
    the “intermediate” (often named feed-forward) layer in decoder.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_encoder_layers` (`int`, *optional*, defaults to 12) — Number of encoder
    layers.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_encoder_attention_heads` (`int`, *optional*, defaults to 16) — Number
    of attention heads for each attention layer in the Transformer encoder.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 4096) — Dimensionality of
    the `intermediate` (often named feed-forward) layer in decoder.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_decoder_layers` (`int`, *optional*, defaults to 12) — Number of decoder
    layers.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_decoder_attention_heads` (`int`, *optional*, defaults to 16) — Number
    of attention heads for each attention layer in the Transformer decoder.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.1) — The dropout ratio
    for the attention probabilities.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`init_std` (`float`, *optional*, defaults to 0.02) — The standard deviation
    of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`add_cross_attention` (`bool`, *optional*, defaults to `True`) — Whether cross-attention
    layers should be added to the model.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_encoder_decoder` (`bool`, *optional*, defaults to `True`) — Whether this
    is an encoder/decoder model.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pad_token_id` (`int`, *optional*, defaults to 1) — Padding token id.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bos_token_id` (`int`, *optional*, defaults to 0) — Beginning of stream token
    id.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eos_token_id` (`int`, *optional*, defaults to 2) — End of stream token id.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ngram` (`int`, *optional*, defaults to 2) — Number of future tokens to predict.
    Set to 1 to be same as traditional Language model to predict next first token.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_buckets` (`int`, *optional*, defaults to 32) — The number of buckets to
    use for each attention layer. This is for relative position calculation. See the
    [T5 paper](see [https://arxiv.org/abs/1910.10683](https://arxiv.org/abs/1910.10683))
    for more details.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`relative_max_distance` (`int`, *optional*, defaults to 128) — Relative distances
    greater than this number will be put into the last same bucket. This is for relative
    position calculation. See the [T5 paper](see [https://arxiv.org/abs/1910.10683](https://arxiv.org/abs/1910.10683))
    for more details.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`disable_ngram_loss` (`bool`, *optional*, defaults to `False`) — Whether be
    trained predicting only the next first token.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eps` (`float`, *optional*, defaults to 0.0) — Controls the `epsilon` parameter
    value for label smoothing in the loss calculation. If set to 0, no label smoothing
    is performed.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the configuration class to store the configuration of a [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel).
    It is used to instantiate a XLMProphetNet model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the XLMProphetNet [microsoft/xprophetnet-large-wiki100-cased](https://huggingface.co/microsoft/xprophetnet-large-wiki100-cased)
    architecture.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: XLMProphetNetTokenizer
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.XLMProphetNetTokenizer`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L59)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab_file` (`str`) — Path to the vocabulary file.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bos_token` (`str`, *optional*, defaults to `"[SEP]"`) — The beginning of sequence
    token that was used during pretraining. Can be used a sequence classifier token.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token` (`str`, *可选*, 默认为 `"[SEP]"`) — 在预训练期间使用的序列开始标记。可用作序列分类器标记。'
- en: When building a sequence using special tokens, this is not the token that is
    used for the beginning of sequence. The token used is the `cls_token`.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在使用特殊标记构建序列时，这不是用于表示序列开始的标记。用于表示序列开始的标记是 `cls_token`。
- en: '`eos_token` (`str`, *optional*, defaults to `"[SEP]"`) — The end of sequence
    token.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token` (`str`, *可选*, 默认为 `"[SEP]"`) — 序列结束标记。'
- en: When building a sequence using special tokens, this is not the token that is
    used for the end of sequence. The token used is the `sep_token`.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在使用特殊标记构建序列时，这不是用于表示序列结束的标记。用于表示序列结束的标记是 `sep_token`。
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token` (`str`, *可选*, 默认为 `"[SEP]"`) — 分隔符标记，在从多个序列构建序列时使用，例如用于序列分类的两个序列或用于问答的文本和问题。也用作使用特殊标记构建的序列的最后一个标记。'
- en: '`unk_token` (`str`, *optional*, defaults to `"[UNK]"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token` (`str`, *可选*, 默认为 `"[UNK]"`) — 未知标记。词汇表中不存在的标记无法转换为ID，而是设置为此标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"[PAD]"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *可选*, 默认为 `"[PAD]"`) — 用于填充的标记，例如在对不同长度的序列进行批处理时使用。'
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token` (`str`, *可选*, 默认为 `"[CLS]"`) — 用于进行序列分类（整个序列的分类，而不是每个标记的分类）时使用的分类器标记。在使用特殊标记构建时，它是序列的第一个标记。'
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token` (`str`, *可选*, 默认为 `"[MASK]"`) — 用于屏蔽值的标记。在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。'
- en: '`sp_model_kwargs` (`dict`, *optional*) — Will be passed to the `SentencePieceProcessor.__init__()`
    method. The [Python wrapper for SentencePiece](https://github.com/google/sentencepiece/tree/master/python)
    can be used, among other things, to set:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sp_model_kwargs` (`dict`, *可选*) — 将传递给 `SentencePieceProcessor.__init__()`
    方法。[SentencePiece的Python封装](https://github.com/google/sentencepiece/tree/master/python)可用于设置以下内容之一：'
- en: '`enable_sampling`: Enable subword regularization.'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enable_sampling`: 启用子词正则化。'
- en: '`nbest_size`: Sampling parameters for unigram. Invalid for BPE-Dropout.'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size`: 用于unigram的采样参数。对于BPE-Dropout无效。'
- en: '`nbest_size = {0,1}`: No sampling is performed.'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size = {0,1}`: 不执行采样。'
- en: '`nbest_size > 1`: samples from the nbest_size results.'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size > 1`: 从nbest_size结果中进行采样。'
- en: '`nbest_size < 0`: assuming that nbest_size is infinite and samples from the
    all hypothesis (lattice) using forward-filtering-and-backward-sampling algorithm.'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size < 0`: 假设nbest_size为无限，并使用前向过滤和后向采样算法从所有假设（格）中进行采样。'
- en: '`alpha`: Smoothing parameter for unigram sampling, and dropout probability
    of merge operations for BPE-dropout.'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`: 用于unigram采样的平滑参数，以及用于BPE-dropout合并操作的dropout概率。'
- en: '`sp_model` (`SentencePieceProcessor`) — The *SentencePiece* processor that
    is used for every conversion (string, tokens and IDs).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sp_model` (`SentencePieceProcessor`) — 用于每次转换（字符串、标记和ID）的*SentencePiece*处理器。'
- en: Adapted from [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    and [XLNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizer).
    Based on [SentencePiece](https://github.com/google/sentencepiece).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 改编自[RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)和[XLNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizer)。基于[SentencePiece](https://github.com/google/sentencepiece)。
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此标记器继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L318)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L318)'
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs to which the special tokens will
    be added'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0` (`List[int]`) — 将添加特殊标记的ID列表'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1` (`List[int]`, *可选*) — 序列对的可选第二个ID列表。'
- en: Returns
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: list of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 包含适当特殊标记的[input IDs](../glossary#input-ids)列表。
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. A XLMProphetNet sequence has
    the following format:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通过连接和添加特殊标记，从序列或序列对构建用于序列分类任务的模型输入。XLMProphetNet序列的格式如下：
- en: 'single sequence: `X [SEP]`'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个序列：`X [SEP]`
- en: 'pair of sequences: `A [SEP] B [SEP]`'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列对：`A [SEP] B [SEP]`
- en: '#### `convert_tokens_to_string`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `convert_tokens_to_string`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L296)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L296)'
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Converts a sequence of tokens (strings for sub-words) in a single string.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L245)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: List of zeros.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. XLMProphetNet does not make use of token type ids, therefore a list of zeros
    is returned.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_special_tokens_mask`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py#L217)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '`List[int]`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: XLMProphetNetModel
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.XLMProphetNetModel`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L1747)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bare XLMProphetNet Model outputting raw hidden-states without any specific
    head on top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Original ProphetNet code can be found [here](https://github.com/microsoft/ProphetNet).
    Checkpoints were converted from original Fairseq checkpoints. For more information
    on the checkpoint conversion, please take a look at the file `convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matters related to general usage and behavior.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L1791)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: XLMProphetNet uses the `eos_token_id` as the starting token for `decoder_input_ids`
    generation. If `past_key_values` is used, optionally only the last `decoder_input_ids`
    have to be input (see `past_key_values`).
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) — Contains precomputed key and value hidden-states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetSeq2SeqModelOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetSeq2SeqModelOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    and inputs.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetSeq2SeqModelOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)）和输入而异的各种元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, decoder_sequence_length,
    hidden_size)`) — Sequence of main stream hidden-states at the output of the last
    layer of the decoder of the model.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, decoder_sequence_length,
    hidden_size)`) — 模型解码器最后一层的主流隐藏状态序列。'
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，则只输出形状为`(batch_size, 1, hidden_size)`的序列的最后一个隐藏状态。
- en: '`last_hidden_state_ngram` (`torch.FloatTensor` of shape `(batch_size,ngram
    * decoder_sequence_length, config.vocab_size)`, *optional*) — Sequence of predict
    stream hidden-states at the output of the last layer of the decoder of the model.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state_ngram` (`torch.FloatTensor`，形状为`(batch_size,ngram * decoder_sequence_length,
    config.vocab_size)`，*optional*) — 模型解码器最后一层的预测流隐藏状态序列。'
- en: '`past_key_values` (`List[torch.FloatTensor]`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — List of `torch.FloatTensor` of length
    `config.n_layers`, with each tensor of shape `(2, batch_size, num_attn_heads,
    decoder_sequence_length, embed_size_per_head)`).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`List[torch.FloatTensor]`，*optional*，当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`torch.FloatTensor`列表，每个张量的形状为`(2, batch_size, num_attn_heads,
    decoder_sequence_length, embed_size_per_head)`。'
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    of the decoder that can be used (see `past_key_values` input) to speed up sequential
    decoding.
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含解码器的预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, decoder_sequence_length, hidden_size)`.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, decoder_sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of main stream of the decoder at the output of each layer plus
    the initial embedding outputs.
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器主流的隐藏状态，在每一层的输出以及初始嵌入输出。
- en: '`decoder_ngram_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, ngram * decoder_sequence_length,
    hidden_size)`.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ngram_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, ngram * decoder_sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the predict stream of the decoder at the output of each layer
    plus the initial embedding outputs.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器预测流的隐藏状态，在每一层的输出以及初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_attn_heads,
    decoder_sequence_length, decoder_sequence_length)`.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_attn_heads, decoder_sequence_length, decoder_sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`decoder_ngram_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_attentions=True` is passed or when `config.output_attentions=True`)
    — Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_attn_heads,
    decoder_sequence_length, decoder_sequence_length)`.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ngram_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_attn_heads, decoder_sequence_length, decoder_sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the predict stream of the decoder, after the attention
    softmax, used to compute the weighted average in the
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器预测流的注意力权重，在注意力softmax之后，用于计算加权平均值
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_attn_heads, encoder_sequence_length,
    decoder_sequence_length)`.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_attn_heads, encoder_sequence_length, decoder_sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the cross-attention layer of the decoder, after the attention
    softmax, used to compute the weighted average in the
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算加权平均值
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, encoder_sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, encoder_sequence_length,
    hidden_size)`，*optional*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, encoder_sequence_length, hidden_size)`.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_attn_heads,
    encoder_sequence_length, encoder_sequence_length)`.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: XLMProphetNetEncoder
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.XLMProphetNetEncoder`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L1243)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The standalone encoder part of the XLMProphetNetModel. This model inherits from
    [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Original ProphetNet code can be found [here](https://github.com/microsoft/ProphetNet).
    Checkpoints were converted from original Fairseq checkpoints. For more information
    on the checkpoint conversion, please take a look at the file `convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py`.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matters related to general usage and behavior.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'word_embeddings (`torch.nn.Embeddings` of shape `(config.vocab_size, config.hidden_size)`,
    *optional*): The word embedding parameters. This can be used to initialize [XLMProphetNetEncoder](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetEncoder)
    with pre-defined word embeddings instead of randomly initialized word embeddings.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L1278)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 用于避免在填充令牌索引上执行注意力的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 代表未被`masked`的标记，
- en: 0 for tokens that are `masked`.
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 代表被`masked`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — 用于使编码器中注意力模块的选定头部失效的掩码。掩码值选在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被`masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 indicates the head is `masked`.
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: Returns
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    and inputs.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含根据配置（[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)）和输入而异的各种元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — 模型最后一层的隐藏状态序列。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [XLMProphetNetEncoder](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetEncoder)
    forward method, overrides the `__call__` special method.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[XLMProphetNetEncoder](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetEncoder)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE11]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: XLMProphetNetDecoder
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XLMProphetNetDecoder
- en: '### `class transformers.XLMProphetNetDecoder`'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.XLMProphetNetDecoder`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L1378)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L1378)'
- en: '[PRE12]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The standalone decoder part of the XLMProphetNetModel. This model inherits from
    [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Original ProphetNet code can be found [here](https://github.com/microsoft/ProphetNet).
    Checkpoints were converted from original Fairseq checkpoints. For more information
    on the checkpoint conversion, please take a look at the file `convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py`.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matters related to general usage and behavior.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: 'word_embeddings (`torch.nn.Embeddings` of shape `(config.vocab_size, config.hidden_size)`,
    *optional*): The word embedding parameters. This can be used to initialize [XLMProphetNetEncoder](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetEncoder)
    with pre-defined word embeddings instead of randomly initialized word embeddings.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L1420)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder. Used in the cross-attention if the model is configured as
    a decoder.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on the padding token indices
    of the encoder input. This mask is used in the cross-attention if the model is
    configured as a decoder. Mask values selected in `[0, 1]`:'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) — Contains precomputed key and value hidden-states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetDecoderModelOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetDecoderModelOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    and inputs.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, decoder_sequence_length,
    hidden_size)`) — Sequence of main stream hidden-states at the output of the last
    layer of the decoder of the model.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`last_hidden_state_ngram` (`torch.FloatTensor` of shape `(batch_size, ngram
    * decoder_sequence_length, config.vocab_size)`) — Sequence of predict stream hidden-states
    at the output of the last layer of the decoder of the model.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`List[torch.FloatTensor]`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — List of `torch.FloatTensor` of length
    `config.n_layers`, with each tensor of shape `(2, batch_size, num_attn_heads,
    decoder_sequence_length, embed_size_per_head)`).'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    of the decoder that can be used (see `past_key_values` input) to speed up sequential
    decoding.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, decoder_sequence_length, hidden_size)`.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of main stream of the decoder at the output of each layer plus
    the initial embedding outputs.
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`ngram_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, ngram * decoder_sequence_length,
    hidden_size)`.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the predict stream of the decoder at the output of each layer
    plus the initial embedding outputs.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_attn_heads, decoder_sequence_length,
    decoder_sequence_length)`.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`ngram_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_attn_heads, decoder_sequence_length,
    decoder_sequence_length)`.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the predict stream of the decoder, after the attention
    softmax, used to compute the weighted average in the
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_attn_heads, encoder_sequence_length,
    decoder_sequence_length)`.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the cross-attention layer of the decoder, after the attention
    softmax, used to compute the weighted average in the
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [XLMProphetNetDecoder](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetDecoder)
    forward method, overrides the `__call__` special method.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: XLMProphetNetForConditionalGeneration
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.XLMProphetNetForConditionalGeneration`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L1882)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The XLMProphetNet Model with a language modeling head. Can be used for sequence
    generation tasks. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Original ProphetNet code can be found [here](https://github.com/microsoft/ProphetNet).
    Checkpoints were converted from original Fairseq checkpoints. For more information
    on the checkpoint conversion, please take a look at the file `convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py`.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matters related to general usage and behavior.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L1914)'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: XLMProphetNet uses the `eos_token_id` as the starting token for `decoder_input_ids`
    generation. If `past_key_values` is used, optionally only the last `decoder_input_ids`
    have to be input (see `past_key_values`).
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attention_mask` (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) — Contains precomputed key and value hidden-states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[-100, 0, ..., config.vocab_size - 1]`. All labels set to `-100` are ignored
    (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetSeq2SeqLMOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetSeq2SeqLMOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    and inputs.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, decoder_sequence_length,
    config.vocab_size)`) — Prediction scores of the main stream language modeling
    head (scores for each vocabulary token before SoftMax).'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits_ngram` (`torch.FloatTensor` of shape `(batch_size, ngram * decoder_sequence_length,
    config.vocab_size)`) — Prediction scores of the predict stream language modeling
    head (scores for each vocabulary token before SoftMax).'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`List[torch.FloatTensor]`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — List of `torch.FloatTensor` of length
    `config.n_layers`, with each tensor of shape `(2, batch_size, num_attn_heads,
    decoder_sequence_length, embed_size_per_head)`).'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    of the decoder that can be used (see `past_key_values` input) to speed up sequential
    decoding.
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, decoder_sequence_length, hidden_size)`.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of main stream of the decoder at the output of each layer plus
    the initial embedding outputs.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_ngram_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, ngram * decoder_sequence_length,
    hidden_size)`.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the predict stream of the decoder at the output of each layer
    plus the initial embedding outputs.
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_attn_heads,
    decoder_sequence_length, decoder_sequence_length)`.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`decoder_ngram_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_attentions=True` is passed or when `config.output_attentions=True`)
    — Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_attn_heads,
    decoder_sequence_length, decoder_sequence_length)`.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the predict stream of the decoder, after the attention
    softmax, used to compute the weighted average in the self-attention heads.
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_attn_heads, encoder_sequence_length,
    decoder_sequence_length)`.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the cross-attention layer of the decoder, after the attention
    softmax, used to compute the weighted average in the
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, encoder_sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, encoder_sequence_length, hidden_size)`.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_attn_heads,
    encoder_sequence_length, encoder_sequence_length)`. Attentions weights of the
    encoder, after the attention softmax, used to compute the weighted average in
    the self-attention heads.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [XLMProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration)
    forward method, overrides the `__call__` special method.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: XLMProphetNetForCausalLM
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.XLMProphetNetForCausalLM`'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L2099)'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The standalone decoder part of the XLMProphetNetModel with a lm head on top.
    The model can be used for causal language modeling. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Original ProphetNet code can be found [here](https://github.com/microsoft/ProphetNet).
    Checkpoints were converted from original Fairseq checkpoints. For more information
    on the checkpoint conversion, please take a look at the file `convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py`.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matters related to general usage and behavior.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py#L2150)'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-359
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-360
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-364
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_hidden_states` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder. Used in the cross-attention if the model is configured as
    a decoder.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on the padding token indices
    of the encoder input. This mask is used in the cross-attention if the model is
    configured as a decoder. Mask values selected in `[0, 1]`:'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is `not masked`,
  id: totrans-371
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is `masked`.
  id: totrans-372
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers`
    with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length
    - 1, embed_size_per_head)`) — Contains precomputed key and value hidden-states
    of the attention blocks. Can be used to speed up decoding.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are `not masked`,
  id: totrans-376
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are `masked`.
  id: totrans-377
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the left-to-right language modeling loss (next word prediction).
    Indices should be in `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring)
    Tokens with indices set to `-100` are ignored (masked), the loss is only computed
    for the tokens with labels n `[0, ..., config.vocab_size]`'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: '`transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetDecoderLMOutput`
    or `tuple(torch.FloatTensor)`'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: A `transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetDecoderLMOutput`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig))
    and inputs.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, decoder_sequence_length,
    config.vocab_size)`) — Prediction scores of the main stream language modeling
    head (scores for each vocabulary token before SoftMax).'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits_ngram` (`torch.FloatTensor` of shape `(batch_size, ngram * decoder_sequence_length,
    config.vocab_size)`) — Prediction scores of the predict stream language modeling
    head (scores for each vocabulary token before SoftMax).'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_key_values` (`List[torch.FloatTensor]`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — List of `torch.FloatTensor` of length
    `config.n_layers`, with each tensor of shape `(2, batch_size, num_attn_heads,
    decoder_sequence_length, embed_size_per_head)`).'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    of the decoder that can be used (see `past_key_values` input) to speed up sequential
    decoding.
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, decoder_sequence_length, hidden_size)`.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of main stream of the decoder at the output of each layer plus
    the initial embedding outputs.
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`ngram_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for
    the output of each layer) of shape `(batch_size, ngram * decoder_sequence_length,
    hidden_size)`.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the predict stream of the decoder at the output of each layer
    plus the initial embedding outputs.
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_attn_heads, decoder_sequence_length,
    decoder_sequence_length)`.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`ngram_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_attn_heads, decoder_sequence_length,
    decoder_sequence_length)`.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the predict stream of the decoder, after the attention
    softmax, used to compute the weighted average in the
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_attn_heads, encoder_sequence_length,
    decoder_sequence_length)`.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the cross-attention layer of the decoder, after the attention
    softmax, used to compute the weighted average in the
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [XLMProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM)
    forward method, overrides the `__call__` special method.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
