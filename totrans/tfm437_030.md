# å›¾åƒåˆ†ç±»

> åŽŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/tasks/image_classification`](https://huggingface.co/docs/transformers/v4.37.2/en/tasks/image_classification)

[`www.youtube-nocookie.com/embed/tjAIM7BOYhw`](https://www.youtube-nocookie.com/embed/tjAIM7BOYhw)

å›¾åƒåˆ†ç±»ä¸ºå›¾åƒåˆ†é…ä¸€ä¸ªæ ‡ç­¾æˆ–ç±»åˆ«ã€‚ä¸Žæ–‡æœ¬æˆ–éŸ³é¢‘åˆ†ç±»ä¸åŒï¼Œè¾“å…¥æ˜¯ç»„æˆå›¾åƒçš„åƒç´ å€¼ã€‚å›¾åƒåˆ†ç±»æœ‰è®¸å¤šåº”ç”¨ï¼Œä¾‹å¦‚åœ¨è‡ªç„¶ç¾å®³åŽæ£€æµ‹æŸåã€ç›‘æµ‹ä½œç‰©å¥åº·æˆ–å¸®åŠ©ç­›æŸ¥åŒ»å­¦å›¾åƒä¸­çš„ç–¾ç—…è¿¹è±¡ã€‚

æœ¬æŒ‡å—è¯´æ˜Žäº†å¦‚ä½•ï¼š

1.  åœ¨[Food-101](https://huggingface.co/datasets/food101)æ•°æ®é›†ä¸Šå¯¹ ViT è¿›è¡Œå¾®è°ƒï¼Œä»¥å¯¹å›¾åƒä¸­çš„é£Ÿç‰©é¡¹ç›®è¿›è¡Œåˆ†ç±»ã€‚

1.  ä½¿ç”¨æ‚¨å¾®è°ƒçš„æ¨¡åž‹è¿›è¡ŒæŽ¨æ–­ã€‚

æœ¬æ•™ç¨‹ä¸­æ‰€ç¤ºçš„ä»»åŠ¡ç”±ä»¥ä¸‹æ¨¡åž‹æž¶æž„æ”¯æŒï¼š

BEiTã€BiTã€ConvNeXTã€ConvNeXTV2ã€CvTã€Data2VecVisionã€DeiTã€DiNATã€DINOv2ã€EfficientFormerã€EfficientNetã€FocalNetã€ImageGPTã€LeViTã€MobileNetV1ã€MobileNetV2ã€MobileViTã€MobileViTV2ã€NATã€Perceiverã€PoolFormerã€PVTã€RegNetã€ResNetã€SegFormerã€SwiftFormerã€Swin Transformerã€Swin Transformer V2ã€VANã€ViTã€ViT Hybridã€ViTMSN

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ï¼š

```py
pip install transformers datasets evaluate
```

æˆ‘ä»¬é¼“åŠ±æ‚¨ç™»å½•æ‚¨çš„ Hugging Face å¸æˆ·ï¼Œä»¥ä¾¿ä¸Šä¼ å’Œä¸Žç¤¾åŒºåˆ†äº«æ‚¨çš„æ¨¡åž‹ã€‚åœ¨æç¤ºæ—¶ï¼Œè¾“å…¥æ‚¨çš„ä»¤ç‰Œä»¥ç™»å½•ï¼š

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## åŠ è½½ Food-101 æ•°æ®é›†

é¦–å…ˆä»ŽðŸ¤—æ•°æ®é›†åº“ä¸­åŠ è½½ Food-101 æ•°æ®é›†çš„ä¸€ä¸ªè¾ƒå°å­é›†ã€‚è¿™å°†è®©æ‚¨æœ‰æœºä¼šè¿›è¡Œå®žéªŒï¼Œå¹¶ç¡®ä¿ä¸€åˆ‡æ­£å¸¸ï¼Œç„¶åŽå†èŠ±æ›´å¤šæ—¶é—´åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚

```py
>>> from datasets import load_dataset

>>> food = load_dataset("food101", split="train[:5000]")
```

ä½¿ç”¨[train_test_split](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.train_test_split)æ–¹æ³•å°†æ•°æ®é›†çš„`train`æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š

```py
>>> food = food.train_test_split(test_size=0.2)
```

ç„¶åŽçœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š

```py
>>> food["train"][0]
{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at 0x7F52AFC8AC50>,
 'label': 79}
```

æ•°æ®é›†ä¸­çš„æ¯ä¸ªç¤ºä¾‹éƒ½æœ‰ä¸¤ä¸ªå­—æ®µï¼š

+   `image`ï¼šé£Ÿç‰©é¡¹ç›®çš„ PIL å›¾åƒ

+   `label`ï¼šé£Ÿç‰©é¡¹ç›®çš„æ ‡ç­¾ç±»åˆ«

ä¸ºäº†ä½¿æ¨¡åž‹æ›´å®¹æ˜“ä»Žæ ‡ç­¾ ID èŽ·å–æ ‡ç­¾åç§°ï¼Œåˆ›å»ºä¸€ä¸ªå°†æ ‡ç­¾åç§°æ˜ å°„åˆ°æ•´æ•°åŠåä¹‹çš„å­—å…¸ï¼š

```py
>>> labels = food["train"].features["label"].names
>>> label2id, id2label = dict(), dict()
>>> for i, label in enumerate(labels):
...     label2id[label] = str(i)
...     id2label[str(i)] = label
```

çŽ°åœ¨æ‚¨å¯ä»¥å°†æ ‡ç­¾ ID è½¬æ¢ä¸ºæ ‡ç­¾åç§°ï¼š

```py
>>> id2label[str(79)]
'prime_rib'
```

## é¢„å¤„ç†

ä¸‹ä¸€æ­¥æ˜¯åŠ è½½ä¸€ä¸ª ViT å›¾åƒå¤„ç†å™¨ï¼Œå°†å›¾åƒå¤„ç†ä¸ºå¼ é‡ï¼š

```py
>>> from transformers import AutoImageProcessor

>>> checkpoint = "google/vit-base-patch16-224-in21k"
>>> image_processor = AutoImageProcessor.from_pretrained(checkpoint)
```

PytorchHide Pytorch content

å¯¹å›¾åƒåº”ç”¨ä¸€äº›å›¾åƒè½¬æ¢ï¼Œä½¿æ¨¡åž‹æ›´å…·æŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›ã€‚åœ¨è¿™é‡Œï¼Œæ‚¨å°†ä½¿ç”¨ torchvision çš„[`transforms`](https://pytorch.org/vision/stable/transforms.html)æ¨¡å—ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨æ‚¨å–œæ¬¢çš„ä»»ä½•å›¾åƒåº“ã€‚

è£å‰ªå›¾åƒçš„éšæœºéƒ¨åˆ†ï¼Œè°ƒæ•´å¤§å°ï¼Œå¹¶ä½¿ç”¨å›¾åƒçš„å‡å€¼å’Œæ ‡å‡†å·®è¿›è¡Œå½’ä¸€åŒ–ï¼š

```py
>>> from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor

>>> normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
>>> size = (
...     image_processor.size["shortest_edge"]
...     if "shortest_edge" in image_processor.size
...     else (image_processor.size["height"], image_processor.size["width"])
... )
>>> _transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])
```

ç„¶åŽåˆ›å»ºä¸€ä¸ªé¢„å¤„ç†å‡½æ•°æ¥åº”ç”¨è½¬æ¢å¹¶è¿”å›ž`pixel_values` - å›¾åƒçš„æ¨¡åž‹è¾“å…¥ï¼š

```py
>>> def transforms(examples):
...     examples["pixel_values"] = [_transforms(img.convert("RGB")) for img in examples["image"]]
...     del examples["image"]
...     return examples
```

è¦åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨é¢„å¤„ç†å‡½æ•°ï¼Œè¯·ä½¿ç”¨ðŸ¤—æ•°æ®é›†çš„[with_transform](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.with_transform)æ–¹æ³•ã€‚å½“åŠ è½½æ•°æ®é›†çš„å…ƒç´ æ—¶ï¼Œè½¬æ¢ä¼šå³æ—¶åº”ç”¨ï¼š

```py
>>> food = food.with_transform(transforms)
```

çŽ°åœ¨ä½¿ç”¨ DefaultDataCollator åˆ›å»ºä¸€æ‰¹ç¤ºä¾‹ã€‚ä¸ŽðŸ¤— Transformers ä¸­çš„å…¶ä»–æ•°æ®æ•´ç†å™¨ä¸åŒï¼Œ`DefaultDataCollator`ä¸ä¼šåº”ç”¨é¢å¤–çš„é¢„å¤„ç†ï¼Œå¦‚å¡«å……ã€‚

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator()
```

TensorFlow éšè— TensorFlow å†…å®¹

ä¸ºäº†é¿å…è¿‡æ‹Ÿåˆå¹¶ä½¿æ¨¡åž‹æ›´åŠ å¥å£®ï¼Œåœ¨æ•°æ®é›†çš„è®­ç»ƒéƒ¨åˆ†æ·»åŠ ä¸€äº›æ•°æ®å¢žå¼ºã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ Keras é¢„å¤„ç†å±‚æ¥å®šä¹‰è®­ç»ƒæ•°æ®ï¼ˆåŒ…æ‹¬æ•°æ®å¢žå¼ºï¼‰çš„è½¬æ¢ï¼Œä»¥åŠéªŒè¯æ•°æ®ï¼ˆä»…ä¸­å¿ƒè£å‰ªã€è°ƒæ•´å¤§å°å’Œå½’ä¸€åŒ–ï¼‰çš„è½¬æ¢ã€‚æ‚¨å¯ä»¥ä½¿ç”¨`tf.image`æˆ–æ‚¨å–œæ¬¢çš„ä»»ä½•å…¶ä»–åº“ã€‚

```py
>>> from tensorflow import keras
>>> from tensorflow.keras import layers

>>> size = (image_processor.size["height"], image_processor.size["width"])

>>> train_data_augmentation = keras.Sequential(
...     [
...         layers.RandomCrop(size[0], size[1]),
...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),
...         layers.RandomFlip("horizontal"),
...         layers.RandomRotation(factor=0.02),
...         layers.RandomZoom(height_factor=0.2, width_factor=0.2),
...     ],
...     name="train_data_augmentation",
... )

>>> val_data_augmentation = keras.Sequential(
...     [
...         layers.CenterCrop(size[0], size[1]),
...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),
...     ],
...     name="val_data_augmentation",
... )
```

æŽ¥ä¸‹æ¥ï¼Œåˆ›å»ºå‡½æ•°å°†é€‚å½“çš„è½¬æ¢åº”ç”¨äºŽä¸€æ‰¹å›¾åƒï¼Œè€Œä¸æ˜¯ä¸€æ¬¡ä¸€ä¸ªå›¾åƒã€‚

```py
>>> import numpy as np
>>> import tensorflow as tf
>>> from PIL import Image

>>> def convert_to_tf_tensor(image: Image):
...     np_image = np.array(image)
...     tf_image = tf.convert_to_tensor(np_image)
...     # `expand_dims()` is used to add a batch dimension since
...     # the TF augmentation layers operates on batched inputs.
...     return tf.expand_dims(tf_image, 0)

>>> def preprocess_train(example_batch):
...     """Apply train_transforms across a batch."""
...     images = [
...         train_data_augmentation(convert_to_tf_tensor(image.convert("RGB"))) for image in example_batch["image"]
...     ]
...     example_batch["pixel_values"] = [tf.transpose(tf.squeeze(image)) for image in images]
...     return example_batch

... def preprocess_val(example_batch):
...     """Apply val_transforms across a batch."""
...     images = [
...         val_data_augmentation(convert_to_tf_tensor(image.convert("RGB"))) for image in example_batch["image"]
...     ]
...     example_batch["pixel_values"] = [tf.transpose(tf.squeeze(image)) for image in images]
...     return example_batch
```

ä½¿ç”¨ðŸ¤— Datasets [set_transform](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.set_transform)åœ¨è¿è¡Œæ—¶åº”ç”¨è½¬æ¢ï¼š

```py
food["train"].set_transform(preprocess_train)
food["test"].set_transform(preprocess_val)
```

ä½œä¸ºæœ€åŽçš„é¢„å¤„ç†æ­¥éª¤ï¼Œä½¿ç”¨`DefaultDataCollator`åˆ›å»ºä¸€æ‰¹ç¤ºä¾‹ã€‚ä¸ŽðŸ¤— Transformers ä¸­çš„å…¶ä»–æ•°æ®æ•´ç†å™¨ä¸åŒï¼Œ`DefaultDataCollator`ä¸ä¼šåº”ç”¨é¢å¤–çš„é¢„å¤„ç†ï¼Œå¦‚å¡«å……ã€‚

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator(return_tensors="tf")
```

## è¯„ä¼°

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒ…å«ä¸€ä¸ªåº¦é‡é€šå¸¸æœ‰åŠ©äºŽè¯„ä¼°æ¨¡åž‹çš„æ€§èƒ½ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ðŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index)åº“å¿«é€ŸåŠ è½½è¯„ä¼°æ–¹æ³•ã€‚å¯¹äºŽæ­¤ä»»åŠ¡ï¼ŒåŠ è½½[accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy)åº¦é‡ï¼ˆæŸ¥çœ‹ðŸ¤— Evaluate [å¿«é€Ÿå¯¼è§ˆ](https://huggingface.co/docs/evaluate/a_quick_tour)ä»¥äº†è§£å¦‚ä½•åŠ è½½å’Œè®¡ç®—åº¦é‡ï¼‰ï¼š

```py
>>> import evaluate

>>> accuracy = evaluate.load("accuracy")
```

ç„¶åŽåˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå°†æ‚¨çš„é¢„æµ‹å’Œæ ‡ç­¾ä¼ é€’ç»™`compute`ä»¥è®¡ç®—å‡†ç¡®æ€§ï¼š

```py
>>> import numpy as np

>>> def compute_metrics(eval_pred):
...     predictions, labels = eval_pred
...     predictions = np.argmax(predictions, axis=1)
...     return accuracy.compute(predictions=predictions, references=labels)
```

æ‚¨çš„`compute_metrics`å‡½æ•°çŽ°åœ¨å·²ç»å‡†å¤‡å°±ç»ªï¼Œå½“æ‚¨è®¾ç½®è®­ç»ƒæ—¶ä¼šè¿”å›žåˆ°å®ƒã€‚

## è®­ç»ƒ

Pytorch éšè— Pytorch å†…å®¹

å¦‚æžœæ‚¨ä¸ç†Ÿæ‚‰ä½¿ç”¨ Trainer å¯¹æ¨¡åž‹è¿›è¡Œå¾®è°ƒï¼Œè¯·æŸ¥çœ‹åŸºæœ¬æ•™ç¨‹è¿™é‡Œï¼

çŽ°åœ¨æ‚¨å¯ä»¥å¼€å§‹è®­ç»ƒæ‚¨çš„æ¨¡åž‹äº†ï¼ä½¿ç”¨ AutoModelForImageClassification åŠ è½½ ViTã€‚æŒ‡å®šæ ‡ç­¾æ•°é‡ä»¥åŠé¢„æœŸæ ‡ç­¾æ•°é‡å’Œæ ‡ç­¾æ˜ å°„ï¼š

```py
>>> from transformers import AutoModelForImageClassification, TrainingArguments, Trainer

>>> model = AutoModelForImageClassification.from_pretrained(
...     checkpoint,
...     num_labels=len(labels),
...     id2label=id2label,
...     label2id=label2id,
... )
```

åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œåªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š

1.  åœ¨ TrainingArguments ä¸­å®šä¹‰æ‚¨çš„è®­ç»ƒè¶…å‚æ•°ã€‚é‡è¦çš„æ˜¯ä¸è¦åˆ é™¤æœªä½¿ç”¨çš„åˆ—ï¼Œå› ä¸ºé‚£ä¼šåˆ é™¤`image`åˆ—ã€‚æ²¡æœ‰`image`åˆ—ï¼Œæ‚¨å°±æ— æ³•åˆ›å»º`pixel_values`ã€‚è®¾ç½®`remove_unused_columns=False`ä»¥é˜²æ­¢è¿™ç§è¡Œä¸ºï¼å”¯ä¸€çš„å…¶ä»–å¿…éœ€å‚æ•°æ˜¯`output_dir`ï¼ŒæŒ‡å®šä¿å­˜æ¨¡åž‹çš„ä½ç½®ã€‚é€šè¿‡è®¾ç½®`push_to_hub=True`å°†æ­¤æ¨¡åž‹æŽ¨é€åˆ° Hubï¼ˆæ‚¨éœ€è¦ç™»å½• Hugging Face æ‰èƒ½ä¸Šä¼ æ‚¨çš„æ¨¡åž‹ï¼‰ã€‚åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ï¼ŒTrainer å°†è¯„ä¼°å‡†ç¡®æ€§å¹¶ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚

1.  å°†è®­ç»ƒå‚æ•°ä¼ é€’ç»™ Trainerï¼Œä»¥åŠæ¨¡åž‹ã€æ•°æ®é›†ã€åˆ†è¯å™¨ã€æ•°æ®æ•´ç†å™¨å’Œ`compute_metrics`å‡½æ•°ã€‚

1.  è°ƒç”¨ train()æ¥å¾®è°ƒæ‚¨çš„æ¨¡åž‹ã€‚

```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_food_model",
...     remove_unused_columns=False,
...     evaluation_strategy="epoch",
...     save_strategy="epoch",
...     learning_rate=5e-5,
...     per_device_train_batch_size=16,
...     gradient_accumulation_steps=4,
...     per_device_eval_batch_size=16,
...     num_train_epochs=3,
...     warmup_ratio=0.1,
...     logging_steps=10,
...     load_best_model_at_end=True,
...     metric_for_best_model="accuracy",
...     push_to_hub=True,
... )

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     data_collator=data_collator,
...     train_dataset=food["train"],
...     eval_dataset=food["test"],
...     tokenizer=image_processor,
...     compute_metrics=compute_metrics,
... )

>>> trainer.train()
```

è®­ç»ƒå®ŒæˆåŽï¼Œä½¿ç”¨ push_to_hub()æ–¹æ³•å°†æ‚¨çš„æ¨¡åž‹å…±äº«åˆ° Hubï¼Œè¿™æ ·æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨æ‚¨çš„æ¨¡åž‹ï¼š

```py
>>> trainer.push_to_hub()
```

TensorFlow éšè— TensorFlow å†…å®¹

å¦‚æžœæ‚¨ä¸ç†Ÿæ‚‰ä½¿ç”¨ Keras å¾®è°ƒæ¨¡åž‹ï¼Œè¯·å…ˆæŸ¥çœ‹åŸºæœ¬æ•™ç¨‹ï¼

è¦åœ¨ TensorFlow ä¸­å¾®è°ƒæ¨¡åž‹ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š

1.  å®šä¹‰è®­ç»ƒè¶…å‚æ•°ï¼Œå¹¶è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ çŽ‡è°ƒåº¦ã€‚

1.  å®žä¾‹åŒ–ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡åž‹ã€‚

1.  å°†ðŸ¤—æ•°æ®é›†è½¬æ¢ä¸º`tf.data.Dataset`ã€‚

1.  ç¼–è¯‘æ‚¨çš„æ¨¡åž‹ã€‚

1.  æ·»åŠ å›žè°ƒå¹¶ä½¿ç”¨`fit()`æ–¹æ³•è¿è¡Œè®­ç»ƒã€‚

1.  å°†æ‚¨çš„æ¨¡åž‹ä¸Šä¼ åˆ°ðŸ¤— Hub ä»¥ä¸Žç¤¾åŒºå…±äº«ã€‚

é¦–å…ˆå®šä¹‰è¶…å‚æ•°ã€ä¼˜åŒ–å™¨å’Œå­¦ä¹ çŽ‡è°ƒåº¦ï¼š

```py
>>> from transformers import create_optimizer

>>> batch_size = 16
>>> num_epochs = 5
>>> num_train_steps = len(food["train"]) * num_epochs
>>> learning_rate = 3e-5
>>> weight_decay_rate = 0.01

>>> optimizer, lr_schedule = create_optimizer(
...     init_lr=learning_rate,
...     num_train_steps=num_train_steps,
...     weight_decay_rate=weight_decay_rate,
...     num_warmup_steps=0,
... )
```

ç„¶åŽï¼Œä½¿ç”¨ TFAutoModelForImageClassification åŠ è½½ ViT ä»¥åŠæ ‡ç­¾æ˜ å°„ï¼š

```py
>>> from transformers import TFAutoModelForImageClassification

>>> model = TFAutoModelForImageClassification.from_pretrained(
...     checkpoint,
...     id2label=id2label,
...     label2id=label2id,
... )
```

ä½¿ç”¨[to_tf_dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset.to_tf_dataset)å’Œæ‚¨çš„`data_collator`å°†æ•°æ®é›†è½¬æ¢ä¸º`tf.data.Dataset`æ ¼å¼ï¼š

```py
>>> # converting our train dataset to tf.data.Dataset
>>> tf_train_dataset = food["train"].to_tf_dataset(
...     columns="pixel_values", label_cols="label", shuffle=True, batch_size=batch_size, collate_fn=data_collator
... )

>>> # converting our test dataset to tf.data.Dataset
>>> tf_eval_dataset = food["test"].to_tf_dataset(
...     columns="pixel_values", label_cols="label", shuffle=True, batch_size=batch_size, collate_fn=data_collator
... )
```

ä½¿ç”¨`compile()`é…ç½®æ¨¡åž‹è¿›è¡Œè®­ç»ƒï¼š

```py
>>> from tensorflow.keras.losses import SparseCategoricalCrossentropy

>>> loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
>>> model.compile(optimizer=optimizer, loss=loss)
```

è¦ä»Žé¢„æµ‹ä¸­è®¡ç®—å‡†ç¡®æ€§å¹¶å°†æ¨¡åž‹æŽ¨é€åˆ°ðŸ¤— Hubï¼Œè¯·ä½¿ç”¨ Keras å›žè°ƒã€‚å°†æ‚¨çš„`compute_metrics`å‡½æ•°ä¼ é€’ç»™ KerasMetricCallbackï¼Œå¹¶ä½¿ç”¨ PushToHubCallback ä¸Šä¼ æ¨¡åž‹ï¼š

```py
>>> from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback

>>> metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_eval_dataset)
>>> push_to_hub_callback = PushToHubCallback(
...     output_dir="food_classifier",
...     tokenizer=image_processor,
...     save_strategy="no",
... )
>>> callbacks = [metric_callback, push_to_hub_callback]
```

æœ€åŽï¼Œæ‚¨å·²ç»å‡†å¤‡å¥½è®­ç»ƒæ‚¨çš„æ¨¡åž‹äº†ï¼ä½¿ç”¨æ‚¨çš„è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ã€æ—¶ä»£æ•°å’Œå›žè°ƒæ¥å¾®è°ƒæ¨¡åž‹è°ƒç”¨`fit()`ï¼š

```py
>>> model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=num_epochs, callbacks=callbacks)
Epoch 1/5
250/250 [==============================] - 313s 1s/step - loss: 2.5623 - val_loss: 1.4161 - accuracy: 0.9290
Epoch 2/5
250/250 [==============================] - 265s 1s/step - loss: 0.9181 - val_loss: 0.6808 - accuracy: 0.9690
Epoch 3/5
250/250 [==============================] - 252s 1s/step - loss: 0.3910 - val_loss: 0.4303 - accuracy: 0.9820
Epoch 4/5
250/250 [==============================] - 251s 1s/step - loss: 0.2028 - val_loss: 0.3191 - accuracy: 0.9900
Epoch 5/5
250/250 [==============================] - 238s 949ms/step - loss: 0.1232 - val_loss: 0.3259 - accuracy: 0.9890
```

æ­å–œï¼æ‚¨å·²ç»å¯¹æ¨¡åž‹è¿›è¡Œäº†å¾®è°ƒï¼Œå¹¶åœ¨ðŸ¤— Hub ä¸Šå…±äº«ã€‚çŽ°åœ¨æ‚¨å¯ä»¥ç”¨å®ƒè¿›è¡ŒæŽ¨ç†ï¼

è¦äº†è§£å¦‚ä½•ä¸ºå›¾åƒåˆ†ç±»å¾®è°ƒæ¨¡åž‹çš„æ›´æ·±å…¥ç¤ºä¾‹ï¼Œè¯·æŸ¥çœ‹ç›¸åº”çš„[PyTorch ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)ã€‚

## æŽ¨ç†

å¤ªæ£’äº†ï¼ŒçŽ°åœ¨æ‚¨å·²ç»å¯¹æ¨¡åž‹è¿›è¡Œäº†å¾®è°ƒï¼Œå¯ä»¥ç”¨äºŽæŽ¨ç†ï¼

åŠ è½½è¦è¿è¡ŒæŽ¨ç†çš„å›¾åƒï¼š

```py
>>> ds = load_dataset("food101", split="validation[:10]")
>>> image = ds["image"][0]
```

![beignets çš„å›¾åƒ](img/c05aba9fec7ae7783c6fb3a48b107e6b.png)

å°è¯•ä½¿ç”¨æ‚¨å¾®è°ƒçš„æ¨¡åž‹è¿›è¡ŒæŽ¨ç†çš„æœ€ç®€å•æ–¹æ³•æ˜¯åœ¨ pipeline()ä¸­ä½¿ç”¨å®ƒã€‚ä½¿ç”¨æ‚¨çš„æ¨¡åž‹å®žä¾‹åŒ–ä¸€ä¸ªç”¨äºŽå›¾åƒåˆ†ç±»çš„`pipeline`ï¼Œå¹¶å°†å›¾åƒä¼ é€’ç»™å®ƒï¼š

```py
>>> from transformers import pipeline

>>> classifier = pipeline("image-classification", model="my_awesome_food_model")
>>> classifier(image)
[{'score': 0.31856709718704224, 'label': 'beignets'},
 {'score': 0.015232225880026817, 'label': 'bruschetta'},
 {'score': 0.01519392803311348, 'label': 'chicken_wings'},
 {'score': 0.013022331520915031, 'label': 'pork_chop'},
 {'score': 0.012728818692266941, 'label': 'prime_rib'}]
```

å¦‚æžœæ„¿æ„ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨å¤åˆ¶`pipeline`çš„ç»“æžœï¼š

PytorchHide Pytorch å†…å®¹

åŠ è½½å›¾åƒå¤„ç†å™¨ä»¥é¢„å¤„ç†å›¾åƒå¹¶å°†`input`è¿”å›žä¸º PyTorch å¼ é‡ï¼š

```py
>>> from transformers import AutoImageProcessor
>>> import torch

>>> image_processor = AutoImageProcessor.from_pretrained("my_awesome_food_model")
>>> inputs = image_processor(image, return_tensors="pt")
```

å°†è¾“å…¥ä¼ é€’ç»™æ¨¡åž‹å¹¶è¿”å›ž logitsï¼š

```py
>>> from transformers import AutoModelForImageClassification

>>> model = AutoModelForImageClassification.from_pretrained("my_awesome_food_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

èŽ·å–å…·æœ‰æœ€é«˜æ¦‚çŽ‡çš„é¢„æµ‹æ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨æ¨¡åž‹çš„`id2label`æ˜ å°„å°†å…¶è½¬æ¢ä¸ºæ ‡ç­¾ï¼š

```py
>>> predicted_label = logits.argmax(-1).item()
>>> model.config.id2label[predicted_label]
'beignets'
```

TensorFlowHide TensorFlow å†…å®¹

åŠ è½½å›¾åƒå¤„ç†å™¨ä»¥é¢„å¤„ç†å›¾åƒå¹¶å°†`input`è¿”å›žä¸º TensorFlow å¼ é‡ï¼š

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("MariaK/food_classifier")
>>> inputs = image_processor(image, return_tensors="tf")
```

å°†è¾“å…¥ä¼ é€’ç»™æ¨¡åž‹å¹¶è¿”å›ž logitsï¼š

```py
>>> from transformers import TFAutoModelForImageClassification

>>> model = TFAutoModelForImageClassification.from_pretrained("MariaK/food_classifier")
>>> logits = model(**inputs).logits
```

èŽ·å–å…·æœ‰æœ€é«˜æ¦‚çŽ‡çš„é¢„æµ‹æ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨æ¨¡åž‹çš„`id2label`æ˜ å°„å°†å…¶è½¬æ¢ä¸ºæ ‡ç­¾ï¼š

```py
>>> predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])
>>> model.config.id2label[predicted_class_id]
'beignets'
```
