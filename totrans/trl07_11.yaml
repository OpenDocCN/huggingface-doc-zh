- en: Trainer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练器
- en: 'Original text: [https://huggingface.co/docs/trl/trainer](https://huggingface.co/docs/trl/trainer)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '原始文本: [https://huggingface.co/docs/trl/trainer](https://huggingface.co/docs/trl/trainer)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: At TRL we support PPO (Proximal Policy Optimisation) with an implementation
    that largely follows the structure introduced in the paper “Fine-Tuning Language
    Models from Human Preferences” by D. Ziegler et al. [[paper](https://arxiv.org/pdf/1909.08593.pdf),
    [code](https://github.com/openai/lm-human-preferences)]. The Trainer and model
    classes are largely inspired from `transformers.Trainer` and `transformers.AutoModel`
    classes and adapted for RL. We also support a `RewardTrainer` that can be used
    to train a reward model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在TRL中，我们支持使用PPO（Proximal Policy Optimization）进行优化语言模型，其实现在很大程度上遵循了D. Ziegler等人在论文“Fine-Tuning
    Language Models from Human Preferences”中介绍的结构。[[paper](https://arxiv.org/pdf/1909.08593.pdf),
    [code](https://github.com/openai/lm-human-preferences)]。Trainer和model类在很大程度上受到`transformers.Trainer`和`transformers.AutoModel`类的启发，并为RL进行了调整。我们还支持一个`RewardTrainer`，可用于训练奖励模型。
- en: PPOConfig
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PPOConfig
- en: '### `class trl.PPOConfig`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.PPOConfig`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_config.py#L34)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_config.py#L34)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Configuration class for PPOTrainer
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: PPOTrainer的配置类
- en: PPOTrainer
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PPOTrainer
- en: '### `class trl.PPOTrainer`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.PPOTrainer`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L109)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L109)'
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '*`*config**` (`PPOConfig`) — Configuration object for PPOTrainer. Check the
    documentation of `PPOConfig` for more — details.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*config**` (`PPOConfig`) — PPOTrainer的配置对象。查看`PPOConfig`的文档以获取更多细节。'
- en: '*`*model**` (`PreTrainedModelWrapper`) — Model to be optimized, Hugging Face
    transformer model with a value head. — Check the documentation of `PreTrainedModelWrapper`
    for more details.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*model**` (`PreTrainedModelWrapper`) — 要优化的模型，带有值头的Hugging Face变换器模型。查看`PreTrainedModelWrapper`的文档以获取更多细节。'
- en: '*`*ref_model**` (`PreTrainedModelWrapper`, *optional*) — Reference model to
    be used for KL penalty, Hugging Face — transformer model with a casual language
    modelling head. Check the documentation of `PreTrainedModelWrapper` for more details.
    If no reference model is provided, the trainer will create a reference model with
    the same architecture as the model to be optimized with shared layers.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*ref_model**` (`PreTrainedModelWrapper`, *可选*) — 用于KL惩罚的参考模型，Hugging Face变换器模型带有一个非正式语言建模头。查看`PreTrainedModelWrapper`的文档以获取更多细节。如果没有提供参考模型，训练器将创建一个具有与要优化的模型相同架构的参考模型，共享层。'
- en: '*`*tokenizer**` (`PreTrainedTokenizerBase`) — Tokenizer to be used for encoding
    the — data. Check the documentation of `transformers.PreTrainedTokenizer` and
    `transformers.PreTrainedTokenizerFast` for more details.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*tokenizer**` (`PreTrainedTokenizerBase`) — 用于编码数据的分词器。查看`transformers.PreTrainedTokenizer`和`transformers.PreTrainedTokenizerFast`的文档以获取更多细节。'
- en: '*`*dataset**` (Union[`torch.utils.data.Dataset`, `datasets.Dataset`], *optional*)
    — PyTorch dataset or Hugging — Face dataset. This is used to create a PyTorch
    dataloader. If no dataset is provided, the dataloader must be created outside
    the trainer users needs to design their own dataloader and make sure the batch
    size that is used is the same as the one specified in the configuration object.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*dataset**` (Union[`torch.utils.data.Dataset`, `datasets.Dataset`], *可选*)
    — PyTorch数据集或Hugging Face数据集。这用于创建一个PyTorch数据加载器。如果没有提供数据集，数据加载器必须在训练器之外创建，用户需要设计自己的数据加载器，并确保使用的批量大小与配置对象中指定的相同。'
- en: '*`*optimizer**` (`torch.optim.Optimizer`, *optional*) — Optimizer to be used
    for training. If no optimizer is — provided, the trainer will create an Adam optimizer
    with the learning rate specified in the configuration object.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*optimizer**` (`torch.optim.Optimizer`, *可选*) — 用于训练的优化器。如果没有提供优化器，训练器将使用配置对象中指定的学习率创建一个Adam优化器。'
- en: '*`*data_collator**` (DataCollatorForLanguageModeling, *optional*) — Data collator
    to be used for training and — passed along the dataloader'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*data_collator**` (DataCollatorForLanguageModeling, *可选*) — 用于训练和传递给数据加载器的数据整合器'
- en: '*`*num_shared_layers**` (int, *optional*) — Number of layers to be shared between
    the model and the reference — model, if no reference model is passed. If no number
    is provided, all the layers will be shared.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*num_shared_layers**` (int, *可选*) — 要在模型和参考模型之间共享的层数，如果没有传递参考模型。如果没有提供数字，所有层将被共享。'
- en: '*`*lr_scheduler**` (`torch.optim.lr_scheduler`, *optional*) — Learning rate
    scheduler to be used for training. —'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*lr_scheduler**` (`torch.optim.lr_scheduler`, *可选*) — 用于训练的学习率调度器'
- en: 'The PPOTrainer uses Proximal Policy Optimization to optimise language models.
    Note, this trainer is heavily inspired by the original OpenAI learning to summarize
    work here: [https://github.com/openai/summarize-from-feedback](https://github.com/openai/summarize-from-feedback)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: PPOTrainer使用Proximal Policy Optimization来优化语言模型。请注意，这个训练器在很大程度上受到原始OpenAI学习总结工作的启发，链接在这里：[https://github.com/openai/summarize-from-feedback](https://github.com/openai/summarize-from-feedback)
- en: '#### `batched_forward_pass`'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batched_forward_pass`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L941)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L941)'
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`queries` (`torch.LongTensor`) — List of tensors containing the encoded queries,
    shape (`batch_size`, `query_length`)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`queries` (`torch.LongTensor`) — 包含编码查询的张量列表，形状为(`batch_size`, `query_length`)'
- en: '`responses` (`torch.LongTensor`) — List of tensors containing the encoded responses,
    shape (`batch_size`, `response_length`)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`responses` (`torch.LongTensor`) — 包含编码响应的张量列表，形状为(`batch_size`, `response_length`)'
- en: '`return_logits` (`bool`, *optional*, defaults to `False`) — Whether to return
    all_logits. Set to `False` if logits are not needed to reduce memory consumption.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_logits` (`bool`, *可选*, 默认为`False`) — 是否返回所有logits。如果不需要logits以减少内存消耗，则设置为`False`。'
- en: Returns
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: (tuple)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: (tuple)
- en: 'all_logprobs (`torch.FloatTensor`): Log probabilities of the responses, shape
    (`batch_size`, `response_length`)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'all_logprobs (`torch.FloatTensor`): 响应的对数概率，形状为(`batch_size`, `response_length`)'
- en: 'all_ref_logprobs (`torch.FloatTensor`): Log probabilities of the responses,
    shape (`batch_size`, `response_length`)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'all_ref_logprobs (`torch.FloatTensor`): 参考响应的对数概率，形状为(`batch_size`, `response_length`)'
- en: 'all_values (`torch.FloatTensor`): Values of the responses, shape (`batch_size`,
    `response_length`)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'all_values (`torch.FloatTensor`): 响应的值，形状为(`batch_size`, `response_length`)'
- en: Calculate model outputs in multiple batches.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个批次中计算模型输出。
- en: '#### `compute_rewards`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `compute_rewards`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1078)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1078)'
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`scores` (`torch.FloatTensor`) — Scores from the reward model, shape (`batch_size`)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scores` (`torch.FloatTensor`) — 来自奖励模型的分数，形状为(`batch_size`)'
- en: '`logprobs` (`torch.FloatTensor`) — Log probabilities of the model, shape (`batch_size`,
    `response_length`)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logprobs` (`torch.FloatTensor`) — 模型的对数概率，形状为(`batch_size`, `response_length`)'
- en: '`ref_logprobs` (`torch.FloatTensor`) — Log probabilities of the reference model,
    shape (`batch_size`, `response_length`)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ref_logprobs` (`torch.FloatTensor`) — 参考模型的对数概率，形状为(`batch_size`, `response_length`)'
- en: Returns
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.FloatTensor`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: 'Per token rewards, shape (`batch_size`, `response_length`) `torch.FloatTensor`:
    Non score rewards, shape (`batch_size`, `response_length`) `torch.FloatTensor`:
    KL penalty, shape (`batch_size`, `response_length`)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '每个标记的奖励，形状为(`batch_size`, `response_length`) `torch.FloatTensor`: 非分数奖励，形状为(`batch_size`,
    `response_length`) `torch.FloatTensor`: KL 惩罚，形状为(`batch_size`, `response_length`)'
- en: Compute per token rewards from scores and KL-penalty.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从分数和 KL 惩罚计算每个标记的奖励。
- en: '#### `create_model_card`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_model_card`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1386)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1386)'
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`path` (`str`) — The path to save the model card to.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`path` (`str`) — 保存模型卡的路径。'
- en: '`model_name` (`str`, *optional*) — The name of the model, defaults to `TRL
    Model`.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_name` (`str`, *optional*) — 模型的名称，默认为`TRL Model`。'
- en: Creates and saves a model card for a TRL model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 创建并保存一个 TRL 模型的模型卡。
- en: '#### `gather_stats`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `gather_stats`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L897)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L897)'
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`stats` (dict[str, Any]) —'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stats` (dict[str, Any]) —'
- en: '`a` dictionary of stats to be gathered. The stats should contain torch tensors.
    —'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个要收集的统计信息字典。统计信息应包含 torch 张量。 —
- en: Returns
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`dict[str, Any]`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`dict[str, Any]`'
- en: A dictionary of stats with the tensors gathered.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含收集到的张量的统计字典。
- en: Gather stats from all processes. Useful in the context of distributed training.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从所有进程中收集统计信息。在分布式训练的情况下很有用。
- en: '#### `generate`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L431)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L431)'
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`query_tensor` (`torch.LongTensor`) — A tensor of shape (`seq_len`) containing
    query tokens or a list of tensors of shape (`seq_len`).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query_tensor` (`torch.LongTensor`) — 一个形状为(`seq_len`)的查询标记张量或一个形状为(`seq_len`)的张量列表。'
- en: '`length_sampler` (`Callable`, *optional*) — Callable that returns the number
    of newly generated tokens.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length_sampler` (`Callable`, *optional*) — 返回新生成的标记数的可调用函数。'
- en: '`batch_size` (`int`, *optional) — Batch size used for generation, defaults
    to `4`.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size` (`int`, *optional) — 用于生成的批量大小，默认为`4`。'
- en: '`return_prompt` (`bool`, *optional*) — If set to `False` the prompt is not
    returned but only the newly generated tokens, defaults to `True`.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_prompt` (`bool`, *optional*) — 如果设置为`False`，则不返回提示，而只返回新生成的标记，默认为`True`。'
- en: '`generate_ref_response` (`bool`, *optional*) — If set to `True` the reference
    response is also generated, defaults to `False`.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_ref_response` (`bool`, *optional*) — 如果设置为`True`，则还会生成参考响应，默认为`False`。'
- en: '`generation_kwargs` (dict[str, Any]) — Keyword arguments for generation.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation_kwargs` (dict[str, Any]) — 用于生成的关键字参数。'
- en: Returns
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.LongTensor`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.LongTensor`'
- en: A tensor of shape (`batch_size`, `gen_len`) containing response tokens.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一个形状为(`batch_size`, `gen_len`)的包含响应标记的张量。
- en: Generate response with the model given the query tensor. call the `generate`
    method of the model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用给定查询张量的模型生成响应。调用模型的`generate`方法。
- en: '#### `log_stats`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `log_stats`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1313)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1313)'
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`stats` (dict[str, Any]) — A dictionary of training stats.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stats` (dict[str, Any]) — 一个包含训练统计信息的字典。'
- en: '`batch` (dict[str, Any]) — A dictionary of batch data, this contains the queries
    and responses.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch` (dict[str, Any]) — 一个包含查询和响应的批量数据的字典。'
- en: '`rewards` (`List[torch.FloatTensor]`) — A tensor of rewards.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rewards` (`List[torch.FloatTensor]`) — 一组奖励的张量。'
- en: A function that logs all the training stats. Call it at the end of each epoch.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一个记录所有训练统计数据的函数。在每个时代结束时调用它。
- en: '#### `loss`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `loss`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1160)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1160)'
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`old_logprobs` (`torch.FloatTensor`) — Log probabilities of the model, shape
    (`batch_size`, `response_length`)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`old_logprobs` (`torch.FloatTensor`) — 模型的对数概率，形状为(`batch_size`, `response_length`)'
- en: '`values` (`torch.FloatTensor`) — Values of the value head, shape (`batch_size`,
    `response_length`)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`values` (`torch.FloatTensor`) — 值头的值，形状为(`batch_size`, `response_length`)'
- en: '`rewards` (`torch.FloatTensor`) — Rewards from the reward model, shape (`batch_size`,
    `response_length`)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rewards` (`torch.FloatTensor`) — 来自奖励模型的奖励，形状为(`batch_size`, `response_length`)'
- en: '`logits` (`torch.FloatTensor`) — Logits of the model, shape (`batch_size`,
    `response_length`, `vocab_size`)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`) — 模型的对数概率，形状为(`batch_size`, `response_length`,
    `vocab_size`)'
- en: '`v_pred` (`torch.FloatTensor`) — Values of the value head, shape (`batch_size`,
    `response_length`)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`v_pred` (`torch.FloatTensor`) — 值头的值，形状为(`batch_size`, `response_length`)'
- en: '`logprobs` (`torch.FloatTensor`) — Log probabilities of the model, shape (`batch_size`,
    `response_length`)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logprobs` (`torch.FloatTensor`) — 模型的对数概率，形状为(`batch_size`, `response_length`)'
- en: Calculate policy and value losses.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 计算策略和值的损失。
- en: '#### `prepare_dataloader`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `prepare_dataloader`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L376)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L376)'
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`dataset` (Union[`torch.utils.data.Dataset`, `datasets.Dataset`]) — PyTorch
    dataset or Hugging Face dataset. If a Hugging Face dataset is passed, the dataset
    will be preprocessed by removing the columns that are not used by the model.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset`（Union[`torch.utils.data.Dataset`，`datasets.Dataset`]）- PyTorch数据集或Hugging
    Face数据集。如果传递了Hugging Face数据集，则将通过删除模型未使用的列来预处理数据集。'
- en: '`data_collator` (Optional[function]) — Data collator function.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_collator`（可选[函数]）- 数据整理函数。'
- en: Returns
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.utils.data.DataLoader`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.utils.data.DataLoader`'
- en: PyTorch dataloader
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch数据加载器
- en: Prepare the dataloader for training.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 准备数据加载器进行训练。
- en: '#### `record_step_stats`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `record_step_stats`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1249)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1249)'
- en: '[PRE10]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`kl_coef` (`float`) — KL coefficient'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kl_coef`（`float`）- KL系数'
- en: '`data` (`dict`) — Dictionary of training step data'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data`（`dict`）- 训练步骤数据的字典'
- en: Returns
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: stats (`dict`)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: stats（`dict`）
- en: Dictionary of training step statistics
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 训练步骤统计字典
- en: Record training step statistics.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 记录训练步骤统计。
- en: '#### `step`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L617)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L617)'
- en: '[PRE11]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`queries` (List`torch.LongTensor`) — List of tensors containing the encoded
    queries of shape (`query_length`)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`queries`（List`torch.LongTensor`）- 包含编码查询的张量列表，形状（`query_length`）'
- en: '`responses` (List`torch.LongTensor`) — List of tensors containing the encoded
    responses of shape (`response_length`)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`responses`（List`torch.LongTensor`）- 包含编码响应的张量列表，形状（`response_length`）'
- en: '`scores` (List`torch.FloatTensor`) — List of tensors containing the scores.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scores`（List`torch.FloatTensor`）- 包含分数的张量列表。'
- en: '`response_masks` (List`torch.FloatTensor`, *optional*)) — List of tensors containing
    masks of the response tokens.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`response_masks`（List`torch.FloatTensor`，*可选*）- 包含响应标记掩码的张量列表。'
- en: Returns
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`dict[str, Any]`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`dict[str，Any]`'
- en: A summary of the training statistics
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 训练统计摘要
- en: Run a PPO optimisation step given a list of queries, model responses, and rewards.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组查询、模型响应和奖励，运行一个PPO优化步骤。
- en: '#### `train_minibatch`'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `train_minibatch`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1032)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ppo_trainer.py#L1032)'
- en: '[PRE12]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`logprobs` (`torch.FloatTensor`) — Log probabilities of the model, shape [mini_batch_size,
    response_length]'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logprobs`（`torch.FloatTensor`）- 模型的对数概率，形状[mini_batch_size，response_length]'
- en: '`values` (`torch.FloatTensor`) — Values of the value head, shape [mini_batch_size,
    response_length]'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`values`（`torch.FloatTensor`）- 值头的值，形状[mini_batch_size，response_length]'
- en: '`query` (`torch.LongTensor`) — Encoded queries, shape [mini_batch_size, query_length]'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query`（`torch.LongTensor`）- 编码的查询，形状[mini_batch_size，query_length]'
- en: '`response` (`torch.LongTensor`) — Encoded responses, shape [mini_batch_size,
    response_length]'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`response`（`torch.LongTensor`）- 编码的响应，形状[mini_batch_size，response_length]'
- en: '`model_input` (`torch.LongTensor`) — Concatenated queries and responses, shape
    [mini_batch_size, query_length+response_length]'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_input`（`torch.LongTensor`）- 连接的查询和响应，形状[mini_batch_size，query_length+response_length]'
- en: Returns
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: train_stats (dict[str, `torch.Tensor`])
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: train_stats（dict[str，`torch.Tensor`]）
- en: Dictionary of training statistics
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 训练统计字典
- en: Train one PPO minibatch
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 训练一个PPO小批量
- en: RewardConfig
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RewardConfig
- en: '### `class trl.RewardConfig`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.RewardConfig`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/reward_config.py#L21)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/reward_config.py#L21)'
- en: '[PRE13]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`max_length` (`int`, *optional*, defaults to `None`) — The maximum length of
    the sequences in the batch. This argument is required if you want to use the default
    data collator.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length`（`int`，*可选*，默认为`None`）- 批次中序列的最大长度。如果要使用默认数据整理器，则需要此参数。'
- en: '`gradient_checkpointing` (`bool`, *optional*, defaults to `True`) — If True,
    use gradient checkpointing to save memory at the expense of slower backward pass.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gradient_checkpointing`（`bool`，*可选*，默认为`True`）- 如果为True，则使用梯度检查点来节省内存，但会导致反向传播变慢。'
- en: RewardConfig collects all training arguments related to the [RewardTrainer](/docs/trl/v0.7.10/en/reward_trainer#trl.RewardTrainer)
    class.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: RewardConfig收集与[RewardTrainer](/docs/trl/v0.7.10/en/reward_trainer#trl.RewardTrainer)类相关的所有训练参数。
- en: Using `HfArgumentParser` we can turn this class into [argparse](https://docs.python.org/3/library/argparse#module-argparse)
    arguments that can be specified on the command line.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`HfArgumentParser`，我们可以将这个类转换为[argparse](https://docs.python.org/3/library/argparse#module-argparse)参数，可以在命令行上指定。
- en: RewardTrainer
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RewardTrainer
- en: '### `class trl.RewardTrainer`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.RewardTrainer`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/reward_trainer.py#L36)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/reward_trainer.py#L36)'
- en: '[PRE14]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The RewardTrainer can be used to train your custom Reward Model. It is a subclass
    of the `transformers.Trainer` class and inherits all of its attributes and methods.
    It is recommended to use an `AutoModelForSequenceClassification` as the reward
    model. The reward model should be trained on a dataset of paired examples, where
    each example is a tuple of two sequences. The reward model should be trained to
    predict which example in the pair is more relevant to the task at hand.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: RewardTrainer可用于训练自定义奖励模型。它是`transformers.Trainer`类的子类，继承了所有属性和方法。建议使用`AutoModelForSequenceClassification`作为奖励模型。奖励模型应该在成对示例的数据集上进行训练，其中每个示例是两个序列的元组。奖励模型应该被训练以预测哪个示例对于当前任务更相关。
- en: The reward trainer expects a very specific format for the dataset. The dataset
    should contain two 4 entries at least if you don’t use the default `RewardDataCollatorWithPadding`
    data collator. The entries should be named
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励训练器对数据集有非常特定的格式要求。数据集应该至少包含两个条目，如果不使用默认的`RewardDataCollatorWithPadding`数据整理器。这些条目应该被命名
- en: '`input_ids_chosen`'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids_chosen`'
- en: '`attention_mask_chosen`'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask_chosen`'
- en: '`input_ids_rejected`'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids_rejected`'
- en: '`attention_mask_rejected`'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask_rejected`'
- en: Optionally, you can also pass a `margin` entry to the dataset. This entry should
    contain the margin used to modulate the loss of the reward model as outlined in
    [https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/).
    If you don’t pass a margin, no margin will be used.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，您还可以向数据集传递一个`margin`条目。此条目应包含用于调节奖励模型损失的边界，如[https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)中所述。如果不传递边界，将不使用边界。
- en: SFTTrainer
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SFTTrainer
- en: '### `class trl.SFTTrainer`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.SFTTrainer`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/sft_trainer.py#L54)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/sft_trainer.py#L54)'
- en: '[PRE15]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (Union[`transformers.PreTrainedModel`, `nn.Module`, `str`]) — The model
    to train, can be a `PreTrainedModel`, a `torch.nn.Module` or a string with the
    model name to load from cache or download. The model can be also converted to
    a `PeftModel` if a `PeftConfig` object is passed to the `peft_config` argument.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（Union[`transformers.PreTrainedModel`，`nn.Module`，`str`]）— 要训练的模型，可以是`PreTrainedModel`，`torch.nn.Module`或包含要从缓存加载或下载的模型名称的字符串。如果将`PeftConfig`对象传递给`peft_config`参数，则模型也可以转换为`PeftModel`。'
- en: '`args` (Optional[transformers.TrainingArguments](https://huggingface.co/docs/transformers/v4.36.2/en/main_classes/trainer#transformers.TrainingArguments))
    — The arguments to tweak for training. Please refer to the official documentation
    of `transformers.TrainingArguments` for more information.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`args`（Optional[transformers.TrainingArguments](https://huggingface.co/docs/transformers/v4.36.2/en/main_classes/trainer#transformers.TrainingArguments)）—
    用于调整训练的参数。有关更多信息，请参阅`transformers.TrainingArguments`的官方文档。'
- en: '`data_collator` (Optional`transformers.DataCollator`) — The data collator to
    use for training.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_collator`（Optional`transformers.DataCollator`）— 用于训练的数据收集器。'
- en: '`train_dataset` (Optional[datasets.Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset))
    — The dataset to use for training. We recommend users to use `trl.trainer.ConstantLengthDataset`
    to create their dataset.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_dataset`（Optional[datasets.Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)）—
    用于训练的数据集。我们建议用户使用`trl.trainer.ConstantLengthDataset`来创建他们的数据集。'
- en: '`eval_dataset` (Optional[Union[`datasets.Dataset`, Dict[`str`, `datasets.Dataset`]]])
    — The dataset to use for evaluation. We recommend users to use `trl.trainer.ConstantLengthDataset`
    to create their dataset.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eval_dataset`（Optional[Union[`datasets.Dataset`，Dict[`str`，`datasets.Dataset`]]）—
    用于评估的数据集。我们建议用户使用`trl.trainer.ConstantLengthDataset`来创建他们的数据集。'
- en: '`tokenizer` (Optional[transformers.PreTrainedTokenizer](https://huggingface.co/docs/transformers/v4.36.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer))
    — The tokenizer to use for training. If not specified, the tokenizer associated
    to the model will be used.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（Optional[transformers.PreTrainedTokenizer](https://huggingface.co/docs/transformers/v4.36.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)）—
    用于训练的分词器。如果未指定，将使用与模型相关联的分词器。'
- en: '`model_init` (`Callable[[], transformers.PreTrainedModel]`) — The model initializer
    to use for training. If None is specified, the default model initializer will
    be used.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_init`（`Callable[[], transformers.PreTrainedModel]`）— 用于训练的模型初始化器。如果指定为None，则将使用默认的模型初始化器。'
- en: '`compute_metrics` (`Callable[[transformers.EvalPrediction], Dict]`, *optional*
    defaults to None) — The function used to compute metrics during evaluation. It
    should return a dictionary mapping metric names to metric values. If not specified,
    only the loss will be computed during evaluation.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compute_metrics`（`Callable[[transformers.EvalPrediction]，Dict]`，*可选*默认为None）—
    用于在评估期间计算指标的函数。它应返回一个将指标名称映射到指标值的字典。如果未指定，评估期间将仅计算损失。'
- en: '`callbacks` (`List[transformers.TrainerCallback]`) — The callbacks to use for
    training.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callbacks`（`List[transformers.TrainerCallback]`）— 用于训练的回调函数。'
- en: '`optimizers` (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`)
    — The optimizer and scheduler to use for training.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizers`（`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`）—
    用于训练的优化器和调度器。'
- en: '`preprocess_logits_for_metrics` (`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`)
    — The function to use to preprocess the logits before computing the metrics.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`preprocess_logits_for_metrics`（`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`）—
    用于在计算指标之前预处理logits的函数。'
- en: '`peft_config` (`Optional[PeftConfig]`) — The PeftConfig object to use to initialize
    the PeftModel.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config`（`Optional[PeftConfig]`）— 用于初始化PeftModel的PeftConfig对象。'
- en: '`dataset_text_field` (`Optional[str]`) — The name of the text field of the
    dataset, in case this is passed by a user, the trainer will automatically create
    a `ConstantLengthDataset` based on the `dataset_text_field` argument.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset_text_field`（`Optional[str]`）— 数据集的文本字段的名称，如果用户传递了此参数，训练器将根据`dataset_text_field`参数自动创建一个`ConstantLengthDataset`。'
- en: '`formatting_func` (`Optional[Callable]`) — The formatting function to be used
    for creating the `ConstantLengthDataset`.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`formatting_func`（`Optional[Callable]`）— 用于创建`ConstantLengthDataset`的格式化函数。'
- en: '`max_seq_length` (`Optional[int]`) — The maximum sequence length to use for
    the `ConstantLengthDataset` and for automatically creating the Dataset. Defaults
    to `512`.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_seq_length`（`Optional[int]`）— 用于`ConstantLengthDataset`和自动创建数据集的最大序列长度。默认为`512`。'
- en: '`infinite` (`Optional[bool]`) — Whether to use an infinite dataset or not.
    Defaults to `False`.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`infinite`（`Optional[bool]`）— 是否使用无限数据集。默认为`False`。'
- en: '`num_of_sequences` (`Optional[int]`) — The number of sequences to use for the
    `ConstantLengthDataset`. Defaults to `1024`.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_of_sequences`（`Optional[int]`）— 用于`ConstantLengthDataset`的序列数。默认为`1024`。'
- en: '`chars_per_token` (`Optional[float]`) — The number of characters per token
    to use for the `ConstantLengthDataset`. Defaults to `3.6`. You can check how this
    is computed in the stack-llama example: [https://github.com/huggingface/trl/blob/08f550674c553c36c51d1027613c29f14f3676a5/examples/stack_llama/scripts/supervised_finetuning.py#L53](https://github.com/huggingface/trl/blob/08f550674c553c36c51d1027613c29f14f3676a5/examples/stack_llama/scripts/supervised_finetuning.py#L53).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chars_per_token` (`Optional[float]`) — 用于`ConstantLengthDataset`的每个标记的字符数。默认为`3.6`。您可以在stack-llama示例中查看如何计算这个值：[https://github.com/huggingface/trl/blob/08f550674c553c36c51d1027613c29f14f3676a5/examples/stack_llama/scripts/supervised_finetuning.py#L53](https://github.com/huggingface/trl/blob/08f550674c553c36c51d1027613c29f14f3676a5/examples/stack_llama/scripts/supervised_finetuning.py#L53)。'
- en: '`packing` (`Optional[bool]`) — Used only in case `dataset_text_field` is passed.
    This argument is used by the `ConstantLengthDataset` to pack the sequences of
    the dataset.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`packing` (`Optional[bool]`) — 仅在传递了`dataset_text_field`时使用。这个参数由`ConstantLengthDataset`用于打包数据集的序列。 '
- en: '`dataset_num_proc` (`Optional[int]`) — The number of workers to use to tokenize
    the data. Only used when `packing=False`. Defaults to None.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset_num_proc` (`Optional[int]`) — 用于标记数据的工作进程数。仅在`packing=False`时使用。默认为None。'
- en: '`dataset_batch_size` (`int`) — The number of examples to tokenize per batch.
    If batch_size <= 0 or batch_size == None, tokenize the full dataset as a single
    batch. Defaults to 1000.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset_batch_size` (`int`) — 每批要标记化的示例数。如果batch_size <= 0或batch_size == None，则将整个数据集标记为单个批次。默认为1000。'
- en: '`neftune_noise_alpha` (`Optional[float]`) — If not `None`, this will activate
    NEFTune noise embeddings. This has been proven to drastically improve model performances
    for instruction fine-tuning. Check out the original paper here: [https://arxiv.org/abs/2310.05914](https://arxiv.org/abs/2310.05914)
    and the original code here: [https://github.com/neelsjain/NEFTune](https://github.com/neelsjain/NEFTune)
    model_init_kwargs — (`Optional[Dict]`, *optional*): Dict of Optional kwargs to
    pass when instantiating the model from a string dataset_kwargs — (`Optional[Dict]`,
    *optional*): Dict of Optional kwargs to pass when creating packed or non-packed
    datasets'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`neftune_noise_alpha` (`Optional[float]`) — 如果不是`None`，这将激活NEFTune噪声嵌入。已经证明这可以极大地提高指令微调的模型性能。查看原始论文：[https://arxiv.org/abs/2310.05914](https://arxiv.org/abs/2310.05914)
    和原始代码：[https://github.com/neelsjain/NEFTune](https://github.com/neelsjain/NEFTune)
    model_init_kwargs — (`Optional[Dict]`, *可选*): 传递给实例化模型时的可选kwargs字典 dataset_kwargs
    — (`Optional[Dict]`, *可选*): 创建打包或非打包数据集时要传递的可选kwargs字典'
- en: Class definition of the Supervised Finetuning Trainer (SFT Trainer). This class
    is a wrapper around the `transformers.Trainer` class and inherits all of its attributes
    and methods. The trainer takes care of properly initializing the PeftModel in
    case a user passes a `PeftConfig` object.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 监督微调训练器（SFT Trainer）的类定义。这个类是`transformers.Trainer`类的包装器，并继承了它的所有属性和方法。训练器负责在用户传递`PeftConfig`对象时正确初始化PeftModel。
- en: DPOTrainer
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DPOTrainer
- en: '### `class trl.DPOTrainer`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.DPOTrainer`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L64)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L64)'
- en: '[PRE16]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`transformers.PreTrainedModel`) — The model to train, preferably an
    `AutoModelForSequenceClassification`.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`transformers.PreTrainedModel`) — 要训练的模型，最好是`AutoModelForSequenceClassification`。'
- en: '`ref_model` (`PreTrainedModelWrapper`) — Hugging Face transformer model with
    a casual language modelling head. Used for implicit reward computation and loss.
    If no reference model is provided, the trainer will create a reference model with
    the same architecture as the model to be optimized.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ref_model` (`PreTrainedModelWrapper`) — 带有非正式语言建模头的Hugging Face变换器模型。用于隐式奖励计算和损失。如果没有提供参考模型，训练器将创建一个与要优化的模型具有相同架构的参考模型。'
- en: '`beta` (`float`, defaults to 0.1) — The beta factor in DPO loss. Higher beta
    means less divergence from the initial policy. For the IPO loss, beta is the regularization
    parameter denoted by tau in the paper.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta` (`float`, 默认为0.1）— DPO损失中的beta因子。较高的beta意味着与初始策略的偏差较小。对于IPO损失，beta是论文中表示为tau的正则化参数。'
- en: '`label_smoothing` (`float`, defaults to 0) — The robust DPO label smoothing
    parameter from the [cDPO](https://ericmitchell.ai/cdpo.pdf) report that should
    be between 0 and 0.5.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_smoothing` (`float`, 默认为0) — 来自[cDPO](https://ericmitchell.ai/cdpo.pdf)报告的鲁棒DPO标签平滑参数，应该在0和0.5之间。'
- en: '`loss_type` (`str`, defaults to `"sigmoid"`) — The type of DPO loss to use.
    Either `"sigmoid"` the default DPO loss,`"hinge"` loss from [SLiC](https://arxiv.org/abs/2305.10425)
    paper, `"ipo"` from [IPO](https://arxiv.org/abs/2310.12036) paper, or `"kto"`
    from the HALOs [report](https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf).'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss_type` (`str`, 默认为`"sigmoid"`) — 要使用的DPO损失类型。可以是`"sigmoid"`默认的DPO损失，`"hinge"`来自[SLiC](https://arxiv.org/abs/2305.10425)论文的损失，`"ipo"`来自[IPO](https://arxiv.org/abs/2310.12036)论文，或者`"kto"`来自HALOs[报告](https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf)。'
- en: '`args` (`transformers.TrainingArguments`) — The arguments to use for training.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`args` (`transformers.TrainingArguments`) — 用于训练的参数。'
- en: '`data_collator` (`transformers.DataCollator`) — The data collator to use for
    training. If None is specified, the default data collator (`DPODataCollatorWithPadding`)
    will be used which will pad the sequences to the maximum length of the sequences
    in the batch, given a dataset of paired sequences.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_collator` (`transformers.DataCollator`) — 用于训练的数据整理器。如果未指定None，则将使用默认数据整理器（`DPODataCollatorWithPadding`），该整理器将序列填充到批次中序列的最大长度，给定一组成对序列的数据集。'
- en: '`label_pad_token_id` (`int`, defaults to `-100`) — The label pad token id.
    This argument is required if you want to use the default data collator.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label_pad_token_id` (`int`, 默认为`-100`) — 标签填充标记id。如果要使用默认数据整理器，则需要这个参数。'
- en: '`padding_value` (`int`, defaults to `0`) — The padding value if it is different
    to the tokenizer’s pad_token_id.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_value` (`int`, 默认为`0`) — 如果与分词器的pad_token_id不同，则为填充值。'
- en: '`truncation_mode` (`str`, defaults to `keep_end`) — The truncation mode to
    use, either `keep_end` or `keep_start`. This argument is required if you want
    to use the default data collator.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation_mode` (`str`，默认为`keep_end`) — 要使用的截断模式，可以是`keep_end`或`keep_start`。如果要使用默认的数据收集器，则此参数是必需的。'
- en: '`train_dataset` (`datasets.Dataset`) — The dataset to use for training.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_dataset` (`datasets.Dataset`) — 用于训练的数据集。'
- en: '`eval_dataset` (`datasets.Dataset`) — The dataset to use for evaluation.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eval_dataset` (`datasets.Dataset`) — 用于评估的数据集。'
- en: '`tokenizer` (`transformers.PreTrainedTokenizerBase`) — The tokenizer to use
    for training. This argument is required if you want to use the default data collator.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`transformers.PreTrainedTokenizerBase`) — 用于训练的分词器。如果要使用默认的数据收集器，则此参数是必需的。'
- en: '`model_init` (`Callable[[], transformers.PreTrainedModel]`) — The model initializer
    to use for training. If None is specified, the default model initializer will
    be used.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_init` (`Callable[[], transformers.PreTrainedModel]`) — 用于训练的模型初始化器。如果指定为None，则将使用默认的模型初始化器。'
- en: '`callbacks` (`List[transformers.TrainerCallback]`) — The callbacks to use for
    training.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callbacks` (`List[transformers.TrainerCallback]`) — 用于训练的回调函数。'
- en: '`optimizers` (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`)
    — The optimizer and scheduler to use for training.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizers` (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`)
    — 用于训练的优化器和调度器。'
- en: '`preprocess_logits_for_metrics` (`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`)
    — The function to use to preprocess the logits before computing the metrics.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`preprocess_logits_for_metrics` (`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`)
    — 用于在计算指标之前预处理logits的函数。'
- en: '`max_length` (`int`, defaults to `None`) — The maximum length of the sequences
    in the batch. This argument is required if you want to use the default data collator.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_length` (`int`，默认为`None`) — 批次中序列的最大长度。如果要使用默认的数据收集器，则此参数是必需的。'
- en: '`max_prompt_length` (`int`, defaults to `None`) — The maximum length of the
    prompt. This argument is required if you want to use the default data collator.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_prompt_length` (`int`，默认为`None`) — 提示的最大长度。如果要使用默认的数据收集器，则此参数是必需的。'
- en: '`max_target_length` (`int`, defaults to `None`) — The maximum length of the
    target. This argument is required if you want to use the default data collator
    and your model is an encoder-decoder.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_target_length` (`int`，默认为`None`) — 目标的最大长度。如果要使用默认的数据收集器并且您的模型是编码器-解码器，则此参数是必需的。'
- en: '`peft_config` (`Dict`, defaults to `None`) — The PEFT configuration to use
    for training. If you pass a PEFT configuration, the model will be wrapped in a
    PEFT model.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` (`Dict`，默认为`None`) — 用于训练的PEFT配置。如果传递PEFT配置，则模型将包装在PEFT模型中。'
- en: '`is_encoder_decoder` (`Optional[bool]`, `optional`, defaults to `None`) — If
    no model is provided, we need to know if the model_init returns an encoder-decoder.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_encoder_decoder` (`Optional[bool]`，*可选*，默认为`None`) — 如果没有提供模型，则需要知道model_init是否返回编码器-解码器。'
- en: '`disable_dropout` (`bool`, defaults to `True`) — Whether or not to disable
    dropouts in `model` and `ref_model`.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`disable_dropout` (`bool`，默认为`True`) — 是否在`model`和`ref_model`中禁用dropout。'
- en: '`generate_during_eval` (`bool`, defaults to `False`) — Whether to sample and
    log generations during evaluation step.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_during_eval` (`bool`，默认为`False`) — 是否在评估步骤中进行采样和记录生成结果。'
- en: '`compute_metrics` (`Callable[[EvalPrediction], Dict]`, *optional*) — The function
    to use to compute the metrics. Must take a `EvalPrediction` and return a dictionary
    string to metric values.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compute_metrics` (`Callable[[EvalPrediction], Dict]`，*可选*) — 用于计算指标的函数。必须接受`EvalPrediction`并返回一个字符串到指标值的字典。'
- en: '`precompute_ref_log_probs` (`bool`, defaults to `False`) — Flag to precompute
    reference model log probabilities and evaluation datasets. This is useful if you
    want to train without the reference model and reduce the total GPU memory needed.
    model_init_kwargs — (`Optional[Dict]`, *optional*): Dict of Optional kwargs to
    pass when instantiating the model from a string ref_model_init_kwargs — (`Optional[Dict]`,
    *optional*): Dict of Optional kwargs to pass when instantiating the ref model
    from a string'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`precompute_ref_log_probs` (`bool`，默认为`False`) — 预计算参考模型的对数概率和评估数据集的标志。如果要在没有参考模型的情况下进行训练并减少所需的总GPU内存，则这很有用。model_init_kwargs
    — (`Optional[Dict]`，*可选*): 传递给从字符串实例化模型时的可选kwargs字典 ref_model_init_kwargs — (`Optional[Dict]`，*可选*):
    传递给从字符串实例化参考模型时的可选kwargs字典'
- en: '`model_adapter_name` (`str`, defaults to `None`) — Name of the train target
    PEFT adapter, when using LoRA with multiple adapters.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_adapter_name` (`str`，默认为`None`) — 使用LoRA时训练目标PEFT适配器的名称。'
- en: '`ref_adapter_name` (`str`, defaults to `None`) — Name of the reference PEFT
    adapter, when using LoRA with multiple adapters.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ref_adapter_name` (`str`，默认为`None`) — 使用LoRA时多个适配器的参考PEFT适配器的名称。'
- en: Initialize DPOTrainer.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化DPOTrainer。
- en: '#### `build_tokenized_answer`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_tokenized_answer`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L523)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L523)'
- en: '[PRE17]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Llama tokenizer does satisfy `enc(a + b) = enc(a) + enc(b)`. It does ensure
    `enc(a + b) = enc(a) + enc(a + b)[len(enc(a)):]`. Reference: [https://github.com/EleutherAI/lm-evaluation-harness/pull/531#issuecomment-1595586257](https://github.com/EleutherAI/lm-evaluation-harness/pull/531#issuecomment-1595586257)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Llama tokenizer确实满足`enc(a + b) = enc(a) + enc(b)`。它确保`enc(a + b) = enc(a) +
    enc(a + b)[len(enc(a)):]`。参考：[https://github.com/EleutherAI/lm-evaluation-harness/pull/531#issuecomment-1595586257](https://github.com/EleutherAI/lm-evaluation-harness/pull/531#issuecomment-1595586257)
- en: '#### `compute_reference_log_probs`'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `compute_reference_log_probs`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L731)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L731)'
- en: '[PRE18]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Computes log probabilities of the reference model for a single padded batch
    of a DPO specific dataset.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 计算DPO特定数据集的单个填充批次的参考模型的对数概率。
- en: '#### `concatenated_forward`'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `concatenated_forward`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L936)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L936)'
- en: '[PRE19]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Run the given model on the given batch of inputs, concatenating the chosen and
    rejected inputs together.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定的输入批次上运行给定的模型，将选择的和拒绝的输入连接在一起。
- en: We do this to avoid doing two forward passes, because it’s faster for FSDP.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这样做是为了避免进行两次前向传递，因为对于FSDP来说更快。
- en: '#### `concatenated_inputs`'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `concatenated_inputs`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L755)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L755)'
- en: '[PRE20]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Concatenate the chosen and rejected inputs into a single tensor.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 将所选和拒绝的输入连接成单个张量。
- en: '#### `dpo_loss`'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `dpo_loss`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L817)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L817)'
- en: '[PRE21]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Returns
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: A tuple of three tensors
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 三个张量的元组
- en: (losses, chosen_rewards, rejected_rewards). The losses tensor contains the DPO
    loss for each example in the batch. The chosen_rewards and rejected_rewards tensors
    contain the rewards for the chosen and rejected responses, respectively.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: （损失、所选奖励、拒绝奖励）。损失张量包含批次中每个示例的DPO损失。所选奖励和拒绝奖励张量分别包含所选和拒绝响应的奖励。
- en: Compute the DPO loss for a batch of policy and reference model log probabilities.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 计算一批策略和参考模型对数概率的DPO损失。
- en: '#### `evaluation_loop`'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `evaluation_loop`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L1154)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L1154)'
- en: '[PRE22]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Overriding built-in evaluation loop to store metrics for each batch. Prediction/evaluation
    loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖内置评估循环以存储每个批次的指标。预测/评估循环，由`Trainer.evaluate()`和`Trainer.predict()`共享。
- en: Works both with or without labels.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于有或无标签的情况。
- en: '#### `get_batch_logps`'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_batch_logps`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L898)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L898)'
- en: '[PRE23]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Compute the log probabilities of the given labels under the given logits.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 计算给定标签在给定对数下的对数概率。
- en: '#### `get_batch_loss_metrics`'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_batch_loss_metrics`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L982)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L982)'
- en: '[PRE24]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Compute the DPO loss and other metrics for the given batch of inputs for train
    or test.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 计算给定输入批次的DPO损失和其他指标，用于训练或测试。
- en: '#### `get_batch_samples`'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_batch_samples`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L1064)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L1064)'
- en: '[PRE25]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Generate samples from the model and reference model for the given batch of inputs.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 为给定输入批次的模型和参考模型生成样本。
- en: '#### `get_eval_dataloader`'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_eval_dataloader`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L471)'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L471)'
- en: '[PRE26]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`eval_dataset` (`torch.utils.data.Dataset`, *optional*) — If provided, will
    override `self.eval_dataset`. If it is a [Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset),
    columns not accepted by the `model.forward()` method are automatically removed.
    It must implement `__len__`.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eval_dataset`（`torch.utils.data.Dataset`，*可选*）- 如果提供，将覆盖`self.eval_dataset`。如果是一个[Dataset](https://huggingface.co/docs/datasets/v2.16.1/en/package_reference/main_classes#datasets.Dataset)，不被`model.forward()`方法接受的列将被自动删除。它必须实现`__len__`。'
- en: Returns the evaluation `~torch.utils.data.DataLoader`.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 返回评估`~torch.utils.data.DataLoader`。
- en: Subclass of transformers.src.transformers.trainer.get_eval_dataloader to precompute
    `ref_log_probs`.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 继承自transformers.src.transformers.trainer.get_eval_dataloader以预计算`ref_log_probs`。
- en: '#### `get_train_dataloader`'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_train_dataloader`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L428)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L428)'
- en: '[PRE27]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Returns the training `~torch.utils.data.DataLoader`.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 返回训练`~torch.utils.data.DataLoader`。
- en: Subclass of transformers.src.transformers.trainer.get_train_dataloader to precompute
    `ref_log_probs`.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 继承自transformers.src.transformers.trainer.get_train_dataloader以预计算`ref_log_probs`。
- en: '#### `log`'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `log`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L1204)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L1204)'
- en: '[PRE28]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`logs` (`Dict[str, float]`) — The values to log.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logs`（`Dict[str, float]`）- 要记录的值。'
- en: Log `logs` on the various objects watching training, including stored metrics.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在观察训练的各种对象上记录日志，包括存储的指标。
- en: '#### `null_ref_context`'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `null_ref_context`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L719)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L719)'
- en: '[PRE29]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Context manager for handling null reference model (that is, peft adapter manipulation).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 用于处理空引用模型（即peft适配器操作）的上下文管理器。
- en: '#### `tokenize_row`'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tokenize_row`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L573)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/dpo_trainer.py#L573)'
- en: '[PRE30]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Tokenize a single row from a DPO specific dataset.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 对来自DPO特定数据集的单行进行标记化。
- en: At this stage, we don’t convert to PyTorch tensors yet; we just handle the truncation
    in case the prompt + chosen or prompt + rejected responses is/are too long. First
    we truncate the prompt; if we’re still too long, we truncate the chosen/rejected.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们还没有转换为PyTorch张量；我们只是处理截断，以防提示+所选或提示+拒绝响应太长。首先我们截断提示；如果仍然太长，我们截断所选/拒绝。
- en: We also create the labels for the chosen/rejected responses, which are of length
    equal to the sum of the length of the prompt and the chosen/rejected response,
    with label_pad_token_id for the prompt tokens.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还为所选/拒绝的响应创建标签，其长度等于提示和所选/拒绝响应的长度之和，对于提示标记使用label_pad_token_id。
- en: DDPOConfig
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DDPOConfig
- en: '### `class trl.DDPOConfig`'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.DDPOConfig`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_config.py#L11)'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_config.py#L11)'
- en: '[PRE31]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Configuration class for DDPOTrainer
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: DDPOTrainer的配置类
- en: DDPOTrainer
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DDPOTrainer
- en: '### `class trl.DDPOTrainer`'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.DDPOTrainer`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L55)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L55)'
- en: '[PRE32]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '*`*config**` (`DDPOConfig`) — Configuration object for DDPOTrainer. Check the
    documentation of `PPOConfig` for more — details.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*config**`（`DDPOConfig`）- DDPOTrainer的配置对象。查看`PPOConfig`的文档以获取更多详细信息。'
- en: '*`*reward_function**` (Callable[[torch.Tensor, Tuple[str], Tuple[Any]], torch.Tensor])
    — Reward function to be used —'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*reward_function**`（Callable[[torch.Tensor，Tuple[str]，Tuple[Any]]，torch.Tensor]）-
    要使用的奖励函数'
- en: '*`*prompt_function**` (Callable[[], Tuple[str, Any]]) — Function to generate
    prompts to guide model —'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*prompt_function**`（Callable[[], Tuple[str，Any]）- 生成提示以指导模型的函数'
- en: '*`*sd_pipeline**` (`DDPOStableDiffusionPipeline`) — Stable Diffusion pipeline
    to be used for training. —'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*sd_pipeline**`（`DDPOStableDiffusionPipeline`）- 用于训练的稳定扩散管道。'
- en: '*`*image_samples_hook**` (Optional[Callable[[Any, Any, Any], Any]]) — Hook
    to be called to log images —'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*image_samples_hook**`（可选[Callable[[Any，Any，Any]，Any]）- 要调用以记录图像的挂钩'
- en: 'The DDPOTrainer uses Deep Diffusion Policy Optimization to optimise diffusion
    models. Note, this trainer is heavily inspired by the work here: [https://github.com/kvablack/ddpo-pytorch](https://github.com/kvablack/ddpo-pytorch)
    As of now only Stable Diffusion based pipelines are supported'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: DDPOTrainer使用深度扩散策略优化来优化扩散模型。请注意，此训练器受到这里的工作的启发：[https://github.com/kvablack/ddpo-pytorch](https://github.com/kvablack/ddpo-pytorch)
    目前仅支持基于稳定扩散的管道
- en: '#### `calculate_loss`'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `calculate_loss`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L340)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L340)'
- en: '[PRE33]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Parameters
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`latents` (torch.Tensor) — The latents sampled from the diffusion model, shape:
    [batch_size, num_channels_latents, height, width]'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents`（torch.Tensor）- 从扩散模型中采样的潜变量，形状：[batch_size，num_channels_latents，height，width]'
- en: '`timesteps` (torch.Tensor) — The timesteps sampled from the diffusion model,
    shape: [batch_size]'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps`（torch.Tensor）- 从扩散模型中采样的时间步长，形状：[batch_size]'
- en: '`next_latents` (torch.Tensor) — The next latents sampled from the diffusion
    model, shape: [batch_size, num_channels_latents, height, width]'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`next_latents`（torch.Tensor）- 从扩散模型中采样的下一个潜变量，形状：[batch_size，num_channels_latents，height，width]'
- en: '`log_probs` (torch.Tensor) — The log probabilities of the latents, shape: [batch_size]'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log_probs`（torch.Tensor）- 潜变量的对数概率，形状：[batch_size]'
- en: '`advantages` (torch.Tensor) — The advantages of the latents, shape: [batch_size]'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`advantages`（torch.Tensor）- 潜变量的优势，形状：[batch_size]'
- en: '`embeds` (torch.Tensor) — The embeddings of the prompts, shape: [2*batch_size
    or batch_size, …] Note: the “or” is because if train_cfg is True, the expectation
    is that negative prompts are concatenated to the embeds'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embeds`（torch.Tensor）- 提示的嵌入，形状：[2*batch_size或batch_size，…] 注意：因为如果train_cfg为True，则期望将负提示连接到embeds。'
- en: Calculate the loss for a batch of an unpacked sample
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 计算解包样本批次的损失
- en: '#### `create_model_card`'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_model_card`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L606)'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L606)'
- en: '[PRE34]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Parameters
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`path` (`str`) — The path to save the model card to.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`path`（`str`）- 要保存模型卡的路径。'
- en: '`model_name` (`str`, *optional*) — The name of the model, defaults to `TRL
    DDPO Model`.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_name`（`str`，*可选*）- 模型的名称，默认为`TRL DDPO Model`。'
- en: Creates and saves a model card for a TRL model.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 为TRL模型创建并保存模型卡。
- en: '#### `step`'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L234)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L234)'
- en: '[PRE35]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`epoch` (int) — The current epoch.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epoch`（int）- 当前时期。'
- en: '`global_step` (int) — The current global step.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`global_step`（int）- 当前全局步骤。'
- en: Returns
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: global_step (int)
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: global_step（int）
- en: The updated global step.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的全局步骤。
- en: Perform a single step of training.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 执行一步训练。
- en: 'Side Effects:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 副作用：
- en: Model weights are updated
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型权重已更新
- en: Logs the statistics to the accelerator trackers.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将统计信息记录到加速器跟踪器中。
- en: If `self.image_samples_callback` is not None, it will be called with the prompt_image_pairs,
    global_step, and the accelerator tracker.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`self.image_samples_callback`不为None，则将使用prompt_image_pairs、global_step和加速器跟踪器调用它。
- en: '#### `train`'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `train`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L596)'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/ddpo_trainer.py#L596)'
- en: '[PRE36]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Train the model for a given number of epochs
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 为给定的时期训练模型
- en: IterativeSFTTrainer
  id: totrans-346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IterativeSFTTrainer
- en: '### `class trl.IterativeSFTTrainer`'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class trl.IterativeSFTTrainer`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/iterative_sft_trainer.py#L39)'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/iterative_sft_trainer.py#L39)'
- en: '[PRE37]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Parameters
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '*`*model**` (`PreTrainedModel`) — Model to be optimized, either an ‘AutoModelForCausalLM’
    or an ‘AutoModelForSeq2SeqLM’. — Check the documentation of `PreTrainedModel`
    for more details.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*model**`（`PreTrainedModel`）- 要优化的模型，可以是''AutoModelForCausalLM''或''AutoModelForSeq2SeqLM''。查看`PreTrainedModel`的文档以获取更多详细信息。'
- en: '*`*args**` (`transformers.TrainingArguments`) — — The arguments to use for
    training.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*args**`（`transformers.TrainingArguments`）- 用于训练的参数。'
- en: '*`*tokenizer**` (`PreTrainedTokenizerBase`) — Tokenizer to be used for encoding
    the — data. Check the documentation of `transformers.PreTrainedTokenizer` and
    `transformers.PreTrainedTokenizerFast` for more details.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*tokenizer**`（`PreTrainedTokenizerBase`）- 用于编码数据的分词器。查看`transformers.PreTrainedTokenizer`和`transformers.PreTrainedTokenizerFast`的文档以获取更多详细信息。'
- en: '*`*optimizers**` (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`)
    — — The optimizer and scheduler to use for training.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*optimizers**`（`Tuple[torch.optim.Optimizer，torch.optim.lr_scheduler.LambdaLR]`）-
    用于训练的优化器和调度程序。'
- en: '*`*data_collator**` (Union[DataCollatorForLanguageModeling, DataCollatorForSeq2Seq],
    *optional*) — Data collator to be used for training and — passed along the dataloader.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*data_collator**`（Union[DataCollatorForLanguageModeling，DataCollatorForSeq2Seq]，*可选*）-
    用于训练和传递给数据加载器的数据整理器。'
- en: '*`*eval_dataset**` (`datasets.Dataset`) — The dataset to use for evaluation.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*eval_dataset**`（`datasets.Dataset`）- 用于评估的数据集。'
- en: '*`*max_length**` (`int`, defaults to `None`) — — The maximum length of the
    input.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*max_length**`（`int`，默认为`None`）- 输入的最大长度。'
- en: '*`*truncation_mode**` (`str`, defaults to `keep_end`) — — The truncation mode
    to use, either `keep_end` or `keep_start`.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*truncation_mode**`（`str`，默认为`keep_end`）- 要使用的截断模式，可以是`keep_end`或`keep_start`。'
- en: '*`*preprocess_logits_for_metrics**` (`Callable[[torch.Tensor, torch.Tensor],
    torch.Tensor]`) — — The function to use to preprocess the logits before computing
    the metrics.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*preprocess_logits_for_metrics**`（`Callable[[torch.Tensor, torch.Tensor],
    torch.Tensor]`）- 用于在计算指标之前预处理logits的函数。'
- en: '*`*compute_metrics**` (`Callable[[EvalPrediction], Dict]`, *optional*) — —
    The function to use to compute the metrics. Must take a `EvalPrediction` and return
    a dictionary string to metric values.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*compute_metrics**`（`Callable[[EvalPrediction], Dict]`，*可选*）- 用于计算指标的函数。必须接受`EvalPrediction`并返回一个字符串字典以表示指标值。'
- en: '*`*optimize_device_cache` * *(`bool`,* optional*, defaults to `False`) — Optimize
    CUDA cache for slightly more memory-efficient training. —'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*`*optimize_device_cache` * *（`bool`，*可选*，默认为`False`）- 优化CUDA缓存以实现略微更节省内存的训练。'
- en: The IterativeSFTTrainer can be used to finetune models with methods that requires
    some steps between optimization.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: IterativeSFTTrainer可用于微调需要在优化之间执行一些步骤的方法的模型。
- en: '#### `step`'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/iterative_sft_trainer.py#L229)'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/trainer/iterative_sft_trainer.py#L229)'
- en: '[PRE38]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Parameters
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (List`torch.LongTensor`) — List of tensors containing the input_ids
    (if not provided, text will be used)'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（List`torch.LongTensor`）- 包含input_ids的张量列表（如果未提供，将使用文本）'
- en: '`attention_mask` (List`torch.LongTensor`, , *optional*) — List of tensors containing
    the attention_mask'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（List`torch.LongTensor`，*可选*）- 包含注意力掩码的张量列表'
- en: '`labels` (List`torch.FloatTensor`, *optional*) — List of tensors containing
    the labels (if set to None, will default to input_ids)'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（List`torch.FloatTensor`，*可选*）- 包含标签的张量列表（如果设置为None，将默认为input_ids）'
- en: '`texts` (List`str`, *optional*) — List of strings containing the text input
    (if not provided, input_ids will directly be used)'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`texts`（List`str`，*可选*）- 包含文本输入的字符串列表（如果未提供，将直接使用input_ids）'
- en: '`texts_labels` (List`str`, *optional*) — List of strings containing the text
    labels (if set to None, will default to text)'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`texts_labels`（List`str`，*可选*）- 包含文本标签的字符串列表（如果设置为None，将默认为文本）'
- en: Returns
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`dict[str, Any]`'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '`dict[str, Any]`'
- en: A summary of the training statistics
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 训练统计摘要
- en: Run an optimisation step given a list of input_ids, attention_mask, and labels
    or a list of text and text_labels.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 给定input_ids、attention_mask和labels列表或文本和text_labels列表，运行优化步骤。
- en: set_seed
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: set_seed
- en: '#### `trl.set_seed`'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `trl.set_seed`'
- en: '[< source >](https://github.com/huggingface/trl/blob/v0.7.10/trl/core.py#L209)'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/trl/blob/v0.7.10/trl/core.py#L209)'
- en: '[PRE39]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Parameters
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`seed` (`int`) — The seed to set.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seed`（`int`）- 要设置的种子。'
- en: Helper function for reproducible behavior to set the seed in `random`, `numpy`,
    and `torch`.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 用于设置`random`，`numpy`和`torch`种子以获得可重现行为的辅助函数。
