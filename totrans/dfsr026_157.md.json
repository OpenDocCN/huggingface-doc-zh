["```py\n>>> import torch\n>>> from diffusers import SemanticStableDiffusionPipeline\n\n>>> pipe = SemanticStableDiffusionPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> out = pipe(\n...     prompt=\"a photo of the face of a woman\",\n...     num_images_per_prompt=1,\n...     guidance_scale=7,\n...     editing_prompt=[\n...         \"smiling, smile\",  # Concepts to apply\n...         \"glasses, wearing glasses\",\n...         \"curls, wavy hair, curly hair\",\n...         \"beard, full beard, mustache\",\n...     ],\n...     reverse_editing_direction=[\n...         False,\n...         False,\n...         False,\n...         False,\n...     ],  # Direction of guidance i.e. increase all concepts\n...     edit_warmup_steps=[10, 10, 10, 10],  # Warmup period for each concept\n...     edit_guidance_scale=[4, 5, 5, 5.4],  # Guidance scale for each concept\n...     edit_threshold=[\n...         0.99,\n...         0.975,\n...         0.925,\n...         0.96,\n...     ],  # Threshold for each concept. Threshold equals the percentile of the latent space that will be discarded. I.e. threshold=0.99 uses 1% of the latent dimensions\n...     edit_momentum_scale=0.3,  # Momentum scale that will be added to the latent guidance\n...     edit_mom_beta=0.6,  # Momentum beta\n...     edit_weights=[1, 1, 1, 1, 1],  # Weights of the individual concepts against each other\n... )\n>>> image = out.images[0]\n```"]