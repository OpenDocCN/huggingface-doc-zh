- en: FNet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FNet
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/fnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/fnet)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '原文链接: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/fnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/fnet)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The FNet model was proposed in [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824)
    by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon. The model
    replaces the self-attention layer in a BERT model with a fourier transform which
    returns only the real parts of the transform. The model is significantly faster
    than the BERT model because it has fewer parameters and is more memory efficient.
    The model achieves about 92-97% accuracy of BERT counterparts on GLUE benchmark,
    and trains much faster than the BERT model. The abstract from the paper is the
    following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'FNet 模型由 James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon 在
    [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824)
    中提出。该模型用傅立叶变换替换了 BERT 模型中的自注意力层，仅返回变换的实部。该模型比 BERT 模型快得多，因为它具有更少的参数并且更节省内存。该模型在
    GLUE 基准测试中达到了约 92-97% 的准确率，并且比 BERT 模型训练速度更快。论文的摘要如下：'
- en: '*We show that Transformer encoder architectures can be sped up, with limited
    accuracy costs, by replacing the self-attention sublayers with simple linear transformations
    that “mix” input tokens. These linear mixers, along with standard nonlinearities
    in feed-forward layers, prove competent at modeling semantic relationships in
    several text classification tasks. Most surprisingly, we find that replacing the
    self-attention sublayer in a Transformer encoder with a standard, unparameterized
    Fourier Transform achieves 92-97% of the accuracy of BERT counterparts on the
    GLUE benchmark, but trains 80% faster on GPUs and 70% faster on TPUs at standard
    512 input lengths. At longer input lengths, our FNet model is significantly faster:
    when compared to the “efficient” Transformers on the Long Range Arena benchmark,
    FNet matches the accuracy of the most accurate models, while outpacing the fastest
    models across all sequence lengths on GPUs (and across relatively shorter lengths
    on TPUs). Finally, FNet has a light memory footprint and is particularly efficient
    at smaller model sizes; for a fixed speed and accuracy budget, small FNet models
    outperform Transformer counterparts.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们展示了 Transformer 编码器架构可以通过用简单的线性变换替换自注意力子层来加速，且准确性损失有限。这些线性混合器，以及前馈层中的标准非线性，在几个文本分类任务中证明了在建模语义关系方面的能力。最令人惊讶的是，我们发现将
    Transformer 编码器中的自注意力子层替换为标准的、无参数的傅立叶变换，在 GLUE 基准测试中达到了 BERT 对应模型准确率的 92-97%，但在
    GPU 上训练速度快 80%，在 TPU 上快 70%，在标准的 512 输入长度下。在更长的输入长度下，我们的 FNet 模型速度显著更快：与 Long
    Range Arena 基准测试中的“高效”Transformer相比，FNet 在 GPU 上与最准确的模型匹敌，同时在所有序列长度上超过最快的模型（在
    TPU 上相对较短的长度）。最后，FNet 具有轻量级的内存占用，并且在较小的模型尺寸上特别高效；对于固定的速度和准确性预算，小型的 FNet 模型胜过 Transformer
    对应模型。*'
- en: This model was contributed by [gchhablani](https://huggingface.co/gchhablani).
    The original code can be found [here](https://github.com/google-research/google-research/tree/master/f_net).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由 [gchhablani](https://huggingface.co/gchhablani) 贡献。原始代码可以在 [这里](https://github.com/google-research/google-research/tree/master/f_net)
    找到。
- en: Usage tips
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: The model was trained without an attention mask as it is based on Fourier Transform.
    The model was trained with maximum sequence length 512 which includes pad tokens.
    Hence, it is highly recommended to use the same maximum sequence length for fine-tuning
    and inference.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在训练时没有使用注意力掩码，因为它基于傅立叶变换。该模型在最大序列长度为 512 的情况下进行训练，其中包括填充标记。因此，强烈建议在微调和推理时使用相同的最大序列长度。
- en: Resources
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: '[Text classification task guide](../tasks/sequence_classification)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文本分类任务指南](../tasks/sequence_classification)'
- en: '[Token classification task guide](../tasks/token_classification)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[标记分类任务指南](../tasks/token_classification)'
- en: '[Question answering task guide](../tasks/question_answering)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[问答任务指南](../tasks/question_answering)'
- en: '[Masked language modeling task guide](../tasks/masked_language_modeling)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[遮蔽语言建模任务指南](../tasks/masked_language_modeling)'
- en: '[Multiple choice task guide](../tasks/multiple_choice)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多选任务指南](../tasks/multiple_choice)'
- en: FNetConfig
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FNetConfig
- en: '### `class transformers.FNetConfig`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FNetConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/configuration_fnet.py#L30)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/configuration_fnet.py#L30)'
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 32000) — Vocabulary size of the
    FNet model. Defines the number of different tokens that can be represented by
    the `inputs_ids` passed when calling [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    or `TFFNetModel`.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size` (`int`, *optional*, defaults to 32000) — FNet 模型的词汇表大小。定义了在调用
    [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    或 `TFFNetModel` 时可以表示的不同标记的数量。'
- en: '`hidden_size` (`int`, *optional*, defaults to 768) — Dimension of the encoder
    layers and the pooler layer.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size` (`int`, *optional*, defaults to 768) — 编码器层和池化器层的维度。'
- en: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Number of hidden
    layers in the Transformer encoder.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_hidden_layers` (`int`, *optional*, defaults to 12) — Transformer 编码器中的隐藏层数量。'
- en: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Dimension of the
    “intermediate” (i.e., feed-forward) layer in the Transformer encoder.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`intermediate_size` (`int`, *optional*, defaults to 3072) — Transformer 编码器中“中间”（即前馈）层的维度。'
- en: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu_new"`) —
    The non-linear activation function (function or string) in the encoder and pooler.
    If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"` are supported.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str` or `function`, *optional*, defaults to `"gelu_new"`) —
    编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持 `"gelu"`, `"relu"`, `"selu"` 和 `"gelu_new"`。'
- en: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — The dropout
    probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_dropout_prob` (`float`, *optional*, defaults to 0.1) — 嵌入层、编码器和池化器中所有全连接层的丢弃概率。'
- en: '`max_position_embeddings` (`int`, *optional*, defaults to 512) — The maximum
    sequence length that this model might ever be used with. Typically set this to
    something large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`type_vocab_size` (`int`, *optional*, defaults to 4) — The vocabulary size
    of the `token_type_ids` passed when calling [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    or `TFFNetModel`.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`initializer_range` (`float`, *optional*, defaults to 0.02) — The standard
    deviation of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — The epsilon used
    by the layer normalization layers.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_tpu_fourier_optimizations` (`bool`, *optional*, defaults to `False`) —
    Determines whether to use TPU optimized FFTs. If `True`, the model will favor
    axis-wise FFTs transforms. Set to `False` for GPU/CPU hardware, in which case
    n-dimensional FFTs are used.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tpu_short_seq_length` (`int`, *optional*, defaults to 512) — The sequence
    length that is expected by the model when using TPUs. This will be used to initialize
    the DFT matrix only when *use_tpu_fourier_optimizations* is set to `True` and
    the input sequence is shorter than or equal to 4096 tokens.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the configuration class to store the configuration of a [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel).
    It is used to instantiate an FNet model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the FNet [google/fnet-base](https://huggingface.co/google/fnet-base)
    architecture.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: FNetTokenizer
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FNetTokenizer`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet.py#L46)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab_file` (`str`) — [SentencePiece](https://github.com/google/sentencepiece)
    file (generally has a *.spm* extension) that contains the vocabulary necessary
    to instantiate a tokenizer.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_lower_case` (`bool`, *optional*, defaults to `False`) — Whether or not
    to lowercase the input when tokenizing.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`remove_space` (`bool`, *optional*, defaults to `True`) — Whether or not to
    strip the text when tokenizing (removing excess spaces before and after the string).'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`keep_accents` (`bool`, *optional*, defaults to `True`) — Whether or not to
    keep accents when tokenizing.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sp_model_kwargs` (`dict`, *optional*) — Will be passed to the `SentencePieceProcessor.__init__()`
    method. The [Python wrapper for SentencePiece](https://github.com/google/sentencepiece/tree/master/python)
    can be used, among other things, to set:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sp_model_kwargs`（`dict`，*可选*）- 将传递给`SentencePieceProcessor.__init__()`方法。可以使用[SentencePiece的Python包装器](https://github.com/google/sentencepiece/tree/master/python)，其中包括设置：'
- en: '`enable_sampling`: Enable subword regularization.'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enable_sampling`：启用子词正则化。'
- en: '`nbest_size`: Sampling parameters for unigram. Invalid for BPE-Dropout.'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size`：unigram的抽样参数。对于BPE-Dropout无效。'
- en: '`nbest_size = {0,1}`: No sampling is performed.'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size = {0,1}`：不执行抽样。'
- en: '`nbest_size > 1`: samples from the nbest_size results.'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size > 1`：从nbest_size结果中抽样。'
- en: '`nbest_size < 0`: assuming that nbest_size is infinite and samples from the
    all hypothesis (lattice) using forward-filtering-and-backward-sampling algorithm.'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbest_size < 0`：假设nbest_size是无限的，并使用前向过滤和后向抽样算法从所有假设（格）中抽样。'
- en: '`alpha`: Smoothing parameter for unigram sampling, and dropout probability
    of merge operations for BPE-dropout.'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`：用于unigram抽样的平滑参数，以及用于BPE-dropout的合并操作的丢弃概率。'
- en: '`sp_model` (`SentencePieceProcessor`) — The *SentencePiece* processor that
    is used for every conversion (string, tokens and IDs).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sp_model`（`SentencePieceProcessor`）- 用于每次转换（字符串、标记和ID）的*SentencePiece*处理器。'
- en: Construct an FNet tokenizer. Adapted from [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer).
    Based on [SentencePiece](https://github.com/google/sentencepiece). This tokenizer
    inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个FNet标记器。改编自[AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)。基于[SentencePiece](https://github.com/google/sentencepiece)。此标记器继承自[PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet.py#L254)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet.py#L254)'
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs to which the special tokens will
    be added.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）- 将添加特殊标记的ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）- 序列对的第二个ID列表（可选）。'
- en: Returns
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 具有适当特殊标记的[输入ID列表](../glossary#input-ids)。
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. An FNet sequence has the following
    format:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 通过连接和添加特殊标记，从序列或序列对构建用于序列分类任务的模型输入。FNet序列具有以下格式：
- en: 'single sequence: `[CLS] X [SEP]`'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个序列：`[CLS] X [SEP]`
- en: 'pair of sequences: `[CLS] A [SEP] B [SEP]`'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列对：`[CLS] A [SEP] B [SEP]`
- en: '#### `get_special_tokens_mask`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_special_tokens_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet.py#L279)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet.py#L279)'
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）- ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）- 序列对的第二个ID列表（可选）。'
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`already_has_special_tokens`（`bool`，*可选*，默认为`False`）- 标记列表是否已经格式化为模型的特殊标记。'
- en: Returns
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 一个整数列表，范围为[0, 1]：1表示特殊标记，0表示序列标记。
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从没有添加特殊标记的标记列表中检索序列id。在使用标记器`prepare_for_model`方法添加特殊标记时调用此方法。
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet.py#L307)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet.py#L307)'
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）- ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）- 序列对的第二个ID列表（可选）。'
- en: Returns
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [token type IDs](../glossary#token-type-ids) according to the given
    sequence(s).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 根据给定序列的[标记类型ID列表](../glossary#token-type-ids)。
- en: Create a mask from the two sequences passed to be used in a sequence-pair classification
    task. An FNet sequence
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 从传递的两个序列创建一个掩码，用于在序列对分类任务中使用。一个FNet序列
- en: 'pair mask has the following format: :'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 序列对掩码的格式如下：
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If `token_ids_1` is `None`, this method only returns the first portion of the
    mask (0s).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`token_ids_1`为`None`，则此方法仅返回掩码的第一部分（0）。
- en: '#### `save_vocabulary`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_vocabulary`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet.py#L336)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet.py#L336)'
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: FNetTokenizerFast
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FNetTokenizerFast
- en: '### `class transformers.FNetTokenizerFast`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FNetTokenizerFast`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet_fast.py#L54)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet_fast.py#L54)'
- en: '[PRE8]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — [SentencePiece](https://github.com/google/sentencepiece)
    file (generally has a *.spm* extension) that contains the vocabulary necessary
    to instantiate a tokenizer.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file`（`str`）- 包含实例化标记器所需词汇的[SentencePiece](https://github.com/google/sentencepiece)文件（通常具有*.spm*扩展名）。'
- en: '`do_lower_case` (`bool`, *optional*, defaults to `False`) — Whether or not
    to lowercase the input when tokenizing.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_lower_case`（`bool`，*可选*，默认为`False`）— 在标记化时是否将输入转换为小写。'
- en: '`remove_space` (`bool`, *optional*, defaults to `True`) — Whether or not to
    strip the text when tokenizing (removing excess spaces before and after the string).'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`remove_space`（`bool`，*可选*，默认为`True`）— 在标记化时是否去除文本中的空格（删除字符串前后的多余空格）。'
- en: '`keep_accents` (`bool`, *optional*, defaults to `True`) — Whether or not to
    keep accents when tokenizing.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keep_accents`（`bool`，*可选*，默认为`True`）— 在标记化时是否保留重音。'
- en: '`unk_token` (`str`, *optional*, defaults to `"<unk>"`) — The unknown token.
    A token that is not in the vocabulary cannot be converted to an ID and is set
    to be this token instead.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token`（`str`，*可选*，默认为`"<unk>"`）— 未知标记。词汇表中不存在的标记无法转换为ID，而是设置为此标记。'
- en: '`sep_token` (`str`, *optional*, defaults to `"[SEP]"`) — The separator token,
    which is used when building a sequence from multiple sequences, e.g. two sequences
    for sequence classification or for a text and a question for question answering.
    It is also used as the last token of a sequence built with special tokens.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sep_token`（`str`，*可选*，默认为`"[SEP]"`）— 分隔符标记，在从多个序列构建序列时使用，例如用于序列分类的两个序列或用于问题回答的文本和问题。它还用作使用特殊标记构建的序列的最后一个标记。'
- en: '`pad_token` (`str`, *optional*, defaults to `"<pad>"`) — The token used for
    padding, for example when batching sequences of different lengths.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token`（`str`，*可选*，默认为`"<pad>"`）— 用于填充的标记，例如在批处理不同长度的序列时。'
- en: '`cls_token` (`str`, *optional*, defaults to `"[CLS]"`) — The classifier token
    which is used when doing sequence classification (classification of the whole
    sequence instead of per-token classification). It is the first token of the sequence
    when built with special tokens.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_token`（`str`，*可选*，默认为`"[CLS]"`）— 分类器标记，用于进行序列分类（对整个序列进行分类，而不是对每个标记进行分类）。在使用特殊标记构建时，它是序列的第一个标记。'
- en: '`mask_token` (`str`, *optional*, defaults to `"[MASK]"`) — The token used for
    masking values. This is the token used when training this model with masked language
    modeling. This is the token which the model will try to predict.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_token`（`str`，*可选*，默认为`"[MASK]"`）— 用于屏蔽值的标记。这是在使用掩码语言建模训练此模型时使用的标记。这是模型将尝试预测的标记。'
- en: Construct a “fast” FNetTokenizer (backed by HuggingFace’s *tokenizers* library).
    Adapted from [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast).
    Based on [Unigram](https://huggingface.co/docs/tokenizers/python/latest/components.html?highlight=unigram#models).
    This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个“快速”FNetTokenizer（由HuggingFace的*tokenizers*库支持）。改编自[AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)。基于[Unigram](https://huggingface.co/docs/tokenizers/python/latest/components.html?highlight=unigram#models)。此标记器继承自[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)，其中包含大多数主要方法。用户应参考此超类以获取有关这些方法的更多信息
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet_fast.py#L138)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet_fast.py#L138)'
- en: '[PRE9]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs to which the special tokens will
    be added'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）— 要添加特殊标记的ID列表'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个ID列表。'
- en: Returns
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: list of [input IDs](../glossary#input-ids) with the appropriate special tokens.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 具有适当特殊标记的[input IDs](../glossary#input-ids)列表。
- en: 'Build model inputs from a sequence or a pair of sequence for sequence classification
    tasks by concatenating and adding special tokens. An FNet sequence has the following
    format:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 从序列或序列对构建模型输入，用于序列分类任务，通过连接和添加特殊标记。一个FNet序列具有以下格式：
- en: 'single sequence: `[CLS] X [SEP]`'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个序列：`[CLS] X [SEP]`
- en: 'pair of sequences: `[CLS] A [SEP] B [SEP]`'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列对：`[CLS] A [SEP] B [SEP]`
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet_fast.py#L163)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/tokenization_fnet_fast.py#L163)'
- en: '[PRE10]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of ids.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）— ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个ID列表。'
- en: Returns
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: List of [token type IDs](../glossary#token-type-ids) according to the given
    sequence(s).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 根据给定序列的[标记类型ID](../glossary#token-type-ids)列表。
- en: Creates a mask from the two sequences passed to be used in a sequence-pair classification
    task. An FNet
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 从传递的两个序列创建一个用于序列对分类任务的掩码。一个FNet
- en: 'sequence pair mask has the following format:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 序列对掩码具有以下格式：
- en: '[PRE11]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: if token_ids_1 is None, only returns the first portion of the mask (0s).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果token_ids_1为None，则仅返回掩码的第一部分（0s）。
- en: FNetModel
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FNetModel
- en: '### `class transformers.FNetModel`'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L500)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L500)'
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: The bare FNet Model transformer outputting raw hidden-states without any specific
    head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 裸 FNet 模型变压器输出原始隐藏状态，没有特定的顶部头。该模型是 PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    子类。将其用作常规 PyTorch 模块，并参考 PyTorch 文档以获取有关一般用法和行为的所有相关信息。
- en: 'The model can behave as an encoder, following the architecture described in
    [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824)
    by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '该模型可以作为编码器运行，遵循 [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824)
    中描述的架构，作者为 James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon。'
- en: '#### `forward`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L530)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L530)'
- en: '[PRE13]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参阅 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入 ID？](../glossary#input-ids)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 段标记索引，指示输入的第一部分和第二部分。索引选择在 `[0, 1]` 中：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于 *句子 A* 标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是令牌类型 ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 每个输入序列标记在位置嵌入中的位置索引。在范围 `[0, config.max_position_embeddings - 1]`
    中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置 ID？](../glossary#position-ids)'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，可以直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将 *input_ids*
    索引转换为相关向量，这将很有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: Returns
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值
- en: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    and inputs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.modeling_outputs.BaseModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput)
    或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或 `config.return_dict=False`
    时）包含不同元素，具体取决于配置（[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)）和输入。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — 模型最后一层的隐藏状态序列。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）—形状为`(batch_size,
    sequence_length, hidden_size)`的`torch.FloatTensor`元组（一个用于嵌入的输出，如果模型有一个嵌入层，+一个用于每一层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态加上可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）—形状为`(batch_size,
    num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在注意力softmax之后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Example:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE14]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: FNetForPreTraining
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FNetForPreTraining
- en: '### `class transformers.FNetForPreTraining`'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FNetForPreTraining`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L606)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L606)'
- en: '[PRE15]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: 'FNet Model with two heads on top as done during the pretraining: a `masked
    language modeling` head and a `next sentence prediction (classification)` head.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: FNet模型在预训练期间在顶部有两个头部：一个`掩码语言建模`头部和一个`下一个句子预测（分类）`头部。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 前进
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L631)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L631)'
- en: '[PRE16]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`）— 词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入ID？](../glossary#input-ids)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）—
    段标记索引，用于指示输入的第一部分和第二部分。索引在`[0, 1]`中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0对应于*句子A*标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1对应于*句子B*标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）—
    每个输入序列标记的位置的索引在位置嵌入中。在范围`[0, config.max_position_embeddings - 1]`中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置ID？](../glossary#position-ids)'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds`（形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    可选地，您可以直接传递一个嵌入表示，而不是传递`input_ids`。如果您想要更多控制如何将*input_ids*索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，这是有用的。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should be in
    `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-100` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`标签`（`torch.LongTensor`，形状为`(batch_size, sequence_length)`，*可选*）— 用于计算掩码语言建模损失的标签。索引应在`[-100,
    0, ..., config.vocab_size]`范围内（参见`input_ids`文档字符串）。索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有标签在`[0,
    ..., config.vocab_size]`范围内的标记。'
- en: '`next_sentence_label` (`torch.LongTensor` of shape `(batch_size,)`, *optional*)
    — Labels for computing the next sequence prediction (classification) loss. Input
    should be a sequence pair (see `input_ids` docstring) Indices should be in `[0,
    1]`:'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`next_sentence_label`（形状为`(batch_size,)`的`torch.LongTensor`，*可选*）— 用于计算下一个序列预测（分类）损失的标签。输入应为一个序列对（参见`input_ids`文档字符串）。索引应在`[0,
    1]`范围内：'
- en: 0 indicates sequence B is a continuation of sequence A,
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示序列B是序列A的延续，
- en: 1 indicates sequence B is a random sequence.
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示序列B是一个随机序列。
- en: '`kwargs` (`Dict[str, any]`, optional, defaults to *{}*) — Used to hide legacy
    arguments that have been deprecated.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（`Dict[str, any]`，可选，默认为*{}*）— 用于隐藏已弃用的旧参数。'
- en: Returns
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.models.fnet.modeling_fnet.FNetForPreTrainingOutput` or `tuple(torch.FloatTensor)`'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.models.fnet.modeling_fnet.FNetForPreTrainingOutput`或`tuple(torch.FloatTensor)`'
- en: A `transformers.models.fnet.modeling_fnet.FNetForPreTrainingOutput` or a tuple
    of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    and inputs.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.models.fnet.modeling_fnet.FNetForPreTrainingOutput`或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或当`config.return_dict=False`时）包含根据配置（[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)）和输入的各种元素。
- en: '`loss` (*optional*, returned when `labels` is provided, `torch.FloatTensor`
    of shape `(1,)`) — Total loss as the sum of the masked language modeling loss
    and the next sequence prediction (classification) loss.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（*可选*，当提供`labels`时返回，形状为`(1,)`的`torch.FloatTensor`）— 总损失，作为掩码语言建模损失和下一个序列预测（分类）损失的总和。'
- en: '`prediction_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    config.vocab_size)`) — Prediction scores of the language modeling head (scores
    for each vocabulary token before SoftMax).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`torch.FloatTensor`）—
    语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`seq_relationship_logits` (`torch.FloatTensor` of shape `(batch_size, 2)`)
    — Prediction scores of the next sequence prediction (classification) head (scores
    of True/False continuation before SoftMax).'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seq_relationship_logits`（形状为`(batch_size, 2)`的`torch.FloatTensor`）— 下一个序列预测（分类）头的预测分数（SoftMax之前的True/False延续分数）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`. Hidden-states of the model at the
    output of each layer plus the initial embedding outputs.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。模型在每一层输出的隐藏状态加上初始嵌入输出。'
- en: The [FNetForPreTraining](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForPreTraining)
    forward method, overrides the `__call__` special method.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[FNetForPreTraining](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForPreTraining)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Example:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE17]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: FNetForMaskedLM
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FNetForMaskedLM
- en: '### `class transformers.FNetForMaskedLM`'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FNetForMaskedLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L706)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L706)'
- en: '[PRE18]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)）—
    具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: FNet Model with a `language modeling` head on top. This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: FNet模型顶部带有`语言建模`头。此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有信息。
- en: '#### `forward`'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L725)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L725)'
- en: '[PRE19]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    词汇表中输入序列标记的索引。'
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参阅 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是输入 ID？](../glossary#input-ids)'
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 指示输入的第一部分和第二部分的段标记索引。索引在 `[0, 1]` 中选择：'
- en: 0 corresponds to a *sentence A* token,
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 对应于 *句子 A* 标记，
- en: 1 corresponds to a *sentence B* token.
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 对应于 *句子 B* 标记。
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是标记类型 ID？](../glossary#token-type-ids)'
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 每个输入序列标记在位置嵌入中的位置索引。在范围 `[0, config.max_position_embeddings - 1]`
    中选择。'
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是位置 ID？](../glossary#position-ids)'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，可以直接传递嵌入表示而不是 `input_ids`。如果您想要更多控制如何将 *input_ids*
    索引转换为相关向量，这将非常有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的
    `hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should be in
    `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices
    set to `-100` are ignored (masked), the loss is only computed for the tokens with
    labels in `[0, ..., config.vocab_size]`.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — 用于计算掩码语言建模损失的标签。索引应在 `[-100, 0, ..., config.vocab_size]` 中（参见 `input_ids` 文档字符串）。索引设置为
    `-100` 的标记将被忽略（掩码），损失仅计算具有标签在 `[0, ..., config.vocab_size]` 中的标记。'
- en: Returns
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    and inputs.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.modeling_outputs.MaskedLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput)
    或 `torch.FloatTensor` 元组（如果传递 `return_dict=False` 或 `config.return_dict=False`）包含根据配置（[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Masked language modeling (MLM) loss.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供 `labels` 时返回)
    — 掩码语言建模（MLM）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax 之前每个词汇标记的分数）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递 `output_hidden_states=True`
    或 `config.output_hidden_states=True` 时返回) — 形状为 `(batch_size, sequence_length,
    hidden_size)` 的 `torch.FloatTensor` 元组（如果模型有嵌入层，则为嵌入输出的一个 + 每层输出的一个）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [FNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMaskedLM)
    forward method, overrides the `__call__` special method.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: FNetForNextSentencePrediction
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FNetForNextSentencePrediction`'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L773)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FNet Model with a `next sentence prediction (classification)` head on top. This
    model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L787)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the next sequence prediction (classification) loss. Input should
    be a sequence pair (see `input_ids` docstring). Indices should be in `[0, 1]`:'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates sequence B is a continuation of sequence A,
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates sequence B is a random sequence.
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.NextSentencePredictorOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.NextSentencePredictorOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.NextSentencePredictorOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.NextSentencePredictorOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    and inputs.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `next_sentence_label`
    is provided) — Next sequence prediction (classification) loss.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, 2)`) — Prediction scores
    of the next sequence prediction (classification) head (scores of True/False continuation
    before SoftMax).'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [FNetForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForNextSentencePrediction)
    forward method, overrides the `__call__` special method.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: FNetForSequenceClassification
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FNetForSequenceClassification`'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L865)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FNet Model transformer with a sequence classification/regression head on top
    (a linear layer on top of the pooled output) e.g. for GLUE tasks.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L884)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[0, ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression loss
    is computed (Mean-Square loss), If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    and inputs.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [FNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForSequenceClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of single-label classification:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Example of multi-label classification:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: FNetForMultipleChoice
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FNetForMultipleChoice`'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L950)'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FNet Model with a multiple choice classification head on top (a linear layer
    on top of the pooled output and a softmax) e.g. for RocStories/SWAG tasks.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L968)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, num_choices, sequence_length)`)
    — Indices of input sequence tokens in the vocabulary.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, num_choices, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-347
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, num_choices, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_choices, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the multiple choice classification loss. Indices should be in `[0,
    ..., num_choices-1]` where `num_choices` is the size of the second dimension of
    the input tensors. (See `input_ids` above)'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.MultipleChoiceModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MultipleChoiceModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.MultipleChoiceModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.MultipleChoiceModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    and inputs.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape *(1,)*, *optional*, returned when `labels`
    is provided) — Classification loss.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, num_choices)`) — *num_choices*
    is the second dimension of the input tensors. (see *input_ids* above).'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification scores (before SoftMax).
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [FNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMultipleChoice)
    forward method, overrides the `__call__` special method.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: FNetForTokenClassification
  id: totrans-369
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FNetForTokenClassification`'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L1029)'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FNet Model with a token classification head on top (a linear layer on top of
    the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L1049)'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-385
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-386
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the token classification loss. Indices should be in `[0,
    ..., config.num_labels - 1]`.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.TokenClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    and inputs.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification loss.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_labels)`)
    — Classification scores (before SoftMax).'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [FNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForTokenClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: FNetForQuestionAnswering
  id: totrans-407
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.FNetForQuestionAnswering`'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L1098)'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Parameters
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: '`config` ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FNet Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    sub-class. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: '#### `forward`'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/fnet/modeling_fnet.py#L1117)'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[What are input IDs?](../glossary#input-ids)'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`token_type_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Segment token indices to indicate first and second portions of the
    inputs. Indices are selected in `[0, 1]`:'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 corresponds to a *sentence A* token,
  id: totrans-423
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 corresponds to a *sentence B* token.
  id: totrans-424
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are token type IDs?](../glossary#token-type-ids)'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`position_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each input sequence tokens in the position
    embeddings. Selected in the range `[0, config.max_position_embeddings - 1]`.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are position IDs?](../glossary#position-ids)'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert *input_ids* indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*)
    — Labels for position (index) of the start of the labelled span for computing
    the token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_positions` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) —
    Labels for position (index) of the end of the labelled span for computing the
    token classification loss. Positions are clamped to the length of the sequence
    (`sequence_length`). Position outside of the sequence are not taken into account
    for computing the loss.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.QuestionAnsweringModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig))
    and inputs.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Total span extraction loss is the sum of a Cross-Entropy for the
    start and end positions.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Span-start scores (before SoftMax).'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`)
    — Span-end scores (before SoftMax).'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The [FNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering)
    forward method, overrides the `__call__` special method.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-446
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
