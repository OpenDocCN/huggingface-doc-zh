# XLS-R

> 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xls_r](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/xls_r)

## 概述

XLS-R模型由Arun Babu、Changhan Wang、Andros Tjandra、Kushal Lakhotia、Qiantong Xu、Naman Goyal、Kritika Singh、Patrick von Platen、Yatharth Saraf、Juan Pino、Alexei Baevski、Alexis Conneau、Michael Auli在[XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale](https://arxiv.org/abs/2111.09296)中提出。

论文的摘要如下：

*本文介绍了XLS-R，这是一个基于wav2vec 2.0的大规模跨语言语音表示学习模型。我们在128种语言中使用多达20亿参数的模型进行训练，使用近50万小时的公开可用语音音频数据，比已知最大的先前工作的公共数据量大一个数量级。我们的评估涵盖了各种任务、领域、数据制度和语言，包括高资源和低资源语言。在CoVoST-2语音翻译基准测试中，我们将先前的最新技术平均提高了7.4 BLEU，涵盖了21个翻译方向到英语。对于语音识别，XLS-R在BABEL、MLS、CommonVoice以及VoxPopuli等最佳已知先前工作上的错误率平均降低了14-34%。XLS-R还在VoxLingua107语言识别上树立了新的技术水平。此外，我们展示了在足够大的模型尺寸下，跨语言预训练可以在将英语语音翻译成其他语言时胜过仅英语预训练，这种情况有利于单语预训练。我们希望XLS-R可以帮助改进世界上更多语言的语音处理任务。*

相关的检查点可以在[https://huggingface.co/models?other=xls_r](https://huggingface.co/models?other=xls_r)下找到。

原始代码可以在[这里](https://github.com/pytorch/fairseq/tree/master/fairseq/models/wav2vec)找到。

## 使用提示

+   XLS-R是一个语音模型，接受与语音信号的原始波形对应的浮点数组。

+   XLS-R模型是使用连接主义时间分类（CTC）进行训练的，因此模型输出必须使用[Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)进行解码。

XLS-R的架构基于Wav2Vec2模型，请参考[Wav2Vec2的文档页面](wav2vec2)获取API参考。
