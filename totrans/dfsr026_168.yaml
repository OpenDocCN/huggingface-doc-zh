- en: Stable Diffusion XL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£XL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Stable Diffusion XL (SDXL) was proposed in [SDXL: Improving Latent Diffusion
    Models for High-Resolution Image Synthesis](https://huggingface.co/papers/2307.01952)
    by Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas
    MÃ¼ller, Joe Penna, and Robin Rombach.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç¨³å®šæ‰©æ•£XLï¼ˆSDXLï¼‰ç”±Dustin Podellã€Zion Englishã€Kyle Laceyã€Andreas Blattmannã€Tim Dockhornã€Jonas
    MÃ¼llerã€Joe Pennaå’ŒRobin Rombachåœ¨[SDXL: Improving Latent Diffusion Models for High-Resolution
    Image Synthesis](https://huggingface.co/papers/2307.01952)ä¸­æå‡ºã€‚'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š
- en: '*We present SDXL, a latent diffusion model for text-to-image synthesis. Compared
    to previous versions of Stable Diffusion, SDXL leverages a three times larger
    UNet backbone: The increase of model parameters is mainly due to more attention
    blocks and a larger cross-attention context as SDXL uses a second text encoder.
    We design multiple novel conditioning schemes and train SDXL on multiple aspect
    ratios. We also introduce a refinement model which is used to improve the visual
    fidelity of samples generated by SDXL using a post-hoc image-to-image technique.
    We demonstrate that SDXL shows drastically improved performance compared the previous
    versions of Stable Diffusion and achieves results competitive with those of black-box
    state-of-the-art image generators.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*æˆ‘ä»¬æå‡ºäº†SDXLï¼Œä¸€ä¸ªç”¨äºæ–‡æœ¬åˆ°å›¾åƒåˆæˆçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€‚ä¸ä¹‹å‰çš„ç¨³å®šæ‰©æ•£ç‰ˆæœ¬ç›¸æ¯”ï¼ŒSDXLåˆ©ç”¨äº†ä¸€ä¸ªä¸‰å€å¤§çš„UNetä¸»å¹²ï¼šæ¨¡å‹å‚æ•°çš„å¢åŠ ä¸»è¦æ˜¯ç”±äºæ›´å¤šçš„æ³¨æ„åŠ›å—å’Œæ›´å¤§çš„äº¤å‰æ³¨æ„åŠ›ä¸Šä¸‹æ–‡ï¼Œå› ä¸ºSDXLä½¿ç”¨äº†ç¬¬äºŒä¸ªæ–‡æœ¬ç¼–ç å™¨ã€‚æˆ‘ä»¬è®¾è®¡äº†å¤šç§æ–°é¢–çš„æ¡ä»¶æ–¹æ¡ˆï¼Œå¹¶åœ¨å¤šä¸ªçºµæ¨ªæ¯”ä¸Šè®­ç»ƒäº†SDXLã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªç»†åŒ–æ¨¡å‹ï¼Œç”¨äºé€šè¿‡åå¤„ç†çš„å›¾åƒåˆ°å›¾åƒæŠ€æœ¯æ”¹è¿›SDXLç”Ÿæˆçš„æ ·æœ¬çš„è§†è§‰ä¿çœŸåº¦ã€‚æˆ‘ä»¬è¯æ˜ï¼Œä¸ä¹‹å‰ç‰ˆæœ¬çš„ç¨³å®šæ‰©æ•£ç›¸æ¯”ï¼ŒSDXLè¡¨ç°å‡ºäº†æ˜¾è‘—æ”¹è¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”å–å¾—äº†ä¸é»‘ç›’æœ€å…ˆè¿›å›¾åƒç”Ÿæˆå™¨ç›¸åª²ç¾çš„ç»“æœã€‚*'
- en: Tips
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æç¤º
- en: 'Using SDXL with a DPM++ scheduler for less than 50 steps is known to produce
    [visual artifacts](https://github.com/huggingface/diffusers/issues/5433) because
    the solver becomes numerically unstable. To fix this issue, take a look at this
    [PR](https://github.com/huggingface/diffusers/pull/5541) which recommends for
    ODE/SDE solvers:'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å·²çŸ¥ä½¿ç”¨DPM++è°ƒåº¦ç¨‹åºè¿›è¡Œå°‘äº50æ­¥çš„SDXLä¼šäº§ç”Ÿ[è§†è§‰ä¼ªå½±](https://github.com/huggingface/diffusers/issues/5433)ï¼Œå› ä¸ºæ±‚è§£å™¨å˜å¾—æ•°å€¼ä¸ç¨³å®šã€‚è¦è§£å†³æ­¤é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ­¤[PR](https://github.com/huggingface/diffusers/pull/5541)ï¼Œè¯¥PRå»ºè®®ODE/SDEæ±‚è§£å™¨ï¼š
- en: set `use_karras_sigmas=True` or `lu_lambdas=True` to improve image quality
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¾ç½®`use_karras_sigmas=True`æˆ–`lu_lambdas=True`ä»¥æé«˜å›¾åƒè´¨é‡ã€‚
- en: set `euler_at_final=True` if youâ€™re using a solver with uniform step sizes (DPM++2M
    or DPM++2M SDE)
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨å…·æœ‰å‡åŒ€æ­¥é•¿çš„æ±‚è§£å™¨ï¼ˆDPM++2Mæˆ–DPM++2M SDEï¼‰ï¼Œè¯·è®¾ç½®`euler_at_final=True`ã€‚
- en: Most SDXL checkpoints work best with an image size of 1024x1024\. Image sizes
    of 768x768 and 512x512 are also supported, but the results arenâ€™t as good. Anything
    below 512x512 is not recommended and likely wonâ€™t be for default checkpoints like
    [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0).
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°SDXLæ£€æŸ¥ç‚¹åœ¨å›¾åƒå°ºå¯¸ä¸º1024x1024æ—¶æ•ˆæœæœ€ä½³ã€‚æ”¯æŒ768x768å’Œ512x512çš„å›¾åƒå°ºå¯¸ï¼Œä½†ç»“æœä¸å¤ªå¥½ã€‚ä½äº512x512çš„ä»»ä½•å°ºå¯¸éƒ½ä¸å»ºè®®ä½¿ç”¨ï¼Œå¹¶ä¸”é»˜è®¤æ£€æŸ¥ç‚¹å¦‚[stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)å¯èƒ½ä¸é€‚ç”¨ã€‚
- en: SDXL can pass a different prompt for each of the text encoders it was trained
    on. We can even pass different parts of the same prompt to the text encoders.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SDXLå¯ä»¥ä¸ºå…¶è®­ç»ƒçš„æ¯ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¼ é€’ä¸åŒçš„æç¤ºã€‚æˆ‘ä»¬ç”šè‡³å¯ä»¥å°†åŒä¸€æç¤ºçš„ä¸åŒéƒ¨åˆ†ä¼ é€’ç»™æ–‡æœ¬ç¼–ç å™¨ã€‚
- en: SDXL output images can be improved by making use of a refiner model in an image-to-image
    setting.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SDXLè¾“å‡ºçš„å›¾åƒå¯ä»¥é€šè¿‡åœ¨å›¾åƒåˆ°å›¾åƒè®¾ç½®ä¸­åˆ©ç”¨ä¸€ä¸ªç»†åŒ–æ¨¡å‹æ¥æ”¹è¿›ã€‚
- en: SDXL offers `negative_original_size`, `negative_crops_coords_top_left`, and
    `negative_target_size` to negatively condition the model on image resolution and
    cropping parameters.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SDXLæä¾›`negative_original_size`ã€`negative_crops_coords_top_left`å’Œ`negative_target_size`ï¼Œä»¥åœ¨å›¾åƒåˆ†è¾¨ç‡å’Œè£å‰ªå‚æ•°ä¸Šå¯¹æ¨¡å‹è¿›è¡Œè´Ÿé¢æ¡ä»¶ã€‚
- en: To learn how to use SDXL for various tasks, how to optimize performance, and
    other usage examples, take a look at the [Stable Diffusion XL](../../../using-diffusers/sdxl)
    guide.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¦äº†è§£å¦‚ä½•åœ¨å„ç§ä»»åŠ¡ä¸­ä½¿ç”¨SDXLï¼Œå¦‚ä½•ä¼˜åŒ–æ€§èƒ½ä»¥åŠå…¶ä»–ç”¨æ³•ç¤ºä¾‹ï¼Œè¯·æŸ¥çœ‹[Stable Diffusion XL](../../../using-diffusers/sdxl)æŒ‡å—ã€‚
- en: Check out the [Stability AI](https://huggingface.co/stabilityai) Hub organization
    for the official base and refiner model checkpoints!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[Stability AI](https://huggingface.co/stabilityai) Hubç»„ç»‡ä»¥è·å–å®˜æ–¹åŸºç¡€å’Œç»†åŒ–æ¨¡å‹æ£€æŸ¥ç‚¹ï¼
- en: StableDiffusionXLPipeline
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionXLPipeline
- en: '### `class diffusers.StableDiffusionXLPipeline`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`class diffusers.StableDiffusionXLPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L149)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L149)'
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKLï¼‰ï¼‰-
    å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚'
- en: '`text_encoder` (`CLIPTextModel`) â€” Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`ï¼ˆ`CLIPTextModel`ï¼‰- å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚ç¨³å®šæ‰©æ•£XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)çš„æ–‡æœ¬éƒ¨åˆ†ï¼Œå…·ä½“æ˜¯[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)å˜ä½“ã€‚'
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) â€” Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_2`ï¼ˆ`CLIPTextModelWithProjection`ï¼‰- ç¬¬äºŒä¸ªå†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚Stable Diffusion
    XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection)çš„æ–‡æœ¬å’Œæ± éƒ¨åˆ†ï¼Œå…·ä½“æ˜¯[laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)å˜ä½“ã€‚'
- en: '`tokenizer` (`CLIPTokenizer`) â€” Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼ˆCLIPTokenizerï¼‰- ç±»çš„åˆ†è¯å™¨CLIPTokenizerã€‚'
- en: '`tokenizer_2` (`CLIPTokenizer`) â€” Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_2`ï¼ˆCLIPTokenizerï¼‰- ç±»çš„ç¬¬äºŒä¸ªåˆ†è¯å™¨CLIPTokenizerã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” Conditional U-Net architecture to denoise the encoded image latents.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆUNet2DConditionModelï¼‰- æœ‰æ¡ä»¶çš„U-Netæ¶æ„ï¼Œç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`ï¼ˆSchedulerMixinï¼‰- ä¸`unet`ä¸€èµ·ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨ç‰¹å¾çš„è°ƒåº¦ç¨‹åºã€‚å¯ä»¥æ˜¯DDIMSchedulerã€LMSDiscreteScheduleræˆ–PNDMSchedulerä¹‹ä¸€ã€‚'
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) â€”
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_zeros_for_empty_prompt`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"True"`ï¼‰- æ˜¯å¦å¼ºåˆ¶å°†è´Ÿæç¤ºåµŒå…¥å§‹ç»ˆè®¾ç½®ä¸º0ã€‚è¿˜è¯·å‚é˜…`stabilityai/stable-diffusion-xl-base-1-0`çš„é…ç½®ã€‚'
- en: '`add_watermarker` (`bool`, *optional*) â€” Whether to use the [invisible_watermark
    library](https://github.com/ShieldMnt/invisible-watermark/) to watermark output
    images. If not defined, it will default to True if the package is installed, otherwise
    no watermarker will be used.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_watermarker`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦ä½¿ç”¨invisible_watermarkåº“å¯¹è¾“å‡ºå›¾åƒè¿›è¡Œæ°´å°å¤„ç†ã€‚å¦‚æœæœªå®šä¹‰ï¼Œå¦‚æœå®‰è£…äº†è¯¥è½¯ä»¶åŒ…ï¼Œåˆ™é»˜è®¤ä¸ºTrueï¼Œå¦åˆ™å°†ä¸ä½¿ç”¨æ°´å°ã€‚'
- en: Pipeline for text-to-image generation using Stable Diffusion XL.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºä½¿ç”¨Stable Diffusion XLè¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ç®¡é“ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹ç»§æ‰¿è‡ªDiffusionPipelineã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“ä¸ºæ‰€æœ‰ç®¡é“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ï¼Œåœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰ã€‚
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç®¡é“è¿˜ç»§æ‰¿ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºåŠ è½½`.ckpt`æ–‡ä»¶
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½LoRAæƒé‡
- en: '`save_lora_weights()` for saving LoRA weights'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜LoRAæƒé‡
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½IPé€‚é…å™¨
- en: '#### `__call__`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L885)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥æº
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to guide
    the image generation. If not defined, one has to pass `prompt_embeds`. instead.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`prompt_embeds`ã€‚'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2`ï¼ˆ`str`æˆ–`List[str]`ï¼Œ*å¯é€‰*ï¼‰- è¦å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`çš„æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­éƒ½ä½¿ç”¨`prompt`ã€‚'
- en: '`height` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    â€” The height in pixels of the generated image. This is set to 1024 by default
    for the best results. Anything below 512 pixels wonâ€™t work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.unet.config.sample_size * self.vae_scale_factorï¼‰-
    ç”Ÿæˆå›¾åƒçš„åƒç´ é«˜åº¦ã€‚é»˜è®¤æƒ…å†µä¸‹è®¾ç½®ä¸º1024ä»¥è·å¾—æœ€ä½³ç»“æœã€‚ä½äº512åƒç´ çš„ä»»ä½•å†…å®¹å¯¹äºstabilityai/stable-diffusion-xl-base-1.0å’Œæœªç»ä¸“é—¨è°ƒæ•´ä»¥é€‚åº”ä½åˆ†è¾¨ç‡çš„æ£€æŸ¥ç‚¹æ•ˆæœä¸ä½³ã€‚'
- en: '`width` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    â€” The width in pixels of the generated image. This is set to 1024 by default for
    the best results. Anything below 512 pixels wonâ€™t work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *optional*, é»˜è®¤ä¸ºself.unet.config.sample_size * self.vae_scale_factor)
    â€” ç”Ÿæˆå›¾åƒçš„åƒç´ å®½åº¦ã€‚é»˜è®¤è®¾ç½®ä¸º1024ä»¥è·å¾—æœ€ä½³ç»“æœã€‚ä½äº512åƒç´ çš„ä»»ä½•å†…å®¹éƒ½ä¸é€‚ç”¨äº[stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)å’Œæœªç»ä¸“é—¨è°ƒæ•´ä»¥é€‚åº”ä½åˆ†è¾¨ç‡çš„æ£€æŸ¥ç‚¹ã€‚'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) â€” The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, é»˜è®¤ä¸º50) â€” é™å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„é™å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´æ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä½†æ¨ç†é€Ÿåº¦è¾ƒæ…¢ã€‚'
- en: '`timesteps` (`List[int]`, *optional*) â€” Custom timesteps to use for the denoising
    process with schedulers which support a `timesteps` argument in their `set_timesteps`
    method. If not defined, the default behavior when `num_inference_steps` is passed
    will be used. Must be in descending order.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`List[int]`, *optional*) â€” ç”¨äºå…·æœ‰åœ¨å…¶`set_timesteps`æ–¹æ³•ä¸­æ”¯æŒ`timesteps`å‚æ•°çš„è°ƒåº¦å™¨çš„é™å™ªè¿‡ç¨‹çš„è‡ªå®šä¹‰æ—¶é—´æ­¥ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å°†ä½¿ç”¨ä¼ é€’`num_inference_steps`æ—¶çš„é»˜è®¤è¡Œä¸ºã€‚å¿…é¡»æŒ‰é™åºæ’åˆ—ã€‚'
- en: '`denoising_end` (`float`, *optional*) â€” When specified, determines the fraction
    (between 0.0 and 1.0) of the total denoising process to be completed before it
    is intentionally prematurely terminated. As a result, the returned sample will
    still retain a substantial amount of noise as determined by the discrete timesteps
    selected by the scheduler. The denoising_end parameter should ideally be utilized
    when this pipeline forms a part of a â€œMixture of Denoisersâ€ multi-pipeline setup,
    as elaborated in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`denoising_end` (`float`, *optional*) â€” å½“æŒ‡å®šæ—¶ï¼Œç¡®å®šåœ¨æ„å›¾æå‰ç»ˆæ­¢ä¹‹å‰å®Œæˆçš„æ€»é™å™ªè¿‡ç¨‹çš„æ¯”ä¾‹ï¼ˆä»‹äº0.0å’Œ1.0ä¹‹é—´ï¼‰ã€‚å› æ­¤ï¼Œè¿”å›çš„æ ·æœ¬ä»å°†ä¿ç•™ç”±è°ƒåº¦å™¨é€‰æ‹©çš„ç¦»æ•£æ—¶é—´æ­¥ç¡®å®šçš„å¤§é‡å™ªéŸ³ã€‚å½“æ­¤ç®¡é“å½¢æˆâ€œå»å™ªå™¨æ··åˆâ€å¤šç®¡é“è®¾ç½®çš„ä¸€éƒ¨åˆ†æ—¶ï¼Œåº”ç†æƒ³åœ°åˆ©ç”¨`denoising_end`å‚æ•°ï¼Œå¦‚[`Refining
    the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output)ä¸­æ‰€è¿°ã€‚'
- en: '`guidance_scale` (`float`, *optional*, defaults to 5.0) â€” Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, é»˜è®¤ä¸º5.0) â€” å¦‚[Classifier-Free Diffusion
    Guidance](https://arxiv.org/abs/2207.12598)ä¸­å®šä¹‰çš„æŒ‡å¯¼æ¯”ä¾‹ã€‚`guidance_scale`è¢«å®šä¹‰ä¸º[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)ä¸­æ–¹ç¨‹å¼2çš„`w`ã€‚é€šè¿‡è®¾ç½®`guidance_scale > 1`å¯ç”¨æŒ‡å¯¼æ¯”ä¾‹ã€‚æ›´é«˜çš„æŒ‡å¯¼æ¯”ä¾‹é¼“åŠ±ç”Ÿæˆä¸æ–‡æœ¬`prompt`å¯†åˆ‡ç›¸å…³çš„å›¾åƒï¼Œé€šå¸¸ä»¥é™ä½å›¾åƒè´¨é‡ä¸ºä»£ä»·ã€‚'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` æˆ– `List[str]`, *optional*) â€” ä¸æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`negative_prompt_embeds`ã€‚åœ¨ä¸ä½¿ç”¨æŒ‡å¯¼æ—¶è¢«å¿½ç•¥ï¼ˆå³å¦‚æœ`guidance_scale`å°äº`1`ï¼Œåˆ™è¢«å¿½ç•¥ï¼‰ã€‚'
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_2` (`str` æˆ– `List[str]`, *optional*) â€” ä¸æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºï¼Œå°†å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`ã€‚å¦‚æœæœªå®šä¹‰ï¼Œ`negative_prompt`å°†åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨ã€‚'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” The number of
    images to generate per prompt.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, é»˜è®¤ä¸º1) â€” æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚'
- en: '`eta` (`float`, *optional*, defaults to 0.0) â€” Corresponds to parameter eta
    (Î·) in the DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to [schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    will be ignored for others.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta` (`float`, *optional*, é»˜è®¤ä¸º0.0) â€” å¯¹åº”äºDDIMè®ºæ–‡ä¸­çš„å‚æ•°eta (Î·)ï¼š[https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502)ã€‚ä»…é€‚ç”¨äº[schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œå¯¹äºå…¶ä»–æƒ…å†µå°†è¢«å¿½ç•¥ã€‚'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` æˆ– `List[torch.Generator]`, *optional*) â€” ä¸€ä¸ªæˆ–å¤šä¸ª[torchç”Ÿæˆå™¨](https://pytorch.org/docs/stable/generated/torch.Generator.html)ï¼Œç”¨äºä½¿ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§ã€‚'
- en: '`latents` (`torch.FloatTensor`, *optional*) â€” Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„å˜ˆæ‚æ½œå˜é‡ï¼Œä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„è¾“å…¥ã€‚å¯ç”¨äºä½¿ç”¨ä¸åŒæç¤ºè°ƒæ•´ç›¸åŒç”Ÿæˆã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä½¿ç”¨æä¾›çš„éšæœº`generator`è¿›è¡Œé‡‡æ ·ç”Ÿæˆæ½œå˜é‡å¼ é‡ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œæ–‡æœ¬åµŒå…¥å°†ä»`prompt`è¾“å…¥å‚æ•°ç”Ÿæˆã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»`negative_prompt`è¾“å…¥å‚æ•°ç”Ÿæˆ`negative_prompt_embeds`ã€‚'
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»
    `prompt` è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument. ip_adapter_image â€” (`PipelineImageInput`,
    *optional*): Optional image input to work with IP Adapters.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” é¢„ç”Ÿæˆçš„è´Ÿé¢æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œä¾‹å¦‚æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»
    `negative_prompt` è¾“å…¥å‚æ•°ç”Ÿæˆè´Ÿé¢æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚ip_adapter_image â€” (`PipelineImageInput`, *optional*):
    å¯é€‰çš„å›¾åƒè¾“å…¥ï¼Œç”¨äºä¸ IP é€‚é…å™¨ä¸€èµ·ä½¿ç”¨ã€‚'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” The output format
    of the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, é»˜è®¤ä¸º `"pil"`) â€” ç”Ÿæˆå›¾åƒçš„è¾“å‡ºæ ¼å¼ã€‚å¯é€‰æ‹© [PIL](https://pillow.readthedocs.io/en/stable/)ï¼š`PIL.Image.Image`
    æˆ– `np.array`ã€‚'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a `~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` instead
    of a plain tuple.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦è¿”å› `~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput`
    è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: '`cross_attention_kwargs` (`dict`, *optional*) â€” A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attention_kwargs` (`dict`, *optional*) â€” å¦‚æœæŒ‡å®šï¼Œå°†ä¼ é€’ç»™ `AttentionProcessor`
    ä¸­å®šä¹‰çš„ `self.processor` ä¸‹çš„ kwargs å­—å…¸ï¼Œè¯¦è§ [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)ã€‚'
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) â€” Guidance rescale
    factor proposed by [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    `guidance_scale` is defined as `Ï†` in equation 16\. of [Common Diffusion Noise
    Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_rescale` (`float`, *optional*, é»˜è®¤ä¸º 0.0) â€” [Common Diffusion Noise
    Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf) æå‡ºçš„æŒ‡å¯¼ç¼©æ”¾å› å­ã€‚`guidance_scale`
    åœ¨æ–¹ç¨‹å¼16ä¸­å®šä¹‰ä¸º `Ï†`ã€‚æŒ‡å¯¼ç¼©æ”¾å› å­åº”è¯¥åœ¨ä½¿ç”¨é›¶ç»ˆç«¯ä¿¡å™ªæ¯”æ—¶ä¿®å¤è¿‡æ›å…‰é—®é¢˜ã€‚'
- en: '`original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) â€” If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXLâ€™s
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`original_size` (`Tuple[int]`, *optional*, é»˜è®¤ä¸º (1024, 1024)) â€” å¦‚æœ `original_size`
    ä¸ `target_size` ä¸åŒï¼Œå›¾åƒå°†å‘ˆç°ä¸ºç¼©å°æˆ–æ”¾å¤§ã€‚å¦‚æœæœªæŒ‡å®šï¼Œ`original_size` é»˜è®¤ä¸º `(height, width)`ã€‚è¿™æ˜¯
    SDXL çš„å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    çš„ç¬¬2.2èŠ‚ã€‚'
- en: '`crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0, 0)) â€” `crops_coords_top_left`
    can be used to generate an image that appears to be â€œcroppedâ€ from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crops_coords_top_left` (`Tuple[int]`, *optional*, é»˜è®¤ä¸º (0, 0)) â€” `crops_coords_top_left`
    å¯ç”¨äºç”Ÿæˆä¸€ä¸ªçœ‹èµ·æ¥è¢«â€œè£å‰ªâ€åˆ°ä½ç½® `crops_coords_top_left` ä¸‹æ–¹çš„å›¾åƒã€‚é€šå¸¸é€šè¿‡å°† `crops_coords_top_left`
    è®¾ç½®ä¸º (0, 0) å¯ä»¥å®ç°æœ‰åˆ©ä¸”å±…ä¸­çš„å›¾åƒã€‚è¿™æ˜¯ SDXL çš„å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    çš„ç¬¬2.2èŠ‚ã€‚'
- en: '`target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) â€” For most
    cases, `target_size` should be set to the desired height and width of the generated
    image. If not specified it will default to `(height, width)`. Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_size` (`Tuple[int]`, *optional*, é»˜è®¤ä¸º (1024, 1024)) â€” å¯¹äºå¤§å¤šæ•°æƒ…å†µï¼Œ`target_size`
    åº”è®¾ç½®ä¸ºç”Ÿæˆå›¾åƒçš„æœŸæœ›é«˜åº¦å’Œå®½åº¦ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸º `(height, width)`ã€‚è¿™æ˜¯ SDXL çš„å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    çš„ç¬¬2.2èŠ‚ã€‚'
- en: '`negative_original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    â€” To negatively condition the generation process based on a specific image resolution.
    Part of SDXLâ€™s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_original_size` (`Tuple[int]`, *optional*, é»˜è®¤ä¸º (1024, 1024)) â€” åŸºäºç‰¹å®šå›¾åƒåˆ†è¾¨ç‡å¯¹ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œè´Ÿé¢è°ƒèŠ‚ã€‚è¿™æ˜¯
    SDXL çš„å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    çš„ç¬¬2.2èŠ‚ã€‚æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒæ­¤é—®é¢˜çº¿ç¨‹ï¼š[https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208)ã€‚'
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0,
    0)) â€” To negatively condition the generation process based on a specific crop
    coordinates. Part of SDXLâ€™s micro-conditioning as explained in section 2.2 of
    [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_crops_coords_top_left` (`Tuple[int]`, *optional*, é»˜è®¤ä¸º (0, 0)) â€” åŸºäºç‰¹å®šè£å‰ªåæ ‡å¯¹ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œè´Ÿé¢è°ƒèŠ‚ã€‚è¿™æ˜¯
    SDXL çš„å¾®è°ƒèŠ‚çš„ä¸€éƒ¨åˆ†ï¼Œè¯¦è§ [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952)
    çš„ç¬¬2.2èŠ‚ã€‚æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒæ­¤é—®é¢˜çº¿ç¨‹ï¼š[https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208)ã€‚'
- en: '`negative_target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    â€” To negatively condition the generation process based on a target image resolution.
    It should be as same as the `target_size` for most cases. Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end` (`Callable`, *optional*) â€” A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) â€” The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` or `tuple`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple`. When returning a tuple, the first element is a list
    with the generated images.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Function invoked when calling the pipeline for generation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `disable_freeu`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L758)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_slicing`'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L269)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_tiling`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L286)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_freeu`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L735)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '`s1` (`float`) â€” Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s2` (`float`) â€” Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b1` (`float`) â€” Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b2` (`float`) â€” Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_slicing`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L261)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_tiling`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L277)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L277)'
- en: '[PRE8]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨å¹³é“ºçš„VAEè§£ç ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆç“¦ç‰‡ï¼Œä»¥ä¾¿åœ¨å‡ ä¸ªæ­¥éª¤ä¸­è®¡ç®—è§£ç å’Œç¼–ç ã€‚è¿™å¯¹äºèŠ‚çœå¤§é‡å†…å­˜å¹¶å…è®¸å¤„ç†æ›´å¤§çš„å›¾åƒéå¸¸æœ‰ç”¨ã€‚
- en: '#### `encode_prompt`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `encode_prompt`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L293)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L293)'
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” prompt to be encoded'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” è¦ç¼–ç çš„æç¤º'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device â€” (`torch.device`): torch device'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” å‘é€åˆ° `tokenizer_2` å’Œ `text_encoder_2`
    çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨ `prompt`ã€‚è®¾å¤‡ â€” (`torch.device`): torch è®¾å¤‡'
- en: '`num_images_per_prompt` (`int`) â€” number of images that should be generated
    per prompt'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`) â€” æ¯ä¸ªæç¤ºåº”ç”Ÿæˆçš„å›¾åƒæ•°é‡'
- en: '`do_classifier_free_guidance` (`bool`) â€” whether to use classifier free guidance
    or not'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_classifier_free_guidance` (`bool`) â€” æ˜¯å¦ä½¿ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ä¸æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’ `negative_prompt_embeds`ã€‚å½“ä¸ä½¿ç”¨æŒ‡å¯¼æ—¶ï¼ˆå³ï¼Œå¦‚æœ
    `guidance_scale` å°äº `1`ï¼Œåˆ™å¿½ç•¥ï¼‰ã€‚'
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_2` (`str` æˆ– `List[str]`, *å¯é€‰*) â€” ä¸æŒ‡å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºï¼Œå‘é€åˆ° `tokenizer_2`
    å’Œ `text_encoder_2`ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨ `negative_prompt`ã€‚'
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œ*ä¾‹å¦‚*æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œæ–‡æœ¬åµŒå…¥å°†ä»
    `prompt` è¾“å…¥å‚æ•°ç”Ÿæˆã€‚'
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œ*ä¾‹å¦‚*æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»
    `negative_prompt` è¾“å…¥å‚æ•°ç”Ÿæˆè´Ÿçš„æ–‡æœ¬åµŒå…¥ã€‚'
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooled_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œ*ä¾‹å¦‚*æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»
    `prompt` è¾“å…¥å‚æ•°ç”Ÿæˆæ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚'
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *å¯é€‰*) â€” é¢„ç”Ÿæˆçš„è´Ÿæ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚å¯ç”¨äºè½»æ¾è°ƒæ•´æ–‡æœ¬è¾“å…¥ï¼Œ*ä¾‹å¦‚*æç¤ºåŠ æƒã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä»
    `negative_prompt` è¾“å…¥å‚æ•°ç”Ÿæˆè´Ÿçš„æ± åŒ–æ–‡æœ¬åµŒå…¥ã€‚'
- en: '`lora_scale` (`float`, *optional*) â€” A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_scale` (`float`, *å¯é€‰*) â€” å¦‚æœåŠ è½½äº†LoRAå±‚ï¼Œåˆ™å°†åº”ç”¨äºæ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰LoRAå±‚çš„loraæ¯”ä¾‹ã€‚'
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_skip` (`int`, *å¯é€‰*) â€” åœ¨è®¡ç®—æç¤ºåµŒå…¥æ—¶è¦è·³è¿‡çš„å±‚æ•°ã€‚å€¼ä¸º1è¡¨ç¤ºå°†ä½¿ç”¨é¢„ç»ˆå±‚çš„è¾“å‡ºæ¥è®¡ç®—æç¤ºåµŒå…¥ã€‚'
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æç¤ºç¼–ç ä¸ºæ–‡æœ¬ç¼–ç å™¨éšè—çŠ¶æ€ã€‚
- en: '#### `fuse_qkv_projections`'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `fuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L762)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L762)'
- en: '[PRE10]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` (`bool`, é»˜è®¤ä¸º `True`) â€” åœ¨UNetä¸Šåº”ç”¨èåˆã€‚'
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae` (`bool`, é»˜è®¤ä¸º `True`) â€” åœ¨VAEä¸Šåº”ç”¨èåˆã€‚'
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ç”¨èåˆçš„QKVæŠ•å½±ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œæ‰€æœ‰æŠ•å½±çŸ©é˜µï¼ˆå³æŸ¥è¯¢ã€é”®ã€å€¼ï¼‰éƒ½è¢«èåˆã€‚å¯¹äºäº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œé”®å’Œå€¼æŠ•å½±çŸ©é˜µè¢«èåˆã€‚
- en: This API is ğŸ§ª experimental.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤APIä¸ºğŸ§ªå®éªŒæ€§è´¨ã€‚
- en: '#### `get_guidance_scale_embedding`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_guidance_scale_embedding`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L822)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L822)'
- en: '[PRE11]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`timesteps` (`torch.Tensor`) â€” generate embedding vectors at these timesteps'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`torch.Tensor`) â€” åœ¨è¿™äº›æ—¶é—´æ­¥ç”ŸæˆåµŒå…¥å‘é‡'
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) â€” dimension of the embeddings
    to generate dtype â€” data type of the generated embeddings'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_dim` (`int`, *å¯é€‰*, é»˜è®¤ä¸º512) â€” è¦ç”Ÿæˆçš„åµŒå…¥çš„ç»´åº¦ dtype â€” ç”Ÿæˆçš„åµŒå…¥çš„æ•°æ®ç±»å‹'
- en: Returns
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`torch.FloatTensor`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å½¢çŠ¶ä¸º`(len(timesteps), embedding_dim)`çš„åµŒå…¥å‘é‡
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å‚é˜…[https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
- en: '#### `unfuse_qkv_projections`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `unfuse_qkv_projections`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L793)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L793)'
- en: '[PRE12]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰- åœ¨UNetä¸Šåº”ç”¨èåˆã€‚'
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ`bool`ï¼Œé»˜è®¤ä¸º`True`ï¼‰- åœ¨VAEä¸Šåº”ç”¨èåˆã€‚'
- en: Disable QKV projection fusion if enabled.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå¯ç”¨ï¼Œåˆ™ç¦ç”¨QKVæŠ•å½±èåˆã€‚
- en: This API is ğŸ§ª experimental.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤APIä¸ºğŸ§ªå®éªŒæ€§è´¨ã€‚
- en: StableDiffusionXLImg2ImgPipeline
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StableDiffusionXLImg2ImgPipeline
- en: '### `class diffusers.StableDiffusionXLImg2ImgPipeline`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.StableDiffusionXLImg2ImgPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L167)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L167)'
- en: '[PRE13]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vae`ï¼ˆ[AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL)ï¼‰-
    å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œç”¨äºå¯¹å›¾åƒè¿›è¡Œç¼–ç å’Œè§£ç ï¼Œä»¥åŠä»æ½œåœ¨è¡¨ç¤ºä¸­è§£ç å›¾åƒã€‚'
- en: '`text_encoder` (`CLIPTextModel`) â€” Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`ï¼ˆ`CLIPTextModel`ï¼‰- å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚ Stable Diffusion XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)çš„æ–‡æœ¬éƒ¨åˆ†ï¼Œå…·ä½“æ¥è¯´æ˜¯[clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)å˜ä½“ã€‚'
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) â€” Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder_2`ï¼ˆ`CLIPTextModelWithProjection`ï¼‰- ç¬¬äºŒä¸ªå†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ã€‚ Stable Diffusion
    XLä½¿ç”¨[CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection)çš„æ–‡æœ¬å’Œæ± éƒ¨åˆ†ï¼Œå…·ä½“æ¥è¯´æ˜¯[laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)å˜ä½“ã€‚'
- en: '`tokenizer` (`CLIPTokenizer`) â€” Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼ˆ`CLIPTokenizer`ï¼‰- ç±»[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)çš„åˆ†è¯å™¨ã€‚'
- en: '`tokenizer_2` (`CLIPTokenizer`) â€” Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_2`ï¼ˆ`CLIPTokenizer`ï¼‰- ç±»[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)çš„ç¬¬äºŒä¸ªåˆ†è¯å™¨ã€‚'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” Conditional U-Net architecture to denoise the encoded image latents.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`ï¼ˆ[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)ï¼‰-
    ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œå˜é‡çš„æ¡ä»¶U-Netæ¶æ„ã€‚'
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`ï¼ˆ[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)ï¼‰-
    ä¸`unet`ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œå˜é‡çš„è°ƒåº¦ç¨‹åºã€‚å¯ä»¥æ˜¯[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)ï¼Œ[LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)ï¼Œæˆ–[PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)ä¹‹ä¸€ã€‚'
- en: '`requires_aesthetics_score` (`bool`, *optional*, defaults to `"False"`) â€” Whether
    the `unet` requires an `aesthetic_score` condition to be passed during inference.
    Also see the config of `stabilityai/stable-diffusion-xl-refiner-1-0`.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requires_aesthetics_score`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"False"`ï¼‰- åœ¨æ¨æ–­æœŸé—´ï¼Œ`unet`æ˜¯å¦éœ€è¦ä¼ é€’`aesthetic_score`æ¡ä»¶ã€‚è¿˜è¯·å‚é˜…`stabilityai/stable-diffusion-xl-refiner-1-0`çš„é…ç½®ã€‚'
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) â€”
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_zeros_for_empty_prompt`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"True"`ï¼‰- æ˜¯å¦å¼ºåˆ¶å°†è´Ÿæç¤ºåµŒå…¥å§‹ç»ˆè®¾ç½®ä¸º0ã€‚è¿˜è¯·å‚é˜…`stabilityai/stable-diffusion-xl-base-1-0`çš„é…ç½®ã€‚'
- en: '`add_watermarker` (`bool`, *optional*) â€” Whether to use the [invisible_watermark
    library](https://github.com/ShieldMnt/invisible-watermark/) to watermark output
    images. If not defined, it will default to True if the package is installed, otherwise
    no watermarker will be used.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_watermarker`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦ä½¿ç”¨[invisible_watermarkåº“](https://github.com/ShieldMnt/invisible-watermark/)æ¥ç»™è¾“å‡ºå›¾åƒæ·»åŠ æ°´å°ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¦‚æœå®‰è£…äº†è¯¥è½¯ä»¶åŒ…ï¼Œåˆ™é»˜è®¤ä¸ºTrueï¼Œå¦åˆ™å°†ä¸ä½¿ç”¨æ°´å°ã€‚'
- en: Pipeline for text-to-image generation using Stable Diffusion XL.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Stable Diffusion XLè¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ç®¡é“ã€‚
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)ã€‚æ£€æŸ¥åº“ä¸ºæ‰€æœ‰ç®¡é“å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ï¼Œè¿è¡Œåœ¨ç‰¹å®šè®¾å¤‡ä¸Šç­‰ï¼‰çš„è¶…ç±»æ–‡æ¡£ã€‚
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç®¡é“è¿˜ç»§æ‰¿ä»¥ä¸‹åŠ è½½æ–¹æ³•ï¼š
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    ç”¨äºåŠ è½½æ–‡æœ¬åæ¼”åµŒå…¥'
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    ç”¨äºåŠ è½½`.ckpt`æ–‡ä»¶'
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    ç”¨äºåŠ è½½ LoRA æƒé‡'
- en: '`save_lora_weights()` for saving LoRA weights'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_lora_weights()` ç”¨äºä¿å­˜ LoRA æƒé‡'
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    ç”¨äºåŠ è½½ IP é€‚é…å™¨'
- en: '#### `__call__`'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L1026)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L1026)'
- en: '[PRE14]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to guide
    the image generation. If not defined, one has to pass `prompt_embeds`. instead.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` or `List[str]`, *optional*) â€” ç”¨äºå¼•å¯¼å›¾åƒç”Ÿæˆçš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å¿…é¡»ä¼ é€’`prompt_embeds`ã€‚'
- en: '`prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_2` (`str` or `List[str]`, *optional*) â€” è¦å‘é€åˆ°`tokenizer_2`å’Œ`text_encoder_2`çš„æç¤ºæˆ–æç¤ºã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™`prompt`å°†åœ¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¸­ä½¿ç”¨ã€‚'
- en: '`image` (`torch.FloatTensor` or `PIL.Image.Image` or `np.ndarray` or `List[torch.FloatTensor]`
    or `List[PIL.Image.Image]` or `List[np.ndarray]`) â€” The image(s) to modify with
    the pipeline.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor` or `PIL.Image.Image` or `np.ndarray` or `List[torch.FloatTensor]`
    or `List[PIL.Image.Image]` or `List[np.ndarray]`) â€” è¦ä½¿ç”¨ç®¡é“ä¿®æ”¹çš„å›¾åƒã€‚'
- en: '`strength` (`float`, *optional*, defaults to 0.3) â€” Conceptually, indicates
    how much to transform the reference `image`. Must be between 0 and 1\. `image`
    will be used as a starting point, adding more noise to it the larger the `strength`.
    The number of denoising steps depends on the amount of noise initially added.
    When `strength` is 1, added noise will be maximum and the denoising process will
    run for the full number of iterations specified in `num_inference_steps`. A value
    of 1, therefore, essentially ignores `image`. Note that in the case of `denoising_start`
    being declared as an integer, the value of `strength` will be ignored.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength` (`float`, *optional*, é»˜è®¤ä¸º0.3) â€” åœ¨æ¦‚å¿µä¸Šï¼ŒæŒ‡ç¤ºè¦å¦‚ä½•è½¬æ¢å‚è€ƒ`image`çš„ç¨‹åº¦ã€‚å¿…é¡»ä»‹äº0å’Œ1ä¹‹é—´ã€‚`image`å°†è¢«ç”¨ä½œèµ·ç‚¹ï¼Œæ·»åŠ æ›´å¤šçš„å™ªéŸ³ï¼Œ`strength`è¶Šå¤§ã€‚å»å™ªæ­¥éª¤çš„æ•°é‡å–å†³äºæœ€åˆæ·»åŠ çš„å™ªéŸ³é‡ã€‚å½“`strength`ä¸º1æ—¶ï¼Œæ·»åŠ çš„å™ªéŸ³å°†è¾¾åˆ°æœ€å¤§å€¼ï¼Œå¹¶ä¸”å»å™ªè¿‡ç¨‹å°†è¿è¡ŒæŒ‡å®šçš„`num_inference_steps`çš„å®Œæ•´è¿­ä»£æ¬¡æ•°ã€‚å› æ­¤ï¼Œå€¼ä¸º1åŸºæœ¬ä¸Šå¿½ç•¥`image`ã€‚è¯·æ³¨æ„ï¼Œåœ¨å°†`denoising_start`å£°æ˜ä¸ºæ•´æ•°çš„æƒ…å†µä¸‹ï¼Œå°†å¿½ç•¥`strength`çš„å€¼ã€‚'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) â€” The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, é»˜è®¤ä¸º50) â€” å»å™ªæ­¥éª¤çš„æ•°é‡ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šå¯¼è‡´å›¾åƒè´¨é‡æ›´é«˜ï¼Œä½†æ¨ç†é€Ÿåº¦è¾ƒæ…¢ã€‚'
- en: '`timesteps` (`List[int]`, *optional*) â€” Custom timesteps to use for the denoising
    process with schedulers which support a `timesteps` argument in their `set_timesteps`
    method. If not defined, the default behavior when `num_inference_steps` is passed
    will be used. Must be in descending order.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`List[int]`, *optional*) â€” ç”¨äºå…·æœ‰æ”¯æŒ`timesteps`å‚æ•°çš„è°ƒåº¦å™¨çš„å»å™ªè¿‡ç¨‹çš„è‡ªå®šä¹‰æ—¶é—´æ­¥é•¿ï¼Œåœ¨å…¶`set_timesteps`æ–¹æ³•ä¸­ã€‚å¦‚æœæœªå®šä¹‰ï¼Œåˆ™å°†ä½¿ç”¨ä¼ é€’`num_inference_steps`æ—¶çš„é»˜è®¤è¡Œä¸ºã€‚å¿…é¡»æŒ‰é™åºæ’åˆ—ã€‚'
- en: '`denoising_start` (`float`, *optional*) â€” When specified, indicates the fraction
    (between 0.0 and 1.0) of the total denoising process to be bypassed before it
    is initiated. Consequently, the initial part of the denoising process is skipped
    and it is assumed that the passed `image` is a partly denoised image. Note that
    when this is specified, strength will be ignored. The `denoising_start` parameter
    is particularly beneficial when this pipeline is integrated into a â€œMixture of
    Denoisersâ€ multi-pipeline setup, as detailed in [`Refine Image Quality`](https://huggingface.co/docs/diffusers/using-diffusers/sdxl#refine-image-quality).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`denoising_start` (`float`, *optional*) â€” å½“æŒ‡å®šæ—¶ï¼ŒæŒ‡ç¤ºåœ¨å¯åŠ¨ä¹‹å‰è¦ç»•è¿‡çš„æ€»å»å™ªè¿‡ç¨‹çš„æ¯”ä¾‹ï¼ˆä»‹äº0.0å’Œ1.0ä¹‹é—´ï¼‰ã€‚å› æ­¤ï¼Œå°†è·³è¿‡å»å™ªè¿‡ç¨‹çš„åˆå§‹éƒ¨åˆ†ï¼Œå¹¶å‡å®šä¼ é€’çš„`image`æ˜¯éƒ¨åˆ†å»å™ªçš„å›¾åƒã€‚è¯·æ³¨æ„ï¼Œå½“æŒ‡å®šæ­¤å‚æ•°æ—¶ï¼Œå°†å¿½ç•¥å¼ºåº¦ã€‚å½“æ­¤ç®¡é“è¢«é›†æˆåˆ°â€œå»å™ªå™¨æ··åˆâ€å¤šç®¡é“è®¾ç½®ä¸­æ—¶ï¼Œ`denoising_start`å‚æ•°ç‰¹åˆ«æœ‰ç›Šï¼Œå¦‚[`Refine
    Image Quality`](https://huggingface.co/docs/diffusers/using-diffusers/sdxl#refine-image-quality)ä¸­æ‰€è¿°ã€‚'
- en: '`denoising_end` (`float`, *optional*) â€” When specified, determines the fraction
    (between 0.0 and 1.0) of the total denoising process to be completed before it
    is intentionally prematurely terminated. As a result, the returned sample will
    still retain a substantial amount of noise (ca. final 20% of timesteps still needed)
    and should be denoised by a successor pipeline that has `denoising_start` set
    to 0.8 so that it only denoises the final 20% of the scheduler. The denoising_end
    parameter should ideally be utilized when this pipeline forms a part of a â€œMixture
    of Denoisersâ€ multi-pipeline setup, as elaborated in [`Refine Image Quality`](https://huggingface.co/docs/diffusers/using-diffusers/sdxl#refine-image-quality).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`denoising_end` (`float`, *optional*) â€” å½“æŒ‡å®šæ—¶ï¼Œç¡®å®šåœ¨æ•…æ„æå‰ç»ˆæ­¢ä¹‹å‰å®Œæˆçš„å»å™ªè¿‡ç¨‹çš„æ¯”ä¾‹ï¼ˆä»‹äº0.0å’Œ1.0ä¹‹é—´ï¼‰ã€‚å› æ­¤ï¼Œè¿”å›çš„æ ·æœ¬ä»å°†ä¿ç•™ç›¸å½“å¤šçš„å™ªéŸ³ï¼ˆçº¦å‰©ä½™20%çš„æ—¶é—´æ­¥ä»ç„¶éœ€è¦ï¼‰ï¼Œåº”ç”±åç»­ç®¡é“è¿›è¡Œå»å™ªï¼Œè¯¥ç®¡é“çš„`denoising_start`è®¾ç½®ä¸º0.8ï¼Œä»¥ä¾¿ä»…å¯¹è°ƒåº¦ç¨‹åºçš„æœ€å20%è¿›è¡Œå»å™ªã€‚å½“æ­¤ç®¡é“ä½œä¸ºâ€œå»å™ªå™¨æ··åˆâ€å¤šç®¡é“è®¾ç½®çš„ä¸€éƒ¨åˆ†æ—¶ï¼Œåº”ç†æƒ³åœ°åˆ©ç”¨`denoising_end`å‚æ•°ï¼Œå¦‚[`Refine
    Image Quality`](https://huggingface.co/docs/diffusers/using-diffusers/sdxl#refine-image-quality)ä¸­æ‰€è¿°ã€‚'
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) â€” Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” The number of
    images to generate per prompt.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, *optional*, defaults to 0.0) â€” Corresponds to parameter eta
    (Î·) in the DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to [schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    will be ignored for others.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) â€” One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`torch.FloatTensor`, *optional*) â€” Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument. ip_adapter_image â€” (`PipelineImageInput`,
    *optional*): Optional image input to work with IP Adapters.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” The output format
    of the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a `~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` instead
    of a plain tuple.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`dict`, *optional*) â€” A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) â€” Guidance rescale
    factor proposed by [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    `guidance_scale` is defined as `Ï†` in equation 16\. of [Common Diffusion Noise
    Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) â€” If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXLâ€™s
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0, 0)) â€” `crops_coords_top_left`
    can be used to generate an image that appears to be â€œcroppedâ€ from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) â€” For most
    cases, `target_size` should be set to the desired height and width of the generated
    image. If not specified it will default to `(height, width)`. Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    â€” To negatively condition the generation process based on a specific image resolution.
    Part of SDXLâ€™s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0,
    0)) â€” To negatively condition the generation process based on a specific crop
    coordinates. Part of SDXLâ€™s micro-conditioning as explained in section 2.2 of
    [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    â€” To negatively condition the generation process based on a target image resolution.
    It should be as same as the `target_size` for most cases. Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aesthetic_score` (`float`, *optional*, defaults to 6.0) â€” Used to simulate
    an aesthetic score of the generated image by influencing the positive text condition.
    Part of SDXLâ€™s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_aesthetic_score` (`float`, *optional*, defaults to 2.5) â€” Part of
    SDXLâ€™s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    Can be used to simulate an aesthetic score of the generated image by influencing
    the negative text condition.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end` (`Callable`, *optional*) â€” A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) â€” The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` or `tuple`'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple. When returning a tuple, the first element is a list
    with the generated images.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Function invoked when calling the pipeline for generation.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#### `disable_freeu`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L893)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_slicing`'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L290)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_tiling`'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L307)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_freeu`'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L870)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '`s1` (`float`) â€” Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s2` (`float`) â€” Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b1` (`float`) â€” Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b2` (`float`) â€” Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_slicing`'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L282)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_tiling`'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L298)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '#### `encode_prompt`'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L315)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” prompt to be encoded'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device â€” (`torch.device`): torch device'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`) â€” number of images that should be generated
    per prompt'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_classifier_free_guidance` (`bool`) â€” whether to use classifier free guidance
    or not'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lora_scale` (`float`, *optional*) â€” A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '#### `fuse_qkv_projections`'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L898)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: This API is ğŸ§ª experimental.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_guidance_scale_embedding`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L959)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '`timesteps` (`torch.Tensor`) â€” generate embedding vectors at these timesteps'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) â€” dimension of the embeddings
    to generate dtype â€” data type of the generated embeddings'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '#### `unfuse_qkv_projections`'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L930)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disable QKV projection fusion if enabled.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: This API is ğŸ§ª experimental.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: StableDiffusionXLInpaintPipeline
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.StableDiffusionXLInpaintPipeline`'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L312)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    â€” Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder` (`CLIPTextModel`) â€” Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) â€” Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` (`CLIPTokenizer`) â€” Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer_2` (`CLIPTokenizer`) â€” Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    â€” Conditional U-Net architecture to denoise the encoded image latents.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    â€” A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`requires_aesthetics_score` (`bool`, *optional*, defaults to `"False"`) â€” Whether
    the `unet` requires a aesthetic_score condition to be passed during inference.
    Also see the config of `stabilityai/stable-diffusion-xl-refiner-1-0`.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) â€”
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`add_watermarker` (`bool`, *optional*) â€” Whether to use the [invisible_watermark
    library](https://github.com/ShieldMnt/invisible-watermark/) to watermark output
    images. If not defined, it will default to True if the package is installed, otherwise
    no watermarker will be used.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline for text-to-image generation using Stable Diffusion XL.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline also inherits the following loading methods:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save_lora_weights()` for saving LoRA weights'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1262)'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to guide
    the image generation. If not defined, one has to pass `prompt_embeds`. instead.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image` (`PIL.Image.Image`) â€” `Image`, or tensor representing an image batch
    which will be inpainted, *i.e.* parts of the image will be masked out with `mask_image`
    and repainted according to `prompt`.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_image` (`PIL.Image.Image`) â€” `Image`, or tensor representing an image
    batch, to mask `image`. White pixels in the mask will be repainted, while black
    pixels will be preserved. If `mask_image` is a PIL image, it will be converted
    to a single channel (luminance) before use. If itâ€™s a tensor, it should contain
    one color channel (L) instead of 3, so the expected shape would be `(B, H, W,
    1)`.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    â€” The height in pixels of the generated image. This is set to 1024 by default
    for the best results. Anything below 512 pixels wonâ€™t work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    â€” The width in pixels of the generated image. This is set to 1024 by default for
    the best results. Anything below 512 pixels wonâ€™t work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`padding_mask_crop` (`int`, *optional*, defaults to `None`) â€” The size of margin
    in the crop to be applied to the image and masking. If `None`, no crop is applied
    to image and mask_image. If `padding_mask_crop` is not `None`, it will first find
    a rectangular region with the same aspect ration of the image and contains all
    masked area, and then expand that area based on `padding_mask_crop`. The image
    and mask_image will then be cropped based on the expanded area before resizing
    to the original image size for inpainting. This is useful when the masked area
    is small while the image is large and contain information inreleant for inpainging,
    such as background.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strength` (`float`, *optional*, defaults to 0.9999) â€” Conceptually, indicates
    how much to transform the masked portion of the reference `image`. Must be between
    0 and 1\. `image` will be used as a starting point, adding more noise to it the
    larger the `strength`. The number of denoising steps depends on the amount of
    noise initially added. When `strength` is 1, added noise will be maximum and the
    denoising process will run for the full number of iterations specified in `num_inference_steps`.
    A value of 1, therefore, essentially ignores the masked portion of the reference
    `image`. Note that in the case of `denoising_start` being declared as an integer,
    the value of `strength` will be ignored.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) â€” The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timesteps` (`List[int]`, *optional*) â€” Custom timesteps to use for the denoising
    process with schedulers which support a `timesteps` argument in their `set_timesteps`
    method. If not defined, the default behavior when `num_inference_steps` is passed
    will be used. Must be in descending order.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_start` (`float`, *optional*) â€” When specified, indicates the fraction
    (between 0.0 and 1.0) of the total denoising process to be bypassed before it
    is initiated. Consequently, the initial part of the denoising process is skipped
    and it is assumed that the passed `image` is a partly denoised image. Note that
    when this is specified, strength will be ignored. The `denoising_start` parameter
    is particularly beneficial when this pipeline is integrated into a â€œMixture of
    Denoisersâ€ multi-pipeline setup, as detailed in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output).'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_end` (`float`, *optional*) â€” When specified, determines the fraction
    (between 0.0 and 1.0) of the total denoising process to be completed before it
    is intentionally prematurely terminated. As a result, the returned sample will
    still retain a substantial amount of noise (ca. final 20% of timesteps still needed)
    and should be denoised by a successor pipeline that has `denoising_start` set
    to 0.8 so that it only denoises the final 20% of the scheduler. The denoising_end
    parameter should ideally be utilized when this pipeline forms a part of a â€œMixture
    of Denoisersâ€ multi-pipeline setup, as elaborated in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output).'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) â€” Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument. ip_adapter_image â€” (`PipelineImageInput`,
    *optional*): Optional image input to work with IP Adapters.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) â€” The number of
    images to generate per prompt.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, *optional*, defaults to 0.0) â€” Corresponds to parameter eta
    (Î·) in the DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to [schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    will be ignored for others.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator`, *optional*) â€” One or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`torch.FloatTensor`, *optional*) â€” Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) â€” The output format
    of the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) â€” Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`dict`, *optional*) â€” A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) â€” If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXLâ€™s
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0, 0)) â€” `crops_coords_top_left`
    can be used to generate an image that appears to be â€œcroppedâ€ from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) â€” For most
    cases, `target_size` should be set to the desired height and width of the generated
    image. If not specified it will default to `(height, width)`. Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    â€” To negatively condition the generation process based on a specific image resolution.
    Part of SDXLâ€™s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0,
    0)) â€” To negatively condition the generation process based on a specific crop
    coordinates. Part of SDXLâ€™s micro-conditioning as explained in section 2.2 of
    [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    â€” To negatively condition the generation process based on a target image resolution.
    It should be as same as the `target_size` for most cases. Part of SDXLâ€™s micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aesthetic_score` (`float`, *optional*, defaults to 6.0) â€” Used to simulate
    an aesthetic score of the generated image by influencing the positive text condition.
    Part of SDXLâ€™s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_aesthetic_score` (`float`, *optional*, defaults to 2.5) â€” Part of
    SDXLâ€™s micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    Can be used to simulate an aesthetic score of the generated image by influencing
    the negative text condition.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end` (`Callable`, *optional*) â€” A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) â€” The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` or `tuple`'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple.` tuple. When returning a tuple, the first element
    is a list with the generated images.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: Function invoked when calling the pipeline for generation.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '#### `disable_freeu`'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1129)'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Disables the FreeU mechanism if enabled.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_slicing`'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L441)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_tiling`'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L458)'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_freeu`'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1106)'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '`s1` (`float`) â€” Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s2` (`float`) â€” Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate â€œoversmoothing effectâ€ in the enhanced
    denoising process.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b1` (`float`) â€” Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b2` (`float`) â€” Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_slicing`'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L433)'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_tiling`'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L449)'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: '#### `encode_prompt`'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L520)'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) â€” prompt to be encoded'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device â€” (`torch.device`): torch device'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`) â€” number of images that should be generated
    per prompt'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_classifier_free_guidance` (`bool`) â€” whether to use classifier free guidance
    or not'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) â€” The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) â€” Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lora_scale` (`float`, *optional*) â€” A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) â€” Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encodes the prompt into text encoder hidden states.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '#### `fuse_qkv_projections`'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1134)'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Parameters
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: This API is ğŸ§ª experimental.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_guidance_scale_embedding`'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1195)'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Parameters
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '`timesteps` (`torch.Tensor`) â€” generate embedding vectors at these timesteps'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) â€” dimension of the embeddings
    to generate dtype â€” data type of the generated embeddings'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: '#### `unfuse_qkv_projections`'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1166)'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Parameters
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) â€” To apply fusion on the UNet.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) â€” To apply fusion on the VAE.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disable QKV projection fusion if enabled.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: This API is ğŸ§ª experimental.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
