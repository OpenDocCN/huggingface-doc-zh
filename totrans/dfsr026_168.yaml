- en: Stable Diffusion XL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/77.2b131197.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Tip.230e2334.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Docstring.93f6f462.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/globals.7f7f1b26.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/ExampleCodeBlock.658f5cd6.js">
  prefs: []
  type: TYPE_NORMAL
- en: 'Stable Diffusion XL (SDXL) was proposed in [SDXL: Improving Latent Diffusion
    Models for High-Resolution Image Synthesis](https://huggingface.co/papers/2307.01952)
    by Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas
    M√ºller, Joe Penna, and Robin Rombach.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is:'
  prefs: []
  type: TYPE_NORMAL
- en: '*We present SDXL, a latent diffusion model for text-to-image synthesis. Compared
    to previous versions of Stable Diffusion, SDXL leverages a three times larger
    UNet backbone: The increase of model parameters is mainly due to more attention
    blocks and a larger cross-attention context as SDXL uses a second text encoder.
    We design multiple novel conditioning schemes and train SDXL on multiple aspect
    ratios. We also introduce a refinement model which is used to improve the visual
    fidelity of samples generated by SDXL using a post-hoc image-to-image technique.
    We demonstrate that SDXL shows drastically improved performance compared the previous
    versions of Stable Diffusion and achieves results competitive with those of black-box
    state-of-the-art image generators.*'
  prefs: []
  type: TYPE_NORMAL
- en: Tips
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using SDXL with a DPM++ scheduler for less than 50 steps is known to produce
    [visual artifacts](https://github.com/huggingface/diffusers/issues/5433) because
    the solver becomes numerically unstable. To fix this issue, take a look at this
    [PR](https://github.com/huggingface/diffusers/pull/5541) which recommends for
    ODE/SDE solvers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: set `use_karras_sigmas=True` or `lu_lambdas=True` to improve image quality
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: set `euler_at_final=True` if you‚Äôre using a solver with uniform step sizes (DPM++2M
    or DPM++2M SDE)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Most SDXL checkpoints work best with an image size of 1024x1024\. Image sizes
    of 768x768 and 512x512 are also supported, but the results aren‚Äôt as good. Anything
    below 512x512 is not recommended and likely won‚Äôt be for default checkpoints like
    [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SDXL can pass a different prompt for each of the text encoders it was trained
    on. We can even pass different parts of the same prompt to the text encoders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SDXL output images can be improved by making use of a refiner model in an image-to-image
    setting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SDXL offers `negative_original_size`, `negative_crops_coords_top_left`, and
    `negative_target_size` to negatively condition the model on image resolution and
    cropping parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To learn how to use SDXL for various tasks, how to optimize performance, and
    other usage examples, take a look at the [Stable Diffusion XL](../../../using-diffusers/sdxl)
    guide.
  prefs: []
  type: TYPE_NORMAL
- en: Check out the [Stability AI](https://huggingface.co/stabilityai) Hub organization
    for the official base and refiner model checkpoints!
  prefs: []
  type: TYPE_NORMAL
- en: StableDiffusionXLPipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.StableDiffusionXLPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L149)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    ‚Äî Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder` (`CLIPTextModel`) ‚Äî Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) ‚Äî Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` (`CLIPTokenizer`) ‚Äî Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer_2` (`CLIPTokenizer`) ‚Äî Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    ‚Äî Conditional U-Net architecture to denoise the encoded image latents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    ‚Äî A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) ‚Äî
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`add_watermarker` (`bool`, *optional*) ‚Äî Whether to use the [invisible_watermark
    library](https://github.com/ShieldMnt/invisible-watermark/) to watermark output
    images. If not defined, it will default to True if the package is installed, otherwise
    no watermarker will be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline for text-to-image generation using Stable Diffusion XL.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline also inherits the following loading methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save_lora_weights()` for saving LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L885)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts to guide
    the image generation. If not defined, one has to pass `prompt_embeds`. instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    ‚Äî The height in pixels of the generated image. This is set to 1024 by default
    for the best results. Anything below 512 pixels won‚Äôt work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    ‚Äî The width in pixels of the generated image. This is set to 1024 by default for
    the best results. Anything below 512 pixels won‚Äôt work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) ‚Äî The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timesteps` (`List[int]`, *optional*) ‚Äî Custom timesteps to use for the denoising
    process with schedulers which support a `timesteps` argument in their `set_timesteps`
    method. If not defined, the default behavior when `num_inference_steps` is passed
    will be used. Must be in descending order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_end` (`float`, *optional*) ‚Äî When specified, determines the fraction
    (between 0.0 and 1.0) of the total denoising process to be completed before it
    is intentionally prematurely terminated. As a result, the returned sample will
    still retain a substantial amount of noise as determined by the discrete timesteps
    selected by the scheduler. The denoising_end parameter should ideally be utilized
    when this pipeline forms a part of a ‚ÄúMixture of Denoisers‚Äù multi-pipeline setup,
    as elaborated in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, *optional*, defaults to 5.0) ‚Äî Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) ‚Äî The number of
    images to generate per prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, *optional*, defaults to 0.0) ‚Äî Corresponds to parameter eta
    (Œ∑) in the DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to [schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    will be ignored for others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) ‚Äî One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument. ip_adapter_image ‚Äî (`PipelineImageInput`,
    *optional*): Optional image input to work with IP Adapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) ‚Äî The output format
    of the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) ‚Äî Whether or not to
    return a `~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` instead
    of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`dict`, *optional*) ‚Äî A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) ‚Äî Guidance rescale
    factor proposed by [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    `guidance_scale` is defined as `œÜ` in equation 16\. of [Common Diffusion Noise
    Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) ‚Äî If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXL‚Äôs
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0, 0)) ‚Äî `crops_coords_top_left`
    can be used to generate an image that appears to be ‚Äúcropped‚Äù from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXL‚Äôs micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) ‚Äî For most
    cases, `target_size` should be set to the desired height and width of the generated
    image. If not specified it will default to `(height, width)`. Part of SDXL‚Äôs micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    ‚Äî To negatively condition the generation process based on a specific image resolution.
    Part of SDXL‚Äôs micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0,
    0)) ‚Äî To negatively condition the generation process based on a specific crop
    coordinates. Part of SDXL‚Äôs micro-conditioning as explained in section 2.2 of
    [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    ‚Äî To negatively condition the generation process based on a target image resolution.
    It should be as same as the `target_size` for most cases. Part of SDXL‚Äôs micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end` (`Callable`, *optional*) ‚Äî A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) ‚Äî The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple`. When returning a tuple, the first element is a list
    with the generated images.'
  prefs: []
  type: TYPE_NORMAL
- en: Function invoked when calling the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#### `disable_freeu`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L758)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Disables the FreeU mechanism if enabled.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_slicing`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L269)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_tiling`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L286)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_freeu`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L735)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`s1` (`float`) ‚Äî Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate ‚Äúoversmoothing effect‚Äù in the enhanced
    denoising process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s2` (`float`) ‚Äî Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate ‚Äúoversmoothing effect‚Äù in the enhanced
    denoising process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b1` (`float`) ‚Äî Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b2` (`float`) ‚Äî Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  prefs: []
  type: TYPE_NORMAL
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_slicing`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L261)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_tiling`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L277)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `encode_prompt`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L293)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) ‚Äî prompt to be encoded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device ‚Äî (`torch.device`): torch device'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`) ‚Äî number of images that should be generated
    per prompt'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_classifier_free_guidance` (`bool`) ‚Äî whether to use classifier free guidance
    or not'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lora_scale` (`float`, *optional*) ‚Äî A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) ‚Äî Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encodes the prompt into text encoder hidden states.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `fuse_qkv_projections`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L762)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) ‚Äî To apply fusion on the UNet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) ‚Äî To apply fusion on the VAE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  prefs: []
  type: TYPE_NORMAL
- en: This API is üß™ experimental.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_guidance_scale_embedding`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L822)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`timesteps` (`torch.Tensor`) ‚Äî generate embedding vectors at these timesteps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) ‚Äî dimension of the embeddings
    to generate dtype ‚Äî data type of the generated embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  prefs: []
  type: TYPE_NORMAL
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  prefs: []
  type: TYPE_NORMAL
- en: '#### `unfuse_qkv_projections`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py#L793)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) ‚Äî To apply fusion on the UNet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) ‚Äî To apply fusion on the VAE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disable QKV projection fusion if enabled.
  prefs: []
  type: TYPE_NORMAL
- en: This API is üß™ experimental.
  prefs: []
  type: TYPE_NORMAL
- en: StableDiffusionXLImg2ImgPipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.StableDiffusionXLImg2ImgPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L167)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    ‚Äî Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder` (`CLIPTextModel`) ‚Äî Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) ‚Äî Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` (`CLIPTokenizer`) ‚Äî Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer_2` (`CLIPTokenizer`) ‚Äî Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    ‚Äî Conditional U-Net architecture to denoise the encoded image latents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    ‚Äî A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`requires_aesthetics_score` (`bool`, *optional*, defaults to `"False"`) ‚Äî Whether
    the `unet` requires an `aesthetic_score` condition to be passed during inference.
    Also see the config of `stabilityai/stable-diffusion-xl-refiner-1-0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) ‚Äî
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`add_watermarker` (`bool`, *optional*) ‚Äî Whether to use the [invisible_watermark
    library](https://github.com/ShieldMnt/invisible-watermark/) to watermark output
    images. If not defined, it will default to True if the package is installed, otherwise
    no watermarker will be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline for text-to-image generation using Stable Diffusion XL.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline also inherits the following loading methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save_lora_weights()` for saving LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L1026)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts to guide
    the image generation. If not defined, one has to pass `prompt_embeds`. instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image` (`torch.FloatTensor` or `PIL.Image.Image` or `np.ndarray` or `List[torch.FloatTensor]`
    or `List[PIL.Image.Image]` or `List[np.ndarray]`) ‚Äî The image(s) to modify with
    the pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strength` (`float`, *optional*, defaults to 0.3) ‚Äî Conceptually, indicates
    how much to transform the reference `image`. Must be between 0 and 1\. `image`
    will be used as a starting point, adding more noise to it the larger the `strength`.
    The number of denoising steps depends on the amount of noise initially added.
    When `strength` is 1, added noise will be maximum and the denoising process will
    run for the full number of iterations specified in `num_inference_steps`. A value
    of 1, therefore, essentially ignores `image`. Note that in the case of `denoising_start`
    being declared as an integer, the value of `strength` will be ignored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) ‚Äî The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timesteps` (`List[int]`, *optional*) ‚Äî Custom timesteps to use for the denoising
    process with schedulers which support a `timesteps` argument in their `set_timesteps`
    method. If not defined, the default behavior when `num_inference_steps` is passed
    will be used. Must be in descending order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_start` (`float`, *optional*) ‚Äî When specified, indicates the fraction
    (between 0.0 and 1.0) of the total denoising process to be bypassed before it
    is initiated. Consequently, the initial part of the denoising process is skipped
    and it is assumed that the passed `image` is a partly denoised image. Note that
    when this is specified, strength will be ignored. The `denoising_start` parameter
    is particularly beneficial when this pipeline is integrated into a ‚ÄúMixture of
    Denoisers‚Äù multi-pipeline setup, as detailed in [`Refine Image Quality`](https://huggingface.co/docs/diffusers/using-diffusers/sdxl#refine-image-quality).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_end` (`float`, *optional*) ‚Äî When specified, determines the fraction
    (between 0.0 and 1.0) of the total denoising process to be completed before it
    is intentionally prematurely terminated. As a result, the returned sample will
    still retain a substantial amount of noise (ca. final 20% of timesteps still needed)
    and should be denoised by a successor pipeline that has `denoising_start` set
    to 0.8 so that it only denoises the final 20% of the scheduler. The denoising_end
    parameter should ideally be utilized when this pipeline forms a part of a ‚ÄúMixture
    of Denoisers‚Äù multi-pipeline setup, as elaborated in [`Refine Image Quality`](https://huggingface.co/docs/diffusers/using-diffusers/sdxl#refine-image-quality).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) ‚Äî Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) ‚Äî The number of
    images to generate per prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, *optional*, defaults to 0.0) ‚Äî Corresponds to parameter eta
    (Œ∑) in the DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to [schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    will be ignored for others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) ‚Äî One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument. ip_adapter_image ‚Äî (`PipelineImageInput`,
    *optional*): Optional image input to work with IP Adapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) ‚Äî The output format
    of the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) ‚Äî Whether or not to
    return a `~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` instead
    of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`dict`, *optional*) ‚Äî A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_rescale` (`float`, *optional*, defaults to 0.0) ‚Äî Guidance rescale
    factor proposed by [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf)
    `guidance_scale` is defined as `œÜ` in equation 16\. of [Common Diffusion Noise
    Schedules and Sample Steps are Flawed](https://arxiv.org/pdf/2305.08891.pdf).
    Guidance rescale factor should fix overexposure when using zero terminal SNR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) ‚Äî If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXL‚Äôs
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0, 0)) ‚Äî `crops_coords_top_left`
    can be used to generate an image that appears to be ‚Äúcropped‚Äù from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXL‚Äôs micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) ‚Äî For most
    cases, `target_size` should be set to the desired height and width of the generated
    image. If not specified it will default to `(height, width)`. Part of SDXL‚Äôs micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    ‚Äî To negatively condition the generation process based on a specific image resolution.
    Part of SDXL‚Äôs micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0,
    0)) ‚Äî To negatively condition the generation process based on a specific crop
    coordinates. Part of SDXL‚Äôs micro-conditioning as explained in section 2.2 of
    [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    ‚Äî To negatively condition the generation process based on a target image resolution.
    It should be as same as the `target_size` for most cases. Part of SDXL‚Äôs micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aesthetic_score` (`float`, *optional*, defaults to 6.0) ‚Äî Used to simulate
    an aesthetic score of the generated image by influencing the positive text condition.
    Part of SDXL‚Äôs micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_aesthetic_score` (`float`, *optional*, defaults to 2.5) ‚Äî Part of
    SDXL‚Äôs micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    Can be used to simulate an aesthetic score of the generated image by influencing
    the negative text condition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) ‚Äî Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end` (`Callable`, *optional*) ‚Äî A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) ‚Äî The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple. When returning a tuple, the first element is a list
    with the generated images.'
  prefs: []
  type: TYPE_NORMAL
- en: Function invoked when calling the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '#### `disable_freeu`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L893)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Disables the FreeU mechanism if enabled.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_slicing`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L290)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_tiling`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L307)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_freeu`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L870)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`s1` (`float`) ‚Äî Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate ‚Äúoversmoothing effect‚Äù in the enhanced
    denoising process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s2` (`float`) ‚Äî Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate ‚Äúoversmoothing effect‚Äù in the enhanced
    denoising process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b1` (`float`) ‚Äî Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b2` (`float`) ‚Äî Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  prefs: []
  type: TYPE_NORMAL
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_slicing`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L282)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_tiling`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L298)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `encode_prompt`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L315)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) ‚Äî prompt to be encoded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device ‚Äî (`torch.device`): torch device'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`) ‚Äî number of images that should be generated
    per prompt'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_classifier_free_guidance` (`bool`) ‚Äî whether to use classifier free guidance
    or not'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lora_scale` (`float`, *optional*) ‚Äî A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) ‚Äî Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encodes the prompt into text encoder hidden states.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `fuse_qkv_projections`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L898)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) ‚Äî To apply fusion on the UNet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) ‚Äî To apply fusion on the VAE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  prefs: []
  type: TYPE_NORMAL
- en: This API is üß™ experimental.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_guidance_scale_embedding`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L959)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`timesteps` (`torch.Tensor`) ‚Äî generate embedding vectors at these timesteps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) ‚Äî dimension of the embeddings
    to generate dtype ‚Äî data type of the generated embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  prefs: []
  type: TYPE_NORMAL
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  prefs: []
  type: TYPE_NORMAL
- en: '#### `unfuse_qkv_projections`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py#L930)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) ‚Äî To apply fusion on the UNet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) ‚Äî To apply fusion on the VAE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disable QKV projection fusion if enabled.
  prefs: []
  type: TYPE_NORMAL
- en: This API is üß™ experimental.
  prefs: []
  type: TYPE_NORMAL
- en: StableDiffusionXLInpaintPipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.StableDiffusionXLInpaintPipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L312)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    ‚Äî Variational Auto-Encoder (VAE) Model to encode and decode images to and from
    latent representations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder` (`CLIPTextModel`) ‚Äî Frozen text-encoder. Stable Diffusion XL
    uses the text portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel),
    specifically the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)
    variant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder_2` ( `CLIPTextModelWithProjection`) ‚Äî Second frozen text-encoder.
    Stable Diffusion XL uses the text and pool portion of [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModelWithProjection),
    specifically the [laion/CLIP-ViT-bigG-14-laion2B-39B-b160k](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)
    variant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` (`CLIPTokenizer`) ‚Äî Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer_2` (`CLIPTokenizer`) ‚Äî Second Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    ‚Äî Conditional U-Net architecture to denoise the encoded image latents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    ‚Äî A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`requires_aesthetics_score` (`bool`, *optional*, defaults to `"False"`) ‚Äî Whether
    the `unet` requires a aesthetic_score condition to be passed during inference.
    Also see the config of `stabilityai/stable-diffusion-xl-refiner-1-0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`force_zeros_for_empty_prompt` (`bool`, *optional*, defaults to `"True"`) ‚Äî
    Whether the negative prompt embeddings shall be forced to always be set to 0\.
    Also see the config of `stabilityai/stable-diffusion-xl-base-1-0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`add_watermarker` (`bool`, *optional*) ‚Äî Whether to use the [invisible_watermark
    library](https://github.com/ShieldMnt/invisible-watermark/) to watermark output
    images. If not defined, it will default to True if the package is installed, otherwise
    no watermarker will be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipeline for text-to-image generation using Stable Diffusion XL.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline also inherits the following loading methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    for loading textual inversion embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[from_single_file()](/docs/diffusers/v0.26.3/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file)
    for loading `.ckpt` files'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_lora_weights()](/docs/diffusers/v0.26.3/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights)
    for loading LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save_lora_weights()` for saving LoRA weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[load_ip_adapter()](/docs/diffusers/v0.26.3/en/api/loaders/ip_adapter#diffusers.loaders.IPAdapterMixin.load_ip_adapter)
    for loading IP Adapters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1262)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts to guide
    the image generation. If not defined, one has to pass `prompt_embeds`. instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image` (`PIL.Image.Image`) ‚Äî `Image`, or tensor representing an image batch
    which will be inpainted, *i.e.* parts of the image will be masked out with `mask_image`
    and repainted according to `prompt`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_image` (`PIL.Image.Image`) ‚Äî `Image`, or tensor representing an image
    batch, to mask `image`. White pixels in the mask will be repainted, while black
    pixels will be preserved. If `mask_image` is a PIL image, it will be converted
    to a single channel (luminance) before use. If it‚Äôs a tensor, it should contain
    one color channel (L) instead of 3, so the expected shape would be `(B, H, W,
    1)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    ‚Äî The height in pixels of the generated image. This is set to 1024 by default
    for the best results. Anything below 512 pixels won‚Äôt work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width` (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor)
    ‚Äî The width in pixels of the generated image. This is set to 1024 by default for
    the best results. Anything below 512 pixels won‚Äôt work well for [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
    and checkpoints that are not specifically fine-tuned on low resolutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`padding_mask_crop` (`int`, *optional*, defaults to `None`) ‚Äî The size of margin
    in the crop to be applied to the image and masking. If `None`, no crop is applied
    to image and mask_image. If `padding_mask_crop` is not `None`, it will first find
    a rectangular region with the same aspect ration of the image and contains all
    masked area, and then expand that area based on `padding_mask_crop`. The image
    and mask_image will then be cropped based on the expanded area before resizing
    to the original image size for inpainting. This is useful when the masked area
    is small while the image is large and contain information inreleant for inpainging,
    such as background.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strength` (`float`, *optional*, defaults to 0.9999) ‚Äî Conceptually, indicates
    how much to transform the masked portion of the reference `image`. Must be between
    0 and 1\. `image` will be used as a starting point, adding more noise to it the
    larger the `strength`. The number of denoising steps depends on the amount of
    noise initially added. When `strength` is 1, added noise will be maximum and the
    denoising process will run for the full number of iterations specified in `num_inference_steps`.
    A value of 1, therefore, essentially ignores the masked portion of the reference
    `image`. Note that in the case of `denoising_start` being declared as an integer,
    the value of `strength` will be ignored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) ‚Äî The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timesteps` (`List[int]`, *optional*) ‚Äî Custom timesteps to use for the denoising
    process with schedulers which support a `timesteps` argument in their `set_timesteps`
    method. If not defined, the default behavior when `num_inference_steps` is passed
    will be used. Must be in descending order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_start` (`float`, *optional*) ‚Äî When specified, indicates the fraction
    (between 0.0 and 1.0) of the total denoising process to be bypassed before it
    is initiated. Consequently, the initial part of the denoising process is skipped
    and it is assumed that the passed `image` is a partly denoised image. Note that
    when this is specified, strength will be ignored. The `denoising_start` parameter
    is particularly beneficial when this pipeline is integrated into a ‚ÄúMixture of
    Denoisers‚Äù multi-pipeline setup, as detailed in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`denoising_end` (`float`, *optional*) ‚Äî When specified, determines the fraction
    (between 0.0 and 1.0) of the total denoising process to be completed before it
    is intentionally prematurely terminated. As a result, the returned sample will
    still retain a substantial amount of noise (ca. final 20% of timesteps still needed)
    and should be denoised by a successor pipeline that has `denoising_start` set
    to 0.8 so that it only denoises the final 20% of the scheduler. The denoising_end
    parameter should ideally be utilized when this pipeline forms a part of a ‚ÄúMixture
    of Denoisers‚Äù multi-pipeline setup, as elaborated in [`Refining the Image Output`](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#refining-the-image-output).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) ‚Äî Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument. ip_adapter_image ‚Äî (`PipelineImageInput`,
    *optional*): Optional image input to work with IP Adapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) ‚Äî The number of
    images to generate per prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, *optional*, defaults to 0.0) ‚Äî Corresponds to parameter eta
    (Œ∑) in the DDIM paper: [https://arxiv.org/abs/2010.02502](https://arxiv.org/abs/2010.02502).
    Only applies to [schedulers.DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    will be ignored for others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator`, *optional*) ‚Äî One or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) ‚Äî The output format
    of the generate image. Choose between [PIL](https://pillow.readthedocs.io/en/stable/):
    `PIL.Image.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) ‚Äî Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cross_attention_kwargs` (`dict`, *optional*) ‚Äî A kwargs dictionary that if
    specified is passed along to the `AttentionProcessor` as defined under `self.processor`
    in [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) ‚Äî If `original_size`
    is not the same as `target_size` the image will appear to be down- or upsampled.
    `original_size` defaults to `(height, width)` if not specified. Part of SDXL‚Äôs
    micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0, 0)) ‚Äî `crops_coords_top_left`
    can be used to generate an image that appears to be ‚Äúcropped‚Äù from the position
    `crops_coords_top_left` downwards. Favorable, well-centered images are usually
    achieved by setting `crops_coords_top_left` to (0, 0). Part of SDXL‚Äôs micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024)) ‚Äî For most
    cases, `target_size` should be set to the desired height and width of the generated
    image. If not specified it will default to `(height, width)`. Part of SDXL‚Äôs micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_original_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    ‚Äî To negatively condition the generation process based on a specific image resolution.
    Part of SDXL‚Äôs micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_crops_coords_top_left` (`Tuple[int]`, *optional*, defaults to (0,
    0)) ‚Äî To negatively condition the generation process based on a specific crop
    coordinates. Part of SDXL‚Äôs micro-conditioning as explained in section 2.2 of
    [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_target_size` (`Tuple[int]`, *optional*, defaults to (1024, 1024))
    ‚Äî To negatively condition the generation process based on a target image resolution.
    It should be as same as the `target_size` for most cases. Part of SDXL‚Äôs micro-conditioning
    as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    For more information, refer to this issue thread: [https://github.com/huggingface/diffusers/issues/4208](https://github.com/huggingface/diffusers/issues/4208).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aesthetic_score` (`float`, *optional*, defaults to 6.0) ‚Äî Used to simulate
    an aesthetic score of the generated image by influencing the positive text condition.
    Part of SDXL‚Äôs micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_aesthetic_score` (`float`, *optional*, defaults to 2.5) ‚Äî Part of
    SDXL‚Äôs micro-conditioning as explained in section 2.2 of [https://huggingface.co/papers/2307.01952](https://huggingface.co/papers/2307.01952).
    Can be used to simulate an aesthetic score of the generated image by influencing
    the negative text condition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) ‚Äî Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end` (`Callable`, *optional*) ‚Äî A function that calls at
    the end of each denoising steps during the inference. The function is called with
    the following arguments: `callback_on_step_end(self: DiffusionPipeline, step:
    int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
    list of all tensors as specified by `callback_on_step_end_tensor_inputs`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_on_step_end_tensor_inputs` (`List`, *optional*) ‚Äî The list of tensor
    inputs for the `callback_on_step_end` function. The tensors specified in the list
    will be passed as `callback_kwargs` argument. You will only be able to include
    variables listed in the `._callback_tensor_inputs` attribute of your pipeline
    class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: '`~pipelines.stable_diffusion.StableDiffusionXLPipelineOutput` if `return_dict`
    is True, otherwise a `tuple.` tuple. When returning a tuple, the first element
    is a list with the generated images.'
  prefs: []
  type: TYPE_NORMAL
- en: Function invoked when calling the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '#### `disable_freeu`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1129)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Disables the FreeU mechanism if enabled.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_slicing`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L441)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Disable sliced VAE decoding. If `enable_vae_slicing` was previously enabled,
    this method will go back to computing decoding in one step.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_vae_tiling`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L458)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Disable tiled VAE decoding. If `enable_vae_tiling` was previously enabled, this
    method will go back to computing decoding in one step.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_freeu`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1106)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`s1` (`float`) ‚Äî Scaling factor for stage 1 to attenuate the contributions
    of the skip features. This is done to mitigate ‚Äúoversmoothing effect‚Äù in the enhanced
    denoising process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s2` (`float`) ‚Äî Scaling factor for stage 2 to attenuate the contributions
    of the skip features. This is done to mitigate ‚Äúoversmoothing effect‚Äù in the enhanced
    denoising process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b1` (`float`) ‚Äî Scaling factor for stage 1 to amplify the contributions of
    backbone features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b2` (`float`) ‚Äî Scaling factor for stage 2 to amplify the contributions of
    backbone features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables the FreeU mechanism as in [https://arxiv.org/abs/2309.11497](https://arxiv.org/abs/2309.11497).
  prefs: []
  type: TYPE_NORMAL
- en: The suffixes after the scaling factors represent the stages where they are being
    applied.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the [official repository](https://github.com/ChenyangSi/FreeU)
    for combinations of the values that are known to work well for different pipelines
    such as Stable Diffusion v1, v2, and Stable Diffusion XL.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_slicing`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L433)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Enable sliced VAE decoding. When this option is enabled, the VAE will split
    the input tensor in slices to compute decoding in several steps. This is useful
    to save some memory and allow larger batch sizes.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_vae_tiling`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L449)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Enable tiled VAE decoding. When this option is enabled, the VAE will split the
    input tensor into tiles to compute decoding and encoding in several steps. This
    is useful for saving a large amount of memory and to allow processing larger images.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `encode_prompt`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L520)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str` or `List[str]`, *optional*) ‚Äî prompt to be encoded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts to be
    sent to the `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is used
    in both text-encoders device ‚Äî (`torch.device`): torch device'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`) ‚Äî number of images that should be generated
    per prompt'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_classifier_free_guidance` (`bool`) ‚Äî whether to use classifier free guidance
    or not'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation. If not defined, one has to pass `negative_prompt_embeds`
    instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
    less than `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_2` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    not to guide the image generation to be sent to `tokenizer_2` and `text_encoder_2`.
    If not defined, `negative_prompt` is used in both text-encoders'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated text embeddings.
    Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not provided,
    text embeddings will be generated from `prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
    weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`
    input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated pooled
    text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting.
    If not provided, pooled text embeddings will be generated from `prompt` input
    argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_pooled_prompt_embeds` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated
    negative pooled text embeddings. Can be used to easily tweak text inputs, *e.g.*
    prompt weighting. If not provided, pooled negative_prompt_embeds will be generated
    from `negative_prompt` input argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lora_scale` (`float`, *optional*) ‚Äî A lora scale that will be applied to all
    LoRA layers of the text encoder if LoRA layers are loaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_skip` (`int`, *optional*) ‚Äî Number of layers to be skipped from CLIP
    while computing the prompt embeddings. A value of 1 means that the output of the
    pre-final layer will be used for computing the prompt embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encodes the prompt into text encoder hidden states.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `fuse_qkv_projections`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1134)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) ‚Äî To apply fusion on the UNet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) ‚Äî To apply fusion on the VAE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables fused QKV projections. For self-attention modules, all projection matrices
    (i.e., query, key, value) are fused. For cross-attention modules, key and value
    projection matrices are fused.
  prefs: []
  type: TYPE_NORMAL
- en: This API is üß™ experimental.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_guidance_scale_embedding`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1195)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`timesteps` (`torch.Tensor`) ‚Äî generate embedding vectors at these timesteps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`embedding_dim` (`int`, *optional*, defaults to 512) ‚Äî dimension of the embeddings
    to generate dtype ‚Äî data type of the generated embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: Embedding vectors with shape `(len(timesteps), embedding_dim)`
  prefs: []
  type: TYPE_NORMAL
- en: See [https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298](https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298)
  prefs: []
  type: TYPE_NORMAL
- en: '#### `unfuse_qkv_projections`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py#L1166)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`unet` (`bool`, defaults to `True`) ‚Äî To apply fusion on the UNet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vae` (`bool`, defaults to `True`) ‚Äî To apply fusion on the VAE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disable QKV projection fusion if enabled.
  prefs: []
  type: TYPE_NORMAL
- en: This API is üß™ experimental.
  prefs: []
  type: TYPE_NORMAL
