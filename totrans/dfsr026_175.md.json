["```py\n>>> import torch\n>>> from diffusers import StableDiffusionGLIGENPipeline\n>>> from diffusers.utils import load_image\n\n>>> # Insert objects described by text at the region defined by bounding boxes\n>>> pipe = StableDiffusionGLIGENPipeline.from_pretrained(\n...     \"masterful/gligen-1-4-inpainting-text-box\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> input_image = load_image(\n...     \"https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/livingroom_modern.png\"\n... )\n>>> prompt = \"a birthday cake\"\n>>> boxes = [[0.2676, 0.6088, 0.4773, 0.7183]]\n>>> phrases = [\"a birthday cake\"]\n\n>>> images = pipe(\n...     prompt=prompt,\n...     gligen_phrases=phrases,\n...     gligen_inpaint_image=input_image,\n...     gligen_boxes=boxes,\n...     gligen_scheduled_sampling_beta=1,\n...     output_type=\"pil\",\n...     num_inference_steps=50,\n... ).images\n\n>>> images[0].save(\"./gligen-1-4-inpainting-text-box.jpg\")\n\n>>> # Generate an image described by the prompt and\n>>> # insert objects described by text at the region defined by bounding boxes\n>>> pipe = StableDiffusionGLIGENPipeline.from_pretrained(\n...     \"masterful/gligen-1-4-generation-text-box\", variant=\"fp16\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"a waterfall and a modern high speed train running through the tunnel in a beautiful forest with fall foliage\"\n>>> boxes = [[0.1387, 0.2051, 0.4277, 0.7090], [0.4980, 0.4355, 0.8516, 0.7266]]\n>>> phrases = [\"a waterfall\", \"a modern high speed train running through the tunnel\"]\n\n>>> images = pipe(\n...     prompt=prompt,\n...     gligen_phrases=phrases,\n...     gligen_boxes=boxes,\n...     gligen_scheduled_sampling_beta=1,\n...     output_type=\"pil\",\n...     num_inference_steps=50,\n... ).images\n\n>>> images[0].save(\"./gligen-1-4-generation-text-box.jpg\")\n```", "```py\n>>> import torch\n>>> from diffusers import StableDiffusionGLIGENTextImagePipeline\n>>> from diffusers.utils import load_image\n\n>>> # Insert objects described by image at the region defined by bounding boxes\n>>> pipe = StableDiffusionGLIGENTextImagePipeline.from_pretrained(\n...     \"anhnct/Gligen_Inpainting_Text_Image\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> input_image = load_image(\n...     \"https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/livingroom_modern.png\"\n... )\n>>> prompt = \"a backpack\"\n>>> boxes = [[0.2676, 0.4088, 0.4773, 0.7183]]\n>>> phrases = None\n>>> gligen_image = load_image(\n...     \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/backpack.jpeg\"\n... )\n\n>>> images = pipe(\n...     prompt=prompt,\n...     gligen_phrases=phrases,\n...     gligen_inpaint_image=input_image,\n...     gligen_boxes=boxes,\n...     gligen_images=[gligen_image],\n...     gligen_scheduled_sampling_beta=1,\n...     output_type=\"pil\",\n...     num_inference_steps=50,\n... ).images\n\n>>> images[0].save(\"./gligen-inpainting-text-image-box.jpg\")\n\n>>> # Generate an image described by the prompt and\n>>> # insert objects described by text and image at the region defined by bounding boxes\n>>> pipe = StableDiffusionGLIGENTextImagePipeline.from_pretrained(\n...     \"anhnct/Gligen_Text_Image\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"a flower sitting on the beach\"\n>>> boxes = [[0.0, 0.09, 0.53, 0.76]]\n>>> phrases = [\"flower\"]\n>>> gligen_image = load_image(\n...     \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/pexels-pixabay-60597.jpg\"\n... )\n\n>>> images = pipe(\n...     prompt=prompt,\n...     gligen_phrases=phrases,\n...     gligen_images=[gligen_image],\n...     gligen_boxes=boxes,\n...     gligen_scheduled_sampling_beta=1,\n...     output_type=\"pil\",\n...     num_inference_steps=50,\n... ).images\n\n>>> images[0].save(\"./gligen-generation-text-image-box.jpg\")\n\n>>> # Generate an image described by the prompt and\n>>> # transfer style described by image at the region defined by bounding boxes\n>>> pipe = StableDiffusionGLIGENTextImagePipeline.from_pretrained(\n...     \"anhnct/Gligen_Text_Image\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"a dragon flying on the sky\"\n>>> boxes = [[0.4, 0.2, 1.0, 0.8], [0.0, 1.0, 0.0, 1.0]]  # Set `[0.0, 1.0, 0.0, 1.0]` for the style\n\n>>> gligen_image = load_image(\n...     \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/landscape.png\"\n... )\n\n>>> gligen_placeholder = load_image(\n...     \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/landscape.png\"\n... )\n\n>>> images = pipe(\n...     prompt=prompt,\n...     gligen_phrases=[\n...         \"dragon\",\n...         \"placeholder\",\n...     ],  # Can use any text instead of `placeholder` token, because we will use mask here\n...     gligen_images=[\n...         gligen_placeholder,\n...         gligen_image,\n...     ],  # Can use any image in gligen_placeholder, because we will use mask here\n...     input_phrases_mask=[1, 0],  # Set 0 for the placeholder token\n...     input_images_mask=[0, 1],  # Set 0 for the placeholder image\n...     gligen_boxes=boxes,\n...     gligen_scheduled_sampling_beta=1,\n...     output_type=\"pil\",\n...     num_inference_steps=50,\n... ).images\n\n>>> images[0].save(\"./gligen-generation-text-image-box-style-transfer.jpg\")\n```"]