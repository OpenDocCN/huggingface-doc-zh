["```py\n>>> from optimum.neuron.pipelines import pipeline\n\n>>> classifier = pipeline(task=\"text-classification\")\n```", "```py\n>>> classifier(\"I like you. I love you.\")\n[{'label': 'POSITIVE', 'score': 0.9998838901519775}]\n```", "```py\n>>> from optimum.neuron.pipelines import pipeline\n\n# The model will be loaded to an NeuronModelForQuestionAnswering.\n>>> neuron_qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", export=True)\n>>> question = \"What's my name?\"\n>>> context = \"My name is Philipp and I live in Nuremberg.\"\n\n>>> pred = neuron_qa(question=question, context=context)\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForQuestionAnswering, pipeline\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n\n>>> # Loading the PyTorch checkpoint and converting to the neuron format by providing export=True\n>>> model = NeuronModelForQuestionAnswering.from_pretrained(\n...     \"deepset/roberta-base-squad2\",\n...     export=True\n... )\n\n>>> neuron_qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n>>> question = \"What's my name?\"\n>>> context = \"My name is Philipp and I live in Nuremberg.\"\n\n>>> pred = neuron_qa(question=question, context=context)\n```", "```py\n>>> from optimum.neuron.pipelines import pipeline\n\n>>> input_shapes = {\"batch_size\": 1, \"sequence_length\": 64} \n>>> clt = pipeline(\"token-classification\", model=\"dslim/bert-base-NER\", export=True,input_shapes=input_shapes)\n>>> context = \"My name is Philipp and I live in Nuremberg.\"\n\n>>> pred = clt(context)\n```"]