["```py\npip install transformers datasets evaluate jiwer\n```", "```py\n>>> from huggingface_hub import notebook_login\n\n>>> notebook_login()\n```", "```py\n>>> from datasets import load_dataset, Audio\n\n>>> minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train[:100]\")\n```", "```py\n>>> minds = minds.train_test_split(test_size=0.2)\n```", "```py\n>>> minds\nDatasetDict({\n    train: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 16\n    })\n    test: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 4\n    })\n})\n```", "```py\n>>> minds = minds.remove_columns([\"english_transcription\", \"intent_class\", \"lang_id\"])\n```", "```py\n>>> minds[\"train\"][0]\n{'audio': {'array': array([-0.00024414,  0.        ,  0.        , ...,  0.00024414,\n          0.00024414,  0.00024414], dtype=float32),\n  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',\n  'sampling_rate': 8000},\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',\n 'transcription': \"hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing\"}\n```", "```py\n>>> from transformers import AutoProcessor\n\n>>> processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base\")\n```", "```py\n>>> minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n>>> minds[\"train\"][0]\n{'audio': {'array': array([-2.38064706e-04, -1.58618059e-04, -5.43987835e-06, ...,\n          2.78103951e-04,  2.38446111e-04,  1.18740834e-04], dtype=float32),\n  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',\n  'sampling_rate': 16000},\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',\n 'transcription': \"hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing\"}\n```", "```py\n>>> def uppercase(example):\n...     return {\"transcription\": example[\"transcription\"].upper()}\n\n>>> minds = minds.map(uppercase)\n```", "```py\n>>> def prepare_dataset(batch):\n...     audio = batch[\"audio\"]\n...     batch = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], text=batch[\"transcription\"])\n...     batch[\"input_length\"] = len(batch[\"input_values\"][0])\n...     return batch\n```", "```py\n>>> encoded_minds = minds.map(prepare_dataset, remove_columns=minds.column_names[\"train\"], num_proc=4)\n```", "```py\n>>> import torch\n\n>>> from dataclasses import dataclass, field\n>>> from typing import Any, Dict, List, Optional, Union\n\n>>> @dataclass\n... class DataCollatorCTCWithPadding:\n...     processor: AutoProcessor\n...     padding: Union[bool, str] = \"longest\"\n\n...     def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n...         # split inputs and labels since they have to be of different lengths and need\n...         # different padding methods\n...         input_features = [{\"input_values\": feature[\"input_values\"][0]} for feature in features]\n...         label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n...         batch = self.processor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n\n...         labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=\"pt\")\n\n...         # replace padding with -100 to ignore loss correctly\n...         labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n...         batch[\"labels\"] = labels\n\n...         return batch\n```", "```py\n>>> data_collator = DataCollatorCTCWithPadding(processor=processor, padding=\"longest\")\n```", "```py\n>>> import evaluate\n\n>>> wer = evaluate.load(\"wer\")\n```", "```py\n>>> import numpy as np\n\n>>> def compute_metrics(pred):\n...     pred_logits = pred.predictions\n...     pred_ids = np.argmax(pred_logits, axis=-1)\n\n...     pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n...     pred_str = processor.batch_decode(pred_ids)\n...     label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n...     wer = wer.compute(predictions=pred_str, references=label_str)\n\n...     return {\"wer\": wer}\n```", "```py\n>>> from transformers import AutoModelForCTC, TrainingArguments, Trainer\n\n>>> model = AutoModelForCTC.from_pretrained(\n...     \"facebook/wav2vec2-base\",\n...     ctc_loss_reduction=\"mean\",\n...     pad_token_id=processor.tokenizer.pad_token_id,\n... )\n```", "```py\n>>> training_args = TrainingArguments(\n...     output_dir=\"my_awesome_asr_mind_model\",\n...     per_device_train_batch_size=8,\n...     gradient_accumulation_steps=2,\n...     learning_rate=1e-5,\n...     warmup_steps=500,\n...     max_steps=2000,\n...     gradient_checkpointing=True,\n...     fp16=True,\n...     group_by_length=True,\n...     evaluation_strategy=\"steps\",\n...     per_device_eval_batch_size=8,\n...     save_steps=1000,\n...     eval_steps=1000,\n...     logging_steps=25,\n...     load_best_model_at_end=True,\n...     metric_for_best_model=\"wer\",\n...     greater_is_better=False,\n...     push_to_hub=True,\n... )\n\n>>> trainer = Trainer(\n...     model=model,\n...     args=training_args,\n...     train_dataset=encoded_minds[\"train\"],\n...     eval_dataset=encoded_minds[\"test\"],\n...     tokenizer=processor,\n...     data_collator=data_collator,\n...     compute_metrics=compute_metrics,\n... )\n\n>>> trainer.train()\n```", "```py\n>>> trainer.push_to_hub()\n```", "```py\n>>> from datasets import load_dataset, Audio\n\n>>> dataset = load_dataset(\"PolyAI/minds14\", \"en-US\", split=\"train\")\n>>> dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n>>> sampling_rate = dataset.features[\"audio\"].sampling_rate\n>>> audio_file = dataset[0][\"audio\"][\"path\"]\n```", "```py\n>>> from transformers import pipeline\n\n>>> transcriber = pipeline(\"automatic-speech-recognition\", model=\"stevhliu/my_awesome_asr_minds_model\")\n>>> transcriber(audio_file)\n{'text': 'I WOUD LIKE O SET UP JOINT ACOUNT WTH Y PARTNER'}\n```", "```py\n>>> from transformers import AutoProcessor\n\n>>> processor = AutoProcessor.from_pretrained(\"stevhliu/my_awesome_asr_mind_model\")\n>>> inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n```", "```py\n>>> from transformers import AutoModelForCTC\n\n>>> model = AutoModelForCTC.from_pretrained(\"stevhliu/my_awesome_asr_mind_model\")\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n```", "```py\n>>> import torch\n\n>>> predicted_ids = torch.argmax(logits, dim=-1)\n>>> transcription = processor.batch_decode(predicted_ids)\n>>> transcription\n['I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']\n```"]