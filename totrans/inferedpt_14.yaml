- en: Update your Endpoint
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/inference-endpoints/guides/update_endpoint](https://huggingface.co/docs/inference-endpoints/guides/update_endpoint)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: You can update `running` Endpoints to change some of the configurations. However,
    if your endpoint is in a `failed` state, you need to create a new Endpoint. To
    update your endpoint you need to navigate to the “settings” tab.
  prefs: []
  type: TYPE_NORMAL
- en: You can update the instance type, autoscaling configuration, task and repository
    revision.
  prefs: []
  type: TYPE_NORMAL
- en: Instance size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can update the instance size of your Endpoint in the Endpoint overview menu
    to match your evolving needs. For example, you can downsize to a smaller instance
    type if you don’t need the compute or alternatively, you can upgrade to a larger
    instance type if you need to increase your compute.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’re able to update your *current* instance type: CPU or GPU. There is no
    ability to update from one instance type to another (CPU to GPU or vice versa).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Instance Type selection](../Images/8da2c0a19824e550b79499455e9f4da0.png)'
  prefs: []
  type: TYPE_IMG
- en: Autoscaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can update the autoscaling configuration of your Endpoint in the settings
    menu. Adjust the minimum and maximum number of replicas to upscale or downscale
    your Endpoint. Learn more about autoscaling [here](https://huggingface.co/docs/inference-endpoints/faq#q-how-does-autoscaling-work).
  prefs: []
  type: TYPE_NORMAL
- en: Task
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can update the task of your running Endpoint in the settings menu. The task
    defines the `pipeline` type your Endpoint will use and the inference widget on
    the Endpoint overview.
  prefs: []
  type: TYPE_NORMAL
- en: Revision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can update the revision of your `running` Endpoint in the settings menu.
    The revision defines the version of the model repository you want to use for inference.
  prefs: []
  type: TYPE_NORMAL
