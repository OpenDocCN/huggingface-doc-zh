- en: Create a dataset for training
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†
- en: 'Original text: [https://huggingface.co/docs/diffusers/training/create_dataset](https://huggingface.co/docs/diffusers/training/create_dataset)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/training/create_dataset](https://huggingface.co/docs/diffusers/training/create_dataset)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: There are many datasets on the [Hub](https://huggingface.co/datasets?task_categories=task_categories:text-to-image&sort=downloads)
    to train a model on, but if you canâ€™t find one youâ€™re interested in or want to
    use your own, you can create a dataset with the ğŸ¤— [Datasets](hf.co/docs/datasets)
    library. The dataset structure depends on the task you want to train your model
    on. The most basic dataset structure is a directory of images for tasks like unconditional
    image generation. Another dataset structure may be a directory of images and a
    text file containing their corresponding text captions for tasks like text-to-image
    generation.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Hubä¸Šæœ‰è®¸å¤šæ•°æ®é›†å¯ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œä½†å¦‚æœæ‰¾ä¸åˆ°æ‚¨æ„Ÿå…´è¶£çš„æ•°æ®é›†æˆ–æƒ³ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ğŸ¤—[Datasets](hf.co/docs/datasets)åº“åˆ›å»ºæ•°æ®é›†ã€‚æ•°æ®é›†ç»“æ„å–å†³äºæ‚¨æƒ³è¦è®­ç»ƒæ¨¡å‹çš„ä»»åŠ¡ã€‚æœ€åŸºæœ¬çš„æ•°æ®é›†ç»“æ„æ˜¯å›¾åƒç›®å½•ï¼Œç”¨äºæ— æ¡ä»¶å›¾åƒç”Ÿæˆç­‰ä»»åŠ¡ã€‚å¦ä¸€ä¸ªæ•°æ®é›†ç»“æ„å¯èƒ½æ˜¯å›¾åƒç›®å½•å’ŒåŒ…å«ç›¸åº”æ–‡æœ¬æ ‡é¢˜çš„æ–‡æœ¬æ–‡ä»¶ï¼Œç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç­‰ä»»åŠ¡ã€‚
- en: 'This guide will show you two ways to create a dataset to finetune on:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æŒ‡å—å°†å‘æ‚¨å±•ç¤ºä¸¤ç§åˆ›å»ºæ•°æ®é›†ä»¥è¿›è¡Œå¾®è°ƒçš„æ–¹æ³•ï¼š
- en: provide a folder of images to the `--train_data_dir` argument
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†å›¾åƒæ–‡ä»¶å¤¹æä¾›ç»™`--train_data_dir`å‚æ•°
- en: upload a dataset to the Hub and pass the dataset repository id to the `--dataset_name`
    argument
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ•°æ®é›†ä¸Šä¼ åˆ°Hubï¼Œå¹¶å°†æ•°æ®é›†å­˜å‚¨åº“IDä¼ é€’ç»™`--dataset_name`å‚æ•°
- en: ğŸ’¡ Learn more about how to create an image dataset for training in the [Create
    an image dataset](https://huggingface.co/docs/datasets/image_dataset) guide.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡äº†è§£æœ‰å…³å¦‚ä½•ä¸ºè®­ç»ƒåˆ›å»ºå›¾åƒæ•°æ®é›†çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[åˆ›å»ºå›¾åƒæ•°æ®é›†](https://huggingface.co/docs/datasets/image_dataset)æŒ‡å—ã€‚
- en: Provide a dataset as a folder
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æä¾›ä¸€ä¸ªä½œä¸ºæ–‡ä»¶å¤¹çš„æ•°æ®é›†
- en: 'For unconditional generation, you can provide your own dataset as a folder
    of images. The training script uses the [`ImageFolder`](https://huggingface.co/docs/datasets/en/image_dataset#imagefolder)
    builder from ğŸ¤— Datasets to automatically build a dataset from the folder. Your
    directory structure should look like:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ— æ¡ä»¶ç”Ÿæˆï¼Œæ‚¨å¯ä»¥æä¾›è‡ªå·±çš„æ•°æ®é›†ä½œä¸ºå›¾åƒæ–‡ä»¶å¤¹ã€‚è®­ç»ƒè„šæœ¬ä½¿ç”¨ğŸ¤—æ•°æ®é›†ä¸­çš„[`ImageFolder`](https://huggingface.co/docs/datasets/en/image_dataset#imagefolder)æ„å»ºå™¨ï¼Œè‡ªåŠ¨ä»æ–‡ä»¶å¤¹æ„å»ºæ•°æ®é›†ã€‚æ‚¨çš„ç›®å½•ç»“æ„åº”å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Pass the path to the dataset directory to the `--train_data_dir` argument,
    and then you can start training:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ•°æ®é›†ç›®å½•è·¯å¾„ä¼ é€’ç»™`--train_data_dir`å‚æ•°ï¼Œç„¶åæ‚¨å¯ä»¥å¼€å§‹è®­ç»ƒï¼š
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Upload your data to the Hub
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å°†æ•°æ®ä¸Šä¼ åˆ°Hub
- en: ğŸ’¡ For more details and context about creating and uploading a dataset to the
    Hub, take a look at the [Image search with ğŸ¤— Datasets](https://huggingface.co/blog/image-search-datasets)
    post.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡æœ‰å…³åœ¨Hubä¸Šåˆ›å»ºå’Œä¸Šä¼ æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯å’ŒèƒŒæ™¯ï¼Œè¯·æŸ¥çœ‹[ä½¿ç”¨ğŸ¤—æ•°æ®é›†è¿›è¡Œå›¾åƒæœç´¢](https://huggingface.co/blog/image-search-datasets)å¸–å­ã€‚
- en: Start by creating a dataset with the [`ImageFolder`](https://huggingface.co/docs/datasets/image_load#imagefolder)
    feature, which creates an `image` column containing the PIL-encoded images.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆä½¿ç”¨[`ImageFolder`](https://huggingface.co/docs/datasets/image_load#imagefolder)åŠŸèƒ½åˆ›å»ºä¸€ä¸ªæ•°æ®é›†ï¼Œè¯¥åŠŸèƒ½åˆ›å»ºä¸€ä¸ªåŒ…å«PILç¼–ç å›¾åƒçš„`image`åˆ—ã€‚
- en: 'You can use the `data_dir` or `data_files` parameters to specify the location
    of the dataset. The `data_files` parameter supports mapping specific files to
    dataset splits like `train` or `test`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä½¿ç”¨`data_dir`æˆ–`data_files`å‚æ•°æŒ‡å®šæ•°æ®é›†çš„ä½ç½®ã€‚`data_files`å‚æ•°æ”¯æŒå°†ç‰¹å®šæ–‡ä»¶æ˜ å°„åˆ°æ•°æ®é›†æ‹†åˆ†ï¼Œå¦‚`train`æˆ–`test`ï¼š
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then use the [push_to_hub](https://huggingface.co/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)
    method to upload the dataset to the Hub:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½¿ç”¨[push_to_hub](https://huggingface.co/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)æ–¹æ³•å°†æ•°æ®é›†ä¸Šä¼ åˆ°Hubï¼š
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now the dataset is available for training by passing the dataset name to the
    `--dataset_name` argument:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ•°æ®é›†å¯ä¾›è®­ç»ƒï¼Œé€šè¿‡å°†æ•°æ®é›†åç§°ä¼ é€’ç»™`--dataset_name`å‚æ•°ï¼š
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Next steps
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥
- en: Now that youâ€™ve created a dataset, you can plug it into the `train_data_dir`
    (if your dataset is local) or `dataset_name` (if your dataset is on the Hub) arguments
    of a training script.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²ç»åˆ›å»ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼Œæ‚¨å¯ä»¥å°†å…¶æ’å…¥åˆ°è®­ç»ƒè„šæœ¬çš„`train_data_dir`ï¼ˆå¦‚æœæ‚¨çš„æ•°æ®é›†æ˜¯æœ¬åœ°çš„ï¼‰æˆ–`dataset_name`ï¼ˆå¦‚æœæ‚¨çš„æ•°æ®é›†åœ¨Hubä¸Šï¼‰å‚æ•°ä¸­ã€‚
- en: For your next steps, feel free to try and use your dataset to train a model
    for [unconditional generation](unconditional_training) or [text-to-image generation](text2image)!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‚¨çš„ä¸‹ä¸€æ­¥ä¸­ï¼Œéšæ—¶å°è¯•ä½¿ç”¨æ‚¨çš„æ•°æ®é›†æ¥è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç”¨äº[æ— æ¡ä»¶ç”Ÿæˆ](unconditional_training)æˆ–[æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ](text2image)ï¼
