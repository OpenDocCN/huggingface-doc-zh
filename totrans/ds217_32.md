# 创建音频数据集

> 原始文本：[https://huggingface.co/docs/datasets/audio_dataset](https://huggingface.co/docs/datasets/audio_dataset)

您可以通过在Hugging Face Hub上创建数据集存储库与团队或社区中的任何人共享数据集：

```py
from datasets import load_dataset

dataset = load_dataset("<username>/my_dataset")
```

有几种方法可以创建和共享音频数据集：

+   使用[Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)在Python中从本地文件创建音频数据集。这是一种只需要在Python中进行几个步骤的简单方法。

+   使用`AudioFolder`构建器创建音频数据集存储库。这是一种无代码解决方案，可快速创建包含数千个音频文件的音频数据集。

+   通过编写加载脚本创建音频数据集。这种方法适用于高级用户，需要更多的努力和编码，但您可以更灵活地定义、下载和生成数据集，这对于更复杂或大规模的音频数据集可能很有用。

您可以通过要求用户首先共享其联系信息来控制对数据集的访问权限。查看[Hugging Face Hub上的Gated数据集](https://huggingface.co/docs/hub/datasets-gated)指南，了解如何在Hub上启用此功能的更多信息。

## 本地文件

您可以使用音频文件的路径加载自己的数据集。使用[cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)函数将音频文件路径列转换为[Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)特征：

```py
>>> audio_dataset = Dataset.from_dict({"audio": ["path/to/audio_1", "path/to/audio_2", ..., "path/to/audio_n"]}).cast_column("audio", Audio())
>>> audio_dataset[0]["audio"]
{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,
         0.        ,  0.        ], dtype=float32),
 'path': 'path/to/audio_1',
 'sampling_rate': 16000}
```

然后使用[Dataset.push_to_hub()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub)将数据集上传到Hugging Face Hub：

```py
audio_dataset.push_to_hub("<username>/my_dataset")
```

这将创建一个包含您音频数据集的数据集存储库：

```py
my_dataset/
├── README.md
└── data/
    └── train-00000-of-00001.parquet
```

## AudioFolder

`AudioFolder`是一个数据集构建器，旨在快速加载包含数千个音频文件的音频数据集，而无需您编写任何代码。只要在元数据文件（`metadata.csv`/`metadata.jsonl`）中包含此信息，`AudioFolder`会自动加载有关数据集的任何其他信息 - 如转录、说话者口音或说话者意图。

💡查看[Split pattern hierarchy](repository_structure#split-pattern-hierarchy)以了解有关`AudioFolder`如何根据数据集存储库结构创建数据集拆分的更多信息。

在Hugging Face Hub上创建一个数据集存储库，并按照`AudioFolder`结构上传您的数据集目录：

```py
my_dataset/
├── README.md
├── metadata.csv
└── data/
```

`data`文件夹可以是任何您想要的名称。

如果数据列包含更复杂的格式（如浮点数列表）时，将元数据存储为`jsonl`文件可能会有所帮助，以避免解析错误或将复杂值读取为字符串。

元数据文件应包括一个`file_name`列，将音频文件与其元数据链接起来：

```py
file_name,transcription
data/first_audio_file.mp3,znowu się duch z ciałem zrośnie w młodocianej wstaniesz wiosnie i możesz skutkiem tych leków umierać wstawać wiek wieków dalej tam były przestrogi jak siekać głowę jak nogi
data/second_audio_file.mp3,już u źwierzyńca podwojów król zasiada przy nim książęta i panowie rada a gdzie wzniosły krążył ganek rycerze obok kochanek król skinął palcem zaczęto igrzysko
data/third_audio_file.mp3,pewnie kędyś w obłędzie ubite minęły szlaki zaczekajmy dzień jaki poślemy szukać wszędzie dziś jutro pewnie będzie posłali wszędzie sługi czekali dzień i drugi gdy nic nie doczekali z płaczem chcą jechać dali
```

然后您可以将数据集存储在这样的目录结构中：

```py
metadata.csv
data/first_audio_file.mp3
data/second_audio_file.mp3
data/third_audio_file.mp3

```

用户现在可以通过在[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)中指定`audiofolder`和在`data_dir`中指定数据集目录来加载您的数据集和相关元数据：

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset("audiofolder", data_dir="/path/to/data")
>>> dataset["train"][0]
{'audio':
    {'path': '/path/to/extracted/audio/first_audio_file.mp3',
    'array': array([ 0.00088501,  0.0012207 ,  0.00131226, ..., -0.00045776, -0.00054932, -0.00054932], dtype=float32),
    'sampling_rate': 16000},
 'transcription': 'znowu się duch z ciałem zrośnie w młodocianej wstaniesz wiosnie i możesz skutkiem tych leków umierać wstawać wiek wieków dalej tam były przestrogi jak siekać głowę jak nogi'
}
```

您还可以使用`audiofolder`加载涉及多个拆分的数据集。为此，您的数据集目录可能具有以下结构：

```py
data/train/first_train_audio_file.mp3
data/train/second_train_audio_file.mp3

data/test/first_test_audio_file.mp3
data/test/second_test_audio_file.mp3

```

请注意，如果音频文件不是紧邻元数据文件，`file_name`列应该是音频文件的完整相对路径，而不仅仅是文件名。

对于没有任何关联元数据的音频数据集，`AudioFolder`会根据目录名称自动推断数据集的类标签。这对于音频分类任务可能很有用。您的数据集目录可能如下所示：

```py
data/train/electronic/01.mp3
data/train/punk/01.mp3

data/test/electronic/09.mp3
data/test/punk/09.mp3
```

使用`AudioFolder`加载数据集，它将从目录名称（语言ID）创建一个`label`列：

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset("audiofolder", data_dir="/path/to/data")
>>> dataset["train"][0]
{'audio':
    {'path': '/path/to/electronic/01.mp3',
     'array': array([ 3.9714024e-07,  7.3031038e-07,  7.5640685e-07, ...,
         -1.1963668e-01, -1.1681189e-01, -1.1244172e-01], dtype=float32),
     'sampling_rate': 44100},
 'label': 0  # "electronic"
}
>>> dataset["train"][-1]
{'audio':
    {'path': '/path/to/punk/01.mp3',
     'array': array([0.15237972, 0.13222949, 0.10627693, ..., 0.41940814, 0.37578005,
         0.33717662], dtype=float32),
     'sampling_rate': 44100},
 'label': 1  # "punk"
}
```

如果所有音频文件都包含在一个单独的目录中，或者它们不在相同级别的目录结构中，`label` 列不会自动添加。如果需要它，请显式设置 `drop_labels=False`。

一些音频数据集，比如在[Kaggle 竞赛](https://www.kaggle.com/competitions/kaggle-pog-series-s01e02/overview)中发现的那些，为每个拆分单独提供了元数据文件。只要每个拆分的元数据特征相同，`audiofolder` 就可以用来一次加载所有拆分。如果每个拆分的元数据特征不同，您应该使用单独的 `load_dataset()` 调用来加载它们。

## 加载脚本

编写一个数据集加载脚本来手动创建一个数据集。它定义了数据集的拆分和配置，并处理下载和生成数据集示例。脚本的名称应与您的数据集文件夹或存储库相同：

```py
my_dataset/
├── README.md
├── my_dataset.py
└── data/
```

`data` 文件夹可以是您想要的任何名称，不一定是 `data`。除非您将数据集托管在 Hub 上，否则此文件夹是可选的。

这个目录结构允许您的数据集在一行中加载：

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset("path/to/my_dataset")
```

本指南将向您展示如何为音频数据集创建一个数据集加载脚本，这与[为文本数据集创建加载脚本](./dataset_script)有些不同。音频数据集通常存储在 `tar.gz` 存档中，这需要一种特殊的方法来支持流式模式。虽然流式传输不是必需的，但我们强烈建议在您的音频数据集中实现流式支持，因为没有太多磁盘空间的用户可以在不下载数据集的情况下使用您的数据集。在[Stream](./stream)指南中了解更多关于流式传输的信息！

这里是一个使用 TAR 存档的示例：

```py
my_dataset/
├── README.md
├── my_dataset.py
└── data/
    ├── train.tar.gz
    ├── test.tar.gz
    └── metadata.csv
```

除了学习如何创建一个可流式传输的数据集，您还将学习如何：

+   创建一个数据集构建器类。

+   创建数据集配置。

+   添加数据集元数据。

+   下载并定义数据集拆分。

+   生成数据集。

+   将数据集上传到 Hub。

学习的最佳方法是打开一个现有的音频数据集加载脚本，比如[Vivos](https://huggingface.co/datasets/vivos/blob/main/vivos.py)，并跟着做！

本指南展示了如何处理存储在 TAR 存档中的音频数据 - 这是音频数据集的最常见情况。查看[minds14](https://huggingface.co/datasets/PolyAI/minds14/blob/main/minds14.py) 数据集，了解一个使用 ZIP 存档的音频脚本示例。

为了帮助您入门，我们创建了一个加载脚本[模板](https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py)，您可以复制并用作起点！

### 创建一个数据集构建器类

[GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder) 是从字典生成器生成的数据集的基类。在这个类中，有三种方法可以帮助您创建数据集：

+   `_info` 存储有关数据集的信息，如描述、许可证和特征。

+   `_split_generators` 下载数据集并定义其拆分。

+   `_generate_examples` 为每个拆分生成包含音频数据和 `info` 中指定的其他特征的数据集样本。

首先创建您的数据集类，作为 [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder) 的子类，并添加这三种方法。暂时不用担心填写这些方法中的每一个，您将在接下来的几个部分中开发它们：

```py
class VivosDataset(datasets.GeneratorBasedBuilder):
    """VIVOS is a free Vietnamese speech corpus consisting of 15 hours of recording speech prepared for
    Vietnamese Automatic Speech Recognition task."""

    def _info(self):

    def _split_generators(self, dl_manager):

    def _generate_examples(self, prompts_path, path_to_clips, audio_files):

```

#### 多个配置

在某些情况下，一个数据集可能有多个配置。例如，[LibriVox Indonesia](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia) 数据集有几个对应不同语言的配置。

要创建不同的配置，使用 [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig) 类来创建数据集的子类。唯一需要的参数是配置的 `name`，必须传递给配置的超类 `__init__()`。否则，您可以在配置类中指定任何自定义参数。

```py
class LibriVoxIndonesiaConfig(datasets.BuilderConfig):
    """BuilderConfig for LibriVoxIndonesia."""

    def __init__(self, name, version, **kwargs):
        self.language = kwargs.pop("language", None)
        self.release_date = kwargs.pop("release_date", None)
        self.num_clips = kwargs.pop("num_clips", None)
        self.num_speakers = kwargs.pop("num_speakers", None)
        self.validated_hr = kwargs.pop("validated_hr", None)
        self.total_hr = kwargs.pop("total_hr", None)
        self.size_bytes = kwargs.pop("size_bytes", None)
        self.size_human = size_str(self.size_bytes)
        description = (
            f"LibriVox-Indonesia speech to text dataset in {self.language} released on {self.release_date}. "
            f"The dataset comprises {self.validated_hr} hours of transcribed speech data"
        )
        super(LibriVoxIndonesiaConfig, self).__init__(
            name=name,
            version=datasets.Version(version),
            description=description,
            **kwargs,
        )
```

在 [GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder) 内部的 `BUILDER_CONFIGS` 类变量中定义您的配置。在此示例中，作者从一个单独的 `release_stats.py` [文件](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/release_stats.py) 中导入语言，然后循环遍历每种语言以创建一个配置：

```py
class LibriVoxIndonesia(datasets.GeneratorBasedBuilder):
    DEFAULT_CONFIG_NAME = "all"

    BUILDER_CONFIGS = [
        LibriVoxIndonesiaConfig(
            name=lang,
            version=STATS["version"],
            language=LANGUAGES[lang],
            release_date=STATS["date"],
            num_clips=lang_stats["clips"],
            num_speakers=lang_stats["users"],
            total_hr=float(lang_stats["totalHrs"]) if lang_stats["totalHrs"] else None,
            size_bytes=int(lang_stats["size"]) if lang_stats["size"] else None,
        )
        for lang, lang_stats in STATS["locales"].items()
    ]
```

通常，用户需要指定一个配置来加载 [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)，否则会引发 `ValueError`。您可以通过设置默认数据集配置来避免这种情况，以在 `DEFAULT_CONFIG_NAME` 中加载。

现在，如果用户想要加载 Balinese (`bal`) 配置，他们可以使用配置名称：

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset("indonesian-nlp/librivox-indonesia", "bal", split="train")
```

### 添加数据集元数据

添加关于您的数据集的信息可以帮助用户了解更多。这些信息存储在 [DatasetInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetInfo) 类中，该类由 `info` 方法返回。用户可以通过以下方式访问这些信息：

```py
>>> from datasets import load_dataset_builder
>>> ds_builder = load_dataset_builder("vivos")
>>> ds_builder.info
```

您可以包含很多关于数据集的信息，但一些重要的信息包括：

1.  `description` 提供数据集的简明描述。

1.  `features` 指定数据集列类型。由于您正在创建一个音频加载脚本，您需要包括 [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio) 特征和数据集的 `sampling_rate`。

1.  `homepage` 提供数据集主页的链接。

1.  `license` 指定使用数据集的权限，由许可证类型定义。

1.  `citation` 是数据集的 BibTeX 引用。

您会注意到很多数据集信息在加载脚本中早已定义，这可以使阅读更加容易。还有其他 `~Dataset.Features` 您可以输入，所以一定要查看完整列表和 [features guide](./about_dataset_features) 以获取更多详细信息。

```py
def _info(self):
    return datasets.DatasetInfo(
        description=_DESCRIPTION,
        features=datasets.Features(
            {
                "speaker_id": datasets.Value("string"),
                "path": datasets.Value("string"),
                "audio": datasets.Audio(sampling_rate=16_000),
                "sentence": datasets.Value("string"),
            }
        ),
        supervised_keys=None,
        homepage=_HOMEPAGE,
        license=_LICENSE,
        citation=_CITATION,
    )
```

### 下载并定义数据集拆分

现在您已经添加了一些关于数据集的信息，下一步是下载数据集并定义拆分。

1.  使用 [download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download) 方法下载 `_PROMPTS_URLS` 中的元数据文件和 `_DATA_URL` 中的音频 TAR 存档。此方法返回本地文件/存档的路径。在流式模式下，它不会下载文件，只会返回一个从中流式传输数据的 URL。此方法接受：

    +   Hub 数据集存储库中文件的相对路径（例如，在 `data/` 文件夹中）

    +   一个指向其他地方托管的文件的 URL

    +   一个（嵌套的）文件名或 URL 的列表或字典

1.  在下载数据集后，使用 [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator) 来组织每个拆分中的音频文件和句子提示。为每个拆分命名一个标准名称，如：`Split.TRAIN`、`Split.TEST` 和 `SPLIT.Validation`。

    在 `gen_kwargs` 参数中，指定 `prompts_path` 和 `path_to_clips` 的文件路径。对于 `audio_files`，您需要使用 [iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive) 来迭代 TAR 存档中的音频文件。这使得您的数据集可以进行流式传输。所有这些文件路径都传递到下一步，您将在那里实际生成数据集。

```py
def _split_generators(self, dl_manager):
    """Returns SplitGenerators."""
    prompts_paths = dl_manager.download(_PROMPTS_URLS)
    archive = dl_manager.download(_DATA_URL)
    train_dir = "vivos/train"
    test_dir = "vivos/test"

    return [
        datasets.SplitGenerator(
            name=datasets.Split.TRAIN,
            gen_kwargs={
                "prompts_path": prompts_paths["train"],
                "path_to_clips": train_dir + "/waves",
                "audio_files": dl_manager.iter_archive(archive),
            },
        ),
        datasets.SplitGenerator(
            name=datasets.Split.TEST,
            gen_kwargs={
                "prompts_path": prompts_paths["test"],
                "path_to_clips": test_dir + "/waves",
                "audio_files": dl_manager.iter_archive(archive),
            },
        ),
    ]
```

此实现不会提取已下载的存档。如果您想要在下载后提取文件，您需要额外使用[extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract)，请参阅[(高级) 本地提取 TAR 存档](#advanced-extract-tar-archives-locally)部分。

### 生成数据集

[GeneratorBasedBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.GeneratorBasedBuilder) 类中的最后一个方法实际上生成数据集中的样本。它根据`info`方法中指定的`features`结构生成数据集。如您所见，`generate_examples`接受来自前一方法的`prompts_path`、`path_to_clips`和`audio_files`作为参数。

TAR 存档中的文件按顺序访问和生成。这意味着您需要首先准备好与 TAR 文件中音频文件相关的元数据，以便能够将其与相应的音频文件一起生成。

```py
examples = {}
with open(prompts_path, encoding="utf-8") as f:
    for row in f:
        data = row.strip().split(" ", 1)
        speaker_id = data[0].split("_")[0]
        audio_path = "/".join([path_to_clips, speaker_id, data[0] + ".wav"])
        examples[audio_path] = {
            "speaker_id": speaker_id,
            "path": audio_path,
            "sentence": data[1],
        }
```

最后，在`audio_files`中迭代文件并与其对应的元数据一起生成。[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive) 生成一个元组(`path`, `f`)，其中`path`是 TAR 存档中文件的**相对**路径，`f`是文件对象本身。

```py
inside_clips_dir = False
id_ = 0
for path, f in audio_files:
    if path.startswith(path_to_clips):
        inside_clips_dir = True
        if path in examples:
            audio = {"path": path, "bytes": f.read()}
            yield id_, {**examples[path], "audio": audio}
            id_ += 1
    elif inside_clips_dir:
        break
```

将这两个步骤结合起来，整个`_generate_examples`方法看起来像这样：

```py
def _generate_examples(self, prompts_path, path_to_clips, audio_files):
    """Yields examples as (key, example) tuples."""
    examples = {}
    with open(prompts_path, encoding="utf-8") as f:
        for row in f:
            data = row.strip().split(" ", 1)
            speaker_id = data[0].split("_")[0]
            audio_path = "/".join([path_to_clips, speaker_id, data[0] + ".wav"])
            examples[audio_path] = {
                "speaker_id": speaker_id,
                "path": audio_path,
                "sentence": data[1],
            }
    inside_clips_dir = False
    id_ = 0
    for path, f in audio_files:
        if path.startswith(path_to_clips):
            inside_clips_dir = True
            if path in examples:
                audio = {"path": path, "bytes": f.read()}
                yield id_, {**examples[path], "audio": audio}
                id_ += 1
        elif inside_clips_dir:
            break
```

### 将数据集上传到Hub

一旦您的脚本准备好了，[创建一个数据集卡片](./dataset_card)并[上传到Hub](./share)。

恭喜，您现在可以从Hub加载您的数据集了！🥳

```py
>>> from datasets import load_dataset
>>> load_dataset("<username>/my_dataset")
```

### （高级）本地提取 TAR 存档

在上面的示例中，下载的存档没有被提取，因此示例不包含有关它们在本地存储位置的信息。为了解释如何以支持流式传输的方式进行提取，我们将简要介绍[LibriVox Indonesia](https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/blob/main/librivox-indonesia.py)加载脚本。

#### 下载并定义数据集拆分

1.  使用[download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)方法下载位于`_AUDIO_URL`的音频数据。

1.  要在本地提取音频 TAR 存档，请使用[extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract)。您只能在非流式模式下使用此方法（当`dl_manager.is_streaming=False`时）。这将返回提取的存档目录的本地路径：

    ```py
    local_extracted_archive = dl_manager.extract(audio_path) if not dl_manager.is_streaming else None
    ```

1.  使用[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)方法迭代位于`audio_path`的存档，就像上面的 Vivos 示例一样。[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)不提供有关存档中文件的完整路径的信息，即使已经提取。因此，您需要在`gen_kwargs`中将`local_extracted_archive`路径传递给下一步，以保留有关存档提取位置的信息。这是在生成示例时构建正确的本地文件路径所必需的。

您需要同时使用[download()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download)和[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)的组合，因为无法直接通过路径访问TAR存档中的文件。相反，您需要迭代存档中的文件！您可以使用[download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)和[extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.extract)来处理TAR存档，但只能在非流模式下进行，否则会出错。

1.  使用[download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)方法下载在`_METADATA_URL`中指定的元数据文件。该方法以非流模式返回本地文件的路径。在流模式下，它不会在本地下载文件，而是返回相同的URL。

1.  现在使用[SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)来组织每个拆分中的音频文件和元数据。为每个拆分命名一个标准名称，如：`Split.TRAIN`、`Split.TEST`和`SPLIT.Validation`。

    在`gen_kwargs`参数中，指定`local_extracted_archive`、`audio_files`、`metadata_path`和`path_to_clips`的文件路径。请记住，对于`audio_files`，您需要使用[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)来迭代TAR存档中的音频文件。这将为您的数据集启用流式处理！所有这些文件路径都传递到下一步，生成数据集样本。

```py
def _split_generators(self, dl_manager):
    """Returns SplitGenerators."""
    dl_manager.download_config.ignore_url_params = True

    audio_path = dl_manager.download(_AUDIO_URL)
    local_extracted_archive = dl_manager.extract(audio_path) if not dl_manager.is_streaming else None
    path_to_clips = "librivox-indonesia"

    return [
        datasets.SplitGenerator(
            name=datasets.Split.TRAIN,
            gen_kwargs={
                "local_extracted_archive": local_extracted_archive,
                "audio_files": dl_manager.iter_archive(audio_path),
                "metadata_path": dl_manager.download_and_extract(_METADATA_URL + "/metadata_train.csv.gz"),
                "path_to_clips": path_to_clips,
            },
        ),
        datasets.SplitGenerator(
            name=datasets.Split.TEST,
            gen_kwargs={
                "local_extracted_archive": local_extracted_archive,
                "audio_files": dl_manager.iter_archive(audio_path),
                "metadata_path": dl_manager.download_and_extract(_METADATA_URL + "/metadata_test.csv.gz"),
                "path_to_clips": path_to_clips,
            },
        ),
    ]
```

#### 生成数据集

在这里，`_generate_examples`接受来自先前方法的`local_extracted_archive`、`audio_files`、`metadata_path`和`path_to_clips`作为参数。

1.  TAR文件按顺序访问和产生。这意味着您需要首先将`metadata_path`中的元数据与TAR文件中的音频文件关联起来，以便随后可以将其与相应的音频文件一起产生。

    ```py
    with open(metadata_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            if self.config.name == "all" or self.config.name == row["language"]:
                row["path"] = os.path.join(path_to_clips, row["path"])
                # if data is incomplete, fill with empty values
                for field in data_fields:
                    if field not in row:
                        row[field] = ""
                metadata[row["path"]] = row
    ```

1.  现在您可以在`audio_files`存档中获取文件。当您使用[iter_archive()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.iter_archive)时，它会产生一个元组(`path`, `f`)，其中`path`是存档中文件的**相对路径**，`f`是文件对象本身。要获取本地提取文件的**完整路径**，请将存档提取到的目录(`local_extracted_path`)的路径与相对音频文件路径(`path`)连接起来：

    ```py
    for path, f in audio_files:
        if path in metadata:
            result = dict(metadata[path])
            # set the audio feature and the path to the extracted file
            path = os.path.join(local_extracted_archive, path) if local_extracted_archive else path
            result["audio"] = {"path": path, "bytes": f.read()}
            result["path"] = path
            yield id_, result
            id_ += 1
    ```

将这两个步骤结合起来，整个`_generate_examples`方法应该如下所示：

```py
def _generate_examples( self,
        local_extracted_archive,
        audio_files,
        metadata_path,
        path_to_clips, ):
        """Yields examples."""
        data_fields = list(self._info().features.keys())
        metadata = {}
        with open(metadata_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                if self.config.name == "all" or self.config.name == row["language"]:
                    row["path"] = os.path.join(path_to_clips, row["path"])
                    # if data is incomplete, fill with empty values
                    for field in data_fields:
                        if field not in row:
                            row[field] = ""
                    metadata[row["path"]] = row
        id_ = 0
        for path, f in audio_files:
            if path in metadata:
                result = dict(metadata[path])
                # set the audio feature and the path to the extracted file
                path = os.path.join(local_extracted_archive, path) if local_extracted_archive else path
                result["audio"] = {"path": path, "bytes": f.read()}
                result["path"] = path
                yield id_, result
                id_ += 1
```
