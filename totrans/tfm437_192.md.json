["```py\nfrom transformers import M2M100Config, M2M100ForConditionalGeneration, M2M100Tokenizer\n\nmodel = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\ntokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\", src_lang=\"en\", tgt_lang=\"fr\")\n\nsrc_text = \"Life is like a box of chocolates.\"\ntgt_text = \"La vie est comme une bo\u00eete de chocolat.\"\n\nmodel_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors=\"pt\")\n\nloss = model(**model_inputs).loss  # forward pass\n```", "```py\n>>> from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n\n>>> hi_text = \"\u091c\u0940\u0935\u0928 \u090f\u0915 \u091a\u0949\u0915\u0932\u0947\u091f \u092c\u0949\u0915\u094d\u0938 \u0915\u0940 \u0924\u0930\u0939 \u0939\u0948\u0964\"\n>>> chinese_text = \"\u751f\u6d3b\u5c31\u50cf\u4e00\u76d2\u5de7\u514b\u529b\u3002\"\n\n>>> model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n>>> tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n\n>>> # translate Hindi to French\n>>> tokenizer.src_lang = \"hi\"\n>>> encoded_hi = tokenizer(hi_text, return_tensors=\"pt\")\n>>> generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.get_lang_id(\"fr\"))\n>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n\"La vie est comme une bo\u00eete de chocolat.\"\n\n>>> # translate Chinese to English\n>>> tokenizer.src_lang = \"zh\"\n>>> encoded_zh = tokenizer(chinese_text, return_tensors=\"pt\")\n>>> generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n\"Life is like a box of chocolate.\"\n```", "```py\n>>> from transformers import M2M100Config, M2M100Model\n\n>>> # Initializing a M2M100 facebook/m2m100_418M style configuration\n>>> configuration = M2M100Config()\n\n>>> # Initializing a model (with random weights) from the facebook/m2m100_418M style configuration\n>>> model = M2M100Model(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n\n>>> model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n>>> tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\", src_lang=\"en\", tgt_lang=\"ro\")\n>>> src_text = \" UN Chief Says There Is No Military Solution in Syria\"\n>>> tgt_text = \"\u015eeful ONU declar\u0103 c\u0103 nu exist\u0103 o solu\u0163ie militar\u0103 \u00een Siria\"\n>>> model_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors=\"pt\")\n>>> outputs = model(**model_inputs)  # should work\n```", "```py\n>>> from transformers import AutoTokenizer, M2M100Model\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/m2m100_418M\")\n>>> model = M2M100Model.from_pretrained(\"facebook/m2m100_418M\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> from transformers import AutoTokenizer, M2M100ForConditionalGeneration\n\n>>> model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/m2m100_418M\")\n\n>>> text_to_translate = \"Life is like a box of chocolates\"\n>>> model_inputs = tokenizer(text_to_translate, return_tensors=\"pt\")\n\n>>> # translate to French\n>>> gen_tokens = model.generate(**model_inputs, forced_bos_token_id=tokenizer.get_lang_id(\"fr\"))\n>>> print(tokenizer.batch_decode(gen_tokens, skip_special_tokens=True))\n```"]