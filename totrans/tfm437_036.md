# 单目深度估计

> 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/tasks/monocular_depth_estimation](https://huggingface.co/docs/transformers/v4.37.2/en/tasks/monocular_depth_estimation)

单目深度估计是一个涉及从单个图像预测场景深度信息的计算机视觉任务。换句话说，它是从单个摄像机视角估计场景中物体的距离的过程。

单目深度估计具有各种应用，包括3D重建，增强现实，自动驾驶和机器人技术。这是一个具有挑战性的任务，因为它要求模型理解场景中物体之间以及相应深度信息之间的复杂关系，这些关系可能受到光照条件、遮挡和纹理等因素的影响。

本教程中展示的任务由以下模型架构支持：

[DPT](../model_doc/dpt), [GLPN](../model_doc/glpn)

在本指南中，您将学习如何：

+   创建深度估计管道

+   手动运行深度估计推断

在开始之前，请确保已安装所有必要的库：

```py
pip install -q transformers
```

## 深度估计管道

尝试使用支持深度估计的模型进行推断的最简单方法是使用相应的[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)。从[Hugging Face Hub上的检查点](https://huggingface.co/models?pipeline_tag=depth-estimation&sort=downloads)实例化一个管道：

```py
>>> from transformers import pipeline

>>> checkpoint = "vinvino02/glpn-nyu"
>>> depth_estimator = pipeline("depth-estimation", model=checkpoint)
```

接下来，选择要分析的图像：

```py
>>> from PIL import Image
>>> import requests

>>> url = "https://unsplash.com/photos/HwBAsSbPBDU/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8MzR8fGNhciUyMGluJTIwdGhlJTIwc3RyZWV0fGVufDB8MHx8fDE2Nzg5MDEwODg&force=true&w=640"
>>> image = Image.open(requests.get(url, stream=True).raw)
>>> image
```

![繁忙街道的照片](../Images/7c44a18801e68f14d4d1cb85510d1bdc.png)

将图像传递给管道。

```py
>>> predictions = depth_estimator(image)
```

管道返回一个带有两个条目的字典。第一个条目名为`predicted_depth`，是一个张量，其值为每个像素的以米为单位的深度。第二个条目`depth`是一个PIL图像，可视化深度估计结果。

让我们看一下可视化结果：

```py
>>> predictions["depth"]
```

![深度估计可视化](../Images/dac09b39a795bd23817e4cff71d4b6a8.png)

## 手动进行深度估计推断

现在您已经看到如何使用深度估计管道，让我们看看如何手动复制相同的结果。

从[Hugging Face Hub上的检查点](https://huggingface.co/models?pipeline_tag=depth-estimation&sort=downloads)加载模型和相关处理器开始。这里我们将使用与之前相同的检查点：

```py
>>> from transformers import AutoImageProcessor, AutoModelForDepthEstimation

>>> checkpoint = "vinvino02/glpn-nyu"

>>> image_processor = AutoImageProcessor.from_pretrained(checkpoint)
>>> model = AutoModelForDepthEstimation.from_pretrained(checkpoint)
```

使用`image_processor`准备模型的图像输入，该处理器将处理必要的图像转换，如调整大小和归一化：

```py
>>> pixel_values = image_processor(image, return_tensors="pt").pixel_values
```

通过模型传递准备好的输入：

```py
>>> import torch

>>> with torch.no_grad():
...     outputs = model(pixel_values)
...     predicted_depth = outputs.predicted_depth
```

可视化结果：

```py
>>> import numpy as np

>>> # interpolate to original size
>>> prediction = torch.nn.functional.interpolate(
...     predicted_depth.unsqueeze(1),
...     size=image.size[::-1],
...     mode="bicubic",
...     align_corners=False,
... ).squeeze()
>>> output = prediction.numpy()

>>> formatted = (output * 255 / np.max(output)).astype("uint8")
>>> depth = Image.fromarray(formatted)
>>> depth
```

![深度估计可视化](../Images/dac09b39a795bd23817e4cff71d4b6a8.png)
