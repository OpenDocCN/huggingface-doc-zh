- en: Let’s train and play with Huggy 🐶
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unitbonus1/train](https://huggingface.co/learn/deep-rl-course/unitbonus1/train)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[![Ask a Question](../Images/255e59f8542cbd6d3f1c72646b2fff13.png)](http://hf.co/join/discord)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/bonus-unit1/bonus-unit1.ipynb)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: We strongly **recommend students use Google Colab for the hands-on exercises**
    instead of running them on their personal computers.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: By using Google Colab, **you can focus on learning and experimenting without
    worrying about the technical aspects** of setting up your environments.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Let’s train Huggy 🐶
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**To start to train Huggy, click on Open In Colab button** 👇 :'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/bonus-unit1/bonus-unit1.ipynb)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![Bonus Unit 1Thumbnail](../Images/7875c1859ac22866c086670b47651bdc.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
- en: In this notebook, we’ll reinforce what we learned in the first Unit by **teaching
    Huggy the Dog to fetch the stick and then play with it directly in your browser**
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy](../Images/57b557f6c646b773c9c9c0173a5adf4f.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
- en: The environment 🎮
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Huggy the Dog, an environment created by [Thomas Simonini](https://twitter.com/ThomasSimonini)
    based on [Puppo The Corgi](https://blog.unity.com/technology/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The library used 📚
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[MLAgents](https://github.com/Unity-Technologies/ml-agents)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’re constantly trying to improve our tutorials, so **if you find some issues
    in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Objectives of this notebook 🏆
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At the end of the notebook, you will:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Understand **the state space, action space, and reward function used to train
    Huggy**.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Train your own Huggy** to fetch the stick.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be able to play **with your trained Huggy directly in your browser**.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prerequisites 🏗️
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before diving into the notebook, you need to:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: 🔲 📚 **Develop an understanding of the foundations of Reinforcement learning**
    (MC, TD, Rewards hypothesis…) by doing Unit 1
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 🔲 📚 **Read the introduction to Huggy** by doing Bonus Unit 1
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Set the GPU 💪
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To **accelerate the agent’s training, we’ll use a GPU**. To do that, go to `Runtime
    > Change Runtime type`
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![GPU Step 1](../Images/5378127c314cdd92729aa31b7e11ca44.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: '`Hardware Accelerator > GPU`'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![GPU Step 2](../Images/e0fec252447f98378386ccca8e57a80a.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: Clone the repository and install the dependencies 🔽
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to clone the repository, that contains ML-Agents.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Download and move the environment zip file in ./trained-envs-executables/linux/
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our environment executable is in a zip file.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to download it and place it to `./trained-envs-executables/linux/`
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We downloaded the file Huggy.zip from [https://github.com/huggingface/Huggy](https://github.com/huggingface/Huggy)
    using `wget`
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Make sure your file is accessible
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let’s recap how this environment works
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The State Space: what Huggy perceives.'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Huggy doesn’t “see” his environment. Instead, we provide him information about
    the environment:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: The target (stick) position
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The relative position between himself and the target
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The orientation of his legs.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given all this information, Huggy **can decide which action to take next to
    fulfill his goal**.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy](../Images/57b557f6c646b773c9c9c0173a5adf4f.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: 'The Action Space: what moves Huggy can do'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Huggy action](../Images/df930c385e7a4439c314cb4356dc2db4.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: '**Joint motors drive huggy legs**. This means that to get the target, Huggy
    needs to **learn to rotate the joint motors of each of his legs correctly so he
    can move**.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: The Reward Function
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The reward function is designed so that **Huggy will fulfill his goal** : fetch
    the stick.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember that one of the foundations of Reinforcement Learning is the *reward
    hypothesis*: a goal can be described as the **maximization of the expected cumulative
    reward**.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，强化学习的基础之一是*奖励假设*：目标可以描述为**最大化预期的累积奖励**。
- en: Here, our goal is that Huggy **goes towards the stick but without spinning too
    much**. Hence, our reward function must translate this goal.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们的目标是让Huggy**朝着棍子走，但不要转得太多**。因此，我们的奖励函数必须体现这一目标。
- en: 'Our reward function:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的奖励函数：
- en: '![Huggy reward function](../Images/02ce46ce021fe61f090b79e963e5fc0e.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![Huggy reward function](../Images/02ce46ce021fe61f090b79e963e5fc0e.png)'
- en: '*Orientation bonus*: we **reward him for getting close to the target**.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*方向奖励*：我们**奖励他靠近目标**。'
- en: '*Time penalty*: a fixed-time penalty given at every action to **force him to
    get to the stick as fast as possible**.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*时间惩罚*：在每个动作中给予的固定时间惩罚，**强迫他尽快到达棍子**。'
- en: '*Rotation penalty*: we penalize Huggy if **he spins too much and turns too
    quickly**.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*旋转惩罚*：如果**他转得太多并且转得太快**，我们会惩罚Huggy。'
- en: '*Getting to the target reward*: we reward Huggy for **reaching the target**.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*达到目标奖励*：我们奖励Huggy**达到目标**。'
- en: Check the Huggy config file
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查Huggy配置文件
- en: In ML-Agents, you define the **training hyperparameters in config.yaml files.**
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在ML-Agents中，您可以在config.yaml文件中定义**训练超参数。**
- en: For the scope of this notebook, we’re not going to modify the hyperparameters,
    but if you want to try as an experiment, Unity provides very [good documentation
    explaining each of them here](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md).
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本笔记本的范围内，我们不打算修改超参数，但如果您想尝试作为实验，Unity提供了非常[好的文档，在这里解释每一个](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md)。
- en: We need to create a config file for Huggy.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要为Huggy创建一个配置文件。
- en: Go to `/content/ml-agents/config/ppo`
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转到`/content/ml-agents/config/ppo`
- en: Create a new file called `Huggy.yaml`
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个名为`Huggy.yaml`的新文件
- en: Copy and paste the content below 🔽
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复制并粘贴下面的内容🔽
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Don’t forget to save the file!
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要忘记保存文件！
- en: '**In the case you want to modify the hyperparameters**, in Google Colab notebook,
    you can click here to open the config.yaml: `/content/ml-agents/config/ppo/Huggy.yaml`'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**如果您想修改超参数**，在Google Colab笔记本中，您可以单击此处打开config.yaml文件：`/content/ml-agents/config/ppo/Huggy.yaml`'
- en: We’re now ready to train our agent 🔥.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好训练我们的agent🔥。
- en: Train our agent
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练我们的agent
- en: To train our agent, we just need to **launch mlagents-learn and select the executable
    containing the environment.**
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练我们的agent，我们只需要**启动mlagents-learn并选择包含环境的可执行文件。**
- en: '![ml learn function](../Images/7345c12d798a0cc836b7f858c8315e94.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![ml learn function](../Images/7345c12d798a0cc836b7f858c8315e94.png)'
- en: 'With ML Agents, we run a training script. We define four parameters:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用ML Agents，我们运行一个训练脚本。我们定义了四个参数：
- en: '`mlagents-learn <config>`: the path where the hyperparameter config file is.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`mlagents-learn <config>`：超参数配置文件的路径。'
- en: '`--env`: where the environment executable is.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`--env`：环境可执行文件的位置。'
- en: '`--run-id`: the name you want to give to your training run id.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`--run-id`：您要为训练运行ID指定的名称。'
- en: '`--no-graphics`: to not launch the visualization during the training.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`--no-graphics`：在训练期间不启动可视化。'
- en: Train the model and use the `--resume` flag to continue training in case of
    interruption.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型并使用`--resume`标志继续训练以防中断。
- en: It will fail first time when you use `--resume`, try running the block again
    to bypass the error.
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第一次使用`--resume`时会失败，请尝试再次运行该块以绕过错误。
- en: The training will take 30 to 45min depending on your machine (don’t forget to
    **set up a GPU**), go take a ☕️ you deserve it 🤗.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 训练将花费30到45分钟，取决于您的机器（不要忘记**设置GPU**），去喝杯☕️，您值得拥有🤗。
- en: '[PRE7]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Push the agent to the 🤗 Hub
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将代理推送到🤗 Hub
- en: Now that we trained our agent, we’re **ready to push it to the Hub to be able
    to play with Huggy on your browser🔥.**
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在我们已经训练了我们的agent，我们**准备将其推送到Hub，以便在浏览器上与Huggy一起玩🔥。**
- en: 'To be able to share your model with the community there are three more steps
    to follow:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够与社区分享您的模型，还有三个步骤要遵循：
- en: 1️⃣ (If it’s not already done) create an account to HF ➡ [https://huggingface.co/join](https://huggingface.co/join)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 1️⃣（如果尚未完成）创建一个HF帐户➡[https://huggingface.co/join](https://huggingface.co/join)
- en: 2️⃣ Sign in and then get your token from the Hugging Face website.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 2️⃣ 登录，然后从Hugging Face网站获取您的令牌。
- en: Create a new token ([https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))
    **with write role**
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新的令牌（[https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)）**具有写入权限**
- en: '![Create HF Token](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![Create HF Token](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
- en: Copy the token
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复制令牌
- en: Run the cell below and paste the token
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行下面的单元格并粘贴令牌
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you don’t want to use Google Colab or a Jupyter Notebook, you need to use
    this command instead: `huggingface-cli login`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不想使用Google Colab或Jupyter Notebook，您需要使用此命令：`huggingface-cli login`
- en: Then, we simply need to run `mlagents-push-to-hf`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们只需要运行`mlagents-push-to-hf`。
- en: '![ml learn function](../Images/15fdd1817bf2650c653297025f24cfe5.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![ml learn function](../Images/15fdd1817bf2650c653297025f24cfe5.png)'
- en: 'And we define 4 parameters:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了4个参数：
- en: '`--run-id`: the name of the training run id.'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`--run-id`：训练运行ID的名称。'
- en: '`--local-dir`: where the agent was saved, it’s results/<run_id name>, so in
    my case results/First Training.'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`--local-dir`：代理保存的位置，是results/<run_id名称>，所以在我的情况下是results/First Training。'
- en: '`--repo-id`: the name of the Hugging Face repo you want to create or update.
    It’s always <your huggingface username>/<the repo name> If the repo does not exist
    **it will be created automatically**'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`--repo-id`：您要创建或更新的Hugging Face repo的名称。它始终是<您的Hugging Face用户名>/<repo名称>如果repo不存在，**将自动创建**'
- en: '`--commit-message`: since HF repos are git repositories you need to give a
    commit message.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`--commit-message`：由于HF repos是git存储库，您需要提供提交消息。'
- en: '[PRE9]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If everything worked you should see this at the end of the process (but with
    a different url 😆) :'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，您应该在过程结束时看到这个（但是网址不同😆）：
- en: '[PRE10]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: It’s the link to your model repository. The repository contains a model card
    that explains how to use the model, your Tensorboard logs and your config file.
    **What’s awesome is that it’s a git repository, which means you can have different
    commits, update your repository with a new push, open Pull Requests, etc.**
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你的模型存储库的链接。存储库包含一个模型卡，解释如何使用模型，你的Tensorboard日志和配置文件。**最棒的是它是一个git存储库，这意味着你可以有不同的提交，用新的推送更新你的存储库，打开Pull
    Requests等。**
- en: '![ml learn function](../Images/c394875425468d5d1214245cdd809c69.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![ml learn function](../Images/c394875425468d5d1214245cdd809c69.png)'
- en: 'But now comes the best part: **being able to play with Huggy online 👀.**'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在最好的部分来了：**能够在线与Huggy玩耍👀。**
- en: Play with your Huggy 🐕
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 和你的Huggy 🐕一起玩
- en: 'This step is the simplest:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步是最简单的：
- en: 'Open the Huggy game in your browser: [https://huggingface.co/spaces/ThomasSimonini/Huggy](https://huggingface.co/spaces/ThomasSimonini/Huggy)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在浏览器中打开Huggy游戏：[https://huggingface.co/spaces/ThomasSimonini/Huggy](https://huggingface.co/spaces/ThomasSimonini/Huggy)
- en: Click on Play with my Huggy model
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击Play with my Huggy model
- en: '![load-huggy](../Images/9ed3c5a5aa1a1ccd093d892f43f68ac3.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![load-huggy](../Images/9ed3c5a5aa1a1ccd093d892f43f68ac3.png)'
- en: In step 1, choose your model repository, which is the model id (in my case ThomasSimonini/ppo-Huggy).
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第1步，选择你的模型存储库，即模型ID（在我的情况下是ThomasSimonini/ppo-Huggy）。
- en: 'In step 2, **choose which model you want to replay**:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第2步，**选择你想要重播的模型**：
- en: I have multiple ones, since we saved a model every 500000 timesteps.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我有多个，因为我们每500000个时间步保存一个模型。
- en: But since I want the most recent one, I choose `Huggy.onnx`
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 但是因为我想要最新的那个，我选择了 `Huggy.onnx`
- en: 👉 It’s good **to try with different models steps to see the improvement of the
    agent.**
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 👉 **尝试使用不同的模型步骤来查看代理的改进。**
- en: Congrats on finishing this bonus unit!
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了这个奖励单元！
- en: You can now sit and enjoy playing with your Huggy 🐶. And don’t **forget to spread
    the love by sharing Huggy with your friends 🤗**. And if you share about it on
    social media, **please tag us @huggingface and me @simoninithomas**
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以坐下来享受和你的Huggy 🐶玩耍了。而且**不要忘记通过与朋友分享Huggy来传递爱 🤗**。如果你在社交媒体上分享了关于它的内容，**请标记我们
    @huggingface 和我 @simoninithomas**
- en: '![Huggy cover](../Images/43d3b16262aca3954e9ac9ccf73b9c3d.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![Huggy封面](../Images/43d3b16262aca3954e9ac9ccf73b9c3d.png)'
- en: Keep Learning, Stay awesome 🤗
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 继续学习，保持棒棒的 🤗
