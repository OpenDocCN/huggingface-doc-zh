- en: Let‚Äôs train and play with Huggy üê∂
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unitbonus1/train](https://huggingface.co/learn/deep-rl-course/unitbonus1/train)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[![Ask
    a Question](../Images/255e59f8542cbd6d3f1c72646b2fff13.png)](http://hf.co/join/discord)
    [![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/bonus-unit1/bonus-unit1.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: We strongly **recommend students use Google Colab for the hands-on exercises**
    instead of running them on their personal computers.
  prefs: []
  type: TYPE_NORMAL
- en: By using Google Colab, **you can focus on learning and experimenting without
    worrying about the technical aspects** of setting up your environments.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs train Huggy üê∂
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**To start to train Huggy, click on Open In Colab button** üëá :'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Open In Colab](../Images/7e2db436150c38a00650f96925aa5581.png)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/bonus-unit1/bonus-unit1.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bonus Unit 1Thumbnail](../Images/7875c1859ac22866c086670b47651bdc.png)'
  prefs: []
  type: TYPE_IMG
- en: In this notebook, we‚Äôll reinforce what we learned in the first Unit by **teaching
    Huggy the Dog to fetch the stick and then play with it directly in your browser**
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy](../Images/57b557f6c646b773c9c9c0173a5adf4f.png)'
  prefs: []
  type: TYPE_IMG
- en: The environment üéÆ
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Huggy the Dog, an environment created by [Thomas Simonini](https://twitter.com/ThomasSimonini)
    based on [Puppo The Corgi](https://blog.unity.com/technology/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The library used üìö
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[MLAgents](https://github.com/Unity-Technologies/ml-agents)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We‚Äôre constantly trying to improve our tutorials, so **if you find some issues
    in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues).
  prefs: []
  type: TYPE_NORMAL
- en: Objectives of this notebook üèÜ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At the end of the notebook, you will:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand **the state space, action space, and reward function used to train
    Huggy**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Train your own Huggy** to fetch the stick.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be able to play **with your trained Huggy directly in your browser**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prerequisites üèóÔ∏è
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before diving into the notebook, you need to:'
  prefs: []
  type: TYPE_NORMAL
- en: üî≤ üìö **Develop an understanding of the foundations of Reinforcement learning**
    (MC, TD, Rewards hypothesis‚Ä¶) by doing Unit 1
  prefs: []
  type: TYPE_NORMAL
- en: üî≤ üìö **Read the introduction to Huggy** by doing Bonus Unit 1
  prefs: []
  type: TYPE_NORMAL
- en: Set the GPU üí™
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To **accelerate the agent‚Äôs training, we‚Äôll use a GPU**. To do that, go to `Runtime
    > Change Runtime type`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![GPU Step 1](../Images/5378127c314cdd92729aa31b7e11ca44.png)'
  prefs: []
  type: TYPE_IMG
- en: '`Hardware Accelerator > GPU`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![GPU Step 2](../Images/e0fec252447f98378386ccca8e57a80a.png)'
  prefs: []
  type: TYPE_IMG
- en: Clone the repository and install the dependencies üîΩ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to clone the repository, that contains ML-Agents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Download and move the environment zip file in ./trained-envs-executables/linux/
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our environment executable is in a zip file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to download it and place it to `./trained-envs-executables/linux/`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We downloaded the file Huggy.zip from [https://github.com/huggingface/Huggy](https://github.com/huggingface/Huggy)
    using `wget`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Make sure your file is accessible
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let‚Äôs recap how this environment works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The State Space: what Huggy perceives.'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Huggy doesn‚Äôt ‚Äúsee‚Äù his environment. Instead, we provide him information about
    the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: The target (stick) position
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The relative position between himself and the target
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The orientation of his legs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given all this information, Huggy **can decide which action to take next to
    fulfill his goal**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy](../Images/57b557f6c646b773c9c9c0173a5adf4f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Action Space: what moves Huggy can do'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Huggy action](../Images/df930c385e7a4439c314cb4356dc2db4.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Joint motors drive huggy legs**. This means that to get the target, Huggy
    needs to **learn to rotate the joint motors of each of his legs correctly so he
    can move**.'
  prefs: []
  type: TYPE_NORMAL
- en: The Reward Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The reward function is designed so that **Huggy will fulfill his goal** : fetch
    the stick.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember that one of the foundations of Reinforcement Learning is the *reward
    hypothesis*: a goal can be described as the **maximization of the expected cumulative
    reward**.'
  prefs: []
  type: TYPE_NORMAL
- en: Here, our goal is that Huggy **goes towards the stick but without spinning too
    much**. Hence, our reward function must translate this goal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our reward function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy reward function](../Images/02ce46ce021fe61f090b79e963e5fc0e.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Orientation bonus*: we **reward him for getting close to the target**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time penalty*: a fixed-time penalty given at every action to **force him to
    get to the stick as fast as possible**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Rotation penalty*: we penalize Huggy if **he spins too much and turns too
    quickly**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Getting to the target reward*: we reward Huggy for **reaching the target**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check the Huggy config file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In ML-Agents, you define the **training hyperparameters in config.yaml files.**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the scope of this notebook, we‚Äôre not going to modify the hyperparameters,
    but if you want to try as an experiment, Unity provides very [good documentation
    explaining each of them here](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to create a config file for Huggy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Go to `/content/ml-agents/config/ppo`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a new file called `Huggy.yaml`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copy and paste the content below üîΩ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Don‚Äôt forget to save the file!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**In the case you want to modify the hyperparameters**, in Google Colab notebook,
    you can click here to open the config.yaml: `/content/ml-agents/config/ppo/Huggy.yaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We‚Äôre now ready to train our agent üî•.
  prefs: []
  type: TYPE_NORMAL
- en: Train our agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To train our agent, we just need to **launch mlagents-learn and select the executable
    containing the environment.**
  prefs: []
  type: TYPE_NORMAL
- en: '![ml learn function](../Images/7345c12d798a0cc836b7f858c8315e94.png)'
  prefs: []
  type: TYPE_IMG
- en: 'With ML Agents, we run a training script. We define four parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mlagents-learn <config>`: the path where the hyperparameter config file is.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`--env`: where the environment executable is.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`--run-id`: the name you want to give to your training run id.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`--no-graphics`: to not launch the visualization during the training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model and use the `--resume` flag to continue training in case of
    interruption.
  prefs: []
  type: TYPE_NORMAL
- en: It will fail first time when you use `--resume`, try running the block again
    to bypass the error.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The training will take 30 to 45min depending on your machine (don‚Äôt forget to
    **set up a GPU**), go take a ‚òïÔ∏è you deserve it ü§ó.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Push the agent to the ü§ó Hub
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we trained our agent, we‚Äôre **ready to push it to the Hub to be able
    to play with Huggy on your browserüî•.**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To be able to share your model with the community there are three more steps
    to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: 1Ô∏è‚É£ (If it‚Äôs not already done) create an account to HF ‚û° [https://huggingface.co/join](https://huggingface.co/join)
  prefs: []
  type: TYPE_NORMAL
- en: 2Ô∏è‚É£ Sign in and then get your token from the Hugging Face website.
  prefs: []
  type: TYPE_NORMAL
- en: Create a new token ([https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))
    **with write role**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Create HF Token](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
  prefs: []
  type: TYPE_IMG
- en: Copy the token
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the cell below and paste the token
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If you don‚Äôt want to use Google Colab or a Jupyter Notebook, you need to use
    this command instead: `huggingface-cli login`'
  prefs: []
  type: TYPE_NORMAL
- en: Then, we simply need to run `mlagents-push-to-hf`.
  prefs: []
  type: TYPE_NORMAL
- en: '![ml learn function](../Images/15fdd1817bf2650c653297025f24cfe5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And we define 4 parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--run-id`: the name of the training run id.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`--local-dir`: where the agent was saved, it‚Äôs results/<run_id name>, so in
    my case results/First Training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`--repo-id`: the name of the Hugging Face repo you want to create or update.
    It‚Äôs always <your huggingface username>/<the repo name> If the repo does not exist
    **it will be created automatically**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`--commit-message`: since HF repos are git repositories you need to give a
    commit message.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything worked you should see this at the end of the process (but with
    a different url üòÜ) :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It‚Äôs the link to your model repository. The repository contains a model card
    that explains how to use the model, your Tensorboard logs and your config file.
    **What‚Äôs awesome is that it‚Äôs a git repository, which means you can have different
    commits, update your repository with a new push, open Pull Requests, etc.**
  prefs: []
  type: TYPE_NORMAL
- en: '![ml learn function](../Images/c394875425468d5d1214245cdd809c69.png)'
  prefs: []
  type: TYPE_IMG
- en: 'But now comes the best part: **being able to play with Huggy online üëÄ.**'
  prefs: []
  type: TYPE_NORMAL
- en: Play with your Huggy üêï
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This step is the simplest:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Huggy game in your browser: [https://huggingface.co/spaces/ThomasSimonini/Huggy](https://huggingface.co/spaces/ThomasSimonini/Huggy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Click on Play with my Huggy model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![load-huggy](../Images/9ed3c5a5aa1a1ccd093d892f43f68ac3.png)'
  prefs: []
  type: TYPE_IMG
- en: In step 1, choose your model repository, which is the model id (in my case ThomasSimonini/ppo-Huggy).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In step 2, **choose which model you want to replay**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I have multiple ones, since we saved a model every 500000 timesteps.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But since I want the most recent one, I choose `Huggy.onnx`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: üëâ It‚Äôs good **to try with different models steps to see the improvement of the
    agent.**
  prefs: []
  type: TYPE_NORMAL
- en: Congrats on finishing this bonus unit!
  prefs: []
  type: TYPE_NORMAL
- en: You can now sit and enjoy playing with your Huggy üê∂. And don‚Äôt **forget to spread
    the love by sharing Huggy with your friends ü§ó**. And if you share about it on
    social media, **please tag us @huggingface and me @simoninithomas**
  prefs: []
  type: TYPE_NORMAL
- en: '![Huggy cover](../Images/43d3b16262aca3954e9ac9ccf73b9c3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Keep Learning, Stay awesome ü§ó
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
