# PoolFormer

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/poolformer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/poolformer)

## æ¦‚è¿°

PoolFormeræ¨¡å‹æ˜¯ç”±Sea AI Labsåœ¨[MetaFormer is Actually What You Need for Vision](https://arxiv.org/abs/2111.11418)ä¸­æå‡ºçš„ã€‚è¯¥å·¥ä½œçš„ç›®æ ‡ä¸æ˜¯è®¾è®¡å¤æ‚çš„ä»¤ç‰Œæ··åˆå™¨æ¥å®ç°SOTAæ€§èƒ½ï¼Œè€Œæ˜¯å±•ç¤ºå˜å‹å™¨æ¨¡å‹çš„èƒ½åŠ›ä¸»è¦æºè‡ªé€šç”¨æ¶æ„MetaFormerã€‚

è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š

*å˜å‹å™¨åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚äººä»¬æ™®éè®¤ä¸ºå®ƒä»¬åŸºäºæ³¨æ„åŠ›çš„ä»¤ç‰Œæ··åˆå™¨æ¨¡å—å¯¹å…¶èƒ½åŠ›åšå‡ºäº†æœ€å¤§è´¡çŒ®ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œå˜å‹å™¨ä¸­åŸºäºæ³¨æ„åŠ›çš„æ¨¡å—å¯ä»¥è¢«ç©ºé—´MLPæ›¿ä»£ï¼Œç»“æœæ¨¡å‹ä»ç„¶è¡¨ç°å‡ºè‰²ã€‚åŸºäºè¿™ä¸€è§‚å¯Ÿï¼Œæˆ‘ä»¬å‡è®¾å˜å‹å™¨çš„é€šç”¨æ¶æ„ï¼Œè€Œä¸æ˜¯ç‰¹å®šçš„ä»¤ç‰Œæ··åˆå™¨æ¨¡å—ï¼Œå¯¹æ¨¡å‹çš„æ€§èƒ½æ›´ä¸ºé‡è¦ã€‚ä¸ºäº†éªŒè¯è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æ•…æ„å°†å˜å‹å™¨ä¸­çš„æ³¨æ„åŠ›æ¨¡å—æ›¿æ¢ä¸ºä¸€ä¸ªéå¸¸ç®€å•çš„ç©ºé—´æ± åŒ–è¿ç®—ç¬¦ï¼Œä»…è¿›è¡Œæœ€åŸºæœ¬çš„ä»¤ç‰Œæ··åˆã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°è¡ç”Ÿæ¨¡å‹PoolFormeråœ¨å¤šä¸ªè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸Šå–å¾—äº†ç«äº‰æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨ImageNet-1Kä¸Šï¼ŒPoolFormerå®ç°äº†82.1%çš„top-1å‡†ç¡®ç‡ï¼Œè¶…è¿‡äº†ç»è¿‡è‰¯å¥½è°ƒæ•´çš„è§†è§‰å˜å‹å™¨/ç±»ä¼¼MLPåŸºçº¿DeiT-B/ResMLP-B24çš„0.3%/1.1%å‡†ç¡®ç‡ï¼Œå‚æ•°å‡å°‘äº†35%/52%ï¼ŒMACså‡å°‘äº†48%/60%ã€‚PoolFormerçš„æœ‰æ•ˆæ€§éªŒè¯äº†æˆ‘ä»¬çš„å‡è®¾ï¼Œå¹¶ä¿ƒä½¿æˆ‘ä»¬æå‡ºâ€œMetaFormerâ€æ¦‚å¿µï¼Œè¿™æ˜¯ä»å˜å‹å™¨ä¸­æŠ½è±¡å‡ºæ¥çš„é€šç”¨æ¶æ„ï¼Œè€Œä¸æŒ‡å®šä»¤ç‰Œæ··åˆå™¨ã€‚åŸºäºå¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬è®¤ä¸ºMetaFormeræ˜¯å®ç°æœ€è¿‘å˜å‹å™¨å’Œç±»ä¼¼MLPæ¨¡å‹åœ¨è§†è§‰ä»»åŠ¡ä¸Šå–å¾—ä¼˜è¶Šç»“æœçš„å…³é”®å› ç´ ã€‚è¿™é¡¹å·¥ä½œå‘¼åæœªæ¥æ›´å¤šçš„ç ”ç©¶è‡´åŠ›äºæ”¹è¿›MetaFormerï¼Œè€Œä¸æ˜¯ä¸“æ³¨äºä»¤ç‰Œæ··åˆå™¨æ¨¡å—ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºçš„PoolFormerå¯ä»¥ä½œä¸ºæœªæ¥MetaFormeræ¶æ„è®¾è®¡çš„èµ·ç‚¹åŸºçº¿ã€‚*

ä¸‹å›¾å±•ç¤ºäº†PoolFormerçš„æ¶æ„ã€‚æ‘˜è‡ª[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2111.11418)ã€‚

![](../Images/3034170d23213533d28047793aeaaeed.png)

æ­¤æ¨¡å‹ç”±[heytanay](https://huggingface.co/heytanay)è´¡çŒ®ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/sail-sg/poolformer)æ‰¾åˆ°ã€‚

## ä½¿ç”¨æç¤º

+   PoolFormerå…·æœ‰åˆ†å±‚æ¶æ„ï¼Œå…¶ä¸­å­˜åœ¨ä¸€ä¸ªç®€å•çš„å¹³å‡æ± åŒ–å±‚ï¼Œè€Œä¸æ˜¯æ³¨æ„åŠ›ã€‚æ¨¡å‹çš„æ‰€æœ‰æ£€æŸ¥ç‚¹éƒ½å¯ä»¥åœ¨[hub](https://huggingface.co/models?other=poolformer)ä¸Šæ‰¾åˆ°ã€‚

+   å¯ä»¥ä½¿ç”¨[PoolFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerImageProcessor)æ¥ä¸ºæ¨¡å‹å‡†å¤‡å›¾åƒã€‚

+   ä¸å¤§å¤šæ•°æ¨¡å‹ä¸€æ ·ï¼ŒPoolFormeræœ‰ä¸åŒçš„å¤§å°ï¼Œè¯¦æƒ…å¯ä»¥åœ¨ä¸‹è¡¨ä¸­æ‰¾åˆ°ã€‚

| **æ¨¡å‹å˜ä½“** | **æ·±åº¦** | **éšè—å¤§å°** | **å‚æ•°ï¼ˆç™¾ä¸‡ï¼‰** | **ImageNet-1k Top 1** |
| :-: | --- | --- | :-: | :-: |
| s12 | [2, 2, 6, 2] | [64, 128, 320, 512] | 12 | 77.2 |
| s24 | [4, 4, 12, 4] | [64, 128, 320, 512] | 21 | 80.3 |
| s36 | [6, 6, 18, 6] | [64, 128, 320, 512] | 31 | 81.4 |
| m36 | [6, 6, 18, 6] | [96, 192, 384, 768] | 56 | 82.1 |
| m48 | [8, 8, 24, 8] | [96, 192, 384, 768] | 73 | 82.5 |

## èµ„æº

ä»¥ä¸‹æ˜¯å®˜æ–¹Hugging Faceå’Œç¤¾åŒºèµ„æºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰ï¼Œå¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨PoolFormerã€‚

å›¾åƒåˆ†ç±»

+   [PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)æ”¯æŒã€‚

+   å¦è¯·å‚é˜…ï¼š[å›¾åƒåˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/image_classification)

å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€ä¸€ä¸ªPull Requestï¼Œæˆ‘ä»¬å°†å¯¹å…¶è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥å±•ç¤ºä¸€äº›æ–°çš„ä¸œè¥¿ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚

## PoolFormerConfig

### `class transformers.PoolFormerConfig`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/poolformer/configuration_poolformer.py#L34)

```py
( num_channels = 3 patch_size = 16 stride = 16 pool_size = 3 mlp_ratio = 4.0 depths = [2, 2, 6, 2] hidden_sizes = [64, 128, 320, 512] patch_sizes = [7, 3, 3, 3] strides = [4, 2, 2, 2] padding = [2, 1, 1, 1] num_encoder_blocks = 4 drop_path_rate = 0.0 hidden_act = 'gelu' use_layer_scale = True layer_scale_init_value = 1e-05 initializer_range = 0.02 **kwargs )
```

å‚æ•°

+   `num_channels` (`int`, *å¯é€‰*, é»˜è®¤ä¸º3) â€” è¾“å…¥å›¾åƒä¸­çš„é€šé“æ•°ã€‚

+   `patch_size` (`int`, *å¯é€‰*, é»˜è®¤ä¸º16) â€” è¾“å…¥è¡¥ä¸çš„å¤§å°ã€‚

+   `stride` (`int`, *å¯é€‰*, é»˜è®¤ä¸º16) â€” è¾“å…¥è¡¥ä¸çš„æ­¥å¹…ã€‚

+   `pool_size` (`int`, *å¯é€‰*, é»˜è®¤ä¸º3) â€” æ± åŒ–çª—å£çš„å¤§å°ã€‚

+   `mlp_ratio` (`float`, *å¯é€‰*, é»˜è®¤ä¸º4.0) â€” MLPè¾“å‡ºé€šé“æ•°ä¸è¾“å…¥é€šé“æ•°çš„æ¯”ç‡ã€‚

+   `depths` (`list`, *å¯é€‰*, é»˜è®¤ä¸º`[2, 2, 6, 2]`) â€” æ¯ä¸ªç¼–ç å™¨å—çš„æ·±åº¦ã€‚

+   `hidden_sizes` (`list`, *å¯é€‰*, é»˜è®¤ä¸º`[64, 128, 320, 512]`) â€” æ¯ä¸ªç¼–ç å™¨å—çš„éšè—å¤§å°ã€‚

+   `patch_sizes` (`list`, *å¯é€‰*, é»˜è®¤ä¸º`[7, 3, 3, 3]`) â€” æ¯ä¸ªç¼–ç å™¨å—çš„è¾“å…¥è¡¥ä¸çš„å¤§å°ã€‚

+   `strides` (`list`, *å¯é€‰*, é»˜è®¤ä¸º`[4, 2, 2, 2]`) â€” æ¯ä¸ªç¼–ç å™¨å—çš„è¾“å…¥è¡¥ä¸çš„æ­¥å¹…ã€‚

+   `padding` (`list`, *å¯é€‰*, é»˜è®¤ä¸º`[2, 1, 1, 1]`) â€” æ¯ä¸ªç¼–ç å™¨å—çš„è¾“å…¥è¡¥ä¸çš„å¡«å……ã€‚

+   `num_encoder_blocks` (`int`, *å¯é€‰*, é»˜è®¤ä¸º4) â€” ç¼–ç å™¨å—çš„æ•°é‡ã€‚

+   `drop_path_rate` (`float`, *å¯é€‰*, é»˜è®¤ä¸º0.0) â€” ä¸¢å¼ƒå±‚çš„ä¸¢å¼ƒç‡ã€‚

+   `hidden_act` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`"gelu"`) â€” éšè—å±‚çš„æ¿€æ´»å‡½æ•°ã€‚

+   `use_layer_scale` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`True`) â€” æ˜¯å¦ä½¿ç”¨å±‚æ¯”ä¾‹ã€‚

+   `layer_scale_init_value` (`float`, *å¯é€‰*, é»˜è®¤ä¸º1e-05) â€” å±‚æ¯”ä¾‹çš„åˆå§‹å€¼ã€‚

+   `initializer_range` (`float`, *å¯é€‰*, é»˜è®¤ä¸º0.02) â€” æƒé‡çš„åˆå§‹åŒ–èŒƒå›´ã€‚

è¿™æ˜¯ç”¨äºå­˜å‚¨[PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel)é…ç½®çš„ç±»ã€‚æ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–ä¸€ä¸ªPoolFormeræ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äºPoolFormer [sail/poolformer_s12](https://huggingface.co/sail/poolformer_s12)æ¶æ„çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import PoolFormerConfig, PoolFormerModel

>>> # Initializing a PoolFormer sail/poolformer_s12 style configuration
>>> configuration = PoolFormerConfig()

>>> # Initializing a model (with random weights) from the sail/poolformer_s12 style configuration
>>> model = PoolFormerModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## PoolFormerFeatureExtractor

### `class transformers.PoolFormerFeatureExtractor`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/poolformer/feature_extraction_poolformer.py#L26)

```py
( *args **kwargs )
```

#### `__call__`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)

```py
( images **kwargs )
```

é¢„å¤„ç†ä¸€å¼ å›¾ç‰‡æˆ–ä¸€æ‰¹å›¾ç‰‡ã€‚

## PoolFormerImageProcessor

### `class transformers.PoolFormerImageProcessor`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/poolformer/image_processing_poolformer.py#L49)

```py
( do_resize: bool = True size: Dict = None crop_pct: int = 0.9 resample: Resampling = <Resampling.BICUBIC: 3> do_center_crop: bool = True crop_size: Dict = None rescale_factor: Union = 0.00392156862745098 do_rescale: bool = True do_normalize: bool = True image_mean: Union = None image_std: Union = None **kwargs )
```

å‚æ•°

+   `do_resize` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†å›¾åƒçš„ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰å°ºå¯¸è°ƒæ•´ä¸ºæŒ‡å®šçš„ `size`ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `do_resize` è¦†ç›–ã€‚

+   `size` (`Dict[str, int]` *å¯é€‰*ï¼Œé»˜è®¤ä¸º `{"shortest_edge" -- 224}`)ï¼šè°ƒæ•´å¤§å°åçš„å›¾åƒå¤§å°ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `size` è¦†ç›–ã€‚å¦‚æœæœªè®¾ç½® crop_pctï¼š

    +   size ä¸º `{"height": h, "width": w}`ï¼šå°†å›¾åƒè°ƒæ•´å¤§å°ä¸º `(h, w)`ã€‚

    +   size ä¸º `{"shortest_edge": s}`ï¼šå°†å›¾åƒçš„æœ€çŸ­è¾¹è°ƒæ•´å¤§å°ä¸º sï¼ŒåŒæ—¶ä¿æŒçºµæ¨ªæ¯”ã€‚

    å¦‚æœè®¾ç½®äº† crop_pctï¼š

    +   size ä¸º `{"height": h, "width": w}`ï¼šå°†å›¾åƒè°ƒæ•´å¤§å°ä¸º `(int(floor(h/crop_pct)), int(floor(w/crop_pct)))`

    +   size ä¸º `{"height": c, "width": c}`ï¼šå°†å›¾åƒçš„æœ€çŸ­è¾¹è°ƒæ•´å¤§å°ä¸º `int(floor(c/crop_pct)`ï¼ŒåŒæ—¶ä¿æŒçºµæ¨ªæ¯”ã€‚

    +   size ä¸º `{"shortest_edge": c}`ï¼šå°†å›¾åƒçš„æœ€çŸ­è¾¹è°ƒæ•´å¤§å°ä¸º `int(floor(c/crop_pct)`ï¼ŒåŒæ—¶ä¿æŒçºµæ¨ªæ¯”ã€‚

+   `crop_pct` (`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0.9) â€” ä»ä¸­å¿ƒè£å‰ªå›¾åƒçš„ç™¾åˆ†æ¯”ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `crop_pct` è¦†ç›–ã€‚

+   `resample` (`PILImageResampling`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `Resampling.BICUBIC`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™è¦ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `resample` è¦†ç›–ã€‚

+   `do_center_crop` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œä¸­å¿ƒè£å‰ªã€‚å¦‚æœè¾“å…¥å°ºå¯¸æ²¿ä»»ä¸€è¾¹å°äº `crop_size`ï¼Œåˆ™å›¾åƒå°†å¡«å……ä¸º 0ï¼Œç„¶åè¿›è¡Œä¸­å¿ƒè£å‰ªã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `do_center_crop` è¦†ç›–ã€‚

+   `crop_size` (`Dict[str, int]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `{"height" -- 224, "width": 224}`)ï¼šåº”ç”¨ä¸­å¿ƒè£å‰ªåçš„å›¾åƒå¤§å°ã€‚ä»…åœ¨ `do_center_crop` è®¾ç½®ä¸º `True` æ—¶æœ‰æ•ˆã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `crop_size` å‚æ•°è¦†ç›–ã€‚

+   `rescale_factor` (`int` æˆ– `float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `1/255`) â€” å¦‚æœé‡æ–°ç¼©æ”¾å›¾åƒï¼Œåˆ™ä½¿ç”¨çš„æ¯”ä¾‹å› å­ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `rescale_factor` å‚æ•°è¦†ç›–ã€‚

+   `do_rescale` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`) â€” æ˜¯å¦æŒ‰æŒ‡å®šæ¯”ä¾‹ `rescale_factor` é‡æ–°ç¼©æ”¾å›¾åƒã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `do_rescale` å‚æ•°è¦†ç›–ã€‚

+   `do_normalize` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `True`) â€” æ§åˆ¶æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œæ ‡å‡†åŒ–ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `do_normalize` å‚æ•°è¦†ç›–ã€‚

+   `image_mean` (`float` æˆ– `List[float]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `IMAGENET_STANDARD_MEAN`) â€” å¦‚æœå¯¹å›¾åƒè¿›è¡Œæ ‡å‡†åŒ–ï¼Œåˆ™ä½¿ç”¨çš„å‡å€¼ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_mean` å‚æ•°è¦†ç›–ã€‚

+   `image_std` (`float` æˆ– `List[float]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `IMAGENET_STANDARD_STD`) â€” å¦‚æœå¯¹å›¾åƒè¿›è¡Œæ ‡å‡†åŒ–ï¼Œåˆ™ä½¿ç”¨çš„æ ‡å‡†å·®ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_std` å‚æ•°è¦†ç›–ã€‚

æ„å»ºä¸€ä¸ª PoolFormer å›¾åƒå¤„ç†å™¨ã€‚

#### `preprocess`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/poolformer/image_processing_poolformer.py#L211)

```py
( images: Union do_resize: bool = None size: Dict = None crop_pct: int = None resample: Resampling = None do_center_crop: bool = None crop_size: Dict = None do_rescale: bool = None rescale_factor: float = None do_normalize: bool = None image_mean: Union = None image_std: Union = None return_tensors: Union = None data_format: ChannelDimension = <ChannelDimension.FIRST: 'channels_first'> input_data_format: Union = None **kwargs )
```

å‚æ•°

+   `images` (`ImageInput`) â€” è¦é¢„å¤„ç†çš„å›¾åƒã€‚æœŸæœ›ä¼ å…¥åƒç´ å€¼èŒƒå›´ä¸º 0 åˆ° 255 çš„å•ä¸ªå›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ã€‚å¦‚æœä¼ å…¥åƒç´ å€¼åœ¨ 0 åˆ° 1 ä¹‹é—´çš„å›¾åƒï¼Œè¯·è®¾ç½® `do_rescale=False`ã€‚

+   `do_resize` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.do_resize`) â€” æ˜¯å¦è°ƒæ•´å›¾åƒå¤§å°ã€‚

+   `size` (`Dict[str, int]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.size`) â€” è°ƒæ•´å¤§å°åçš„å›¾åƒå¤§å°ã€‚

+   `crop_pct` (`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.crop_pct`) â€” è¦è£å‰ªçš„å›¾åƒç™¾åˆ†æ¯”ã€‚ä»…åœ¨ `do_resize` è®¾ç½®ä¸º `True` æ—¶æœ‰æ•ˆã€‚

+   `resample` (`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.resample`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™è¦ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚è¿™å¯ä»¥æ˜¯æšä¸¾ `PILImageResampling` ä¸­çš„ä¸€ä¸ªã€‚ä»…å½“ `do_resize` è®¾ç½®ä¸º `True` æ—¶æ‰æœ‰æ•ˆã€‚

+   `do_center_crop` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.do_center_crop`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œä¸­å¿ƒè£å‰ªã€‚

+   `crop_size` (`Dict[str, int]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.crop_size`) â€” åº”ç”¨ä¸­å¿ƒè£å‰ªåçš„å›¾åƒå¤§å°ã€‚

+   `do_rescale` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.do_rescale`) â€” æ˜¯å¦å°†å›¾åƒå€¼é‡æ–°ç¼©æ”¾åœ¨ [0 - 1] ä¹‹é—´ã€‚

+   `rescale_factor` (`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.rescale_factor`) â€” å¦‚æœ `do_rescale` è®¾ç½®ä¸º `True`ï¼Œåˆ™ç”¨äºé‡æ–°ç¼©æ”¾å›¾åƒçš„é‡æ–°ç¼©æ”¾å› å­ã€‚

+   `do_normalize` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.do_normalize`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚

+   `image_mean` (`float` æˆ– `List[float]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.image_mean`) â€” å›¾åƒå‡å€¼ã€‚

+   `image_std` (`float` æˆ– `List[float]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `self.image_std`) â€” å›¾åƒæ ‡å‡†å·®ã€‚

+   `return_tensors` (`str` æˆ– `TensorType`ï¼Œ*å¯é€‰*) â€” è¦è¿”å›çš„å¼ é‡ç±»å‹ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   æœªè®¾ç½®ï¼šè¿”å›ä¸€ä¸ª `np.ndarray` åˆ—è¡¨ã€‚

    +   `TensorType.TENSORFLOW` æˆ– `'tf'`ï¼šè¿”å›ä¸€ä¸ªç±»å‹ä¸º `tf.Tensor` çš„æ‰¹æ¬¡ã€‚

    +   `TensorType.PYTORCH` æˆ– `'pt'`ï¼šè¿”å›ä¸€ä¸ªç±»å‹ä¸º `torch.Tensor` çš„æ‰¹æ¬¡ã€‚

    +   `TensorType.NUMPY` æˆ– `'np'`ï¼šè¿”å›ä¸€ä¸ªç±»å‹ä¸º `np.ndarray` çš„æ‰¹æ¬¡ã€‚

    +   `TensorType.JAX` æˆ– `'jax'`ï¼šè¿”å›ä¸€ä¸ªç±»å‹ä¸º `jax.numpy.ndarray` çš„æ‰¹æ¬¡ã€‚

+   `data_format` (`ChannelDimension` æˆ– `str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `ChannelDimension.FIRST`) â€” è¾“å‡ºå›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `ChannelDimension.FIRST`ï¼šå›¾åƒä»¥ (num_channels, height, width) æ ¼å¼ã€‚

    +   `ChannelDimension.LAST`ï¼šå›¾åƒä»¥ (height, width, num_channels) æ ¼å¼ã€‚

+   `input_data_format` (`ChannelDimension` æˆ– `str`ï¼Œ*å¯é€‰*) â€” è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™ä»è¾“å…¥å›¾åƒä¸­æ¨æ–­é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `"channels_first"` æˆ– `ChannelDimension.FIRST`ï¼šå›¾åƒä»¥ (num_channels, height, width) æ ¼å¼ã€‚

    +   `"channels_last"` æˆ– `ChannelDimension.LAST`ï¼šå›¾åƒä»¥ (height, width, num_channels) æ ¼å¼ã€‚

    +   `"none"` æˆ– `ChannelDimension.NONE`ï¼šå›¾åƒä»¥ (height, width) æ ¼å¼ã€‚

é¢„å¤„ç†å›¾åƒæˆ–ä¸€æ‰¹å›¾åƒã€‚

## PoolFormerModel

### `class transformers.PoolFormerModel`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/poolformer/modeling_poolformer.py#L304)

```py
( config )
```

å‚æ•°

+   `config` ([PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)) â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

è£¸çš„ PoolFormer æ¨¡å‹å˜å‹å™¨ï¼Œè¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚æ­¤æ¨¡å‹æ˜¯ PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/poolformer/modeling_poolformer.py#L321)

```py
( pixel_values: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.BaseModelOutputWithNoAttention or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º `(batch_size, num_channels, height, width)`) â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨ [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor) è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [PoolFormerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

è¿”å›

`transformers.modeling_outputs.BaseModelOutputWithNoAttention` æˆ– `tuple(torch.FloatTensor)`

ä¸€ä¸ª`transformers.modeling_outputs.BaseModelOutputWithNoAttention`æˆ–è€…ä¸€ä¸ª`torch.FloatTensor`çš„å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–è€…å½“`config.return_dict=False`æ—¶ï¼‰åŒ…æ‹¬ä¸åŒçš„å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆ[PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)ï¼‰å’Œè¾“å…¥ã€‚

+   `last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`ï¼‰â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—è¾“å‡ºã€‚

+   `hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’äº†`output_hidden_states=True`æˆ–è€…å½“`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸€ä¸ªç”¨äºåµŒå…¥è¾“å‡ºï¼Œ+ ä¸€ä¸ªç”¨äºæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚

    æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚

[PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, PoolFormerModel
>>> import torch
>>> from datasets import load_dataset

>>> dataset = load_dataset("huggingface/cats-image")
>>> image = dataset["test"]["image"][0]

>>> image_processor = AutoImageProcessor.from_pretrained("sail/poolformer_s12")
>>> model = PoolFormerModel.from_pretrained("sail/poolformer_s12")

>>> inputs = image_processor(image, return_tensors="pt")

>>> with torch.no_grad():
...     outputs = model(**inputs)

>>> last_hidden_states = outputs.last_hidden_state
>>> list(last_hidden_states.shape)
[1, 512, 7, 7]
```

## PoolFormerForImageClassification

### `class transformers.PoolFormerForImageClassification`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/poolformer/modeling_poolformer.py#L369)

```py
( config )
```

å‚æ•°

+   `config`ï¼ˆ[PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)ï¼‰â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

å…·æœ‰å›¾åƒåˆ†ç±»å¤´éƒ¨çš„PoolFormeræ¨¡å‹å˜å‹å™¨

è¿™ä¸ªæ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/poolformer/modeling_poolformer.py#L391)

```py
( pixel_values: Optional = None labels: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.ImageClassifierOutputWithNoAttention or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`ï¼‰â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[PoolFormerImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `labels`ï¼ˆå½¢çŠ¶ä¸º`(batch_size,)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè®¡ç®—å›¾åƒåˆ†ç±»/å›å½’æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[0, ..., config.num_labels - 1]`èŒƒå›´å†…ã€‚å¦‚æœ`config.num_labels == 1`ï¼Œåˆ™è®¡ç®—å›å½’æŸå¤±ï¼ˆå‡æ–¹æŸå¤±ï¼‰ï¼Œå¦‚æœ`config.num_labels > 1`ï¼Œåˆ™è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰ã€‚

è¿”å›

[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)æˆ–è€…`tuple(torch.FloatTensor)`

ä¸€ä¸ª[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)æˆ–è€…ä¸€ä¸ª`torch.FloatTensor`çš„å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–è€…å½“`config.return_dict=False`æ—¶ï¼‰åŒ…æ‹¬ä¸åŒçš„å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆ[PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)ï¼‰å’Œè¾“å…¥ã€‚

+   `loss`ï¼ˆå½¢çŠ¶ä¸º`(1,)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼‰ â€” åˆ†ç±»ï¼ˆå¦‚æœconfig.num_labels==1åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚

+   `logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰ â€” åˆ†ç±»ï¼ˆå¦‚æœconfig.num_labels==1åˆ™ä¸ºå›å½’ï¼‰å¾—åˆ†ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚

+   `hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰ â€” å½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º+æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼‰ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µè¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚

[PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification)çš„å‰å‘æ–¹æ³•è¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

å°½ç®¡å‰å‘ä¼ é€’çš„é…æ–¹éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…åˆ™é»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, PoolFormerForImageClassification
>>> import torch
>>> from datasets import load_dataset

>>> dataset = load_dataset("huggingface/cats-image")
>>> image = dataset["test"]["image"][0]

>>> image_processor = AutoImageProcessor.from_pretrained("sail/poolformer_s12")
>>> model = PoolFormerForImageClassification.from_pretrained("sail/poolformer_s12")

>>> inputs = image_processor(image, return_tensors="pt")

>>> with torch.no_grad():
...     logits = model(**inputs).logits

>>> # model predicts one of the 1000 ImageNet classes
>>> predicted_label = logits.argmax(-1).item()
>>> print(model.config.id2label[predicted_label])
tabby, tabby cat
```
