- en: Kandinsky 2.1
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kandinsky 2.1
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/pipelines/kandinsky](https://huggingface.co/docs/diffusers/api/pipelines/kandinsky)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '原文链接: [https://huggingface.co/docs/diffusers/api/pipelines/kandinsky](https://huggingface.co/docs/diffusers/api/pipelines/kandinsky)'
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Kandinsky 2.1 is created by [Arseniy Shakhmatov](https://github.com/cene555),
    [Anton Razzhigaev](https://github.com/razzant), [Aleksandr Nikolich](https://github.com/AlexWortega),
    [Vladimir Arkhipkin](https://github.com/oriBetelgeuse), [Igor Pavlov](https://github.com/boomb0om),
    [Andrey Kuznetsov](https://github.com/kuznetsoffandrey), and [Denis Dimitrov](https://github.com/denndimitrov).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky 2.1由[Arseniy Shakhmatov](https://github.com/cene555)、[Anton Razzhigaev](https://github.com/razzant)、[Aleksandr
    Nikolich](https://github.com/AlexWortega)、[Vladimir Arkhipkin](https://github.com/oriBetelgeuse)、[Igor
    Pavlov](https://github.com/boomb0om)、[Andrey Kuznetsov](https://github.com/kuznetsoffandrey)和[Denis
    Dimitrov](https://github.com/denndimitrov)创建。
- en: 'The description from it’s GitHub page is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 它在GitHub页面上的描述是：
- en: '*Kandinsky 2.1 inherits best practicies from Dall-E 2 and Latent diffusion,
    while introducing some new ideas. As text and image encoder it uses CLIP model
    and diffusion image prior (mapping) between latent spaces of CLIP modalities.
    This approach increases the visual performance of the model and unveils new horizons
    in blending images and text-guided image manipulation.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*Kandinsky 2.1继承了Dall-E 2和潜在扩散的最佳实践，同时引入了一些新的想法。作为文本和图像编码器，它使用CLIP模型和潜在空间之间的扩散图像先验（映射）。这种方法提高了模型的视觉性能，并揭示了在图像和文本引导的图像操作中开启新的视野。*'
- en: The original codebase can be found at [ai-forever/Kandinsky-2](https://github.com/ai-forever/Kandinsky-2).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 原始代码库可在[ai-forever/Kandinsky-2](https://github.com/ai-forever/Kandinsky-2)找到。
- en: Check out the [Kandinsky Community](https://huggingface.co/kandinsky-community)
    organization on the Hub for the official model checkpoints for tasks like text-to-image,
    image-to-image, and inpainting.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 查看Hub上的[Kandinsky Community](https://huggingface.co/kandinsky-community)组织，获取官方模型检查点，用于文本到图像、图像到图像和修复等任务。
- en: Make sure to check out the Schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保查看调度器的[指南](../../using-diffusers/schedulers)，了解如何探索调度器速度和质量之间的权衡，并查看[跨管道重用组件](../../using-diffusers/loading#reuse-components-across-pipelines)部分，了解如何有效地将相同的组件加载到多个管道中。
- en: KandinskyPriorPipeline
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyPriorPipeline
- en: '### `class diffusers.KandinskyPriorPipeline`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyPriorPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_prior.py#L128)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_prior.py#L128)'
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — 用于从文本嵌入中近似图像嵌入的经典unCLIP先验。'
- en: '`image_encoder` (`CLIPVisionModelWithProjection`) — Frozen image-encoder.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_encoder` (`CLIPVisionModelWithProjection`) — 冻结的图像编码器。'
- en: '`text_encoder` (`CLIPTextModelWithProjection`) — Frozen text-encoder.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` (`CLIPTextModelWithProjection`) — 冻结的文本编码器。'
- en: '`tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`CLIPTokenizer`) — 类[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)的分词器。'
- en: '`scheduler` (`UnCLIPScheduler`) — A scheduler to be used in combination with
    `prior` to generate image embedding.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (`UnCLIPScheduler`) — 与`prior`结合使用的调度器，用于生成图像嵌入。'
- en: Pipeline for generating image prior for Kandinsky
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成Kandinsky图像先验的管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档，了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_prior.py#L397)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_prior.py#L397)'
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str`或`List[str]`) — 用于指导图像生成的提示。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str`或`List[str]`, *optional*) — 不用于指导图像生成的提示。如果不使用指导（即如果`guidance_scale`小于`1`，则忽略）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, 默认为1) — 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 25) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, 默认为25) — 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`或`List[torch.Generator]`, *optional*) — 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预先生成的噪声潜变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，则将使用提供的随机
    `generator` 进行采样生成潜变量张量。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 4.0) — 如 [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)
    中定义的引导比例。`guidance_scale` 定义为 [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)
    中方程式 2 的 `w`。通过设置 `guidance_scale > 1` 来启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`output_type` (`str`, *optional*, defaults to `"pt"`) — The output format of
    the generate image. Choose between: `"np"` (`np.array`) or `"pt"` (`torch.Tensor`).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为 `"pt"`) — 生成图像的输出格式。选择之间: `"np"` (`np.array`)
    或 `"pt"` (`torch.Tensor`)。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    而不是普通元组。'
- en: Returns
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`KandinskyPriorPipelineOutput` or `tuple`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`KandinskyPriorPipelineOutput` 或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道以进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `interpolate`'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `插值`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_prior.py#L172)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_prior.py#L172)'
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`images_and_prompts` (`List[Union[str, PIL.Image.Image, torch.FloatTensor]]`)
    — list of prompts and images to guide the image generation. weights — (`List[float]`):
    list of weights for each condition in `images_and_prompts`'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images_and_prompts` (`List[Union[str, PIL.Image.Image, torch.FloatTensor]]`)
    — 用于引导图像生成的提示和图像列表。权重 — (`List[float]`): `images_and_prompts` 中每个条件的权重列表'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 25) — The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 25) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个 [torch
    生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html) 以使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预先生成的噪声潜变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，则将使用提供的随机
    `generator` 进行采样生成潜变量张量。'
- en: '`negative_prior_prompt` (`str`, *optional*) — The prompt not to guide the prior
    diffusion process. Ignored when not using guidance (i.e., ignored if `guidance_scale`
    is less than `1`).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prior_prompt` (`str`, *可选*) — 不用来引导先前扩散过程的提示。当不使用引导时被忽略（即如果 `guidance_scale`
    小于 `1` 则被忽略）。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt not to guide
    the image generation. Ignored when not using guidance (i.e., ignored if `guidance_scale`
    is less than `1`).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用来引导图像生成的提示。当不使用引导时被忽略（即如果
    `guidance_scale` 小于 `1` 则被忽略）。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 4.0) — 如 [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)
    中定义的引导比例。`guidance_scale` 定义为 [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)
    中方程式 2 的 `w`。通过设置 `guidance_scale > 1` 来启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: Returns
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`KandinskyPriorPipelineOutput` or `tuple`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`KandinskyPriorPipelineOutput` 或 `tuple`'
- en: Function invoked when using the prior pipeline for interpolation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用先前管道进行插值时调用的函数。
- en: 'Examples:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: KandinskyPipeline
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyPipeline
- en: '### `class diffusers.KandinskyPipeline`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky.py#L76)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky.py#L76)'
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_encoder` (`MultilingualCLIP`) — Frozen text-encoder.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` (`MultilingualCLIP`) — 冻结的文本编码器。'
- en: '`tokenizer` (`XLMRobertaTokenizer`) — Tokenizer of class'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`XLMRobertaTokenizer`) — 类的分词器'
- en: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — A scheduler to be used
    in combination with `unet` to generate image latents.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — 用于与 `unet` 结合使用以生成图像潜变量的调度器。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪图像嵌入的条件 U-Net 架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — 用于从潜在空间生成图像的 MoVQ 解码器。'
- en: Pipeline for text-to-image generation using Kandinsky
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用 Kandinsky 进行文本到图像生成的管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky.py#L231)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky.py#L231)'
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`) — 用于指导图像生成的提示或提示。'
- en: '`image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`) — The clip
    image embeddings for text prompt, that will be used to condition the image generation.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) — 用于文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`negative_image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`)
    — The clip image embeddings for negative text prompt, will be used to condition
    the image generation.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) —
    负文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用于指导图像生成的提示或提示。如果不使用指导（即如果
    `guidance_scale` 小于 `1`，则忽略）。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为 512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为 512) — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 4.0) — 在 [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)
    中定义的指导比例。`guidance_scale` 定义为 [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)
    中方程式 2 的 `w`。通过设置 `guidance_scale > 1` 来启用指导比例。更高的指导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个 [torch
    生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预先生成的噪声潜在空间，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示微调相同生成。如果未提供，则将使用提供的随机
    `generator` 进行采样生成潜在空间张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为 `"pil"`) — 生成图像的输出格式。可选择 `"pil"` (`PIL.Image.Image`)、`"np"`
    (`np.array`) 或 `"pt"` (`torch.Tensor`)。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *可选*) — 在推理过程中每隔 `callback_steps` 步调用的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *可选*, 默认为 1) — 调用 `callback` 函数的频率。如果未指定，则在每一步都会调用回调函数。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    而不是普通元组。'
- en: Returns
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: KandinskyCombinedPipeline
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyCombinedPipeline
- en: '### `class diffusers.KandinskyCombinedPipeline`'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyCombinedPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L113)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L113)'
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_encoder` (`MultilingualCLIP`) — Frozen text-encoder.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` (`MultilingualCLIP`) — 冻结的文本编码器。'
- en: '`tokenizer` (`XLMRobertaTokenizer`) — Tokenizer of class'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`XLMRobertaTokenizer`) — 类的分词器'
- en: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — A scheduler to be used
    in combination with `unet` to generate image latents.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — 用于与 `unet` 结合使用以生成图像潜变量的调度器。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于降噪图像嵌入的条件 U-Net 架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ 解码器，用于从潜变量生成图像。'
- en: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — 用于近似从文本嵌入到图像嵌入的经典 unCLIP 先验。'
- en: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — Frozen image-encoder.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — 冻结的图像编码器。'
- en: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — Frozen text-encoder.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — 冻结的文本编码器。'
- en: '`prior_tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_tokenizer` (`CLIPTokenizer`) — 类的分词器 [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)。'
- en: '`prior_scheduler` (`UnCLIPScheduler`) — A scheduler to be used in combination
    with `prior` to generate image embedding.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_scheduler` (`UnCLIPScheduler`) — 用于与 `prior` 结合使用以生成图像嵌入的调度器。'
- en: Combined Pipeline for text-to-image generation using Kandinsky
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kandinsky 进行文本到图像生成的组合管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L214)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L214)'
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`) — 用于引导图像生成的提示或多个提示。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用于引导图像生成的提示或多个提示。如果不使用引导（即如果
    `guidance_scale` 小于 `1`，则忽略）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*，默认为 1) — 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*，默认为 100) — 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*，默认为 512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*，默认为 512) — 生成图像的像素宽度。'
- en: '`prior_guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale
    as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_guidance_scale` (`float`, *可选*，默认为 4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。
    `guidance_scale` 定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式 2
    的 `w`。 通过设置 `guidance_scale > 1` 来启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以牺牲图像质量为代价。'
- en: '`prior_num_inference_steps` (`int`, *optional*, defaults to 100) — The number
    of denoising steps. More denoising steps usually lead to a higher quality image
    at the expense of slower inference.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_num_inference_steps` (`int`, *可选*，默认为 100) — 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*，默认为 4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。
    `guidance_scale` 定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式 2
    的 `w`。 通过设置 `guidance_scale > 1` 来启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以牺牲图像质量为代价。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`（`torch.Generator`或`List[torch.Generator]`，*可选*）— 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents`（`torch.FloatTensor`，*可选*）— 预生成的嘈杂潜变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示调整相同生成。如果未提供，将使用提供的随机`generator`进行采样生成潜变量张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type`（`str`，*可选*，默认为`"pil"`）— 生成图像的输出格式。可选择："pil"（`PIL.Image.Image`）、"np"（`np.array`）或"pt"（`torch.Tensor`）。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback`（`Callable`，*可选*）— 在推断过程中每`callback_steps`步调用的函数。该函数使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps`（`int`，*可选*，默认为1）— 调用`callback`函数的频率。如果未指定，则在每个步骤时调用回调。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。'
- en: Returns
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)或`tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `enable_sequential_cpu_offload`'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_sequential_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L195)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[<源代码>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L195)'
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Offloads all models (`unet`, `text_encoder`, `vae`, and `safety checker` state
    dicts) to CPU using 🤗 Accelerate, significantly reducing memory usage. Models
    are moved to a `torch.device('meta')` and loaded on a GPU only when their specific
    submodule’s `forward` method is called. Offloading happens on a submodule basis.
    Memory savings are higher than using `enable_model_cpu_offload`, but performance
    is lower.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用🤗 Accelerate将所有模型（`unet`、`text_encoder`、`vae`和`safety checker`状态字典）转移到CPU，显著减少内存使用。模型移至`torch.device('meta')`，仅在调用其特定子模块的`forward`方法时才加载到GPU。卸载是基于子模块的。内存节省高于使用`enable_model_cpu_offload`，但性能较低。
- en: KandinskyImg2ImgPipeline
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyImg2ImgPipeline
- en: '### `class diffusers.KandinskyImg2ImgPipeline`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyImg2ImgPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_img2img.py#L98)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[<源代码>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_img2img.py#L98)'
- en: '[PRE12]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_encoder` (`MultilingualCLIP`) — Frozen text-encoder.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`（`MultilingualCLIP`）— 冻结的文本编码器。'
- en: '`tokenizer` (`XLMRobertaTokenizer`) — Tokenizer of class'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（`XLMRobertaTokenizer`）— 类的分词器'
- en: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — A scheduler to be used in combination with `unet` to generate image latents.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`（[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)）—
    用于与`unet`结合使用以生成图像潜变量的调度器。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`（[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)）—
    用于去噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ image encoder and decoder'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq`（[VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel)）—
    MoVQ图像编码器和解码器'
- en: Pipeline for image-to-image generation using Kandinsky
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Kandinsky的图像到图像生成管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以获取库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_img2img.py#L293)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[<源代码>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_img2img.py#L293)'
- en: '[PRE13]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`（`str`或`List[str]`）— 用于引导图像生成的提示或提示。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`) — `Image`, or tensor representing
    an image batch, that will be used as the starting point for the process.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`（`torch.FloatTensor`，`PIL.Image.Image`）— `Image`，或表示图像批次的张量，将用作过程的起始点。'
- en: '`image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`) — The clip
    image embeddings for text prompt, that will be used to condition the image generation.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds`（`torch.FloatTensor`或`List[torch.FloatTensor]`）— 用于文本提示的剪辑图像嵌入，将用于条件图像生成。'
- en: '`negative_image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`)
    — The clip image embeddings for negative text prompt, will be used to condition
    the image generation.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) —
    用于负文本提示的clip图像嵌入，将用于条件图像生成。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *optional*) — 不用于指导图像生成的提示或提示。如果不使用指导（即如果
    `guidance_scale` 小于 `1`），则忽略。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *optional*, 默认为512) — 生成图像的高度（像素）。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *optional*, 默认为512) — 生成图像的宽度（像素）。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*, 默认为100) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`strength` (`float`, *optional*, defaults to 0.3) — Conceptually, indicates
    how much to transform the reference `image`. Must be between 0 and 1\. `image`
    will be used as a starting point, adding more noise to it the larger the `strength`.
    The number of denoising steps depends on the amount of noise initially added.
    When `strength` is 1, added noise will be maximum and the denoising process will
    run for the full number of iterations specified in `num_inference_steps`. A value
    of 1, therefore, essentially ignores `image`.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength` (`float`, *optional*, 默认为0.3) — 在概念上，指示要转换参考`image`的程度。必须在0和1之间。`image`将被用作起点，添加的噪音越多，`strength`越大。去噪步骤的数量取决于最初添加的噪音量。当
    `strength` 为1 时，添加的噪音将最大化，去噪过程将运行指定的 `num_inference_steps` 的全部迭代次数。因此，值为1 的情况下，基本上忽略了
    `image`。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*, 默认为4.0) — 在[Classifier-Free Diffusion
    Guidance](https://arxiv.org/abs/2207.12598)中定义的指导比例。`guidance_scale` 在[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)的方程式2中定义为`w`。通过设置 `guidance_scale
    > 1` 来启用指导比例。更高的指导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *optional*, 默认为1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *optional*) — 一个或多个用于使生成过程确定性的[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *optional*, 默认为`"pil"`) — 生成图像的输出格式。可选择："pil" (`PIL.Image.Image`)、"np"
    (`np.array`) 或 "pt" (`torch.Tensor`)。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *optional*) — 在推理过程中每隔 `callback_steps` 步调用的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *optional*, 默认为1) — 调用 `callback` 函数的频率。如果未指定，将在每一步调用回调函数。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*, 默认为`True`) — 是否返回一个[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是一个普通的元组。'
- en: Returns
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE14]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: KandinskyImg2ImgCombinedPipeline
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyImg2ImgCombinedPipeline
- en: '### `class diffusers.KandinskyImg2ImgCombinedPipeline`'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyImg2ImgCombinedPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L330)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L330)'
- en: '[PRE15]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_encoder` (`MultilingualCLIP`) — Frozen text-encoder.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` (`MultilingualCLIP`) — 冻结的文本编码器。'
- en: '`tokenizer` (`XLMRobertaTokenizer`) — Tokenizer of class'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`XLMRobertaTokenizer`) — 类的分词器'
- en: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — A scheduler to be used
    in combination with `unet` to generate image latents.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — 与 `unet` 结合使用的调度器，用于生成图像潜在空间。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于去噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — 用于从潜在空间生成图像的MoVQ解码器。'
- en: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_prior`（[PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer)）—用于近似从文本嵌入到图像嵌入的规范化unCLIP先验。'
- en: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — Frozen image-encoder.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_image_encoder`（`CLIPVisionModelWithProjection`）—冻结的图像编码器。'
- en: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — Frozen text-encoder.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_text_encoder`（`CLIPTextModelWithProjection`）—冻结的文本编码器。'
- en: '`prior_tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_tokenizer`（`CLIPTokenizer`）—类[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)的分词器。'
- en: '`prior_scheduler` (`UnCLIPScheduler`) — A scheduler to be used in combination
    with `prior` to generate image embedding.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_scheduler`（`UnCLIPScheduler`）—用于与`prior`结合使用以生成图像嵌入的调度器。'
- en: Combined Pipeline for image-to-image generation using Kandinsky
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kandinsky进行图像到图像生成的组合管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。检查超类文档以了解库为所有管道实现的通用方法（例如下载或保存，运行在特定设备上等）。
- en: '#### `__call__`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L432)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L432)'
- en: '[PRE16]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`（`str`或`List[str]`）—用于指导图像生成的提示或提示。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image`, or tensor representing
    an image batch, that will be used as the starting point for the process. Can also
    accept image latents as `image`, if passing latents directly, it will not be encoded
    again.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`（`torch.FloatTensor`，`PIL.Image.Image`，`np.ndarray`，`List[torch.FloatTensor]`，`List[PIL.Image.Image]`或`List[np.ndarray]`）—将用作过程起点的`Image`或表示图像批次的张量。如果直接传递潜在值，则不会再次编码。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt`（`str`或`List[str]`，*可选*）—不用于指导图像生成的提示或提示。当不使用引导时（即，如果`guidance_scale`小于`1`，则忽略）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt`（`int`，*可选*，默认为1）—每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps`（`int`，*可选*，默认为100）—去噪步骤的数量。更多的去噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height`（`int`，*可选*，默认为512）—生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width`（`int`，*可选*，默认为512）—生成图像的像素宽度。'
- en: '`strength` (`float`, *optional*, defaults to 0.3) — Conceptually, indicates
    how much to transform the reference `image`. Must be between 0 and 1\. `image`
    will be used as a starting point, adding more noise to it the larger the `strength`.
    The number of denoising steps depends on the amount of noise initially added.
    When `strength` is 1, added noise will be maximum and the denoising process will
    run for the full number of iterations specified in `num_inference_steps`. A value
    of 1, therefore, essentially ignores `image`.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strength`（`float`，*可选*，默认为0.3）—在概念上，指示要转换参考`image`的程度。必须介于0和1之间。`image`将被用作起点，添加更多的噪音，`strength`越大。去噪步骤的数量取决于最初添加的噪音量。当`strength`为1时，添加的噪音将是最大的，并且去噪过程将运行指定的`num_inference_steps`的完整迭代次数。因此，值为1基本上忽略了`image`。'
- en: '`prior_guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale
    as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_guidance_scale`（`float`，*可选*，默认为4.0）—在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`被定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式2的`w`。通过设置`guidance_scale > 1`来启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`prior_num_inference_steps` (`int`, *optional*, defaults to 100) — The number
    of denoising steps. More denoising steps usually lead to a higher quality image
    at the expense of slower inference.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_num_inference_steps`（`int`，*可选*，默认为100）—去噪步骤的数量。更多的去噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale`（`float`，*可选*，默认为4.0）—在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`被定义为[Imagen
    Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式2的`w`。通过设置`guidance_scale > 1`来启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`（`torch.Generator`或`List[torch.Generator]`，*可选*）— 一个或多个[torch生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)用于使生成具有确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents`（`torch.FloatTensor`，*可选*）— 预生成的噪声潜变量，从高斯分布中采样，用作图像生成的输入。可用于使用不同提示微调相同的生成。如果未提供，将使用提供的随机`generator`进行采样生成潜变量张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type`（`str`，*可选*，默认为`"pil"`）— 生成图像的输出格式。选择`"pil"`（`PIL.Image.Image`），`"np"`（`np.array`）或`"pt"`（`torch.Tensor`）之间。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback`（`Callable`，*可选*）— 每`callback_steps`步在推断期间调用的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps`（`int`，*可选*，默认为1）— 调用`callback`函数的频率。如果未指定，将在每一步调用回调。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*，默认为`True`）— 是否返回[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)而不是普通元组。'
- en: Returns
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)或`tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用管道进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE17]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#### `enable_sequential_cpu_offload`'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_sequential_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L412)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L412)'
- en: '[PRE18]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Offloads all models to CPU using accelerate, significantly reducing memory usage.
    When called, unet, text_encoder, vae and safety checker have their state dicts
    saved to CPU and then are moved to a `torch.device('meta') and loaded to GPU only
    when their specific submodule has its` forward`method called. Note that offloading
    happens on a submodule basis. Memory savings are higher than with`enable_model_cpu_offload`,
    but performance is lower.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速将所有模型转移到CPU，显着减少内存使用。调用时，unet、text_encoder、vae和safety checker的状态字典将保存到CPU，然后移动到`torch.device('meta')，仅在它们的特定子模块调用其`forward`方法时才加载到GPU。请注意，卸载是基于子模块的。内存节省高于`enable_model_cpu_offload`，但性能较低。
- en: KandinskyInpaintPipeline
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyInpaintPipeline
- en: '### `class diffusers.KandinskyInpaintPipeline`'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyInpaintPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_inpaint.py#L240)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_inpaint.py#L240)'
- en: '[PRE19]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_encoder` (`MultilingualCLIP`) — Frozen text-encoder.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`（`MultilingualCLIP`）— 冻结的文本编码器。'
- en: '`tokenizer` (`XLMRobertaTokenizer`) — Tokenizer of class'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（`XLMRobertaTokenizer`）— 类的分词器'
- en: '`scheduler` ([DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler))
    — A scheduler to be used in combination with `unet` to generate image latents.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler`（[DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler)）—
    用于与`unet`结合使用以生成图像潜变量的调度器。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet`（[UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)）—
    用于去噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ image encoder and decoder'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq`（[VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel)）—
    MoVQ图像编码器和解码器'
- en: Pipeline for text-guided image inpainting using Kandinsky2.1
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kandinsky2.1进行文本引导图像修复的管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。检查超类文档以了解库为所有管道实现的通用方法（例如下载或保存，运行在特定设备上等）。
- en: '#### `__call__`'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_inpaint.py#L396)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_inpaint.py#L396)'
- en: '[PRE20]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`（`str`或`List[str]`）— 用于引导图像生成的提示或提示。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image` or `np.ndarray`) — `Image`,
    or tensor representing an image batch, that will be used as the starting point
    for the process.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`（`torch.FloatTensor`，`PIL.Image.Image`或`np.ndarray`）— `Image`，或表示图像批次的张量，将用作过程的起始点。'
- en: '`mask_image` (`PIL.Image.Image`,`torch.FloatTensor` or `np.ndarray`) — `Image`,
    or a tensor representing an image batch, to mask `image`. White pixels in the
    mask will be repainted, while black pixels will be preserved. You can pass a pytorch
    tensor as mask only if the image you passed is a pytorch tensor, and it should
    contain one color channel (L) instead of 3, so the expected shape would be either
    `(B, 1, H, W,)`, `(B, H, W)`, `(1, H, W)` or `(H, W)` If image is an PIL image
    or numpy array, mask should also be a either PIL image or numpy array. If it is
    a PIL image, it will be converted to a single channel (luminance) before use.
    If it is a nummpy array, the expected shape is `(H, W)`.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_image` (`PIL.Image.Image`,`torch.FloatTensor` 或 `np.ndarray`) — `Image`，或表示图像批次的张量，用于遮罩
    `image`。遮罩中的白色像素将被重新绘制，而黑色像素将被保留。只有当传递的图像是 pytorch 张量时，才能将 pytorch 张量作为遮罩传递，它应该包含一个颜色通道（L）而不是
    3，因此预期的形状应为 `(B, 1, H, W,)`、`(B, H, W)`、`(1, H, W)` 或 `(H, W)`。如果图像是 PIL 图像或 numpy
    数组，则遮罩也应该是 PIL 图像或 numpy 数组。如果是 PIL 图像，它将在使用之前转换为单通道（亮度）。如果是 numpy 数组，则预期形状为 `(H,
    W)`。'
- en: '`image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`) — The clip
    image embeddings for text prompt, that will be used to condition the image generation.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) — 用于文本提示的
    clip 图像嵌入，将用于条件图像生成。'
- en: '`negative_image_embeds` (`torch.FloatTensor` or `List[torch.FloatTensor]`)
    — The clip image embeddings for negative text prompt, will be used to condition
    the image generation.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_image_embeds` (`torch.FloatTensor` 或 `List[torch.FloatTensor]`) —
    用于负面文本提示的 clip 图像嵌入，将用于条件图像生成。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用来引导图像生成的提示或提示。当不使用引导时被忽略（即如果
    `guidance_scale` 小于 `1` 则被忽略）。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为 512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为 512) — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为 100) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`
    定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式 2 的 `w`。通过设置 `guidance_scale
    > 1` 来启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为 1) — 每个提示生成的图像数量。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个[torch
    生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html)，用于使生成过程确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预先生成的嘈杂潜变量，从高斯分布中采样，用作图像生成的输入。可以用来使用不同提示调整相同生成。如果未提供，则将使用随机
    `generator` 采样生成潜变量张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为 `"pil"`) — 生成图像的输出格式。可选择 `"pil"` (`PIL.Image.Image`)、`"np"`
    (`np.array`) 或 `"pt"` (`torch.Tensor`)。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *可选*) — 在推理过程中每 `callback_steps` 步调用的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *可选*, 默认为 1) — 调用 `callback` 函数的频率。如果未指定，将在每一步调用回调函数。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    而不是普通元组。'
- en: Returns
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE21]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: KandinskyInpaintCombinedPipeline
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KandinskyInpaintCombinedPipeline
- en: '### `class diffusers.KandinskyInpaintCombinedPipeline`'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.KandinskyInpaintCombinedPipeline`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L570)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L570)'
- en: '[PRE22]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text_encoder` (`MultilingualCLIP`) — Frozen text-encoder.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder` (`MultilingualCLIP`) — 冻结的文本编码器。'
- en: '`tokenizer` (`XLMRobertaTokenizer`) — Tokenizer of class'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer` (`XLMRobertaTokenizer`) — 类的分词器'
- en: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — A scheduler to be used
    in combination with `unet` to generate image latents.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheduler` (Union[`DDIMScheduler`,`DDPMScheduler`]) — 用于与`unet`结合使用以生成图像潜在的调度器。'
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — Conditional U-Net architecture to denoise the image embedding.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    — 用于降噪图像嵌入的条件U-Net架构。'
- en: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — MoVQ Decoder to generate the image from the latents.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movq` ([VQModel](/docs/diffusers/v0.26.3/en/api/models/vq#diffusers.VQModel))
    — 用于从潜在图像生成图像的MoVQ解码器。'
- en: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — The canonincal unCLIP prior to approximate the image embedding from the text
    embedding.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_prior` ([PriorTransformer](/docs/diffusers/v0.26.3/en/api/models/prior_transformer#diffusers.PriorTransformer))
    — 用于从文本嵌入中近似生成图像嵌入的标准unCLIP先验。'
- en: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — Frozen image-encoder.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_image_encoder` (`CLIPVisionModelWithProjection`) — 冻结的图像编码器。'
- en: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — Frozen text-encoder.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_text_encoder` (`CLIPTextModelWithProjection`) — 冻结的文本编码器。'
- en: '`prior_tokenizer` (`CLIPTokenizer`) — Tokenizer of class [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_tokenizer` (`CLIPTokenizer`) — 类[CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer)的分词器。'
- en: '`prior_scheduler` (`UnCLIPScheduler`) — A scheduler to be used in combination
    with `prior` to generate image embedding.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_scheduler` (`UnCLIPScheduler`) — 用于与`prior`结合使用以生成图像嵌入的调度器。'
- en: Combined Pipeline for generation using Kandinsky
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kandinsky进行生成的组合管道
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods the library implements
    for all the pipelines (such as downloading or saving, running on a particular
    device, etc.)
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)。查看超类文档以了解库为所有管道实现的通用方法（如下载或保存、在特定设备上运行等）。
- en: '#### `__call__`'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L672)'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L672)'
- en: '[PRE23]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str` or `List[str]`) — The prompt or prompts to guide the image
    generation.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str` 或 `List[str]`) — 用于指导图像生成的提示或多个提示。'
- en: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, or `List[np.ndarray]`) — `Image`, or tensor representing
    an image batch, that will be used as the starting point for the process. Can also
    accept image latents as `image`, if passing latents directly, it will not be encoded
    again.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`,
    `List[PIL.Image.Image]`, 或 `List[np.ndarray]`) — 用作过程起点的`Image`或表示图像批次的张量。如果直接传递潜在图像，则不会再次编码。'
- en: '`mask_image` (`np.array`) — Tensor representing an image batch, to mask `image`.
    White pixels in the mask will be repainted, while black pixels will be preserved.
    If `mask_image` is a PIL image, it will be converted to a single channel (luminance)
    before use. If it’s a tensor, it should contain one color channel (L) instead
    of 3, so the expected shape would be `(B, H, W, 1)`.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_image` (`np.array`) — 表示图像批次的张量，用于遮罩`image`。遮罩中的白色像素将被重新绘制，而黑色像素将被保留。如果`mask_image`是PIL图像，则在使用之前将其转换为单通道（亮度）。如果它是张量，则应该包含一个颜色通道（L）而不是3个，因此预期形状将是`(B,
    H, W, 1)`。'
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) — The prompt or prompts
    not to guide the image generation. Ignored when not using guidance (i.e., ignored
    if `guidance_scale` is less than `1`).'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str` 或 `List[str]`, *可选*) — 不用于指导图像生成的提示或多个提示。如果不使用引导（即如果`guidance_scale`小于`1`，则忽略）。'
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) — The number of
    images to generate per prompt.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_images_per_prompt` (`int`, *可选*, 默认为1) — 每个提示生成的图像数量。'
- en: '`num_inference_steps` (`int`, *optional*, defaults to 100) — The number of
    denoising steps. More denoising steps usually lead to a higher quality image at
    the expense of slower inference.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*, 默认为100) — 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`height` (`int`, *optional*, defaults to 512) — The height in pixels of the
    generated image.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *可选*, 默认为512) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*, defaults to 512) — The width in pixels of the generated
    image.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *可选*, 默认为512) — 生成图像的像素宽度。'
- en: '`prior_guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale
    as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_guidance_scale` (`float`, *可选*, 默认为4.0) — 如[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`
    在[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)的方程式2中定义为`w`。通过设置`guidance_scale
    > 1`来启用引导比例。更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`prior_num_inference_steps` (`int`, *optional*, defaults to 100) — The number
    of denoising steps. More denoising steps usually lead to a higher quality image
    at the expense of slower inference.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior_num_inference_steps` (`int`, *可选*, 默认为100) — 降噪步骤的数量。更多的降噪步骤通常会导致图像质量更高，但推理速度较慢。'
- en: '`guidance_scale` (`float`, *optional*, defaults to 4.0) — Guidance scale as
    defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
    `guidance_scale` is defined as `w` of equation 2\. of [Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf).
    Guidance scale is enabled by setting `guidance_scale > 1`. Higher guidance scale
    encourages to generate images that are closely linked to the text `prompt`, usually
    at the expense of lower image quality.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*, 默认为 4.0) — 在[无分类器扩散引导](https://arxiv.org/abs/2207.12598)中定义的引导比例。`guidance_scale`
    定义为[Imagen Paper](https://arxiv.org/pdf/2205.11487.pdf)中方程式 2 的 `w`。通过设置 `guidance_scale
    > 1` 启用引导比例。更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) — One
    or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator` 或 `List[torch.Generator]`, *可选*) — 一个或多个 [torch
    生成器](https://pytorch.org/docs/stable/generated/torch.Generator.html) 以使生成具有确定性。'
- en: '`latents` (`torch.FloatTensor`, *optional*) — Pre-generated noisy latents,
    sampled from a Gaussian distribution, to be used as inputs for image generation.
    Can be used to tweak the same generation with different prompts. If not provided,
    a latents tensor will ge generated by sampling using the supplied random `generator`.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`latents` (`torch.FloatTensor`, *可选*) — 预先生成的噪声潜变量，从高斯分布中采样，用作图像生成的输入。可以用来使用不同提示微调相同的生成。如果未提供，则将使用提供的随机
    `generator` 进行采样生成潜变量张量。'
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) — The output format
    of the generate image. Choose between: `"pil"` (`PIL.Image.Image`), `"np"` (`np.array`)
    or `"pt"` (`torch.Tensor`).'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_type` (`str`, *可选*, 默认为 `"pil"`) — 生成图像的输出格式。可选择：`"pil"` (`PIL.Image.Image`)、`"np"`
    (`np.array`) 或 `"pt"` (`torch.Tensor`)。'
- en: '`callback` (`Callable`, *optional*) — A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` (`Callable`, *可选*) — 在推理过程中每隔 `callback_steps` 步调用一次的函数。该函数将使用以下参数调用：`callback(step:
    int, timestep: int, latents: torch.FloatTensor)`。'
- en: '`callback_steps` (`int`, *optional*, defaults to 1) — The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_steps` (`int`, *可选*, 默认为 1) — 调用 `callback` 函数的频率。如果未指定，则在每一步调用回调。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    instead of a plain tuple.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为 `True`) — 是否返回 [ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    而不是普通的元组。'
- en: Returns
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    or `tuple`'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImagePipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_unclip#diffusers.ImagePipelineOutput)
    或 `tuple`'
- en: Function invoked when calling the pipeline for generation.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 调用管道进行生成时调用的函数。
- en: 'Examples:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE24]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '#### `enable_sequential_cpu_offload`'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `enable_sequential_cpu_offload`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L652)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py#L652)'
- en: '[PRE25]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Offloads all models to CPU using accelerate, significantly reducing memory usage.
    When called, unet, text_encoder, vae and safety checker have their state dicts
    saved to CPU and then are moved to a `torch.device('meta') and loaded to GPU only
    when their specific submodule has its` forward`method called. Note that offloading
    happens on a submodule basis. Memory savings are higher than with`enable_model_cpu_offload`,
    but performance is lower.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速器将所有模型转移到 CPU，显著减少内存使用。调用时，unet、text_encoder、vae 和安全检查器的状态字典将保存到 CPU，然后移动到
    `torch.device('meta')`，仅在它们的特定子模块调用`forward`方法时才加载到 GPU。请注意，卸载是基于子模块的。与`enable_model_cpu_offload`相比，内存节省更高，但性能较低。
