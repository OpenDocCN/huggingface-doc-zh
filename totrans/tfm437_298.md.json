["```py\n>>> from transformers import VitMatteConfig, VitMatteForImageMatting\n\n>>> # Initializing a ViTMatte hustvl/vitmatte-small-composition-1k style configuration\n>>> configuration = VitMatteConfig()\n\n>>> # Initializing a model (with random weights) from the hustvl/vitmatte-small-composition-1k style configuration\n>>> model = VitMatteForImageMatting(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import VitMatteImageProcessor, VitMatteForImageMatting\n>>> import torch\n>>> from PIL import Image\n>>> from huggingface_hub import hf_hub_download\n\n>>> processor = VitMatteImageProcessor.from_pretrained(\"hustvl/vitmatte-small-composition-1k\")\n>>> model = VitMatteForImageMatting.from_pretrained(\"hustvl/vitmatte-small-composition-1k\")\n\n>>> filepath = hf_hub_download(\n...     repo_id=\"hf-internal-testing/image-matting-fixtures\", filename=\"image.png\", repo_type=\"dataset\"\n... )\n>>> image = Image.open(filepath).convert(\"RGB\")\n>>> filepath = hf_hub_download(\n...     repo_id=\"hf-internal-testing/image-matting-fixtures\", filename=\"trimap.png\", repo_type=\"dataset\"\n... )\n>>> trimap = Image.open(filepath).convert(\"L\")\n\n>>> # prepare image + trimap for the model\n>>> inputs = processor(images=image, trimaps=trimap, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     alphas = model(**inputs).alphas\n>>> print(alphas.shape)\ntorch.Size([1, 1, 640, 960])\n```"]