- en: Quicktour
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速入门
- en: 'Original text: [https://huggingface.co/docs/diffusers/quicktour](https://huggingface.co/docs/diffusers/quicktour)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/diffusers/quicktour](https://huggingface.co/docs/diffusers/quicktour)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Diffusion models are trained to denoise random Gaussian noise step-by-step to
    generate a sample of interest, such as an image or audio. This has sparked a tremendous
    amount of interest in generative AI, and you have probably seen examples of diffusion
    generated images on the internet. 🧨 Diffusers is a library aimed at making diffusion
    models widely accessible to everyone.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散模型被训练为逐步去噪随机高斯噪声，以生成感兴趣的样本，如图像或音频。这引发了对生成式人工智能的极大兴趣，您可能在互联网上看到过扩散生成的图像示例。🧨
    Diffusers 是一个旨在使扩散模型普遍可访问的库。
- en: 'Whether you’re a developer or an everyday user, this quicktour will introduce
    you to 🧨 Diffusers and help you get up and generating quickly! There are three
    main components of the library to know about:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是开发人员还是日常用户，这个快速入门将向您介绍 🧨 Diffusers 并帮助您快速上手生成！了解该库的三个主要组件：
- en: The [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    is a high-level end-to-end class designed to rapidly generate samples from pretrained
    diffusion models for inference.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    是一个高级端到端类，旨在快速从预训练的扩散模型中生成样本以进行推断。'
- en: Popular pretrained [model](./api/models) architectures and modules that can
    be used as building blocks for creating diffusion systems.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流行的预训练 [模型](./api/models) 架构和模块可用作创建扩散系统的构建块。
- en: Many different [schedulers](./api/schedulers/overview) - algorithms that control
    how noise is added for training, and how to generate denoised images during inference.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多不同的 [调度程序](./api/schedulers/overview) - 控制训练时如何添加噪声以及推断时如何生成去噪图像的算法。
- en: The quicktour will show you how to use the [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    for inference, and then walk you through how to combine a model and scheduler
    to replicate what’s happening inside the [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 快速入门将向您展示如何使用 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    进行推断，然后指导您如何组合模型和调度程序以复制 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    内部发生的情况。
- en: The quicktour is a simplified version of the introductory 🧨 Diffusers [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb)
    to help you get started quickly. If you want to learn more about 🧨 Diffusers’
    goal, design philosophy, and additional details about its core API, check out
    the notebook!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 快速入门是简化的 🧨 Diffusers 入门笔记本，帮助您快速入门。如果您想了解更多关于 🧨 Diffusers 的目标、设计理念以及有关其核心 API
    的其他详细信息，请查看笔记本！
- en: 'Before you begin, make sure you have all the necessary libraries installed:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保已安装所有必要的库：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[🤗 Accelerate](https://huggingface.co/docs/accelerate/index) speeds up model
    loading for inference and training.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[🤗 Accelerate](https://huggingface.co/docs/accelerate/index) 可加快模型加载的速度，用于推断和训练。'
- en: '[🤗 Transformers](https://huggingface.co/docs/transformers/index) is required
    to run the most popular diffusion models, such as [Stable Diffusion](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要运行最受欢迎的扩散模型，如 [稳定扩散](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview)，需要
    [🤗 Transformers](https://huggingface.co/docs/transformers/index)。
- en: DiffusionPipeline
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DiffusionPipeline
- en: The [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    is the easiest way to use a pretrained diffusion system for inference. It is an
    end-to-end system containing the model and the scheduler. You can use the [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    out-of-the-box for many tasks. Take a look at the table below for some supported
    tasks, and for a complete list of supported tasks, check out the [🧨 Diffusers
    Summary](./api/pipelines/overview#diffusers-summary) table.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    是使用预训练扩散系统进行推断的最简单方式。它是一个包含模型和调度程序的端到端系统。您可以直接使用 [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    来执行许多任务。查看下面的表格以了解一些支持的任务，以及完整支持任务列表，请查看 [🧨 Diffusers 概要](./api/pipelines/overview#diffusers-summary)
    表。'
- en: '| **Task** | **Description** | **Pipeline** |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| **任务** | **描述** | **管道** |'
- en: '| --- | --- | --- |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Unconditional Image Generation | generate an image from Gaussian noise |
    [unconditional_image_generation](./using-diffusers/unconditional_image_generation)
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 无条件图像生成 | 从高斯噪声生成图像 | [无条件图像生成](./using-diffusers/unconditional_image_generation)
    |'
- en: '| Text-Guided Image Generation | generate an image given a text prompt | [conditional_image_generation](./using-diffusers/conditional_image_generation)
    |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 文本引导的图像生成 | 根据文本提示生成图像 | [有条件图像生成](./using-diffusers/conditional_image_generation)
    |'
- en: '| Text-Guided Image-to-Image Translation | adapt an image guided by a text
    prompt | [img2img](./using-diffusers/img2img) |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 文本引导的图像到图像转换 | 根据文本提示调整图像 | [img2img](./using-diffusers/img2img) |'
- en: '| Text-Guided Image-Inpainting | fill the masked part of an image given the
    image, the mask and a text prompt | [inpaint](./using-diffusers/inpaint) |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 文本引导的图像修复 | 根据图像、蒙版和文本提示填充图像的遮罩部分 | [inpaint](./using-diffusers/inpaint)
    |'
- en: '| Text-Guided Depth-to-Image Translation | adapt parts of an image guided by
    a text prompt while preserving structure via depth estimation | [depth2img](./using-diffusers/depth2img)
    |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 文本引导的深度到图像转换 | 在保留结构的同时，通过深度估计调整图像的部分，由文本提示引导 | [depth2img](./using-diffusers/depth2img)
    |'
- en: Start by creating an instance of a [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    and specify which pipeline checkpoint you would like to download. You can use
    the [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    for any [checkpoint](https://huggingface.co/models?library=diffusers&sort=downloads)
    stored on the Hugging Face Hub. In this quicktour, you’ll load the [`stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    checkpoint for text-to-image generation.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: For [Stable Diffusion](https://huggingface.co/CompVis/stable-diffusion) models,
    please carefully read the [license](https://huggingface.co/spaces/CompVis/stable-diffusion-license)
    first before running the model. 🧨 Diffusers implements a [`safety_checker`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/safety_checker.py)
    to prevent offensive or harmful content, but the model’s improved image generation
    capabilities can still produce potentially harmful content.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the model with the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)
    method:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    downloads and caches all modeling, tokenization, and scheduling components. You’ll
    see that the Stable Diffusion pipeline is composed of the [UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)
    and [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)
    among other things:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We strongly recommend running the pipeline on a GPU because the model consists
    of roughly 1.4 billion parameters. You can move the generator object to a GPU,
    just like you would in PyTorch:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now you can pass a text prompt to the `pipeline` to generate an image, and then
    access the denoised image. By default, the image output is wrapped in a [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=image#the-image-class)
    object.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/020c32038fcd5d69660e0f7072208150.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: 'Save the image by calling `save`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Local pipeline
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can also use the pipeline locally. The only difference is you need to download
    the weights first:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then load the saved weights into the pipeline:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, you can run the pipeline as you would in the section above.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Swapping schedulers
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Different schedulers come with different denoising speeds and quality trade-offs.
    The best way to find out which one works best for you is to try them out! One
    of the main features of 🧨 Diffusers is to allow you to easily switch between schedulers.
    For example, to replace the default [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler)
    with the [EulerDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler),
    load it with the [from_config()](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin.from_config)
    method:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Try generating an image with the new scheduler and see if you notice a difference!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you’ll take a closer look at the components - the model
    and scheduler - that make up the [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    and learn how to use these components to generate an image of a cat.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Models
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most models take a noisy sample, and at each timestep it predicts the *noise
    residual* (other models learn to predict the previous sample directly or the velocity
    or [`v-prediction`](https://github.com/huggingface/diffusers/blob/5e5ce13e2f89ac45a0066cb3f369462a3cf1d9ef/src/diffusers/schedulers/scheduling_ddim.py#L110)),
    the difference between a less noisy image and the input image. You can mix and
    match models to create other diffusion systems.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Models are initiated with the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.from_pretrained)
    method which also locally caches the model weights so it is faster the next time
    you load the model. For the quicktour, you’ll load the [UNet2DModel](/docs/diffusers/v0.26.3/en/api/models/unet2d#diffusers.UNet2DModel),
    a basic unconditional image generation model with a checkpoint trained on cat
    images:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是使用[from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.from_pretrained)方法初始化的，该方法还会本地缓存模型权重，因此下次加载模型时会更快。对于快速入门，您将加载[UNet2DModel](/docs/diffusers/v0.26.3/en/api/models/unet2d#diffusers.UNet2DModel)，这是一个基本的无条件图像生成模型，带有在猫图像上训练的检查点：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To access the model parameters, call `model.config`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问模型参数，请调用`model.config`：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The model configuration is a 🧊 frozen 🧊 dictionary, which means those parameters
    can’t be changed after the model is created. This is intentional and ensures that
    the parameters used to define the model architecture at the start remain the same,
    while other parameters can still be adjusted during inference.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 模型配置是一个🧊冻结🧊字典，这意味着在创建模型后无法更改这些参数。这是有意为之的，可以确保在开始定义模型架构时使用的参数保持不变，而其他参数仍然可以在推断过程中进行调整。
- en: 'Some of the most important parameters are:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最重要的参数是：
- en: '`sample_size`: the height and width dimension of the input sample.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_size`：输入样本的高度和宽度维度。'
- en: '`in_channels`: the number of input channels of the input sample.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_channels`：输入样本的输入通道数。'
- en: '`down_block_types` and `up_block_types`: the type of down- and upsampling blocks
    used to create the UNet architecture.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`down_block_types`和`up_block_types`：用于创建UNet架构的下采样和上采样块的类型。'
- en: '`block_out_channels`: the number of output channels of the downsampling blocks;
    also used in reverse order for the number of input channels of the upsampling
    blocks.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`block_out_channels`：下采样块的输出通道数；也以相反顺序用于上采样块的输入通道数。'
- en: '`layers_per_block`: the number of ResNet blocks present in each UNet block.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layers_per_block`：每个UNet块中存在的ResNet块的数量。'
- en: 'To use the model for inference, create the image shape with random Gaussian
    noise. It should have a `batch` axis because the model can receive multiple random
    noises, a `channel` axis corresponding to the number of input channels, and a
    `sample_size` axis for the height and width of the image:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要将模型用于推断，请使用随机高斯噪声创建图像形状。它应该有一个`batch`轴，因为模型可以接收多个随机噪声，一个`channel`轴对应于输入通道的数量，以及一个`sample_size`轴用于图像的高度和宽度：
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'For inference, pass the noisy image and a `timestep` to the model. The `timestep`
    indicates how noisy the input image is, with more noise at the beginning and less
    at the end. This helps the model determine its position in the diffusion process,
    whether it is closer to the start or the end. Use the `sample` method to get the
    model output:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于推断，将嘈杂图像和一个`timestep`传递给模型。`timestep`指示输入图像有多嘈杂，开始时更多噪声，结束时更少噪声。这有助于模型确定其在扩散过程中的位置，无论是靠近开始还是结束。使用`sample`方法获取模型输出：
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To generate actual examples though, you’ll need a scheduler to guide the denoising
    process. In the next section, you’ll learn how to couple a model with a scheduler.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 但要生成实际示例，您需要一个调度器来指导去噪过程。在下一节中，您将学习如何将模型与调度器配对。
- en: Schedulers
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度器
- en: Schedulers manage going from a noisy sample to a less noisy sample given the
    model output - in this case, it is the `noisy_residual`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器管理从嘈杂的样本到较少嘈杂的样本的转变，给定模型输出 - 在这种情况下，它是`noisy_residual`。
- en: 🧨 Diffusers is a toolbox for building diffusion systems. While the [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)
    is a convenient way to get started with a pre-built diffusion system, you can
    also choose your own model and scheduler components separately to build a custom
    diffusion system.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 🧨 Diffusers是一个构建扩散系统的工具箱。虽然[DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline)是一个方便的方式来开始使用预构建的扩散系统，但您也可以选择自己的模型和调度器组件分别构建自定义扩散系统。
- en: 'For the quicktour, you’ll instantiate the [DDPMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.DDPMScheduler)
    with its [from_config()](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin.from_config)
    method:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于快速入门，您将使用其[from_config()](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin.from_config)方法实例化[DDPMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.DDPMScheduler)：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 💡 Unlike a model, a scheduler does not have trainable weights and is parameter-free!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 💡 与模型不同，调度器没有可训练的权重，也没有参数！
- en: 'Some of the most important parameters are:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最重要的参数是：
- en: '`num_train_timesteps`: the length of the denoising process or, in other words,
    the number of timesteps required to process random Gaussian noise into a data
    sample.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_train_timesteps`：去噪过程的长度，或者换句话说，处理随机高斯噪声成为数据样本所需的时间步数。'
- en: '`beta_schedule`: the type of noise schedule to use for inference and training.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_schedule`：用于推断和训练的噪声计划类型。'
- en: '`beta_start` and `beta_end`: the start and end noise values for the noise schedule.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta_start`和`beta_end`：噪声计划的起始和结束噪声值。'
- en: 'To predict a slightly less noisy image, pass the following to the scheduler’s
    [step()](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.DDPMScheduler.step)
    method: model output, `timestep`, and current `sample`.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 要预测一个稍微不那么嘈杂的图像，请将以下内容传递给调度器的[step()](/docs/diffusers/v0.26.3/en/api/schedulers/ddpm#diffusers.DDPMScheduler.step)方法：模型输出，`timestep`和当前`sample`。
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `less_noisy_sample` can be passed to the next `timestep` where it’ll get
    even less noisy! Let’s bring it all together now and visualize the entire denoising
    process.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`less_noisy_sample`可以传递到下一个`timestep`，在那里它会变得更少嘈杂！现在让我们把所有内容汇总起来，可视化整个去噪过程。'
- en: 'First, create a function that postprocesses and displays the denoised image
    as a `PIL.Image`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个后处理和显示去噪图像的函数作为`PIL.Image`：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To speed up the denoising process, move the input and model to a GPU:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为加快去噪过程，请将输入和模型移至GPU：
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now create a denoising loop that predicts the residual of the less noisy sample,
    and computes the less noisy sample with the scheduler:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在创建一个去噪循环，预测较少噪音样本的残差，并使用调度器计算较少噪音的样本：
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Sit back and watch as a cat is generated from nothing but noise! 😻
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 坐下来看着一只猫从一无所有的噪音中生成！😻
- en: '![](../Images/e6bad1468d511bff5946306330accda8.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6bad1468d511bff5946306330accda8.png)'
- en: Next steps
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步
- en: 'Hopefully, you generated some cool images with 🧨 Diffusers in this quicktour!
    For your next steps, you can:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您在这次快速浏览中使用🧨 Diffusers 生成了一些酷炫的图像！接下来，您可以：
- en: Train or finetune a model to generate your own images in the [training](./tutorials/basic_training)
    tutorial.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[训练](./tutorials/basic_training)教程中训练或微调模型以生成您自己的图像。
- en: See example official and community [training or finetuning scripts](https://github.com/huggingface/diffusers/tree/main/examples#-diffusers-examples)
    for a variety of use cases.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看官方和社区的[训练或微调脚本示例](https://github.com/huggingface/diffusers/tree/main/examples#-diffusers-examples)，适用于各种用例。
- en: Learn more about loading, accessing, changing, and comparing schedulers in the
    [Using different Schedulers](./using-diffusers/schedulers) guide.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[使用不同调度器](./using-diffusers/schedulers)指南中了解更多关于加载、访问、更改和比较调度器的信息。
- en: Explore prompt engineering, speed and memory optimizations, and tips and tricks
    for generating higher-quality images with the [Stable Diffusion](./stable_diffusion)
    guide.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索快速工程、速度和内存优化，以及使用[稳定扩散](./stable_diffusion)指南生成更高质量图像的技巧和窍门。
- en: Dive deeper into speeding up 🧨 Diffusers with guides on [optimized PyTorch on
    a GPU](./optimization/fp16), and inference guides for running [Stable Diffusion
    on Apple Silicon (M1/M2)](./optimization/mps) and [ONNX Runtime](./optimization/onnx).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入了解如何通过[优化PyTorch在GPU上](./optimization/fp16)的指南以及在Apple Silicon（M1/M2）上运行[稳定扩散](./optimization/mps)和[ONNX
    Runtime](./optimization/onnx)的推理指南来加快🧨 Diffusers的速度。
