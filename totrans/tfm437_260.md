# DeiT

> åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deit](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deit)

## æ¦‚è¿°

DeiTæ¨¡å‹æ˜¯ç”±Hugo Touvronã€Matthieu Cordã€Matthijs Douzeã€Francisco Massaã€Alexandre Sablayrollesã€HervÃ© JÃ©gouåœ¨[é€šè¿‡æ³¨æ„åŠ›è¿›è¡Œæ•°æ®é«˜æ•ˆå›¾åƒå˜æ¢å™¨è®­ç»ƒå’Œè’¸é¦](https://arxiv.org/abs/2012.12877)ä¸­æå‡ºçš„ã€‚[Vision Transformerï¼ˆViTï¼‰](vit)æ˜¯ç”±[Dosovitskiyç­‰äººï¼Œ2020](https://arxiv.org/abs/2010.11929)å¼•å…¥çš„ï¼Œå®ƒè¡¨æ˜å¯ä»¥ä½¿ç”¨Transformerç¼–ç å™¨ï¼ˆç±»ä¼¼BERTï¼‰åŒ¹é…ç”šè‡³è¶…è¶Šç°æœ‰çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚ç„¶è€Œï¼Œè¯¥è®ºæ–‡ä¸­ä»‹ç»çš„ViTæ¨¡å‹éœ€è¦åœ¨æ˜‚è´µçš„åŸºç¡€è®¾æ–½ä¸Šè¿›è¡Œå¤šå‘¨çš„è®­ç»ƒï¼Œä½¿ç”¨å¤–éƒ¨æ•°æ®ã€‚DeiTï¼ˆæ•°æ®é«˜æ•ˆå›¾åƒå˜æ¢å™¨ï¼‰æ˜¯æ›´é«˜æ•ˆçš„ç”¨äºå›¾åƒåˆ†ç±»çš„è®­ç»ƒå˜æ¢å™¨ï¼Œä¸åŸå§‹ViTæ¨¡å‹ç›¸æ¯”ï¼Œéœ€è¦æ›´å°‘çš„æ•°æ®å’Œæ›´å°‘çš„è®¡ç®—èµ„æºã€‚

è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š

*æœ€è¿‘ï¼Œçº¯åŸºäºæ³¨æ„åŠ›çš„ç¥ç»ç½‘ç»œè¢«è¯æ˜å¯ä»¥è§£å†³å›¾åƒç†è§£ä»»åŠ¡ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€‚ç„¶è€Œï¼Œè¿™äº›è§†è§‰å˜æ¢å™¨æ˜¯ä½¿ç”¨æ˜‚è´µçš„åŸºç¡€è®¾æ–½å¯¹æ•°äº¿å¼ å›¾åƒè¿›è¡Œé¢„è®­ç»ƒçš„ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬çš„é‡‡ç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä»…åœ¨Imagenetä¸Šè¿›è¡Œè®­ç»ƒï¼Œåˆ¶ä½œäº†ä¸€æ¬¾ç«äº‰åŠ›å¼ºçš„æ— å·ç§¯å˜æ¢å™¨ã€‚æˆ‘ä»¬åœ¨ä¸åˆ°3å¤©çš„æ—¶é—´å†…åœ¨ä¸€å°è®¡ç®—æœºä¸Šå¯¹å®ƒä»¬è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬çš„å‚è€ƒè§†è§‰å˜æ¢å™¨ï¼ˆ8600ä¸‡å‚æ•°ï¼‰åœ¨ImageNetä¸Šçš„å•è£å‰ªè¯„ä¼°ä¸­å®ç°äº†83.1%çš„top-1å‡†ç¡®ç‡ï¼Œæ²¡æœ‰ä½¿ç”¨å¤–éƒ¨æ•°æ®ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç‰¹å®šäºå˜æ¢å™¨çš„å¸ˆç”Ÿç­–ç•¥ã€‚å®ƒä¾èµ–äºä¸€ä¸ªè’¸é¦æ ‡è®°ï¼Œç¡®ä¿å­¦ç”Ÿé€šè¿‡æ³¨æ„åŠ›ä»è€å¸ˆé‚£é‡Œå­¦ä¹ ã€‚æˆ‘ä»¬å±•ç¤ºäº†åŸºäºè¿™ç§åŸºäºæ ‡è®°çš„è’¸é¦çš„å…´è¶£ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨å·ç§¯ç½‘ç»œä½œä¸ºè€å¸ˆæ—¶ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤ŸæŠ¥å‘Šä¸å·ç§¯ç½‘ç»œåœ¨Imagenetä¸Šç«äº‰çš„ç»“æœï¼ˆæˆ‘ä»¬çš„å‡†ç¡®ç‡é«˜è¾¾85.2%ï¼‰ï¼Œä»¥åŠåœ¨è½¬ç§»åˆ°å…¶ä»–ä»»åŠ¡æ—¶ã€‚æˆ‘ä»¬åˆ†äº«æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹ã€‚*

è¯¥æ¨¡å‹ç”±[nielsr](https://huggingface.co/nielsr)è´¡çŒ®ã€‚è¯¥æ¨¡å‹çš„TensorFlowç‰ˆæœ¬ç”±[amyeroberts](https://huggingface.co/amyeroberts)æ·»åŠ ã€‚

## ä½¿ç”¨æç¤º

+   ä¸ViTç›¸æ¯”ï¼ŒDeiTæ¨¡å‹ä½¿ç”¨æ‰€è°“çš„è’¸é¦æ ‡è®°æ¥æœ‰æ•ˆåœ°ä»è€å¸ˆé‚£é‡Œå­¦ä¹ ï¼ˆåœ¨DeiTè®ºæ–‡ä¸­ï¼Œè€å¸ˆæ˜¯ç±»ä¼¼ResNetçš„æ¨¡å‹ï¼‰ã€‚é€šè¿‡è‡ªæ³¨æ„åŠ›å±‚ï¼Œè’¸é¦æ ‡è®°é€šè¿‡ä¸ç±»ï¼ˆ[CLS]ï¼‰å’Œè¡¥ä¸æ ‡è®°çš„äº¤äº’è¿›è¡Œåå‘ä¼ æ’­å­¦ä¹ ã€‚

+   å¯¹è’¸é¦æ¨¡å‹è¿›è¡Œå¾®è°ƒæœ‰ä¸¤ç§æ–¹å¼ï¼Œè¦ä¹ˆï¼ˆ1ï¼‰é‡‡ç”¨ä¼ ç»Ÿæ–¹å¼ï¼Œåªåœ¨ç±»æ ‡è®°çš„æœ€ç»ˆéšè—çŠ¶æ€ä¸Šæ”¾ç½®ä¸€ä¸ªé¢„æµ‹å¤´ï¼Œä¸ä½¿ç”¨è’¸é¦ä¿¡å·ï¼Œè¦ä¹ˆï¼ˆ2ï¼‰åœ¨ç±»æ ‡è®°å’Œè’¸é¦æ ‡è®°çš„é¡¶éƒ¨éƒ½æ”¾ç½®ä¸€ä¸ªé¢„æµ‹å¤´ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ[CLS]é¢„æµ‹å¤´ä½¿ç”¨é¢„æµ‹å¤´å’Œåœ°é¢çœŸå®æ ‡ç­¾ä¹‹é—´çš„å¸¸è§„äº¤å‰ç†µè¿›è¡Œè®­ç»ƒï¼Œè€Œè’¸é¦é¢„æµ‹å¤´ä½¿ç”¨ç¡¬è’¸é¦è¿›è¡Œè®­ç»ƒï¼ˆè’¸é¦å¤´çš„é¢„æµ‹å’Œæ•™å¸ˆé¢„æµ‹çš„æ ‡ç­¾ä¹‹é—´çš„äº¤å‰ç†µï¼‰ã€‚åœ¨æ¨ç†æ—¶ï¼Œå°†ä¸¤ä¸ªå¤´ä¹‹é—´çš„å¹³å‡é¢„æµ‹ä½œä¸ºæœ€ç»ˆé¢„æµ‹ã€‚ï¼ˆ2ï¼‰ä¹Ÿè¢«ç§°ä¸ºâ€œè’¸é¦å¾®è°ƒâ€ï¼Œå› ä¸ºä¾èµ–äºå·²ç»åœ¨ä¸‹æ¸¸æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒçš„æ•™å¸ˆã€‚åœ¨æ¨¡å‹æ–¹é¢ï¼Œï¼ˆ1ï¼‰å¯¹åº”äº[DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)ï¼Œï¼ˆ2ï¼‰å¯¹åº”äº[DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)ã€‚

+   è¯·æ³¨æ„ï¼Œä½œè€…ä»¬è¿˜å°è¯•äº†å¯¹ï¼ˆ2ï¼‰è¿›è¡Œè½¯è’¸é¦ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè’¸é¦é¢„æµ‹å¤´ä½¿ç”¨KLæ•£åº¦è¿›è¡Œè®­ç»ƒï¼Œä»¥åŒ¹é…è€å¸ˆçš„softmaxè¾“å‡ºï¼‰ï¼Œä½†ç¡¬è’¸é¦æ•ˆæœæœ€å¥½ã€‚

+   æ‰€æœ‰å‘å¸ƒçš„æ£€æŸ¥ç‚¹ä»…åœ¨ImageNet-1kä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒå’Œå¾®è°ƒã€‚æ²¡æœ‰ä½¿ç”¨å¤–éƒ¨æ•°æ®ã€‚è¿™ä¸åŸå§‹çš„ViTæ¨¡å‹å½¢æˆå¯¹æ¯”ï¼ŒåŸå§‹çš„ViTæ¨¡å‹ä½¿ç”¨äº†å¤–éƒ¨æ•°æ®ï¼Œå¦‚JFT-300Mæ•°æ®é›†/Imagenet-21kè¿›è¡Œé¢„è®­ç»ƒã€‚

+   DeiTçš„ä½œè€…è¿˜å‘å¸ƒäº†æ›´é«˜æ•ˆè®­ç»ƒçš„ViTæ¨¡å‹ï¼Œæ‚¨å¯ä»¥ç›´æ¥æ’å…¥[ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel)æˆ–[ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification)ã€‚ä¸ºäº†æ¨¡æ‹Ÿåœ¨ä¸€ä¸ªæ›´å¤§çš„æ•°æ®é›†ä¸Šè®­ç»ƒï¼ˆä»…ä½¿ç”¨ImageNet-1kè¿›è¡Œé¢„è®­ç»ƒï¼‰ï¼Œä½¿ç”¨äº†æ•°æ®å¢å¼ºã€ä¼˜åŒ–å’Œæ­£åˆ™åŒ–ç­‰æŠ€æœ¯ã€‚æœ‰4ä¸ªå˜ä½“å¯ç”¨ï¼ˆ3ç§ä¸åŒå¤§å°ï¼‰ï¼š*facebook/deit-tiny-patch16-224*ã€*facebook/deit-small-patch16-224*ã€*facebook/deit-base-patch16-224*å’Œ*facebook/deit-base-patch16-384*ã€‚è¯·æ³¨æ„ï¼Œåº”è¯¥ä½¿ç”¨[DeiTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTImageProcessor)æ¥ä¸ºæ¨¡å‹å‡†å¤‡å›¾åƒã€‚

## èµ„æº

ä¸€ç³»åˆ—å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºï¼Œå¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨DeiTã€‚

å›¾åƒåˆ†ç±»

+   [DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)æ”¯æŒã€‚

+   å‚è§ï¼š[å›¾åƒåˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/image_classification)

æ­¤å¤–ï¼š

+   [DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining)æ”¯æŒã€‚

å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æ‰“å¼€ä¸€ä¸ªPull Requestï¼Œæˆ‘ä»¬å°†å¯¹å…¶è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥ç†æƒ³åœ°å±•ç¤ºä¸€äº›æ–°ä¸œè¥¿ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚

## DeiTConfig

### `class transformers.DeiTConfig`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/configuration_deit.py#L37)

```py
( hidden_size = 768 num_hidden_layers = 12 num_attention_heads = 12 intermediate_size = 3072 hidden_act = 'gelu' hidden_dropout_prob = 0.0 attention_probs_dropout_prob = 0.0 initializer_range = 0.02 layer_norm_eps = 1e-12 image_size = 224 patch_size = 16 num_channels = 3 qkv_bias = True encoder_stride = 16 **kwargs )
```

å‚æ•°

+   `hidden_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º768ï¼‰â€” ç¼–ç å™¨å±‚å’Œæ± åŒ–å±‚çš„ç»´åº¦ã€‚

+   `num_hidden_layers`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º12ï¼‰â€” Transformerç¼–ç å™¨ä¸­çš„éšè—å±‚æ•°é‡ã€‚

+   `num_attention_heads`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º12ï¼‰â€” Transformerç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `intermediate_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º3072ï¼‰â€” Transformerç¼–ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆå³å‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚

+   `hidden_act`ï¼ˆ`str`æˆ–`function`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"gelu"`ï¼‰â€” ç¼–ç å™¨å’Œæ± åŒ–å±‚ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ`"gelu"`ã€`"relu"`ã€`"selu"`å’Œ`"gelu_new"`ã€‚

+   `hidden_dropout_prob`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0.0ï¼‰â€” åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œæ± åŒ–å±‚ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„ä¸¢å¤±æ¦‚ç‡ã€‚

+   `attention_probs_dropout_prob`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0.0ï¼‰â€” æ³¨æ„åŠ›æ¦‚ç‡çš„ä¸¢å¤±æ¯”ç‡ã€‚

+   `initializer_range`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º0.02ï¼‰â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚

+   `layer_norm_eps`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º1e-12ï¼‰â€” å±‚å½’ä¸€åŒ–å±‚ä½¿ç”¨çš„epsilonã€‚

+   `image_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º224ï¼‰â€” æ¯ä¸ªå›¾åƒçš„å¤§å°ï¼ˆåˆ†è¾¨ç‡ï¼‰ã€‚

+   `patch_size`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º16ï¼‰â€” æ¯ä¸ªè¡¥ä¸çš„å¤§å°ï¼ˆåˆ†è¾¨ç‡ï¼‰ã€‚

+   `num_channels`ï¼ˆ`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º3ï¼‰â€” è¾“å…¥é€šé“çš„æ•°é‡ã€‚

+   `qkv_bias`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ˜¯å¦ä¸ºæŸ¥è¯¢ã€é”®å’Œå€¼æ·»åŠ åç½®ã€‚

+   `encoder_stride` (`int`, *optional*, é»˜è®¤ä¸º 16) â€” ç”¨äºåœ¨è§£ç å™¨å¤´éƒ¨å¢åŠ ç©ºé—´åˆ†è¾¨ç‡çš„å› å­ï¼Œç”¨äºé®è”½å›¾åƒå»ºæ¨¡ã€‚

è¿™æ˜¯ä¸€ä¸ªé…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨ [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel) çš„é…ç½®ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–ä¸€ä¸ª DeiT æ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äº DeiT [facebook/deit-base-distilled-patch16-224](https://huggingface.co/facebook/deit-base-distilled-patch16-224) æ¶æ„çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»æ¥è‡ª [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig) çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import DeiTConfig, DeiTModel

>>> # Initializing a DeiT deit-base-distilled-patch16-224 style configuration
>>> configuration = DeiTConfig()

>>> # Initializing a model (with random weights) from the deit-base-distilled-patch16-224 style configuration
>>> model = DeiTModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## DeiTFeatureExtractor

### `class transformers.DeiTFeatureExtractor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/feature_extraction_deit.py#L26)

```py
( *args **kwargs )
```

#### `__call__`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)

```py
( images **kwargs )
```

é¢„å¤„ç†å›¾åƒæˆ–ä¸€æ‰¹å›¾åƒã€‚

## DeiTImageProcessor

### `class transformers.DeiTImageProcessor`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/image_processing_deit.py#L45)

```py
( do_resize: bool = True size: Dict = None resample: Resampling = 3 do_center_crop: bool = True crop_size: Dict = None rescale_factor: Union = 0.00392156862745098 do_rescale: bool = True do_normalize: bool = True image_mean: Union = None image_std: Union = None **kwargs )
```

å‚æ•°

+   `do_resize` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å°†å›¾åƒçš„ (height, width) å°ºå¯¸è°ƒæ•´ä¸ºæŒ‡å®šçš„ `size`ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `do_resize` è¦†ç›–ã€‚

+   `size` (`Dict[str, int]` *optional*, é»˜è®¤ä¸º `{"height" -- 256, "width": 256}`): `resize` åçš„å›¾åƒå°ºå¯¸ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `size` è¦†ç›–ã€‚

+   `resample` (`PILImageResampling` è¿‡æ»¤å™¨, *optional*, é»˜è®¤ä¸º `Resampling.BICUBIC`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œè¦ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `resample` è¦†ç›–ã€‚

+   `do_center_crop` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œä¸­å¿ƒè£å‰ªã€‚å¦‚æœè¾“å…¥å°ºå¯¸åœ¨ä»»ä¸€è¾¹å°äº `crop_size`ï¼Œåˆ™å›¾åƒå°†ç”¨ 0 å¡«å……ï¼Œç„¶åè¿›è¡Œä¸­å¿ƒè£å‰ªã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `do_center_crop` è¦†ç›–ã€‚

+   `crop_size` (`Dict[str, int]`, *optional*, é»˜è®¤ä¸º `{"height" -- 224, "width": 224}`): åº”ç”¨ä¸­å¿ƒè£å‰ªæ—¶çš„æœŸæœ›è¾“å‡ºå°ºå¯¸ã€‚å¯ä»¥è¢« `preprocess` ä¸­çš„ `crop_size` è¦†ç›–ã€‚

+   `rescale_factor` (`int` æˆ– `float`, *optional*, é»˜è®¤ä¸º `1/255`) â€” å¦‚æœé‡æ–°ç¼©æ”¾å›¾åƒï¼Œè¦ä½¿ç”¨çš„ç¼©æ”¾å› å­ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `rescale_factor` å‚æ•°è¦†ç›–ã€‚

+   `do_rescale` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦æŒ‰æŒ‡å®šæ¯”ä¾‹ `rescale_factor` é‡æ–°ç¼©æ”¾å›¾åƒã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `do_rescale` å‚æ•°è¦†ç›–ã€‚

+   `do_normalize` (`bool`, *optional*, é»˜è®¤ä¸º `True`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `do_normalize` å‚æ•°è¦†ç›–ã€‚

+   `image_mean` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `IMAGENET_STANDARD_MEAN`) â€” å¦‚æœå¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ï¼Œè¦ä½¿ç”¨çš„å‡å€¼ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_mean` å‚æ•°è¦†ç›–ã€‚

+   `image_std` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `IMAGENET_STANDARD_STD`) â€” å¦‚æœå¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ï¼Œè¦ä½¿ç”¨çš„æ ‡å‡†å·®ã€‚è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æˆ–ä¸å›¾åƒé€šé“æ•°ç›¸åŒé•¿åº¦çš„æµ®ç‚¹æ•°åˆ—è¡¨ã€‚å¯ä»¥è¢« `preprocess` æ–¹æ³•ä¸­çš„ `image_std` å‚æ•°è¦†ç›–ã€‚

æ„å»ºä¸€ä¸ª DeiT å›¾åƒå¤„ç†å™¨ã€‚

#### `preprocess`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/image_processing_deit.py#L161)

```py
( images: Union do_resize: bool = None size: Dict = None resample = None do_center_crop: bool = None crop_size: Dict = None do_rescale: bool = None rescale_factor: float = None do_normalize: bool = None image_mean: Union = None image_std: Union = None return_tensors: Union = None data_format: ChannelDimension = <ChannelDimension.FIRST: 'channels_first'> input_data_format: Union = None **kwargs )
```

å‚æ•°

+   `images` (`ImageInput`) â€” è¦é¢„å¤„ç†çš„å›¾åƒã€‚æœŸæœ›å•ä¸ªå›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ï¼Œåƒç´ å€¼èŒƒå›´ä¸º 0 åˆ° 255ã€‚å¦‚æœä¼ å…¥åƒç´ å€¼åœ¨ 0 åˆ° 1 ä¹‹é—´çš„å›¾åƒï¼Œè¯·è®¾ç½® `do_rescale=False`ã€‚

+   `do_resize` (`bool`, *optional*, é»˜è®¤ä¸º `self.do_resize`) â€” æ˜¯å¦è°ƒæ•´å›¾åƒå¤§å°ã€‚

+   `size` (`Dict[str, int]`, *optional*, é»˜è®¤ä¸º `self.size`) â€” `resize` åçš„å›¾åƒå¤§å°ã€‚

+   `resample` (`PILImageResampling`, *optional*, é»˜è®¤ä¸º `self.resample`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™ä½¿ç”¨çš„ PILImageResampling è¿‡æ»¤å™¨ã€‚ä»…åœ¨ `do_resize` è®¾ç½®ä¸º `True` æ—¶æœ‰æ•ˆã€‚

+   `do_center_crop` (`bool`, *optional*, é»˜è®¤ä¸º `self.do_center_crop`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œä¸­å¿ƒè£å‰ªã€‚

+   `crop_size` (`Dict[str, int]`, *optional*, é»˜è®¤ä¸º `self.crop_size`) â€” å±…ä¸­è£å‰ªåçš„å›¾åƒå¤§å°ã€‚å¦‚æœå›¾åƒçš„ä¸€æ¡è¾¹å°äº `crop_size`ï¼Œåˆ™å°†ç”¨é›¶å¡«å……ï¼Œç„¶åè£å‰ªã€‚

+   `do_rescale` (`bool`, *optional*, é»˜è®¤ä¸º `self.do_rescale`) â€” æ˜¯å¦å°†å›¾åƒå€¼é‡æ–°ç¼©æ”¾åˆ° [0 - 1] ä¹‹é—´ã€‚

+   `rescale_factor` (`float`, *optional*, é»˜è®¤ä¸º `self.rescale_factor`) â€” å¦‚æœ `do_rescale` è®¾ç½®ä¸º `True`ï¼Œåˆ™ç”¨äºé‡æ–°ç¼©æ”¾å›¾åƒçš„é‡æ–°ç¼©æ”¾å› å­ã€‚

+   `do_normalize` (`bool`, *optional*, é»˜è®¤ä¸º `self.do_normalize`) â€” æ˜¯å¦å¯¹å›¾åƒè¿›è¡Œå½’ä¸€åŒ–ã€‚

+   `image_mean` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `self.image_mean`) â€” å›¾åƒå‡å€¼ã€‚

+   `image_std` (`float` æˆ– `List[float]`, *optional*, é»˜è®¤ä¸º `self.image_std`) â€” å›¾åƒæ ‡å‡†å·®ã€‚

+   `return_tensors` (`str` æˆ– `TensorType`, *optional*) â€” è¦è¿”å›çš„å¼ é‡ç±»å‹ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `None`: è¿”å›ä¸€ä¸ª `np.ndarray` åˆ—è¡¨ã€‚

    +   `TensorType.TENSORFLOW` æˆ– `'tf'`: è¿”å›ç±»å‹ä¸º `tf.Tensor` çš„æ‰¹æ¬¡ã€‚

    +   `TensorType.PYTORCH` æˆ– `'pt'`: è¿”å›ç±»å‹ä¸º `torch.Tensor` çš„æ‰¹æ¬¡ã€‚

    +   `TensorType.NUMPY` æˆ– `'np'`: è¿”å›ç±»å‹ä¸º `np.ndarray` çš„æ‰¹æ¬¡ã€‚

    +   `TensorType.JAX` æˆ– `'jax'`: è¿”å›ç±»å‹ä¸º `jax.numpy.ndarray` çš„æ‰¹æ¬¡ã€‚

+   `data_format` (`ChannelDimension` æˆ– `str`, *optional*, é»˜è®¤ä¸º `ChannelDimension.FIRST`) â€” è¾“å‡ºå›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `ChannelDimension.FIRST`: å›¾åƒä»¥ (num_channels, height, width) æ ¼å¼ã€‚

    +   `ChannelDimension.LAST`: å›¾åƒä»¥ (height, width, num_channels) æ ¼å¼ã€‚

+   `input_data_format` (`ChannelDimension` æˆ– `str`, *optional*) â€” è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™ä»è¾“å…¥å›¾åƒä¸­æ¨æ–­é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `"channels_first"` æˆ– `ChannelDimension.FIRST`: å›¾åƒä»¥ (num_channels, height, width) æ ¼å¼ã€‚

    +   `"channels_last"` æˆ– `ChannelDimension.LAST`: å›¾åƒä»¥ (height, width, num_channels) æ ¼å¼ã€‚

    +   `"none"` æˆ– `ChannelDimension.NONE`: å›¾åƒä»¥ (height, width) æ ¼å¼ã€‚

é¢„å¤„ç†å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ã€‚

PytorchHide Pytorch content

## DeiTModel

### `class transformers.DeiTModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L447)

```py
( config: DeiTConfig add_pooling_layer: bool = True use_mask_token: bool = False )
```

å‚æ•°

+   `config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)) â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

è£¸ DeiT æ¨¡å‹å˜æ¢å™¨è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡¶éƒ¨å¤´ã€‚æ­¤æ¨¡å‹æ˜¯ PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„ PyTorch æ¨¡å—ï¼Œå¹¶å‚è€ƒ PyTorch æ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ä¿¡æ¯ã€‚

#### `forward`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L476)

```py
( pixel_values: Optional = None bool_masked_pos: Optional = None head_mask: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.BaseModelOutputWithPooling or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`) â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨ [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor) è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `head_mask` (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰åœ¨ `[0, 1]`ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«é®è”½ï¼Œ

    +   0 è¡¨ç¤ºå¤´éƒ¨è¢«é®è”½ã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸­çš„ `attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸­çš„ `hidden_states`ã€‚

+   `return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å› [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput) è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `bool_masked_pos` (`torch.BoolTensor` of shape `(batch_size, num_patches)`, *optional*) â€” å¸ƒå°”æ©ç ä½ç½®ã€‚æŒ‡ç¤ºå“ªäº›è¡¥ä¸è¢«é®è”½ï¼ˆ1ï¼‰å“ªäº›æ²¡æœ‰ï¼ˆ0ï¼‰ã€‚

è¿”å›

[transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling) æˆ– `tuple(torch.FloatTensor)`

ä¸€ä¸ª [transformers.modeling_outputs.BaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling) æˆ–ä¸€ä¸ª `torch.FloatTensor` å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº† `return_dict=False` æˆ–å½“ `config.return_dict=False` æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ä¸åŒå…ƒç´ ã€‚

+   `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`) â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`) â€” åºåˆ—ç¬¬ä¸€ä¸ªæ ‡è®°ï¼ˆåˆ†ç±»æ ‡è®°ï¼‰çš„æœ€åä¸€å±‚éšè—çŠ¶æ€ï¼Œåœ¨é€šè¿‡ç”¨äºè¾…åŠ©é¢„è®­ç»ƒä»»åŠ¡çš„å±‚è¿›ä¸€æ­¥å¤„ç†åã€‚ä¾‹å¦‚ï¼Œå¯¹äº BERT ç³»åˆ—æ¨¡å‹ï¼Œè¿™å°†è¿”å›ç»è¿‡çº¿æ€§å±‚å’ŒåŒæ›²æ­£åˆ‡æ¿€æ´»å‡½æ•°å¤„ç†åçš„åˆ†ç±»æ ‡è®°ã€‚çº¿æ€§å±‚æƒé‡æ˜¯ä»é¢„è®­ç»ƒæœŸé—´çš„ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹ï¼ˆåˆ†ç±»ï¼‰ç›®æ ‡ä¸­è®­ç»ƒçš„ã€‚

+   `hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’ `output_hidden_states=True` æˆ–å½“ `config.output_hidden_states=True` æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º `(batch_size, sequence_length, hidden_size)` çš„ `torch.FloatTensor` å…ƒç»„ã€‚

    æ¯å±‚æ¨¡å‹çš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’ `output_attentions=True` æˆ–å½“ `config.output_attentions=True` æ—¶è¿”å›) â€” å½¢çŠ¶ä¸º `(batch_size, num_heads, sequence_length, sequence_length)` çš„ `torch.FloatTensor` å…ƒç»„ã€‚

    æ³¨æ„åŠ› softmax åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel) çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº† `__call__` ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨ `Module` å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, DeiTModel
>>> import torch
>>> from datasets import load_dataset

>>> dataset = load_dataset("huggingface/cats-image")
>>> image = dataset["test"]["image"][0]

>>> image_processor = AutoImageProcessor.from_pretrained("facebook/deit-base-distilled-patch16-224")
>>> model = DeiTModel.from_pretrained("facebook/deit-base-distilled-patch16-224")

>>> inputs = image_processor(image, return_tensors="pt")

>>> with torch.no_grad():
...     outputs = model(**inputs)

>>> last_hidden_states = outputs.last_hidden_state
>>> list(last_hidden_states.shape)
[1, 198, 768]
```

## DeiTForMaskedImageModeling

### `class transformers.DeiTForMaskedImageModeling`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L559)

```py
( config: DeiTConfig )
```

å‚æ•°

+   `config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰ â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

å¸¦æœ‰é¡¶éƒ¨è§£ç å™¨çš„DeiTæ¨¡å‹ï¼Œç”¨äºé®ç½©å›¾åƒå»ºæ¨¡ï¼Œå¦‚[SimMIM](https://arxiv.org/abs/2111.09886)ä¸­æå‡ºçš„ã€‚ 

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åœ¨æˆ‘ä»¬çš„[ç¤ºä¾‹ç›®å½•](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining)ä¸­æä¾›äº†ä¸€ä¸ªè„šæœ¬ï¼Œç”¨äºåœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šé¢„è®­ç»ƒæ­¤æ¨¡å‹ã€‚

è¿™ä¸ªæ¨¡å‹æ˜¯ä¸€ä¸ªPyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚

#### `forward`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L589)

```py
( pixel_values: Optional = None bool_masked_pos: Optional = None head_mask: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.MaskedImageModelingOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`) â€” åƒç´ å€¼ã€‚åƒç´ å€¼å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `head_mask` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`ï¼Œ*optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚åœ¨`[0, 1]`ä¸­é€‰æ‹©çš„æ©ç å€¼ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨æ˜¯`not masked`,

    +   0è¡¨ç¤ºå¤´éƒ¨æ˜¯`masked`ã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚

+   `bool_masked_pos` (`torch.BoolTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_patches)`) â€” å¸ƒå°”æ©ç ä½ç½®ã€‚æŒ‡ç¤ºå“ªäº›è¡¥ä¸è¢«æ©ç›–ï¼ˆ1ï¼‰å“ªäº›æ²¡æœ‰ï¼ˆ0ï¼‰ã€‚

è¿”å›

`transformers.modeling_outputs.MaskedImageModelingOutput`æˆ–`tuple(torch.FloatTensor)`

ä¸€ä¸ª`transformers.modeling_outputs.MaskedImageModelingOutput`æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå…·ä½“å–å†³äºé…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ã€‚

+   `loss` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(1,)`ï¼Œ*optional*ï¼Œå½“æä¾›`bool_masked_pos`æ—¶è¿”å›) â€” é‡å»ºæŸå¤±ã€‚

+   `reconstruction` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`) â€” é‡å»º/å®Œæˆçš„å›¾åƒã€‚

+   `hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æ—¶è¿”å›

+   `when` `config.output_hidden_states=True`) â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º+æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼‰ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µè¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚

+   `attentions` (`tuple(torch.FloatTensor)`ï¼Œ*optional*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›

+   `config.output_attentions=True):` å½¢çŠ¶ä¸º`(batch_size, num_heads, patch_size, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„æ³¨æ„åŠ›softmaxä¹‹åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, DeiTForMaskedImageModeling
>>> import torch
>>> from PIL import Image
>>> import requests

>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> image_processor = AutoImageProcessor.from_pretrained("facebook/deit-base-distilled-patch16-224")
>>> model = DeiTForMaskedImageModeling.from_pretrained("facebook/deit-base-distilled-patch16-224")

>>> num_patches = (model.config.image_size // model.config.patch_size) ** 2
>>> pixel_values = image_processor(images=image, return_tensors="pt").pixel_values
>>> # create random boolean mask of shape (batch_size, num_patches)
>>> bool_masked_pos = torch.randint(low=0, high=2, size=(1, num_patches)).bool()

>>> outputs = model(pixel_values, bool_masked_pos=bool_masked_pos)
>>> loss, reconstructed_pixel_values = outputs.loss, outputs.reconstruction
>>> list(reconstructed_pixel_values.shape)
[1, 3, 224, 224]
```

## DeiTForImageClassification

### `class transformers.DeiTForImageClassification`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L676)

```py
( config: DeiTConfig )
```

å‚æ•°

+   `config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰- æ¨¡å‹çš„æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´éƒ¨çš„DeiTæ¨¡å‹å˜æ¢å™¨ï¼ˆåœ¨[CLS]æ ‡è®°çš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºImageNetã€‚

æ­¤æ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚

#### `forward`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L696)

```py
( pixel_values: Optional = None head_mask: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.modeling_outputs.ImageClassifierOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`ï¼‰- åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`èŒƒå›´å†…ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`masked`ï¼Œ

    +   0è¡¨ç¤ºå¤´éƒ¨æ˜¯`masked`ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `labels`ï¼ˆå½¢çŠ¶ä¸º`(batch_size,)`çš„`torch.LongTensor`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºè®¡ç®—å›¾åƒåˆ†ç±»/å›å½’æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[0, ..., config.num_labels - 1]`èŒƒå›´å†…ã€‚å¦‚æœ`config.num_labels == 1`ï¼Œåˆ™è®¡ç®—å›å½’æŸå¤±ï¼ˆå‡æ–¹æŸå¤±ï¼‰ï¼Œå¦‚æœ`config.num_labels > 1`ï¼Œåˆ™è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰ã€‚

è¿”å›

[transformers.modeling_outputs.ImageClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutput)æˆ–`tuple(torch.FloatTensor)`

ä¸€ä¸ª[transformers.modeling_outputs.ImageClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutput)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ä¸åŒå…ƒç´ ã€‚

+   `loss`ï¼ˆå½¢çŠ¶ä¸º`(1,)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›ï¼‰â€” åˆ†ç±»ï¼ˆå¦‚æœ`config.num_labels==1`åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚

+   `logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰â€” åˆ†ç±»ï¼ˆå¦‚æœ`config.num_labels==1`åˆ™ä¸ºå›å½’ï¼‰åˆ†æ•°ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚

+   `hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚

+   `attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, patch_size, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚

    è‡ªæ³¨æ„åŠ›å¤´ä¸­ç”¨äºè®¡ç®—åŠ æƒå¹³å‡å€¼çš„æ³¨æ„åŠ›æƒé‡åœ¨æ³¨æ„åŠ›softmaxä¹‹åã€‚

[DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, DeiTForImageClassification
>>> import torch
>>> from PIL import Image
>>> import requests

>>> torch.manual_seed(3)
>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> # note: we are loading a DeiTForImageClassificationWithTeacher from the hub here,
>>> # so the head will be randomly initialized, hence the predictions will be random
>>> image_processor = AutoImageProcessor.from_pretrained("facebook/deit-base-distilled-patch16-224")
>>> model = DeiTForImageClassification.from_pretrained("facebook/deit-base-distilled-patch16-224")

>>> inputs = image_processor(images=image, return_tensors="pt")
>>> outputs = model(**inputs)
>>> logits = outputs.logits
>>> # model predicts one of the 1000 ImageNet classes
>>> predicted_class_idx = logits.argmax(-1).item()
>>> print("Predicted class:", model.config.id2label[predicted_class_idx])
Predicted class: magpie
```

## DeiTForImageClassificationWithTeacher

### `class transformers.DeiTForImageClassificationWithTeacher`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L821)

```py
( config: DeiTConfig )
```

å‚æ•°

+   `config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

DeiTæ¨¡å‹å˜å‹å™¨ï¼Œé¡¶éƒ¨å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´ï¼ˆåœ¨[CLS]ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼Œåœ¨è’¸é¦ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºImageNetã€‚

.. è­¦å‘Š::

è¿™ä¸ªæ¨¡å‹ä»…æ”¯æŒæ¨ç†ã€‚å°šä¸æ”¯æŒä½¿ç”¨è’¸é¦ï¼ˆå³ä½¿ç”¨æ•™å¸ˆï¼‰è¿›è¡Œå¾®è°ƒã€‚

è¿™ä¸ªæ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_deit.py#L851)

```py
( pixel_values: Optional = None head_mask: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.models.deit.modeling_deit.DeiTForImageClassificationWithTeacherOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`ï¼‰â€” åƒç´ å€¼ã€‚åƒç´ å€¼å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`torch.FloatTensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨`[0, 1]`ä¸­é€‰æ‹©ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨æœªè¢«é®è”½ï¼Œ

    +   0è¡¨ç¤ºå¤´éƒ¨æ˜¯`masked`ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

è¿”å›

`transformers.models.deit.modeling_deit.DeiTForImageClassificationWithTeacherOutput`æˆ–`tuple(torch.FloatTensor)`

ä¸€ä¸ª`transformers.models.deit.modeling_deit.DeiTForImageClassificationWithTeacherOutput`æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ã€‚

+   `logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰- é¢„æµ‹åˆ†æ•°ï¼Œä½œä¸º`cls_logits`å’Œè’¸é¦`logits`çš„å¹³å‡å€¼ã€‚

+   `cls_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰- åˆ†ç±»å¤´éƒ¨çš„é¢„æµ‹åˆ†æ•°ï¼ˆå³ç±»ä»¤ç‰Œæœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨çš„çº¿æ€§å±‚ï¼‰ã€‚

+   `distillation_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`torch.FloatTensor`ï¼‰- è’¸é¦å¤´éƒ¨çš„é¢„æµ‹åˆ†æ•°ï¼ˆå³è’¸é¦ä»¤ç‰Œæœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨çš„çº¿æ€§å±‚ï¼‰ã€‚

+   `hidden_states`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰- å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º + ä¸€ä¸ªç”¨äºæ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚æ¨¡å‹åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºå’Œåˆå§‹åµŒå…¥è¾“å‡ºå¤„çš„éšè—çŠ¶æ€ã€‚

+   `attentions`ï¼ˆ`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰- å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`torch.FloatTensor`å…ƒç»„ã€‚æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ–¹æ³•éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, DeiTForImageClassificationWithTeacher
>>> import torch
>>> from datasets import load_dataset

>>> dataset = load_dataset("huggingface/cats-image")
>>> image = dataset["test"]["image"][0]

>>> image_processor = AutoImageProcessor.from_pretrained("facebook/deit-base-distilled-patch16-224")
>>> model = DeiTForImageClassificationWithTeacher.from_pretrained("facebook/deit-base-distilled-patch16-224")

>>> inputs = image_processor(image, return_tensors="pt")

>>> with torch.no_grad():
...     logits = model(**inputs).logits

>>> # model predicts one of the 1000 ImageNet classes
>>> predicted_label = logits.argmax(-1).item()
>>> print(model.config.id2label[predicted_label])
tabby, tabby cat
```

TensorFlowéšè—TensorFlowå†…å®¹

## TFDeiTModel

### `class transformers.TFDeiTModel`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L723)

```py
( config: DeiTConfig add_pooling_layer: bool = True use_mask_token: bool = False **kwargs )
```

å‚æ•°

+   `config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰- å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

è£¸DeiTæ¨¡å‹å˜å‹å™¨è¾“å‡ºåŸå§‹éšè—çŠ¶æ€ï¼Œæ²¡æœ‰ç‰¹å®šå¤´éƒ¨ã€‚æ­¤æ¨¡å‹æ˜¯ä¸€ä¸ªTensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)ã€‚å°†å…¶ç”¨ä½œå¸¸è§„TensorFlowæ¨¡å—ï¼Œå¹¶å‚è€ƒTensorFlowæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `call`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L737)

```py
( pixel_values: tf.Tensor | None = None bool_masked_pos: tf.Tensor | None = None head_mask: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: bool = False ) â†’ export const metadata = 'undefined';transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling or tuple(tf.Tensor)
```

å‚æ•°

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`tf.Tensor`ï¼‰â€” åƒç´ å€¼ã€‚åƒç´ å€¼å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰å®šåœ¨`[0, 1]`ä¸­ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨`æœªè¢«æ©ç›–`ï¼Œ

    +   0è¡¨ç¤ºå¤´éƒ¨`è¢«æ©ç›–`ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

è¿”å›

[transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling)æˆ–`tuple(tf.Tensor)`

[transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling)æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚

+   `last_hidden_state`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`ï¼‰â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `pooler_output`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, hidden_size)`çš„`tf.Tensor`ï¼‰â€” åºåˆ—ç¬¬ä¸€ä¸ªæ ‡è®°ï¼ˆåˆ†ç±»æ ‡è®°ï¼‰çš„æœ€åä¸€å±‚éšè—çŠ¶æ€ï¼Œç»è¿‡çº¿æ€§å±‚å’ŒTanhæ¿€æ´»å‡½æ•°è¿›ä¸€æ­¥å¤„ç†ã€‚çº¿æ€§å±‚çš„æƒé‡æ˜¯åœ¨é¢„è®­ç»ƒæœŸé—´ä»ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹ï¼ˆåˆ†ç±»ï¼‰ç›®æ ‡ä¸­è®­ç»ƒçš„ã€‚

    è¿™ä¸ªè¾“å‡ºé€šå¸¸*ä¸æ˜¯*è¾“å…¥çš„è¯­ä¹‰å†…å®¹çš„å¥½æ‘˜è¦ï¼Œé€šå¸¸æœ€å¥½å¯¹æ•´ä¸ªè¾“å…¥åºåˆ—çš„éšè—çŠ¶æ€è¿›è¡Œå¹³å‡æˆ–æ± åŒ–ã€‚

+   `hidden_states`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ï¼ˆåµŒå…¥è¾“å‡ºçš„ä¸€ä¸ª+æ¯å±‚è¾“å‡ºçš„ä¸€ä¸ªï¼‰ã€‚

    æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`tf.Tensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚

    æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, TFDeiTModel
>>> from datasets import load_dataset

>>> dataset = load_dataset("huggingface/cats-image")
>>> image = dataset["test"]["image"][0]

>>> image_processor = AutoImageProcessor.from_pretrained("facebook/deit-base-distilled-patch16-224")
>>> model = TFDeiTModel.from_pretrained("facebook/deit-base-distilled-patch16-224")

>>> inputs = image_processor(image, return_tensors="tf")
>>> outputs = model(**inputs)

>>> last_hidden_states = outputs.last_hidden_state
>>> list(last_hidden_states.shape)
[1, 198, 768]
```

## TFDeiTForMaskedImageModeling

### `class transformers.TFDeiTForMaskedImageModeling`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L859)

```py
( config: DeiTConfig )
```

å‚æ•°

+   `config` ([DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)) â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

DeiT æ¨¡å‹åœ¨é¡¶éƒ¨å¸¦æœ‰è§£ç å™¨ï¼Œç”¨äºé®è”½å›¾åƒå»ºæ¨¡ï¼Œå¦‚ [SimMIM](https://arxiv.org/abs/2111.09886) ä¸­æå‡ºçš„ã€‚æ­¤æ¨¡å‹æ˜¯ä¸€ä¸ª TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)ã€‚å°†å…¶ç”¨ä½œå¸¸è§„ TensorFlow æ¨¡å—ï¼Œå¹¶å‚è€ƒ TensorFlow æ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `call`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L871)

```py
( pixel_values: tf.Tensor | None = None bool_masked_pos: tf.Tensor | None = None head_mask: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: bool = False ) â†’ export const metadata = 'undefined';transformers.modeling_tf_outputs.TFMaskedImageModelingOutput or tuple(tf.Tensor)
```

å‚æ•°

+   `pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`) â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨ [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor) è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `head_mask` (`tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*) â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼åœ¨ `[0, 1]` ä¸­é€‰æ‹©ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨æ˜¯ `not masked`,

    +   0 è¡¨ç¤ºå¤´éƒ¨æ˜¯ `masked`ã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„ `attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„ `hidden_states`ã€‚

+   `return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å› [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput) è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `bool_masked_pos` (`tf.Tensor` of type bool and shape `(batch_size, num_patches)`) â€” å¸ƒå°”æ©ç ä½ç½®ã€‚æŒ‡ç¤ºå“ªäº›è¡¥ä¸è¢«é®è”½ï¼ˆ1ï¼‰å“ªäº›æ²¡æœ‰ï¼ˆ0ï¼‰ã€‚

è¿”å›

`transformers.modeling_tf_outputs.TFMaskedImageModelingOutput` æˆ– `tuple(tf.Tensor)`

ä¸€ä¸ª `transformers.modeling_tf_outputs.TFMaskedImageModelingOutput` æˆ–ä¸€ä¸ª `tf.Tensor` å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº† `return_dict=False` æˆ–å½“ `config.return_dict=False` æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚

+   `loss` (`tf.Tensor` of shape `(1,)`, *optional*, returned when `bool_masked_pos` is provided) â€” Reconstruction loss.

+   `reconstruction` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`) â€” é‡å»º/å®Œæˆçš„å›¾åƒã€‚

+   `hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when

+   `config.output_hidden_states=True):` `tf.Tensor` å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹å…·æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸€ä¸ªç”¨äºåµŒå…¥çš„è¾“å‡º + ä¸€ä¸ªç”¨äºæ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼‰çš„å½¢çŠ¶ä¸º `(batch_size, sequence_length, hidden_size)`ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µè¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚

+   `attentions` (`tuple(tf.Tensor)`, *optional*, å½“ä¼ é€’ `output_attentions=True` æˆ–

+   `config.output_attentions=True):` `tf.Tensor` å…ƒç»„ï¼ˆæ¯ä¸ªå±‚ä¸€ä¸ªï¼‰çš„å½¢çŠ¶ä¸º `(batch_size, num_heads, patch_size, sequence_length)`ã€‚æ³¨æ„åŠ› softmax åçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling) çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº† `__call__` ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨ `Module` å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, TFDeiTForMaskedImageModeling
>>> import tensorflow as tf
>>> from PIL import Image
>>> import requests

>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> image_processor = AutoImageProcessor.from_pretrained("facebook/deit-base-distilled-patch16-224")
>>> model = TFDeiTForMaskedImageModeling.from_pretrained("facebook/deit-base-distilled-patch16-224")

>>> num_patches = (model.config.image_size // model.config.patch_size) ** 2
>>> pixel_values = image_processor(images=image, return_tensors="tf").pixel_values
>>> # create random boolean mask of shape (batch_size, num_patches)
>>> bool_masked_pos = tf.cast(tf.random.uniform((1, num_patches), minval=0, maxval=2, dtype=tf.int32), tf.bool)

>>> outputs = model(pixel_values, bool_masked_pos=bool_masked_pos)
>>> loss, reconstructed_pixel_values = outputs.loss, outputs.reconstruction
>>> list(reconstructed_pixel_values.shape)
[1, 3, 224, 224]
```

## TFDeiTForImageClassification

### `class transformers.TFDeiTForImageClassification`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L983)

```py
( config: DeiTConfig )
```

å‚æ•°

+   `config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹ [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

DeiT æ¨¡å‹å˜å‹å™¨ï¼Œé¡¶éƒ¨å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´éƒ¨ï¼ˆåœ¨ [CLS] æ ‡è®°çš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äº ImageNetã€‚

æ­¤æ¨¡å‹æ˜¯ä¸€ä¸ª TensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)ã€‚å°†å…¶ç”¨ä½œå¸¸è§„ TensorFlow æ¨¡å—ï¼Œå¹¶å‚è€ƒ TensorFlow æ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚

#### `call`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L1005)

```py
( pixel_values: tf.Tensor | None = None head_mask: tf.Tensor | None = None labels: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: bool = False ) â†’ export const metadata = 'undefined';transformers.modeling_tf_outputs.TFImageClassifierOutput or tuple(tf.Tensor)
```

å‚æ•°

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º `(batch_size, num_channels, height, width)` çš„ `tf.Tensor`ï¼‰â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨ [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor) è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º `(num_heads,)` æˆ– `(num_layers, num_heads)` çš„ `tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—çš„é€‰å®šå¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰å®šåœ¨ `[0, 1]` èŒƒå›´å†…ï¼š

    +   1 è¡¨ç¤ºå¤´éƒ¨æœªè¢«é®ç½©ï¼Œ

    +   0 è¡¨ç¤ºå¤´éƒ¨è¢«é®ç½©ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹è¿”å›å¼ é‡ä¸‹çš„ `attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹è¿”å›å¼ é‡ä¸‹çš„ `hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰â€” æ˜¯å¦è¿”å› [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput) è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `labels`ï¼ˆå½¢çŠ¶ä¸º `(batch_size,)` çš„ `tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰â€” ç”¨äºè®¡ç®—å›¾åƒåˆ†ç±»/å›å½’æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨ `[0, ..., config.num_labels - 1]` èŒƒå›´å†…ã€‚å¦‚æœ `config.num_labels == 1`ï¼Œåˆ™è®¡ç®—å›å½’æŸå¤±ï¼ˆå‡æ–¹æŸå¤±ï¼‰ï¼Œå¦‚æœ `config.num_labels > 1`ï¼Œåˆ™è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰ã€‚

è¿”å›

`transformers.modeling_tf_outputs.TFImageClassifierOutput` æˆ– `tuple(tf.Tensor)`

`transformers.modeling_tf_outputs.TFImageClassifierOutput` æˆ– `tuple(tf.Tensor)`ï¼ˆå¦‚æœä¼ é€’äº† `return_dict=False` æˆ–å½“ `config.return_dict=False` æ—¶ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰å’Œè¾“å…¥ã€‚

+   `loss`ï¼ˆå½¢çŠ¶ä¸º `(1,)` çš„ `tf.Tensor`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾› `labels` æ—¶è¿”å›ï¼‰â€” åˆ†ç±»ï¼ˆæˆ–å¦‚æœ `config.num_labels==1` åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚

+   `logits`ï¼ˆå½¢çŠ¶ä¸º `(batch_size, config.num_labels)` çš„ `tf.Tensor`ï¼‰â€” åˆ†ç±»ï¼ˆæˆ–å¦‚æœ `config.num_labels==1` åˆ™ä¸ºå›å½’ï¼‰åˆ†æ•°ï¼ˆSoftMax ä¹‹å‰ï¼‰ã€‚

+   `hidden_states`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰- å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹å…·æœ‰åµŒå…¥å±‚çš„è¾“å‡ºï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º+æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼‰ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚

+   `attentions`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰- å½¢çŠ¶ä¸º`(batch_size, num_heads, patch_size, sequence_length)`çš„`tf.Tensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚

    æ³¨æ„æƒé‡åœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

[TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„é…æ–¹éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, TFDeiTForImageClassification
>>> import tensorflow as tf
>>> from PIL import Image
>>> import requests

>>> tf.keras.utils.set_random_seed(3)
>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> # note: we are loading a TFDeiTForImageClassificationWithTeacher from the hub here,
>>> # so the head will be randomly initialized, hence the predictions will be random
>>> image_processor = AutoImageProcessor.from_pretrained("facebook/deit-base-distilled-patch16-224")
>>> model = TFDeiTForImageClassification.from_pretrained("facebook/deit-base-distilled-patch16-224")

>>> inputs = image_processor(images=image, return_tensors="tf")
>>> outputs = model(**inputs)
>>> logits = outputs.logits
>>> # model predicts one of the 1000 ImageNet classes
>>> predicted_class_idx = tf.math.argmax(logits, axis=-1)[0]
>>> print("Predicted class:", model.config.id2label[int(predicted_class_idx)])
Predicted class: little blue heron, Egretta caerulea
```

## TFDeiTForImageClassificationWithTeacher

### `class transformers.TFDeiTForImageClassificationWithTeacher`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L1092)

```py
( config: DeiTConfig )
```

å‚æ•°

+   `config`ï¼ˆ[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)ï¼‰- æ¨¡å‹é…ç½®ç±»ï¼ŒåŒ…å«æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

DeiTæ¨¡å‹å˜å‹å™¨ï¼Œé¡¶éƒ¨å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´ï¼ˆåœ¨[CLS]ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼Œåœ¨è’¸é¦ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºImageNetã€‚

.. è­¦å‘Š::

æ­¤æ¨¡å‹ä»…æ”¯æŒæ¨æ–­ã€‚å°šä¸æ”¯æŒä½¿ç”¨è’¸é¦ï¼ˆå³ä¸æ•™å¸ˆä¸€èµ·ï¼‰è¿›è¡Œå¾®è°ƒã€‚

æ­¤æ¨¡å‹æ˜¯ä¸€ä¸ªTensorFlow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„TensorFlowæ¨¡å—ï¼Œå¹¶å‚è€ƒTensorFlowæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `call`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deit/modeling_tf_deit.py#L1124)

```py
( pixel_values: tf.Tensor | None = None head_mask: tf.Tensor | None = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: bool = False ) â†’ export const metadata = 'undefined';transformers.models.deit.modeling_tf_deit.TFDeiTForImageClassificationWithTeacherOutput or tuple(tf.Tensor)
```

å‚æ•°

+   `pixel_values`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`tf.Tensor`ï¼‰- åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeiTImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `head_mask`ï¼ˆå½¢çŠ¶ä¸º`(num_heads,)`æˆ–`(num_layers, num_heads)`çš„`tf.Tensor`ï¼Œ*å¯é€‰*ï¼‰- ç”¨äºä½¿è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­é€‰æ‹©çš„å¤´éƒ¨å¤±æ•ˆçš„æ©ç ã€‚æ©ç å€¼é€‰æ‹©åœ¨`[0, 1]`ä¸­ï¼š

    +   1è¡¨ç¤ºå¤´éƒ¨æœªè¢«`masked`ï¼Œ

    +   0è¡¨ç¤ºå¤´éƒ¨è¢«`masked`ã€‚

+   `output_attentions`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼‰- æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

è¿”å›

`transformers.models.deit.modeling_tf_deit.TFDeiTForImageClassificationWithTeacherOutput`æˆ–`tuple(tf.Tensor)`

ä¸€ä¸ª`transformers.models.deit.modeling_tf_deit.TFDeiTForImageClassificationWithTeacherOutput`æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆDeiTConfigï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚

+   `logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`tf.Tensor`ï¼‰- é¢„æµ‹åˆ†æ•°ï¼Œä½œä¸ºcls_logitså’Œdistillation logitsçš„å¹³å‡å€¼ã€‚

+   `cls_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`tf.Tensor`ï¼‰- åˆ†ç±»å¤´éƒ¨çš„é¢„æµ‹åˆ†æ•°ï¼ˆå³åœ¨ç±»ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ã€‚

+   `distillation_logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`tf.Tensor`ï¼‰- è’¸é¦å¤´éƒ¨çš„é¢„æµ‹åˆ†æ•°ï¼ˆå³åœ¨è’¸é¦ä»¤ç‰Œçš„æœ€ç»ˆéšè—çŠ¶æ€ä¹‹ä¸Šçš„çº¿æ€§å±‚ï¼‰ã€‚

+   `hidden_states`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰- å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ã€‚æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `attentions`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰- å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`tf.Tensor`å…ƒç»„ã€‚æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

TFDeiTForImageClassificationWithTeacherçš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import AutoImageProcessor, TFDeiTForImageClassificationWithTeacher
>>> import tensorflow as tf
>>> from datasets import load_dataset

>>> dataset = load_dataset("huggingface/cats-image")
>>> image = dataset["test"]["image"][0]

>>> image_processor = AutoImageProcessor.from_pretrained("facebook/deit-base-distilled-patch16-224")
>>> model = TFDeiTForImageClassificationWithTeacher.from_pretrained("facebook/deit-base-distilled-patch16-224")

>>> inputs = image_processor(image, return_tensors="tf")
>>> logits = model(**inputs).logits

>>> # model predicts one of the 1000 ImageNet classes
>>> predicted_label = int(tf.math.argmax(logits, axis=-1))
>>> print(model.config.id2label[predicted_label])
tabby, tabby cat
```
