# 总结

> 原文：[https://huggingface.co/learn/deep-rl-course/unit1/summary](https://huggingface.co/learn/deep-rl-course/unit1/summary)

这是很多信息！让我们总结一下：

+   强化学习是一种从行动中学习的计算方法。我们构建一个代理，通过**通过试错与环境互动**并接收奖励（负面或正面）作为反馈来学习。

+   任何强化学习代理的目标都是最大化其预期累积奖励（也称为预期回报），因为强化学习基于**奖励假设**，即**所有目标都可以描述为最大化预期累积奖励。**

+   强化学习过程是一个循环，输出一系列**状态、行动、奖励和下一个状态。**

+   为了计算预期累积奖励（预期回报），我们对奖励进行折现：较早出现的奖励（在游戏开始时）**更有可能发生，因为它们比长期未来奖励更可预测。**

+   要解决强化学习问题，您希望**找到一个最优策略**。策略是您代理的“大脑”，它将告诉我们**在给定状态下采取什么行动。**最优策略是那个**给出最大化预期回报的行动。**

+   有两种方法可以找到您的最优策略：

    1.  通过直接训练您的策略：**基于策略的方法。**

    1.  通过训练一个告诉我们代理在每个状态将获得的预期回报的价值函数，并使用这个函数来定义我们的策略：**基于价值的方法。**

+   最后，我们谈到了深度强化学习，因为我们引入了**深度神经网络来估计要采取的行动（基于策略）或估计状态的价值（基于价值）**，因此得名“深度”。
