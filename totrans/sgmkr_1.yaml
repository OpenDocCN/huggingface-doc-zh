- en: Hugging Face on Amazon SageMaker
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Amazon SageMaker上的Hugging Face
- en: 'Original text: [https://huggingface.co/docs/sagemaker/index](https://huggingface.co/docs/sagemaker/index)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/sagemaker/index](https://huggingface.co/docs/sagemaker/index)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![cover](../Images/050af512638f1fb24402f93714ea3aad.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![封面](../Images/050af512638f1fb24402f93714ea3aad.png)'
- en: Deep Learning Containers
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习容器
- en: Deep Learning Containers (DLCs) are Docker images pre-installed with deep learning
    frameworks and libraries such as 🤗 Transformers, 🤗 Datasets, and 🤗 Tokenizers.
    The DLCs allow you to start training models immediately, skipping the complicated
    process of building and optimizing your training environments from scratch. Our
    DLCs are thoroughly tested and optimized for deep learning environments, requiring
    no configuration or maintenance on your part. In particular, the Hugging Face
    Inference DLC comes with a pre-written serving stack which drastically lowers
    the technical bar of deep learning serving.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习容器（DLCs）是预先安装有深度学习框架和库的Docker镜像，如🤗 Transformers、🤗 Datasets和🤗 Tokenizers。DLCs允许您立即开始训练模型，跳过从头开始构建和优化训练环境的复杂过程。我们的DLCs经过彻底测试和优化，适用于深度学习环境，无需您进行任何配置或维护。特别是，Hugging
    Face推理DLC配备了一个预先编写的服务堆栈，大大降低了深度学习服务的技术门槛。
- en: 'Our DLCs are available everywhere [Amazon SageMaker](https://aws.amazon.com/sagemaker/)
    is [available](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/).
    While it is possible to use the DLCs without the SageMaker Python SDK, there are
    many advantages to using SageMaker to train your model:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的DLCs在[Amazon SageMaker](https://aws.amazon.com/sagemaker/)可用的任何地方都可用。虽然可以在没有SageMaker
    Python SDK的情况下使用DLCs，但使用SageMaker训练模型有许多优势：
- en: 'Cost-effective: Training instances are only live for the duration of your job.
    Once your job is complete, the training cluster stops, and you won’t be billed
    anymore. SageMaker also supports [Spot instances]((https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html)),
    which can reduce costs up to 90%.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本效益：训练实例仅在作业期间处于活动状态。一旦作业完成，训练集群停止，您将不再收费。SageMaker还支持[Spot实例]((https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html))，可将成本降低高达90%。
- en: 'Built-in automation: SageMaker automatically stores training metadata and logs
    in a serverless managed metastore and fully manages I/O operations with S3 for
    your datasets, checkpoints, and model artifacts.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置自动化：SageMaker自动将训练元数据和日志存储在无服务器托管的元存储中，并完全管理S3的I/O操作，用于您的数据集、检查点和模型工件。
- en: 'Multiple security mechanisms: SageMaker offers [encryption at rest](https://docs.aws.amazon.com/sagemaker/latest/dg/encryption-at-rest-nbi.html),
    [in transit](https://docs.aws.amazon.com/sagemaker/latest/dg/encryption-in-transit.html),
    [Virtual Private Cloud](https://docs.aws.amazon.com/sagemaker/latest/dg/interface-vpc-endpoint.html)
    connectivity, and [Identity and Access Management](https://docs.aws.amazon.com/sagemaker/latest/dg/security_iam_service-with-iam.html)
    to secure your data and code.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多种安全机制：SageMaker提供[静态加密](https://docs.aws.amazon.com/sagemaker/latest/dg/encryption-at-rest-nbi.html)、[传输中加密](https://docs.aws.amazon.com/sagemaker/latest/dg/encryption-in-transit.html)、[虚拟私有云](https://docs.aws.amazon.com/sagemaker/latest/dg/interface-vpc-endpoint.html)连接和[身份和访问管理](https://docs.aws.amazon.com/sagemaker/latest/dg/security_iam_service-with-iam.html)以保护您的数据和代码。
- en: Hugging Face DLCs are open source and licensed under Apache 2.0\. Feel free
    to reach out on our [community forum](https://discuss.huggingface.co/c/sagemaker/17)
    if you have any questions. For premium support, our [Expert Acceleration Program](https://huggingface.co/support)
    gives you direct dedicated support from our team.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face DLCs是开源的，根据Apache 2.0许可。如果您有任何问题，请随时在我们的[社区论坛](https://discuss.huggingface.co/c/sagemaker/17)上联系我们。对于高级支持，我们的[专家加速计划](https://huggingface.co/support)为您提供来自我们团队的直接专门支持。
- en: Features & benefits 🔥
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 功能和优势🔥
- en: 'Hugging Face Deep DLCs make it easier than ever to train Transformer models
    in SageMaker. Here is why you should consider using Hugging Face DLCs to train
    and deploy your next machine learning models:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face Deep DLCs使在SageMaker中训练Transformer模型比以往更容易。以下是您应该考虑使用Hugging Face
    DLCs来训练和部署下一个机器学习模型的原因：
- en: '**One command is all you need**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**只需一条命令**'
- en: With the new Hugging Face DLCs, train cutting-edge Transformers-based NLP models
    in a single line of code. Choose from multiple DLC variants, each one optimized
    for TensorFlow and PyTorch, single-GPU, single-node multi-GPU, and multi-node
    clusters.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的Hugging Face DLCs，在一行代码中训练最先进的基于Transformer的NLP模型。选择多个DLC变体，每个变体都针对TensorFlow和PyTorch进行了优化，包括单GPU、单节点多GPU和多节点集群。
- en: '**Accelerate machine learning from science to production**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速从科学到生产的机器学习**'
- en: In addition to Hugging Face DLCs, we created a first-class Hugging Face extension
    for the SageMaker Python SDK to accelerate data science teams, reducing the time
    required to set up and run experiments from days to minutes.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Hugging Face DLCs，我们还为SageMaker Python SDK创建了一流的Hugging Face扩展，以加速数据科学团队，将设置和运行实验所需的时间从几天缩短到几分钟。
- en: You can use the Hugging Face DLCs with SageMaker’s automatic model tuning to
    optimize your training hyperparameters and increase the accuracy of your models.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Hugging Face DLCs与SageMaker的自动模型调整来优化您的训练超参数，并提高模型的准确性。
- en: Deploy your trained models for inference with just one more line of code or
    select any of the 10,000+ publicly available models from the [model Hub](https://huggingface.co/models)
    and deploy them with SageMaker.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 只需再加一行代码即可将训练好的模型部署到推理中，或者从[模型Hub](https://huggingface.co/models)中选择任何10000多个公开可用的模型，并使用SageMaker部署它们。
- en: Easily track and compare your experiments and training artifacts in SageMaker
    Studio’s web-based integrated development environment (IDE).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker Studio的基于Web的集成开发环境（IDE）中轻松跟踪和比较您的实验和训练工件。
- en: '**Built-in performance**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**内置性能**'
- en: Hugging Face DLCs feature built-in performance optimizations for PyTorch and
    TensorFlow to train NLP models faster. The DLCs also give you the flexibility
    to choose a training infrastructure that best aligns with the price/performance
    ratio for your workload.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face DLCs具有针对PyTorch和TensorFlow的内置性能优化，可加快训练NLP模型的速度。 DLCs还为您提供了灵活性，可以选择最符合您工作负载价格/性能比的训练基础设施。
- en: The Hugging Face Training DLCs are fully integrated with SageMaker distributed
    training libraries to train models faster than ever, using the latest generation
    of instances available on Amazon Elastic Compute Cloud.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face Training DLCs与SageMaker分布式训练库完全集成，可以使用Amazon Elastic Compute Cloud上提供的最新一代实例更快地训练模型。
- en: Hugging Face Inference DLCs provide you with production-ready endpoints that
    scale quickly with your AWS environment, built-in monitoring, and a ton of enterprise
    features.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face推理DLCs为您提供了可快速扩展到AWS环境的生产就绪端点、内置监控和大量企业功能。
- en: '* * *'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Resources, Documentation & Samples 📄
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源、文档和示例 📄
- en: Take a look at our published blog posts, videos, documentation, sample notebooks
    and scripts for additional help and more context about Hugging Face DLCs on SageMaker.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 查看我们发布的博客文章、视频、文档、示例笔记本和脚本，以获取有关Hugging Face DLCs在SageMaker上的更多帮助和更多上下文。
- en: Blogs and videos
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 博客和视频
- en: '[AWS: Embracing natural language processing with Hugging Face](https://aws.amazon.com/de/blogs/opensource/embracing-natural-language-processing-with-hugging-face/)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS：与Hugging Face一起拥抱自然语言处理](https://aws.amazon.com/de/blogs/opensource/embracing-natural-language-processing-with-hugging-face/)'
- en: '[Deploy Hugging Face models easily with Amazon SageMaker](https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Amazon SageMaker轻松部署Hugging Face模型](https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker)'
- en: '[AWS and Hugging Face collaborate to simplify and accelerate adoption of natural
    language processing models](https://aws.amazon.com/blogs/machine-learning/aws-and-hugging-face-collaborate-to-simplify-and-accelerate-adoption-of-natural-language-processing-models/)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS和Hugging Face合作简化和加速自然语言处理模型的采用](https://aws.amazon.com/blogs/machine-learning/aws-and-hugging-face-collaborate-to-simplify-and-accelerate-adoption-of-natural-language-processing-models/)'
- en: '[Walkthrough: End-to-End Text Classification](https://youtu.be/ok3hetb42gU)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[演示：端到端文本分类](https://youtu.be/ok3hetb42gU)'
- en: '[Working with Hugging Face models on Amazon SageMaker](https://youtu.be/leyrCgLAGjMn)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Amazon SageMaker上使用Hugging Face模型](https://youtu.be/leyrCgLAGjMn)'
- en: '[Distributed Training: Train BART/T5 for Summarization using 🤗 Transformers
    and Amazon SageMaker](https://huggingface.co/blog/sagemaker-distributed-training-seq2seq)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分布式训练：使用🤗 Transformers和Amazon SageMaker为摘要训练BART/T5](https://huggingface.co/blog/sagemaker-distributed-training-seq2seq)'
- en: '[Deploy a Hugging Face Transformers Model from S3 to Amazon SageMaker](https://youtu.be/pfBGgSGnYLs)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将Hugging Face Transformers模型从S3部署到Amazon SageMaker](https://youtu.be/pfBGgSGnYLs)'
- en: '[Deploy a Hugging Face Transformers Model from the Model Hub to Amazon SageMaker](https://youtu.be/l9QZuazbzWM)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将Hugging Face Transformers模型从模型中心部署到Amazon SageMaker](https://youtu.be/l9QZuazbzWM)'
- en: Documentation
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文档
- en: '[Run training on Amazon SageMaker](/docs/sagemaker/train)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Amazon SageMaker上运行训练](/docs/sagemaker/train)'
- en: '[Deploy models to Amazon SageMaker](/docs/sagemaker/inference)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将模型部署到Amazon SageMaker](/docs/sagemaker/inference)'
- en: '[Reference](/docs/sagemaker/reference)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[参考资料](/docs/sagemaker/reference)'
- en: '[Amazon SageMaker documentation for Hugging Face](https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hugging Face的Amazon SageMaker文档](https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html)'
- en: '[Python SDK SageMaker documentation for Hugging Face](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hugging Face的Python SDK SageMaker文档](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html)'
- en: '[Deep Learning Container](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-training-containers)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习容器](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-training-containers)'
- en: '[SageMaker’s Distributed Data Parallel Library](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker的分布式数据并行库](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html)'
- en: '[SageMaker’s Distributed Model Parallel Library](https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker的分布式模型并行库](https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel.html)'
- en: Sample notebooks
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例笔记本
- en: '[All notebooks](https://github.com/huggingface/notebooks/tree/master/sagemaker)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[所有笔记本](https://github.com/huggingface/notebooks/tree/master/sagemaker)'
- en: '[Getting Started with Pytorch](https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/sagemaker-notebook.ipynb)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Pytorch入门](https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/sagemaker-notebook.ipynb)'
- en: '[Getting Started with Tensorflow](https://github.com/huggingface/notebooks/blob/main/sagemaker/02_getting_started_tensorflow/sagemaker-notebook.ipynb)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Tensorflow入门](https://github.com/huggingface/notebooks/blob/main/sagemaker/02_getting_started_tensorflow/sagemaker-notebook.ipynb)'
- en: '[Distributed Training Data Parallelism](https://github.com/huggingface/notebooks/blob/main/sagemaker/03_distributed_training_data_parallelism/sagemaker-notebook.ipynb)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分布式训练数据并行性](https://github.com/huggingface/notebooks/blob/main/sagemaker/03_distributed_training_data_parallelism/sagemaker-notebook.ipynb)'
- en: '[Distributed Training Model Parallelism](https://github.com/huggingface/notebooks/blob/main/sagemaker/04_distributed_training_model_parallelism/sagemaker-notebook.ipynb)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分布式训练模型并行性](https://github.com/huggingface/notebooks/blob/main/sagemaker/04_distributed_training_model_parallelism/sagemaker-notebook.ipynb)'
- en: '[Spot Instances and continue training](https://github.com/huggingface/notebooks/blob/main/sagemaker/05_spot_instances/sagemaker-notebook.ipynb)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用折扣实例继续训练](https://github.com/huggingface/notebooks/blob/main/sagemaker/05_spot_instances/sagemaker-notebook.ipynb)'
- en: '[SageMaker Metrics](https://github.com/huggingface/notebooks/blob/main/sagemaker/06_sagemaker_metrics/sagemaker-notebook.ipynb)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker指标](https://github.com/huggingface/notebooks/blob/main/sagemaker/06_sagemaker_metrics/sagemaker-notebook.ipynb)'
- en: '[Distributed Training Data Parallelism Tensorflow](https://github.com/huggingface/notebooks/blob/main/sagemaker/07_tensorflow_distributed_training_data_parallelism/sagemaker-notebook.ipynb)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Tensorflow的分布式训练数据并行性](https://github.com/huggingface/notebooks/blob/main/sagemaker/07_tensorflow_distributed_training_data_parallelism/sagemaker-notebook.ipynb)'
- en: '[Distributed Training Summarization](https://github.com/huggingface/notebooks/blob/main/sagemaker/08_distributed_summarization_bart_t5/sagemaker-notebook.ipynb)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分布式训练摘要](https://github.com/huggingface/notebooks/blob/main/sagemaker/08_distributed_summarization_bart_t5/sagemaker-notebook.ipynb)'
- en: '[Image Classification with Vision Transformer](https://github.com/huggingface/notebooks/blob/main/sagemaker/09_image_classification_vision_transformer/sagemaker-notebook.ipynb)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Vision Transformer 进行图像分类](https://github.com/huggingface/notebooks/blob/main/sagemaker/09_image_classification_vision_transformer/sagemaker-notebook.ipynb)'
- en: '[Deploy one of the 10 000+ Hugging Face Transformers to Amazon SageMaker for
    Inference](https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将 10,000 多个 Hugging Face Transformers 之一部署到 Amazon SageMaker 进行推理](https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb)'
- en: '[Deploy a Hugging Face Transformer model from S3 to SageMaker for inference](https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将 Hugging Face Transformer 模型从 S3 部署到 SageMaker 进行推理](https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb)'
