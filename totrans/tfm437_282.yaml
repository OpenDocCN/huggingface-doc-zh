- en: RegNet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RegNet
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/regnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/regnet)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/regnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/regnet)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: The RegNet model was proposed in [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)
    by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr DollÃ¡r.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: RegNetæ¨¡å‹æ˜¯ç”±Ilija Radosavovicã€Raj Prateek Kosarajuã€Ross Girshickã€Kaiming Heã€Piotr
    DollÃ¡råœ¨[è®¾è®¡ç½‘ç»œè®¾è®¡ç©ºé—´](https://arxiv.org/abs/2003.13678)ä¸­æå‡ºçš„ã€‚
- en: The authors design search spaces to perform Neural Architecture Search (NAS).
    They first start from a high dimensional search space and iteratively reduce the
    search space by empirically applying constraints based on the best-performing
    models sampled by the current search space.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…è®¾è®¡äº†æœç´¢ç©ºé—´æ¥æ‰§è¡Œç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰ã€‚ä»–ä»¬é¦–å…ˆä»é«˜ç»´æœç´¢ç©ºé—´å¼€å§‹ï¼Œå¹¶é€šè¿‡æ ¹æ®å½“å‰æœç´¢ç©ºé—´é‡‡æ ·çš„è¡¨ç°æœ€ä½³æ¨¡å‹ç»éªŒæ€§åœ°åº”ç”¨çº¦æŸæ¥è¿­ä»£åœ°å‡å°‘æœç´¢ç©ºé—´ã€‚
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š
- en: '*In this work, we present a new network design paradigm. Our goal is to help
    advance the understanding of network design and discover design principles that
    generalize across settings. Instead of focusing on designing individual network
    instances, we design network design spaces that parametrize populations of networks.
    The overall process is analogous to classic manual design of networks, but elevated
    to the design space level. Using our methodology we explore the structure aspect
    of network design and arrive at a low-dimensional design space consisting of simple,
    regular networks that we call RegNet. The core insight of the RegNet parametrization
    is surprisingly simple: widths and depths of good networks can be explained by
    a quantized linear function. We analyze the RegNet design space and arrive at
    interesting findings that do not match the current practice of network design.
    The RegNet design space provides simple and fast networks that work well across
    a wide range of flop regimes. Under comparable training settings and flops, the
    RegNet models outperform the popular EfficientNet models while being up to 5x
    faster on GPUs.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç½‘ç»œè®¾è®¡èŒƒå¼ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ¨åŠ¨å¯¹ç½‘ç»œè®¾è®¡çš„ç†è§£ï¼Œå¹¶å‘ç°å¯ä»¥åœ¨å„ç§è®¾ç½®ä¸­æ¨å¹¿çš„è®¾è®¡åŸåˆ™ã€‚æˆ‘ä»¬ä¸å†ä¸“æ³¨äºè®¾è®¡å•ä¸ªç½‘ç»œå®ä¾‹ï¼Œè€Œæ˜¯è®¾è®¡å¯ä»¥å‚æ•°åŒ–ç½‘ç»œç¾¤ä½“çš„ç½‘ç»œè®¾è®¡ç©ºé—´ã€‚æ•´ä¸ªè¿‡ç¨‹ç±»ä¼¼äºç»å…¸æ‰‹åŠ¨è®¾è®¡ç½‘ç»œï¼Œä½†æå‡åˆ°è®¾è®¡ç©ºé—´çº§åˆ«ã€‚ä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬æ¢ç´¢ç½‘ç»œè®¾è®¡çš„ç»“æ„æ–¹é¢ï¼Œå¹¶å¾—å‡ºä¸€ä¸ªç”±ç®€å•ã€è§„åˆ™ç½‘ç»œç»„æˆçš„ä½ç»´è®¾è®¡ç©ºé—´ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºRegNetã€‚RegNetå‚æ•°åŒ–çš„æ ¸å¿ƒè§è§£ä»¤äººæƒŠè®¶ç®€å•ï¼šå¥½ç½‘ç»œçš„å®½åº¦å’Œæ·±åº¦å¯ä»¥ç”¨é‡åŒ–çš„çº¿æ€§å‡½æ•°è§£é‡Šã€‚æˆ‘ä»¬åˆ†æäº†RegNetè®¾è®¡ç©ºé—´ï¼Œå¹¶å¾—å‡ºäº†ä¸å½“å‰ç½‘ç»œè®¾è®¡å®è·µä¸ç¬¦çš„æœ‰è¶£å‘ç°ã€‚åœ¨å¯æ¯”çš„è®­ç»ƒè®¾ç½®å’Œflopsä¸‹ï¼ŒRegNetæ¨¡å‹åœ¨GPUä¸Šæ¯”æµè¡Œçš„EfficientNetæ¨¡å‹è¡¨ç°æ›´å¥½ï¼ŒåŒæ—¶é€Ÿåº¦æé«˜äº†å¤šè¾¾5å€ã€‚*'
- en: This model was contributed by [Francesco](https://huggingface.co/Francesco).
    The TensorFlow version of the model was contributed by [sayakpaul](https://huggingface.co/sayakpaul)
    and [ariG23498](https://huggingface.co/ariG23498). The original code can be found
    [here](https://github.com/facebookresearch/pycls).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹æ˜¯ç”±[Francesco](https://huggingface.co/Francesco)è´¡çŒ®çš„ã€‚æ¨¡å‹çš„TensorFlowç‰ˆæœ¬æ˜¯ç”±[sayakpaul](https://huggingface.co/sayakpaul)å’Œ[ariG23498](https://huggingface.co/ariG23498)è´¡çŒ®çš„ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/facebookresearch/pycls)æ‰¾åˆ°ã€‚
- en: The huge 10B model from [Self-supervised Pretraining of Visual Features in the
    Wild](https://arxiv.org/abs/2103.01988), trained on one billion Instagram images,
    is available on the [hub](https://huggingface.co/facebook/regnet-y-10b-seer)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ª[é‡å¤–è‡ªç›‘ç£è§†è§‰ç‰¹å¾é¢„è®­ç»ƒ](https://arxiv.org/abs/2103.01988)çš„å·¨å¤§10Bæ¨¡å‹ï¼Œè®­ç»ƒäº†10äº¿å¼ Instagramå›¾ç‰‡ï¼Œå¯åœ¨[hub](https://huggingface.co/facebook/regnet-y-10b-seer)ä¸Šæ‰¾åˆ°
- en: Resources
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èµ„æº
- en: A list of official Hugging Face and community (indicated by ğŸŒ) resources to
    help you get started with RegNet.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€äº›å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºåˆ—è¡¨ï¼Œå¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨RegNetã€‚
- en: Image Classification
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒåˆ†ç±»
- en: '[RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)ç”±è¿™ä¸ª[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)æ”¯æŒã€‚'
- en: 'See also: [Image classification task guide](../tasks/image_classification)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦è¯·å‚é˜…ï¼š[å›¾åƒåˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/image_classification)
- en: If youâ€™re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and weâ€™ll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æå‡ºæ‹‰å–è¯·æ±‚ï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥ç†æƒ³åœ°å±•ç¤ºä¸€äº›æ–°å†…å®¹ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚
- en: RegNetConfig
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RegNetConfig
- en: '### `class transformers.RegNetConfig`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RegNetConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/configuration_regnet.py#L28)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/configuration_regnet.py#L28)'
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`num_channels` (`int`, *optional*, defaults to 3) â€” The number of input channels.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *å¯é€‰*, é»˜è®¤ä¸º3) â€” è¾“å…¥é€šé“çš„æ•°é‡ã€‚'
- en: '`embedding_size` (`int`, *optional*, defaults to 64) â€” Dimensionality (hidden
    size) for the embedding layer.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_size` (`int`, *å¯é€‰*, é»˜è®¤ä¸º64) â€” åµŒå…¥å±‚çš„ç»´åº¦ï¼ˆéšè—å¤§å°ï¼‰ã€‚'
- en: '`hidden_sizes` (`List[int]`, *optional*, defaults to `[256, 512, 1024, 2048]`)
    â€” Dimensionality (hidden size) at each stage.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_sizes` (`List[int]`, *å¯é€‰*, é»˜è®¤ä¸º`[256, 512, 1024, 2048]`) â€” æ¯ä¸ªé˜¶æ®µçš„ç»´åº¦ï¼ˆéšè—å¤§å°ï¼‰ã€‚'
- en: '`depths` (`List[int]`, *optional*, defaults to `[3, 4, 6, 3]`) â€” Depth (number
    of layers) for each stage.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depths` (`List[int]`, *å¯é€‰*, é»˜è®¤ä¸º`[3, 4, 6, 3]`) â€” æ¯ä¸ªé˜¶æ®µçš„æ·±åº¦ï¼ˆå±‚æ•°ï¼‰ã€‚'
- en: '`layer_type` (`str`, *optional*, defaults to `"y"`) â€” The layer to use, it
    can be either `"x" or` â€œyâ€`. An` x`layer is a ResNet''s BottleNeck layer with`reduction`fixed
    to`1`. While a` y`layer is a`x` but with squeeze and excitation. Please refer
    to the paper for a detailed explanation of how these layers were constructed.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_type` (`str`, *optional*, é»˜è®¤ä¸º`"y"`) â€” è¦ä½¿ç”¨çš„å±‚ï¼Œå¯ä»¥æ˜¯`"x"`æˆ–`"y"`ã€‚`x`å±‚æ˜¯ResNetçš„BottleNeckå±‚ï¼Œ`reduction`å›ºå®šä¸º`1`ã€‚è€Œ`y`å±‚æ˜¯`x`å±‚ï¼Œä½†å¸¦æœ‰squeezeå’Œexcitationã€‚è¯·å‚è€ƒè®ºæ–‡ä»¥è·å–è¿™äº›å±‚æ˜¯å¦‚ä½•æ„å»ºçš„è¯¦ç»†è§£é‡Šã€‚'
- en: '`hidden_act` (`str`, *optional*, defaults to `"relu"`) â€” The non-linear activation
    function in each block. If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"`
    are supported.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str`, *optional*, é»˜è®¤ä¸º`"relu"`) â€” æ¯ä¸ªå—ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ`"gelu"`ã€`"relu"`ã€`"selu"`å’Œ`"gelu_new"`ã€‚'
- en: '`downsample_in_first_stage` (`bool`, *optional*, defaults to `False`) â€” If
    `True`, the first stage will downsample the inputs using a `stride` of 2.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`downsample_in_first_stage` (`bool`, *optional*, é»˜è®¤ä¸º`False`) â€” å¦‚æœä¸º`True`ï¼Œç¬¬ä¸€é˜¶æ®µå°†ä½¿ç”¨`stride`ä¸º2å¯¹è¾“å…¥è¿›è¡Œä¸‹é‡‡æ ·ã€‚'
- en: This is the configuration class to store the configuration of a [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel).
    It is used to instantiate a RegNet model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the RegNet [facebook/regnet-y-040](https://huggingface.co/facebook/regnet-y-040)
    architecture.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯é…ç½®ç±»ï¼Œç”¨äºå­˜å‚¨[RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)çš„é…ç½®ã€‚æ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–RegNetæ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äºRegNet
    [facebook/regnet-y-040](https://huggingface.co/facebook/regnet-y-040)æ¶æ„çš„é…ç½®ã€‚
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚
- en: 'Example:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: PytorchHide Pytorch content
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch content
- en: RegNetModel
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RegNetModel
- en: '### `class transformers.RegNetModel`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RegNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L321)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L321)'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare RegNet model outputting raw features without any specific head on top.
    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matters related to general usage and behavior.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸çš„RegNetæ¨¡å‹è¾“å‡ºåŸå§‹ç‰¹å¾ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚è¿™ä¸ªæ¨¡å‹æ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰äº‹é¡¹ã€‚
- en: '#### `forward`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L336)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L336)'
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚'
- en: Returns
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention` or
    `tuple(torch.FloatTensor)`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention`æˆ–`tuple(torch.FloatTensor)`'
- en: A `transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention` or
    a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    and inputs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention`æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–å½“`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) â€” Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    â€” Last layer hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, hidden_size)`ï¼‰ â€” åœ¨ç©ºé—´ç»´åº¦ä¸Šè¿›è¡Œæ± åŒ–æ“ä½œåçš„æœ€åä¸€å±‚éšè—çŠ¶æ€ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, num_channels, height,
    width)`.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`ï¼Œ*optional*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–å½“`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰
    â€” å½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`å…ƒç»„ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚ '
- en: The [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ–¹æ³•éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹è€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: RegNetForImageClassification
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RegNetForImageClassification
- en: '### `class transformers.RegNetForImageClassification`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RegNetForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L372)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L372)'
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)ï¼‰
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: RegNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é¡¶éƒ¨å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´éƒ¨çš„RegNetæ¨¡å‹ï¼ˆåœ¨æ± åŒ–ç‰¹å¾çš„é¡¶éƒ¨æœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºImageNetã€‚
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matters related to general usage and behavior.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹æ˜¯PyTorchçš„[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ä¿¡æ¯ã€‚
- en: '#### `forward`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L393)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L393)'
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height,
    width)`ï¼‰ â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) â€” Labels
    for computing the image classification/regression loss. Indices should be in `[0,
    ..., config.num_labels - 1]`. If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size,)`ï¼Œ*optional*) â€” ç”¨äºè®¡ç®—å›¾åƒåˆ†ç±»/å›å½’æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[0,
    ..., config.num_labels - 1]`èŒƒå›´å†…ã€‚å¦‚æœ`config.num_labels > 1`ï¼Œåˆ™è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰ã€‚'
- en: Returns
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)
    or `tuple(torch.FloatTensor)`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    and inputs.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–å½“`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) â€” Classification (or regression if config.num_labels==1) loss.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(1,)`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›) â€” åˆ†ç±»ï¼ˆå¦‚æœ`config.num_labels==1`åˆ™ä¸ºå›å½’ï¼‰æŸå¤±ã€‚'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) â€”
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`) â€” åˆ†ç±»ï¼ˆå¦‚æœ`config.num_labels==1`åˆ™ä¸ºå›å½’ï¼‰å¾—åˆ†ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each stage) of shape `(batch_size, num_channels, height,
    width)`. Hidden-states (also called feature maps) of the model at the output of
    each stage.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–å½“`config.output_hidden_states=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º
    + æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼‰ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µè¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚'
- en: The [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨è¿™ä¸ªå‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªå‡½æ•°ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: TensorFlowHide TensorFlow content
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowéšè—TensorFlowå†…å®¹
- en: TFRegNetModel
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFRegNetModel
- en: '### `class transformers.TFRegNetModel`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFRegNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L483)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L483)'
- en: '[PRE8]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: The bare RegNet model outputting raw features without any specific head on top.
    This model is a Tensorflow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)
    sub-class. Use it as a regular Tensorflow Module and refer to the Tensorflow documentation
    for all matter related to general usage and behavior.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸çš„RegNetæ¨¡å‹è¾“å‡ºåŸå§‹ç‰¹å¾ï¼Œæ²¡æœ‰ç‰¹å®šçš„å¤´éƒ¨ã€‚è¿™ä¸ªæ¨¡å‹æ˜¯ä¸€ä¸ªTensorflow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„Tensorflowæ¨¡å—ï¼Œå¹¶å‚è€ƒTensorflowæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ä¿¡æ¯ã€‚
- en: '#### `call`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L492)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L492)'
- en: '[PRE9]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See `ConveNextImageProcessor.__call__` for details.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`)
    â€” åƒç´ å€¼ã€‚åƒç´ å€¼å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…`ConveNextImageProcessor.__call__`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šçš„å…ƒç»„ã€‚'
- en: Returns
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    or `tuple(tf.Tensor)`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    æˆ– `tuple(tf.Tensor)`'
- en: A `transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    and inputs.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–å½“`config.return_dict=False`æ—¶ï¼‰åŒ…å«å„ç§å…ƒç´ ï¼Œå–å†³äºé…ç½®ï¼ˆ[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)ï¼‰å’Œè¾“å…¥ã€‚
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, num_channels, height,
    width)`) â€” Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`)
    â€” æ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`pooler_output` (`tf.Tensor` of shape `(batch_size, hidden_size)`) â€” Last layer
    hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, hidden_size)`) â€” ç©ºé—´ç»´åº¦ä¸Šè¿›è¡Œæ± åŒ–æ“ä½œåçš„æœ€åä¸€å±‚éšè—çŠ¶æ€ã€‚'
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings, if the model has an embedding layer, + one for
    the output of each layer) of shape `(batch_size, num_channels, height, width)`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–å½“`config.output_hidden_states=True`æ—¶è¿”å›)
    â€” å½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`çš„`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º+æ¯ä¸ªå±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºå¤„çš„éšè—çŠ¶æ€ä»¥åŠå¯é€‰çš„åˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: The [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„é…æ–¹éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE10]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: TFRegNetForImageClassification
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFRegNetForImageClassification
- en: '### `class transformers.TFRegNetForImageClassification`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFRegNetForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L537)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L537)'
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)ï¼‰
    â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: RegNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é¡¶éƒ¨å¸¦æœ‰å›¾åƒåˆ†ç±»å¤´éƒ¨çš„RegNetæ¨¡å‹ï¼ˆåœ¨æ± åŒ–ç‰¹å¾çš„é¡¶éƒ¨æ˜¯ä¸€ä¸ªçº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºImageNetã€‚
- en: This model is a Tensorflow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)
    sub-class. Use it as a regular Tensorflow Module and refer to the Tensorflow documentation
    for all matter related to general usage and behavior.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹æ˜¯ä¸€ä¸ªTensorflow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„Tensorflowæ¨¡å—ï¼Œå¹¶å‚è€ƒTensorflowæ–‡æ¡£ä»¥è·å–æ‰€æœ‰ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„äº‹é¡¹ã€‚
- en: '#### `call`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L555)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L555)'
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    â€” Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See `ConveNextImageProcessor.__call__` for details.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`)
    â€” åƒç´ å€¼ã€‚å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–åƒç´ å€¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…`ConveNextImageProcessor.__call__`ã€‚'
- en: '`output_hidden_states` (`bool`, *optional*) â€” Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚'
- en: '`return_dict` (`bool`, *optional*) â€” Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›ä¸€ä¸ª[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯ä¸€ä¸ªæ™®é€šå…ƒç»„ã€‚'
- en: '`labels` (`tf.Tensor` of shape `(batch_size,)`, *optional*) â€” Labels for computing
    the image classification/regression loss. Indices should be in `[0, ..., config.num_labels
    - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size,)`ï¼Œ*å¯é€‰*) â€” ç”¨äºè®¡ç®—å›¾åƒåˆ†ç±»/å›å½’æŸå¤±çš„æ ‡ç­¾ã€‚ç´¢å¼•åº”åœ¨`[0,
    ..., config.num_labels - 1]`èŒƒå›´å†…ã€‚å¦‚æœ`config.num_labels > 1`ï¼Œåˆ™è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰ã€‚'
- en: Returns
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)æˆ–`tuple(tf.Tensor)`'
- en: A [transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    and inputs.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)æˆ–ä¸€ä¸ª`tf.Tensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–å½“`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚
- en: '`loss` (`tf.Tensor` of shape `(batch_size, )`, *optional*, returned when `labels`
    is provided) â€” Classification (or regression if config.num_labels==1) loss.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, )`ï¼Œ*å¯é€‰*ï¼Œå½“æä¾›`labels`æ—¶è¿”å›) â€” åˆ†ç±»ï¼ˆæˆ–å›å½’ï¼Œå¦‚æœ`config.num_labels==1`ï¼‰æŸå¤±ã€‚'
- en: '`logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`) â€” Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`tf.Tensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`) â€” åˆ†ç±»ï¼ˆæˆ–å›å½’ï¼Œå¦‚æœ`config.num_labels==1`ï¼‰å¾—åˆ†ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–å½“`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`tf.Tensor`å…ƒç»„ï¼ˆç”¨äºåµŒå…¥è¾“å‡ºå’Œæ¯å±‚è¾“å‡ºå„ä¸€ä¸ªï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚è¾“å‡ºå¤„çš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`ï¼ˆ`tuple(tf.Tensor)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–å½“`config.output_attentions=True`æ—¶è¿”å›ï¼‰-
    å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`tf.Tensor`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è‡ªæ³¨æ„åŠ›å¤´ä¸­ä½¿ç”¨æ³¨æ„åŠ›softmaxåçš„æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè®¡ç®—åŠ æƒå¹³å‡å€¼ã€‚
- en: The [TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)å‰å‘æ–¹æ³•ï¼Œè¦†ç›–`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: JAXHide JAX content
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: JAXHide JAX content
- en: FlaxRegNetModel
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxRegNetModel
- en: '### `class transformers.FlaxRegNetModel`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxRegNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L686)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L686)'
- en: '[PRE14]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`ï¼ˆ[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)ï¼‰-
    æ¨¡å‹çš„æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) â€”
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype`ï¼ˆ`jax.numpy.dtype`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`jax.numpy.float32`ï¼‰- è®¡ç®—çš„æ•°æ®ç±»å‹ã€‚å¯ä»¥æ˜¯`jax.numpy.float32`ã€`jax.numpy.float16`ï¼ˆåœ¨GPUä¸Šï¼‰å’Œ`jax.numpy.bfloat16`ï¼ˆåœ¨TPUä¸Šï¼‰ä¹‹ä¸€ã€‚'
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified all the computation will be performed with the given
    `dtype`.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥ç”¨äºåœ¨GPUæˆ–TPUä¸Šå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒæˆ–åŠç²¾åº¦æ¨æ–­ã€‚å¦‚æœæŒ‡å®šäº†ï¼Œæ‰€æœ‰è®¡ç®—å°†ä½¿ç”¨ç»™å®šçš„`dtype`æ‰§è¡Œã€‚
- en: '`Note that this only specifies the dtype of the computation and does not influence
    the dtype of model parameters.`'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`è¯·æ³¨æ„ï¼Œè¿™ä»…æŒ‡å®šè®¡ç®—çš„æ•°æ®ç±»å‹ï¼Œä¸å½±å“æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹ã€‚`'
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å¸Œæœ›æ›´æ”¹æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹ï¼Œè¯·å‚é˜…[to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)å’Œ[to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)ã€‚
- en: The bare RegNet model outputting raw features without any specific head on top.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: è£¸çš„RegNetæ¨¡å‹è¾“å‡ºåŸå§‹ç‰¹å¾ï¼Œæ²¡æœ‰ä»»ä½•ç‰¹å®šçš„å¤´éƒ¨ã€‚
- en: This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading, saving and converting weights from PyTorch
    models)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª[FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ï¼Œäº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½ã€ä¿å­˜å’Œä»PyTorchæ¨¡å‹è½¬æ¢æƒé‡ï¼‰ã€‚
- en: This model is also a [flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)
    subclass. Use it as a regular Flax linen Module and refer to the Flax documentation
    for all matter related to general usage and behavior.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ª[flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„Flax
    linenæ¨¡å—ï¼Œå¹¶å‚è€ƒFlaxæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚
- en: 'Finally, this model supports inherent JAX features such as:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œè¿™ä¸ªæ¨¡å‹æ”¯æŒJAXçš„å›ºæœ‰ç‰¹æ€§ï¼Œæ¯”å¦‚ï¼š
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å³æ—¶ï¼ˆJITï¼‰ç¼–è¯‘](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è‡ªåŠ¨å¾®åˆ†](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[çŸ¢é‡åŒ–](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å¹¶è¡ŒåŒ–](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L597)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L597)'
- en: '[PRE15]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Returns
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling)
    or `tuple(torch.FloatTensor)`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling)æˆ–`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.regnet.configuration_regnet.RegNetConfig'>`)
    and inputs.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling)æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ`<class
    ''transformers.models.regnet.configuration_regnet.RegNetConfig''>`ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚'
- en: '`last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`) â€” Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`jnp.ndarray`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`)
    â€” æ¨¡å‹æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚'
- en: '`pooler_output` (`jnp.ndarray` of shape `(batch_size, hidden_size)`) â€” Last
    layer hidden-state of the first token of the sequence (classification token) further
    processed by a Linear layer and a Tanh activation function. The Linear layer weights
    are trained from the next sentence prediction (classification) objective during
    pretraining.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`jnp.ndarray`ï¼Œå½¢çŠ¶ä¸º`(batch_size, hidden_size)`) â€” åºåˆ—ç¬¬ä¸€ä¸ªæ ‡è®°ï¼ˆåˆ†ç±»æ ‡è®°ï¼‰çš„æœ€åä¸€å±‚éšè—çŠ¶æ€ï¼Œè¿›ä¸€æ­¥ç”±çº¿æ€§å±‚å’ŒTanhæ¿€æ´»å‡½æ•°å¤„ç†ã€‚çº¿æ€§å±‚çš„æƒé‡æ˜¯åœ¨é¢„è®­ç»ƒæœŸé—´ä»ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹ï¼ˆåˆ†ç±»ï¼‰ç›®æ ‡ä¸­è®­ç»ƒçš„ã€‚'
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) â€” Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(jnp.ndarray)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›ï¼‰
    â€” å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`jnp.ndarray`å…ƒç»„ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥è¾“å‡ºï¼Œä¸€ä¸ªç”¨äºæ¯ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨æ¯ä¸€å±‚çš„è¾“å‡ºéšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚
- en: '`attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) â€” Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(jnp.ndarray)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›ï¼‰
    â€” å½¢çŠ¶ä¸º`(batch_size, num_heads, sequence_length, sequence_length)`çš„`jnp.ndarray`å…ƒç»„ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„åŠ›æƒé‡åœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The `FlaxRegNetPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`FlaxRegNetPreTrainedModel`çš„å‰å‘æ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªï¼Œå› ä¸ºå‰è€…ä¼šå¤„ç†è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Examples:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE16]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: FlaxRegNetForImageClassification
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxRegNetForImageClassification
- en: '### `class transformers.FlaxRegNetForImageClassification`'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxRegNetForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L776)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L776)'
- en: '[PRE17]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    â€” Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼Œåªä¼šåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) â€”
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jax.numpy.dtype`, *å¯é€‰*, é»˜è®¤ä¸º `jax.numpy.float32`) â€” è®¡ç®—çš„æ•°æ®ç±»å‹ã€‚å¯ä»¥æ˜¯`jax.numpy.float32`ã€`jax.numpy.float16`ï¼ˆåœ¨GPUä¸Šï¼‰å’Œ`jax.numpy.bfloat16`ï¼ˆåœ¨TPUä¸Šï¼‰ä¹‹ä¸€ã€‚'
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified all the computation will be performed with the given
    `dtype`.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥ç”¨äºåœ¨GPUæˆ–TPUä¸Šå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒæˆ–åŠç²¾åº¦æ¨æ–­ã€‚å¦‚æœæŒ‡å®šäº†ï¼Œæ‰€æœ‰è®¡ç®—å°†ä½¿ç”¨ç»™å®šçš„`dtype`æ‰§è¡Œã€‚
- en: '`Note that this only specifies the dtype of the computation and does not influence
    the dtype of model parameters.`'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`è¯·æ³¨æ„ï¼Œè¿™ä»…æŒ‡å®šè®¡ç®—çš„æ•°æ®ç±»å‹ï¼Œä¸å½±å“æ¨¡å‹å‚æ•°çš„æ•°æ®ç±»å‹ã€‚`'
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨å¸Œæœ›æ›´æ”¹æ¨¡å‹å‚æ•°çš„dtypeï¼Œè¯·å‚é˜…[to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)å’Œ[to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)ã€‚
- en: RegNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é¡¶éƒ¨æ·»åŠ ä¸€ä¸ªå›¾åƒåˆ†ç±»å¤´çš„RegNetæ¨¡å‹ï¼ˆåœ¨æ± åŒ–ç‰¹å¾çš„é¡¶éƒ¨æ·»åŠ ä¸€ä¸ªçº¿æ€§å±‚ï¼‰ï¼Œä¾‹å¦‚ç”¨äºImageNetã€‚
- en: This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading, saving and converting weights from PyTorch
    models)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª[FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ä»¥äº†è§£åº“å®ç°çš„æ‰€æœ‰æ¨¡å‹çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä»PyTorchæ¨¡å‹ä¸‹è½½ã€ä¿å­˜å’Œè½¬æ¢æƒé‡ï¼‰ã€‚
- en: This model is also a [flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)
    subclass. Use it as a regular Flax linen Module and refer to the Flax documentation
    for all matter related to general usage and behavior.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ª[flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„Flax
    linenæ¨¡å—ï¼Œå¹¶å‚è€ƒFlaxæ–‡æ¡£ä»¥äº†è§£æ‰€æœ‰ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„äº‹é¡¹ã€‚
- en: 'Finally, this model supports inherent JAX features such as:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œè¿™ä¸ªæ¨¡å‹æ”¯æŒå†…åœ¨çš„JAXç‰¹æ€§ï¼Œæ¯”å¦‚ï¼š
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å³æ—¶ï¼ˆJITï¼‰ç¼–è¯‘](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è‡ªåŠ¨å¾®åˆ†](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å‘é‡åŒ–](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å¹¶è¡ŒåŒ–](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L597)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L597)'
- en: '[PRE18]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Returns
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›
- en: '`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    or `tuple(torch.FloatTensor)`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`æˆ–`tuple(torch.FloatTensor)`'
- en: A `transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.regnet.configuration_regnet.RegNetConfig'>`)
    and inputs.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–`config.return_dict=False`æ—¶ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ`<class
    'transformers.models.regnet.configuration_regnet.RegNetConfig'>`ï¼‰å’Œè¾“å…¥çš„ä¸åŒå…ƒç´ ã€‚
- en: '`logits` (`jnp.ndarray` of shape `(batch_size, config.num_labels)`) â€” Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`ï¼ˆå½¢çŠ¶ä¸º`(batch_size, config.num_labels)`çš„`jnp.ndarray`ï¼‰â€”åˆ†ç±»ï¼ˆå¦‚æœ`config.num_labels==1`åˆ™ä¸ºå›å½’ï¼‰å¾—åˆ†ï¼ˆSoftMaxä¹‹å‰ï¼‰ã€‚'
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`ï¼ˆ`tuple(jnp.ndarray)`ï¼Œ*å¯é€‰*ï¼Œå½“ä¼ é€’`output_hidden_states=True`æˆ–'
- en: '`config.output_hidden_states=True):` Tuple of `jnp.ndarray` (one for the output
    of the embeddings, if the model has an embedding layer, + one for the output of
    each stage) of shape `(batch_size, num_channels, height, width)`. Hidden-states
    (also called feature maps) of the model at the output of each stage.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config.output_hidden_states=True):` å½¢çŠ¶ä¸º`(batch_size, num_channels, height,
    width)`çš„`jnp.ndarray`å…ƒç»„ï¼ˆå¦‚æœæ¨¡å‹æœ‰åµŒå…¥å±‚ï¼Œåˆ™ä¸ºåµŒå…¥çš„è¾“å‡º+æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼‰ã€‚æ¨¡å‹åœ¨æ¯ä¸ªé˜¶æ®µè¾“å‡ºçš„éšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾å›¾ï¼‰ã€‚'
- en: The `FlaxRegNetPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`FlaxRegNetPreTrainedModel`çš„å‰å‘æ–¹æ³•è¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å‰å‘ä¼ é€’çš„æ­¥éª¤éœ€è¦åœ¨è¿™ä¸ªå‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯è¿™ä¸ªå‡½æ•°ï¼Œå› ä¸ºå‰è€…ä¼šè´Ÿè´£è¿è¡Œå‰åå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚
- en: 'Example:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE19]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
