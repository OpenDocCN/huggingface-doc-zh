- en: RegNet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RegNet
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/regnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/regnet)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/regnet](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/regnet)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The RegNet model was proposed in [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)
    by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Dollár.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: RegNet模型是由Ilija Radosavovic、Raj Prateek Kosaraju、Ross Girshick、Kaiming He、Piotr
    Dollár在[设计网络设计空间](https://arxiv.org/abs/2003.13678)中提出的。
- en: The authors design search spaces to perform Neural Architecture Search (NAS).
    They first start from a high dimensional search space and iteratively reduce the
    search space by empirically applying constraints based on the best-performing
    models sampled by the current search space.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 作者设计了搜索空间来执行神经架构搜索（NAS）。他们首先从高维搜索空间开始，并通过根据当前搜索空间采样的表现最佳模型经验性地应用约束来迭代地减少搜索空间。
- en: 'The abstract from the paper is the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*In this work, we present a new network design paradigm. Our goal is to help
    advance the understanding of network design and discover design principles that
    generalize across settings. Instead of focusing on designing individual network
    instances, we design network design spaces that parametrize populations of networks.
    The overall process is analogous to classic manual design of networks, but elevated
    to the design space level. Using our methodology we explore the structure aspect
    of network design and arrive at a low-dimensional design space consisting of simple,
    regular networks that we call RegNet. The core insight of the RegNet parametrization
    is surprisingly simple: widths and depths of good networks can be explained by
    a quantized linear function. We analyze the RegNet design space and arrive at
    interesting findings that do not match the current practice of network design.
    The RegNet design space provides simple and fast networks that work well across
    a wide range of flop regimes. Under comparable training settings and flops, the
    RegNet models outperform the popular EfficientNet models while being up to 5x
    faster on GPUs.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*在这项工作中，我们提出了一种新的网络设计范式。我们的目标是推动对网络设计的理解，并发现可以在各种设置中推广的设计原则。我们不再专注于设计单个网络实例，而是设计可以参数化网络群体的网络设计空间。整个过程类似于经典手动设计网络，但提升到设计空间级别。使用我们的方法，我们探索网络设计的结构方面，并得出一个由简单、规则网络组成的低维设计空间，我们称之为RegNet。RegNet参数化的核心见解令人惊讶简单：好网络的宽度和深度可以用量化的线性函数解释。我们分析了RegNet设计空间，并得出了与当前网络设计实践不符的有趣发现。在可比的训练设置和flops下，RegNet模型在GPU上比流行的EfficientNet模型表现更好，同时速度提高了多达5倍。*'
- en: This model was contributed by [Francesco](https://huggingface.co/Francesco).
    The TensorFlow version of the model was contributed by [sayakpaul](https://huggingface.co/sayakpaul)
    and [ariG23498](https://huggingface.co/ariG23498). The original code can be found
    [here](https://github.com/facebookresearch/pycls).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是由[Francesco](https://huggingface.co/Francesco)贡献的。模型的TensorFlow版本是由[sayakpaul](https://huggingface.co/sayakpaul)和[ariG23498](https://huggingface.co/ariG23498)贡献的。原始代码可以在[这里](https://github.com/facebookresearch/pycls)找到。
- en: The huge 10B model from [Self-supervised Pretraining of Visual Features in the
    Wild](https://arxiv.org/abs/2103.01988), trained on one billion Instagram images,
    is available on the [hub](https://huggingface.co/facebook/regnet-y-10b-seer)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[野外自监督视觉特征预训练](https://arxiv.org/abs/2103.01988)的巨大10B模型，训练了10亿张Instagram图片，可在[hub](https://huggingface.co/facebook/regnet-y-10b-seer)上找到
- en: Resources
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with RegNet.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些官方Hugging Face和社区（由🌎表示）资源列表，可帮助您开始使用RegNet。
- en: Image Classification
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类
- en: '[RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)
    is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)
    and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)由这个[示例脚本](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification)和[笔记本](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)支持。'
- en: 'See also: [Image classification task guide](../tasks/image_classification)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另请参阅：[图像分类任务指南](../tasks/image_classification)
- en: If you’re interested in submitting a resource to be included here, please feel
    free to open a Pull Request and we’ll review it! The resource should ideally demonstrate
    something new instead of duplicating an existing resource.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣提交资源以包含在此处，请随时提出拉取请求，我们将进行审查！资源应该理想地展示一些新内容，而不是重复现有资源。
- en: RegNetConfig
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RegNetConfig
- en: '### `class transformers.RegNetConfig`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RegNetConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/configuration_regnet.py#L28)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/configuration_regnet.py#L28)'
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_channels` (`int`, *optional*, defaults to 3) — The number of input channels.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` (`int`, *可选*, 默认为3) — 输入通道的数量。'
- en: '`embedding_size` (`int`, *optional*, defaults to 64) — Dimensionality (hidden
    size) for the embedding layer.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding_size` (`int`, *可选*, 默认为64) — 嵌入层的维度（隐藏大小）。'
- en: '`hidden_sizes` (`List[int]`, *optional*, defaults to `[256, 512, 1024, 2048]`)
    — Dimensionality (hidden size) at each stage.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_sizes` (`List[int]`, *可选*, 默认为`[256, 512, 1024, 2048]`) — 每个阶段的维度（隐藏大小）。'
- en: '`depths` (`List[int]`, *optional*, defaults to `[3, 4, 6, 3]`) — Depth (number
    of layers) for each stage.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depths` (`List[int]`, *可选*, 默认为`[3, 4, 6, 3]`) — 每个阶段的深度（层数）。'
- en: '`layer_type` (`str`, *optional*, defaults to `"y"`) — The layer to use, it
    can be either `"x" or` “y”`. An` x`layer is a ResNet''s BottleNeck layer with`reduction`fixed
    to`1`. While a` y`layer is a`x` but with squeeze and excitation. Please refer
    to the paper for a detailed explanation of how these layers were constructed.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_type` (`str`, *optional*, 默认为`"y"`) — 要使用的层，可以是`"x"`或`"y"`。`x`层是ResNet的BottleNeck层，`reduction`固定为`1`。而`y`层是`x`层，但带有squeeze和excitation。请参考论文以获取这些层是如何构建的详细解释。'
- en: '`hidden_act` (`str`, *optional*, defaults to `"relu"`) — The non-linear activation
    function in each block. If string, `"gelu"`, `"relu"`, `"selu"` and `"gelu_new"`
    are supported.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_act` (`str`, *optional*, 默认为`"relu"`) — 每个块中的非线性激活函数。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`和`"gelu_new"`。'
- en: '`downsample_in_first_stage` (`bool`, *optional*, defaults to `False`) — If
    `True`, the first stage will downsample the inputs using a `stride` of 2.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`downsample_in_first_stage` (`bool`, *optional*, 默认为`False`) — 如果为`True`，第一阶段将使用`stride`为2对输入进行下采样。'
- en: This is the configuration class to store the configuration of a [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel).
    It is used to instantiate a RegNet model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the RegNet [facebook/regnet-y-040](https://huggingface.co/facebook/regnet-y-040)
    architecture.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是配置类，用于存储[RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)的配置。根据指定的参数实例化RegNet模型，定义模型架构。使用默认值实例化配置将产生类似于RegNet
    [facebook/regnet-y-040](https://huggingface.co/facebook/regnet-y-040)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: PytorchHide Pytorch content
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch content
- en: RegNetModel
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RegNetModel
- en: '### `class transformers.RegNetModel`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RegNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L321)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L321)'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare RegNet model outputting raw features without any specific head on top.
    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matters related to general usage and behavior.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的RegNet模型输出原始特征，没有特定的头部。这个模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取与一般用法和行为相关的所有事项。
- en: '#### `forward`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L336)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L336)'
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — 像素值。可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取像素值。有关详细信息，请参阅[ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention` or
    `tuple(torch.FloatTensor)`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention`或`tuple(torch.FloatTensor)`'
- en: A `transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention` or
    a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    and inputs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.modeling_outputs.BaseModelOutputWithPoolingAndNoAttention`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含根据配置([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))和输入的各种元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_channels,
    height, width)`) — 模型最后一层的隐藏状态序列。'
- en: '`pooler_output` (`torch.FloatTensor` of shape `(batch_size, hidden_size)`)
    — Last layer hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`torch.FloatTensor`，形状为`(batch_size, hidden_size)`） — 在空间维度上进行池化操作后的最后一层隐藏状态。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, num_channels, height,
    width)`.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*optional*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '模型在每一层输出的隐藏状态以及可选的初始嵌入输出。 '
- en: The [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)的前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例而不是这个，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: RegNetForImageClassification
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RegNetForImageClassification
- en: '### `class transformers.RegNetForImageClassification`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.RegNetForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L372)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L372)'
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)）
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: RegNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部带有图像分类头部的RegNet模型（在池化特征的顶部有一个线性层），例如用于ImageNet。
- en: This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matters related to general usage and behavior.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是PyTorch的[torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规的PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有信息。
- en: '#### `forward`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L393)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_regnet.py#L393)'
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)`) — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See [ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)
    for details.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`torch.FloatTensor`，形状为`(batch_size, num_channels, height,
    width)`） — 像素值。可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取像素值。有关详细信息，请参阅[ConvNextImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the image classification/regression loss. Indices should be in `[0,
    ..., config.num_labels - 1]`. If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor`，形状为`(batch_size,)`，*optional*) — 用于计算图像分类/回归损失的标签。索引应在`[0,
    ..., config.num_labels - 1]`范围内。如果`config.num_labels > 1`，则计算分类损失（交叉熵）。'
- en: Returns
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)
    or `tuple(torch.FloatTensor)`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    and inputs.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.ImageClassifierOutputWithNoAttention](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含根据配置（[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 分类（如果`config.num_labels==1`则为回归）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为`(batch_size, config.num_labels)`) — 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each stage) of shape `(batch_size, num_channels, height,
    width)`. Hidden-states (also called feature maps) of the model at the output of
    each stage.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入的输出
    + 每个阶段的输出）。模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: The [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在此之后调用`Module`实例，而不是这个函数，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: TensorFlowHide TensorFlow content
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow隐藏TensorFlow内容
- en: TFRegNetModel
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFRegNetModel
- en: '### `class transformers.TFRegNetModel`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFRegNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L483)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L483)'
- en: '[PRE8]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parameters
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare RegNet model outputting raw features without any specific head on top.
    This model is a Tensorflow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)
    sub-class. Use it as a regular Tensorflow Module and refer to the Tensorflow documentation
    for all matter related to general usage and behavior.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的RegNet模型输出原始特征，没有特定的头部。这个模型是一个Tensorflow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)子类。将其用作常规的Tensorflow模块，并参考Tensorflow文档以获取有关一般用法和行为的所有信息。
- en: '#### `call`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L492)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L492)'
- en: '[PRE9]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See `ConveNextImageProcessor.__call__` for details.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`tf.Tensor`，形状为`(batch_size, num_channels, height, width)`)
    — 像素值。像素值可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取。有关详细信息，请参阅`ConveNextImageProcessor.__call__`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`，*可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通的元组。'
- en: Returns
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    or `tuple(tf.Tensor)`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    或 `tuple(tf.Tensor)`'
- en: A `transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    and inputs.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndNoAttention`或一个`tf.Tensor`元组（如果传递了`return_dict=False`或当`config.return_dict=False`时）包含各种元素，取决于配置（[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)）和输入。
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, num_channels, height,
    width)`) — Sequence of hidden-states at the output of the last layer of the model.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`tf.Tensor`，形状为`(batch_size, num_channels, height, width)`)
    — 模型最后一层输出的隐藏状态序列。'
- en: '`pooler_output` (`tf.Tensor` of shape `(batch_size, hidden_size)`) — Last layer
    hidden-state after a pooling operation on the spatial dimensions.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`tf.Tensor`，形状为`(batch_size, hidden_size)`) — 空间维度上进行池化操作后的最后一层隐藏状态。'
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings, if the model has an embedding layer, + one for
    the output of each layer) of shape `(batch_size, num_channels, height, width)`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, num_channels, height, width)`的`tf.Tensor`元组（如果模型有嵌入层，则为嵌入的输出+每个层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每个层的输出处的隐藏状态以及可选的初始嵌入输出。
- en: The [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)
    forward method, overrides the `__call__` special method.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: TFRegNetForImageClassification
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFRegNetForImageClassification
- en: '### `class transformers.TFRegNetForImageClassification`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFRegNetForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L537)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L537)'
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)）
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: RegNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部带有图像分类头部的RegNet模型（在池化特征的顶部是一个线性层），例如用于ImageNet。
- en: This model is a Tensorflow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)
    sub-class. Use it as a regular Tensorflow Module and refer to the Tensorflow documentation
    for all matter related to general usage and behavior.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是一个Tensorflow [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)子类。将其用作常规的Tensorflow模块，并参考Tensorflow文档以获取所有与一般用法和行为相关的事项。
- en: '#### `call`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L555)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_tf_regnet.py#L555)'
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pixel_values` (`tf.Tensor` of shape `(batch_size, num_channels, height, width)`)
    — Pixel values. Pixel values can be obtained using [AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor).
    See `ConveNextImageProcessor.__call__` for details.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pixel_values` (`tf.Tensor`，形状为`(batch_size, num_channels, height, width)`)
    — 像素值。可以使用[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)获取像素值。有关详细信息，请参阅`ConveNextImageProcessor.__call__`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`，*可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`labels` (`tf.Tensor` of shape `(batch_size,)`, *optional*) — Labels for computing
    the image classification/regression loss. Indices should be in `[0, ..., config.num_labels
    - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`tf.Tensor`，形状为`(batch_size,)`，*可选*) — 用于计算图像分类/回归损失的标签。索引应在`[0,
    ..., config.num_labels - 1]`范围内。如果`config.num_labels > 1`，则计算分类损失（交叉熵）。'
- en: Returns
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)或`tuple(tf.Tensor)`'
- en: A [transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    and inputs.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_tf_outputs.TFSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput)或一个`tf.Tensor`元组（如果传递`return_dict=False`或当`config.return_dict=False`时）包含根据配置（[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)）和输入的不同元素。
- en: '`loss` (`tf.Tensor` of shape `(batch_size, )`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`tf.Tensor`，形状为`(batch_size, )`，*可选*，当提供`labels`时返回) — 分类（或回归，如果`config.num_labels==1`）损失。'
- en: '`logits` (`tf.Tensor` of shape `(batch_size, config.num_labels)`) — Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`tf.Tensor`，形状为`(batch_size, config.num_labels)`) — 分类（或回归，如果`config.num_labels==1`）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（用于嵌入输出和每层输出各一个）。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出处的隐藏状态加上初始嵌入输出。
- en: '`attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在自注意力头中使用注意力softmax后的注意力权重，用于计算加权平均值。
- en: The [TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)前向方法，覆盖`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者会负责运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: JAXHide JAX content
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: JAXHide JAX content
- en: FlaxRegNetModel
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxRegNetModel
- en: '### `class transformers.FlaxRegNetModel`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxRegNetModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L686)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L686)'
- en: '[PRE14]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)）-
    模型的所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype`（`jax.numpy.dtype`，*可选*，默认为`jax.numpy.float32`）- 计算的数据类型。可以是`jax.numpy.float32`、`jax.numpy.float16`（在GPU上）和`jax.numpy.bfloat16`（在TPU上）之一。'
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified all the computation will be performed with the given
    `dtype`.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以用于在GPU或TPU上启用混合精度训练或半精度推断。如果指定了，所有计算将使用给定的`dtype`执行。
- en: '`Note that this only specifies the dtype of the computation and does not influence
    the dtype of model parameters.`'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`请注意，这仅指定计算的数据类型，不影响模型参数的数据类型。`'
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您希望更改模型参数的数据类型，请参阅[to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)和[to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)。
- en: The bare RegNet model outputting raw features without any specific head on top.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的RegNet模型输出原始特征，没有任何特定的头部。
- en: This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading, saving and converting weights from PyTorch
    models)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)。查看超类文档，了解库为所有模型实现的通用方法（如下载、保存和从PyTorch模型转换权重）。
- en: This model is also a [flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)
    subclass. Use it as a regular Flax linen Module and refer to the Flax documentation
    for all matter related to general usage and behavior.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个[flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)子类。将其用作常规的Flax
    linen模块，并参考Flax文档以获取与一般用法和行为相关的所有内容。
- en: 'Finally, this model supports inherent JAX features such as:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个模型支持JAX的固有特性，比如：
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[即时（JIT）编译](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动微分](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[矢量化](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[并行化](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L597)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L597)'
- en: '[PRE15]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Returns
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling)
    or `tuple(torch.FloatTensor)`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.regnet.configuration_regnet.RegNetConfig'>`)
    and inputs.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（`<class
    ''transformers.models.regnet.configuration_regnet.RegNetConfig''>`）和输入的不同元素。'
- en: '`last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the model.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`jnp.ndarray`，形状为`(batch_size, sequence_length, hidden_size)`)
    — 模型最后一层的隐藏状态序列。'
- en: '`pooler_output` (`jnp.ndarray` of shape `(batch_size, hidden_size)`) — Last
    layer hidden-state of the first token of the sequence (classification token) further
    processed by a Linear layer and a Tanh activation function. The Linear layer weights
    are trained from the next sentence prediction (classification) objective during
    pretraining.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pooler_output` (`jnp.ndarray`，形状为`(batch_size, hidden_size)`) — 序列第一个标记（分类标记）的最后一层隐藏状态，进一步由线性层和Tanh激活函数处理。线性层的权重是在预训练期间从下一个句子预测（分类）目标中训练的。'
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层的输出隐藏状态加上初始嵌入输出。
- en: '`attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力权重在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The `FlaxRegNetPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`FlaxRegNetPreTrainedModel`的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Examples:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE16]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: FlaxRegNetForImageClassification
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxRegNetForImageClassification
- en: '### `class transformers.FlaxRegNetForImageClassification`'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxRegNetForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L776)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L776)'
- en: '[PRE17]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jax.numpy.dtype`, *可选*, 默认为 `jax.numpy.float32`) — 计算的数据类型。可以是`jax.numpy.float32`、`jax.numpy.float16`（在GPU上）和`jax.numpy.bfloat16`（在TPU上）之一。'
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified all the computation will be performed with the given
    `dtype`.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以用于在GPU或TPU上启用混合精度训练或半精度推断。如果指定了，所有计算将使用给定的`dtype`执行。
- en: '`Note that this only specifies the dtype of the computation and does not influence
    the dtype of model parameters.`'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`请注意，这仅指定计算的数据类型，不影响模型参数的数据类型。`'
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您希望更改模型参数的dtype，请参阅[to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)和[to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)。
- en: RegNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部添加一个图像分类头的RegNet模型（在池化特征的顶部添加一个线性层），例如用于ImageNet。
- en: This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading, saving and converting weights from PyTorch
    models)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)。查看超类文档以了解库实现的所有模型的通用方法（例如从PyTorch模型下载、保存和转换权重）。
- en: This model is also a [flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)
    subclass. Use it as a regular Flax linen Module and refer to the Flax documentation
    for all matter related to general usage and behavior.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个[flax.linen.Module](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)子类。将其用作常规的Flax
    linen模块，并参考Flax文档以了解所有与一般用法和行为相关的事项。
- en: 'Finally, this model supports inherent JAX features such as:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个模型支持内在的JAX特性，比如：
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[即时（JIT）编译](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动微分](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[向量化](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[并行化](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L597)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/regnet/modeling_flax_regnet.py#L597)'
- en: '[PRE18]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Returns
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    or `tuple(torch.FloatTensor)`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`或`tuple(torch.FloatTensor)`'
- en: A `transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration (`<class 'transformers.models.regnet.configuration_regnet.RegNetConfig'>`)
    and inputs.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`transformers.modeling_flax_outputs.FlaxImageClassifierOutputWithNoAttention`或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含根据配置（`<class
    'transformers.models.regnet.configuration_regnet.RegNetConfig'>`）和输入的不同元素。
- en: '`logits` (`jnp.ndarray` of shape `(batch_size, config.num_labels)`) — Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, config.num_labels)`的`jnp.ndarray`）—分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states`（`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或'
- en: '`config.output_hidden_states=True):` Tuple of `jnp.ndarray` (one for the output
    of the embeddings, if the model has an embedding layer, + one for the output of
    each stage) of shape `(batch_size, num_channels, height, width)`. Hidden-states
    (also called feature maps) of the model at the output of each stage.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config.output_hidden_states=True):` 形状为`(batch_size, num_channels, height,
    width)`的`jnp.ndarray`元组（如果模型有嵌入层，则为嵌入的输出+每个阶段的输出）。模型在每个阶段输出的隐藏状态（也称为特征图）。'
- en: The `FlaxRegNetPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`FlaxRegNetPreTrainedModel`的前向方法覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在这个函数内定义，但应该在之后调用`Module`实例，而不是这个函数，因为前者会负责运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE19]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
