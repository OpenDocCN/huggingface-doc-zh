- en: Creating an EvaluationSuite
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个EvaluationSuite
- en: 'Original text: [https://huggingface.co/docs/evaluate/evaluation_suite](https://huggingface.co/docs/evaluate/evaluation_suite)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/evaluate/evaluation_suite](https://huggingface.co/docs/evaluate/evaluation_suite)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: It can be useful to evaluate models on a variety of different tasks to understand
    their downstream performance. Assessing the model on several types of tasks can
    reveal gaps in performance along some axis. For example, when training a language
    model, it is often useful to measure perplexity on an in-domain corpus, but also
    to concurrently evaluate on tasks which test for general language capabilities
    like natural language entailment or question-answering, or tasks designed to probe
    the model along fairness and bias dimensions.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种不同任务上评估模型可以帮助我们了解它们的下游性能。在几种类型的任务上评估模型可以揭示在某些方面性能差距。例如，在训练语言模型时，通常有必要在一个领域语料库上测量困惑度，但同时也要在测试一般语言能力的任务上进行评估，比如自然语言蕴涵或问答，或者旨在探测模型在公平性和偏见维度上的任务。
- en: The `EvaluationSuite` provides a way to compose any number of ([evaluator](base_evaluator),
    dataset, metric) tuples as a SubTask to evaluate a model on a collection of several
    evaluation tasks. See the [evaluator documentation](base_evaluator) for a list
    of currently supported tasks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '`EvaluationSuite`提供了一种将任意数量的([evaluator](base_evaluator), dataset, metric)元组组合为一个SubTask，以便在多个评估任务集合上评估模型的方法。请参阅[evaluator文档](base_evaluator)以获取当前支持的任务列表。'
- en: A new `EvaluationSuite` is made up of a list of `SubTask` classes, each defining
    an evaluation task. The Python file containing the definition can be uploaded
    to a Space on the Hugging Face Hub so it can be shared with the community or saved/loaded
    locally as a Python script.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一个新的`EvaluationSuite`由一系列定义评估任务的`SubTask`类组成。包含定义的Python文件可以上传到Hugging Face
    Hub上的一个Space中，以便与社区共享，或者保存/加载为一个Python脚本。
- en: Some datasets require additional preprocessing before passing them to an `Evaluator`.
    You can set a `data_preprocessor` for each `SubTask` which is applied via a `map`
    operation using the `datasets` library. Keyword arguments for the `Evaluator`
    can be passed down through the `args_for_task` attribute.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 有些数据集在传递给`Evaluator`之前需要额外的预处理。您可以为每个`SubTask`设置一个`data_preprocessor`，通过`datasets`库使用`map`操作应用它。`Evaluator`的关键参数可以通过`args_for_task`属性传递下来。
- en: To create a new `EvaluationSuite`, create a [new Space](https://huggingface.co/new-space)
    with a .py file which matches the name of the Space, add the below template to
    a Python file, and fill in the attributes for a new task.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '`task_type`映射到Evaluator当前支持的任务。'
- en: The mandatory attributes for a new `SubTask` are `task_type` and `data`.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一个新的`SubTask`的必需属性是`task_type`和`data`。
- en: '`task_type` maps to the tasks currently supported by the Evaluator.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '| 0.4 | 1.67552 | 5.9683 | 0.167552 | glue/rte |'
- en: '`data` can be an instantiated Hugging Face dataset object or the name of a
    dataset.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`data`可以是一个实例化的Hugging Face数据集对象，也可以是一个数据集的名称。'
- en: '`subset` and `split` can be used to define which name and split of the dataset
    should be used for evaluation.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`subset`和`split`可以用来定义数据集的哪个名称和分割应该用于评估。'
- en: '`args_for_task` should be a dictionary with kwargs to be passed to the Evaluator.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`args_for_task`应该是一个包含要传递给Evaluator的关键字参数的字典。'
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'An `EvaluationSuite` can be loaded by name from the Hugging Face Hub, or locally
    by providing a path, and run with the `run(model_or_pipeline)` method. The evaluation
    results are returned along with their task names and information about the time
    it took to obtain predictions through the pipeline. These can be easily displayed
    with a `pandas.DataFrame`:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过名称从Hugging Face Hub加载`EvaluationSuite`，或者通过提供路径本地加载，并使用`run(model_or_pipeline)`方法运行。评估结果将与任务名称以及通过管道获取预测所需时间的信息一起返回。这些结果可以很容易地用`pandas.DataFrame`显示出来：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '| accuracy | total_time_in_seconds | samples_per_second | latency_in_seconds
    | task_name |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| accuracy | total_time_in_seconds | samples_per_second | latency_in_seconds
    | task_name |'
- en: '| --: | --: | --: | --: | :-- |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: 要创建一个新的`EvaluationSuite`，请创建一个与Space名称匹配的.py文件的[新Space](https://huggingface.co/new-space)，将下面的模板添加到一个Python文件中，并填写一个新任务的属性。
- en: '| 0.5 | 0.740811 | 13.4987 | 0.0740811 | glue/sst2 |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 0.5 | 0.740811 | 13.4987 | 0.0740811 | glue/sst2 |'
- en: '| 0.4 | 1.67552 | 5.9683 | 0.167552 | glue/rte |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| --: | --: | --: | --: | :-- |'
