["```py\n( url_endpoint token = None chat_prompt_template = None run_prompt_template = None additional_tools = None )\n```", "```py\nfrom transformers import HfAgent\n\nagent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\nagent.run(\"Is the following `text` (in Spanish) positive or negative?\", text=\"\u00a1Este es un API muy agradable!\")\n```", "```py\n( model tokenizer chat_prompt_template = None run_prompt_template = None additional_tools = None )\n```", "```py\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, LocalAgent\n\ncheckpoint = \"bigcode/starcoder\"\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", torch_dtype=torch.bfloat16)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\nagent = LocalAgent(model, tokenizer)\nagent.run(\"Draw me a picture of rivers and lakes.\")\n```", "```py\n( pretrained_model_name_or_path **kwargs )\n```", "```py\nimport torch\nfrom transformers import LocalAgent\n\nagent = LocalAgent.from_pretrained(\"bigcode/starcoder\", device_map=\"auto\", torch_dtype=torch.bfloat16)\nagent.run(\"Draw me a picture of rivers and lakes.\")\n```", "```py\n( model = 'text-davinci-003' api_key = None chat_prompt_template = None run_prompt_template = None additional_tools = None )\n```", "```py\nfrom transformers import OpenAiAgent\n\nagent = OpenAiAgent(model=\"text-davinci-003\", api_key=xxx)\nagent.run(\"Is the following `text` (in Spanish) positive or negative?\", text=\"\u00a1Este es un API muy agradable!\")\n```", "```py\n( deployment_id api_key = None resource_name = None api_version = '2022-12-01' is_chat_model = None chat_prompt_template = None run_prompt_template = None additional_tools = None )\n```", "```py\nfrom transformers import AzureOpenAiAgent\n\nagent = AzureAiAgent(deployment_id=\"Davinci-003\", api_key=xxx, resource_name=yyy)\nagent.run(\"Is the following `text` (in Spanish) positive or negative?\", text=\"\u00a1Este es un API muy agradable!\")\n```", "```py\n( chat_prompt_template = None run_prompt_template = None additional_tools = None )\n```", "```py\n( task return_code = False remote = False **kwargs )\n```", "```py\nfrom transformers import HfAgent\n\nagent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\nagent.chat(\"Draw me a picture of rivers and lakes\")\n\nagent.chat(\"Transform the picture so that there is a rock in there\")\n```", "```py\n( task return_code = False remote = False **kwargs )\n```", "```py\nfrom transformers import HfAgent\n\nagent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\nagent.run(\"Draw me a picture of rivers and lakes\")\n```", "```py\n( )\n```", "```py\n( task_or_repo_id model_repo_id = None remote = False token = None **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( gradio_tool )\n```", "```py\n( repo_id: str model_repo_id: Optional = None token: Optional = None remote: bool = False **kwargs )\n```", "```py\n( repo_id: str commit_message: str = 'Upload tool' private: Optional = None token: Union = None create_pr: bool = False )\n```", "```py\n( output_dir )\n```", "```py\n( )\n```", "```py\n( model = None pre_processor = None post_processor = None device = None device_map = None model_kwargs = None token = None **hub_kwargs )\n```", "```py\n( outputs )\n```", "```py\n( raw_inputs )\n```", "```py\n( inputs )\n```", "```py\n( )\n```", "```py\n( endpoint_url = None token = None tool_class = None )\n```", "```py\n( outputs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( tool_class: Tool )\n```", "```py\n( value )\n```", "```py\n( value )\n```", "```py\n( )\n```", "```py\n( )\n```", "```py\n( value samplerate = 16000 )\n```", "```py\n( )\n```", "```py\n( )\n```"]