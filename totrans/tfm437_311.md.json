["```py\npip install pretty-midi==0.2.9 essentia==2.1b6.dev1034 librosa scipy\n```", "```py\n>>> from datasets import load_dataset\n>>> from transformers import Pop2PianoForConditionalGeneration, Pop2PianoProcessor\n\n>>> model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\")\n>>> processor = Pop2PianoProcessor.from_pretrained(\"sweetcocoa/pop2piano\")\n>>> ds = load_dataset(\"sweetcocoa/pop2piano_ci\", split=\"test\")\n\n>>> inputs = processor(\n...     audio=ds[\"audio\"][0][\"array\"], sampling_rate=ds[\"audio\"][0][\"sampling_rate\"], return_tensors=\"pt\"\n... )\n>>> model_output = model.generate(input_features=inputs[\"input_features\"], composer=\"composer1\")\n>>> tokenizer_output = processor.batch_decode(\n...     token_ids=model_output, feature_extractor_output=inputs\n... )[\"pretty_midi_objects\"][0]\n>>> tokenizer_output.write(\"./Outputs/midi_output.mid\")\n```", "```py\n>>> import librosa\n>>> from transformers import Pop2PianoForConditionalGeneration, Pop2PianoProcessor\n\n>>> audio, sr = librosa.load(\"<your_audio_file_here>\", sr=44100)  # feel free to change the sr to a suitable value.\n>>> model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\")\n>>> processor = Pop2PianoProcessor.from_pretrained(\"sweetcocoa/pop2piano\")\n\n>>> inputs = processor(audio=audio, sampling_rate=sr, return_tensors=\"pt\")\n>>> model_output = model.generate(input_features=inputs[\"input_features\"], composer=\"composer1\")\n>>> tokenizer_output = processor.batch_decode(\n...     token_ids=model_output, feature_extractor_output=inputs\n... )[\"pretty_midi_objects\"][0]\n>>> tokenizer_output.write(\"./Outputs/midi_output.mid\")\n```", "```py\n>>> import librosa\n>>> from transformers import Pop2PianoForConditionalGeneration, Pop2PianoProcessor\n\n>>> # feel free to change the sr to a suitable value.\n>>> audio1, sr1 = librosa.load(\"<your_first_audio_file_here>\", sr=44100)  \n>>> audio2, sr2 = librosa.load(\"<your_second_audio_file_here>\", sr=44100)\n>>> model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\")\n>>> processor = Pop2PianoProcessor.from_pretrained(\"sweetcocoa/pop2piano\")\n\n>>> inputs = processor(audio=[audio1, audio2], sampling_rate=[sr1, sr2], return_attention_mask=True, return_tensors=\"pt\")\n>>> # Since we now generating in batch(2 audios) we must pass the attention_mask\n>>> model_output = model.generate(\n...     input_features=inputs[\"input_features\"],\n...     attention_mask=inputs[\"attention_mask\"],\n...     composer=\"composer1\",\n... )\n>>> tokenizer_output = processor.batch_decode(\n...     token_ids=model_output, feature_extractor_output=inputs\n... )[\"pretty_midi_objects\"]\n\n>>> # Since we now have 2 generated MIDI files\n>>> tokenizer_output[0].write(\"./Outputs/midi_output1.mid\")\n>>> tokenizer_output[1].write(\"./Outputs/midi_output2.mid\")\n```", "```py\n>>> import librosa\n>>> from transformers import Pop2PianoForConditionalGeneration, Pop2PianoFeatureExtractor, Pop2PianoTokenizer\n\n>>> # feel free to change the sr to a suitable value.\n>>> audio1, sr1 = librosa.load(\"<your_first_audio_file_here>\", sr=44100)  \n>>> audio2, sr2 = librosa.load(\"<your_second_audio_file_here>\", sr=44100)\n>>> model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\")\n>>> feature_extractor = Pop2PianoFeatureExtractor.from_pretrained(\"sweetcocoa/pop2piano\")\n>>> tokenizer = Pop2PianoTokenizer.from_pretrained(\"sweetcocoa/pop2piano\")\n\n>>> inputs = feature_extractor(\n...     audio=[audio1, audio2], \n...     sampling_rate=[sr1, sr2], \n...     return_attention_mask=True, \n...     return_tensors=\"pt\",\n... )\n>>> # Since we now generating in batch(2 audios) we must pass the attention_mask\n>>> model_output = model.generate(\n...     input_features=inputs[\"input_features\"],\n...     attention_mask=inputs[\"attention_mask\"],\n...     composer=\"composer1\",\n... )\n>>> tokenizer_output = tokenizer.batch_decode(\n...     token_ids=model_output, feature_extractor_output=inputs\n... )[\"pretty_midi_objects\"]\n\n>>> # Since we now have 2 generated MIDI files\n>>> tokenizer_output[0].write(\"./Outputs/midi_output1.mid\")\n>>> tokenizer_output[1].write(\"./Outputs/midi_output2.mid\")\n```"]