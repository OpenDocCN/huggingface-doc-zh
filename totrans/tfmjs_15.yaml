- en: Server-side Audio Processing in Node.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/transformers.js/guides/node-audio-processing](https://huggingface.co/docs/transformers.js/guides/node-audio-processing)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/transformers.js/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/entry/start.d68a6d16.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/scheduler.b108d059.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/singletons.e4b794f0.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/paths.0114e475.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/entry/app.c6513cb2.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/index.008de539.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/nodes/0.7513fd35.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/nodes/19.f2fe6d68.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/Tip.aeb15ab7.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/CodeBlock.3968c746.js">
    <link rel="modulepreload" href="/docs/transformers.js/main/en/_app/immutable/chunks/Heading.88bfeb84.js">
  prefs: []
  type: TYPE_NORMAL
- en: A major benefit of writing code for the web is that you can access the multitude
    of APIs that are available in modern browsers. Unfortunately, when writing server-side
    code, we are not afforded such luxury, so we have to find another way. In this
    tutorial, we will design a simple Node.js application that uses Transformers.js
    for speech recognition with [Whisper](https://huggingface.co/Xenova/whisper-tiny.en),
    and in the process, learn how to process audio on the server.
  prefs: []
  type: TYPE_NORMAL
- en: The main problem we need to solve is that the [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
    is not available in Node.js, meaning we can’t use the [`AudioContext`](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext)
    class to process audio. So, we will need to install third-party libraries to obtain
    the raw audio data. For this example, we will only consider `.wav` files, but
    the same principles apply to other audio formats.
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial will be written as an ES module, but you can easily adapt it to
    use CommonJS instead. For more information, see the [node tutorial](https://huggingface.co/docs/transformers.js/tutorials/node).
  prefs: []
  type: TYPE_NORMAL
- en: '**Useful links:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source code](https://github.com/xenova/transformers.js/tree/main/examples/node-audio-processing)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Documentation](https://huggingface.co/docs/transformers.js)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Node.js](https://nodejs.org/en/) version 18+'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[npm](https://www.npmjs.com/) version 9+'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start by creating a new Node.js project and installing Transformers.js
    via [NPM](https://www.npmjs.com/package/@xenova/transformers):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember to add `"type": "module"` to your `package.json` to indicate that
    your project uses ECMAScript modules.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s install the [`wavefile`](https://www.npmjs.com/package/wavefile)
    package, which we will use for loading `.wav` files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Creating the application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Start by creating a new file called `index.js`, which will be the entry point
    for our application. Let’s also import the necessary modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For this tutorial, we will use the `Xenova/whisper-tiny.en` model, but feel
    free to choose one of the other whisper models from the [Hugging Face Hub](https://huggingface.co/models?library=transformers.js&search=whisper).
    Let’s create our pipeline with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s load an audio file and convert it to the format required by Transformers.js:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Finally, let’s run the model and measure execution duration.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You can now run the application with `node index.js`. Note that when running
    the script for the first time, it may take a while to download and cache the model.
    Subsequent requests will use the cached model, and model loading will be much
    faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see output similar to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: That’s it! You’ve successfully created a Node.js application that uses Transformers.js
    for speech recognition with Whisper. You can now use this as a starting point
    for your own applications.
  prefs: []
  type: TYPE_NORMAL
