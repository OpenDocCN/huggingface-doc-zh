["```py\n( peft_type: Union = None auto_mapping: Optional = None base_model_name_or_path: Optional = None revision: Optional = None task_type: Union = None inference_mode: bool = False num_virtual_tokens: int = None token_dim: int = None num_transformer_submodules: Optional = None num_attention_heads: Optional = None num_layers: Optional = None encoder_reparameterization_type: Union = <PromptEncoderReparameterizationType.MLP: 'MLP'> encoder_hidden_size: int = None encoder_num_layers: int = 2 encoder_dropout: float = 0.0 )\n```", "```py\n( config )\n```", "```py\n>>> from peft import PromptEncoder, PromptEncoderConfig\n\n>>> config = PromptEncoderConfig(\n...     peft_type=\"P_TUNING\",\n...     task_type=\"SEQ_2_SEQ_LM\",\n...     num_virtual_tokens=20,\n...     token_dim=768,\n...     num_transformer_submodules=1,\n...     num_attention_heads=12,\n...     num_layers=12,\n...     encoder_reparameterization_type=\"MLP\",\n...     encoder_hidden_size=768,\n... )\n\n>>> prompt_encoder = PromptEncoder(config)\n```"]