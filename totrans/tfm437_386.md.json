["```py\n( num_input_channels: int = 1 context_length: int = 32 distribution_output: str = 'student_t' loss: str = 'mse' patch_length: int = 1 patch_stride: int = 1 num_hidden_layers: int = 3 d_model: int = 128 num_attention_heads: int = 4 share_embedding: bool = True channel_attention: bool = False ffn_dim: int = 512 norm_type: str = 'batchnorm' norm_eps: float = 1e-05 attention_dropout: float = 0.0 dropout: float = 0.0 positional_dropout: float = 0.0 path_dropout: float = 0.0 ff_dropout: float = 0.0 bias: bool = True activation_function: str = 'gelu' pre_norm: bool = True positional_encoding_type: str = 'sincos' use_cls_token: bool = False init_std: float = 0.02 share_projection: bool = True scaling: Union = 'std' do_mask_input: Optional = None mask_type: str = 'random' random_mask_ratio: float = 0.5 num_forecast_mask_patches: Union = [2] channel_consistent_masking: Optional = False unmasked_channel_indices: Optional = None mask_value: int = 0 pooling_type: str = 'mean' head_dropout: float = 0.0 prediction_length: int = 24 num_targets: int = 1 output_range: Optional = None num_parallel_samples: int = 100 **kwargs )\n```", "```py\n>>> from transformers import PatchTSTConfig, PatchTSTModel\n\n>>> # Initializing an PatchTST configuration with 12 time steps for prediction\n>>> configuration = PatchTSTConfig(prediction_length=12)\n\n>>> # Randomly initializing a model (with random weights) from the configuration\n>>> model = PatchTSTModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( config: PatchTSTConfig )\n```", "```py\n( past_values: Tensor past_observed_mask: Optional = None future_values: Optional = None output_hidden_states: Optional = None output_attentions: Optional = None return_dict: Optional = None )\n```", "```py\n>>> from huggingface_hub import hf_hub_download\n>>> import torch\n>>> from transformers import PatchTSTModel\n\n>>> file = hf_hub_download(\n...     repo_id=\"hf-internal-testing/etth1-hourly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n... )\n>>> batch = torch.load(file)\n\n>>> model = PatchTSTModel.from_pretrained(\"namctin/patchtst_etth1_pretrain\")\n\n>>> # during training, one provides both past and future values\n>>> outputs = model(\n...     past_values=batch[\"past_values\"],\n...     future_values=batch[\"future_values\"],\n... )\n\n>>> last_hidden_state = outputs.last_hidden_state\n```", "```py\n( config: PatchTSTConfig )\n```", "```py\n( past_values: Tensor past_observed_mask: Optional = None future_values: Optional = None output_hidden_states: Optional = None output_attentions: Optional = None return_dict: Optional = None )\n```", "```py\n>>> from huggingface_hub import hf_hub_download\n>>> import torch\n>>> from transformers import PatchTSTConfig, PatchTSTForPrediction\n\n>>> file = hf_hub_download(\n...     repo_id=\"hf-internal-testing/etth1-hourly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n... )\n>>> batch = torch.load(file)\n\n>>> # Prediction task with 7 input channels and prediction length is 96\n>>> model = PatchTSTForPrediction.from_pretrained(\"namctin/patchtst_etth1_forecast\")\n\n>>> # during training, one provides both past and future values\n>>> outputs = model(\n...     past_values=batch[\"past_values\"],\n...     future_values=batch[\"future_values\"],\n... )\n\n>>> loss = outputs.loss\n>>> loss.backward()\n\n>>> # during inference, one only provides past values, the model outputs future values\n>>> outputs = model(past_values=batch[\"past_values\"])\n>>> prediction_outputs = outputs.prediction_outputs\n```", "```py\n( config: PatchTSTConfig )\n```", "```py\n( past_values: Tensor target_values: Tensor = None past_observed_mask: Optional = None output_hidden_states: Optional = None output_attentions: Optional = None return_dict: Optional = None )\n```", "```py\n>>> from transformers import PatchTSTConfig, PatchTSTForClassification\n\n>>> # classification task with two input channel2 and 3 classes\n>>> config = PatchTSTConfig(\n...     num_input_channels=2,\n...     num_targets=3,\n...     context_length=512,\n...     patch_length=12,\n...     stride=12,\n...     use_cls_token=True,\n... )\n>>> model = PatchTSTForClassification(config=config)\n\n>>> # during inference, one only provides past values\n>>> past_values = torch.randn(20, 512, 2)\n>>> outputs = model(past_values=past_values)\n>>> labels = outputs.prediction_logits\n```", "```py\n( config: PatchTSTConfig )\n```", "```py\n( past_values: Tensor past_observed_mask: Optional = None output_hidden_states: Optional = None output_attentions: Optional = None return_dict: Optional = None )\n```", "```py\n>>> from huggingface_hub import hf_hub_download\n>>> import torch\n>>> from transformers import PatchTSTConfig, PatchTSTForPretraining\n\n>>> file = hf_hub_download(\n...     repo_id=\"hf-internal-testing/etth1-hourly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n... )\n>>> batch = torch.load(file)\n\n>>> # Config for random mask pretraining\n>>> config = PatchTSTConfig(\n...     num_input_channels=7,\n...     context_length=512,\n...     patch_length=12,\n...     stride=12,\n...     mask_type='random',\n...     random_mask_ratio=0.4,\n...     use_cls_token=True,\n... )\n>>> # Config for forecast mask pretraining\n>>> config = PatchTSTConfig(\n...     num_input_channels=7,\n...     context_length=512,\n...     patch_length=12,\n...     stride=12,\n...     mask_type='forecast',\n...     num_forecast_mask_patches=5,\n...     use_cls_token=True,\n... )\n>>> model = PatchTSTForPretraining(config)\n\n>>> # during training, one provides both past and future values\n>>> outputs = model(past_values=batch[\"past_values\"])\n\n>>> loss = outputs.loss\n>>> loss.backward()\n```", "```py\n( config: PatchTSTConfig )\n```", "```py\n( past_values: Tensor target_values: Tensor = None past_observed_mask: Optional = None output_hidden_states: Optional = None output_attentions: Optional = None return_dict: Optional = None )\n```", "```py\n>>> from transformers import PatchTSTConfig, PatchTSTForRegression\n\n>>> # Regression task with 6 input channels and regress 2 targets\n>>> model = PatchTSTForRegression.from_pretrained(\"namctin/patchtst_etth1_regression\")\n\n>>> # during inference, one only provides past values, the model outputs future values\n>>> past_values = torch.randn(20, 512, 6)\n>>> outputs = model(past_values=past_values)\n>>> regression_outputs = outputs.regression_outputs\n```"]