["```py\n# uncomment to install the necessary libraries in Colab\n#!pip install -q diffusers transformers accelerate trimesh\n```", "```py\nimport torch\nfrom diffusers import ShapEPipeline\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\npipe = ShapEPipeline.from_pretrained(\"openai/shap-e\", torch_dtype=torch.float16, variant=\"fp16\")\npipe = pipe.to(device)\n\nguidance_scale = 15.0\nprompt = [\"A firecracker\", \"A birthday cupcake\"]\n\nimages = pipe(\n    prompt,\n    guidance_scale=guidance_scale,\n    num_inference_steps=64,\n    frame_size=256,\n).images\n```", "```py\nfrom diffusers.utils import export_to_gif\n\nexport_to_gif(images[0], \"firecracker_3d.gif\")\nexport_to_gif(images[1], \"cake_3d.gif\")\n```", "```py\nfrom diffusers import DiffusionPipeline\nimport torch\n\nprior_pipeline = DiffusionPipeline.from_pretrained(\"kandinsky-community/kandinsky-2-1-prior\", torch_dtype=torch.float16, use_safetensors=True).to(\"cuda\")\npipeline = DiffusionPipeline.from_pretrained(\"kandinsky-community/kandinsky-2-1\", torch_dtype=torch.float16, use_safetensors=True).to(\"cuda\")\n\nprompt = \"A cheeseburger, white background\"\n\nimage_embeds, negative_image_embeds = prior_pipeline(prompt, guidance_scale=1.0).to_tuple()\nimage = pipeline(\n    prompt,\n    image_embeds=image_embeds,\n    negative_image_embeds=negative_image_embeds,\n).images[0]\n\nimage.save(\"burger.png\")\n```", "```py\nfrom PIL import Image\nfrom diffusers import ShapEImg2ImgPipeline\nfrom diffusers.utils import export_to_gif\n\npipe = ShapEImg2ImgPipeline.from_pretrained(\"openai/shap-e-img2img\", torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n\nguidance_scale = 3.0\nimage = Image.open(\"burger.png\").resize((256, 256))\n\nimages = pipe(\n    image,\n    guidance_scale=guidance_scale,\n    num_inference_steps=64,\n    frame_size=256,\n).images\n\ngif_path = export_to_gif(images[0], \"burger_3d.gif\")\n```", "```py\nimport torch\nfrom diffusers import ShapEPipeline\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\npipe = ShapEPipeline.from_pretrained(\"openai/shap-e\", torch_dtype=torch.float16, variant=\"fp16\")\npipe = pipe.to(device)\n\nguidance_scale = 15.0\nprompt = \"A birthday cupcake\"\n\nimages = pipe(prompt, guidance_scale=guidance_scale, num_inference_steps=64, frame_size=256, output_type=\"mesh\").images\n```", "```py\nfrom diffusers.utils import export_to_ply\n\nply_path = export_to_ply(images[0], \"3d_cake.ply\")\nprint(f\"Saved to folder: {ply_path}\")\n```", "```py\nimport trimesh\n\nmesh = trimesh.load(\"3d_cake.ply\")\nmesh_export = mesh.export(\"3d_cake.glb\", file_type=\"glb\")\n```", "```py\nimport trimesh\nimport numpy as np\n\nmesh = trimesh.load(\"3d_cake.ply\")\nrot = trimesh.transformations.rotation_matrix(-np.pi / 2, [1, 0, 0])\nmesh = mesh.apply_transform(rot)\nmesh_export = mesh.export(\"3d_cake.glb\", file_type=\"glb\")\n```"]