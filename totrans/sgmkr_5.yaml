- en: Reference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考
- en: 'Original text: [https://huggingface.co/docs/sagemaker/reference](https://huggingface.co/docs/sagemaker/reference)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/sagemaker/reference](https://huggingface.co/docs/sagemaker/reference)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning Container
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习容器
- en: Below you can find a version table of currently available Hugging Face DLCs.
    The table doesn’t include the full `image_uri` here are two examples on how to
    construct those if needed.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是当前可用的Hugging Face DLC的版本表。该表不包括完整的`image_uri`，如果需要，这里有两个构建的示例。
- en: '**Manually construction the `image_uri`**'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**手动构建`image_uri`**'
- en: '`{dlc-aws-account-id}.dkr.ecr.{region}.amazonaws.com/huggingface-{framework}-{(training
    | inference)}:{framework-version}-transformers{transformers-version}-{device}-{python-version}-{device-tag}`'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '`{dlc-aws-account-id}.dkr.ecr.{region}.amazonaws.com/huggingface-{framework}-{(training
    | inference)}:{framework-version}-transformers{transformers-version}-{device}-{python-version}-{device-tag}`'
- en: '`dlc-aws-account-id`: The AWS account ID of the account that owns the ECR repository.
    You can find them in the [here](https://github.com/aws/sagemaker-python-sdk/blob/e0b9d38e1e3b48647a02af23c4be54980e53dc61/src/sagemaker/image_uri_config/huggingface.json#L21)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dlc-aws-account-id`: 拥有ECR存储库的帐户的AWS帐户ID。您可以在[这里](https://github.com/aws/sagemaker-python-sdk/blob/e0b9d38e1e3b48647a02af23c4be54980e53dc61/src/sagemaker/image_uri_config/huggingface.json#L21)找到它们'
- en: '`region`: The AWS region where you want to use it.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`region`: 您想要使用的AWS区域。'
- en: '`framework`: The framework you want to use, either `pytorch` or `tensorflow`.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`framework`: 您想要使用的框架，可以是`pytorch`或`tensorflow`。'
- en: '`(training | inference)`: The training or inference mode.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(training | inference)`: 训练或推理模式。'
- en: '`framework-version`: The version of the framework you want to use.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`framework-version`: 您想要使用的框架的版本。'
- en: '`transformers-version`: The version of the transformers library you want to
    use.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformers-version`: 您想要使用的transformers库的版本。'
- en: '`device`: The device you want to use, either `cpu` or `gpu`.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device`: 您想要使用的设备，可以是`cpu`或`gpu`。'
- en: '`python-version`: The version of the python of the DLC.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`python-version`: DLC的Python版本。'
- en: '`device-tag`: The device tag you want to use. The device tag can include os
    version and cuda version'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device-tag`: 您想要使用的设备标签。设备标签可以包括操作系统版本和cuda版本'
- en: '**Example 1: PyTorch Training:** `763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.6.0-transformers4.4.2-gpu-py36-cu110-ubuntu18.04`
    **Example 2: Tensorflow Inference:** `763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-tensorflow-inference:2.4.1-transformers4.6.1-cpu-py37-ubuntu18.04`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例1：PyTorch训练：** `763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.6.0-transformers4.4.2-gpu-py36-cu110-ubuntu18.04`
    **示例2：Tensorflow推理：** `763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-tensorflow-inference:2.4.1-transformers4.6.1-cpu-py37-ubuntu18.04`'
- en: Training DLC Overview
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练DLC概述
- en: The Training DLC overview includes all released and available Hugging Face Training
    DLCs. It includes PyTorch and TensorFlow flavored versions for GPU.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 训练DLC概述包括所有发布和可用的Hugging Face训练DLC。它包括用于GPU的PyTorch和TensorFlow版本。
- en: '| 🤗 Transformers version | 🤗 Datasets version | PyTorch/TensorFlow version
    | type | device | Python Version |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 🤗 Transformers版本 | 🤗 数据集版本 | PyTorch/TensorFlow版本 | 类型 | 设备 | Python版本 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 4.4.2 | 1.5.0 | PyTorch 1.6.0 | training | GPU | 3.6 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 4.4.2 | 1.5.0 | PyTorch 1.6.0 | 训练 | GPU | 3.6 |'
- en: '| 4.4.2 | 1.5.0 | TensorFlow 2.4.1 | training | GPU | 3.7 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 4.4.2 | 1.5.0 | TensorFlow 2.4.1 | 训练 | GPU | 3.7 |'
- en: '| 4.5.0 | 1.5.0 | PyTorch 1.6.0 | training | GPU | 3.6 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 4.5.0 | 1.5.0 | PyTorch 1.6.0 | 训练 | GPU | 3.6 |'
- en: '| 4.5.0 | 1.5.0 | TensorFlow 2.4.1 | training | GPU | 3.7 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 4.5.0 | 1.5.0 | TensorFlow 2.4.1 | 训练 | GPU | 3.7 |'
- en: '| 4.6.1 | 1.6.2 | PyTorch 1.6.0 | training | GPU | 3.6 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 4.6.1 | 1.6.2 | PyTorch 1.6.0 | 训练 | GPU | 3.6 |'
- en: '| 4.6.1 | 1.6.2 | PyTorch 1.7.1 | training | GPU | 3.6 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 4.6.1 | 1.6.2 | PyTorch 1.7.1 | 训练 | GPU | 3.6 |'
- en: '| 4.6.1 | 1.6.2 | TensorFlow 2.4.1 | training | GPU | 3.7 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 4.6.1 | 1.6.2 | TensorFlow 2.4.1 | 训练 | GPU | 3.7 |'
- en: '| 4.10.2 | 1.11.0 | PyTorch 1.8.1 | training | GPU | 3.6 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | 1.11.0 | PyTorch 1.8.1 | 训练 | GPU | 3.6 |'
- en: '| 4.10.2 | 1.11.0 | PyTorch 1.9.0 | training | GPU | 3.8 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | 1.11.0 | PyTorch 1.9.0 | 训练 | GPU | 3.8 |'
- en: '| 4.10.2 | 1.11.0 | TensorFlow 2.4.1 | training | GPU | 3.7 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | 1.11.0 | TensorFlow 2.4.1 | 训练 | GPU | 3.7 |'
- en: '| 4.10.2 | 1.11.0 | TensorFlow 2.5.1 | training | GPU | 3.7 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | 1.11.0 | TensorFlow 2.5.1 | 训练 | GPU | 3.7 |'
- en: '| 4.11.0 | 1.12.1 | PyTorch 1.9.0 | training | GPU | 3.8 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 4.11.0 | 1.12.1 | PyTorch 1.9.0 | 训练 | GPU | 3.8 |'
- en: '| 4.11.0 | 1.12.1 | TensorFlow 2.5.1 | training | GPU | 3.7 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 4.11.0 | 1.12.1 | TensorFlow 2.5.1 | 训练 | GPU | 3.7 |'
- en: '| 4.12.3 | 1.15.1 | PyTorch 1.9.1 | training | GPU | 3.8 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 4.12.3 | 1.15.1 | PyTorch 1.9.1 | 训练 | GPU | 3.8 |'
- en: '| 4.12.3 | 1.15.1 | TensorFlow 2.5.1 | training | GPU | 3.7 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 4.12.3 | 1.15.1 | TensorFlow 2.5.1 | 训练 | GPU | 3.7 |'
- en: '| 4.17.0 | 1.18.4 | PyTorch 1.10.2 | training | GPU | 3.8 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 4.17.0 | 1.18.4 | PyTorch 1.10.2 | 训练 | GPU | 3.8 |'
- en: '| 4.17.0 | 1.18.4 | TensorFlow 2.6.3 | training | GPU | 3.8 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 4.17.0 | 1.18.4 | TensorFlow 2.6.3 | 训练 | GPU | 3.8 |'
- en: '| 4.26.0 | 2.9.0 | PyTorch 1.13.1 | training | GPU | 3.9 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 4.26.0 | 2.9.0 | PyTorch 1.13.1 | 训练 | GPU | 3.9 |'
- en: Inference DLC Overview
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理DLC概述
- en: The Inference DLC overview includes all released and available Hugging Face
    Inference DLCs. It includes PyTorch and TensorFlow flavored versions for CPU,
    GPU & AWS Inferentia.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 推理DLC概述包括所有发布和可用的Hugging Face推理DLC。它包括用于CPU、GPU和AWS Inferentia的PyTorch和TensorFlow版本。
- en: '| 🤗 Transformers version | PyTorch/TensorFlow version | type | device | Python
    Version |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 🤗 Transformers版本 | PyTorch/TensorFlow版本 | 类型 | 设备 | Python版本 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 4.6.1 | PyTorch 1.7.1 | inference | CPU | 3.6 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 4.6.1 | PyTorch 1.7.1 | 推理 | CPU | 3.6 |'
- en: '| 4.6.1 | PyTorch 1.7.1 | inference | GPU | 3.6 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 4.6.1 | PyTorch 1.7.1 | 推理 | GPU | 3.6 |'
- en: '| 4.6.1 | TensorFlow 2.4.1 | inference | CPU | 3.7 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 4.6.1 | TensorFlow 2.4.1 | 推理 | CPU | 3.7 |'
- en: '| 4.6.1 | TensorFlow 2.4.1 | inference | GPU | 3.7 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 4.6.1 | TensorFlow 2.4.1 | 推理 | GPU | 3.7 |'
- en: '| 4.10.2 | PyTorch 1.8.1 | inference | GPU | 3.6 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | PyTorch 1.8.1 | 推理 | GPU | 3.6 |'
- en: '| 4.10.2 | PyTorch 1.9.0 | inference | GPU | 3.8 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | PyTorch 1.9.0 | 推理 | GPU | 3.8 |'
- en: '| 4.10.2 | TensorFlow 2.4.1 | inference | GPU | 3.7 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | TensorFlow 2.4.1 | 推理 | GPU | 3.7 |'
- en: '| 4.10.2 | TensorFlow 2.5.1 | inference | GPU | 3.7 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | TensorFlow 2.5.1 | 推理 | GPU | 3.7 |'
- en: '| 4.10.2 | PyTorch 1.8.1 | inference | CPU | 3.6 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | PyTorch 1.8.1 | 推理 | CPU | 3.6 |'
- en: '| 4.10.2 | PyTorch 1.9.0 | inference | CPU | 3.8 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | PyTorch 1.9.0 | 推理 | CPU | 3.8 |'
- en: '| 4.10.2 | TensorFlow 2.4.1 | inference | CPU | 3.7 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | TensorFlow 2.4.1 | 推理 | CPU | 3.7 |'
- en: '| 4.10.2 | TensorFlow 2.5.1 | inference | CPU | 3.7 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 4.10.2 | TensorFlow 2.5.1 | 推理 | CPU | 3.7 |'
- en: '| 4.11.0 | PyTorch 1.9.0 | inference | GPU | 3.8 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 4.11.0 | PyTorch 1.9.0 | 推理 | GPU | 3.8 |'
- en: '| 4.11.0 | TensorFlow 2.5.1 | inference | GPU | 3.7 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 4.11.0 | TensorFlow 2.5.1 | 推理 | GPU | 3.7 |'
- en: '| 4.11.0 | PyTorch 1.9.0 | inference | CPU | 3.8 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 4.11.0 | PyTorch 1.9.0 | 推理 | CPU | 3.8 |'
- en: '| 4.11.0 | TensorFlow 2.5.1 | inference | CPU | 3.7 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 4.11.0 | TensorFlow 2.5.1 | 推理 | CPU | 3.7 |'
- en: '| 4.12.3 | PyTorch 1.9.1 | inference | GPU | 3.8 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 4.12.3 | PyTorch 1.9.1 | 推理 | GPU | 3.8 |'
- en: '| 4.12.3 | TensorFlow 2.5.1 | inference | GPU | 3.7 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 4.12.3 | TensorFlow 2.5.1 | 推理 | GPU | 3.7 |'
- en: '| 4.12.3 | PyTorch 1.9.1 | inference | CPU | 3.8 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 4.12.3 | PyTorch 1.9.1 | 推理 | CPU | 3.8 |'
- en: '| 4.12.3 | TensorFlow 2.5.1 | inference | CPU | 3.7 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 4.12.3 | TensorFlow 2.5.1 | 推理 | CPU | 3.7 |'
- en: '| 4.12.3 | PyTorch 1.9.1 | inference | Inferentia | 3.7 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 4.12.3 | PyTorch 1.9.1 | 推理 | Inferentia | 3.7 |'
- en: '| 4.17.0 | PyTorch 1.10.2 | inference | GPU | 3.8 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 4.17.0 | PyTorch 1.10.2 | 推理 | GPU | 3.8 |'
- en: '| 4.17.0 | TensorFlow 2.6.3 | inference | GPU | 3.8 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 4.17.0 | TensorFlow 2.6.3 | 推理 | GPU | 3.8 |'
- en: '| 4.17.0 | PyTorch 1.10.2 | inference | CPU | 3.8 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 4.17.0 | PyTorch 1.10.2 | 推理 | CPU | 3.8 |'
- en: '| 4.17.0 | TensorFlow 2.6.3 | inference | CPU | 3.8 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 4.17.0 | TensorFlow 2.6.3 | 推理 | CPU | 3.8 |'
- en: '| 4.26.0 | PyTorch 1.13.1 | inference | CPU | 3.9 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 4.26.0 | PyTorch 1.13.1 | 推理 | CPU | 3.9 |'
- en: '| 4.26.0 | PyTorch 1.13.1 | inference | GPU | 3.9 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 4.26.0 | PyTorch 1.13.1 | 推理 | GPU | 3.9 |'
- en: Hugging Face Transformers Amazon SageMaker Examples
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Face Transformers Amazon SageMaker 示例
- en: Example Jupyter notebooks that demonstrate how to build, train, and deploy [Hugging
    Face Transformers](https://github.com/huggingface/transformers) using [Amazon
    SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html) and the
    [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 展示如何使用 Amazon SageMaker 和 Amazon SageMaker Python SDK 构建、训练和部署 Hugging Face
    Transformers 的示例 Jupyter 笔记本
- en: '| Notebook | Type | Description |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| [01 Getting started with PyTorch](https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/sagemaker-notebook.ipynb)
    | Training | Getting started end-to-end example on how to fine-tune a pre-trained
    Hugging Face Transformer for Text-Classification using PyTorch |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| [01 PyTorch 入门](https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/sagemaker-notebook.ipynb)
    | 训练 | 使用 PyTorch 对预训练的 Hugging Face Transformer 进行文本分类微调的入门端到端示例 |'
- en: '| [02 getting started with TensorFlow](https://github.com/huggingface/notebooks/blob/main/sagemaker/02_getting_started_tensorflow/sagemaker-notebook.ipynb)
    | Training | Getting started end-to-end example on how to fine-tune a pre-trained
    Hugging Face Transformer for Text-Classification using TensorFlow |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| [02 TensorFlow 入门](https://github.com/huggingface/notebooks/blob/main/sagemaker/02_getting_started_tensorflow/sagemaker-notebook.ipynb)
    | 训练 | 使用 TensorFlow 对预训练的 Hugging Face Transformer 进行文本分类微调的入门端到端示例 |'
- en: '| [03 Distributed Training: Data Parallelism](https://github.com/huggingface/notebooks/blob/main/sagemaker/03_distributed_training_data_parallelism/sagemaker-notebook.ipynb)
    | Training | End-to-end example on how to use distributed training with data-parallelism
    strategy for fine-tuning a pre-trained Hugging Face Transformer for Question-Answering
    using Amazon SageMaker Data Parallelism |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| [03 分布式训练：数据并行](https://github.com/huggingface/notebooks/blob/main/sagemaker/03_distributed_training_data_parallelism/sagemaker-notebook.ipynb)
    | 训练 | 使用数据并行策略对预训练的 Hugging Face Transformer 进行问答微调的分布式训练端到端示例，使用 Amazon SageMaker
    数据并行 |'
- en: '| [04 Distributed Training: Model Parallelism](https://github.com/huggingface/notebooks/blob/main/sagemaker/04_distributed_training_model_parallelism/sagemaker-notebook.ipynb)
    | Training | End-to-end example on how to use distributed training with model-parallelism
    strategy to pre-trained Hugging Face Transformer using Amazon SageMaker Model
    Parallelism |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| [04 分布式训练：模型并行](https://github.com/huggingface/notebooks/blob/main/sagemaker/04_distributed_training_model_parallelism/sagemaker-notebook.ipynb)
    | 训练 | 使用模型并行策略对预训练的 Hugging Face Transformer 进行分布式训练的端到端示例，使用 Amazon SageMaker
    模型并行 |'
- en: '| [05 How to use Spot Instances & Checkpointing](https://github.com/huggingface/notebooks/blob/main/sagemaker/05_spot_instances/sagemaker-notebook.ipynb)
    | Training | End-to-end example on how to use Spot Instances and Checkpointing
    to reduce training cost |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| [05 如何使用 Spot 实例和检查点](https://github.com/huggingface/notebooks/blob/main/sagemaker/05_spot_instances/sagemaker-notebook.ipynb)
    | 训练 | 使用 Spot 实例和检查点来降低训练成本的端到端示例 |'
- en: '| [06 Experiment Tracking with SageMaker Metrics](https://github.com/huggingface/notebooks/blob/main/sagemaker/06_sagemaker_metrics/sagemaker-notebook.ipynb)
    | Training | End-to-end example on how to use SageMaker metrics to track your
    experiments and training jobs |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| [06 使用 SageMaker Metrics 进行实验跟踪](https://github.com/huggingface/notebooks/blob/main/sagemaker/06_sagemaker_metrics/sagemaker-notebook.ipynb)
    | 训练 | 使用 SageMaker 指标跟踪实验和训练作业的端到端示例'
- en: '| [07 Distributed Training: Data Parallelism](https://github.com/huggingface/notebooks/blob/main/sagemaker/07_tensorflow_distributed_training_data_parallelism/sagemaker-notebook.ipynb)
    | Training | End-to-end example on how to use Amazon SageMaker Data Parallelism
    with TensorFlow |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| [07 分布式训练：数据并行](https://github.com/huggingface/notebooks/blob/main/sagemaker/07_tensorflow_distributed_training_data_parallelism/sagemaker-notebook.ipynb)
    | 训练 | 使用 TensorFlow 和 Amazon SageMaker 数据并行的端到端示例 |'
- en: '| [08 Distributed Training: Summarization with T5/BART](https://github.com/huggingface/notebooks/blob/main/sagemaker/08_distributed_summarization_bart_t5/sagemaker-notebook.ipynb)
    | Training | End-to-end example on how to fine-tune BART/T5 for Summarization
    using Amazon SageMaker Data Parallelism |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| [08 分布式训练：T5/BART 摘要](https://github.com/huggingface/notebooks/blob/main/sagemaker/08_distributed_summarization_bart_t5/sagemaker-notebook.ipynb)
    | 训练 | 使用 Amazon SageMaker 数据并行对 BART/T5 进行摘要微调的端到端示例 |'
- en: '| [09 Vision: Fine-tune ViT](https://github.com/huggingface/notebooks/blob/main/sagemaker/09_image_classification_vision_transformer/sagemaker-notebook.ipynb)
    | Training | End-to-end example on how to fine-tune Vision Transformer for Image-Classification
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| [09 视觉：微调 ViT](https://github.com/huggingface/notebooks/blob/main/sagemaker/09_image_classification_vision_transformer/sagemaker-notebook.ipynb)
    | 训练 | 使用 Vision Transformer 进行图像分类的端到端微调示例 |'
- en: '| [10 Deploy HF Transformer from Amazon S3](https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb)
    | Inference | End-to-end example on how to deploy a model from Amazon S3 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| [10 从Amazon S3部署HF Transformer](https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb)
    | 推理 | 有关如何从Amazon S3部署模型的端到端示例 |'
- en: '| [11 Deploy HF Transformer from Hugging Face Hub](https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb)
    | Inference | End-to-end example on how to deploy a model from the Hugging Face
    Hub |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| [11 从Hugging Face Hub部署HF Transformer](https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb)
    | 推理 | 有关如何从Hugging Face Hub部署模型的端到端示例 |'
- en: '| [12 Batch Processing with Amazon SageMaker Batch Transform](https://github.com/huggingface/notebooks/blob/main/sagemaker/12_batch_transform_inference/sagemaker-notebook.ipynb)
    | Inference | End-to-end example on how to do batch processing with Amazon SageMaker
    Batch Transform |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| [12 使用Amazon SageMaker批量转换进行批处理处理](https://github.com/huggingface/notebooks/blob/main/sagemaker/12_batch_transform_inference/sagemaker-notebook.ipynb)
    | 推理 | 有关如何使用Amazon SageMaker批量转换进行批处理处理的端到端示例 |'
- en: '| [13 Autoscaling SageMaker Endpoints](https://github.com/huggingface/notebooks/blob/main/sagemaker/13_deploy_and_autoscaling_transformers/sagemaker-notebook.ipynb)
    | Inference | End-to-end example on how to do use autoscaling for a HF Endpoint
    |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| [13 自动缩放SageMaker端点](https://github.com/huggingface/notebooks/blob/main/sagemaker/13_deploy_and_autoscaling_transformers/sagemaker-notebook.ipynb)
    | 推理 | 有关如何为HF端点使用自动缩放的端到端示例 |'
- en: '| [14 Fine-tune and push to Hub](https://github.com/huggingface/notebooks/blob/main/sagemaker/14_train_and_push_to_hub/sagemaker-notebook.ipynb)
    | Training | End-to-end example on how to do use the Hugging Face Hub as MLOps
    backend for saving checkpoints during training |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| [14 微调并推送到Hub](https://github.com/huggingface/notebooks/blob/main/sagemaker/14_train_and_push_to_hub/sagemaker-notebook.ipynb)
    | 训练 | 有关如何将Hugging Face Hub用作MLOps后端以在训练期间保存检查点的端到端示例 |'
- en: '| [15 Training Compiler](https://github.com/huggingface/notebooks/blob/main/sagemaker/15_training_compiler/sagemaker-notebook.ipynb)
    | Training | End-to-end example on how to do use Amazon SageMaker Training Compiler
    to speed up training time |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| [15 训练编译器](https://github.com/huggingface/notebooks/blob/main/sagemaker/15_training_compiler/sagemaker-notebook.ipynb)
    | 训练 | 有关如何使用Amazon SageMaker训练编译器加快训练时间的端到端示例 |'
- en: '| [16 Asynchronous Inference](https://github.com/huggingface/notebooks/blob/main/sagemaker/16_async_inference_hf_hub/sagemaker-notebook.ipynb)
    | Inference | End-to-end example on how to do use Amazon SageMaker Asynchronous
    Inference endpoints with Hugging Face Transformers |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| [16 异步推理](https://github.com/huggingface/notebooks/blob/main/sagemaker/16_async_inference_hf_hub/sagemaker-notebook.ipynb)
    | 推理 | 有关如何使用Amazon SageMaker异步推理端点与Hugging Face Transformers的端到端示例 |'
- en: '| [17 Custom inference.py script](https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb)
    | Inference | End-to-end example on how to create a custom inference.py for Sentence
    Transformers and sentence embeddings |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| [17 自定义推理.py脚本](https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb)
    | 推理 | 有关如何为句子转换器和句子嵌入创建自定义推理.py的端到端示例 |'
- en: '| [18 AWS Inferentia](https://github.com/huggingface/notebooks/blob/main/sagemaker/18_inferentia_inference/sagemaker-notebook.ipynb)
    | Inference | End-to-end example on how to AWS Inferentia to speed up inference
    time |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| [18 AWS Inferentia](https://github.com/huggingface/notebooks/blob/main/sagemaker/18_inferentia_inference/sagemaker-notebook.ipynb)
    | 推理 | 有关如何使用AWS Inferentia加快推理时间的端到端示例 |'
- en: Inference Toolkit API
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理工具包API
- en: The Inference Toolkit accepts inputs in the `inputs` key, and supports additional
    [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines)
    parameters in the `parameters` key. You can provide any of the supported `kwargs`
    from `pipelines` as `parameters`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 推理工具包接受`inputs`键中的输入，并在`parameters`键中支持额外的[`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines)参数。您可以将`pipelines`中支持的任何`kwargs`作为`parameters`提供。
- en: 'Tasks supported by the Inference Toolkit API include:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 推理工具包API支持的任务包括：
- en: '**`text-classification`**'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`text-classification`**'
- en: '**`sentiment-analysis`**'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`sentiment-analysis`**'
- en: '**`token-classification`**'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`token-classification`**'
- en: '**`feature-extraction`**'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`feature-extraction`**'
- en: '**`fill-mask`**'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`fill-mask`**'
- en: '**`summarization`**'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`summarization`**'
- en: '**`translation_xx_to_yy`**'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`translation_xx_to_yy`**'
- en: '**`text2text-generation`**'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`text2text-generation`**'
- en: '**`text-generation`**'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`text-generation`**'
- en: '**`audio-classificatin`**'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`audio-classificatin`**'
- en: '**`automatic-speech-recognition`**'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`automatic-speech-recognition`**'
- en: '**`conversational`**'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`conversational`**'
- en: '**`image-classification`**'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`image-classification`**'
- en: '**`image-segmentation`**'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`image-segmentation`**'
- en: '**`object-detection`**'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`object-detection`**'
- en: '**`table-question-answering`**'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`table-question-answering`**'
- en: '**`zero-shot-classification`**'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`zero-shot-classification`**'
- en: '**`zero-shot-image-classification`**'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`zero-shot-image-classification`**'
- en: 'See the following request examples for some of the tasks:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下请求示例，了解一些任务：
- en: '**`text-classification`**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**`text-classification`**'
- en: '[PRE0]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**`sentiment-analysis`**'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**`sentiment-analysis`**'
- en: '[PRE1]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**`token-classification`**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**`token-classification`**'
- en: '[PRE2]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**`question-answering`**'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**`question-answering`**'
- en: '[PRE3]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**`zero-shot-classification`**'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**`zero-shot-classification`**'
- en: '[PRE4]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**`table-question-answering`**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**`table-question-answering`**'
- en: '[PRE5]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**`parameterized-request`**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**`parameterized-request`**'
- en: '[PRE6]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Inference Toolkit environment variables
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理工具包环境变量
- en: 'The Inference Toolkit implements various additional environment variables to
    simplify deployment. A complete list of Hugging Face specific environment variables
    is shown below:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 推理工具包实现了各种额外的环境变量以简化部署。下面显示了Hugging Face特定环境变量的完整列表：
- en: '**`HF_TASK`**'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**`HF_TASK`**'
- en: '`HF_TASK` defines the task for the 🤗 Transformers pipeline used . See [here](https://huggingface.co/docs/transformers/main_classes/pipelines)
    for a complete list of tasks.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`HF_TASK`定义了🤗 Transformers管道使用的任务。请参阅[此处](https://huggingface.co/docs/transformers/main_classes/pipelines)获取任务的完整列表。'
- en: '[PRE7]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**`HF_MODEL_ID`**'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**`HF_MODEL_ID`**'
- en: '`HF_MODEL_ID` defines the model ID which is automatically loaded from [hf.co/models](https://huggingface.co/models)
    when creating a SageMaker endpoint. All of the 🤗 Hub’s 10,000+ models are available
    through this environment variable.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`HF_MODEL_ID` 定义了模型 ID，在创建 SageMaker 端点时会自动从 [hf.co/models](https://huggingface.co/models)
    加载。所有 🤗 Hub 的 10,000 多个模型都可以通过这个环境变量获得。'
- en: '[PRE8]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**`HF_MODEL_REVISION`**'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**`HF_MODEL_REVISION`**'
- en: '`HF_MODEL_REVISION` is an extension to `HF_MODEL_ID` and allows you to define
    or pin a model revision to make sure you always load the same model on your SageMaker
    endpoint.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`HF_MODEL_REVISION` 是 `HF_MODEL_ID` 的扩展，允许您定义或固定一个模型修订版本，以确保您始终在 SageMaker
    端点上加载相同的模型。'
- en: '[PRE9]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**`HF_API_TOKEN`**'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**`HF_API_TOKEN`**'
- en: '`HF_API_TOKEN` defines your Hugging Face authorization token. The `HF_API_TOKEN`
    is used as a HTTP bearer authorization for remote files like private models. You
    can find your token under [Settings](https://huggingface.co/settings/tokens) of
    your Hugging Face account.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`HF_API_TOKEN` 定义了您的 Hugging Face 授权令牌。`HF_API_TOKEN` 被用作远程文件（如私有模型）的 HTTP
    bearer 授权。您可以在您的 Hugging Face 账户的 [设置](https://huggingface.co/settings/tokens)
    下找到您的令牌。'
- en: '[PRE10]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
