# ğŸ¤— Hugging Face Agents.js

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/huggingface.js/agents/README](https://huggingface.co/docs/huggingface.js/agents/README)

ä¸€ç§ä»è‡ªç„¶è¯­è¨€ä¸­è°ƒç”¨Hugging Faceæ¨¡å‹å’Œæ¨ç†ç«¯ç‚¹çš„æ–¹æ³•ï¼Œä½¿ç”¨LLMã€‚

## å®‰è£…

```py
pnpm add @huggingface/agents

npm add @huggingface/agents

yarn add @huggingface/agents
```

### Deno

```py
// esm.sh
import { HfAgent } from "https://esm.sh/@huggingface/agent"
// or npm:
import { HfAgent } from "npm:@huggingface/agent"
```

## ç”¨æ³•

Agents.jsåˆ©ç”¨åœ¨HFä¸Šæ‰˜ç®¡çš„LLMä½œä¸ºæ¨ç†ç«¯ç‚¹ï¼Œå› æ­¤æ‚¨éœ€è¦åˆ›å»ºä¸€ä¸ªå¸æˆ·å¹¶ç”Ÿæˆä¸€ä¸ª[è®¿é—®ä»¤ç‰Œ](https://huggingface.co/settings/tokens)ã€‚

```py
import { HfAgent } from "@huggingface/agents";

const agent = new HfAgent("hf_...");

const code = await agent.generateCode("Draw a picture of a cat, wearing a top hat.")
console.log(code) // always good to check the generated code before running it
const outputs = await agent.evaluateCode(code);
console.log(outputs) 
```

### é€‰æ‹©æ‚¨çš„LLM

æ‚¨è¿˜å¯ä»¥é€šè¿‡è°ƒç”¨`LLMFrom*`å‡½æ•°ä¹‹ä¸€æ¥ä½¿ç”¨è‡ªå·±çš„LLMã€‚

#### æ¥è‡ªhub

åªè¦å®ƒä»¬æœ‰APIï¼Œæ‚¨å¯ä»¥æŒ‡å®šhubä¸Šçš„ä»»ä½•æœ‰æ•ˆæ¨¡å‹ã€‚

```py
import { HfAgent, LLMFromHub } from "@huggingface/agents";

const agent = new HfAgent(
  "hf_...",
  LLMFromHub("hf_...", "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5")
);
```

#### ä»æ‚¨è‡ªå·±çš„ç«¯ç‚¹

æ‚¨è¿˜å¯ä»¥æŒ‡å®šè‡ªå·±çš„ç«¯ç‚¹ï¼Œåªè¦å®ƒå®ç°ç›¸åŒçš„APIï¼Œä¾‹å¦‚ä½¿ç”¨[text generation inference](https://github.com/huggingface/text-generation-inference)å’Œ[Inference Endpoints](https://huggingface.co/inference-endpoints)ã€‚

```py
import { HfAgent, LLMFromEndpoint } from "@huggingface/agents";

const agent = new HfAgent(
  "hf_...",
  LLMFromEndpoint("hf_...", "http://...")
);
```

#### è‡ªå®šä¹‰LLM

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒLLMè¢«å®šä¹‰ä¸ºä»»ä½•å¼‚æ­¥å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²è¾“å…¥å¹¶è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³è¦ä½¿ç”¨OpenAI APIï¼Œæ‚¨å¯ä»¥è¿™æ ·åšï¼š

```py
import { HfAgent } from "@huggingface/agents";
import { Configuration, OpenAIApi } from "openai";

const api = new OpenAIApi(new Configuration({ apiKey: "sk-..." }));

const llmOpenAI = async (prompt: string): Promise<string> => {
  return (
    (
      await api.createCompletion({
        model: "text-davinci-003",
        prompt: prompt,
        max_tokens: 1000,
      })
    ).data.choices[0].text ?? ""
  );
};

const agent = new HfAgent(
  "hf_...",
  llmOpenAI
);

// do anything you want with the agent here

```

### å·¥å…·

é»˜è®¤æƒ…å†µä¸‹ï¼Œä»£ç†ç¨‹åºé…å¤‡æœ‰4ç§å·¥å…·ã€‚ ï¼ˆtextToImageï¼ŒtextToSpeechï¼ŒimageToTextï¼ŒspeechToTextï¼‰

ä½†æ˜¯æ‚¨å¯ä»¥é€šè¿‡åˆ›å»ºæ–°å·¥å…·å¹¶åœ¨åˆå§‹åŒ–æ—¶ä¼ é€’å®ƒä»¬æ¥è½»æ¾æ‰©å±•å·¥å…·åˆ—è¡¨ã€‚

```py
import { HfAgent, defaultTools, LLMFromHub } from "@huggingface/agents";
import type { Tool } from "@huggingface/agents/src/types";

// define the tool
const uppercaseTool: Tool = {
    name: "uppercase",
    description: "uppercase the input string and returns it ",
    examples: [
        {
            prompt: "uppercase the string: hello world",
            code: `const output = uppercase("hello world")`,
            tools: ["uppercase"],
        },
    ],
    call: async (input) => {
        const data = await input;
        if (typeof data !== "string") {
            throw new Error("Input must be a string");
        }
        return data.toUpperCase();
    },
};

// pass it in the agent
const agent = new HfAgent(process.env.HF_TOKEN,
                LLMFromHub("hf_...", "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5"),
                [uppercaseTool, ...defaultTools]);
```

## ä¾èµ–

+   `@huggingface/inference`ï¼šéœ€è¦è°ƒç”¨æ¨ç†ç«¯ç‚¹æœ¬èº«ã€‚
