["```py\npip install --upgrade pip\npip install --upgrade transformers g2p-en\n```", "```py\n\nfrom transformers import FastSpeech2ConformerTokenizer, FastSpeech2ConformerModel, FastSpeech2ConformerHifiGan\nimport soundfile as sf\n\ntokenizer = FastSpeech2ConformerTokenizer.from_pretrained(\"espnet/fastspeech2_conformer\")\ninputs = tokenizer(\"Hello, my dog is cute.\", return_tensors=\"pt\")\ninput_ids = inputs[\"input_ids\"]\n\nmodel = FastSpeech2ConformerModel.from_pretrained(\"espnet/fastspeech2_conformer\")\noutput_dict = model(input_ids, return_dict=True)\nspectrogram = output_dict[\"spectrogram\"]\n\nhifigan = FastSpeech2ConformerHifiGan.from_pretrained(\"espnet/fastspeech2_conformer_hifigan\")\nwaveform = hifigan(spectrogram)\n\nsf.write(\"speech.wav\", waveform.squeeze().detach().numpy(), samplerate=22050)\n```", "```py\nfrom transformers import FastSpeech2ConformerTokenizer, FastSpeech2ConformerWithHifiGan\nimport soundfile as sf\n\ntokenizer = FastSpeech2ConformerTokenizer.from_pretrained(\"espnet/fastspeech2_conformer\")\ninputs = tokenizer(\"Hello, my dog is cute.\", return_tensors=\"pt\")\ninput_ids = inputs[\"input_ids\"]\n\nmodel = FastSpeech2ConformerWithHifiGan.from_pretrained(\"espnet/fastspeech2_conformer_with_hifigan\")\noutput_dict = model(input_ids, return_dict=True)\nwaveform = output_dict[\"waveform\"]\n\nsf.write(\"speech.wav\", waveform.squeeze().detach().numpy(), samplerate=22050)\n```", "```py\nfrom transformers import pipeline, FastSpeech2ConformerHifiGan\nimport soundfile as sf\n\nvocoder = FastSpeech2ConformerHifiGan.from_pretrained(\"espnet/fastspeech2_conformer_hifigan\")\nsynthesiser = pipeline(model=\"espnet/fastspeech2_conformer\", vocoder=vocoder)\n\nspeech = synthesiser(\"Hello, my dog is cooler than you!\")\n\nsf.write(\"speech.wav\", speech[\"audio\"].squeeze(), samplerate=speech[\"sampling_rate\"])\n```", "```py\n>>> from transformers import FastSpeech2ConformerModel, FastSpeech2ConformerConfig\n\n>>> # Initializing a FastSpeech2Conformer style configuration\n>>> configuration = FastSpeech2ConformerConfig()\n\n>>> # Initializing a model from the FastSpeech2Conformer style configuration\n>>> model = FastSpeech2ConformerModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import FastSpeech2ConformerHifiGan, FastSpeech2ConformerHifiGanConfig\n\n>>> # Initializing a FastSpeech2ConformerHifiGan configuration\n>>> configuration = FastSpeech2ConformerHifiGanConfig()\n\n>>> # Initializing a model (with random weights) from the configuration\n>>> model = FastSpeech2ConformerHifiGan(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import (\n...     FastSpeech2ConformerConfig,\n...     FastSpeech2ConformerHifiGanConfig,\n...     FastSpeech2ConformerWithHifiGanConfig,\n...     FastSpeech2ConformerWithHifiGan,\n... )\n\n>>> # Initializing FastSpeech2ConformerWithHifiGan sub-modules configurations.\n>>> model_config = FastSpeech2ConformerConfig()\n>>> vocoder_config = FastSpeech2ConformerHifiGanConfig()\n\n>>> # Initializing a FastSpeech2ConformerWithHifiGan module style configuration\n>>> configuration = FastSpeech2ConformerWithHifiGanConfig(model_config.to_dict(), vocoder_config.to_dict())\n\n>>> # Initializing a model (with random weights)\n>>> model = FastSpeech2ConformerWithHifiGan(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import (\n...     FastSpeech2ConformerTokenizer,\n...     FastSpeech2ConformerModel,\n...     FastSpeech2ConformerHifiGan,\n... )\n\n>>> tokenizer = FastSpeech2ConformerTokenizer.from_pretrained(\"espnet/fastspeech2_conformer\")\n>>> inputs = tokenizer(\"some text to convert to speech\", return_tensors=\"pt\")\n>>> input_ids = inputs[\"input_ids\"]\n\n>>> model = FastSpeech2ConformerModel.from_pretrained(\"espnet/fastspeech2_conformer\")\n>>> output_dict = model(input_ids, return_dict=True)\n>>> spectrogram = output_dict[\"spectrogram\"]\n\n>>> vocoder = FastSpeech2ConformerHifiGan.from_pretrained(\"espnet/fastspeech2_conformer_hifigan\")\n>>> waveform = vocoder(spectrogram)\n>>> print(waveform.shape)\ntorch.Size([1, 49664])\n```", "```py\n>>> from transformers import (\n...     FastSpeech2ConformerTokenizer,\n...     FastSpeech2ConformerWithHifiGan,\n... )\n\n>>> tokenizer = FastSpeech2ConformerTokenizer.from_pretrained(\"espnet/fastspeech2_conformer\")\n>>> inputs = tokenizer(\"some text to convert to speech\", return_tensors=\"pt\")\n>>> input_ids = inputs[\"input_ids\"]\n\n>>> model = FastSpeech2ConformerWithHifiGan.from_pretrained(\"espnet/fastspeech2_conformer_with_hifigan\")\n>>> output_dict = model(input_ids, return_dict=True)\n>>> waveform = output_dict[\"waveform\"]\n>>> print(waveform.shape)\ntorch.Size([1, 49664])\n```"]