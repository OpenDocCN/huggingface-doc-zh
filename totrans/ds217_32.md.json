["```py\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"<username>/my_dataset\")\n```", "```py\n>>> audio_dataset = Dataset.from_dict({\"audio\": [\"path/to/audio_1\", \"path/to/audio_2\", ..., \"path/to/audio_n\"]}).cast_column(\"audio\", Audio())\n>>> audio_dataset[0][\"audio\"]\n{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,\n         0.        ,  0.        ], dtype=float32),\n 'path': 'path/to/audio_1',\n 'sampling_rate': 16000}\n```", "```py\naudio_dataset.push_to_hub(\"<username>/my_dataset\")\n```", "```py\nmy_dataset/\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 data/\n    \u2514\u2500\u2500 train-00000-of-00001.parquet\n```", "```py\nmy_dataset/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 metadata.csv\n\u2514\u2500\u2500 data/\n```", "```py\nfile_name,transcription\ndata/first_audio_file.mp3,znowu si\u0119 duch z cia\u0142em zro\u015bnie w m\u0142odocianej wstaniesz wiosnie i mo\u017cesz skutkiem tych lek\u00f3w umiera\u0107 wstawa\u0107 wiek wiek\u00f3w dalej tam by\u0142y przestrogi jak sieka\u0107 g\u0142ow\u0119 jak nogi\ndata/second_audio_file.mp3,ju\u017c u \u017awierzy\u0144ca podwoj\u00f3w kr\u00f3l zasiada przy nim ksi\u0105\u017c\u0119ta i panowie rada a gdzie wznios\u0142y kr\u0105\u017cy\u0142 ganek rycerze obok kochanek kr\u00f3l skin\u0105\u0142 palcem zacz\u0119to igrzysko\ndata/third_audio_file.mp3,pewnie k\u0119dy\u015b w ob\u0142\u0119dzie ubite min\u0119\u0142y szlaki zaczekajmy dzie\u0144 jaki po\u015blemy szuka\u0107 wsz\u0119dzie dzi\u015b jutro pewnie b\u0119dzie pos\u0142ali wsz\u0119dzie s\u0142ugi czekali dzie\u0144 i drugi gdy nic nie doczekali z p\u0142aczem chc\u0105 jecha\u0107 dali\n```", "```py\nmetadata.csv\ndata/first_audio_file.mp3\ndata/second_audio_file.mp3\ndata/third_audio_file.mp3\n\n```", "```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"audiofolder\", data_dir=\"/path/to/data\")\n>>> dataset[\"train\"][0]\n{'audio':\n    {'path': '/path/to/extracted/audio/first_audio_file.mp3',\n    'array': array([ 0.00088501,  0.0012207 ,  0.00131226, ..., -0.00045776, -0.00054932, -0.00054932], dtype=float32),\n    'sampling_rate': 16000},\n 'transcription': 'znowu si\u0119 duch z cia\u0142em zro\u015bnie w m\u0142odocianej wstaniesz wiosnie i mo\u017cesz skutkiem tych lek\u00f3w umiera\u0107 wstawa\u0107 wiek wiek\u00f3w dalej tam by\u0142y przestrogi jak sieka\u0107 g\u0142ow\u0119 jak nogi'\n}\n```", "```py\ndata/train/first_train_audio_file.mp3\ndata/train/second_train_audio_file.mp3\n\ndata/test/first_test_audio_file.mp3\ndata/test/second_test_audio_file.mp3\n\n```", "```py\ndata/train/electronic/01.mp3\ndata/train/punk/01.mp3\n\ndata/test/electronic/09.mp3\ndata/test/punk/09.mp3\n```", "```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"audiofolder\", data_dir=\"/path/to/data\")\n>>> dataset[\"train\"][0]\n{'audio':\n    {'path': '/path/to/electronic/01.mp3',\n     'array': array([ 3.9714024e-07,  7.3031038e-07,  7.5640685e-07, ...,\n         -1.1963668e-01, -1.1681189e-01, -1.1244172e-01], dtype=float32),\n     'sampling_rate': 44100},\n 'label': 0  # \"electronic\"\n}\n>>> dataset[\"train\"][-1]\n{'audio':\n    {'path': '/path/to/punk/01.mp3',\n     'array': array([0.15237972, 0.13222949, 0.10627693, ..., 0.41940814, 0.37578005,\n         0.33717662], dtype=float32),\n     'sampling_rate': 44100},\n 'label': 1  # \"punk\"\n}\n```", "```py\nmy_dataset/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 my_dataset.py\n\u2514\u2500\u2500 data/\n```", "```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"path/to/my_dataset\")\n```", "```py\nmy_dataset/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 my_dataset.py\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 train.tar.gz\n    \u251c\u2500\u2500 test.tar.gz\n    \u2514\u2500\u2500 metadata.csv\n```", "```py\nclass VivosDataset(datasets.GeneratorBasedBuilder):\n    \"\"\"VIVOS is a free Vietnamese speech corpus consisting of 15 hours of recording speech prepared for\n    Vietnamese Automatic Speech Recognition task.\"\"\"\n\n    def _info(self):\n\n    def _split_generators(self, dl_manager):\n\n    def _generate_examples(self, prompts_path, path_to_clips, audio_files):\n\n```", "```py\nclass LibriVoxIndonesiaConfig(datasets.BuilderConfig):\n    \"\"\"BuilderConfig for LibriVoxIndonesia.\"\"\"\n\n    def __init__(self, name, version, **kwargs):\n        self.language = kwargs.pop(\"language\", None)\n        self.release_date = kwargs.pop(\"release_date\", None)\n        self.num_clips = kwargs.pop(\"num_clips\", None)\n        self.num_speakers = kwargs.pop(\"num_speakers\", None)\n        self.validated_hr = kwargs.pop(\"validated_hr\", None)\n        self.total_hr = kwargs.pop(\"total_hr\", None)\n        self.size_bytes = kwargs.pop(\"size_bytes\", None)\n        self.size_human = size_str(self.size_bytes)\n        description = (\n            f\"LibriVox-Indonesia speech to text dataset in {self.language} released on {self.release_date}. \"\n            f\"The dataset comprises {self.validated_hr} hours of transcribed speech data\"\n        )\n        super(LibriVoxIndonesiaConfig, self).__init__(\n            name=name,\n            version=datasets.Version(version),\n            description=description,\n            **kwargs,\n        )\n```", "```py\nclass LibriVoxIndonesia(datasets.GeneratorBasedBuilder):\n    DEFAULT_CONFIG_NAME = \"all\"\n\n    BUILDER_CONFIGS = [\n        LibriVoxIndonesiaConfig(\n            name=lang,\n            version=STATS[\"version\"],\n            language=LANGUAGES[lang],\n            release_date=STATS[\"date\"],\n            num_clips=lang_stats[\"clips\"],\n            num_speakers=lang_stats[\"users\"],\n            total_hr=float(lang_stats[\"totalHrs\"]) if lang_stats[\"totalHrs\"] else None,\n            size_bytes=int(lang_stats[\"size\"]) if lang_stats[\"size\"] else None,\n        )\n        for lang, lang_stats in STATS[\"locales\"].items()\n    ]\n```", "```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"indonesian-nlp/librivox-indonesia\", \"bal\", split=\"train\")\n```", "```py\n>>> from datasets import load_dataset_builder\n>>> ds_builder = load_dataset_builder(\"vivos\")\n>>> ds_builder.info\n```", "```py\ndef _info(self):\n    return datasets.DatasetInfo(\n        description=_DESCRIPTION,\n        features=datasets.Features(\n            {\n                \"speaker_id\": datasets.Value(\"string\"),\n                \"path\": datasets.Value(\"string\"),\n                \"audio\": datasets.Audio(sampling_rate=16_000),\n                \"sentence\": datasets.Value(\"string\"),\n            }\n        ),\n        supervised_keys=None,\n        homepage=_HOMEPAGE,\n        license=_LICENSE,\n        citation=_CITATION,\n    )\n```", "```py\ndef _split_generators(self, dl_manager):\n    \"\"\"Returns SplitGenerators.\"\"\"\n    prompts_paths = dl_manager.download(_PROMPTS_URLS)\n    archive = dl_manager.download(_DATA_URL)\n    train_dir = \"vivos/train\"\n    test_dir = \"vivos/test\"\n\n    return [\n        datasets.SplitGenerator(\n            name=datasets.Split.TRAIN,\n            gen_kwargs={\n                \"prompts_path\": prompts_paths[\"train\"],\n                \"path_to_clips\": train_dir + \"/waves\",\n                \"audio_files\": dl_manager.iter_archive(archive),\n            },\n        ),\n        datasets.SplitGenerator(\n            name=datasets.Split.TEST,\n            gen_kwargs={\n                \"prompts_path\": prompts_paths[\"test\"],\n                \"path_to_clips\": test_dir + \"/waves\",\n                \"audio_files\": dl_manager.iter_archive(archive),\n            },\n        ),\n    ]\n```", "```py\nexamples = {}\nwith open(prompts_path, encoding=\"utf-8\") as f:\n    for row in f:\n        data = row.strip().split(\" \", 1)\n        speaker_id = data[0].split(\"_\")[0]\n        audio_path = \"/\".join([path_to_clips, speaker_id, data[0] + \".wav\"])\n        examples[audio_path] = {\n            \"speaker_id\": speaker_id,\n            \"path\": audio_path,\n            \"sentence\": data[1],\n        }\n```", "```py\ninside_clips_dir = False\nid_ = 0\nfor path, f in audio_files:\n    if path.startswith(path_to_clips):\n        inside_clips_dir = True\n        if path in examples:\n            audio = {\"path\": path, \"bytes\": f.read()}\n            yield id_, {**examples[path], \"audio\": audio}\n            id_ += 1\n    elif inside_clips_dir:\n        break\n```", "```py\ndef _generate_examples(self, prompts_path, path_to_clips, audio_files):\n    \"\"\"Yields examples as (key, example) tuples.\"\"\"\n    examples = {}\n    with open(prompts_path, encoding=\"utf-8\") as f:\n        for row in f:\n            data = row.strip().split(\" \", 1)\n            speaker_id = data[0].split(\"_\")[0]\n            audio_path = \"/\".join([path_to_clips, speaker_id, data[0] + \".wav\"])\n            examples[audio_path] = {\n                \"speaker_id\": speaker_id,\n                \"path\": audio_path,\n                \"sentence\": data[1],\n            }\n    inside_clips_dir = False\n    id_ = 0\n    for path, f in audio_files:\n        if path.startswith(path_to_clips):\n            inside_clips_dir = True\n            if path in examples:\n                audio = {\"path\": path, \"bytes\": f.read()}\n                yield id_, {**examples[path], \"audio\": audio}\n                id_ += 1\n        elif inside_clips_dir:\n            break\n```", "```py\n>>> from datasets import load_dataset\n>>> load_dataset(\"<username>/my_dataset\")\n```", "```py\n    local_extracted_archive = dl_manager.extract(audio_path) if not dl_manager.is_streaming else None\n    ```", "```py\ndef _split_generators(self, dl_manager):\n    \"\"\"Returns SplitGenerators.\"\"\"\n    dl_manager.download_config.ignore_url_params = True\n\n    audio_path = dl_manager.download(_AUDIO_URL)\n    local_extracted_archive = dl_manager.extract(audio_path) if not dl_manager.is_streaming else None\n    path_to_clips = \"librivox-indonesia\"\n\n    return [\n        datasets.SplitGenerator(\n            name=datasets.Split.TRAIN,\n            gen_kwargs={\n                \"local_extracted_archive\": local_extracted_archive,\n                \"audio_files\": dl_manager.iter_archive(audio_path),\n                \"metadata_path\": dl_manager.download_and_extract(_METADATA_URL + \"/metadata_train.csv.gz\"),\n                \"path_to_clips\": path_to_clips,\n            },\n        ),\n        datasets.SplitGenerator(\n            name=datasets.Split.TEST,\n            gen_kwargs={\n                \"local_extracted_archive\": local_extracted_archive,\n                \"audio_files\": dl_manager.iter_archive(audio_path),\n                \"metadata_path\": dl_manager.download_and_extract(_METADATA_URL + \"/metadata_test.csv.gz\"),\n                \"path_to_clips\": path_to_clips,\n            },\n        ),\n    ]\n```", "```py\n    with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            if self.config.name == \"all\" or self.config.name == row[\"language\"]:\n                row[\"path\"] = os.path.join(path_to_clips, row[\"path\"])\n                # if data is incomplete, fill with empty values\n                for field in data_fields:\n                    if field not in row:\n                        row[field] = \"\"\n                metadata[row[\"path\"]] = row\n    ```", "```py\n    for path, f in audio_files:\n        if path in metadata:\n            result = dict(metadata[path])\n            # set the audio feature and the path to the extracted file\n            path = os.path.join(local_extracted_archive, path) if local_extracted_archive else path\n            result[\"audio\"] = {\"path\": path, \"bytes\": f.read()}\n            result[\"path\"] = path\n            yield id_, result\n            id_ += 1\n    ```", "```py\ndef _generate_examples( self,\n        local_extracted_archive,\n        audio_files,\n        metadata_path,\n        path_to_clips, ):\n        \"\"\"Yields examples.\"\"\"\n        data_fields = list(self._info().features.keys())\n        metadata = {}\n        with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                if self.config.name == \"all\" or self.config.name == row[\"language\"]:\n                    row[\"path\"] = os.path.join(path_to_clips, row[\"path\"])\n                    # if data is incomplete, fill with empty values\n                    for field in data_fields:\n                        if field not in row:\n                            row[field] = \"\"\n                    metadata[row[\"path\"]] = row\n        id_ = 0\n        for path, f in audio_files:\n            if path in metadata:\n                result = dict(metadata[path])\n                # set the audio feature and the path to the extracted file\n                path = os.path.join(local_extracted_archive, path) if local_extracted_archive else path\n                result[\"audio\"] = {\"path\": path, \"bytes\": f.read()}\n                result[\"path\"] = path\n                yield id_, result\n                id_ += 1\n```"]