# Intel® PyTorch 扩展

> 原文：[`huggingface.co/docs/accelerate/usage_guides/ipex`](https://huggingface.co/docs/accelerate/usage_guides/ipex)

[IPEX](https://github.com/intel/intel-extension-for-pytorch)经过优化，适用于具有 AVX-512 或更高版本的 CPU，并且在仅具有 AVX2 的 CPU 上也可以正常运行。因此，预计在具有 AVX-512 或更高版本的 Intel CPU 代数上会带来性能优势，而仅具有 AVX2 的 CPU（例如 AMD CPU 或较旧的 Intel CPU）在 IPEX 下可能会获得更好的性能，但不能保证。IPEX 为使用 Float32 和 BFloat16 进行 CPU 训练提供了性能优化。以下部分主要关注 BFloat16 的使用。

低精度数据类型 BFloat16 已经在第三代 Xeon® Scalable 处理器（也称为 Cooper Lake）上本地支持，具有 AVX512 指令集，并将在下一代 Intel® Xeon® Scalable 处理器上支持，具有 Intel® Advanced Matrix Extensions（Intel® AMX）指令集，进一步提高性能。自 PyTorch-1.10 以来，CPU 后端的自动混合精度已经启用。同时，在 Intel® PyTorch 扩展中，已经大规模启用了 CPU 和 BFloat16 优化运算符的自动混合精度，并部分上游到 PyTorch 主分支。用户可以通过 IPEX 自动混合精度获得更好的性能和用户体验。

## IPEX 安装：

IPEX 发布遵循 PyTorch 版本，可以通过 pip 进行安装：

| PyTorch 版本 | IPEX 版本 |
| :-: | :-: |
| 2.0 | 2.0.0 |
| 1.13 | 1.13.0 |
| 1.12 | 1.12.300 |
| 1.11 | 1.11.200 |
| 1.10 | 1.10.100 |

```py
pip install intel_extension_for_pytorch==<version_name> -f https://developer.intel.com/ipex-whl-stable-cpu
```

查看更多[IPEX 安装方法](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/installation.html)。

## CPU 训练优化的工作原理

🤗 Accelerate 已经集成了[IPEX](https://github.com/intel/intel-extension-for-pytorch)，您只需要通过配置启用它。

**场景 1**：无分布式 CPU 训练加速

在您的机器上运行 accelerate config：

```py
$ accelerate config
-----------------------------------------------------------------------------------------------------------------------------------------------------------
In which compute environment are you running?
This machine
-----------------------------------------------------------------------------------------------------------------------------------------------------------
Which type of machine are you using?
No distributed training
Do you want to run your training on CPU only (even if a GPU / Apple Silicon device is available)? [yes/NO]:yes
Do you want to use Intel PyTorch Extension (IPEX) to speed up training on CPU? [yes/NO]:yes
Do you wish to optimize your script with torch dynamo?[yes/NO]:NO
Do you want to use DeepSpeed? [yes/NO]: NO
-----------------------------------------------------------------------------------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
bf16
```

这将生成一个配置文件，将自动用于在进行时正确设置默认选项

```py
accelerate launch my_script.py --args_to_my_script
```

例如，这是如何在启用 IPEX 的情况下运行 NLP 示例`examples/nlp_example.py`（从存储库的根目录）的方法。在`accelerate config`之后生成的 default_config.yaml

```py
compute_environment: LOCAL_MACHINE
distributed_type: 'NO'
downcast_bf16: 'no'
ipex_config:
  ipex: true
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 1
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: true
```

```py
accelerate launch examples/nlp_example.py
```

**场景 2**：分布式 CPU 训练加速，我们使用 Intel oneCCL 进行通信，结合 Intel® MPI 库在 Intel®架构上提供灵活、高效、可扩展的集群消息传递。您可以参考[这里](https://huggingface.co/docs/transformers/perf_train_cpu_many)进行安装指南

在您的机器上运行 accelerate config（node0）：

```py
$ accelerate config
-----------------------------------------------------------------------------------------------------------------------------------------------------------
In which compute environment are you running?
This machine
-----------------------------------------------------------------------------------------------------------------------------------------------------------
Which type of machine are you using?
multi-CPU
How many different machines will you use (use more than 1 for multi-node training)? [1]: 4
-----------------------------------------------------------------------------------------------------------------------------------------------------------
What is the rank of this machine?
0
What is the IP address of the machine that will host the main process? 36.112.23.24
What is the port you will use to communicate with the main process? 29500
Are all the machines on the same local network? Answer `no` if nodes are on the cloud and/or on different network hosts [YES/no]: yes
Do you want to use Intel PyTorch Extension (IPEX) to speed up training on CPU? [yes/NO]:yes
Do you wish to optimize your script with torch dynamo?[yes/NO]:NO
How many CPU(s) should be used for distributed training? [1]:16
-----------------------------------------------------------------------------------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
bf16
```

例如，这是如何在启用 IPEX 的情况下运行 NLP 示例`examples/nlp_example.py`（从存储库的根目录）进行分布式 CPU 训练的方法。

在`accelerate config`之后生成的 default_config.yaml

```py
compute_environment: LOCAL_MACHINE
distributed_type: MULTI_CPU
downcast_bf16: 'no'
ipex_config:
  ipex: true
machine_rank: 0
main_process_ip: 36.112.23.24
main_process_port: 29500
main_training_function: main
mixed_precision: bf16
num_machines: 4
num_processes: 16
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: true
```

设置以下环境并使用 Intel MPI 启动训练

在 node0 中，您需要创建一个包含每个节点 IP 地址的配置文件（例如 hostfile），并将该配置文件路径作为参数传递。

```py
$ cat hostfile
xxx.xxx.xxx.xxx #node0 ip
xxx.xxx.xxx.xxx #node1 ip
xxx.xxx.xxx.xxx #node2 ip
xxx.xxx.xxx.xxx #node3 ip
```

现在，在 node0 中运行以下命令，将在 node0、node1、node2、node3 中启用**16DDP**，并使用 BF16 混合精度：

```py
oneccl_bindings_for_pytorch_path=$(python -c "from oneccl_bindings_for_pytorch import cwd; print(cwd)")
source $oneccl_bindings_for_pytorch_path/env/setvars.sh
export CCL_WORKER_COUNT=1
export MASTER_ADDR=xxx.xxx.xxx.xxx #node0 ip
export CCL_ATL_TRANSPORT=ofi
mpirun -f hostfile -n 16 -ppn 4 accelerate launch examples/nlp_example.py
```

## 相关资源

+   [项目的 github](https://github.com/intel/intel-extension-for-pytorch)

+   [API 文档](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/api_doc.html)

+   [调优指南](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/performance_tuning/tuning_guide.html)

+   [博客和出版物](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/blogs_publications.html)
