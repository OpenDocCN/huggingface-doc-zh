["```py\npip install transformers datasets accelerate tensorboard evaluate --upgrade\n```", "```py\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"beans\")\n```", "```py\nfrom transformers import AutoImageProcessor\nteacher_processor = AutoImageProcessor.from_pretrained(\"merve/beans-vit-224\")\n\ndef process(examples):\n    processed_inputs = teacher_processor(examples[\"image\"])\n    return processed_inputs\n\nprocessed_datasets = dataset.map(process, batched=True)\n```", "```py\nfrom transformers import TrainingArguments, Trainer\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ImageDistilTrainer(Trainer):\n    def __init__(self, teacher_model=None, student_model=None, temperature=None, lambda_param=None,  *args, **kwargs):\n        super().__init__(model=student_model, *args, **kwargs)\n        self.teacher = teacher_model\n        self.student = student_model\n        self.loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.teacher.to(device)\n        self.teacher.eval()\n        self.temperature = temperature\n        self.lambda_param = lambda_param\n\n    def compute_loss(self, student, inputs, return_outputs=False):\n        student_output = self.student(**inputs)\n\n        with torch.no_grad():\n          teacher_output = self.teacher(**inputs)\n\n        # Compute soft targets for teacher and student\n        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)\n        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)\n\n        # Compute the loss\n        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)\n\n        # Compute the true label loss\n        student_target_loss = student_output.loss\n\n        # Calculate final loss\n        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss\n        return (loss, student_output) if return_outputs else loss\n```", "```py\nfrom huggingface_hub import notebook_login\n\nnotebook_login()\n```", "```py\nfrom transformers import AutoModelForImageClassification, MobileNetV2Config, MobileNetV2ForImageClassification\n\ntraining_args = TrainingArguments(\n    output_dir=\"my-awesome-model\",\n    num_train_epochs=30,\n    fp16=True,\n    logging_dir=f\"{repo_name}/logs\",\n    logging_strategy=\"epoch\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    report_to=\"tensorboard\",\n    push_to_hub=True,\n    hub_strategy=\"every_save\",\n    hub_model_id=repo_name,\n    )\n\nnum_labels = len(processed_datasets[\"train\"].features[\"labels\"].names)\n\n# initialize models\nteacher_model = AutoModelForImageClassification.from_pretrained(\n    \"merve/beans-vit-224\",\n    num_labels=num_labels,\n    ignore_mismatched_sizes=True\n)\n\n# training MobileNetV2 from scratch\nstudent_config = MobileNetV2Config()\nstudent_config.num_labels = num_labels\nstudent_model = MobileNetV2ForImageClassification(student_config)\n```", "```py\nimport evaluate\nimport numpy as np\n\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    acc = accuracy.compute(references=labels, predictions=np.argmax(predictions, axis=1))\n    return {\"accuracy\": acc[\"accuracy\"]}\n```", "```py\nfrom transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator()\ntrainer = ImageDistilTrainer(\n    student_model=student_model,\n    teacher_model=teacher_model,\n    training_args=training_args,\n    train_dataset=processed_datasets[\"train\"],\n    eval_dataset=processed_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=teacher_processor,\n    compute_metrics=compute_metrics,\n    temperature=5,\n    lambda_param=0.5\n)\n```", "```py\ntrainer.train()\n```", "```py\ntrainer.evaluate(processed_datasets[\"test\"])\n```"]