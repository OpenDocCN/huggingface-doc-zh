- en: Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://huggingface.co/docs/diffusers/api/models/overview](https://huggingface.co/docs/diffusers/api/models/overview)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/19.e8043372.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Tip.230e2334.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Docstring.93f6f462.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/globals.7f7f1b26.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/ExampleCodeBlock.658f5cd6.js">
  prefs: []
  type: TYPE_NORMAL
- en: ü§ó Diffusers provides pretrained models for popular algorithms and modules to
    create custom diffusion systems. The primary function of models is to denoise
    an input sample as modeled by the distribution <math><semantics><mrow><msub><mi>p</mi><mi>Œ∏</mi></msub><mo
    stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mi
    mathvariant="normal">‚à£</mi><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">p_{\theta}(x_{t-1}|x_{t})</annotation></semantics></math>pŒ∏‚Äã(xt‚àí1‚Äã‚à£xt‚Äã).
  prefs: []
  type: TYPE_NORMAL
- en: All models are built from the base [ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)
    class which is a [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)
    providing basic functionality for saving and loading models, locally and from
    the Hugging Face Hub.
  prefs: []
  type: TYPE_NORMAL
- en: ModelMixin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class diffusers.ModelMixin'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L186)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: Base class for all models.
  prefs: []
  type: TYPE_NORMAL
- en: '[ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)
    takes care of storing the model configuration and provides methods for loading,
    downloading and saving models.'
  prefs: []
  type: TYPE_NORMAL
- en: '**config_name** (`str`) ‚Äî Filename to save a model to when calling [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.save_pretrained).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### disable_gradient_checkpointing'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L238)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: Deactivates gradient checkpointing for the current model (may be referred to
    as *activation checkpointing* or *checkpoint activations* in other frameworks).
  prefs: []
  type: TYPE_NORMAL
- en: '#### disable_xformers_memory_efficient_attention'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L299)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  prefs: []
  type: TYPE_NORMAL
- en: '#### enable_gradient_checkpointing'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L229)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: Activates gradient checkpointing for the current model (may be referred to as
    *activation checkpointing* or *checkpoint activations* in other frameworks).
  prefs: []
  type: TYPE_NORMAL
- en: '#### enable_xformers_memory_efficient_attention'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L263)'
  prefs: []
  type: TYPE_NORMAL
- en: '( attention_op: Optional = None )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**attention_op** (`Callable`, *optional*) ‚Äî Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  prefs: []
  type: TYPE_NORMAL
- en: When this option is enabled, you should observe lower GPU memory usage and a
    potential speed up during inference. Speed up during training is not guaranteed.
  prefs: []
  type: TYPE_NORMAL
- en: ‚ö†Ô∏è When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L393)'
  prefs: []
  type: TYPE_NORMAL
- en: '( pretrained_model_name_or_path: Union **kwargs )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`, *optional*) ‚Äî Can
    be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* (for example `google/ddpm-celebahq-256`) of a pretrained
    model hosted on the Hub.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* (for example `./my_model_directory`) containing the
    model weights saved with [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.save_pretrained).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`Union[str, os.PathLike]`, *optional*) ‚Äî Path to a directory
    where a downloaded pretrained model configuration is cached if the standard cache
    is not used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**torch_dtype** (`str` or `torch.dtype`, *optional*) ‚Äî Override the default
    `torch.dtype` and load the model with another dtype. If `"auto"` is passed, the
    dtype is automatically derived from the model‚Äôs weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) ‚Äî Whether or
    not to resume downloading the model weights and configuration files. If set to
    `False`, any incompletely downloaded files are deleted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) ‚Äî A dictionary of proxy servers
    to use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info** (`bool`, *optional*, defaults to `False`) ‚Äî Whether
    or not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) ‚Äî Whether to
    only load local model weights and configuration files or not. If set to `True`,
    the model won‚Äôt be downloaded from the Hub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**token** (`str` or *bool*, *optional*) ‚Äî The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) ‚Äî The specific model
    version to use. It can be a branch name, a tag name, a commit id, or any identifier
    allowed by Git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_flax** (`bool`, *optional*, defaults to `False`) ‚Äî Load the model weights
    from a Flax checkpoint save file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**subfolder** (`str`, *optional*, defaults to `""`) ‚Äî The subfolder location
    of a model file within a larger model repository on the Hub or locally.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mirror** (`str`, *optional*) ‚Äî Mirror source to resolve accessibility issues
    if you‚Äôre downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**device_map** (`str` or `Dict[str, Union[int, str, torch.device]]`, *optional*)
    ‚Äî A map that specifies where each submodule should go. It doesn‚Äôt need to be defined
    for each parameter/buffer name; once a given module name is inside, every submodule
    of it will be sent to the same device.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set `device_map="auto"` to have ü§ó Accelerate automatically compute the most
    optimized `device_map`. For more information about each option see [designing
    a device map](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**max_memory** (`Dict`, *optional*) ‚Äî A dictionary device identifier for the
    maximum memory. Will default to the maximum memory available for each GPU and
    the available CPU RAM if unset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**offload_folder** (`str` or `os.PathLike`, *optional*) ‚Äî The path to offload
    weights if `device_map` contains the value `"disk"`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**offload_state_dict** (`bool`, *optional*) ‚Äî If `True`, temporarily offloads
    the CPU state dict to the hard drive to avoid running out of CPU RAM if the weight
    of the CPU state dict + the biggest shard of the checkpoint does not fit. Defaults
    to `True` when there is some disk offload.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**low_cpu_mem_usage** (`bool`, *optional*, defaults to `True` if torch version
    >= 1.9.0 else `False`) ‚Äî Speed up model loading only loading the pretrained weights
    and not initializing the weights. This also tries to not use more than 1x model
    size in CPU memory (including peak memory) while loading the model. Only supported
    for PyTorch >= 1.9.0\. If you are using an older version of PyTorch, setting this
    argument to `True` will raise an error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**variant** (`str`, *optional*) ‚Äî Load weights from a specified `variant` filename
    such as `"fp16"` or `"ema"`. This is ignored when loading `from_flax`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**use_safetensors** (`bool`, *optional*, defaults to `None`) ‚Äî If set to `None`,
    the `safetensors` weights are downloaded if they‚Äôre available **and** if the `safetensors`
    library is installed. If set to `True`, the model is forcibly loaded from `safetensors`
    weights. If set to `False`, `safetensors` weights are not loaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate a pretrained PyTorch model from a pretrained model configuration.
  prefs: []
  type: TYPE_NORMAL
- en: The model is set in evaluation mode - `model.eval()` - by default, and dropout
    modules are deactivated. To train the model, set it back in training mode with
    `model.train()`.
  prefs: []
  type: TYPE_NORMAL
- en: To use private or [gated models](https://huggingface.co/docs/hub/models-gated#gated-models),
    log-in with `huggingface-cli login`. You can also activate the special [‚Äúoffline-mode‚Äù](https://huggingface.co/diffusers/installation.html#offline-mode)
    to use this method in a firewalled environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#### num_parameters'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L893)'
  prefs: []
  type: TYPE_NORMAL
- en: '( only_trainable: bool = False exclude_embeddings: bool = False ) ‚Üí `int`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**only_trainable** (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to return only the number of trainable parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**exclude_embeddings** (`bool`, *optional*, defaults to `False`) ‚Äî Whether
    or not to return only the number of non-embedding parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`int`'
  prefs: []
  type: TYPE_NORMAL
- en: The number of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Get number of (trainable or non-embedding) parameters in the module.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '#### save_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L305)'
  prefs: []
  type: TYPE_NORMAL
- en: '( save_directory: Union is_main_process: bool = True save_function: Optional
    = None safe_serialization: bool = True variant: Optional = None push_to_hub: bool
    = False **kwargs )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**save_directory** (`str` or `os.PathLike`) ‚Äî Directory to save a model and
    its configuration file to. Will be created if it doesn‚Äôt exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**is_main_process** (`bool`, *optional*, defaults to `True`) ‚Äî Whether the
    process calling this is the main process or not. Useful during distributed training
    and you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**save_function** (`Callable`) ‚Äî The function to use to save the state dictionary.
    Useful during distributed training when you need to replace `torch.save` with
    another method. Can be configured with the environment variable `DIFFUSERS_SAVE_MODE`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**safe_serialization** (`bool`, *optional*, defaults to `True`) ‚Äî Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**variant** (`str`, *optional*) ‚Äî If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**push_to_hub** (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to push your model to the Hugging Face Hub after saving it. You can specify the
    repository you want to push to with `repo_id` (will default to the name of `save_directory`
    in your namespace).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (`Dict[str, Any]`, *optional*) ‚Äî Additional keyword arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save a model and its configuration file to a directory so that it can be reloaded
    using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.from_pretrained)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: FlaxModelMixin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class diffusers.FlaxModelMixin'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L50)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: Base class for all Flax models.
  prefs: []
  type: TYPE_NORMAL
- en: '[FlaxModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin)
    takes care of storing the model configuration and provides methods for loading,
    downloading and saving models.'
  prefs: []
  type: TYPE_NORMAL
- en: '**config_name** (`str`) ‚Äî Filename to save a model to when calling [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.save_pretrained).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L203)'
  prefs: []
  type: TYPE_NORMAL
- en: '( pretrained_model_name_or_path: Union dtype: dtype = <class ''jax.numpy.float32''>
    *model_args **kwargs )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) ‚Äî Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* (for example `runwayml/stable-diffusion-v1-5`) of a
    pretrained model hosted on the Hub.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* (for example `./my_model_directory`) containing the
    model weights saved using [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.save_pretrained).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dtype** (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`)
    ‚Äî The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified, all the computation will be performed with the
    given `dtype`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This only specifies the dtype of the *computation* and does not influence the
    dtype of model parameters.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.to_fp16)
    and [to_bf16()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.to_bf16).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**model_args** (sequence of positional arguments, *optional*) ‚Äî All remaining
    positional arguments are passed to the underlying model‚Äôs `__init__` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`Union[str, os.PathLike]`, *optional*) ‚Äî Path to a directory
    where a downloaded pretrained model configuration is cached if the standard cache
    is not used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) ‚Äî Whether or
    not to resume downloading the model weights and configuration files. If set to
    `False`, any incompletely downloaded files are deleted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) ‚Äî A dictionary of proxy servers
    to use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) ‚Äî Whether to
    only load local model weights and configuration files or not. If set to `True`,
    the model won‚Äôt be downloaded from the Hub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) ‚Äî The specific model
    version to use. It can be a branch name, a tag name, a commit id, or any identifier
    allowed by Git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) ‚Äî Load the model weights
    from a PyTorch checkpoint save file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (remaining dictionary of keyword arguments, *optional*) ‚Äî Can be
    used to update the configuration object (after it is loaded) and initiate the
    model (for example, `output_attentions=True`). Behaves differently depending on
    whether a `config` is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `kwargs` are directly passed to
    the underlying model‚Äôs `__init__` method (we assume all relevant updates to the
    configuration have already been done).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` are first passed to the configuration
    class initialization function [from_config()](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin.from_config).
    Each key of the `kwargs` that corresponds to a configuration attribute is used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute are passed to the underlying
    model‚Äôs `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate a pretrained Flax model from a pretrained model configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '#### save_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L502)'
  prefs: []
  type: TYPE_NORMAL
- en: '( save_directory: Union params: Union is_main_process: bool = True push_to_hub:
    bool = False **kwargs )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**save_directory** (`str` or `os.PathLike`) ‚Äî Directory to save a model and
    its configuration file to. Will be created if it doesn‚Äôt exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**params** (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` of model parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**is_main_process** (`bool`, *optional*, defaults to `True`) ‚Äî Whether the
    process calling this is the main process or not. Useful during distributed training
    and you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**push_to_hub** (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (`Dict[str, Any]`, *optional*) ‚Äî Additional key word arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save a model and its configuration file to a directory so that it can be reloaded
    using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.from_pretrained)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: '#### to_bf16'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L95)'
  prefs: []
  type: TYPE_NORMAL
- en: '( params: Union mask: Any = None )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**params** (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` of model parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mask** (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans. It should be `True` for params you
    want to cast, and `False` for those you want to skip.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cast the floating-point `params` to `jax.numpy.bfloat16`. This returns a new
    `params` tree and does not cast the `params` in place.
  prefs: []
  type: TYPE_NORMAL
- en: This method can be used on a TPU to explicitly convert the model parameters
    to bfloat16 precision to do full half-precision training or to save weights in
    bfloat16 for inference in order to save memory and improve speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '#### to_fp16'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L161)'
  prefs: []
  type: TYPE_NORMAL
- en: '( params: Union mask: Any = None )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**params** (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` of model parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mask** (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans. It should be `True` for params you
    want to cast, and `False` for those you want to skip.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cast the floating-point `params` to `jax.numpy.float16`. This returns a new
    `params` tree and does not cast the `params` in place.
  prefs: []
  type: TYPE_NORMAL
- en: This method can be used on a GPU to explicitly convert the model parameters
    to float16 precision to do full half-precision training or to save weights in
    float16 for inference in order to save memory and improve speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '#### to_fp32'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L134)'
  prefs: []
  type: TYPE_NORMAL
- en: '( params: Union mask: Any = None )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**params** (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` of model parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mask** (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans. It should be `True` for params you
    want to cast, and `False` for those you want to skip.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cast the floating-point `params` to `jax.numpy.float32`. This method can be
    used to explicitly convert the model parameters to fp32 precision. This returns
    a new `params` tree and does not cast the `params` in place.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: PushToHubMixin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class diffusers.utils.PushToHubMixin'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L351)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: A Mixin to push a model, scheduler, or pipeline to the Hugging Face Hub.
  prefs: []
  type: TYPE_NORMAL
- en: '#### push_to_hub'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L380)'
  prefs: []
  type: TYPE_NORMAL
- en: '( repo_id: str commit_message: Optional = None private: Optional = None token:
    Optional = None create_pr: bool = False safe_serialization: bool = True variant:
    Optional = None )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**repo_id** (`str`) ‚Äî The name of the repository you want to push your model,
    scheduler, or pipeline files to. It should contain your organization name when
    pushing to an organization. `repo_id` can also be a path to a local directory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**commit_message** (`str`, *optional*) ‚Äî Message to commit while pushing. Default
    to `"Upload {object}"`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**private** (`bool`, *optional*) ‚Äî Whether or not the repository created should
    be private.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**token** (`str`, *optional*) ‚Äî The token to use as HTTP bearer authorization
    for remote files. The token generated when running `huggingface-cli login` (stored
    in `~/.huggingface`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**create_pr** (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not to
    create a PR with the uploaded files or directly commit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**safe_serialization** (`bool`, *optional*, defaults to `True`) ‚Äî Whether or
    not to convert the model weights to the `safetensors` format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**variant** (`str`, *optional*) ‚Äî If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upload model, scheduler, or pipeline files to the ü§ó Hugging Face Hub.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
