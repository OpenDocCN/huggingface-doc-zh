- en: Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/models/overview](https://huggingface.co/docs/diffusers/api/models/overview)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ü§ó Diffusers provides pretrained models for popular algorithms and modules to
    create custom diffusion systems. The primary function of models is to denoise
    an input sample as modeled by the distribution <math><semantics><mrow><msub><mi>p</mi><mi>Œ∏</mi></msub><mo
    stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mi
    mathvariant="normal">‚à£</mi><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">p_{\theta}(x_{t-1}|x_{t})</annotation></semantics></math>pŒ∏‚Äã(xt‚àí1‚Äã‚à£xt‚Äã).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: All models are built from the base [ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)
    class which is a [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)
    providing basic functionality for saving and loading models, locally and from
    the Hugging Face Hub.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: ModelMixin
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.ModelMixin`'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L186)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Base class for all models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '[ModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin)
    takes care of storing the model configuration and provides methods for loading,
    downloading and saving models.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '`config_name` (`str`) ‚Äî Filename to save a model to when calling [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.save_pretrained).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `disable_gradient_checkpointing`'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L238)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Deactivates gradient checkpointing for the current model (may be referred to
    as *activation checkpointing* or *checkpoint activations* in other frameworks).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '#### `disable_xformers_memory_efficient_attention`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L299)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Disable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_gradient_checkpointing`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L229)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Activates gradient checkpointing for the current model (may be referred to as
    *activation checkpointing* or *checkpoint activations* in other frameworks).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '#### `enable_xformers_memory_efficient_attention`'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L263)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '`attention_op` (`Callable`, *optional*) ‚Äî Override the default `None` operator
    for use as `op` argument to the [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
    function of xFormers.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable memory efficient attention from [xFormers](https://facebookresearch.github.io/xformers/).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: When this option is enabled, you should observe lower GPU memory usage and a
    potential speed up during inference. Speed up during training is not guaranteed.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: ‚ö†Ô∏è When memory efficient attention and sliced attention are both enabled, memory
    efficient attention takes precedent.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#### `from_pretrained`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L393)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`, *optional*) ‚Äî Can
    be either:'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* (for example `google/ddpm-celebahq-256`) of a pretrained
    model hosted on the Hub.
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* (for example `./my_model_directory`) containing the
    model weights saved with [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.save_pretrained).
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) ‚Äî Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`torch_dtype` (`str` or `torch.dtype`, *optional*) ‚Äî Override the default `torch.dtype`
    and load the model with another dtype. If `"auto"` is passed, the dtype is automatically
    derived from the model‚Äôs weights.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`force_download` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxies` (`Dict[str, str]`, *optional*) ‚Äî A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_loading_info` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or
    not to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`local_files_only(bool,` *optional*, defaults to `False`) ‚Äî Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model won‚Äôt be downloaded from the Hub.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token` (`str` or *bool*, *optional*) ‚Äî The token to use as HTTP bearer authorization
    for remote files. If `True`, the token generated from `diffusers-cli login` (stored
    in `~/.huggingface`) is used.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`revision` (`str`, *optional*, defaults to `"main"`) ‚Äî The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`from_flax` (`bool`, *optional*, defaults to `False`) ‚Äî Load the model weights
    from a Flax checkpoint save file.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subfolder` (`str`, *optional*, defaults to `""`) ‚Äî The subfolder location
    of a model file within a larger model repository on the Hub or locally.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mirror` (`str`, *optional*) ‚Äî Mirror source to resolve accessibility issues
    if you‚Äôre downloading a model in China. We do not guarantee the timeliness or
    safety of the source, and you should refer to the mirror site for more information.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device_map` (`str` or `Dict[str, Union[int, str, torch.device]]`, *optional*)
    ‚Äî A map that specifies where each submodule should go. It doesn‚Äôt need to be defined
    for each parameter/buffer name; once a given module name is inside, every submodule
    of it will be sent to the same device.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set `device_map="auto"` to have ü§ó Accelerate automatically compute the most
    optimized `device_map`. For more information about each option see [designing
    a device map](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map).
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`max_memory` (`Dict`, *optional*) ‚Äî A dictionary device identifier for the
    maximum memory. Will default to the maximum memory available for each GPU and
    the available CPU RAM if unset.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`offload_folder` (`str` or `os.PathLike`, *optional*) ‚Äî The path to offload
    weights if `device_map` contains the value `"disk"`.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`offload_state_dict` (`bool`, *optional*) ‚Äî If `True`, temporarily offloads
    the CPU state dict to the hard drive to avoid running out of CPU RAM if the weight
    of the CPU state dict + the biggest shard of the checkpoint does not fit. Defaults
    to `True` when there is some disk offload.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`low_cpu_mem_usage` (`bool`, *optional*, defaults to `True` if torch version
    >= 1.9.0 else `False`) ‚Äî Speed up model loading only loading the pretrained weights
    and not initializing the weights. This also tries to not use more than 1x model
    size in CPU memory (including peak memory) while loading the model. Only supported
    for PyTorch >= 1.9.0\. If you are using an older version of PyTorch, setting this
    argument to `True` will raise an error.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`variant` (`str`, *optional*) ‚Äî Load weights from a specified `variant` filename
    such as `"fp16"` or `"ema"`. This is ignored when loading `from_flax`.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_safetensors` (`bool`, *optional*, defaults to `None`) ‚Äî If set to `None`,
    the `safetensors` weights are downloaded if they‚Äôre available **and** if the `safetensors`
    library is installed. If set to `True`, the model is forcibly loaded from `safetensors`
    weights. If set to `False`, `safetensors` weights are not loaded.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate a pretrained PyTorch model from a pretrained model configuration.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: The model is set in evaluation mode - `model.eval()` - by default, and dropout
    modules are deactivated. To train the model, set it back in training mode with
    `model.train()`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: To use private or [gated models](https://huggingface.co/docs/hub/models-gated#gated-models),
    log-in with `huggingface-cli login`. You can also activate the special [‚Äúoffline-mode‚Äù](https://huggingface.co/diffusers/installation.html#offline-mode)
    to use this method in a firewalled environment.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#### `num_parameters`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L893)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '`only_trainable` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to return only the number of trainable parameters.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`exclude_embeddings` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or
    not to return only the number of non-embedding parameters.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '`int`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: The number of parameters.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Get number of (trainable or non-embedding) parameters in the module.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `save_pretrained`'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_utils.py#L305)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '`save_directory` (`str` or `os.PathLike`) ‚Äî Directory to save a model and its
    configuration file to. Will be created if it doesn‚Äôt exist.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) ‚Äî Whether the process
    calling this is the main process or not. Useful during distributed training and
    you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save_function` (`Callable`) ‚Äî The function to use to save the state dictionary.
    Useful during distributed training when you need to replace `torch.save` with
    another method. Can be configured with the environment variable `DIFFUSERS_SAVE_MODE`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) ‚Äî Whether to
    save the model using `safetensors` or the traditional PyTorch way with `pickle`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`variant` (`str`, *optional*) ‚Äî If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not to
    push your model to the Hugging Face Hub after saving it. You can specify the repository
    you want to push to with `repo_id` (will default to the name of `save_directory`
    in your namespace).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kwargs` (`Dict[str, Any]`, *optional*) ‚Äî Additional keyword arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save a model and its configuration file to a directory so that it can be reloaded
    using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.ModelMixin.from_pretrained)
    class method.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: FlaxModelMixin
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.FlaxModelMixin`'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L50)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Base class for all Flax models.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[FlaxModelMixin](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin)
    takes care of storing the model configuration and provides methods for loading,
    downloading and saving models.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '`config_name` (`str`) ‚Äî Filename to save a model to when calling [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.save_pretrained).'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#### `from_pretrained`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L203)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) ‚Äî Can be either:'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* (for example `runwayml/stable-diffusion-v1-5`) of a
    pretrained model hosted on the Hub.
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* (for example `./my_model_directory`) containing the
    model weights saved using [save_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.save_pretrained).
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) ‚Äî
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs).'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be used to enable mixed-precision training or half-precision inference
    on GPUs or TPUs. If specified, all the computation will be performed with the
    given `dtype`.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This only specifies the dtype of the *computation* and does not influence the
    dtype of model parameters.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.to_fp16)
    and [to_bf16()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.to_bf16).
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`model_args` (sequence of positional arguments, *optional*) ‚Äî All remaining
    positional arguments are passed to the underlying model‚Äôs `__init__` method.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cache_dir` (`Union[str, os.PathLike]`, *optional*) ‚Äî Path to a directory where
    a downloaded pretrained model configuration is cached if the standard cache is
    not used.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`force_download` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not
    to resume downloading the model weights and configuration files. If set to `False`,
    any incompletely downloaded files are deleted.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxies` (`Dict[str, str]`, *optional*) ‚Äî A dictionary of proxy servers to
    use by protocol or endpoint, for example, `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`local_files_only(bool,` *optional*, defaults to `False`) ‚Äî Whether to only
    load local model weights and configuration files or not. If set to `True`, the
    model won‚Äôt be downloaded from the Hub.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`revision` (`str`, *optional*, defaults to `"main"`) ‚Äî The specific model version
    to use. It can be a branch name, a tag name, a commit id, or any identifier allowed
    by Git.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) ‚Äî Load the model weights
    from a PyTorch checkpoint save file.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kwargs` (remaining dictionary of keyword arguments, *optional*) ‚Äî Can be used
    to update the configuration object (after it is loaded) and initiate the model
    (for example, `output_attentions=True`). Behaves differently depending on whether
    a `config` is provided or automatically loaded:'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `kwargs` are directly passed to
    the underlying model‚Äôs `__init__` method (we assume all relevant updates to the
    configuration have already been done).
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` are first passed to the configuration
    class initialization function [from_config()](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin.from_config).
    Each key of the `kwargs` that corresponds to a configuration attribute is used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute are passed to the underlying
    model‚Äôs `__init__` function.
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate a pretrained Flax model from a pretrained model configuration.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you get the error message below, you need to finetune the weights for your
    downstream task:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#### `save_pretrained`'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L502)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '`save_directory` (`str` or `os.PathLike`) ‚Äî Directory to save a model and its
    configuration file to. Will be created if it doesn‚Äôt exist.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`params` (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` of model parameters.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_main_process` (`bool`, *optional*, defaults to `True`) ‚Äî Whether the process
    calling this is the main process or not. Useful during distributed training and
    you need to call this function on all processes. In this case, set `is_main_process=True`
    only on the main process to avoid race conditions.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kwargs` (`Dict[str, Any]`, *optional*) ‚Äî Additional key word arguments passed
    along to the [push_to_hub()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub)
    method.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save a model and its configuration file to a directory so that it can be reloaded
    using the [from_pretrained()](/docs/diffusers/v0.26.3/en/api/models/overview#diffusers.FlaxModelMixin.from_pretrained)
    class method.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '#### `to_bf16`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L95)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '`params` (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` of model parameters.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask` (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans. It should be `True` for params you
    want to cast, and `False` for those you want to skip.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cast the floating-point `params` to `jax.numpy.bfloat16`. This returns a new
    `params` tree and does not cast the `params` in place.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: This method can be used on a TPU to explicitly convert the model parameters
    to bfloat16 precision to do full half-precision training or to save weights in
    bfloat16 for inference in order to save memory and improve speed.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '#### `to_fp16`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L161)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '`params` (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` of model parameters.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask` (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans. It should be `True` for params you
    want to cast, and `False` for those you want to skip.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cast the floating-point `params` to `jax.numpy.float16`. This returns a new
    `params` tree and does not cast the `params` in place.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: This method can be used on a GPU to explicitly convert the model parameters
    to float16 precision to do full half-precision training or to save weights in
    float16 for inference in order to save memory and improve speed.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#### `to_fp32`'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_flax_utils.py#L134)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '`params` (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` of model parameters.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask` (`Union[Dict, FrozenDict]`) ‚Äî A `PyTree` with same structure as the
    `params` tree. The leaves should be booleans. It should be `True` for params you
    want to cast, and `False` for those you want to skip.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cast the floating-point `params` to `jax.numpy.float32`. This method can be
    used to explicitly convert the model parameters to fp32 precision. This returns
    a new `params` tree and does not cast the `params` in place.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: PushToHubMixin
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.utils.PushToHubMixin`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L351)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: A Mixin to push a model, scheduler, or pipeline to the Hugging Face Hub.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '#### `push_to_hub`'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/hub_utils.py#L380)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '`repo_id` (`str`) ‚Äî The name of the repository you want to push your model,
    scheduler, or pipeline files to. It should contain your organization name when
    pushing to an organization. `repo_id` can also be a path to a local directory.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo_id` (`str`) ‚Äî ÊÇ®Ë¶ÅÊé®ÈÄÅÊ®°Âûã„ÄÅË∞ÉÂ∫¶Âô®ÊàñÊµÅÊ∞¥Á∫øÊñá‰ª∂ÁöÑÂ≠òÂÇ®Â∫ìÂêçÁß∞„ÄÇÂú®Êé®ÈÄÅÂà∞ÁªÑÁªáÊó∂ÔºåÂ∫îÂåÖÂê´ÊÇ®ÁöÑÁªÑÁªáÂêçÁß∞„ÄÇ`repo_id`‰πüÂèØ‰ª•ÊòØÊú¨Âú∞ÁõÆÂΩïÁöÑË∑ØÂæÑ„ÄÇ'
- en: '`commit_message` (`str`, *optional*) ‚Äî Message to commit while pushing. Default
    to `"Upload {object}"`.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit_message` (`str`, *optional*) ‚Äî Êé®ÈÄÅÊó∂Ë¶ÅÊèê‰∫§ÁöÑÊ∂àÊÅØ„ÄÇÈªòËÆ§‰∏∫`"Upload {object}"`„ÄÇ'
- en: '`private` (`bool`, *optional*) ‚Äî Whether or not the repository created should
    be private.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`private` (`bool`, *optional*) ‚Äî ÊòØÂê¶Â∫îÂ∞ÜÂàõÂª∫ÁöÑÂ≠òÂÇ®Â∫ìËÆæÁΩÆ‰∏∫ÁßÅÊúâ„ÄÇ'
- en: '`token` (`str`, *optional*) ‚Äî The token to use as HTTP bearer authorization
    for remote files. The token generated when running `huggingface-cli login` (stored
    in `~/.huggingface`).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`, *optional*) ‚Äî Áî®‰ΩúËøúÁ®ãÊñá‰ª∂ÁöÑHTTP bearerÊéàÊùÉÁöÑ‰ª§Áâå„ÄÇÂú®ËøêË°å`huggingface-cli login`Êó∂ÁîüÊàêÁöÑ‰ª§ÁâåÔºàÂ≠òÂÇ®Âú®`~/.huggingface`‰∏≠Ôºâ„ÄÇ'
- en: '`create_pr` (`bool`, *optional*, defaults to `False`) ‚Äî Whether or not to create
    a PR with the uploaded files or directly commit.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_pr` (`bool`, *optional*, ÈªòËÆ§‰∏∫`False`) ‚Äî ÊòØÂê¶ÂàõÂª∫‰∏Ä‰∏™Â∏¶Êúâ‰∏ä‰º†Êñá‰ª∂ÁöÑPRÊàñÁõ¥Êé•Êèê‰∫§„ÄÇ'
- en: '`safe_serialization` (`bool`, *optional*, defaults to `True`) ‚Äî Whether or
    not to convert the model weights to the `safetensors` format.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_serialization` (`bool`, *optional*, ÈªòËÆ§‰∏∫`True`) ‚Äî ÊòØÂê¶Â∞ÜÊ®°ÂûãÊùÉÈáçËΩ¨Êç¢‰∏∫`safetensors`Ê†ºÂºè„ÄÇ'
- en: '`variant` (`str`, *optional*) ‚Äî If specified, weights are saved in the format
    `pytorch_model.<variant>.bin`.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant` (`str`, *optional*) ‚Äî Â¶ÇÊûúÊåáÂÆöÔºåÊùÉÈáçÂ∞Ü‰ª•`pytorch_model.<variant>.bin`Ê†ºÂºè‰øùÂ≠ò„ÄÇ'
- en: Upload model, scheduler, or pipeline files to the ü§ó Hugging Face Hub.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Â∞ÜÊ®°Âûã„ÄÅË∞ÉÂ∫¶Âô®ÊàñÊµÅÊ∞¥Á∫øÊñá‰ª∂‰∏ä‰º†Âà∞ü§ó Hugging Face Hub„ÄÇ
- en: 'Examples:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Á§∫‰æãÔºö
- en: '[PRE25]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
