["```py\n( namespace: str raw: Dict _token: Optional _api: HfApi )\n```", "```py\n>>> from huggingface_hub import get_inference_endpoint\n>>> endpoint = get_inference_endpoint(\"my-text-to-image\")\n>>> endpoint\nInferenceEndpoint(name='my-text-to-image', ...)\n\n# Get status\n>>> endpoint.status\n'running'\n>>> endpoint.url\n'https://my-text-to-image.region.vendor.endpoints.huggingface.cloud'\n\n# Run inference\n>>> endpoint.client.text_to_image(...)\n\n# Pause endpoint to save $$$\n>>> endpoint.pause()\n\n# ...\n# Resume and wait for deployment\n>>> endpoint.resume()\n>>> endpoint.wait()\n>>> endpoint.client.text_to_image(...)\n```", "```py\n( raw: Dict namespace: str token: Optional = None api: Optional = None )\n```", "```py\n( ) \u2192 export const metadata = 'undefined';InferenceClient\n```", "```py\n( ) \u2192 export const metadata = 'undefined';AsyncInferenceClient\n```", "```py\n( )\n```", "```py\n( ) \u2192 export const metadata = 'undefined';InferenceEndpoint\n```", "```py\n( ) \u2192 export const metadata = 'undefined';InferenceEndpoint\n```", "```py\n( ) \u2192 export const metadata = 'undefined';InferenceEndpoint\n```", "```py\n( ) \u2192 export const metadata = 'undefined';InferenceEndpoint\n```", "```py\n( accelerator: Optional = None instance_size: Optional = None instance_type: Optional = None min_replica: Optional = None max_replica: Optional = None repository: Optional = None framework: Optional = None revision: Optional = None task: Optional = None ) \u2192 export const metadata = 'undefined';InferenceEndpoint\n```", "```py\n( timeout: Optional = None refresh_every: int = 5 ) \u2192 export const metadata = 'undefined';InferenceEndpoint\n```", "```py\n( value names = None module = None qualname = None type = None start = 1 )\n```", "```py\n( value names = None module = None qualname = None type = None start = 1 )\n```", "```py\n( )\n```"]