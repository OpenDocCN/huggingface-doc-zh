# åœ¨å•ä¸ªGPUä¸Šè¿›è¡Œé«˜æ•ˆè®­ç»ƒçš„æ–¹æ³•å’Œå·¥å…·

> åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/perf_train_gpu_one](https://huggingface.co/docs/transformers/v4.37.2/en/perf_train_gpu_one)

æœ¬æŒ‡å—æ¼”ç¤ºäº†æ‚¨å¯ä»¥ä½¿ç”¨çš„å®ç”¨æŠ€æœ¯ï¼Œé€šè¿‡ä¼˜åŒ–å†…å­˜åˆ©ç”¨ç‡ã€åŠ å¿«è®­ç»ƒé€Ÿåº¦æˆ–ä¸¤è€…å…¼è€Œæœ‰ä¹‹æ¥æé«˜æ¨¡å‹è®­ç»ƒçš„æ•ˆç‡ã€‚å¦‚æœæ‚¨æƒ³äº†è§£GPUåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä½¿ç”¨æƒ…å†µï¼Œè¯·å…ˆå‚è€ƒ[æ¨¡å‹è®­ç»ƒè§£å‰–](model_memory_anatomy)æ¦‚å¿µæŒ‡å—ã€‚æœ¬æŒ‡å—ä¾§é‡äºå®ç”¨æŠ€æœ¯ã€‚

å¦‚æœæ‚¨å¯ä»¥è®¿é—®å…·æœ‰å¤šä¸ªGPUçš„è®¡ç®—æœºï¼Œè¿™äº›æ–¹æ³•ä»ç„¶æœ‰æ•ˆï¼Œæ­¤å¤–ï¼Œæ‚¨è¿˜å¯ä»¥åˆ©ç”¨[å¤šGPUéƒ¨åˆ†](perf_train_gpu_many)ä¸­æ¦‚è¿°çš„å…¶ä»–æ–¹æ³•ã€‚

åœ¨è®­ç»ƒå¤§å‹æ¨¡å‹æ—¶ï¼Œåº”åŒæ—¶è€ƒè™‘ä¸¤ä¸ªæ–¹é¢ï¼š

+   æ•°æ®ååé‡/è®­ç»ƒæ—¶é—´

+   æ¨¡å‹æ€§èƒ½

æœ€å¤§åŒ–ååé‡ï¼ˆæ ·æœ¬/ç§’ï¼‰å¯ä»¥é™ä½è®­ç»ƒæˆæœ¬ã€‚é€šå¸¸é€šè¿‡å°½å¯èƒ½å……åˆ†åˆ©ç”¨GPUå¹¶å°†GPUå†…å­˜å¡«æ»¡æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚å¦‚æœæ‰€éœ€çš„æ‰¹å¤„ç†å¤§å°è¶…å‡ºäº†GPUå†…å­˜çš„é™åˆ¶ï¼Œå¯ä»¥ä½¿ç”¨å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼Œå¦‚æ¢¯åº¦ç´¯ç§¯ï¼Œæ¥å¸®åŠ©ã€‚

ç„¶è€Œï¼Œå¦‚æœé¦–é€‰çš„æ‰¹å¤„ç†å¤§å°é€‚åˆå†…å­˜ï¼Œå°±æ²¡æœ‰ç†ç”±åº”ç”¨å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½ä¼šå‡æ…¢è®­ç»ƒé€Ÿåº¦ã€‚ä»…ä»…å› ä¸ºå¯ä»¥ä½¿ç”¨å¤§æ‰¹å¤„ç†å¤§å°ï¼Œå¹¶ä¸ä¸€å®šæ„å‘³ç€åº”è¯¥è¿™æ ·åšã€‚ä½œä¸ºè¶…å‚æ•°è°ƒæ•´çš„ä¸€éƒ¨åˆ†ï¼Œæ‚¨åº”è¯¥ç¡®å®šå“ªç§æ‰¹å¤„ç†å¤§å°äº§ç”Ÿæœ€ä½³ç»“æœï¼Œç„¶åç›¸åº”åœ°ä¼˜åŒ–èµ„æºã€‚

æœ¬æŒ‡å—æ¶µç›–çš„æ–¹æ³•å’Œå·¥å…·å¯ä»¥æ ¹æ®å®ƒä»¬å¯¹è®­ç»ƒè¿‡ç¨‹çš„å½±å“è¿›è¡Œåˆ†ç±»ï¼š

| æ–¹æ³•/å·¥å…· | æé«˜è®­ç»ƒé€Ÿåº¦ | ä¼˜åŒ–å†…å­˜åˆ©ç”¨ç‡ |
| :-- | :-- | :-- |
| [æ‰¹å¤„ç†å¤§å°é€‰æ‹©](#æ‰¹å¤„ç†å¤§å°é€‰æ‹©) | æ˜¯ | æ˜¯ |
| [æ¢¯åº¦ç´¯ç§¯](#æ¢¯åº¦ç´¯ç§¯) | å¦ | æ˜¯ |
| [æ¢¯åº¦æ£€æŸ¥ç‚¹](#æ¢¯åº¦æ£€æŸ¥ç‚¹) | å¦ | æ˜¯ |
| [æ··åˆç²¾åº¦è®­ç»ƒ](#æ··åˆç²¾åº¦è®­ç»ƒ) | æ˜¯ | (å¦) |
| [ä¼˜åŒ–å™¨é€‰æ‹©](#ä¼˜åŒ–å™¨é€‰æ‹©) | æ˜¯ | æ˜¯ |
| [æ•°æ®é¢„åŠ è½½](#æ•°æ®é¢„åŠ è½½) | æ˜¯ | å¦ |
| [DeepSpeed Zero](#deepspeed-zero) | å¦ | æ˜¯ |
| [torch.compile](#ä½¿ç”¨torchcompile) | æ˜¯ | å¦ |
| [å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰](#peft) | å¦ | æ˜¯ |

æ³¨æ„ï¼šå½“ä½¿ç”¨æ··åˆç²¾åº¦ä¸å°æ¨¡å‹å’Œå¤§æ‰¹å¤„ç†å¤§å°æ—¶ï¼Œä¼šæœ‰ä¸€äº›å†…å­˜èŠ‚çœï¼Œä½†å¯¹äºå¤§æ¨¡å‹å’Œå°æ‰¹å¤„ç†å¤§å°ï¼Œå†…å­˜ä½¿ç”¨é‡ä¼šæ›´å¤§ã€‚

æ‚¨å¯ä»¥ç»“åˆä¸Šè¿°æ–¹æ³•ä»¥è·å¾—ç´¯ç§¯æ•ˆæœã€‚è¿™äº›æŠ€æœ¯å¯¹æ‚¨éƒ½æ˜¯å¯ç”¨çš„ï¼Œæ— è®ºæ‚¨æ˜¯ä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)è®­ç»ƒæ¨¡å‹ï¼Œè¿˜æ˜¯ç¼–å†™çº¯PyTorchå¾ªç¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥é€šè¿‡[ä½¿ç”¨ğŸ¤— Accelerateé…ç½®è¿™äº›ä¼˜åŒ–](#ä½¿ç”¨åŠ é€Ÿ)ã€‚

å¦‚æœè¿™äº›æ–¹æ³•æ²¡æœ‰å¸¦æ¥è¶³å¤Ÿçš„æ”¶ç›Šï¼Œæ‚¨å¯ä»¥æ¢ç´¢ä»¥ä¸‹é€‰é¡¹ï¼š

+   [è€ƒè™‘æ„å»ºè‡ªå·±çš„è‡ªå®šä¹‰Dockerå®¹å™¨ï¼Œå…¶ä¸­åŒ…å«é«˜æ•ˆçš„è½¯ä»¶é¢„æ„å»º](#é«˜æ•ˆè½¯ä»¶é¢„æ„å»º)

+   [è€ƒè™‘ä½¿ç”¨ä¸“å®¶æ··åˆï¼ˆMoEï¼‰çš„æ¨¡å‹](#ä¸“å®¶æ··åˆ)

+   [å°†æ‚¨çš„æ¨¡å‹è½¬æ¢ä¸ºBetterTransformerä»¥åˆ©ç”¨PyTorchåŸç”Ÿæ³¨æ„åŠ›](#ä½¿ç”¨pytorchåŸç”Ÿæ³¨æ„åŠ›)

æœ€åï¼Œå¦‚æœå³ä½¿åˆ‡æ¢åˆ°åƒA100è¿™æ ·çš„æœåŠ¡å™¨çº§GPUåä»ç„¶ä¸å¤Ÿï¼Œè€ƒè™‘åˆ‡æ¢åˆ°å¤šGPUè®¾ç½®ã€‚æ‰€æœ‰è¿™äº›æ–¹æ³•åœ¨å¤šGPUè®¾ç½®ä¸­ä»ç„¶æœ‰æ•ˆï¼Œæ­¤å¤–ï¼Œæ‚¨è¿˜å¯ä»¥åˆ©ç”¨[å¤šGPUéƒ¨åˆ†](perf_train_gpu_many)ä¸­æ¦‚è¿°çš„å…¶ä»–å¹¶è¡ŒæŠ€æœ¯ã€‚

## æ‰¹å¤„ç†å¤§å°é€‰æ‹©

ä¸ºäº†å®ç°æœ€ä½³æ€§èƒ½ï¼Œé¦–å…ˆè¦ç¡®å®šé€‚å½“çš„æ‰¹å¤„ç†å¤§å°ã€‚å»ºè®®ä½¿ç”¨å¤§å°ä¸º2^Nçš„æ‰¹å¤„ç†å¤§å°å’Œè¾“å…¥/è¾“å‡ºç¥ç»å…ƒè®¡æ•°ã€‚é€šå¸¸æ˜¯8çš„å€æ•°ï¼Œä½†å¯ä»¥æ›´é«˜ï¼Œå…·ä½“å–å†³äºæ‰€ä½¿ç”¨çš„ç¡¬ä»¶å’Œæ¨¡å‹çš„æ•°æ®ç±»å‹ã€‚

æœ‰å…³å‚è€ƒï¼Œè¯·æŸ¥çœ‹NVIDIAå…³äºå…¨è¿æ¥å±‚ï¼ˆæ¶‰åŠGEMMsï¼ˆé€šç”¨çŸ©é˜µä¹˜æ³•ï¼‰ï¼‰çš„[è¾“å…¥/è¾“å‡ºç¥ç»å…ƒè®¡æ•°](https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html#input-features)å’Œ[æ‰¹æ¬¡å¤§å°](https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html#batch-size)çš„å»ºè®®ã€‚

[Tensor Coreè¦æ±‚](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc)æ ¹æ®æ•°æ®ç±»å‹å’Œç¡¬ä»¶å®šä¹‰ä¹˜æ•°ã€‚ä¾‹å¦‚ï¼Œå¯¹äºfp16æ•°æ®ç±»å‹ï¼Œæ¨èä½¿ç”¨8çš„å€æ•°ï¼Œé™¤éæ˜¯A100 GPUï¼Œæ­¤æ—¶ä½¿ç”¨64çš„å€æ•°ã€‚

å¯¹äºè¾ƒå°çš„å‚æ•°ï¼Œè¿˜è¦è€ƒè™‘[ç»´åº¦é‡åŒ–æ•ˆåº”](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#dim-quantization)ã€‚è¿™æ˜¯ç“¦ç‰‡åŒ–å‘ç”Ÿçš„åœ°æ–¹ï¼Œæ­£ç¡®çš„ä¹˜æ•°å¯ä»¥æ˜¾è‘—åŠ å¿«é€Ÿåº¦ã€‚

## æ¢¯åº¦ç´¯ç§¯

**æ¢¯åº¦ç´¯ç§¯**æ–¹æ³•æ—¨åœ¨ä»¥è¾ƒå°çš„å¢é‡è®¡ç®—æ¢¯åº¦ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡ä¸ºæ•´ä¸ªæ‰¹æ¬¡è®¡ç®—æ¢¯åº¦ã€‚è¿™ç§æ–¹æ³•æ¶‰åŠé€šè¿‡æ¨¡å‹æ‰§è¡Œå‰å‘å’Œåå‘ä¼ é€’ï¼Œå¹¶åœ¨è¿‡ç¨‹ä¸­ç´¯ç§¯æ¢¯åº¦æ¥è¿­ä»£è®¡ç®—è¾ƒå°æ‰¹æ¬¡çš„æ¢¯åº¦ã€‚ä¸€æ—¦ç§¯ç´¯äº†è¶³å¤Ÿæ•°é‡çš„æ¢¯åº¦ï¼Œå°±ä¼šæ‰§è¡Œæ¨¡å‹çš„ä¼˜åŒ–æ­¥éª¤ã€‚é€šè¿‡ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼Œå¯ä»¥å°†**æœ‰æ•ˆæ‰¹æ¬¡å¤§å°**å¢åŠ åˆ°GPUå†…å­˜å®¹é‡æ‰€æ–½åŠ çš„é™åˆ¶ä¹‹å¤–ã€‚ç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ¢¯åº¦ç´¯ç§¯å¼•å…¥çš„é¢å¤–å‰å‘å’Œåå‘ä¼ é€’å¯èƒ½ä¼šå‡æ…¢è®­ç»ƒè¿‡ç¨‹ã€‚

æ‚¨å¯ä»¥é€šè¿‡å‘[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)æ·»åŠ `gradient_accumulation_steps`å‚æ•°æ¥å¯ç”¨æ¢¯åº¦ç´¯ç§¯ï¼š

```py
training_args = TrainingArguments(per_device_train_batch_size=1, gradient_accumulation_steps=4, **default_args)
```

åœ¨ä¸Šè¿°ç¤ºä¾‹ä¸­ï¼Œæ‚¨çš„æœ‰æ•ˆæ‰¹æ¬¡å¤§å°å˜ä¸º4ã€‚

æˆ–è€…ï¼Œä½¿ç”¨ğŸ¤— Accelerateæ¥å®Œå…¨æ§åˆ¶è®­ç»ƒå¾ªç¯ã€‚åœ¨æœ¬æŒ‡å—çš„[åé¢](#using-accelerate)æ‰¾åˆ°ğŸ¤— Accelerateç¤ºä¾‹ã€‚

å°½å¯èƒ½åœ°æœ€å¤§åŒ–GPUä½¿ç”¨ç‡æ˜¯å»ºè®®çš„ï¼Œä½†æ˜¯é«˜æ•°é‡çš„æ¢¯åº¦ç´¯ç§¯æ­¥éª¤å¯èƒ½ä¼šå¯¼è‡´è®­ç»ƒå‡é€Ÿæ›´åŠ æ˜æ˜¾ã€‚è€ƒè™‘ä»¥ä¸‹ç¤ºä¾‹ã€‚å‡è®¾`per_device_train_batch_size=4`ï¼Œæ²¡æœ‰æ¢¯åº¦ç´¯ç§¯è¾¾åˆ°äº†GPUçš„æé™ã€‚å¦‚æœæ‚¨æƒ³è¦ä½¿ç”¨å¤§å°ä¸º64çš„æ‰¹æ¬¡è¿›è¡Œè®­ç»ƒï¼Œè¯·ä¸è¦å°†`per_device_train_batch_size`è®¾ç½®ä¸º1ï¼Œå¹¶å°†`gradient_accumulation_steps`è®¾ç½®ä¸º64ã€‚ç›¸åï¼Œä¿æŒ`per_device_train_batch_size=4`ï¼Œå¹¶è®¾ç½®`gradient_accumulation_steps=16`ã€‚è¿™æ ·å¯ä»¥å®ç°ç›¸åŒçš„æœ‰æ•ˆæ‰¹æ¬¡å¤§å°ï¼ŒåŒæ—¶æ›´å¥½åœ°åˆ©ç”¨å¯ç”¨çš„GPUèµ„æºã€‚

æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ[RTX-3090](https://github.com/huggingface/transformers/issues/14608#issuecomment-1004392537)å’Œ[A100](https://github.com/huggingface/transformers/issues/15026#issuecomment-1005033957)çš„æ‰¹æ¬¡å¤§å°å’Œæ¢¯åº¦ç´¯ç§¯åŸºå‡†ã€‚

## æ¢¯åº¦æ£€æŸ¥ç‚¹

å³ä½¿å°†æ‰¹æ¬¡å¤§å°è®¾ç½®ä¸º1å¹¶ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼Œä¸€äº›å¤§å‹æ¨¡å‹ä»å¯èƒ½é¢ä¸´å†…å­˜é—®é¢˜ã€‚è¿™æ˜¯å› ä¸ºè¿˜æœ‰å…¶ä»–ç»„ä»¶ä¹Ÿéœ€è¦å†…å­˜å­˜å‚¨ã€‚

ä¿å­˜å‰å‘ä¼ é€’ä¸­çš„æ‰€æœ‰æ¿€æ´»ä»¥ä¾¿åœ¨åå‘ä¼ é€’æœŸé—´è®¡ç®—æ¢¯åº¦å¯èƒ½ä¼šå¯¼è‡´æ˜¾ç€çš„å†…å­˜å¼€é”€ã€‚å¦ä¸€ç§æ–¹æ³•æ˜¯åœ¨åå‘ä¼ é€’æœŸé—´ä¸¢å¼ƒæ¿€æ´»å¹¶åœ¨éœ€è¦æ—¶é‡æ–°è®¡ç®—å®ƒä»¬ï¼Œè¿™å°†å¼•å…¥ç›¸å½“å¤§çš„è®¡ç®—å¼€é”€å¹¶å‡æ…¢è®­ç»ƒè¿‡ç¨‹ã€‚

**æ¢¯åº¦æ£€æŸ¥ç‚¹**æä¾›äº†è¿™ä¸¤ç§æ–¹æ³•ä¹‹é—´çš„æŠ˜è¡·æ–¹æ¡ˆï¼Œå¹¶åœ¨è®¡ç®—å›¾ä¸­ä¿å­˜äº†ç­–ç•¥æ€§é€‰æ‹©çš„æ¿€æ´»ï¼Œå› æ­¤åªéœ€é‡æ–°è®¡ç®—ä¸€å°éƒ¨åˆ†æ¿€æ´»ä»¥è·å¾—æ¢¯åº¦ã€‚æœ‰å…³æ¢¯åº¦æ£€æŸ¥ç‚¹çš„æ·±å…¥è§£é‡Šï¼Œè¯·å‚é˜…[è¿™ç¯‡å¾ˆæ£’çš„æ–‡ç« ](https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9)ã€‚

è¦åœ¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ä¸­å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œè¯·å°†ç›¸åº”çš„æ ‡å¿—ä¼ é€’ç»™[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ï¼š

```py
training_args = TrainingArguments(
    per_device_train_batch_size=1, gradient_accumulation_steps=4, gradient_checkpointing=True, **default_args
)
```

æˆ–è€…ï¼Œä½¿ç”¨ğŸ¤— Accelerate-åœ¨æœ¬æŒ‡å—ä¸­æ‰¾åˆ°ğŸ¤— Accelerateç¤ºä¾‹[ï¼ˆ#ä½¿ç”¨åŠ é€Ÿï¼‰](#using-accelerate)ã€‚

è™½ç„¶æ¢¯åº¦æ£€æŸ¥ç‚¹å¯èƒ½æé«˜å†…å­˜æ•ˆç‡ï¼Œä½†ä¼šä½¿è®­ç»ƒé€Ÿåº¦å‡æ…¢çº¦20%ã€‚

## æ··åˆç²¾åº¦è®­ç»ƒ

**æ··åˆç²¾åº¦è®­ç»ƒ**æ˜¯ä¸€ç§æ—¨åœ¨é€šè¿‡åˆ©ç”¨è¾ƒä½ç²¾åº¦æ•°å€¼æ ¼å¼æ¥å¤„ç†æŸäº›å˜é‡æ¥ä¼˜åŒ–è®­ç»ƒæ¨¡å‹çš„è®¡ç®—æ•ˆç‡çš„æŠ€æœ¯ã€‚ä¼ ç»Ÿä¸Šï¼Œå¤§å¤šæ•°æ¨¡å‹ä½¿ç”¨32ä½æµ®ç‚¹ç²¾åº¦ï¼ˆfp32æˆ–float32ï¼‰æ¥è¡¨ç¤ºå’Œå¤„ç†å˜é‡ã€‚ç„¶è€Œï¼Œå¹¶éæ‰€æœ‰å˜é‡éƒ½éœ€è¦è¿™ç§é«˜ç²¾åº¦çº§åˆ«æ‰èƒ½è·å¾—å‡†ç¡®çš„ç»“æœã€‚é€šè¿‡å°†æŸäº›å˜é‡çš„ç²¾åº¦é™ä½åˆ°è¾ƒä½çš„æ•°å€¼æ ¼å¼ï¼Œå¦‚16ä½æµ®ç‚¹ï¼ˆfp16æˆ–float16ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ã€‚å› ä¸ºåœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œä¸€äº›è®¡ç®—æ˜¯ä»¥åŠç²¾åº¦è¿›è¡Œçš„ï¼Œè€Œä¸€äº›ä»ç„¶æ˜¯ä»¥å…¨ç²¾åº¦è¿›è¡Œçš„ï¼Œæ‰€ä»¥è¿™ç§æ–¹æ³•è¢«ç§°ä¸ºæ··åˆç²¾åº¦è®­ç»ƒã€‚

æœ€å¸¸è§çš„æ··åˆç²¾åº¦è®­ç»ƒæ˜¯é€šè¿‡ä½¿ç”¨fp16ï¼ˆfloat16ï¼‰æ•°æ®ç±»å‹æ¥å®ç°çš„ï¼Œä½†æ˜¯ä¸€äº›GPUæ¶æ„ï¼ˆä¾‹å¦‚Ampereæ¶æ„ï¼‰æä¾›äº†bf16å’Œtf32ï¼ˆCUDAå†…éƒ¨æ•°æ®ç±»å‹ï¼‰æ•°æ®ç±»å‹ã€‚æŸ¥çœ‹[NVIDIAåšå®¢](https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/)ä»¥äº†è§£è¿™äº›æ•°æ®ç±»å‹ä¹‹é—´çš„åŒºåˆ«ã€‚

### fp16

æ··åˆç²¾åº¦è®­ç»ƒçš„ä¸»è¦ä¼˜åŠ¿æ¥è‡ªäºå°†æ¿€æ´»ä¿å­˜åœ¨åŠç²¾åº¦ï¼ˆfp16ï¼‰ä¸­ã€‚å°½ç®¡æ¢¯åº¦ä¹Ÿæ˜¯ä»¥åŠç²¾åº¦è®¡ç®—çš„ï¼Œä½†å®ƒä»¬åœ¨ä¼˜åŒ–æ­¥éª¤ä¸­è¢«è½¬æ¢å›å…¨ç²¾åº¦ï¼Œå› æ­¤åœ¨è¿™é‡Œæ²¡æœ‰èŠ‚çœå†…å­˜ã€‚è™½ç„¶æ··åˆç²¾åº¦è®­ç»ƒå¯ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œä½†ä¹Ÿå¯èƒ½å¯¼è‡´æ›´å¤šçš„GPUå†…å­˜è¢«åˆ©ç”¨ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå°æ‰¹é‡å¤§å°ã€‚è¿™æ˜¯å› ä¸ºæ¨¡å‹ç°åœ¨ä»¥16ä½å’Œ32ä½ç²¾åº¦ï¼ˆGPUä¸ŠåŸå§‹æ¨¡å‹çš„1.5å€ï¼‰å­˜åœ¨äºGPUä¸Šã€‚

è¦å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œè¯·å°†`fp16`æ ‡å¿—è®¾ç½®ä¸º`True`ï¼š

```py
training_args = TrainingArguments(per_device_train_batch_size=4, fp16=True, **default_args)
```

å¦‚æœæ‚¨æ›´å–œæ¬¢ä½¿ç”¨ğŸ¤— Accelerateï¼Œè¯·åœ¨æœ¬æŒ‡å—ä¸­æ‰¾åˆ°ğŸ¤— Accelerateç¤ºä¾‹[ï¼ˆ#ä½¿ç”¨åŠ é€Ÿï¼‰](#using-accelerate)ã€‚

### BF16

å¦‚æœæ‚¨å¯ä»¥è®¿é—®Ampereæˆ–æ›´æ–°çš„ç¡¬ä»¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨bf16è¿›è¡Œæ··åˆç²¾åº¦è®­ç»ƒå’Œè¯„ä¼°ã€‚è™½ç„¶bf16çš„ç²¾åº¦æ¯”fp16å·®ï¼Œä½†å®ƒå…·æœ‰æ›´å¤§çš„åŠ¨æ€èŒƒå›´ã€‚åœ¨fp16ä¸­ï¼Œæ‚¨å¯ä»¥æ‹¥æœ‰çš„æœ€å¤§æ•°å­—æ˜¯`65535`ï¼Œä»»ä½•è¶…è¿‡è¿™ä¸ªæ•°å­—çš„æ•°å­—éƒ½ä¼šå¯¼è‡´æº¢å‡ºã€‚bf16çš„æ•°å­—å¯ä»¥è¾¾åˆ°`3.39e+38`ï¼ˆï¼ï¼‰ï¼Œè¿™å¤§çº¦ä¸fp32ç›¸åŒ-å› ä¸ºä¸¤è€…éƒ½ä½¿ç”¨äº†8ä½ç”¨äºæ•°å€¼èŒƒå›´ã€‚

æ‚¨å¯ä»¥åœ¨ğŸ¤— Trainerä¸­å¯ç”¨BF16ï¼š

```py
training_args = TrainingArguments(bf16=True, **default_args)
```

### TF32

Ampereç¡¬ä»¶ä½¿ç”¨ä¸€ç§åä¸ºtf32çš„ç¥å¥‡æ•°æ®ç±»å‹ã€‚å®ƒå…·æœ‰ä¸fp32ç›¸åŒçš„æ•°å€¼èŒƒå›´ï¼ˆ8ä½ï¼‰ï¼Œä½†æ˜¯ç²¾åº¦åªæœ‰10ä½ï¼ˆä¸fp16ç›¸åŒï¼‰ï¼Œæ€»å…±åªä½¿ç”¨äº†19ä½ã€‚å®ƒåœ¨è¿™ç§æ„ä¹‰ä¸Šæ˜¯â€œç¥å¥‡çš„â€ï¼Œå³æ‚¨å¯ä»¥ä½¿ç”¨æ­£å¸¸çš„fp32è®­ç»ƒå’Œ/æˆ–æ¨ç†ä»£ç ï¼Œå¹¶é€šè¿‡å¯ç”¨tf32æ”¯æŒï¼Œæ‚¨å¯ä»¥è·å¾—é«˜è¾¾3å€çš„ååé‡æ”¹è¿›ã€‚æ‚¨åªéœ€è¦å°†ä»¥ä¸‹å†…å®¹æ·»åŠ åˆ°æ‚¨çš„ä»£ç ä¸­ï¼š

```py
import torch
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
```

CUDAå°†åœ¨å¯èƒ½çš„æƒ…å†µä¸‹è‡ªåŠ¨åˆ‡æ¢åˆ°ä½¿ç”¨tf32è€Œä¸æ˜¯fp32ï¼Œå‡è®¾æ‰€ä½¿ç”¨çš„GPUæ¥è‡ªAmpereç³»åˆ—ã€‚

æ ¹æ®[NVIDIAç ”ç©¶](https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/)ï¼Œå¤§å¤šæ•°æœºå™¨å­¦ä¹ è®­ç»ƒå·¥ä½œè´Ÿè½½æ˜¾ç¤ºå‡ºä¸fp32ç›¸åŒçš„å›°æƒ‘åº¦å’Œæ”¶æ•›æ€§ã€‚å¦‚æœæ‚¨å·²ç»åœ¨ä½¿ç”¨fp16æˆ–bf16æ··åˆç²¾åº¦ï¼Œè¿™ä¹Ÿå¯èƒ½æœ‰åŠ©äºæé«˜ååé‡ã€‚

æ‚¨å¯ä»¥åœ¨ğŸ¤— Trainerä¸­å¯ç”¨æ­¤æ¨¡å¼ï¼š

```py
TrainingArguments(tf32=True, **default_args)
```

tf32æ— æ³•é€šè¿‡`tensor.to(dtype=torch.tf32)`ç›´æ¥è®¿é—®ï¼Œå› ä¸ºå®ƒæ˜¯å†…éƒ¨CUDAæ•°æ®ç±»å‹ã€‚æ‚¨éœ€è¦`torch>=1.7`æ‰èƒ½ä½¿ç”¨tf32æ•°æ®ç±»å‹ã€‚

æœ‰å…³tf32ä¸å…¶ä»–ç²¾åº¦çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒä»¥ä¸‹åŸºå‡†æµ‹è¯•ï¼š[RTX-3090](https://github.com/huggingface/transformers/issues/14608#issuecomment-1004390803)å’Œ[A100](https://github.com/huggingface/transformers/issues/15026#issuecomment-1004543189)ã€‚

## Flash Attention 2

æ‚¨å¯ä»¥é€šè¿‡åœ¨transformersä¸­ä½¿ç”¨Flash Attention 2é›†æˆæ¥åŠ å¿«è®­ç»ƒååé‡ã€‚æŸ¥çœ‹[å•GPUéƒ¨åˆ†](./perf_infer_gpu_one#Flash-Attention-2)ä¸­çš„é€‚å½“éƒ¨åˆ†ï¼Œäº†è§£å¦‚ä½•åŠ è½½å¸¦æœ‰Flash Attention 2æ¨¡å—çš„æ¨¡å‹çš„æ›´å¤šä¿¡æ¯ã€‚

## ä¼˜åŒ–å™¨é€‰æ‹©

ç”¨äºè®­ç»ƒå˜å‹å™¨æ¨¡å‹çš„æœ€å¸¸ç”¨ä¼˜åŒ–å™¨æ˜¯Adamæˆ–AdamWï¼ˆå¸¦æœ‰æƒé‡è¡°å‡çš„Adamï¼‰ã€‚Adamé€šè¿‡å­˜å‚¨å…ˆå‰æ¢¯åº¦çš„æ»šåŠ¨å¹³å‡å€¼å®ç°è‰¯å¥½çš„æ”¶æ•›ï¼›ç„¶è€Œï¼Œå®ƒä¼šå¢åŠ ä¸æ¨¡å‹å‚æ•°æ•°é‡ç›¸åŒæ•°é‡çº§çš„é¢å¤–å†…å­˜å ç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å¦ä¸€ç§ä¼˜åŒ–å™¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨åœ¨NVIDIA GPUä¸Šå®‰è£…äº†[NVIDIA/apex](https://github.com/NVIDIA/apex)ï¼Œæˆ–è€…åœ¨AMD GPUä¸Šå®‰è£…äº†[ROCmSoftwarePlatform/apex](https://github.com/ROCmSoftwarePlatform/apex)ï¼Œ`adamw_apex_fused`å°†ä¸ºæ‚¨æä¾›æ‰€æœ‰æ”¯æŒçš„AdamWä¼˜åŒ–å™¨ä¸­æœ€å¿«çš„è®­ç»ƒä½“éªŒã€‚

[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)é›†æˆäº†å„ç§å¯ç«‹å³ä½¿ç”¨çš„ä¼˜åŒ–å™¨ï¼š`adamw_hf`ã€`adamw_torch`ã€`adamw_torch_fused`ã€`adamw_apex_fused`ã€`adamw_anyprecision`ã€`adafactor`æˆ–`adamw_bnb_8bit`ã€‚æ›´å¤šä¼˜åŒ–å™¨å¯ä»¥é€šè¿‡ç¬¬ä¸‰æ–¹å®ç°æ’å…¥ã€‚

è®©æˆ‘ä»¬æ›´ä»”ç»†åœ°çœ‹çœ‹ä¸¤ç§æ›¿ä»£AdamWä¼˜åŒ–å™¨ï¼š

1.  `adafactor`å¯åœ¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ä¸­ä½¿ç”¨

1.  `adamw_bnb_8bit`ä¹Ÿå¯åœ¨Trainerä¸­ä½¿ç”¨ï¼Œä½†ä»¥ä¸‹æä¾›äº†ç¬¬ä¸‰æ–¹é›†æˆä»¥ä¾›æ¼”ç¤ºã€‚

ä»¥3Bå‚æ•°æ¨¡å‹â€œt5-3bâ€ä¸ºä¾‹è¿›è¡Œæ¯”è¾ƒï¼š

+   æ ‡å‡†çš„AdamWä¼˜åŒ–å™¨å°†éœ€è¦24GBçš„GPUå†…å­˜ï¼Œå› ä¸ºå®ƒä¸ºæ¯ä¸ªå‚æ•°ä½¿ç”¨8å­—èŠ‚ï¼ˆ8*3 => 24GBï¼‰

+   Adafactorä¼˜åŒ–å™¨å°†éœ€è¦è¶…è¿‡12GBã€‚å®ƒä¸ºæ¯ä¸ªå‚æ•°ä½¿ç”¨ç•¥å¤šäº4å­—èŠ‚ï¼Œå› æ­¤4*3ï¼Œç„¶åå†åŠ ä¸€äº›ã€‚

+   8ä½BNBé‡åŒ–ä¼˜åŒ–å™¨å°†ä»…ä½¿ç”¨ï¼ˆ2*3ï¼‰6GBï¼Œå¦‚æœæ‰€æœ‰ä¼˜åŒ–å™¨çŠ¶æ€éƒ½è¢«é‡åŒ–ã€‚

### Adafactor

Adafactorä¸ä¼šä¸ºæƒé‡çŸ©é˜µä¸­çš„æ¯ä¸ªå…ƒç´ å­˜å‚¨æ»šåŠ¨å¹³å‡å€¼ã€‚ç›¸åï¼Œå®ƒä¿ç•™èšåˆä¿¡æ¯ï¼ˆæŒ‰è¡Œå’Œåˆ—çš„æ»šåŠ¨å¹³å‡å’Œï¼‰ï¼Œæ˜¾è‘—å‡å°‘äº†å†…å­˜å ç”¨ã€‚ç„¶è€Œï¼Œä¸Adamç›¸æ¯”ï¼ŒAdafactoråœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½æ”¶æ•›è¾ƒæ…¢ã€‚

æ‚¨å¯ä»¥é€šè¿‡åœ¨[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ä¸­è®¾ç½®`optim="adafactor"`æ¥åˆ‡æ¢åˆ°Adafactorï¼š

```py
training_args = TrainingArguments(per_device_train_batch_size=4, optim="adafactor", **default_args)
```

ç»“åˆå…¶ä»–æ–¹æ³•ï¼ˆæ¢¯åº¦ç´¯ç§¯ã€æ¢¯åº¦æ£€æŸ¥ç‚¹å’Œæ··åˆç²¾åº¦è®­ç»ƒï¼‰ï¼Œæ‚¨å¯ä»¥åœ¨ä¿æŒååé‡çš„åŒæ—¶å®ç°é«˜è¾¾3å€çš„æ”¹è¿›ï¼ç„¶è€Œï¼Œå¦‚å‰æ‰€è¿°ï¼ŒAdafactorçš„æ”¶æ•›æ€§å¯èƒ½æ¯”Adamæ›´å·®ã€‚

### 8ä½Adam

ä¸Adafactorç­‰èšåˆä¼˜åŒ–å™¨çŠ¶æ€ä¸åŒï¼Œ8ä½Adamä¿ç•™å®Œæ•´çŠ¶æ€å¹¶å¯¹å…¶è¿›è¡Œé‡åŒ–ã€‚é‡åŒ–æ„å‘³ç€ä»¥è¾ƒä½ç²¾åº¦å­˜å‚¨çŠ¶æ€ï¼Œå¹¶ä»…åœ¨ä¼˜åŒ–æ—¶å¯¹å…¶è¿›è¡Œåé‡åŒ–ã€‚è¿™ç±»ä¼¼äºæ··åˆç²¾åº¦è®­ç»ƒçš„æ€æƒ³ã€‚

è¦ä½¿ç”¨`adamw_bnb_8bit`ï¼Œæ‚¨åªéœ€åœ¨[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ä¸­è®¾ç½®`optim="adamw_bnb_8bit"`ï¼š

```py
training_args = TrainingArguments(per_device_train_batch_size=4, optim="adamw_bnb_8bit", **default_args)
```

ç„¶è€Œï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ç¬¬ä¸‰æ–¹å®ç°çš„8ä½ä¼˜åŒ–å™¨è¿›è¡Œæ¼”ç¤ºï¼Œä»¥äº†è§£å¦‚ä½•é›†æˆã€‚

é¦–å…ˆï¼ŒæŒ‰ç…§GitHub [repo](https://github.com/TimDettmers/bitsandbytes)ä¸­çš„å®‰è£…æŒ‡å—å®‰è£…å®ç°8ä½Adamä¼˜åŒ–å™¨çš„`bitsandbytes`åº“ã€‚

æ¥ä¸‹æ¥éœ€è¦åˆå§‹åŒ–ä¼˜åŒ–å™¨ã€‚è¿™æ¶‰åŠä¸¤ä¸ªæ­¥éª¤ï¼š

+   é¦–å…ˆï¼Œå°†æ¨¡å‹çš„å‚æ•°åˆ†ä¸ºä¸¤ç»„ - ä¸€ç»„åº”ç”¨æƒé‡è¡°å‡ï¼Œå¦ä¸€ç»„ä¸åº”ç”¨ã€‚é€šå¸¸ï¼Œåç½®å’Œå±‚å½’ä¸€åŒ–å‚æ•°ä¸ä¼šè¢«æƒé‡è¡°å‡ã€‚

+   ç„¶åè¿›è¡Œä¸€äº›å‚æ•°æ•´ç†ï¼Œä»¥ä½¿ç”¨ä¸å…ˆå‰ä½¿ç”¨çš„AdamWä¼˜åŒ–å™¨ç›¸åŒçš„å‚æ•°ã€‚

```py
import bitsandbytes as bnb
from torch import nn
from transformers.trainer_pt_utils import get_parameter_names

training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)

decay_parameters = get_parameter_names(model, [nn.LayerNorm])
decay_parameters = [name for name in decay_parameters if "bias" not in name]
optimizer_grouped_parameters = [
    {
        "params": [p for n, p in model.named_parameters() if n in decay_parameters],
        "weight_decay": training_args.weight_decay,
    },
    {
        "params": [p for n, p in model.named_parameters() if n not in decay_parameters],
        "weight_decay": 0.0,
    },
]

optimizer_kwargs = {
    "betas": (training_args.adam_beta1, training_args.adam_beta2),
    "eps": training_args.adam_epsilon,
}
optimizer_kwargs["lr"] = training_args.learning_rate
adam_bnb_optim = bnb.optim.Adam8bit(
    optimizer_grouped_parameters,
    betas=(training_args.adam_beta1, training_args.adam_beta2),
    eps=training_args.adam_epsilon,
    lr=training_args.learning_rate,
)
```

æœ€åï¼Œå°†è‡ªå®šä¹‰ä¼˜åŒ–å™¨ä½œä¸ºå‚æ•°ä¼ é€’ç»™`Trainer`ï¼š

```py
trainer = Trainer(model=model, args=training_args, train_dataset=ds, optimizers=(adam_bnb_optim, None))
```

ç»“åˆå…¶ä»–æ–¹æ³•ï¼ˆæ¢¯åº¦ç´¯ç§¯ã€æ¢¯åº¦æ£€æŸ¥ç‚¹å’Œæ··åˆç²¾åº¦è®­ç»ƒï¼‰ï¼Œæ‚¨å¯ä»¥æœŸæœ›è·å¾—å¤§çº¦3å€çš„å†…å­˜æ”¹è¿›ï¼Œç”šè‡³æ¯”ä½¿ç”¨Adafactoræ—¶çš„ååé‡ç¨é«˜ã€‚

### multi_tensor

pytorch-nightlyå¼•å…¥äº†`torch.optim._multi_tensor`ï¼Œåº”è¯¥æ˜¾ç€åŠ å¿«å…·æœ‰å¤§é‡å°ç‰¹å¾å¼ é‡çš„ä¼˜åŒ–å™¨çš„é€Ÿåº¦ã€‚æœ€ç»ˆåº”è¯¥æˆä¸ºé»˜è®¤è®¾ç½®ï¼Œä½†å¦‚æœæ‚¨æƒ³æ›´æ—©å°è¯•å®ƒï¼Œè¯·æŸ¥çœ‹è¿™ä¸ªGitHub [é—®é¢˜](https://github.com/huggingface/transformers/issues/9965)ã€‚

## æ•°æ®é¢„åŠ è½½

è¾¾åˆ°è‰¯å¥½è®­ç»ƒé€Ÿåº¦çš„ä¸€ä¸ªé‡è¦è¦æ±‚æ˜¯èƒ½å¤Ÿä»¥GPUèƒ½å¤Ÿå¤„ç†çš„æœ€å¤§é€Ÿåº¦æä¾›æ•°æ®ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ“ä½œéƒ½åœ¨ä¸»è¿›ç¨‹ä¸­è¿›è¡Œï¼Œå¯èƒ½æ— æ³•å¿«é€Ÿä»ç£ç›˜è¯»å–æ•°æ®ï¼Œä»è€Œå¯¼è‡´ç“¶é¢ˆï¼Œå¯¼è‡´GPUåˆ©ç”¨ç‡ä¸è¶³ã€‚é…ç½®ä»¥ä¸‹å‚æ•°ä»¥å‡å°‘ç“¶é¢ˆï¼š

+   `DataLoader(pin_memory=True, ...)` - ç¡®ä¿æ•°æ®é¢„åŠ è½½åˆ°CPUä¸Šçš„å›ºå®šå†…å­˜ä¸­ï¼Œé€šå¸¸ä¼šå¯¼è‡´ä»CPUåˆ°GPUå†…å­˜çš„ä¼ è¾“é€Ÿåº¦æ›´å¿«ã€‚

+   `DataLoader(num_workers=4, ...)` - ç”Ÿæˆå‡ ä¸ªå·¥ä½œè¿›ç¨‹ä»¥æ›´å¿«åœ°é¢„åŠ è½½æ•°æ®ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè§‚å¯ŸGPUåˆ©ç”¨ç‡ç»Ÿè®¡æ•°æ®ï¼›å¦‚æœè¿œç¦»100ï¼…ï¼Œå°è¯•å¢åŠ å·¥ä½œè¿›ç¨‹çš„æ•°é‡ã€‚å½“ç„¶ï¼Œé—®é¢˜å¯èƒ½å‡ºåœ¨å…¶ä»–åœ°æ–¹ï¼Œå› æ­¤è®¸å¤šå·¥ä½œè¿›ç¨‹ä¸ä¸€å®šä¼šå¯¼è‡´æ›´å¥½çš„æ€§èƒ½ã€‚

åœ¨ä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)æ—¶ï¼Œç›¸åº”çš„[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)æ˜¯ï¼š`dataloader_pin_memory`ï¼ˆé»˜è®¤ä¸º`True`ï¼‰ï¼Œå’Œ`dataloader_num_workers`ï¼ˆé»˜è®¤ä¸º`0`ï¼‰ã€‚

## DeepSpeed ZeRO

DeepSpeedæ˜¯ä¸€ä¸ªå¼€æºçš„æ·±åº¦å­¦ä¹ ä¼˜åŒ–åº“ï¼Œä¸ğŸ¤— Transformerså’ŒğŸ¤— Accelerateé›†æˆã€‚å®ƒæä¾›äº†å„ç§åŠŸèƒ½å’Œä¼˜åŒ–ï¼Œæ—¨åœ¨æé«˜å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è®­ç»ƒçš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚

å¦‚æœæ‚¨çš„æ¨¡å‹é€‚åˆå•ä¸ªGPUå¹¶ä¸”æœ‰è¶³å¤Ÿçš„ç©ºé—´æ¥å®¹çº³å°æ‰¹é‡å¤§å°ï¼Œåˆ™ä¸éœ€è¦ä½¿ç”¨DeepSpeedï¼Œå› ä¸ºå®ƒåªä¼šå‡æ…¢é€Ÿåº¦ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ¨¡å‹æ— æ³•é€‚åº”å•ä¸ªGPUæˆ–æ— æ³•å®¹çº³å°æ‰¹é‡ï¼Œåˆ™å¯ä»¥åˆ©ç”¨DeepSpeed ZeRO + CPU Offloadï¼Œæˆ–NVMe Offloadæ¥å¤„ç†æ›´å¤§çš„æ¨¡å‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦å•ç‹¬[å®‰è£…è¯¥åº“](main_classes/deepspeed#installation)ï¼Œç„¶åæŒ‰ç…§æŒ‡å—ä¹‹ä¸€åˆ›å»ºé…ç½®æ–‡ä»¶å¹¶å¯åŠ¨DeepSpeedï¼š

+   æœ‰å…³DeepSpeedä¸[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)é›†æˆçš„è¯¦ç»†æŒ‡å—ï¼Œè¯·æŸ¥çœ‹[ç›¸åº”æ–‡æ¡£](main_classes/deepspeed)ï¼Œç‰¹åˆ«æ˜¯[å•ä¸ªGPUéƒ¨ç½²](main_classes/deepspeed#deployment-with-one-gpu)éƒ¨åˆ†ã€‚åœ¨ç¬”è®°æœ¬ä¸­ä½¿ç”¨DeepSpeedéœ€è¦è¿›è¡Œä¸€äº›è°ƒæ•´ï¼›è¯·æŸ¥çœ‹[ç›¸åº”æŒ‡å—](main_classes/deepspeed#deployment-in-notebooks)ã€‚

+   å¦‚æœæ‚¨æ›´å–œæ¬¢ä½¿ç”¨ğŸ¤— Accelerateï¼Œè¯·å‚è€ƒ[ğŸ¤— Accelerate DeepSpeedæŒ‡å—](https://huggingface.co/docs/accelerate/en/usage_guides/deepspeed)ã€‚

## ä½¿ç”¨torch.compile

PyTorch 2.0å¼•å…¥äº†ä¸€ä¸ªæ–°çš„ç¼–è¯‘å‡½æ•°ï¼Œä¸éœ€è¦å¯¹ç°æœ‰çš„PyTorchä»£ç è¿›è¡Œä»»ä½•ä¿®æ”¹ï¼Œåªéœ€æ·»åŠ ä¸€è¡Œä»£ç å³å¯ä¼˜åŒ–æ‚¨çš„ä»£ç ï¼š`model = torch.compile(model)`ã€‚

å¦‚æœä½¿ç”¨[Trainer](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.Trainer)ï¼Œæ‚¨åªéœ€è¦åœ¨[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ä¸­ä¼ é€’`torch_compile`é€‰é¡¹ï¼š

```py
training_args = TrainingArguments(torch_compile=True, **default_args)
```

`torch.compile`ä½¿ç”¨Pythonçš„å¸§è¯„ä¼°APIè‡ªåŠ¨ä»ç°æœ‰çš„PyTorchç¨‹åºåˆ›å»ºå›¾ã€‚åœ¨æ•è·å›¾ä¹‹åï¼Œå¯ä»¥éƒ¨ç½²ä¸åŒçš„åç«¯ä»¥å°†å›¾é™ä½åˆ°ä¼˜åŒ–å¼•æ“ã€‚æ‚¨å¯ä»¥åœ¨[PyTorchæ–‡æ¡£](https://pytorch.org/get-started/pytorch-2.0/)ä¸­æ‰¾åˆ°æ›´å¤šè¯¦ç»†ä¿¡æ¯å’ŒåŸºå‡†æµ‹è¯•ã€‚

`torch.compile`æœ‰ä¸€ä¸ªä¸æ–­å¢é•¿çš„åç«¯åˆ—è¡¨ï¼Œå¯ä»¥é€šè¿‡è°ƒç”¨`torchdynamo.list_backends()`æ‰¾åˆ°ï¼Œæ¯ä¸ªåç«¯éƒ½æœ‰å…¶å¯é€‰ä¾èµ–é¡¹ã€‚

é€šè¿‡åœ¨[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ä¸­æŒ‡å®š`torch_compile_backend`æ¥é€‰æ‹©è¦ä½¿ç”¨çš„åç«¯ã€‚ä¸€äº›æœ€å¸¸ç”¨çš„åç«¯åŒ…æ‹¬ï¼š

**è°ƒè¯•åç«¯**ï¼š

+   `dynamo.optimize("eager")` - ä½¿ç”¨PyTorchè¿è¡Œæå–çš„GraphModuleã€‚è¿™åœ¨è°ƒè¯•TorchDynamoé—®é¢˜æ—¶éå¸¸æœ‰ç”¨ã€‚

+   `dynamo.optimize("aot_eager")` - ä½¿ç”¨AotAutogradè€Œä¸ä½¿ç”¨ç¼–è¯‘å™¨ï¼Œå³ä»…ä½¿ç”¨PyTorch eagerè¿›è¡ŒAotAutogradçš„æå–å‰å‘å’Œåå‘å›¾ã€‚è¿™å¯¹è°ƒè¯•å¾ˆæœ‰ç”¨ï¼Œä½†ä¸å¤ªå¯èƒ½æä¾›åŠ é€Ÿã€‚

**è®­ç»ƒå’Œæ¨ç†åç«¯**ï¼š

+   `dynamo.optimize("inductor")` - ä½¿ç”¨TorchInductoråç«¯ï¼Œé€šè¿‡åˆ©ç”¨codegened Tritonå†…æ ¸å®ç°AotAutogradå’Œcudagraphsã€‚[é˜…è¯»æ›´å¤š](https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747)

+   `dynamo.optimize("nvfuser")` - nvFuserä¸TorchScriptã€‚[é˜…è¯»æ›´å¤š](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)

+   `dynamo.optimize("aot_nvfuser")` - nvFuserä¸AotAutogradã€‚[é˜…è¯»æ›´å¤š](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)

+   `dynamo.optimize("aot_cudagraphs")` - ä½¿ç”¨AotAutogradçš„cudagraphsã€‚[é˜…è¯»æ›´å¤š](https://github.com/pytorch/torchdynamo/pull/757)

**ä»…æ¨ç†åç«¯**ï¼š

+   `dynamo.optimize("ofi")` - ä½¿ç”¨Torchscriptçš„optimize_for_inferenceã€‚[é˜…è¯»æ›´å¤š](https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html)

+   `dynamo.optimize("fx2trt")` - ä½¿ç”¨NVIDIA TensorRTè¿›è¡Œæ¨ç†ä¼˜åŒ–ã€‚[é˜…è¯»æ›´å¤š](https://pytorch.org/TensorRT/tutorials/getting_started_with_fx_path.html)

+   `dynamo.optimize("onnxrt")` - ä½¿ç”¨ONNXRTè¿›è¡ŒCPU/GPUæ¨ç†ã€‚[é˜…è¯»æ›´å¤š](https://onnxruntime.ai/)

+   `dynamo.optimize("ipex")` - ä½¿ç”¨IPEXè¿›è¡ŒCPUæ¨ç†ã€‚[é˜…è¯»æ›´å¤š](https://github.com/intel/intel-extension-for-pytorch)

ä½¿ç”¨`torch.compile`ä¸ğŸ¤— Transformersçš„ç¤ºä¾‹ï¼Œè¯·æŸ¥çœ‹è¿™ç¯‡[åšæ–‡ï¼Œä»‹ç»å¦‚ä½•ä½¿ç”¨æœ€æ–°çš„PyTorch 2.0åŠŸèƒ½å¾®è°ƒBERTæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»](https://www.philschmid.de/getting-started-pytorch-2-0-transformers)

## ä½¿ç”¨ğŸ¤— PEFT

[å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰](https://huggingface.co/blog/peft)æ–¹æ³•åœ¨å¾®è°ƒæœŸé—´å†»ç»“é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ï¼Œå¹¶åœ¨å…¶ä¸Šæ·»åŠ å°‘é‡å¯è®­ç»ƒå‚æ•°ï¼ˆé€‚é…å™¨ï¼‰ã€‚

å› æ­¤ï¼Œ[ä¸ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦ç›¸å…³çš„å†…å­˜](https://huggingface.co/docs/transformers/model_memory_anatomy#anatomy-of-models-memory)å¤§å¤§å‡å°‘ã€‚

ä¾‹å¦‚ï¼Œå¯¹äºæ™®é€šçš„AdamWï¼Œä¼˜åŒ–å™¨çŠ¶æ€çš„å†…å­˜éœ€æ±‚å°†æ˜¯ï¼š

+   fp32å‚æ•°çš„å‰¯æœ¬ï¼š4å­—èŠ‚/å‚æ•°

+   åŠ¨é‡ï¼š4å­—èŠ‚/å‚æ•°

+   æ–¹å·®ï¼š4å­—èŠ‚/å‚æ•°

å‡è®¾ä¸€ä¸ªå…·æœ‰70äº¿å‚æ•°å’Œ2äº¿å‚æ•°æ³¨å…¥[ä½ç§©é€‚é…å™¨](https://huggingface.co/docs/peft/conceptual_guides/lora)çš„æ¨¡å‹ã€‚

æ™®é€šæ¨¡å‹çš„ä¼˜åŒ–å™¨çŠ¶æ€çš„å†…å­˜éœ€æ±‚å°†ä¸º12 * 7 = 84 GBï¼ˆå‡è®¾æœ‰7Bå¯è®­ç»ƒå‚æ•°ï¼‰ã€‚

æ·»åŠ Loraä¼šç•¥å¾®å¢åŠ ä¸æ¨¡å‹æƒé‡ç›¸å…³çš„å†…å­˜ï¼Œå¹¶å¤§å¹…å‡å°‘ä¼˜åŒ–å™¨çŠ¶æ€çš„å†…å­˜éœ€æ±‚è‡³12 * 0.2 = 2.4GBã€‚

åœ¨[PEFTæ–‡æ¡£](https://huggingface.co/docs/peft/)æˆ–[PEFTå­˜å‚¨åº“](https://github.com/huggingface/peft)ä¸­è¯¦ç»†äº†è§£PEFTåŠå…¶è¯¦ç»†ç”¨æ³•ã€‚

## ä½¿ç”¨ğŸ¤— Accelerate

ä½¿ç”¨[ğŸ¤— Accelerate](https://huggingface.co/docs/accelerate/index)å¯ä»¥åœ¨å®Œå…¨æ§åˆ¶è®­ç»ƒå¾ªç¯çš„åŒæ—¶ä½¿ç”¨ä¸Šè¿°æ–¹æ³•ï¼Œå¹¶ä¸”åŸºæœ¬ä¸Šå¯ä»¥ä½¿ç”¨çº¯PyTorchç¼–å†™å¾ªç¯å¹¶è¿›è¡Œä¸€äº›å¾®å°ä¿®æ”¹ã€‚

å‡è®¾æ‚¨å·²å°†[TrainingArguments](/docs/transformers/v4.37.2/en/main_classes/trainer#transformers.TrainingArguments)ä¸­çš„æ–¹æ³•ç»„åˆå¦‚ä¸‹ï¼š

```py
training_args = TrainingArguments(
    per_device_train_batch_size=1,
    gradient_accumulation_steps=4,
    gradient_checkpointing=True,
    fp16=True,
    **default_args,
)
```

ä½¿ç”¨ğŸ¤— Accelerateçš„å®Œæ•´ç¤ºä¾‹è®­ç»ƒå¾ªç¯åªæœ‰å‡ è¡Œä»£ç ï¼š

```py
from accelerate import Accelerator
from torch.utils.data.dataloader import DataLoader

dataloader = DataLoader(ds, batch_size=training_args.per_device_train_batch_size)

if training_args.gradient_checkpointing:
    model.gradient_checkpointing_enable()

accelerator = Accelerator(fp16=training_args.fp16)
model, optimizer, dataloader = accelerator.prepare(model, adam_bnb_optim, dataloader)

model.train()
for step, batch in enumerate(dataloader, start=1):
    loss = model(**batch).loss
    loss = loss / training_args.gradient_accumulation_steps
    accelerator.backward(loss)
    if step % training_args.gradient_accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åŒ…è£…åœ¨[`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ä¸­ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨æ¨¡å‹çš„[gradient_checkpointing_enable()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.gradient_checkpointing_enable)æ–¹æ³•å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ã€‚å½“æˆ‘ä»¬åˆå§‹åŒ–[`Accelerator`](https://huggingface.co/docs/accelerate/package_reference/accelerator#accelerate.Accelerator)æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šæ˜¯å¦è¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œå¹¶ä¸”å®ƒå°†åœ¨`prepare`è°ƒç”¨ä¸­ä¸ºæˆ‘ä»¬å¤„ç†ã€‚åœ¨[`prepare`](https://huggingface.co/docs/accelerate/package_reference/accelerator#accelerate.Accelerator.prepare)è°ƒç”¨æœŸé—´ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨å¤šä¸ªGPUï¼Œæ•°æ®åŠ è½½å™¨ä¹Ÿå°†åˆ†å¸ƒåœ¨å·¥ä½œè¿›ç¨‹ä¹‹é—´ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸ä¹‹å‰ç¤ºä¾‹ç›¸åŒçš„[8ä½ä¼˜åŒ–å™¨](#8-bit-adam)ã€‚

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸»è¦çš„è®­ç»ƒå¾ªç¯ã€‚è¯·æ³¨æ„ï¼Œ`backward`è°ƒç”¨ç”±ğŸ¤— Accelerateå¤„ç†ã€‚æˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°æ¢¯åº¦ç´¯ç§¯çš„å·¥ä½œåŸç†ï¼šæˆ‘ä»¬è§„èŒƒåŒ–æŸå¤±ï¼Œå› æ­¤åœ¨ç´¯ç§¯ç»“æŸæ—¶è·å¾—å¹³å‡å€¼ï¼Œä¸€æ—¦æˆ‘ä»¬æœ‰è¶³å¤Ÿçš„æ­¥éª¤ï¼Œæˆ‘ä»¬å°±è¿è¡Œä¼˜åŒ–ã€‚

ä½¿ç”¨ğŸ¤— Accelerateå®ç°è¿™äº›ä¼˜åŒ–æŠ€æœ¯åªéœ€è¦å‡ è¡Œä»£ç ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒå¾ªç¯ä¸­å…·æœ‰æ›´å¤§çš„çµæ´»æ€§ã€‚è¦æŸ¥çœ‹æ‰€æœ‰åŠŸèƒ½çš„å®Œæ•´æ–‡æ¡£ï¼Œè¯·æŸ¥çœ‹[Accelerateæ–‡æ¡£](https://huggingface.co/docs/accelerate/index)ã€‚

## é«˜æ•ˆçš„è½¯ä»¶é¢„æ„å»º

PyTorchçš„[pipå’Œcondaæ„å»º](https://pytorch.org/get-started/locally/#start-locally)é¢„å…ˆæ„å»ºäº†cudaå·¥å…·åŒ…ï¼Œè¶³ä»¥è¿è¡ŒPyTorchï¼Œä½†å¦‚æœéœ€è¦æ„å»ºcudaæ‰©å±•ï¼Œåˆ™ä¸è¶³ã€‚

æœ‰æ—¶ï¼Œå¯èƒ½éœ€è¦é¢å¤–çš„åŠªåŠ›æ¥é¢„æ„å»ºä¸€äº›ç»„ä»¶ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯æœªç»é¢„ç¼–è¯‘çš„åº“ï¼Œå¦‚`apex`ã€‚åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œå¼„æ¸…æ¥šå¦‚ä½•åœ¨ç³»ç»ŸèŒƒå›´å†…å®‰è£…æ­£ç¡®çš„cudaå·¥å…·åŒ…å¯èƒ½ä¼šå¾ˆå¤æ‚ã€‚ä¸ºäº†è§£å†³è¿™äº›æƒ…å†µï¼ŒPyTorchå’ŒNVIDIAå‘å¸ƒäº†ä¸€ä¸ªæ–°ç‰ˆæœ¬çš„NGC dockerå®¹å™¨ï¼Œå…¶ä¸­å·²ç»é¢„å…ˆæ„å»ºäº†ä¸€åˆ‡ã€‚æ‚¨åªéœ€åœ¨å…¶ä¸­å®‰è£…æ‚¨çš„ç¨‹åºï¼Œå®ƒå°±å¯ä»¥ç«‹å³è¿è¡Œã€‚

è¿™ç§æ–¹æ³•åœ¨æ‚¨æƒ³è¦è°ƒæ•´pytorchæºä»£ç å’Œ/æˆ–åˆ¶ä½œæ–°çš„å®šåˆ¶æ„å»ºæ—¶ä¹Ÿå¾ˆæœ‰ç”¨ã€‚è¦æ‰¾åˆ°æ‚¨æƒ³è¦çš„dockeré•œåƒç‰ˆæœ¬ï¼Œè¯·ä»[PyTorchå‘å¸ƒè¯´æ˜](https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/)å¼€å§‹ï¼Œé€‰æ‹©æœ€æ–°çš„ä¸€ä¸ªæœˆå‘å¸ƒä¹‹ä¸€ã€‚è¿›å…¥æ‰€éœ€å‘å¸ƒçš„å‘å¸ƒè¯´æ˜ï¼Œæ£€æŸ¥ç¯å¢ƒçš„ç»„ä»¶æ˜¯å¦ç¬¦åˆæ‚¨çš„éœ€æ±‚ï¼ˆåŒ…æ‹¬NVIDIAé©±åŠ¨ç¨‹åºè¦æ±‚ï¼ï¼‰ï¼Œç„¶ååœ¨è¯¥æ–‡æ¡£çš„é¡¶éƒ¨è½¬åˆ°ç›¸åº”çš„NGCé¡µé¢ã€‚å¦‚æœç”±äºæŸç§åŸå› æ‚¨è¿·å¤±äº†æ–¹å‘ï¼Œè¿™é‡Œæ˜¯[æ‰€æœ‰PyTorch NGCé•œåƒçš„ç´¢å¼•](https://ngc.nvidia.com/catalog/containers/nvidia:pytorch)ã€‚

æ¥ä¸‹æ¥æŒ‰ç…§è¯´æ˜ä¸‹è½½å’Œéƒ¨ç½²dockeré•œåƒã€‚

## ä¸“å®¶æ··åˆ

ä¸€äº›æœ€è¿‘çš„è®ºæ–‡æŠ¥å‘Šäº†4-5å€çš„è®­ç»ƒåŠ é€Ÿå’Œå°†Mixture of Expertsï¼ˆMoEï¼‰é›†æˆåˆ°Transformeræ¨¡å‹ä¸­ä»¥å®ç°æ›´å¿«çš„æ¨ç†ã€‚

ç”±äºå‘ç°æ›´å¤šçš„å‚æ•°ä¼šå¯¼è‡´æ›´å¥½çš„æ€§èƒ½ï¼Œè¿™ç§æŠ€æœ¯å…è®¸å°†å‚æ•°æ•°é‡å¢åŠ ä¸€ä¸ªæ•°é‡çº§ï¼Œè€Œä¸å¢åŠ è®­ç»ƒæˆæœ¬ã€‚

åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæ¯ä¸ªå…¶ä»–çš„FFNå±‚éƒ½è¢«ä¸€ä¸ªMoEå±‚æ›¿æ¢ï¼Œè¯¥å±‚ç”±è®¸å¤šä¸“å®¶ç»„æˆï¼Œå…·æœ‰ä¸€ä¸ªé—¨æ§å‡½æ•°ï¼Œæ ¹æ®è¾“å…¥ä»¤ç‰Œåœ¨åºåˆ—ä¸­çš„ä½ç½®å¹³è¡¡åœ°è®­ç»ƒæ¯ä¸ªä¸“å®¶ã€‚

![MoE Transformer 2x block](../Images/582afa9e1fb35b75b07f45d236dc9d35.png)

(æ¥æºï¼š[GLAM](https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html))

æ‚¨å¯ä»¥åœ¨æœ¬èŠ‚æœ«å°¾åˆ—å‡ºçš„è®ºæ–‡ä¸­æ‰¾åˆ°è¯¦å°½çš„ç»†èŠ‚å’Œæ¯”è¾ƒè¡¨ã€‚

è¿™ç§æ–¹æ³•çš„ä¸»è¦ç¼ºç‚¹æ˜¯å®ƒéœ€è¦å¤§é‡çš„GPUå†…å­˜ - å‡ ä¹æ¯”å…¶å¯†é›†ç­‰ä»·ç‰©å¤§ä¸€ä¸ªæ•°é‡çº§ã€‚æå‡ºäº†å„ç§è’¸é¦å’Œæ–¹æ³•ï¼Œä»¥å…‹æœæ›´é«˜çš„å†…å­˜éœ€æ±‚ã€‚

ç„¶è€Œï¼Œå­˜åœ¨ç›´æ¥çš„æƒè¡¡ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å°‘é‡ä¸“å®¶å’Œ2-3å€è¾ƒå°çš„åŸºç¡€æ¨¡å‹ï¼Œè€Œä¸æ˜¯æ•°åæˆ–æ•°ç™¾ä¸ªä¸“å®¶ï¼Œä»è€Œå¯¼è‡´5å€è¾ƒå°çš„æ¨¡å‹ï¼Œå› æ­¤é€‚åº¦å¢åŠ è®­ç»ƒé€Ÿåº¦ï¼ŒåŒæ—¶é€‚åº¦å¢åŠ å†…å­˜éœ€æ±‚ã€‚

å¤§å¤šæ•°ç›¸å…³è®ºæ–‡å’Œå®ç°éƒ½æ˜¯å›´ç»•Tensorflow/TPUsæ„å»ºçš„ï¼š

+   [GShard: ä½¿ç”¨æ¡ä»¶è®¡ç®—å’Œè‡ªåŠ¨åˆ†ç‰‡æ‰©å±•å·¨å‹æ¨¡å‹](https://arxiv.org/abs/2006.16668)

+   [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/abs/2101.03961)

+   [GLaM: Generalist Language Model (GLaM)](https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html)

å¯¹äºPytorchï¼ŒDeepSpeedä¹Ÿæ„å»ºäº†ä¸€ä¸ªï¼š[DeepSpeed-MoE: æ¨è¿›æ··åˆä¸“å®¶æ¨ç†å’Œè®­ç»ƒä»¥æ”¯æŒä¸‹ä¸€ä»£AIè§„æ¨¡](https://arxiv.org/abs/2201.05596)ï¼Œ[Mixture of Experts](https://www.deepspeed.ai/tutorials/mixture-of-experts/) - åšæ–‡ï¼š[1](https://www.microsoft.com/en-us/research/blog/deepspeed-powers-8x-larger-moe-model-training-with-high-performance/)ï¼Œ[2](https://www.microsoft.com/en-us/research/publication/scalable-and-efficient-moe-training-for-multitask-multilingual-models/)ä»¥åŠå¤§å‹åŸºäºTransformerçš„è‡ªç„¶è¯­è¨€ç”Ÿæˆæ¨¡å‹çš„ç‰¹å®šéƒ¨ç½²ï¼š[åšæ–‡](https://www.deepspeed.ai/2021/12/09/deepspeed-moe-nlg.html)ï¼Œ[Megatron-Deepspeedåˆ†æ”¯](https://github.com/microsoft/Megatron-DeepSpeed/tree/moe-training)ã€‚

## ä½¿ç”¨PyTorchåŸç”Ÿæ³¨æ„åŠ›å’ŒFlash Attention

PyTorch 2.0å‘å¸ƒäº†ä¸€ä¸ªåŸç”Ÿçš„[`torch.nn.functional.scaled_dot_product_attention`](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html)ï¼ˆSDPAï¼‰ï¼Œå…è®¸ä½¿ç”¨èåˆçš„GPUå†…æ ¸ï¼Œå¦‚[å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›](https://arxiv.org/abs/2112.05682)å’Œ[é—ªå­˜æ³¨æ„åŠ›](https://arxiv.org/abs/2205.14135)ã€‚

å®‰è£…[`optimum`](https://github.com/huggingface/optimum)åŒ…åï¼Œå¯ä»¥æ›¿æ¢ç›¸å…³çš„å†…éƒ¨æ¨¡å—ä»¥ä½¿ç”¨PyTorchçš„åŸç”Ÿæ³¨æ„åŠ›ï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š

```py
model = model.to_bettertransformer()
```

è½¬æ¢åï¼Œåƒå¾€å¸¸ä¸€æ ·è®­ç»ƒæ¨¡å‹ã€‚

PyTorchåŸç”Ÿçš„`scaled_dot_product_attention`æ“ä½œç¬¦åªæœ‰åœ¨æ²¡æœ‰æä¾›`attention_mask`æ—¶æ‰èƒ½åˆ†æ´¾åˆ°Flash Attentionã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œåœ¨è®­ç»ƒæ¨¡å¼ä¸‹ï¼ŒBetterTransformeré›†æˆ**å–æ¶ˆäº†æ©ç æ”¯æŒï¼Œåªèƒ½ç”¨äºä¸éœ€è¦å¡«å……æ©ç çš„æ‰¹é‡è®­ç»ƒ**ã€‚ä¾‹å¦‚ï¼Œåœ¨æ©ç è¯­è¨€å»ºæ¨¡æˆ–å› æœè¯­è¨€å»ºæ¨¡æœŸé—´ã€‚BetterTransformerä¸é€‚ç”¨äºéœ€è¦å¡«å……æ©ç çš„ä»»åŠ¡çš„å¾®è°ƒæ¨¡å‹ã€‚

æŸ¥çœ‹è¿™ç¯‡[åšæ–‡](https://pytorch.org/blog/out-of-the-box-acceleration/)ï¼Œäº†è§£æœ‰å…³SDPAåŠ é€Ÿå’ŒèŠ‚çœå†…å­˜çš„æ›´å¤šä¿¡æ¯ã€‚
