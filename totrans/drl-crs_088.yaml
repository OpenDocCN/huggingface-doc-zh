- en: An introduction to Multi-Agents Reinforcement Learning (MARL)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/learn/deep-rl-course/unit7/introduction-to-marl](https://huggingface.co/learn/deep-rl-course/unit7/introduction-to-marl)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/deep-rl-course/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/start.c0547f01.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/scheduler.37c15a92.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/singletons.b4cd11ef.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.18351ede.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/paths.3cd722f3.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/entry/app.41e0adab.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/index.7cb9c9b8.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/0.b906e680.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/nodes/75.16c742dc.js">
    <link rel="modulepreload" href="/docs/deep-rl-course/main/en/_app/immutable/chunks/Heading.d3928e2a.js">
  prefs: []
  type: TYPE_NORMAL
- en: From single agent to multiple agents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the first unit, we learned to train agents in a single-agent system. When
    our agent was alone in its environment: **it was not cooperating or collaborating
    with other agents**.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Patchwork](../Images/0bfa9643ea17c46664be61fcfb3e7a48.png)'
  prefs: []
  type: TYPE_IMG
- en: A patchwork of all the environments you've trained your agents on since the
    beginning of the course
  prefs: []
  type: TYPE_NORMAL
- en: When we do multi-agents reinforcement learning (MARL), we are in a situation
    where we have multiple agents **that share and interact in a common environment**.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, you can think of a warehouse where **multiple robots need to navigate
    to load and unload packages**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Warehouse](../Images/2e1d606f26899a2b71fe8753420674f7.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Image by upklyak](https://www.freepik.com/free-vector/robots-warehouse-interior-automated-machines_32117680.htm#query=warehouse
    robot&position=17&from_view=keyword) on Freepik'
  prefs: []
  type: TYPE_NORMAL
- en: Or a road with **several autonomous vehicles**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Self driving cars](../Images/df2e97029db297cd2432fa0827f04c5d.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Image by jcomp](https://www.freepik.com/free-vector/autonomous-smart-car-automatic-wireless-sensor-driving-road-around-car-autonomous-smart-car-goes-scans-roads-observe-distance-automatic-braking-system_26413332.htm#query=self
    driving cars highway&position=34&from_view=search&track=ais) on Freepik'
  prefs: []
  type: TYPE_NORMAL
- en: In these examples, we have **multiple agents interacting in the environment
    and with the other agents**. This implies defining a multi-agents system. But
    first, let’s understand the different types of multi-agent environments.
  prefs: []
  type: TYPE_NORMAL
- en: Different types of multi-agent environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Given that, in a multi-agent system, agents interact with other agents, we
    can have different types of environments:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Cooperative environments*: where your agents need **to maximize the common
    benefits**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For instance, in a warehouse, **robots must collaborate to load and unload the
    packages efficiently (as fast as possible)**.
  prefs: []
  type: TYPE_NORMAL
- en: '*Competitive/Adversarial environments*: in this case, your agent **wants to
    maximize its benefits by minimizing the opponent’s**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, in a game of tennis, **each agent wants to beat the other agent**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Tennis](../Images/614a5ed542429a87559635bca3dc68a4.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Mixed of both adversarial and cooperative*: like in our SoccerTwos environment,
    two agents are part of a team (blue or purple): they need to cooperate with each
    other and beat the opponent team.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![SoccerTwos](../Images/b8d7d800c316a50a5f64472742088b73.png)'
  prefs: []
  type: TYPE_IMG
- en: This environment was made by the [Unity MLAgents Team](https://github.com/Unity-Technologies/ml-agents)
  prefs: []
  type: TYPE_NORMAL
- en: 'So now we might wonder: how can we design these multi-agent systems? Said differently,
    **how can we train agents in a multi-agent setting** ?'
  prefs: []
  type: TYPE_NORMAL
