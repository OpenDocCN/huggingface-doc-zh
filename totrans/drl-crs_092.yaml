- en: Quiz
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测验
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit7/quiz](https://huggingface.co/learn/deep-rl-course/unit7/quiz)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/learn/deep-rl-course/unit7/quiz](https://huggingface.co/learn/deep-rl-course/unit7/quiz)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The best way to learn and [to avoid the illusion of competence](https://www.coursera.org/lecture/learning-how-to-learn/illusions-of-competence-BuFzf)
    **is to test yourself.** This will help you to find **where you need to reinforce
    your knowledge**.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 学习和[避免能力错觉](https://www.coursera.org/lecture/learning-how-to-learn/illusions-of-competence-BuFzf)的最佳方法**是测试自己**。这将帮助您找到**需要加强知识的地方**。
- en: 'Q1: Chose the option which fits better when comparing different types of multi-agent
    environments'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q1: 在比较不同类型的多智能体环境时，选择更合适的选项'
- en: Your agents aim to maximize common benefits in ____ environments
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的智能体旨在在 ____ 环境中最大化共同利益
- en: Your agents aim to maximize common benefits while minimizing opponent’s in ____
    environments
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的智能体旨在在 ____ 环境中最大化共同利益，同时最小化对手的利益
- en: 'Q2: Which of the following statements are true about decentralized learning?'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q2: 以下哪些关于分散式学习的陈述是正确的？'
- en: 'Q3: Which of the following statements are true about centralized learning?'
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q3: 以下哪些关于集中式学习的陈述是正确的？'
- en: 'Q4: Explain in your own words what is the Self-Play approach'
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q4: 用您自己的话解释什么是自我对弈方法'
- en: <details data-svelte-h="svelte-17h7xil"><summary>Solution</summary>
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: <details data-svelte-h="svelte-17h7xil"><summary>解决方案</summary>
- en: '`Self-play` is an approach to instantiate copies of agents with the same policy
    as your as opponents, so that your agent learns from agents with same training
    level.</details>'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: “自我对弈”是一种方法，通过实例化具有与对手相同策略的代理的副本，使您的代理从具有相同训练水平的代理中学习。</details>
- en: 'Q5: When configuring Self-play , several parameters are important. Could you
    identify, by their definition, which parameter are we talking about?'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q5: 在配置自我对弈时，有几个重要参数。您能根据其定义确定我们正在谈论哪些参数吗？'
- en: The probability of playing against the current self vs an opponent from a pool
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与当前自己对战的概率 vs 从对手池中选择对手对战的概率
- en: Variety (dispersion) of training levels of the opponents you can face
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面对对手的训练水平的差异（分散）
- en: The number of training steps before spawning a new opponent
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成新对手之前的训练步骤数
- en: Opponent change rate
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对手更换率
- en: 'Q6: What are the main motivations to use a ELO rating Score?'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Q6: 使用ELO评分的主要动机是什么？'
- en: Congrats on finishing this Quiz 🥳, if you missed some elements, take time to
    read the chapter again to reinforce (😏) your knowledge.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您完成了这个测验🥳，如果您错过了一些元素，请花时间再次阅读章节，以加强（😏）您的知识。
