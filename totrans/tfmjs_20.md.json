["```py\nimport { AutoTokenizer } from '@xenova/transformers';\n\nconst tokenizer = await AutoTokenizer.from_pretrained('Xenova/bert-base-uncased');\nconst { input_ids } = await tokenizer('I love transformers!');\n// Tensor {\n//   data: BigInt64Array(6) [101n, 1045n, 2293n, 19081n, 999n, 102n],\n//   dims: [1, 6],\n//   type: 'int64',\n//   size: 6,\n// }\n```", "```py\nimport { AutoTokenizer } from \"@xenova/transformers\";\n\nconst tokenizer = await AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\");\n\nconst chat = [\n  { \"role\": \"user\", \"content\": \"Hello, how are you?\" },\n  { \"role\": \"assistant\", \"content\": \"I'm doing great. How can I help you today?\" },\n  { \"role\": \"user\", \"content\": \"I'd like to show off how chat templating works!\" },\n]\n\nconst text = tokenizer.apply_chat_template(chat, { tokenize: false });\n// \"<s>[INST] Hello, how are you? [/INST]I'm doing great. How can I help you today?</s> [INST] I'd like to show off how chat templating works! [/INST]\"\n\nconst input_ids = tokenizer.apply_chat_template(chat, { tokenize: true, return_tensor: false });\n// [1, 733, 16289, 28793, 22557, 28725, 910, 460, 368, 28804, 733, 28748, 16289, 28793, 28737, 28742, 28719, 2548, 1598, 28723, 1602, 541, 315, 1316, 368, 3154, 28804, 2, 28705, 733, 16289, 28793, 315, 28742, 28715, 737, 298, 1347, 805, 910, 10706, 5752, 1077, 3791, 28808, 733, 28748, 16289, 28793]\n```", "```py\n// instantiate the tokenizer and set the prefix token to Spanish\nconst tokenizer = await WhisperTokenizer.from_pretrained('Xenova/whisper-tiny');\nconst forced_decoder_ids = tokenizer.get_decoder_prompt_ids({ language: 'spanish' });\n// [(1, 50262), (2, 50363)]\n```"]