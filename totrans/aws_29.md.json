["```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForFeatureExtraction\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/all-MiniLM-L6-v2-neuronx\")\n>>> model = NeuronModelForFeatureExtraction.from_pretrained(\"optimum/all-MiniLM-L6-v2-neuronx\")\n\n>>> inputs = tokenizer(\"Dear Evan Hansen is the winner of six Tony Awards.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> last_hidden_state = outputs.last_hidden_state\n>>> list(last_hidden_state.shape)\n[1, 13, 384]\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForSentenceTransformers\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/bge-base-en-v1.5-neuronx\")\n>>> model = NeuronModelForSentenceTransformers.from_pretrained(\"optimum/bge-base-en-v1.5-neuronx\")\n\n>>> inputs = tokenizer(\"In the smouldering promise of the fall of Troy, a mythical world of gods and mortals rises from the ashes.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> token_embeddings = outputs.token_embeddings\n>>> sentence_embedding = = outputs.sentence_embedding\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForMaskedLM\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/legal-bert-base-uncased-neuronx\")\n>>> model = NeuronModelForMaskedLM.from_pretrained(\"optimum/legal-bert-base-uncased-neuronx\")\n\n>>> inputs = tokenizer(\"This [MASK] Agreement is between General Motors and John Murray.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> logits = outputs.logits\n>>> list(logits.shape)\n[1, 13, 30522]\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForSequenceClassification\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/distilbert-base-uncased-finetuned-sst-2-english-neuronx\")\n>>> model = NeuronModelForSequenceClassification.from_pretrained(\"optimum/distilbert-base-uncased-finetuned-sst-2-english-neuronx\")\n\n>>> inputs = tokenizer(\"Hamilton is considered to be the best musical of human history.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> logits = outputs.logits\n>>> list(logits.shape)\n[1, 2]\n```", "```py\n>>> import torch\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForQuestionAnswering\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/roberta-base-squad2-neuronx\")\n>>> model = NeuronModelForQuestionAnswering.from_pretrained(\"optimum/roberta-base-squad2-neuronx\")\n\n>>> question, text = \"Are there wheelchair spaces in the theatres?\", \"Yes, we have reserved wheelchair spaces with a good view.\"\n>>> inputs = tokenizer(question, text, return_tensors=\"pt\")\n>>> start_positions = torch.tensor([1])\n>>> end_positions = torch.tensor([12])\n\n>>> outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n>>> start_scores = outputs.start_logits\n>>> end_scores = outputs.end_logits\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForTokenClassification\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/bert-base-NER-neuronx\")\n>>> model = NeuronModelForTokenClassification.from_pretrained(\"optimum/bert-base-NER-neuronx\")\n\n>>> inputs = tokenizer(\"Lin-Manuel Miranda is an American songwriter, actor, singer, filmmaker, and playwright.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> logits = outputs.logits\n>>> list(logits.shape)\n[1, 20, 9]\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForMultipleChoice\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/bert-base-uncased_SWAG-neuronx\")\n>>> model = NeuronModelForMultipleChoice.from_pretrained(\"optimum/bert-base-uncased_SWAG-neuronx\", export=True)\n\n>>> num_choices = 4\n>>> first_sentence = [\"Members of the procession walk down the street holding small horn brass instruments.\"] * num_choices\n>>> second_sentence = [\n...     \"A drum line passes by walking down the street playing their instruments.\",\n...     \"A drum line has heard approaching them.\",\n...     \"A drum line arrives and they're outside dancing and asleep.\",\n...     \"A drum line turns the lead singer watches the performance.\"\n... ]\n>>> inputs = tokenizer(first_sentence, second_sentence, truncation=True, padding=True)\n\n# Unflatten the inputs values expanding it to the shape [batch_size, num_choices, seq_length]\n>>> for k, v in inputs.items():\n...     inputs[k] = [v[i: i + num_choices] for i in range(0, len(v), num_choices)]\n>>> inputs = dict(inputs.convert_to_tensors(tensor_type=\"pt\"))\n>>> outputs = model(**inputs)\n>>> logits = outputs.logits\n>>> logits.shape\n[1, 4]\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForCausalLM\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n>>> model = NeuronModelForCausalLM.from_pretrained(\"gpt2\", export=True)\n\n>>> inputs = tokenizer(\"My favorite moment of the day is\", return_tensors=\"pt\")\n\n>>> gen_tokens = model.generate(**inputs, do_sample=True, temperature=0.9, min_length=20, max_length=20)\n>>> tokenizer.batch_decode(gen_tokens)\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionPipeline\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 512, \"width\": 512}\n\n>>> stable_diffusion = NeuronStableDiffusionPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\", export=True, **compiler_args, **input_shapes\n... )\n>>> stable_diffusion.save_pretrained(\"sd_neuron/\")\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> image = stable_diffusion(prompt).images[0]\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionImg2ImgPipeline\n>>> from diffusers.utils import load_image\n\n>>> url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n>>> init_image = load_image(url).convert(\"RGB\")\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 512, \"width\": 512}\n>>> pipeline = NeuronStableDiffusionImg2ImgPipeline.from_pretrained(\n...     \"nitrosocke/Ghibli-Diffusion\", export=True, **compiler_args, **input_shapes,\n... )\n>>> pipeline.save_pretrained(\"sd_img2img/\")\n\n>>> prompt = \"ghibli style, a fantasy landscape with snowcapped mountains, trees, lake with detailed reflection.\"\n>>> image = pipeline(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images[0]\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionInpaintPipeline\n>>> from diffusers.utils import load_image\n\n>>> img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n>>> mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n\n>>> init_image = load_image(img_url).convert(\"RGB\")\n>>> mask_image = load_image(mask_url).convert(\"RGB\")\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 1024, \"width\": 1024}\n>>> pipeline = NeuronStableDiffusionInpaintPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-inpainting\", export=True, **compiler_args, **input_shapes,\n... )\n>>> pipeline.save_pretrained(\"sd_inpaint/\")\n\n>>> prompt = \"Face of a yellow cat, high resolution, sitting on a park bench\"\n>>> image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionXLPipeline\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 1024, \"width\": 1024}\n\n>>> stable_diffusion_xl = NeuronStableDiffusionXLPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-xl-base-1.0\", export=True, **compiler_args, **input_shapes)\n... )\n>>> stable_diffusion_xl.save_pretrained(\"sd_neuron_xl/\")\n\n>>> prompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n>>> image = stable_diffusion_xl(prompt).images[0]\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionXLImg2ImgPipeline\n>>> from diffusers.utils import load_image\n\n>>> url = \"https://huggingface.co/datasets/optimum/documentation-images/resolve/main/intel/openvino/sd_xl/castle_friedrich.png\"\n>>> init_image = load_image(url).convert(\"RGB\")\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 512, \"width\": 512}\n>>> pipeline = NeuronStableDiffusionXLImg2ImgPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-xl-base-1.0\", export=True, **compiler_args, **input_shapes,\n... )\n>>> pipeline.save_pretrained(\"sdxl_img2img/\")\n\n>>> prompt = \"a dog running, lake, moat\"\n>>> image = pipeline(prompt=prompt, image=init_image).images[0]\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionXLInpaintPipeline\n>>> from diffusers.utils import load_image\n\n>>> img_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png\" (\n>>> mask_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-inpaint-mask.png\"\n\n>>> init_image = load_image(img_url).convert(\"RGB\")\n>>> mask_image = load_image(mask_url).convert(\"RGB\")\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 1024, \"width\": 1024}\n>>> pipeline = NeuronStableDiffusionXLInpaintPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-xl-base-1.0\", export=True, **compiler_args, **input_shapes,\n... )\n>>> pipeline.save_pretrained(\"sdxl_inpaint/\")\n\n>>> prompt = \"A deep sea diver floating\"\n>>> image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.85, guidance_scale=12.5).images[0]\n```"]