["```py\n( model: ScriptModule config: PretrainedConfig model_save_dir: Union = None model_file_name: Optional = None preprocessors: Optional = None neuron_config: Optional = None **kwargs )\n```", "```py\n( neuron_config: NeuronDefaultConfig )\n```", "```py\n( path: Union )\n```", "```py\n( outputs: List dims: List indices: List padding_side: Literal = 'right' )\n```", "```py\n( config: PretrainedConfig checkpoint_dir: Union compiled_dir: Union = None generation_config: Optional = None )\n```", "```py\n( model: ScriptModule config: PretrainedConfig model_save_dir: Union = None model_file_name: Optional = None preprocessors: Optional = None neuron_config: Optional = None **kwargs )\n```", "```py\n( input_ids: Tensor attention_mask: Tensor token_type_ids: Optional = None **kwargs )\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForFeatureExtraction\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/all-MiniLM-L6-v2-neuronx\")\n>>> model = NeuronModelForFeatureExtraction.from_pretrained(\"optimum/all-MiniLM-L6-v2-neuronx\")\n\n>>> inputs = tokenizer(\"Dear Evan Hansen is the winner of six Tony Awards.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> last_hidden_state = outputs.last_hidden_state\n>>> list(last_hidden_state.shape)\n[1, 13, 384]\n```", "```py\n( model: ScriptModule config: PretrainedConfig model_save_dir: Union = None model_file_name: Optional = None preprocessors: Optional = None neuron_config: Optional = None **kwargs )\n```", "```py\n( input_ids: Tensor attention_mask: Tensor token_type_ids: Optional = None **kwargs )\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForSentenceTransformers\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/bge-base-en-v1.5-neuronx\")\n>>> model = NeuronModelForSentenceTransformers.from_pretrained(\"optimum/bge-base-en-v1.5-neuronx\")\n\n>>> inputs = tokenizer(\"In the smouldering promise of the fall of Troy, a mythical world of gods and mortals rises from the ashes.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> token_embeddings = outputs.token_embeddings\n>>> sentence_embedding = = outputs.sentence_embedding\n```", "```py\n( model: ScriptModule config: PretrainedConfig model_save_dir: Union = None model_file_name: Optional = None preprocessors: Optional = None neuron_config: Optional = None **kwargs )\n```", "```py\n( input_ids: Tensor attention_mask: Tensor token_type_ids: Optional = None **kwargs )\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForMaskedLM\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/legal-bert-base-uncased-neuronx\")\n>>> model = NeuronModelForMaskedLM.from_pretrained(\"optimum/legal-bert-base-uncased-neuronx\")\n\n>>> inputs = tokenizer(\"This [MASK] Agreement is between General Motors and John Murray.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> logits = outputs.logits\n>>> list(logits.shape)\n[1, 13, 30522]\n```", "```py\n( model: ScriptModule config: PretrainedConfig model_save_dir: Union = None model_file_name: Optional = None preprocessors: Optional = None neuron_config: Optional = None **kwargs )\n```", "```py\n( input_ids: Tensor attention_mask: Tensor token_type_ids: Optional = None **kwargs )\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForSequenceClassification\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/distilbert-base-uncased-finetuned-sst-2-english-neuronx\")\n>>> model = NeuronModelForSequenceClassification.from_pretrained(\"optimum/distilbert-base-uncased-finetuned-sst-2-english-neuronx\")\n\n>>> inputs = tokenizer(\"Hamilton is considered to be the best musical of human history.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> logits = outputs.logits\n>>> list(logits.shape)\n[1, 2]\n```", "```py\n( model: ScriptModule config: PretrainedConfig model_save_dir: Union = None model_file_name: Optional = None preprocessors: Optional = None neuron_config: Optional = None **kwargs )\n```", "```py\n( input_ids: Tensor attention_mask: Tensor token_type_ids: Optional = None **kwargs )\n```", "```py\n>>> import torch\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForQuestionAnswering\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/roberta-base-squad2-neuronx\")\n>>> model = NeuronModelForQuestionAnswering.from_pretrained(\"optimum/roberta-base-squad2-neuronx\")\n\n>>> question, text = \"Are there wheelchair spaces in the theatres?\", \"Yes, we have reserved wheelchair spaces with a good view.\"\n>>> inputs = tokenizer(question, text, return_tensors=\"pt\")\n>>> start_positions = torch.tensor([1])\n>>> end_positions = torch.tensor([12])\n\n>>> outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n>>> start_scores = outputs.start_logits\n>>> end_scores = outputs.end_logits\n```", "```py\n( model: ScriptModule config: PretrainedConfig model_save_dir: Union = None model_file_name: Optional = None preprocessors: Optional = None neuron_config: Optional = None **kwargs )\n```", "```py\n( input_ids: Tensor attention_mask: Tensor token_type_ids: Optional = None **kwargs )\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForTokenClassification\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/bert-base-NER-neuronx\")\n>>> model = NeuronModelForTokenClassification.from_pretrained(\"optimum/bert-base-NER-neuronx\")\n\n>>> inputs = tokenizer(\"Lin-Manuel Miranda is an American songwriter, actor, singer, filmmaker, and playwright.\", return_tensors=\"pt\")\n\n>>> outputs = model(**inputs)\n>>> logits = outputs.logits\n>>> list(logits.shape)\n[1, 20, 9]\n```", "```py\n( model: ScriptModule config: PretrainedConfig model_save_dir: Union = None model_file_name: Optional = None preprocessors: Optional = None neuron_config: Optional = None **kwargs )\n```", "```py\n( input_ids: Tensor attention_mask: Tensor token_type_ids: Optional = None **kwargs )\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForMultipleChoice\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/bert-base-uncased_SWAG-neuronx\")\n>>> model = NeuronModelForMultipleChoice.from_pretrained(\"optimum/bert-base-uncased_SWAG-neuronx\", export=True)\n\n>>> num_choices = 4\n>>> first_sentence = [\"Members of the procession walk down the street holding small horn brass instruments.\"] * num_choices\n>>> second_sentence = [\n...     \"A drum line passes by walking down the street playing their instruments.\",\n...     \"A drum line has heard approaching them.\",\n...     \"A drum line arrives and they're outside dancing and asleep.\",\n...     \"A drum line turns the lead singer watches the performance.\"\n... ]\n>>> inputs = tokenizer(first_sentence, second_sentence, truncation=True, padding=True)\n\n# Unflatten the inputs values expanding it to the shape [batch_size, num_choices, seq_length]\n>>> for k, v in inputs.items():\n...     inputs[k] = [v[i: i + num_choices] for i in range(0, len(v), num_choices)]\n>>> inputs = dict(inputs.convert_to_tensors(tensor_type=\"pt\"))\n>>> outputs = model(**inputs)\n>>> logits = outputs.logits\n>>> logits.shape\n[1, 4]\n```", "```py\n( config: PretrainedConfig checkpoint_dir: Union compiled_dir: Union = None generation_config: Optional = None )\n```", "```py\n( )\n```", "```py\n( input_ids: Tensor cache_ids: Tensor start_ids: Tensor = None return_dict: bool = True )\n```", "```py\n>>> from transformers import AutoTokenizer\n>>> from optimum.neuron import NeuronModelForCausalLM\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n>>> model = NeuronModelForCausalLM.from_pretrained(\"gpt2\", export=True)\n\n>>> inputs = tokenizer(\"My favorite moment of the day is\", return_tensors=\"pt\")\n\n>>> gen_tokens = model.generate(**inputs, do_sample=True, temperature=0.9, min_length=20, max_length=20)\n>>> tokenizer.batch_decode(gen_tokens)\n```", "```py\n( input_ids: Tensor attention_mask: Optional = None generation_config: Optional = None stopping_criteria: Optional = None **kwargs ) \u2192 export const metadata = 'undefined';torch.Tensor\n```", "```py\n( input_ids: LongTensor selector: TokenSelector batch_size: int attention_mask: Optional = None **model_kwargs ) \u2192 export const metadata = 'undefined';torch.LongTensor\n```", "```py\n( text_encoder: ScriptModule unet: ScriptModule vae_decoder: Union config: Dict tokenizer: CLIPTokenizer scheduler: Union data_parallel_mode: str vae_encoder: Union = None text_encoder_2: Union = None tokenizer_2: Optional = None feature_extractor: Optional = None configs: Optional = None neuron_configs: Optional = None model_save_dir: Union = None model_and_config_save_paths: Optional = None )\n```", "```py\n( data_parallel_mode: Optional text_encoder_path: Union unet_path: Union vae_decoder_path: Union = None vae_encoder_path: Union = None text_encoder_2_path: Union = None dynamic_batch_size: bool = False )\n```", "```py\n( text_encoder: ScriptModule unet: ScriptModule vae_decoder: Union config: Dict tokenizer: CLIPTokenizer scheduler: Union data_parallel_mode: str vae_encoder: Union = None text_encoder_2: Union = None tokenizer_2: Optional = None feature_extractor: Optional = None configs: Optional = None neuron_configs: Optional = None model_save_dir: Union = None model_and_config_save_paths: Optional = None )\n```", "```py\n( prompt: Union = None num_inference_steps: int = 50 guidance_scale: float = 7.5 negative_prompt: Union = None num_images_per_prompt: int = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None guidance_rescale: float = 0.0 ) \u2192 export const metadata = 'undefined';diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput or tuple\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionPipeline\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 512, \"width\": 512}\n\n>>> stable_diffusion = NeuronStableDiffusionPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\", export=True, **compiler_args, **input_shapes\n... )\n>>> stable_diffusion.save_pretrained(\"sd_neuron/\")\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> image = stable_diffusion(prompt).images[0]\n```", "```py\n( text_encoder: ScriptModule unet: ScriptModule vae_decoder: Union config: Dict tokenizer: CLIPTokenizer scheduler: Union data_parallel_mode: str vae_encoder: Union = None text_encoder_2: Union = None tokenizer_2: Optional = None feature_extractor: Optional = None configs: Optional = None neuron_configs: Optional = None model_save_dir: Union = None model_and_config_save_paths: Optional = None )\n```", "```py\n( prompt: Union = None image: Optional = None strength: float = 0.8 num_inference_steps: int = 50 guidance_scale: float = 7.5 negative_prompt: Union = None num_images_per_prompt: int = 1 eta: float = 0.0 generator: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: str = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None ) \u2192 export const metadata = 'undefined';diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput or tuple\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionImg2ImgPipeline\n>>> from diffusers.utils import load_image\n\n>>> url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n>>> init_image = load_image(url).convert(\"RGB\")\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 512, \"width\": 512}\n>>> pipeline = NeuronStableDiffusionImg2ImgPipeline.from_pretrained(\n...     \"nitrosocke/Ghibli-Diffusion\", export=True, **compiler_args, **input_shapes,\n... )\n>>> pipeline.save_pretrained(\"sd_img2img/\")\n\n>>> prompt = \"ghibli style, a fantasy landscape with snowcapped mountains, trees, lake with detailed reflection.\"\n>>> image = pipeline(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images[0]\n```", "```py\n( text_encoder: ScriptModule unet: ScriptModule vae_decoder: Union config: Dict tokenizer: CLIPTokenizer scheduler: Union data_parallel_mode: str vae_encoder: Union = None text_encoder_2: Union = None tokenizer_2: Optional = None feature_extractor: Optional = None configs: Optional = None neuron_configs: Optional = None model_save_dir: Union = None model_and_config_save_paths: Optional = None )\n```", "```py\n( prompt: Union = None image: Optional = None mask_image: Optional = None masked_image_latents: Optional = None strength: float = 1.0 num_inference_steps: int = 50 guidance_scale: float = 7.5 negative_prompt: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None clip_skip: int = None ) \u2192 export const metadata = 'undefined';diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput or tuple\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionInpaintPipeline\n>>> from diffusers.utils import load_image\n\n>>> img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n>>> mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n\n>>> init_image = load_image(img_url).convert(\"RGB\")\n>>> mask_image = load_image(mask_url).convert(\"RGB\")\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 1024, \"width\": 1024}\n>>> pipeline = NeuronStableDiffusionInpaintPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-inpainting\", export=True, **compiler_args, **input_shapes,\n... )\n>>> pipeline.save_pretrained(\"sd_inpaint/\")\n\n>>> prompt = \"Face of a yellow cat, high resolution, sitting on a park bench\"\n>>> image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]\n```", "```py\n( text_encoder: ScriptModule unet: ScriptModule vae_decoder: Union config: Dict tokenizer: CLIPTokenizer scheduler: Union data_parallel_mode: str vae_encoder: Union = None text_encoder_2: Union = None tokenizer_2: Optional = None feature_extractor: Optional = None configs: Optional = None neuron_configs: Optional = None model_save_dir: Union = None model_and_config_save_paths: Optional = None )\n```", "```py\n( prompt: Union = None num_inference_steps: int = 50 original_inference_steps: Optional = None guidance_scale: float = 8.5 num_images_per_prompt: int = 1 generator: Union = None latents: Optional = None prompt_embeds: Optional = None output_type: str = 'pil' return_dict: bool = True cross_attention_kwargs: Optional = None clip_skip: Optional = None callback_on_step_end: Optional = None callback_on_step_end_tensor_inputs: List = ['latents'] ) \u2192 export const metadata = 'undefined';diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput or tuple\n```", "```py\n( text_encoder: ScriptModule unet: ScriptModule vae_decoder: ScriptModule config: Dict tokenizer: CLIPTokenizer scheduler: Union data_parallel_mode: str vae_encoder: Optional = None text_encoder_2: Optional = None tokenizer_2: Optional = None feature_extractor: Optional = None configs: Optional = None neuron_configs: Optional = None model_save_dir: Union = None model_and_config_save_paths: Optional = None add_watermarker: Optional = None )\n```", "```py\n( prompt: Union = None prompt_2: Union = None num_inference_steps: int = 50 denoising_end: Optional = None guidance_scale: float = 5.0 negative_prompt: Union = None negative_prompt_2: Union = None num_images_per_prompt: int = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None pooled_prompt_embeds: Optional = None negative_pooled_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None guidance_rescale: float = 0.0 original_size: Optional = None crops_coords_top_left: Tuple = (0, 0) target_size: Optional = None negative_original_size: Optional = None negative_crops_coords_top_left: Tuple = (0, 0) negative_target_size: Optional = None clip_skip: Optional = None ) \u2192 export const metadata = 'undefined';diffusers.pipelines.stable_diffusion_xl.StableDiffusionXLPipelineOutput or tuple\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionXLPipeline\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 1024, \"width\": 1024}\n\n>>> stable_diffusion_xl = NeuronStableDiffusionXLPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-xl-base-1.0\", export=True, **compiler_args, **input_shapes)\n... )\n>>> stable_diffusion_xl.save_pretrained(\"sd_neuron_xl/\")\n\n>>> prompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n>>> image = stable_diffusion_xl(prompt).images[0]\n```", "```py\n( text_encoder: ScriptModule unet: ScriptModule vae_decoder: ScriptModule config: Dict tokenizer: CLIPTokenizer scheduler: Union data_parallel_mode: str vae_encoder: Optional = None text_encoder_2: Optional = None tokenizer_2: Optional = None feature_extractor: Optional = None configs: Optional = None neuron_configs: Optional = None model_save_dir: Union = None model_and_config_save_paths: Optional = None add_watermarker: Optional = None )\n```", "```py\n( prompt: Union = None prompt_2: Union = None image: Optional = None strength: float = 0.3 num_inference_steps: int = 50 denoising_start: Optional = None denoising_end: Optional = None guidance_scale: float = 5.0 negative_prompt: Union = None negative_prompt_2: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None pooled_prompt_embeds: Optional = None negative_pooled_prompt_embeds: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback: Optional = None callback_steps: int = 1 cross_attention_kwargs: Optional = None guidance_rescale: float = 0.0 original_size: Tuple = None crops_coords_top_left: Tuple = (0, 0) target_size: Tuple = None negative_original_size: Optional = None negative_crops_coords_top_left: Tuple = (0, 0) negative_target_size: Optional = None aesthetic_score: float = 6.0 negative_aesthetic_score: float = 2.5 clip_skip: Optional = None ) \u2192 export const metadata = 'undefined';diffusers.pipelines.stable_diffusion.StableDiffusionXLPipelineOutput or tuple\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionXLImg2ImgPipeline\n>>> from diffusers.utils import load_image\n\n>>> url = \"https://huggingface.co/datasets/optimum/documentation-images/resolve/main/intel/openvino/sd_xl/castle_friedrich.png\"\n>>> init_image = load_image(url).convert(\"RGB\")\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 512, \"width\": 512}\n>>> pipeline = NeuronStableDiffusionXLImg2ImgPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-xl-base-1.0\", export=True, **compiler_args, **input_shapes,\n... )\n>>> pipeline.save_pretrained(\"sdxl_img2img/\")\n\n>>> prompt = \"a dog running, lake, moat\"\n>>> image = pipeline(prompt=prompt, image=init_image).images[0]\n```", "```py\n( text_encoder: ScriptModule unet: ScriptModule vae_decoder: ScriptModule config: Dict tokenizer: CLIPTokenizer scheduler: Union data_parallel_mode: str vae_encoder: Optional = None text_encoder_2: Optional = None tokenizer_2: Optional = None feature_extractor: Optional = None configs: Optional = None neuron_configs: Optional = None model_save_dir: Union = None model_and_config_save_paths: Optional = None add_watermarker: Optional = None )\n```", "```py\n( prompt: Union = None prompt_2: Union = None image: Optional = None mask_image: Optional = None masked_image_latents: Optional = None padding_mask_crop: Optional = None strength: float = 0.9999 num_inference_steps: int = 50 timesteps: Optional = None denoising_start: Optional = None denoising_end: Optional = None guidance_scale: float = 7.5 negative_prompt: Union = None negative_prompt_2: Union = None num_images_per_prompt: Optional = 1 eta: float = 0.0 generator: Union = None latents: Optional = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None pooled_prompt_embeds: Optional = None negative_pooled_prompt_embeds: Optional = None ip_adapter_image: Union = None output_type: Optional = 'pil' return_dict: bool = True cross_attention_kwargs: Optional = None guidance_rescale: float = 0.0 original_size: Tuple = None crops_coords_top_left: Tuple = (0, 0) target_size: Tuple = None negative_original_size: Optional = None negative_crops_coords_top_left: Tuple = (0, 0) negative_target_size: Optional = None aesthetic_score: float = 6.0 negative_aesthetic_score: float = 2.5 clip_skip: Optional = None callback_on_step_end: Optional = None callback_on_step_end_tensor_inputs: List = ['latents'] **kwargs ) \u2192 export const metadata = 'undefined';diffusers.pipelines.stable_diffusion.StableDiffusionXLPipelineOutput or tuple\n```", "```py\n>>> from optimum.neuron import NeuronStableDiffusionXLInpaintPipeline\n>>> from diffusers.utils import load_image\n\n>>> img_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png\" (\n>>> mask_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-inpaint-mask.png\"\n\n>>> init_image = load_image(img_url).convert(\"RGB\")\n>>> mask_image = load_image(mask_url).convert(\"RGB\")\n\n>>> compiler_args = {\"auto_cast\": \"matmul\", \"auto_cast_type\": \"bf16\"}\n>>> input_shapes = {\"batch_size\": 1, \"height\": 1024, \"width\": 1024}\n>>> pipeline = NeuronStableDiffusionXLInpaintPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-xl-base-1.0\", export=True, **compiler_args, **input_shapes,\n... )\n>>> pipeline.save_pretrained(\"sdxl_inpaint/\")\n\n>>> prompt = \"A deep sea diver floating\"\n>>> image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.85, guidance_scale=12.5).images[0]\n```"]