["```py\nimport torch\nfrom diffusers import DiffusionPipeline\nfrom diffusers.utils import export_to_video\n\npipe = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16, variant=\"fp16\")\npipe = pipe.to(\"cuda\")\n\nprompt = \"Spiderman is surfing\"\nvideo_frames = pipe(prompt).frames\nvideo_path = export_to_video(video_frames)\nvideo_path\n```", "```py\nimport torch\nfrom diffusers import DiffusionPipeline\nfrom diffusers.utils import export_to_video\n\npipe = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16, variant=\"fp16\")\npipe.enable_model_cpu_offload()\n\n# memory optimization\npipe.enable_vae_slicing()\n\nprompt = \"Darth Vader surfing a wave\"\nvideo_frames = pipe(prompt, num_frames=64).frames\nvideo_path = export_to_video(video_frames)\nvideo_path\n```", "```py\nimport torch\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nfrom diffusers.utils import export_to_video\n\npipe = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16, variant=\"fp16\")\npipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\npipe.enable_model_cpu_offload()\n\nprompt = \"Spiderman is surfing\"\nvideo_frames = pipe(prompt, num_inference_steps=25).frames\nvideo_path = export_to_video(video_frames)\nvideo_path\n```", "```py\nimport torch\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nfrom diffusers.utils import export_to_video\nfrom PIL import Image\n\npipe = DiffusionPipeline.from_pretrained(\"cerspense/zeroscope_v2_576w\", torch_dtype=torch.float16)\npipe.enable_model_cpu_offload()\n\n# memory optimization\npipe.unet.enable_forward_chunking(chunk_size=1, dim=1)\npipe.enable_vae_slicing()\n\nprompt = \"Darth Vader surfing a wave\"\nvideo_frames = pipe(prompt, num_frames=24).frames\nvideo_path = export_to_video(video_frames)\nvideo_path\n```", "```py\npipe = DiffusionPipeline.from_pretrained(\"cerspense/zeroscope_v2_XL\", torch_dtype=torch.float16)\npipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\npipe.enable_model_cpu_offload()\n\n# memory optimization\npipe.unet.enable_forward_chunking(chunk_size=1, dim=1)\npipe.enable_vae_slicing()\n\nvideo = [Image.fromarray(frame).resize((1024, 576)) for frame in video_frames]\n\nvideo_frames = pipe(prompt, video=video, strength=0.6).frames\nvideo_path = export_to_video(video_frames)\nvideo_path\n```", "```py\n>>> import torch\n>>> from diffusers import TextToVideoSDPipeline\n>>> from diffusers.utils import export_to_video\n\n>>> pipe = TextToVideoSDPipeline.from_pretrained(\n...     \"damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16, variant=\"fp16\"\n... )\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = \"Spiderman is surfing\"\n>>> video_frames = pipe(prompt).frames\n>>> video_path = export_to_video(video_frames)\n>>> video_path\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n>>> from diffusers.utils import export_to_video\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"cerspense/zeroscope_v2_576w\", torch_dtype=torch.float16)\n>>> pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n>>> pipe.to(\"cuda\")\n\n>>> prompt = \"spiderman running in the desert\"\n>>> video_frames = pipe(prompt, num_inference_steps=40, height=320, width=576, num_frames=24).frames\n>>> # safe low-res video\n>>> video_path = export_to_video(video_frames, output_video_path=\"./video_576_spiderman.mp4\")\n\n>>> # let's offload the text-to-image model\n>>> pipe.to(\"cpu\")\n\n>>> # and load the image-to-image model\n>>> pipe = DiffusionPipeline.from_pretrained(\n...     \"cerspense/zeroscope_v2_XL\", torch_dtype=torch.float16, revision=\"refs/pr/15\"\n... )\n>>> pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n>>> pipe.enable_model_cpu_offload()\n\n>>> # The VAE consumes A LOT of memory, let's make sure we run it in sliced mode\n>>> pipe.vae.enable_slicing()\n\n>>> # now let's upscale it\n>>> video = [Image.fromarray(frame).resize((1024, 576)) for frame in video_frames]\n\n>>> # and denoise it\n>>> video_frames = pipe(prompt, video=video, strength=0.6).frames\n>>> video_path = export_to_video(video_frames, output_video_path=\"./video_1024_spiderman.mp4\")\n>>> video_path\n```"]