# 梯度同步

> 原文链接：[`huggingface.co/docs/accelerate/concept_guides/gradient_synchronization`](https://huggingface.co/docs/accelerate/concept_guides/gradient_synchronization)

PyTorch 的分布式模块通过在系统中的所有 GPU 之间来回通信来运行。这种通信需要时间，并且确保所有进程在使用`ddp`模块时在特定触发点知道彼此的状态。

这些触发点被添加到 PyTorch 模型中，特别是它们的`forward()`和`backward()`方法。当模型被包装为`DistributedDataParallel`时会发生这种情况：

```py
import torch.nn as nn
from torch.nn.parallel import DistributedDataParallel

model = nn.Linear(10, 10)
ddp_model = DistributedDataParallel(model)
```

在🤗 Accelerate 中，当调用 prepare()并传入您的模型时，此转换会自动发生。

```py
+ from accelerate import Accelerator
+ accelerator = Accelerator()
  import torch.nn as nn
- from torch.nn.parallel import DistributedDataParallel

  model = nn.Linear(10,10)
+ model = accelerator.prepare(model)
```

## 梯度累积中的减速

您现在了解到，在分布式设置中训练时，PyTorch 会向您的 PyTorch 模型的`forward`和`backward`方法添加钩子。但是这如何会导致您的代码减速呢？

在 DDP（分布式数据并行）中，执行和运行进程的特定顺序预期在特定点发生，并且在继续之前必须大致同时发生。

最直接的例子是当您通过`optimizer.step()`更新模型参数时。没有梯度累积，所有模型实例需要在继续下一个数据批次之前更新它们的梯度计算、整合和更新。进行梯度累积时，您累积`n`个损失梯度，并在达到`n`个批次之前跳过`optimizer.step()`。由于所有训练过程只需要在调用`optimizer.step()`时同步，而不需要对训练步骤进行任何修改，这种不必要的进程间通信可能会导致显著的减速。

如何避免这种开销？

## 解决减速问题

由于在这些批次上训练时跳过模型参数更新，它们的梯度不需要在实际调用`optimizer.step()`时同步。PyTorch 无法自动判断何时需要执行此操作，但他们提供了一个工具来帮助，通过在将模型转换为 DDP 后添加到您的模型的[`no_sync`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.no_sync)上下文管理器。

在这个上下文管理器下，当调用`.backward()`时，PyTorch 将跳过同步梯度，并且在此上下文管理器之外第一次调用`.backward()`时将触发同步。请参见下面的示例：

```py
ddp_model, dataloader, optimizer = accelerator.prepare(model, dataloader, optimizer)

for index, batch in enumerate(dataloader):
    inputs, targets = batch
    # Trigger gradient synchronization on the last batch
    if index != (len(dataloader) - 1):
        with ddp_model.no_sync():
            # Gradients only accumulate
            outputs = ddp_model(inputs)
            loss = loss_func(outputs)
            accelerator.backward(loss)
    else:
        # Gradients finally sync
        outputs = ddp_model(inputs)
        loss = loss_func(outputs)
        accelerator.backward(loss)
        optimizer.step()
```

在🤗 Accelerate 中，使其成为一个可以调用的 API，无论训练设备如何（尽管如果您不在分布式系统中可能不会执行任何操作！），`ddp_model.no_sync`被替换为 no_sync()，并且操作方式相同：

```py
  ddp_model, dataloader, optimizer = accelerator.prepare(model, dataloader, optimizer)

  for index, batch in enumerate(dataloader):
      inputs, targets = batch
      # Trigger gradient synchronization on the last batch
      if index != (len(dataloader)-1):
-         with ddp_model.no_sync():
+         with accelerator.no_sync(model):
              # Gradients only accumulate
              outputs = ddp_model(inputs)
              loss = loss_func(outputs, targets)
              accelerator.backward(loss)
      else:
          # Gradients finally sync
          outputs = ddp_model(inputs)
          loss = loss_func(outputs)
          accelerator.backward(loss)
          optimizer.step()
          optimizer.zero_grad()
```

正如您所期望的那样，accumulate()函数通过跟踪当前批次号码来包装这个条件检查，使您得到最终的梯度累积 API：

```py
ddp_model, dataloader, optimizer = accelerator.prepare(model, dataloader, optimizer)

for batch in dataloader:
    with accelerator.accumulate(model):
        optimizer.zero_grad()
        inputs, targets = batch
        outputs = model(inputs)
        loss = loss_function(outputs, targets)
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
```

因此，在选择 API 时，您应该使用*`accelerator.accumulate`或`accelerator.no_sync`*。

## 有多少减速，以及您可能犯的简单错误

建立一个现实的例子，考虑以下设置：

+   两个单 GPU T4 节点和一个有两个 GPU 的节点

+   每个 GPU 都是 T4，并且托管在 GCP 上

+   使用的脚本是[NLP 示例](https://github.com/muellerzr/timing_experiments/blob/main/baseline.py)脚本的修改

+   每个 GPU 的批量大小为 16，并且每 4 步累积梯度。

所有脚本都在[此存储库](https://github.com/muellerzr/timing_experiments)中可用。

如果不注意梯度同步和 GPU 通信，那么这些 GPU 在不必要的时期进行通信时会浪费大量时间。

多少？

参考：

+   基线：不使用此处讨论的任何同步实践

+   `no_sync`不正确：`no_sync`仅在`backward`调用周围，而不是`forward`

+   `no_sync`: 正确使用`no_sync`模式

+   `accumulate`: 使用 accumulate()正确地

以下是在单节点和双节点设置上迭代 29 批数据的平均秒数，对比每种设置：

|  | 基线 | `no_sync`不正确 | `no_sync` | `accumulate` |
| :-: | :-: | :-: | :-: | :-: |
| 多节点 | 2±0.01 秒 | 2.13±0.08 秒 | **0.91±0.11 秒** | **0.91±0.11 秒** |
| 单节点 | 0.50±0.01 秒 | 0.50±0.01 秒 | **0.41±0.015 秒** | **0.41±0.015 秒** |

正如您所看到的，如果不注意如何设置梯度同步，训练期间可能会出现超过 2 倍的减速！

如果您担心确保一切都做得正确，我们强烈建议利用 accumulate()函数，并向 Accelerator 对象传递`gradient_accumulation_steps`或`gradient_accumulation_plugin`，以便 Accelerate 可以为您处理这些。
