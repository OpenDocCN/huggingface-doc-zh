["```py\nimport torch\nfrom diffusers import DiffusionPipeline\n\npipeline = DiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16\n).to(\"cuda\")\npipeline.load_lora_weights(\n    \"peft-internal-testing/artificialguybr__3DRedmond-V1\", \n    weight_name=\"3DRedmond-3DRenderStyle-3DRenderAF.safetensors\", \n    adapter_name=\"3d\"\n)\nimage = pipeline(\"sushi rolls shaped like kawaii cat faces\").images[0]\nimage\n```", "```py\npipeline.load_lora_weights(\n    \"ostris/super-cereal-sdxl-lora\", \n    weight_name=\"cereal_box_sdxl_v1.safetensors\", \n    adapter_name=\"cereal\"\n)\npipeline.set_adapters(\"cereal\")\nimage = pipeline(\"sushi rolls shaped like kawaii cat faces\").images[0]\nimage\n```", "```py\npipeline.disable_lora()\n```", "```py\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n```", "```py\nfrom peft import LoraConfig\n\nconfig = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\nmodel.add_adapter(peft_config)\n```", "```py\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"ybelkada/opt-350m-lora\")\n```", "```py\nfrom transformers import AutoModelForCausalLM\nfrom peft import LoraConfig\n\nmodel = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\nmodel.add_adapter(lora_config_1, adapter_name=\"adapter_1\")\n```", "```py\nmodel.add_adapter(lora_config_2, adapter_name=\"adapter_2\")\n```", "```py\nmodel.set_adapter(\"adapter_1\")\noutput = model.generate(**inputs)\nprint(tokenizer.decode(output_disabled[0], skip_special_tokens=True))\n```", "```py\nmodel.disable_adapter()\n```"]