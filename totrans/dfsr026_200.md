# KDPM2AncestralDiscreteScheduler

> 原始文本：[https://huggingface.co/docs/diffusers/api/schedulers/dpm_discrete_ancestral](https://huggingface.co/docs/diffusers/api/schedulers/dpm_discrete_ancestral)

具有祖先采样的`KDPM2DiscreteScheduler`受到[Elucidating the Design Space of Diffusion-Based Generative Models](https://huggingface.co/papers/2206.00364)论文的启发，调度器从[Katherine Crowson](https://github.com/crowsonkb/)那里移植并创建。

原始代码库可在[crowsonkb/k-diffusion](https://github.com/crowsonkb/k-diffusion)找到。

## KDPM2AncestralDiscreteScheduler

### `class diffusers.KDPM2AncestralDiscreteScheduler`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_k_dpm_2_ancestral_discrete.py#L72)

```py
( num_train_timesteps: int = 1000 beta_start: float = 0.00085 beta_end: float = 0.012 beta_schedule: str = 'linear' trained_betas: Union = None use_karras_sigmas: Optional = False prediction_type: str = 'epsilon' timestep_spacing: str = 'linspace' steps_offset: int = 0 )
```

参数

+   `num_train_timesteps` (`int`, 默认为1000) — 训练模型的扩散步数。

+   `beta_start` (`float`, 默认为0.00085）— 推断的起始`beta`值。

+   `beta_end` (`float`, 默认为0.012) — 最终的`beta`值。

+   `beta_schedule` (`str`, 默认为`"linear"`) — beta计划，从beta范围映射到用于模型步进的beta序列。可选择`linear`或`scaled_linear`。

+   `trained_betas` (`np.ndarray`, *可选*) — 直接传递一个beta数组给构造函数，以绕过`beta_start`和`beta_end`。

+   `use_karras_sigmas` (`bool`, *可选*, 默认为`False`) — 在采样过程中是否使用Karras sigmas来调整噪声计划中的步长。如果为`True`，则根据噪声级别序列{σi}确定sigmas。

+   `prediction_type` (`str`, 默认为`epsilon`, *可选*) — 调度器函数的预测类型；可以是`epsilon`（预测扩散过程的噪声）、`sample`（直接预测带噪样本）或`v_prediction`（参见[Imagen Video](https://imagen.research.google/video/paper.pdf)论文第2.4节）。

+   `timestep_spacing` (`str`, 默认为`"linspace"`) — 时间步应该如何缩放。有关更多信息，请参考[Common Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891)的表2。 

+   `steps_offset` (`int`, 默认为0) — 添加到推断步骤的偏移量。您可以使用`offset=1`和`set_alpha_to_one=False`的组合，使最后一步使用前一个alpha乘积的步骤0，就像在Stable Diffusion中一样。

具有祖先采样的KDPM2DiscreteScheduler受到[Elucidating the Design Space of Diffusion-Based Generative Models](https://huggingface.co/papers/2206.00364)论文中DPMSolver2和Algorithm 2的启发。

该模型继承自[SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)和[ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)。查看超类文档以了解库为所有调度器实现的通用方法，如加载和保存。

#### `scale_model_input`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_k_dpm_2_ancestral_discrete.py#L179)

```py
( sample: FloatTensor timestep: Union ) → export const metadata = 'undefined';torch.FloatTensor
```

参数

+   `sample` (`torch.FloatTensor`) — 输入样本。

+   `timestep` (`int`, *可选*) — 扩散链中的当前时间步。

返回

`torch.FloatTensor`

一个经过缩放的输入样本。

确保与需要根据当前时间步长缩放去噪模型输入的调度器可以互换。

#### `set_timesteps`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_k_dpm_2_ancestral_discrete.py#L209)

```py
( num_inference_steps: int device: Union = None num_train_timesteps: Optional = None )
```

参数

+   `num_inference_steps` (`int`) — 使用预训练模型生成样本时使用的扩散步数。

+   `device` (`str`或`torch.device`, *可选*) — 时间步应移动到的设备。如果为`None`，则不移动时间步。

设置用于扩散链的离散时间步骤（在推理之前运行）。

#### `step`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_k_dpm_2_ancestral_discrete.py#L377)

```py
( model_output: Union timestep: Union sample: Union generator: Optional = None return_dict: bool = True ) → export const metadata = 'undefined';SchedulerOutput or tuple
```

参数

+   `model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出的结果。

+   `timestep` (`float`) — 扩散链中当前的离散时间步。

+   `sample` (`torch.FloatTensor`) — 由扩散过程创建的样本的当前实例。

+   `generator` (`torch.Generator`，*可选的*) — 一个随机数生成器。

+   `return_dict` (`bool`) — 是否返回一个[SchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/dpm_discrete_ancestral#diffusers.schedulers.scheduling_utils.SchedulerOutput)或元组。

返回值

[SchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/dpm_discrete_ancestral#diffusers.schedulers.scheduling_utils.SchedulerOutput)或`tuple`

如果`return_dict`为`True`，则返回`~schedulers.scheduling_ddim.SchedulerOutput`，否则返回一个元组，其中第一个元素是样本张量。

通过反转SDE来预测前一个时间步的样本。此函数从学习模型输出（通常是预测的噪声）中传播扩散过程。

## SchedulerOutput

### `class diffusers.schedulers.scheduling_utils.SchedulerOutput`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_utils.py#L50)

```py
( prev_sample: FloatTensor )
```

参数

+   `prev_sample` (`torch.FloatTensor`，对于图像为形状为`(batch_size, num_channels, height, width)`的张量) — 先前时间步的计算样本`(x_{t-1})`。`prev_sample`应该在去噪循环中作为下一个模型输入使用。

调度器`step`函数输出的基类。
