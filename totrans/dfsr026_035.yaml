- en: Prompt weighting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/using-diffusers/weighted_prompts](https://huggingface.co/docs/diffusers/using-diffusers/weighted_prompts)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Prompt weighting provides a way to emphasize or de-emphasize certain parts of
    a prompt, allowing for more control over the generated image. A prompt can include
    several concepts, which gets turned into contextualized text embeddings. The embeddings
    are used by the model to condition its cross-attention layers to generate an image
    (read the Stable Diffusion [blog post](https://huggingface.co/blog/stable_diffusion)
    to learn more about how it works).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Prompt weighting works by increasing or decreasing the scale of the text embedding
    vector that corresponds to its concept in the prompt because you may not necessarily
    want the model to focus on all concepts equally. The easiest way to prepare the
    prompt-weighted embeddings is to use [Compel](https://github.com/damian0815/compel),
    a text prompt-weighting and blending library. Once you have the prompt-weighted
    embeddings, you can pass them to any pipeline that has a [`prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__.prompt_embeds)
    (and optionally [`negative_prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__.negative_prompt_embeds))
    parameter, such as [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline),
    [StableDiffusionControlNetPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/controlnet#diffusers.StableDiffusionControlNetPipeline),
    and [StableDiffusionXLPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: If your favorite pipeline doesnâ€™t have a `prompt_embeds` parameter, please open
    an [issue](https://github.com/huggingface/diffusers/issues/new/choose) so we can
    add it!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: This guide will show you how to weight and blend your prompts with Compel in
    ğŸ¤— Diffusers.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you begin, make sure you have the latest version of Compel installed:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For this guide, letâ€™s generate an image with the prompt `"a red cat playing
    with a ball"` using the [StableDiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline):'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/24306b5413fb415e890bea8d0fc47df3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
- en: Weighting
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Youâ€™ll notice there is no â€œballâ€ in the image! Letâ€™s use compel to upweight
    the concept of â€œballâ€ in the prompt. Create a [`Compel`](https://github.com/damian0815/compel/blob/main/doc/compel.md#compel-objects)
    object, and pass it a tokenizer and text encoder:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'compel uses `+` or `-` to increase or decrease the weight of a word in the
    prompt. To increase the weight of â€œballâ€:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '`+` corresponds to the value `1.1`, `++` corresponds to `1.1^2`, and so on.
    Similarly, `-` corresponds to `0.9` and `--` corresponds to `0.9^2`. Feel free
    to experiment with adding more `+` or `-` in your prompt!'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Pass the prompt to `compel_proc` to create the new prompt embeddings which
    are passed to the pipeline:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/a6ea0a8316ec0e299ce79bd94f29d7a8.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: 'To downweight parts of the prompt, use the `-` suffix:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/eed909df9ef11a12b97771b8f85ab810.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: 'You can even up or downweight multiple concepts in the same prompt:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/b82d3f52e501e13a58f1b034a7a8f0ad.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: Blending
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also create a weighted *blend* of prompts by adding `.blend()` to a
    list of prompts and passing it some weights. Your blend may not always produce
    the result you expect because it breaks some assumptions about how the text encoder
    functions, so just have fun and experiment with it!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/103f3c5f3fa90b6e9ec2d9e26bbb49cc.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: Conjunction
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A conjunction diffuses each prompt independently and concatenates their results
    by their weighted sum. Add `.and()` to the end of a list of prompts to create
    a conjunction:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªè¿è¯ç‹¬ç«‹åœ°æ‰©æ•£æ¯ä¸ªæç¤ºï¼Œå¹¶é€šè¿‡å®ƒä»¬çš„åŠ æƒå’Œè¿æ¥å®ƒä»¬çš„ç»“æœã€‚åœ¨æç¤ºåˆ—è¡¨çš„æœ«å°¾æ·»åŠ `.and()`ä»¥åˆ›å»ºä¸€ä¸ªè¿è¯ï¼š
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/82df108b16157d244b56b16b408735a0.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82df108b16157d244b56b16b408735a0.png)'
- en: Textual inversion
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ–‡æœ¬åè½¬
- en: '[Textual inversion](../training/text_inversion) is a technique for learning
    a specific concept from some images which you can use to generate new images conditioned
    on that concept.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ–‡æœ¬åè½¬](../training/text_inversion)æ˜¯ä¸€ç§ä»ä¸€äº›å›¾åƒä¸­å­¦ä¹ ç‰¹å®šæ¦‚å¿µçš„æŠ€æœ¯ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒæ¥ç”ŸæˆåŸºäºè¯¥æ¦‚å¿µçš„æ–°å›¾åƒã€‚'
- en: 'Create a pipeline and use the [load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)
    function to load the textual inversion embeddings (feel free to browse the [Stable
    Diffusion Conceptualizer](https://huggingface.co/spaces/sd-concepts-library/stable-diffusion-conceptualizer)
    for 100+ trained concepts):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªç®¡é“ï¼Œå¹¶ä½¿ç”¨[load_textual_inversion()](/docs/diffusers/v0.26.3/en/api/loaders/textual_inversion#diffusers.loaders.TextualInversionLoaderMixin.load_textual_inversion)å‡½æ•°åŠ è½½æ–‡æœ¬åè½¬åµŒå…¥ï¼ˆéšæ—¶æµè§ˆ[ç¨³å®šæ‰©æ•£æ¦‚å¿µåŒ–å™¨](https://huggingface.co/spaces/sd-concepts-library/stable-diffusion-conceptualizer)ä»¥è·å–100å¤šä¸ªè®­ç»ƒæ¦‚å¿µï¼‰ï¼š
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Compel provides a `DiffusersTextualInversionManager` class to simplify prompt
    weighting with textual inversion. Instantiate `DiffusersTextualInversionManager`
    and pass it to the `Compel` class:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Compelæä¾›äº†ä¸€ä¸ª`DiffusersTextualInversionManager`ç±»ï¼Œç”¨äºç®€åŒ–æ–‡æœ¬åè½¬çš„æç¤ºåŠ æƒã€‚å®ä¾‹åŒ–`DiffusersTextualInversionManager`å¹¶å°†å…¶ä¼ é€’ç»™`Compel`ç±»ï¼š
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Incorporate the concept to condition a prompt with using the `<concept>` syntax:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¦‚å¿µåˆå¹¶åˆ°æ¡ä»¶æç¤ºä¸­ï¼Œä½¿ç”¨`<concept>`è¯­æ³•ï¼š
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/018f9f77083d1e4a4a4c59065acae017.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/018f9f77083d1e4a4a4c59065acae017.png)'
- en: DreamBooth
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DreamBooth
- en: '[DreamBooth](../training/dreambooth) is a technique for generating contextualized
    images of a subject given just a few images of the subject to train on. It is
    similar to textual inversion, but DreamBooth trains the full model whereas textual
    inversion only fine-tunes the text embeddings. This means you should use [from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)
    to load the DreamBooth model (feel free to browse the [Stable Diffusion Dreambooth
    Concepts Library](https://huggingface.co/sd-dreambooth-library) for 100+ trained
    models):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[DreamBooth](../training/dreambooth)æ˜¯ä¸€ç§æŠ€æœ¯ï¼Œå¯ä»¥æ ¹æ®å¯¹ä¸»é¢˜çš„å‡ å¼ å›¾åƒç”Ÿæˆä¸»é¢˜åŒ–å›¾åƒï¼Œè€Œæ— éœ€å¯¹ä¸»é¢˜è¿›è¡Œè®­ç»ƒã€‚å®ƒç±»ä¼¼äºæ–‡æœ¬åè½¬ï¼Œä½†DreamBoothè®­ç»ƒå®Œæ•´æ¨¡å‹ï¼Œè€Œæ–‡æœ¬åè½¬åªæ˜¯å¾®è°ƒæ–‡æœ¬åµŒå…¥ã€‚è¿™æ„å‘³ç€æ‚¨åº”è¯¥ä½¿ç”¨[from_pretrained()](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)æ¥åŠ è½½DreamBoothæ¨¡å‹ï¼ˆéšæ—¶æµè§ˆ[ç¨³å®šæ‰©æ•£Dreamboothæ¦‚å¿µåº“](https://huggingface.co/sd-dreambooth-library)ä»¥è·å–100å¤šä¸ªè®­ç»ƒæ¨¡å‹ï¼‰ï¼š'
- en: '[PRE12]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Create a `Compel` class with a tokenizer and text encoder, and pass your prompt
    to it. Depending on the model you use, youâ€™ll need to incorporate the modelâ€™s
    unique identifier into your prompt. For example, the `dndcoverart-v1` model uses
    the identifier `dndcoverart`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªå¸¦æœ‰åˆ†è¯å™¨å’Œæ–‡æœ¬ç¼–ç å™¨çš„`Compel`ç±»ï¼Œå¹¶å°†æ‚¨çš„æç¤ºä¼ é€’ç»™å®ƒã€‚æ ¹æ®æ‚¨ä½¿ç”¨çš„æ¨¡å‹ï¼Œæ‚¨éœ€è¦å°†æ¨¡å‹çš„å”¯ä¸€æ ‡è¯†ç¬¦åˆå¹¶åˆ°æ‚¨çš„æç¤ºä¸­ã€‚ä¾‹å¦‚ï¼Œ`dndcoverart-v1`æ¨¡å‹ä½¿ç”¨æ ‡è¯†ç¬¦`dndcoverart`ï¼š
- en: '[PRE13]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/5b0fd6647d5253e64ddf3beb46283bde.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5b0fd6647d5253e64ddf3beb46283bde.png)'
- en: Stable Diffusion XL
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£XL
- en: 'Stable Diffusion XL (SDXL) has two tokenizers and text encoders so itâ€™s usage
    is a bit different. To address this, you should pass both tokenizers and encoders
    to the `Compel` class:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å®šæ‰©æ•£XLï¼ˆSDXLï¼‰æœ‰ä¸¤ä¸ªåˆ†è¯å™¨å’Œæ–‡æœ¬ç¼–ç å™¨ï¼Œå› æ­¤å®ƒçš„ä½¿ç”¨æ–¹å¼æœ‰ç‚¹ä¸åŒã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ‚¨åº”è¯¥å°†ä¸¤ä¸ªåˆ†è¯å™¨å’Œç¼–ç å™¨éƒ½ä¼ é€’ç»™`Compel`ç±»ï¼š
- en: '[PRE14]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This time, letâ€™s upweight â€œballâ€ by a factor of 1.5 for the first prompt, and
    downweight â€œballâ€ by 0.6 for the second prompt. The [StableDiffusionXLPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline)
    also requires [`pooled_prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline.__call__.pooled_prompt_embeds)
    (and optionally [`negative_pooled_prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline.__call__.negative_pooled_prompt_embeds))
    so you should pass those to the pipeline along with the conditioning tensors:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€æ¬¡ï¼Œè®©æˆ‘ä»¬å°†ç¬¬ä¸€ä¸ªæç¤ºä¸­çš„â€œçƒâ€æƒé‡æé«˜1.5å€ï¼Œå¹¶å°†ç¬¬äºŒä¸ªæç¤ºä¸­çš„â€œçƒâ€æƒé‡é™ä½0.6å€ã€‚[StableDiffusionXLPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline)è¿˜éœ€è¦[`pooled_prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline.__call__.pooled_prompt_embeds)ï¼ˆä»¥åŠå¯é€‰çš„[`negative_pooled_prompt_embeds`](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline.__call__.negative_pooled_prompt_embeds)ï¼‰ï¼Œå› æ­¤æ‚¨åº”è¯¥å°†è¿™äº›ä¼ é€’ç»™ç®¡é“ä»¥åŠæ¡ä»¶å¼ é‡ï¼š
- en: '[PRE15]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/067abbd7c08a8dee4ee6a6f556c86e97.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/067abbd7c08a8dee4ee6a6f556c86e97.png)'
- en: '"a red cat playing with a (ball)1.5"'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€åªçº¢è‰²çš„çŒ«æ­£åœ¨ç©ä¸€ä¸ªï¼ˆçƒï¼‰1.5
- en: '![](../Images/1c14404c57c40fb1d0c84a7c12d4cb5c.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c14404c57c40fb1d0c84a7c12d4cb5c.png)'
- en: '"a red cat playing with a (ball)0.6"'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€åªçº¢è‰²çš„çŒ«æ­£åœ¨ç©ä¸€ä¸ªï¼ˆçƒï¼‰0.6
