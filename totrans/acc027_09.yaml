- en: Launching Multi-GPU Training from a Jupyter Environment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/accelerate/basic_tutorials/notebook](https://huggingface.co/docs/accelerate/basic_tutorials/notebook)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial teaches you how to fine tune a computer vision model with ğŸ¤— Accelerate
    from a Jupyter Notebook on a distributed system. You will also learn how to setup
    a few requirements needed for ensuring your environment is configured properly,
    your data has been prepared properly, and finally how to launch training.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial is also available as a Jupyter Notebook [here](https://github.com/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_cv_example.ipynb)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the Environment
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before any training can be performed, a ğŸ¤— Accelerate config file must exist
    in the system. Usually this can be done by running the following in a terminal
    and answering the prompts:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: However, if general defaults are fine and you are *not* running on a TPU, ğŸ¤—Accelerate
    has a utility to quickly write your GPU configuration into a config file via [utils.write_basic_config()](/docs/accelerate/v0.27.2/en/package_reference/utilities#accelerate.commands.config.default.write_basic_config).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: The following code will restart Jupyter after writing the configuration, as
    CUDA code was called to perform this.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: CUDA canâ€™t be initialized more than once on a multi-GPU system. Itâ€™s fine to
    debug in the notebook and have calls to CUDA, but in order to finally train a
    full cleanup and restart will need to be performed.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Preparing the Dataset and Model
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next you should prepare your dataset. As mentioned at earlier, great care should
    be taken when preparing the `DataLoaders` and model to make sure that **nothing**
    is put on *any* GPU.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: If you do, it is recommended to put that specific code into a function and call
    that from within the notebook launcher interface, which will be shown later.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Make sure the dataset is downloaded based on the directions [here](https://github.com/huggingface/accelerate/tree/main/examples#simple-vision-example)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'First you need to create a function to extract the class name based on a filename:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the case here, the label is `beagle`. Using regex you can extract the label
    from the filename:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And you can see it properly returned the right name for our file:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next a `Dataset` class should be made to handle grabbing the image and the
    label:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now to build the dataset. Outside the training function you can find and declare
    all the filenames and labels and use them as references inside the launched function:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next gather all the labels:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Next, you should make a `get_dataloaders` function that will return your built
    dataloaders for you. As mentioned earlier, if data is automatically sent to the
    GPU or a TPU device when building your `DataLoaders`, they must be built using
    this method.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, you should import the scheduler to be used later:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Writing the Training Function
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now you can build the training loop. [notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)
    works by passing in a function to call that will be ran across the distributed
    system.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a basic training loop for the animal classification problem:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: The code has been split up to allow for explanations on each section. A full
    version that can be copy and pasted will be available at the end
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: First you should set the seed and create an [Accelerator](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator)
    object as early in the training loop as possible.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: If training on the TPU, your training loop should take in the model as a parameter
    and it should be instantiated outside of the training loop function. See the [TPU
    best practices](../concept_guides/training_tpu) to learn why
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'Next you should build your dataloaders and create your model:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You build the model here so that the seed also controls the new weight initialization
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'As you are performing transfer learning in this example, the encoder of the
    model starts out frozen so the head of the model can be trained only initially:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ­¤ç¤ºä¾‹ä¸­è¿›è¡Œè¿ç§»å­¦ä¹ æ—¶ï¼Œæ¨¡å‹çš„ç¼–ç å™¨å¼€å§‹æ—¶æ˜¯å†»ç»“çš„ï¼Œå› æ­¤æ¨¡å‹çš„å¤´éƒ¨åªèƒ½æœ€åˆè¿›è¡Œè®­ç»ƒï¼š
- en: '[PRE15]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Normalizing the batches of images will make training a little faster:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹å›¾åƒæ‰¹æ¬¡è¿›è¡Œå½’ä¸€åŒ–å°†ä½¿è®­ç»ƒé€Ÿåº¦ç¨å¿«ï¼š
- en: '[PRE16]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To make these constants available on the active device, you should set it to
    the Acceleratorâ€™s device:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿è¿™äº›å¸¸é‡åœ¨æ´»åŠ¨è®¾å¤‡ä¸Šå¯ç”¨ï¼Œæ‚¨åº”è¯¥å°†å…¶è®¾ç½®ä¸ºåŠ é€Ÿå™¨çš„è®¾å¤‡ï¼š
- en: '[PRE17]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next instantiate the rest of the PyTorch classes used for training:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥å®ä¾‹åŒ–ç”¨äºè®­ç»ƒçš„å…¶ä½™PyTorchç±»ï¼š
- en: '[PRE18]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Before passing everything to [prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å°†æ‰€æœ‰å†…å®¹ä¼ é€’ç»™[prepare()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.prepare)ä¹‹å‰ã€‚
- en: There is no specific order to remember, you just need to unpack the objects
    in the same order you gave them to the prepare method.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰ç‰¹å®šçš„é¡ºåºéœ€è¦è®°ä½ï¼Œæ‚¨åªéœ€è¦æŒ‰ç…§ä¸prepareæ–¹æ³•ä¸­ç»™å‡ºçš„ç›¸åŒé¡ºåºè§£åŒ…å¯¹è±¡ã€‚
- en: '[PRE19]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now train the model:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®­ç»ƒæ¨¡å‹ï¼š
- en: '[PRE20]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The evaluation loop will look slightly different compared to the training loop.
    The number of elements passed as well as the overall total accuracy of each batch
    will be added to two constants:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¯„ä¼°å¾ªç¯ä¸è®­ç»ƒå¾ªç¯ç›¸æ¯”ä¼šç¨æœ‰ä¸åŒã€‚ä¼ é€’çš„å…ƒç´ æ•°é‡ä»¥åŠæ¯ä¸ªæ‰¹æ¬¡çš„æ€»ä½“å‡†ç¡®ç‡å°†æ·»åŠ åˆ°ä¸¤ä¸ªå¸¸é‡ä¸­ï¼š
- en: '[PRE21]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next you have the rest of your standard PyTorch loop:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥æ˜¯æ‚¨æ ‡å‡†PyTorchå¾ªç¯çš„å…¶ä½™éƒ¨åˆ†ï¼š
- en: '[PRE22]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Before finally the last major difference.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åæ˜¯æœ€åä¸€ä¸ªä¸»è¦åŒºåˆ«ã€‚
- en: 'When performing distributed evaluation, the predictions and labels need to
    be passed through [gather()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather)
    so that all of the data is available on the current device and a properly calculated
    metric can be achieved:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›è¡Œåˆ†å¸ƒå¼è¯„ä¼°æ—¶ï¼Œéœ€è¦é€šè¿‡[gather()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.gather)ä¼ é€’é¢„æµ‹å’Œæ ‡ç­¾ï¼Œä»¥ä¾¿æ‰€æœ‰æ•°æ®éƒ½åœ¨å½“å‰è®¾å¤‡ä¸Šå¯ç”¨ï¼Œå¹¶ä¸”å¯ä»¥å®ç°æ­£ç¡®è®¡ç®—çš„æŒ‡æ ‡ï¼š
- en: '[PRE23]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now you just need to calculate the actual metric for this problem, and you
    can print it on the main process using [print()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.print):'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨åªéœ€è¦è®¡ç®—æ­¤é—®é¢˜çš„å®é™…æŒ‡æ ‡ï¼Œå¹¶å¯ä»¥åœ¨ä¸»è¿›ç¨‹ä¸Šä½¿ç”¨[print()](/docs/accelerate/v0.27.2/en/package_reference/accelerator#accelerate.Accelerator.print)æ‰“å°å®ƒï¼š
- en: '[PRE24]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'A full version of this training loop is available below:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æä¾›äº†å®Œæ•´ç‰ˆæœ¬çš„è®­ç»ƒå¾ªç¯ï¼š
- en: '[PRE25]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Using the notebook_launcher
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨notebook_launcher
- en: All thatâ€™s left is to use the [notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å‰©ä¸‹çš„å°±æ˜¯ä½¿ç”¨[notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)ã€‚
- en: You pass in the function, the arguments (as a tuple), and the number of processes
    to train on. (See the [documentation](../package_reference/launchers) for more
    information)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨ä¼ å…¥å‡½æ•°ã€å‚æ•°ï¼ˆä½œä¸ºå…ƒç»„ï¼‰ä»¥åŠè¦è®­ç»ƒçš„è¿›ç¨‹æ•°ã€‚ï¼ˆæœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[æ–‡æ¡£](../package_reference/launchers)ï¼‰
- en: '[PRE26]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In the case of running on multiple nodes, you need to set up a Jupyter session
    at each node and run the launching cell at the same time.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œæ—¶ï¼Œæ‚¨éœ€è¦åœ¨æ¯ä¸ªèŠ‚ç‚¹è®¾ç½®ä¸€ä¸ªJupyterä¼šè¯ï¼Œå¹¶åŒæ—¶è¿è¡Œå¯åŠ¨å•å…ƒæ ¼ã€‚
- en: 'For an environment containing 2 nodes (computers) with 8 GPUs each and the
    main computer with an IP address of â€œ172.31.43.8â€, it would look like so:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåŒ…å«æ¯å°è®¡ç®—æœºæœ‰8ä¸ªGPUçš„2ä¸ªèŠ‚ç‚¹ï¼ˆè®¡ç®—æœºï¼‰çš„ç¯å¢ƒï¼Œä¸»è®¡ç®—æœºçš„IPåœ°å€ä¸ºâ€œ172.31.43.8â€ï¼Œä¼šæ˜¯è¿™æ ·çš„ï¼š
- en: '[PRE28]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'And in the second Jupyter session on the other machine:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¦ä¸€å°æœºå™¨ä¸Šçš„ç¬¬äºŒä¸ªJupyterä¼šè¯ä¸­ï¼š
- en: Notice how the `node_rank` has changed
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„`node_rank`å·²æ›´æ”¹
- en: '[PRE29]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In the case of running on the TPU, it would look like so:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨TPUä¸Šè¿è¡Œæ—¶ï¼Œä¼šæ˜¯è¿™æ ·çš„ï¼š
- en: '[PRE30]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'As itâ€™s running it will print the progress as well as state how many devices
    you ran on. This tutorial was ran with two GPUs:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿è¡Œæ—¶ï¼Œå®ƒå°†æ‰“å°è¿›åº¦ï¼Œå¹¶è¯´æ˜æ‚¨è¿è¡Œåœ¨å¤šå°‘è®¾å¤‡ä¸Šã€‚æœ¬æ•™ç¨‹ä½¿ç”¨äº†ä¸¤ä¸ªGPUï¼š
- en: '[PRE31]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: And thatâ€™s it!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æ˜¯è¿™æ ·ï¼
- en: Debugging
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è°ƒè¯•
- en: A common issue when running the `notebook_launcher` is receiving a CUDA has
    already been initialized issue. This usually stems from an import or prior code
    in the notebook that makes a call to the PyTorch `torch.cuda` sublibrary. To help
    narrow down what went wrong, you can launch the `notebook_launcher` with `ACCELERATE_DEBUG_MODE=yes`
    in your environment and an additional check will be made when spawning that a
    regular process can be created and utilize CUDA without issue. (Your CUDA code
    can still be ran afterwards).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿è¡Œ`notebook_launcher`æ—¶å¸¸è§çš„é—®é¢˜æ˜¯æ”¶åˆ°CUDAå·²ç»åˆå§‹åŒ–çš„é—®é¢˜ã€‚è¿™é€šå¸¸æºäºç¬”è®°æœ¬ä¸­çš„å¯¼å…¥æˆ–å…ˆå‰ä»£ç è°ƒç”¨PyTorchçš„`torch.cuda`å­åº“ã€‚ä¸ºäº†å¸®åŠ©ç¼©å°é—®é¢˜èŒƒå›´ï¼Œæ‚¨å¯ä»¥åœ¨ç¯å¢ƒä¸­ä½¿ç”¨`ACCELERATE_DEBUG_MODE=yes`å¯åŠ¨`notebook_launcher`ï¼Œå¹¶åœ¨ç”Ÿæˆæ—¶è¿›è¡Œé¢å¤–æ£€æŸ¥ï¼Œä»¥ç¡®ä¿å¯ä»¥åˆ›å»ºå¸¸è§„è¿›ç¨‹å¹¶æ— é—®é¢˜åœ°åˆ©ç”¨CUDAã€‚ï¼ˆæ‚¨çš„CUDAä»£ç ä»ç„¶å¯ä»¥åœ¨ä¹‹åè¿è¡Œï¼‰ã€‚
- en: Conclusion
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: 'This notebook showed how to perform distributed training from inside of a Jupyter
    Notebook. Some key notes to remember:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç¬”è®°æœ¬å±•ç¤ºäº†å¦‚ä½•ä»Jupyter Notebookå†…æ‰§è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚è¯·è®°ä½ä¸€äº›å…³é”®è¦ç‚¹ï¼š
- en: Make sure to save any code that use CUDA (or CUDA imports) for the function
    passed to [notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®ä¿ä¿å­˜ä½¿ç”¨CUDAçš„ä»»ä½•ä»£ç ï¼ˆæˆ–CUDAå¯¼å…¥ï¼‰ä»¥ä¼ é€’ç»™[notebook_launcher()](/docs/accelerate/v0.27.2/en/package_reference/launchers#accelerate.notebook_launcher)çš„å‡½æ•°ã€‚
- en: Set the `num_processes` to be the number of devices used for training (such
    as number of GPUs, CPUs, TPUs, etc)
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†`num_processes`è®¾ç½®ä¸ºç”¨äºè®­ç»ƒçš„è®¾å¤‡æ•°é‡ï¼ˆä¾‹å¦‚GPUã€CPUã€TPUç­‰çš„æ•°é‡ï¼‰
- en: If using the TPU, declare your model outside the training loop function
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨TPUï¼Œè¯·åœ¨è®­ç»ƒå¾ªç¯å‡½æ•°ä¹‹å¤–å£°æ˜æ‚¨çš„æ¨¡å‹
