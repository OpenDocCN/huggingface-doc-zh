- en: LoKr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/peft/package_reference/lokr](https://huggingface.co/docs/peft/package_reference/lokr)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/peft/v0.8.2/en/_app/immutable/assets/0.e3b0c442.css" rel="modulepreload">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/entry/start.c9bed6ec.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/scheduler.d627b047.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/singletons.95cf6adf.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/index.a57a1c33.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/paths.5d07c46f.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/entry/app.72c78cae.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/index.d48c4817.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/nodes/0.aa346fde.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/nodes/23.90d88110.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/Docstring.270658d8.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/Heading.47e562a9.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/CodeBlock.5da89496.js">
    <link rel="modulepreload" href="/docs/peft/v0.8.2/en/_app/immutable/chunks/ExampleCodeBlock.a22db1c3.js">
  prefs: []
  type: TYPE_NORMAL
- en: Low-Rank Kronecker Product ([LoKr](https://hf.co/papers/2309.14859)), is a LoRA-variant
    method that approximates the large weight matrix with two low-rank matrices and
    combines them with the Kronecker product. LoKr also provides an optional third
    low-rank matrix to provide better control during fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: LoKrConfig
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class peft.LoKrConfig`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/lokr/config.py#L22)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`r` (`int`) — LoKr rank.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alpha` (`int`) — The alpha parameter for LoKr scaling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rank_dropout` (`float`) — The dropout probability for rank dimension during
    training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`module_dropout` (`float`) — The dropout probability for disabling LoKr modules
    during training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_effective_conv2d` (`bool`) — Use parameter effective decomposition for
    Conv2d with ksize > 1 (“Proposition 3” from FedPara paper).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decompose_both` (`bool`) — Perform rank decomposition of left kronecker product
    matrix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decompose_factor` (`int`) — Kronecker product decomposition factor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target_modules` (`Optional[Union[List[str], str]]`) — The names of the modules
    to apply the adapter to. If this is specified, only the modules with the specified
    names will be replaced. When passing a string, a regex match will be performed.
    When passing a list of strings, either an exact match will be performed or it
    is checked if the name of the module ends with any of the passed strings. If this
    is specified as ‘all-linear’, then all linear/Conv1D modules are chosen, excluding
    the output layer. If this is not specified, modules will be chosen according to
    the model architecture. If the architecture is not known, an error will be raised
    — in this case, you should specify the target modules manually.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`init_weights` (`bool`) — Whether to perform initialization of adapter weights.
    This defaults to `True`, passing `False` is discouraged.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`layers_to_transform` (`Union[List[int], int]`) — The layer indices to transform.
    If a list of ints is passed, it will apply the adapter to the layer indices that
    are specified in this list. If a single integer is passed, it will apply the transformations
    on the layer at this index.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`layers_pattern` (`str`) — The layer pattern name, used only if `layers_to_transform`
    is different from `None`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rank_pattern` (`dict`) — The mapping from layer names or regexp expression
    to ranks which are different from the default rank specified by `r`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alpha_pattern` (`dict`) — The mapping from layer names or regexp expression
    to alphas which are different from the default alpha specified by `alpha`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modules_to_save` (`Optional[List[str]]`) — List of modules apart from adapter
    layers to be set as trainable and saved in the final checkpoint.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration class of [LoKrModel](/docs/peft/v0.8.2/en/package_reference/lokr#peft.LoKrModel).
  prefs: []
  type: TYPE_NORMAL
- en: LoKrModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class peft.LoKrModel`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/tuners/lokr/model.py#L27)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`model` (`torch.nn.Module`) — The model to which the adapter tuner layers will
    be attached.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config` ([LoKrConfig](/docs/peft/v0.8.2/en/package_reference/lokr#peft.LoKrConfig))
    — The configuration of the LoKr model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`adapter_name` (`str`) — The name of the adapter, defaults to `"default"`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.nn.Module`'
  prefs: []
  type: TYPE_NORMAL
- en: The LoKr model.
  prefs: []
  type: TYPE_NORMAL
- en: Creates Low-Rank Kronecker Product model from a pretrained model. The original
    method is partially described in [https://arxiv.org/abs/2108.06098](https://arxiv.org/abs/2108.06098)
    and in [https://arxiv.org/abs/2309.14859](https://arxiv.org/abs/2309.14859) Current
    implementation heavily borrows from [https://github.com/KohakuBlueleaf/LyCORIS/blob/eb460098187f752a5d66406d3affade6f0a07ece/lycoris/modules/lokr.py](https://github.com/KohakuBlueleaf/LyCORIS/blob/eb460098187f752a5d66406d3affade6f0a07ece/lycoris/modules/lokr.py)
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Attributes**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`model` (`~torch.nn.Module`) — The model to be adapted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`peft_config` ([LoKrConfig](/docs/peft/v0.8.2/en/package_reference/lokr#peft.LoKrConfig)):
    The configuration of the LoKr model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
