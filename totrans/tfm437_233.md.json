["```py\nimport torch\nfrom transformers import AutoTokenizer, RwkvConfig, RwkvModel\n\nmodel = RwkvModel.from_pretrained(\"sgugger/rwkv-430M-pile\")\ntokenizer = AutoTokenizer.from_pretrained(\"sgugger/rwkv-430M-pile\")\n\ninputs = tokenizer(\"This is an example.\", return_tensors=\"pt\")\n# Feed everything to the model\noutputs = model(inputs[\"input_ids\"])\noutput_whole = outputs.last_hidden_state\n\noutputs = model(inputs[\"input_ids\"][:, :2])\noutput_one = outputs.last_hidden_state\n\n# Using the state computed on the first inputs, we will get the same output\noutputs = model(inputs[\"input_ids\"][:, 2:], state=outputs.state)\noutput_two = outputs.last_hidden_state\n\ntorch.allclose(torch.cat([output_one, output_two], dim=1), output_whole, atol=1e-5)\n```", "```py\nfrom transformers import StoppingCriteria\n\nclass RwkvStoppingCriteria(StoppingCriteria):\n    def __init__(self, eos_sequence = [187,187], eos_token_id = 537):\n        self.eos_sequence = eos_sequence\n        self.eos_token_id = eos_token_id\n\n    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n        last_2_ids = input_ids[:,-2:].tolist()\n        return self.eos_sequence in last_2_ids\n\noutput = model.generate(inputs[\"input_ids\"], max_new_tokens=64, stopping_criteria = [RwkvStoppingCriteria()])\n```", "```py\n>>> from transformers import RwkvConfig, RwkvModel\n\n>>> # Initializing a Rwkv configuration\n>>> configuration = RwkvConfig()\n\n>>> # Initializing a model (with random weights) from the configuration\n>>> model = RwkvModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import AutoTokenizer, RwkvModel\n>>> import torch\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"RWKV/rwkv-4-169m-pile\")\n>>> model = RwkvModel.from_pretrained(\"RWKV/rwkv-4-169m-pile\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> import torch\n>>> from transformers import AutoTokenizer, RwkvForCausalLM\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"RWKV/rwkv-4-169m-pile\")\n>>> model = RwkvForCausalLM.from_pretrained(\"RWKV/rwkv-4-169m-pile\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n>>> outputs = model(**inputs, labels=inputs[\"input_ids\"])\n>>> loss = outputs.loss\n>>> logits = outputs.logits\n```"]