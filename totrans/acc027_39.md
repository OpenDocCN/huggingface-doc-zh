# 有状态的类

> 原始文本：[`huggingface.co/docs/accelerate/package_reference/state`](https://huggingface.co/docs/accelerate/package_reference/state)

以下是[单例类](https://en.wikipedia.org/wiki/Singleton_pattern)的变体，所有实例共享相同的状态，该状态在第一次实例化时初始化。

这些类是不可变的，存储有关某些配置或状态的信息。

### `class accelerate.PartialState`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L105)

```py
( cpu: bool = False **kwargs )
```

具有有关当前训练环境的信息和帮助处理进程控制的函数的单例类。设计用于仅在需要进程控制和设备执行状态时使用。*不*需要从`Accelerator`初始化。

**可用属性：**

+   `device` (`torch.device`) — 要使用的设备。

+   `distributed_type` (DistributedType) — 当前正在使用的分布式环境的类型。

+   `local_process_index` (`int`) — 当前服务器上当前进程的索引。

+   `mixed_precision` (`str`) — 当前脚本是否将使用混合精度，如果是，则正在执行的混合精度类型。（从‘no’、‘fp16’、‘bf16’或‘fp8’中选择）。

+   `num_processes` (`int`) — 当前并行启动的进程数。

+   `process_index` (`int`) — 当前进程的索引。

+   `is_last_process` (`bool`) — 当前进程是否是最后一个。

+   `is_main_process` (`bool`) — 当前进程是否是主进程。

+   `is_local_main_process` (`bool`) — 当前进程是否是本地节点上的主进程。

+   `debug` (`bool`) — 当前脚本是否以调试模式运行。

#### `local_main_process_first`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L528)

```py
( )
```

让本地主进程在`with`块中执行。

主进程退出后，其他进程将进入`with`块。

示例：

```py
>>> from accelerate.state import PartialState

>>> state = PartialState()
>>> with state.local_main_process_first():
...     # This will be printed first by local process 0 then in a seemingly
...     # random order by the other processes.
...     print(f"This will be printed by process {state.local_process_index}")
```

#### `main_process_first`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L507)

```py
( )
```

让主进程在`with`块中首先执行。

主进程退出后，其他进程将进入`with`块。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> with accelerator.main_process_first():
...     # This will be printed first by process 0 then in a seemingly
...     # random order by the other processes.
...     print(f"This will be printed by process {accelerator.process_index}")
```

#### `on_last_process`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L610)

```py
( function: Callable[..., Any] )
```

参数

+   `function` (`Callable`) — 要装饰的函数。

只在最后一个进程上运行装饰函数的装饰器。

示例：

```py
# Assume we have 4 processes.
from accelerate.state import PartialState

state = PartialState()

@state.on_last_process
def print_something():
    print(f"Printed on process {state.process_index}")

print_something()
"Printed on process 3"
```

#### `on_local_main_process`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L579)

```py
( function: Callable[..., Any] = None )
```

参数

+   `function` (`Callable`) — 要装饰的函数。

只在本地主进程上运行装饰函数的装饰器。

示例：

```py
# Assume we have 2 servers with 4 processes each.
from accelerate.state import PartialState

state = PartialState()

@state.on_local_main_process
def print_something():
    print("This will be printed by process 0 only on each server.")

print_something()
# On server 1:
"This will be printed by process 0 only"
# On server 2:
"This will be printed by process 0 only"
```

#### `on_local_process`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L671)

```py
( function: Callable[..., Any] = None local_process_index: int = None )
```

参数

+   `function` (`Callable`, *可选*) — 要装饰的函数。

+   `local_process_index` (`int`, *可选*) — 要在其上运行函数的本地进程的索引。

只在当前节点上具有给定索引的进程上运行装饰函数的装饰器。

示例：

```py
# Assume we have 2 servers with 4 processes each.
from accelerate import Accelerator

accelerator = Accelerator()

@accelerator.on_local_process(local_process_index=2)
def print_something():
    print(f"Printed on process {accelerator.local_process_index}")

print_something()
# On server 1:
"Printed on process 2"
# On server 2:
"Printed on process 2"
```

#### `on_main_process`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L549)

```py
( function: Callable[..., Any] = None )
```

参数

+   `function` (`Callable`) — 要装饰的函数。

只在主进程上运行装饰函数的装饰器。

示例：

```py
>>> from accelerate.state import PartialState

>>> state = PartialState()

>>> @state.on_main_process
... def print_something():
...     print("This will be printed by process 0 only.")

>>> print_something()
"This will be printed by process 0 only"
```

#### `on_process`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L638)

```py
( function: Callable[..., Any] = None process_index: int = None )
```

参数

+   `function` (`Callable`, `可选`) — 要装饰的函数。

+   `process_index` (`int`, `可选`) — 要在其上运行函数的进程的索引。

只在具有给定索引的进程上运行装饰函数的装饰器。

示例：

```py
# Assume we have 4 processes.
from accelerate.state import PartialState

state = PartialState()

@state.on_process(process_index=2)
def print_something():
    print(f"Printed on process {state.process_index}")

print_something()
"Printed on process 2"
```

#### `split_between_processes`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L428)

```py
( inputs: list | tuple | dict | torch.Tensor apply_padding: bool = False )
```

参数

+   `inputs` (`list`、`tuple`、`torch.Tensor`或`dict`的`list`/`tuple`/`torch.Tensor`） — 在进程之间分割的输入。

+   `apply_padding` (`bool`，可选，默认为`False`) — 是否通过重复输入的最后一个元素来应用填充，以便所有进程具有相同数量的元素。在尝试对输出执行`gather()`等操作或传入少于进程数的输入时很有用。如果是这样，请记得之后删除填充的元素。

快速在`self.num_processes`之间分割`input`，然后可以在该进程上使用。在进行分布式推理时很有用，例如使用不同的提示。

请注意，使用`dict`时，所有键都需要具有相同数量的元素。

示例：

```py
# Assume there are two processes
from accelerate import PartialState

state = PartialState()
with state.split_between_processes(["A", "B", "C"]) as inputs:
    print(inputs)
# Process 0
["A", "B"]
# Process 1
["C"]

with state.split_between_processes(["A", "B", "C"], apply_padding=True) as inputs:
    print(inputs)
# Process 0
["A", "B"]
# Process 1
["C", "C"]
```

#### `wait_for_everyone`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L385)

```py
( )
```

将停止当前进程的执行，直到每个其他进程都达到该点（因此当脚本仅在一个进程中运行时，这不起作用）。在保存模型之前执行此操作很有用。

示例：

```py
>>> # Assuming two GPU processes
>>> import time
>>> from accelerate.state import PartialState

>>> state = PartialState()
>>> if state.is_main_process:
...     time.sleep(2)
>>> else:
...     print("I'm waiting for the main process to finish its sleep...")
>>> state.wait_for_everyone()
>>> # Should print on every process at the same time
>>> print("Everyone is here")
```

### `class accelerate.state.AcceleratorState`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L733)

```py
( mixed_precision: str = None cpu: bool = False dynamo_plugin = None deepspeed_plugin = None fsdp_plugin = None megatron_lm_plugin = None _from_accelerator: bool = False **kwargs )
```

包含有关当前训练环境的信息的单例类。

**可用属性：**

+   `device` (`torch.device`) — 要使用的设备。

+   `distributed_type` (DistributedType) — 当前使用的分布式环境类型。

+   `initialized` (`bool`) — `AcceleratorState`是否已从`Accelerator`初始化。

+   `local_process_index` (`int`) — 当前服务器上当前进程的索引。

+   `mixed_precision` (`str`) — 当前脚本是否使用混合精度，如果是，则执行的混合精度类型。（选择‘no’、‘fp16’、‘bf16’或‘fp8’）。

+   `num_processes` (`int`) — 当前并行启动的进程数。

+   `process_index` (`int`) — 当前进程的索引。

+   `is_last_process` (`bool`) — 当前进程是否为最后一个。

+   `is_main_process` (`bool`) — 当前进程是否为主进程。

+   `is_local_main_process` (`bool`) — 当前进程是否为本地节点上的主进程。

+   `debug` (`bool`) — 当前脚本是否以调试模式运行。

#### `local_main_process_first`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L983)

```py
( )
```

让本地主进程进入 with 块。

其他进程将在主进程退出后进入 with 块。

#### `main_process_first`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L973)

```py
( )
```

让主进程首先进入 with 块。

其他进程将在主进程退出后进入 with 块。

#### `split_between_processes`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L931)

```py
( inputs: list | tuple | dict | torch.Tensor apply_padding: bool = False )
```

参数

+   `inputs` (`list`、`tuple`、`torch.Tensor`或`dict`的`list`/`tuple`/`torch.Tensor`） — 在进程之间分割的输入。

+   `apply_padding` (`bool`，可选，默认为`False`) — 是否通过重复输入的最后一个元素来应用填充，以便所有进程具有相同数量的元素。在尝试对输出执行`gather()`等操作或传入少于进程数的输入时很有用。如果是这样，请记得之后删除填充的元素。

快速在`self.num_processes`之间分割`input`，然后可以在该进程上使用。在进行分布式推理时很有用，例如使用不同的提示。

请注意，使用`dict`时，所有键都需要具有相同数量的元素。

示例：

```py
# Assume there are two processes
from accelerate.state import AcceleratorState

state = AcceleratorState()
with state.split_between_processes(["A", "B", "C"]) as inputs:
    print(inputs)
# Process 0
["A", "B"]
# Process 1
["C"]

with state.split_between_processes(["A", "B", "C"], apply_padding=True) as inputs:
    print(inputs)
# Process 0
["A", "B"]
# Process 1
["C", "C"]
```

### `class accelerate.state.GradientState`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/state.py#L997)

```py
( gradient_accumulation_plugin: Optional[GradientAccumulationPlugin] = None )
```

单例类，包含与梯度累积的梯度同步相关的信息

**可用属性:**

+   `end_of_dataloader` (`bool`) — 我们是否已经到达当前数据加载器的末尾

+   `remainder` (`int`) — 从填充数据加载器中添加的额外样本数

+   `sync_gradients` (`bool`) — 是否应该在所有设备之间同步梯度

+   `active_dataloader` (`Optional[DataLoader]`) — 当前正在迭代的数据加载器

+   `dataloader_references` (`List[Optional[DataLoader]]`) — 正在迭代的数据加载器的引用列表

+   `num_steps` (`int`) — 累积的步数

+   `adjust_scheduler` (`bool`) — 调整调度器以考虑梯度累积

+   `sync_with_dataloader` (`bool`) — 梯度是否应在数据加载器迭代结束时同步，并重置总步数
