# 单个文件

> 原始文本：[`huggingface.co/docs/diffusers/api/loaders/single_file`](https://huggingface.co/docs/diffusers/api/loaders/single_file)

Diffusers 支持加载预训练的管道（或模型）权重，这些权重存储在单个文件中，例如`ckpt`或`safetensors`文件。这些单个文件类型通常是由社区训练的模型生成的。有三个类用于加载单个文件权重：

+   `FromSingleFileMixin`支持加载存储在单个文件中的预训练管道权重，可以是`ckpt`或`safetensors`文件。

+   `FromOriginalVAEMixin`支持从存储在单个文件中的预训练 ControlNet 权重加载预训练的 AutoencoderKL。

+   `FromOriginalControlnetMixin`支持加载存储在单个文件中的预训练 ControlNet 权重，可以是`ckpt`或`safetensors`文件。

要了解如何加载单个文件权重的更多信息，请参阅加载不同的稳定扩散格式加载指南。

## FromSingleFileMixin

### `class diffusers.loaders.FromSingleFileMixin`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/single_file.py#L136)

```py
( )
```

将以`.ckpt`格式保存的模型权重加载到 DiffusionPipeline 中。

#### `from_single_file`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/single_file.py#L141)

```py
( pretrained_model_link_or_path **kwargs )
```

参数

+   `pretrained_model_link_or_path` (`str`或`os.PathLike`, *可选*) — 可以是：

    +   在 Hub 上的`.ckpt`文件的链接（例如 `"https://huggingface.co/<repo_id>/blob/main/<path_to_file>.ckpt"`）。

    +   包含所有管道权重的*文件*路径。

+   `torch_dtype` (`str`或`torch.dtype`, *可选*) — 覆盖默认的`torch.dtype`并使用另一种 dtype 加载模型。

+   `force_download` (`bool`, *可选*, 默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `cache_dir` (`Union[str, os.PathLike]`, *可选*) — 下载预训练模型配置的缓存路径，如果未使用标准缓存。

+   `resume_download` (`bool`, *可选*, 默认为`False`) — 是否恢复下载模型权重和配置文件。如果设置为`False`，则删除任何未完全下载的文件。

+   `proxies` (`Dict[str, str]`, *可选*) — 要使用的代理服务器字典，按协议或端点分类，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `local_files_only` (`bool`, *可选*, 默认为`False`) — 是否仅加载本地模型权重和配置文件。如果设置为`True`，则不会从 Hub 下载模型。

+   `token` (`str`或*bool*, *可选*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为`True`，则使用从`diffusers-cli login`生成的令牌（存储在`~/.huggingface`）。

+   `revision` (`str`, *可选*, 默认为`"main"`) — 要使用的特定模型版本。可以是分支名称、标签名称、提交 ID 或 Git 允许的任何标识符。

+   `use_safetensors` (`bool`, *可选*, 默认为`None`) — 如果设置为`None`，则在可用时下载 safetensors 权重 **并且** 如果已安装 safetensors 库。如果设置为`True`，则从 safetensors 权重强制加载模型。如果设置为`False`，则不加载 safetensors 权重。

从以`.ckpt`或`.safetensors`格式保存的预训练管道权重实例化一个 DiffusionPipeline。默认情况下，管道设置为评估模式（`model.eval()`）。

示例：

```py
>>> from diffusers import StableDiffusionPipeline

>>> # Download pipeline from huggingface.co and cache.
>>> pipeline = StableDiffusionPipeline.from_single_file(
...     "https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix/AbyssOrangeMix.safetensors"
... )

>>> # Download pipeline from local file
>>> # file is downloaded under ./v1-5-pruned-emaonly.ckpt
>>> pipeline = StableDiffusionPipeline.from_single_file("./v1-5-pruned-emaonly")

>>> # Enable float16 and move to GPU
>>> pipeline = StableDiffusionPipeline.from_single_file(
...     "https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned-emaonly.ckpt",
...     torch_dtype=torch.float16,
... )
>>> pipeline.to("cuda")
```

## FromOriginalVAEMixin

### `class diffusers.loaders.FromOriginalVAEMixin`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/autoencoder.py#L23)

```py
( )
```

加载保存在`.ckpt`或`.safetensors`格式中的预训练 AutoencoderKL 权重到 AutoencoderKL。

#### `from_single_file`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/autoencoder.py#L28)

```py
( pretrained_model_link_or_path **kwargs )
```

参数

+   `pretrained_model_link_or_path` (`str` 或 `os.PathLike`, *可选*) — 可以是以下之一：

    +   Hub 上`.ckpt`文件的链接（例如`"https://huggingface.co/<repo_id>/blob/main/<path_to_file>.ckpt"`）。

    +   一个包含所有管道权重的*文件*路径。

+   `config_file` (`str`, *可选*) — 与模型关联的配置 YAML 文件的文件路径。如果未提供，则默认为：[`raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml`](https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml)

+   `torch_dtype` (`str` 或 `torch.dtype`, *可选*) — 覆盖默认的`torch.dtype`并使用另一种 dtype 加载模型。如果传递`"auto"`，dtype 将自动从模型的权重中派生。

+   `force_download` (`bool`, *可选*, 默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `cache_dir` (`Union[str, os.PathLike]`, *可选*) — 下载的预训练模型配置缓存在标准缓存未使用时的目录路径。

+   `resume_download` (`bool`, *可选*, 默认为`False`) — 是否继续下载模型权重和配置文件。如果设置为`False`，任何未完全下载的文件将被删除。

+   `proxies` (`Dict[str, str]`, *可选*) — 用于每个请求的协议或端点的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。

+   `local_files_only` (`bool`, *可选*, 默认为`False`) — 是否仅加载本地模型权重和配置文件。如果设置为 True，则不会从 Hub 下载模型。

+   `token` (`str` 或 *bool*, *可选*) — 用作远程文件 HTTP bearer 授权的令牌。如果为`True`，则使用从`diffusers-cli login`生成的令牌（存储在`~/.huggingface`中）。

+   `revision` (`str`, *可选*, 默认为`"main"`) — 要使用的特定模型版本。可以是分支名称、标签名称、提交 ID 或 Git 允许的任何标识符。

+   `image_size` (`int`, *可选*, 默认为 512) — 模型训练时使用的图像尺寸。对于所有稳定扩散 v1 模型和稳定扩散 v2 基础模型，请使用 512。对于稳定扩散 v2，请使用 768。

+   `scaling_factor` (`float`, *可选*, 默认为 0.18215) — 使用训练集的第一批计算的训练潜在空间的分量标准差。在训练扩散模型时，用于将潜在空间缩放为单位方差。在传递给扩散模型之前，潜在空间使用公式`z = z * scaling_factor`进行缩放。在解码时，潜在空间使用公式缩放回原始比例：`z = 1 / scaling_factor * z`。有关更多详细信息，请参阅[高分辨率图像合成与潜在扩散模型](https://arxiv.org/abs/2112.10752)论文的 4.3.2 和 D.1 节。

+   `use_safetensors` (`bool`, *可选*, 默认为`None`) — 如果设置为`None`，则在可用时下载 safetensors 权重 **且** 如果已安装 safetensors 库。如果设置为`True`，则强制从 safetensors 权重加载模型。如果设置为`False`，则不加载 safetensors 权重。

+   `kwargs`（剩余的关键字参数字典，*可选*）— 可用于覆盖加载和可保存变量（例如特定管道类的管道组件）。被覆盖的组件直接传递给管道的`__init__`方法。有关更多信息，请参见下面的示例。

从原始`.ckpt`或`.safetensors`格式中保存的预训练 ControlNet 权重实例化一个 AutoencoderKL。默认情况下，管道设置为评估模式（`model.eval()`）。

确保在从 SDXL 或更高版本的稳定扩散 v2 模型加载 VAE 时，将`image_size`和`scaling_factor`都传递给`from_single_file()`。

示例：

```py
from diffusers import AutoencoderKL

url = "https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.safetensors"  # can also be local file
model = AutoencoderKL.from_single_file(url)
```

## FromOriginalControlnetMixin

### `class diffusers.loaders.FromOriginalControlNetMixin`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/controlnet.py#L23)

```py
( )
```

将保存在`.ckpt`或`.safetensors`格式中的预训练 ControlNet 权重加载到 ControlNetModel 中。

#### `from_single_file`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/loaders/controlnet.py#L28)

```py
( pretrained_model_link_or_path **kwargs )
```

参数

+   `pretrained_model_link_or_path`（`str`或`os.PathLike`，*可选*）— 可以是：

    +   在 Hub 上的`.ckpt`文件的链接（例如`"https://huggingface.co/<repo_id>/blob/main/<path_to_file>.ckpt"`）。

    +   包含所有管道权重的*文件*路径。

+   `torch_dtype`（`str`或`torch.dtype`，*可选*）— 覆盖默认的`torch.dtype`并使用另一种 dtype 加载模型。如果传递`"auto"`，dtype 将自动从模型的权重中派生。

+   `force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `cache_dir`（`Union[str, os.PathLike]`，*可选*）— 下载预训练模型配置的目录路径，如果未使用标准缓存。

+   `resume_download`（`bool`，*可选*，默认为`False`）— 是否恢复下载模型权重和配置文件。如果设置为`False`，任何未完全下载的文件将被删除。

+   `proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求中使用。

+   `local_files_only`（`bool`，*可选*，默认为`False`）— 是否仅加载本地模型权重和配置文件。如果设置为 True，则模型不会从 Hub 下载。

+   `token`（`str`或*bool*，*可选*）— 用作远程文件的 HTTP 令牌授权的令牌。如果为`True`，则使用从`diffusers-cli login`生成的令牌（存储在`~/.huggingface`中）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。可以是分支名称、标签名称、提交 ID 或 Git 允许的任何标识符。

+   `use_safetensors`（`bool`，*可选*，默认为`None`）— 如果设置为`None`，则在可用时下载 safetensors 权重 **并且** 如果已安装 safetensors 库。如果设置为`True`，则强制从 safetensors 权重加载模型。如果设置为`False`，则不加载 safetensors 权重。

+   `image_size`（`int`，*可选*，默认为 512）— 模型训练的图像大小。对于所有稳定扩散 v1 模型和稳定扩散 v2 基础模型，请使用 512。对于稳定扩散 v2，请使用 768。

+   `upcast_attention`（`bool`，*可选*，默认为`None`）— 是否始终应该将注意力计算上转。

+   `kwargs`（剩余的关键字参数字典，*可选*）- 可用于覆盖可加载和可保存变量（例如特定管道类的管道组件）。被覆盖的组件直接传递给管道的`__init__`方法。更多信息请参见下面的示例。

从预训练的 ControlNet 权重实例化一个 ControlNetModel，这些权重以原始的`.ckpt`或`.safetensors`格式保存。默认情况下，管道设置为评估模式（`model.eval()`）。

示例：

```py
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel

url = "https://huggingface.co/lllyasviel/ControlNet-v1-1/blob/main/control_v11p_sd15_canny.pth"  # can also be a local path
model = ControlNetModel.from_single_file(url)

url = "https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned.safetensors"  # can also be a local path
pipe = StableDiffusionControlNetPipeline.from_single_file(url, controlnet=controlnet)
```
