# Deformable DETR

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deformable_detr](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/deformable_detr)

## æ¦‚è¿°

Deformable DETRæ¨¡å‹æ˜¯ç”±Xizhou Zhuï¼ŒWeijie Suï¼ŒLewei Luï¼ŒBin Liï¼ŒXiaogang Wangï¼ŒJifeng Daiåœ¨[Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159)ä¸­æå‡ºçš„ã€‚Deformable DETRé€šè¿‡åˆ©ç”¨ä¸€ä¸ªæ–°çš„å¯å˜å½¢æ³¨æ„åŠ›æ¨¡å—ï¼Œè¯¥æ¨¡å—åªå…³æ³¨å‚è€ƒå‘¨å›´ä¸€å°ç»„å…³é”®é‡‡æ ·ç‚¹ï¼Œä»è€Œç¼“è§£äº†åŸå§‹[DETR](detr)çš„æ”¶æ•›é€Ÿåº¦æ…¢å’Œç‰¹å¾ç©ºé—´åˆ†è¾¨ç‡æœ‰é™çš„é—®é¢˜ã€‚

è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š

*DETRæœ€è¿‘è¢«æå‡ºï¼Œæ—¨åœ¨æ¶ˆé™¤ç›®æ ‡æ£€æµ‹ä¸­è®¸å¤šæ‰‹å·¥è®¾è®¡çš„ç»„ä»¶çš„éœ€æ±‚ï¼ŒåŒæ—¶è¡¨ç°è‰¯å¥½ã€‚ç„¶è€Œï¼Œç”±äºTransformeræ³¨æ„åŠ›æ¨¡å—åœ¨å¤„ç†å›¾åƒç‰¹å¾å›¾æ—¶çš„é™åˆ¶ï¼Œå®ƒå­˜åœ¨æ”¶æ•›é€Ÿåº¦æ…¢å’Œç‰¹å¾ç©ºé—´åˆ†è¾¨ç‡æœ‰é™çš„é—®é¢˜ã€‚ä¸ºäº†ç¼“è§£è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Deformable DETRï¼Œå…¶æ³¨æ„åŠ›æ¨¡å—åªå…³æ³¨å‚è€ƒå‘¨å›´ä¸€å°ç»„å…³é”®é‡‡æ ·ç‚¹ã€‚Deformable DETRå¯ä»¥æ¯”DETRå®ç°æ›´å¥½çš„æ€§èƒ½ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºå°ç›®æ ‡ï¼‰ï¼Œå¹¶ä¸”è®­ç»ƒæ—¶é•¿å‡å°‘äº†10å€ã€‚åœ¨COCOåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚*

![drawing](../Images/840536d35745dda097869c1c27a80c35.png) Deformable DETRæ¶æ„ã€‚æ‘˜è‡ª[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2010.04159)ã€‚

æ­¤æ¨¡å‹ç”±[nielsr](https://huggingface.co/nielsr)è´¡çŒ®ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/fundamentalvision/Deformable-DETR)æ‰¾åˆ°ã€‚

## ä½¿ç”¨æç¤º

+   è®­ç»ƒDeformable DETRç­‰åŒäºè®­ç»ƒåŸå§‹[DETR](detr)æ¨¡å‹ã€‚æœ‰å…³æ¼”ç¤ºç¬”è®°æœ¬ï¼Œè¯·å‚è§ä¸‹é¢çš„[èµ„æº](#resources)éƒ¨åˆ†ã€‚

## èµ„æº

å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºåˆ—è¡¨ï¼Œå¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨Deformable DETRã€‚

ç›®æ ‡æ£€æµ‹

+   å…³äºåœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šè¿›è¡Œæ¨ç†+å¾®è°ƒçš„æ¼”ç¤ºç¬”è®°æœ¬ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Deformable-DETR)æ‰¾åˆ°ã€‚

+   å¦è¯·å‚é˜…ï¼š[ç›®æ ‡æ£€æµ‹ä»»åŠ¡æŒ‡å—](../tasks/object_detection)ã€‚

å¦‚æœæ‚¨æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æå‡ºæ‹‰å–è¯·æ±‚ï¼Œæˆ‘ä»¬å°†å¯¹å…¶è¿›è¡Œå®¡æŸ¥ï¼èµ„æºåº”è¯¥å±•ç¤ºä¸€äº›æ–°å†…å®¹ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰èµ„æºã€‚

## DeformableDetrImageProcessor

### `class transformers.DeformableDetrImageProcessor`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L756)

```py
( format: Union = <AnnotationFormat.COCO_DETECTION: 'coco_detection'> do_resize: bool = True size: Dict = None resample: Resampling = <Resampling.BILINEAR: 2> do_rescale: bool = True rescale_factor: Union = 0.00392156862745098 do_normalize: bool = True image_mean: Union = None image_std: Union = None do_pad: bool = True **kwargs )
```

å‚æ•°

+   `format` (`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"coco_detection"`) â€” æ³¨é‡Šçš„æ•°æ®æ ¼å¼ã€‚å…¶ä¸­ä¹‹ä¸€æ˜¯`"coco_detection"`æˆ–â€œcoco_panopticâ€ã€‚

+   `do_resize` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`) â€” æ§åˆ¶æ˜¯å¦å°†å›¾åƒçš„ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰å°ºå¯¸è°ƒæ•´ä¸ºæŒ‡å®šçš„`size`ã€‚å¯ä»¥é€šè¿‡`preprocess`æ–¹æ³•ä¸­çš„`do_resize`å‚æ•°è¿›è¡Œè¦†ç›–ã€‚

+   `size` (`Dict[str, int]` *å¯é€‰*ï¼Œé»˜è®¤ä¸º`{"shortest_edge" -- 800, "longest_edge": 1333}`)ï¼šè°ƒæ•´å¤§å°åçš„å›¾åƒï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰å°ºå¯¸ã€‚å¯ä»¥é€šè¿‡`preprocess`æ–¹æ³•ä¸­çš„`size`å‚æ•°è¿›è¡Œè¦†ç›–ã€‚

+   `resample` (`PILImageResampling`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`PILImageResampling.BILINEAR`) â€” å¦‚æœè°ƒæ•´å›¾åƒå¤§å°ï¼Œåˆ™è¦ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚

+   `do_rescale` (`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`) â€” æ§åˆ¶æ˜¯å¦æŒ‰æŒ‡å®šæ¯”ä¾‹`rescale_factor`å¯¹å›¾åƒè¿›è¡Œé‡æ–°ç¼©æ”¾ã€‚å¯ä»¥é€šè¿‡`preprocess`æ–¹æ³•ä¸­çš„`do_rescale`å‚æ•°è¿›è¡Œè¦†ç›–ã€‚

+   `rescale_factor`ï¼ˆ`int`æˆ–`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`1/255`ï¼‰â€” å¦‚æœé‡æ–°ç¼©æ”¾å›¾åƒï¼Œåˆ™ä½¿ç”¨çš„æ¯”ä¾‹å› å­ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`rescale_factor`å‚æ•°è¦†ç›–ã€‚do_normalize â€” æ§åˆ¶æ˜¯å¦è§„èŒƒåŒ–å›¾åƒã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`do_normalize`å‚æ•°è¦†ç›–ã€‚

+   `image_mean`ï¼ˆ`float`æˆ–`List[float]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`IMAGENET_DEFAULT_MEAN`ï¼‰â€” åœ¨è§„èŒƒåŒ–å›¾åƒæ—¶ä½¿ç”¨çš„å‡å€¼ã€‚å¯ä»¥æ˜¯å•ä¸ªå€¼æˆ–å€¼åˆ—è¡¨ï¼Œæ¯ä¸ªé€šé“ä¸€ä¸ªå€¼ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`image_mean`å‚æ•°è¦†ç›–ã€‚

+   `image_std`ï¼ˆ`float`æˆ–`List[float]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`IMAGENET_DEFAULT_STD`ï¼‰â€” åœ¨è§„èŒƒåŒ–å›¾åƒæ—¶ä½¿ç”¨çš„æ ‡å‡†å·®å€¼ã€‚å¯ä»¥æ˜¯å•ä¸ªå€¼æˆ–å€¼åˆ—è¡¨ï¼Œæ¯ä¸ªé€šé“ä¸€ä¸ªå€¼ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`image_std`å‚æ•°è¦†ç›–ã€‚

+   `do_pad`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰â€” æ§åˆ¶æ˜¯å¦å°†å›¾åƒå¡«å……åˆ°æ‰¹æ¬¡ä¸­æœ€å¤§çš„å›¾åƒå¹¶åˆ›å»ºåƒç´ æ©æ¨¡ã€‚å¯ä»¥è¢«`preprocess`æ–¹æ³•ä¸­çš„`do_pad`å‚æ•°è¦†ç›–ã€‚

æ„é€ ä¸€ä¸ªå¯å˜å½¢DETRå›¾åƒå¤„ç†å™¨ã€‚

#### `preprocess`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L1097)

```py
( images: Union annotations: Union = None return_segmentation_masks: bool = None masks_path: Union = None do_resize: Optional = None size: Optional = None resample = None do_rescale: Optional = None rescale_factor: Union = None do_normalize: Optional = None image_mean: Union = None image_std: Union = None do_pad: Optional = None format: Union = None return_tensors: Union = None data_format: Union = <ChannelDimension.FIRST: 'channels_first'> input_data_format: Union = None **kwargs )
```

å‚æ•°

+   `images`ï¼ˆ`ImageInput`ï¼‰â€” è¦é¢„å¤„ç†çš„å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ã€‚æœŸæœ›å•ä¸ªå›¾åƒæˆ–åƒç´ å€¼èŒƒå›´ä»0åˆ°255çš„å›¾åƒæ‰¹æ¬¡ã€‚å¦‚æœä¼ å…¥åƒç´ å€¼åœ¨0åˆ°1ä¹‹é—´çš„å›¾åƒï¼Œè¯·è®¾ç½®`do_rescale=False`ã€‚

+   `annotations`ï¼ˆ`AnnotationType`æˆ–`List[AnnotationType]`ï¼Œ*å¯é€‰*ï¼‰â€” ä¸å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡å…³è”çš„æ³¨é‡Šåˆ—è¡¨ã€‚å¦‚æœæ³¨é‡Šç”¨äºç›®æ ‡æ£€æµ‹ï¼Œåˆ™æ³¨é‡Šåº”è¯¥æ˜¯ä¸€ä¸ªå¸¦æœ‰ä»¥ä¸‹é”®çš„å­—å…¸ï¼š

    +   â€œimage_idâ€ï¼ˆ`int`ï¼‰ï¼šå›¾åƒIDã€‚

    +   â€œannotationsâ€ï¼ˆ`List[Dict]`ï¼‰ï¼šå›¾åƒçš„æ³¨é‡Šåˆ—è¡¨ã€‚æ¯ä¸ªæ³¨é‡Šåº”è¯¥æ˜¯ä¸€ä¸ªå­—å…¸ã€‚ä¸€ä¸ªå›¾åƒå¯ä»¥æ²¡æœ‰æ³¨é‡Šï¼Œæ­¤æ—¶åˆ—è¡¨åº”ä¸ºç©ºã€‚å¦‚æœæ³¨é‡Šæ˜¯ç”¨äºåˆ†å‰²çš„ï¼Œæ³¨é‡Šåº”è¯¥æ˜¯ä¸€ä¸ªå¸¦æœ‰ä»¥ä¸‹é”®çš„å­—å…¸ï¼š

    +   â€œimage_idâ€ï¼ˆ`int`ï¼‰ï¼šå›¾åƒIDã€‚

    +   â€œsegments_infoâ€ï¼ˆ`List[Dict]`ï¼‰ï¼šå›¾åƒçš„åˆ†æ®µåˆ—è¡¨ã€‚æ¯ä¸ªåˆ†æ®µåº”è¯¥æ˜¯ä¸€ä¸ªå­—å…¸ã€‚ä¸€ä¸ªå›¾åƒå¯ä»¥æ²¡æœ‰åˆ†æ®µï¼Œæ­¤æ—¶åˆ—è¡¨åº”ä¸ºç©ºã€‚

    +   â€œfile_nameâ€ï¼ˆ`str`ï¼‰ï¼šå›¾åƒçš„æ–‡ä»¶åã€‚

+   `return_segmentation_masks`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.return_segmentation_masksï¼‰â€” æ˜¯å¦è¿”å›åˆ†å‰²æ©æ¨¡ã€‚

+   `masks_path`ï¼ˆ`str`æˆ–`pathlib.Path`ï¼Œ*å¯é€‰*ï¼‰â€” åŒ…å«åˆ†å‰²æ©æ¨¡çš„ç›®å½•çš„è·¯å¾„ã€‚

+   `do_resize`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.do_resizeï¼‰â€” æ˜¯å¦è°ƒæ•´å›¾åƒå¤§å°ã€‚

+   `size`ï¼ˆ`Dict[str, int]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.sizeï¼‰â€” è°ƒæ•´å¤§å°åçš„å›¾åƒå°ºå¯¸ã€‚

+   `resample`ï¼ˆ`PILImageResampling`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.resampleï¼‰â€” è°ƒæ•´å›¾åƒå¤§å°æ—¶è¦ä½¿ç”¨çš„é‡é‡‡æ ·æ»¤æ³¢å™¨ã€‚

+   `do_rescale`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.do_rescaleï¼‰â€” æ˜¯å¦é‡æ–°ç¼©æ”¾å›¾åƒã€‚

+   `rescale_factor`ï¼ˆ`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.rescale_factorï¼‰â€” é‡æ–°ç¼©æ”¾å›¾åƒæ—¶ä½¿ç”¨çš„æ¯”ä¾‹å› å­ã€‚

+   `do_normalize`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.do_normalizeï¼‰â€” æ˜¯å¦è§„èŒƒåŒ–å›¾åƒã€‚

+   `image_mean`ï¼ˆ`float`æˆ–`List[float]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.image_meanï¼‰â€” åœ¨è§„èŒƒåŒ–å›¾åƒæ—¶ä½¿ç”¨çš„å‡å€¼ã€‚

+   `image_std`ï¼ˆ`float`æˆ–`List[float]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.image_stdï¼‰â€” åœ¨è§„èŒƒåŒ–å›¾åƒæ—¶ä½¿ç”¨çš„æ ‡å‡†å·®ã€‚

+   `do_pad`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.do_padï¼‰â€” æ˜¯å¦å¡«å……å›¾åƒã€‚

+   `format`ï¼ˆ`str`æˆ–`AnnotationFormat`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.formatï¼‰â€” æ³¨é‡Šçš„æ ¼å¼ã€‚

+   `return_tensors`ï¼ˆ`str`æˆ–`TensorType`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸ºself.return_tensorsï¼‰â€” è¦è¿”å›çš„å¼ é‡ç±»å‹ã€‚å¦‚æœä¸º`None`ï¼Œå°†è¿”å›å›¾åƒåˆ—è¡¨ã€‚

+   `data_format` (`ChannelDimension` æˆ– `str`, *å¯é€‰*, é»˜è®¤ä¸º `ChannelDimension.FIRST`) â€” è¾“å‡ºå›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `"channels_first"` æˆ– `ChannelDimension.FIRST`ï¼šå›¾åƒä»¥ (é€šé“æ•°, é«˜åº¦, å®½åº¦) æ ¼å¼ã€‚

    +   `"channels_last"` æˆ– `ChannelDimension.LAST`ï¼šå›¾åƒä»¥ (é«˜åº¦, å®½åº¦, é€šé“æ•°) æ ¼å¼ã€‚

    +   æœªè®¾ç½®ï¼šä½¿ç”¨è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚

+   `input_data_format` (`ChannelDimension` æˆ– `str`, *å¯é€‰*) â€” è¾“å…¥å›¾åƒçš„é€šé“ç»´åº¦æ ¼å¼ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™ä»è¾“å…¥å›¾åƒä¸­æ¨æ–­é€šé“ç»´åº¦æ ¼å¼ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š

    +   `"channels_first"` æˆ– `ChannelDimension.FIRST`ï¼šå›¾åƒä»¥ (é€šé“æ•°, é«˜åº¦, å®½åº¦) æ ¼å¼ã€‚

    +   `"channels_last"` æˆ– `ChannelDimension.LAST`ï¼šå›¾åƒä»¥ (é«˜åº¦, å®½åº¦, é€šé“æ•°) æ ¼å¼ã€‚

    +   `"none"` æˆ– `ChannelDimension.NONE`ï¼šå›¾åƒä»¥ (é«˜åº¦, å®½åº¦) æ ¼å¼ã€‚

é¢„å¤„ç†å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ï¼Œä»¥ä¾¿æ¨¡å‹å¯ä»¥ä½¿ç”¨ã€‚

#### `post_process_object_detection`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L1373)

```py
( outputs threshold: float = 0.5 target_sizes: Union = None top_k: int = 100 ) â†’ export const metadata = 'undefined';List[Dict]
```

å‚æ•°

+   `outputs` (`DetrObjectDetectionOutput`) â€” æ¨¡å‹çš„åŸå§‹è¾“å‡ºã€‚

+   `threshold` (`float`, *å¯é€‰*) â€” ä¿ç•™ç›®æ ‡æ£€æµ‹é¢„æµ‹çš„åˆ†æ•°é˜ˆå€¼ã€‚

+   `target_sizes` (`torch.Tensor` æˆ– `List[Tuple[int, int]]`, *å¯é€‰*) â€” å½¢çŠ¶ä¸º `(batch_size, 2)` çš„å¼ é‡æˆ–åŒ…å«æ‰¹æ¬¡ä¸­æ¯ä¸ªå›¾åƒç›®æ ‡å¤§å° (é«˜åº¦, å®½åº¦) çš„å…ƒç»„åˆ—è¡¨ (`Tuple[int, int]`)ã€‚å¦‚æœä¸º Noneï¼Œåˆ™é¢„æµ‹ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

+   `top_k` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 100) â€” åœ¨é€šè¿‡é˜ˆå€¼è¿‡æ»¤ä¹‹å‰ä»…ä¿ç•™å‰ k ä¸ªè¾¹ç•Œæ¡†ã€‚

è¿”å›

`List[Dict]`

ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«æ¨¡å‹é¢„æµ‹çš„æ‰¹æ¬¡ä¸­æ¯ä¸ªå›¾åƒçš„åˆ†æ•°ã€æ ‡ç­¾å’Œæ¡†ã€‚

å°† [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection) çš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºæœ€ç»ˆçš„è¾¹ç•Œæ¡†ï¼Œæ ¼å¼ä¸º (å·¦ä¸Šè§’ x åæ ‡, å·¦ä¸Šè§’ y åæ ‡, å³ä¸‹è§’ x åæ ‡, å³ä¸‹è§’ y åæ ‡)ã€‚ä»…æ”¯æŒ PyTorchã€‚

## DeformableDetrFeatureExtractor

### `class transformers.DeformableDetrFeatureExtractor`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/feature_extraction_deformable_detr.py#L36)

```py
( *args **kwargs )
```

#### `__call__`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/image_processing_utils.py#L550)

```py
( images **kwargs )
```

é¢„å¤„ç†å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡ã€‚

#### `post_process_object_detection`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/image_processing_deformable_detr.py#L1373)

```py
( outputs threshold: float = 0.5 target_sizes: Union = None top_k: int = 100 ) â†’ export const metadata = 'undefined';List[Dict]
```

å‚æ•°

+   `outputs` (`DetrObjectDetectionOutput`) â€” æ¨¡å‹çš„åŸå§‹è¾“å‡ºã€‚

+   `threshold` (`float`, *å¯é€‰*) â€” ä¿ç•™ç›®æ ‡æ£€æµ‹é¢„æµ‹çš„åˆ†æ•°é˜ˆå€¼ã€‚

+   `target_sizes` (`torch.Tensor` æˆ– `List[Tuple[int, int]]`, *å¯é€‰*) â€” å½¢çŠ¶ä¸º `(batch_size, 2)` çš„å¼ é‡æˆ–åŒ…å«æ‰¹æ¬¡ä¸­æ¯ä¸ªå›¾åƒç›®æ ‡å¤§å° (é«˜åº¦, å®½åº¦) çš„å…ƒç»„åˆ—è¡¨ (`Tuple[int, int]`)ã€‚å¦‚æœä¸º Noneï¼Œåˆ™é¢„æµ‹ä¸ä¼šè¢«è°ƒæ•´å¤§å°ã€‚

+   `top_k` (`int`, *å¯é€‰*, é»˜è®¤ä¸º 100) â€” åœ¨é€šè¿‡é˜ˆå€¼è¿‡æ»¤ä¹‹å‰ä»…ä¿ç•™å‰ k ä¸ªè¾¹ç•Œæ¡†ã€‚

è¿”å›

`List[Dict]`

ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«æ¨¡å‹é¢„æµ‹çš„æ‰¹æ¬¡ä¸­æ¯ä¸ªå›¾åƒçš„åˆ†æ•°ã€æ ‡ç­¾å’Œæ¡†ã€‚

å°† [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection) çš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºæœ€ç»ˆçš„è¾¹ç•Œæ¡†ï¼Œæ ¼å¼ä¸º (å·¦ä¸Šè§’ x åæ ‡, å·¦ä¸Šè§’ y åæ ‡, å³ä¸‹è§’ x åæ ‡, å³ä¸‹è§’ y åæ ‡)ã€‚ä»…æ”¯æŒ PyTorchã€‚

## DeformableDetrConfig

### `class transformers.DeformableDetrConfig`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/configuration_deformable_detr.py#L30)

```py
( use_timm_backbone = True backbone_config = None num_channels = 3 num_queries = 300 max_position_embeddings = 1024 encoder_layers = 6 encoder_ffn_dim = 1024 encoder_attention_heads = 8 decoder_layers = 6 decoder_ffn_dim = 1024 decoder_attention_heads = 8 encoder_layerdrop = 0.0 is_encoder_decoder = True activation_function = 'relu' d_model = 256 dropout = 0.1 attention_dropout = 0.0 activation_dropout = 0.0 init_std = 0.02 init_xavier_std = 1.0 return_intermediate = True auxiliary_loss = False position_embedding_type = 'sine' backbone = 'resnet50' use_pretrained_backbone = True dilation = False num_feature_levels = 4 encoder_n_points = 4 decoder_n_points = 4 two_stage = False two_stage_num_proposals = 300 with_box_refine = False class_cost = 1 bbox_cost = 5 giou_cost = 2 mask_loss_coefficient = 1 dice_loss_coefficient = 1 bbox_loss_coefficient = 5 giou_loss_coefficient = 2 eos_coefficient = 0.1 focal_alpha = 0.25 disable_custom_kernels = False **kwargs )
```

å‚æ•°

+   `use_timm_backbone` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦ä½¿ç”¨ `timm` åº“ä½œä¸ºéª¨å¹²ç½‘ç»œã€‚å¦‚æœè®¾ç½®ä¸º `False`ï¼Œå°†ä½¿ç”¨ `AutoBackbone` APIã€‚

+   `backbone_config` (`PretrainedConfig` or `dict`, *optional*) â€” éª¨å¹²æ¨¡å‹çš„é…ç½®ã€‚ä»…åœ¨ `use_timm_backbone` è®¾ç½®ä¸º `False` æ—¶ä½¿ç”¨ï¼Œæ­¤æ—¶é»˜è®¤ä¸º `ResNetConfig()`ã€‚

+   `num_channels` (`int`, *optional*, defaults to 3) â€” è¾“å…¥é€šé“æ•°ã€‚

+   `num_queries` (`int`, *optional*, defaults to 300) â€” å¯¹è±¡æŸ¥è¯¢çš„æ•°é‡ï¼Œå³æ£€æµ‹æ§½ä½ã€‚è¿™æ˜¯ [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel) åœ¨å•ä¸ªå›¾åƒä¸­å¯ä»¥æ£€æµ‹åˆ°çš„å¯¹è±¡çš„æœ€å¤§æ•°é‡ã€‚å¦‚æœå°† `two_stage` è®¾ç½®ä¸º `True`ï¼Œåˆ™ä½¿ç”¨ `two_stage_num_proposals`ã€‚

+   `d_model` (`int`, *optional*, defaults to 256) â€” å±‚çš„ç»´åº¦ã€‚

+   `encoder_layers` (`int`, *optional*, defaults to 6) â€” ç¼–ç å™¨å±‚æ•°ã€‚

+   `decoder_layers` (`int`, *optional*, defaults to 6) â€” è§£ç å™¨å±‚æ•°ã€‚

+   `encoder_attention_heads` (`int`, *optional*, defaults to 8) â€” Transformer ç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `decoder_attention_heads` (`int`, *optional*, defaults to 8) â€” Transformer è§£ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¤´æ•°ã€‚

+   `decoder_ffn_dim` (`int`, *optional*, defaults to 1024) â€” è§£ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚

+   `encoder_ffn_dim` (`int`, *optional*, defaults to 1024) â€” è§£ç å™¨ä¸­â€œä¸­é—´â€ï¼ˆé€šå¸¸ç§°ä¸ºå‰é¦ˆï¼‰å±‚çš„ç»´åº¦ã€‚

+   `activation_function` (`str` or `function`, *optional*, defaults to `"relu"`) â€” ç¼–ç å™¨å’Œæ± åŒ–å±‚ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ”¯æŒ `"gelu"`ã€`"relu"`ã€`"silu"` å’Œ `"gelu_new"`ã€‚

+   `dropout` (`float`, *optional*, defaults to 0.1) â€” åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œæ± åŒ–å±‚ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚çš„ä¸¢å¤±æ¦‚ç‡ã€‚

+   `attention_dropout` (`float`, *optional*, defaults to 0.0) â€” æ³¨æ„åŠ›æ¦‚ç‡çš„ä¸¢å¤±æ¯”ç‡ã€‚

+   `activation_dropout` (`float`, *optional*, defaults to 0.0) â€” å…¨è¿æ¥å±‚å†…æ¿€æ´»çš„ä¸¢å¤±æ¯”ç‡ã€‚

+   `init_std` (`float`, *optional*, defaults to 0.02) â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„æˆªæ–­æ­£æ€åˆå§‹åŒ–å™¨çš„æ ‡å‡†å·®ã€‚

+   `init_xavier_std` (`float`, *optional*, defaults to 1) â€” ç”¨äº HM Attention map æ¨¡å—ä¸­çš„ Xavier åˆå§‹åŒ–å¢ç›Šçš„ç¼©æ”¾å› å­ã€‚

+   `encoder_layerdrop` (`float`, *optional*, defaults to 0.0) â€” ç¼–ç å™¨çš„ LayerDrop æ¦‚ç‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[LayerDrop è®ºæ–‡](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))ã€‚

+   `auxiliary_loss` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦ä½¿ç”¨è¾…åŠ©è§£ç æŸå¤±ï¼ˆæ¯ä¸ªè§£ç å™¨å±‚çš„æŸå¤±ï¼‰ã€‚

+   `position_embedding_type` (`str`, *optional*, defaults to `"sine"`) â€” åœ¨å›¾åƒç‰¹å¾ä¹‹ä¸Šä½¿ç”¨çš„ä½ç½®åµŒå…¥ç±»å‹ã€‚å…¶ä¸­ä¹‹ä¸€æ˜¯ `"sine"` æˆ– `"learned"`ã€‚

+   `backbone` (`str`, *optional*, defaults to `"resnet50"`) â€” åœ¨ `use_timm_backbone` = `True` æ—¶è¦ä½¿ç”¨çš„å·ç§¯éª¨å¹²çš„åç§°ã€‚æ”¯æŒæ¥è‡ª timm åŒ…çš„ä»»ä½•å·ç§¯éª¨å¹²ã€‚æœ‰å…³æ‰€æœ‰å¯ç”¨æ¨¡å‹çš„åˆ—è¡¨ï¼Œè¯·å‚è§[æ­¤é¡µé¢](https://rwightman.github.io/pytorch-image-models/#load-a-pretrained-model)ã€‚

+   `use_pretrained_backbone` (`bool`, *optional*, defaults to `True`) â€” æ˜¯å¦å¯¹éª¨å¹²ç½‘ç»œä½¿ç”¨é¢„è®­ç»ƒæƒé‡ã€‚ä»…åœ¨ `use_timm_backbone` = `True` æ—¶æ”¯æŒã€‚

+   `dilation` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åœ¨æœ€åä¸€ä¸ªå·ç§¯å—ï¼ˆDC5ï¼‰ä¸­ç”¨è†¨èƒ€æ›¿æ¢æ­¥å¹…ã€‚ä»…åœ¨ `use_timm_backbone` = `True` æ—¶æ”¯æŒã€‚

+   `class_cost` (`float`, *optional*, defaults to 1) â€” åŒˆç‰™åˆ©åŒ¹é…æˆæœ¬ä¸­åˆ†ç±»é”™è¯¯çš„ç›¸å¯¹æƒé‡ã€‚

+   `bbox_cost` (`float`, *optional*, defaults to 5) â€” åŒˆç‰™åˆ©åŒ¹é…æˆæœ¬ä¸­è¾¹ç•Œæ¡†åæ ‡çš„L1è¯¯å·®çš„ç›¸å¯¹æƒé‡ã€‚

+   `giou_cost` (`float`, *optional*, defaults to 2) â€” åŒˆç‰™åˆ©åŒ¹é…æˆæœ¬ä¸­è¾¹ç•Œæ¡†å¹¿ä¹‰IoUæŸå¤±çš„ç›¸å¯¹æƒé‡ã€‚

+   `mask_loss_coefficient` (`float`, *optional*, defaults to 1) â€” å…¨æ™¯åˆ†å‰²æŸå¤±ä¸­ç„¦ç‚¹æŸå¤±çš„ç›¸å¯¹æƒé‡ã€‚

+   `dice_loss_coefficient` (`float`, *optional*, defaults to 1) â€” DICE/F-1æŸå¤±åœ¨å…¨æ™¯åˆ†å‰²æŸå¤±ä¸­çš„ç›¸å¯¹æƒé‡ã€‚

+   `bbox_loss_coefficient` (`float`, *optional*, defaults to 5) â€” ç›®æ ‡æ£€æµ‹æŸå¤±ä¸­L1è¾¹ç•Œæ¡†æŸå¤±çš„ç›¸å¯¹æƒé‡ã€‚

+   `giou_loss_coefficient` (`float`, *optional*, defaults to 2) â€” ç›®æ ‡æ£€æµ‹æŸå¤±ä¸­å¹¿ä¹‰IoUæŸå¤±çš„ç›¸å¯¹æƒé‡ã€‚

+   `eos_coefficient` (`float`, *optional*, defaults to 0.1) â€” ç›®æ ‡æ£€æµ‹æŸå¤±ä¸­â€œæ— å¯¹è±¡â€ç±»çš„ç›¸å¯¹åˆ†ç±»æƒé‡ã€‚

+   `num_feature_levels` (`int`, *optional*, defaults to 4) â€” è¾“å…¥ç‰¹å¾çº§åˆ«çš„æ•°é‡ã€‚

+   `encoder_n_points` (`int`, *optional*, defaults to 4) â€” ç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„æ¯ä¸ªç‰¹å¾çº§åˆ«ä¸­é‡‡æ ·çš„é”®çš„æ•°é‡ã€‚

+   `decoder_n_points` (`int`, *optional*, defaults to 4) â€” è§£ç å™¨ä¸­æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„æ¯ä¸ªç‰¹å¾çº§åˆ«ä¸­é‡‡æ ·çš„é”®çš„æ•°é‡ã€‚

+   `two_stage` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åº”ç”¨ä¸¤é˜¶æ®µå¯å˜å½¢DETRï¼Œå…¶ä¸­åŒºåŸŸæè®®ä¹Ÿç”±Deformable DETRçš„å˜ä½“ç”Ÿæˆï¼Œå¹¶è¿›ä¸€æ­¥è¾“å…¥è§£ç å™¨è¿›è¡Œè¿­ä»£è¾¹ç•Œæ¡†ç»†åŒ–ã€‚

+   `two_stage_num_proposals` (`int`, *optional*, defaults to 300) â€” è¦ç”Ÿæˆçš„åŒºåŸŸæè®®æ•°é‡ï¼Œå¦‚æœ`two_stage`è®¾ç½®ä¸º`True`ã€‚

+   `with_box_refine` (`bool`, *optional*, defaults to `False`) â€” æ˜¯å¦åº”ç”¨è¿­ä»£è¾¹ç•Œæ¡†ç»†åŒ–ï¼Œå…¶ä¸­æ¯ä¸ªè§£ç å™¨å±‚æ ¹æ®å‰ä¸€å±‚çš„é¢„æµ‹ç»†åŒ–è¾¹ç•Œæ¡†ã€‚

+   `focal_alpha` (`float`, *optional*, defaults to 0.25) â€” ç„¦ç‚¹æŸå¤±ä¸­çš„Alphaå‚æ•°ã€‚

+   `disable_custom_kernels` (`bool`, *optional*, defaults to `False`) â€” ç¦ç”¨è‡ªå®šä¹‰CUDAå’ŒCPUå†…æ ¸çš„ä½¿ç”¨ã€‚è¿™ä¸ªé€‰é¡¹å¯¹ONNXå¯¼å‡ºæ˜¯å¿…è¦çš„ï¼Œå› ä¸ºPyTorch ONNXå¯¼å‡ºä¸æ”¯æŒè‡ªå®šä¹‰å†…æ ¸ã€‚

è¿™æ˜¯ç”¨äºå­˜å‚¨[DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)é…ç½®çš„é…ç½®ç±»ã€‚æ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–Deformable DETRæ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨é»˜è®¤å€¼å®ä¾‹åŒ–é…ç½®å°†äº§ç”Ÿç±»ä¼¼äºDeformable DETR [SenseTime/deformable-detr](https://huggingface.co/SenseTime/deformable-detr)æ¶æ„çš„é…ç½®ã€‚

é…ç½®å¯¹è±¡ç»§æ‰¿è‡ª[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚é˜…è¯»[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)çš„æ–‡æ¡£ä»¥è·å–æ›´å¤šä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š

```py
>>> from transformers import DeformableDetrConfig, DeformableDetrModel

>>> # Initializing a Deformable DETR SenseTime/deformable-detr style configuration
>>> configuration = DeformableDetrConfig()

>>> # Initializing a model (with random weights) from the SenseTime/deformable-detr style configuration
>>> model = DeformableDetrModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## DeformableDetrModel

### `class transformers.DeformableDetrModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1445)

```py
( config: DeformableDetrConfig )
```

å‚æ•°

+   `config` ([DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)) â€” å…·æœ‰æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹ç›¸å…³çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

è£¸çš„Deformable DETRæ¨¡å‹ï¼ˆç”±éª¨å¹²å’Œç¼–ç å™¨-è§£ç å™¨Transformerç»„æˆï¼‰ï¼Œè¾“å‡ºæ²¡æœ‰ç‰¹å®šå¤´éƒ¨çš„åŸå§‹éšè—çŠ¶æ€ã€‚

æ­¤æ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æ£€æŸ¥è¶…ç±»æ–‡æ¡£ä»¥è·å–åº“ä¸ºå…¶æ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

æ­¤æ¨¡å‹ä¹Ÿæ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–æœ‰å…³ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1601)

```py
( pixel_values: FloatTensor pixel_mask: Optional = None decoder_attention_mask: Optional = None encoder_outputs: Optional = None inputs_embeds: Optional = None decoder_inputs_embeds: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModelOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values` (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`) â€” åƒç´ å€¼ã€‚é»˜è®¤æƒ…å†µä¸‹å°†å¿½ç•¥å¡«å……ã€‚

    åƒç´ å€¼å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å¾—ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[DeformableDetrImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `pixel_mask` (`torch.LongTensor` of shape `(batch_size, height, width)`, *optional*) â€” é¿å…åœ¨å¡«å……åƒç´ å€¼ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„è’™ç‰ˆã€‚è’™ç‰ˆå€¼é€‰æ‹©åœ¨`[0, 1]`èŒƒå›´å†…ï¼š

    +   å¯¹äºçœŸå®åƒç´ ä¸º1ï¼ˆå³`not masked`ï¼‰ï¼Œ

    +   å¯¹äºå¡«å……çš„åƒç´ ä¸º0ï¼ˆå³`masked`ï¼‰ã€‚

    [ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›è’™ç‰ˆï¼Ÿ](../glossary#attention-mask)

+   `decoder_attention_mask` (`torch.FloatTensor` of shape `(batch_size, num_queries)`, *optional*) â€” é»˜è®¤æƒ…å†µä¸‹ä¸ä½¿ç”¨ã€‚å¯ç”¨äºå±è”½å¯¹è±¡æŸ¥è¯¢ã€‚

+   `encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) â€” å…ƒç»„åŒ…æ‹¬(`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`) `last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*optional*)æ˜¯ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚

+   `inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’å›¾åƒçš„æ‰å¹³åŒ–è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä¼ é€’æ‰å¹³åŒ–ç‰¹å¾å›¾ï¼ˆéª¨å¹²ç½‘ç»œè¾“å‡º + æŠ•å½±å±‚è¾“å‡ºï¼‰ã€‚

+   `decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, num_queries, hidden_size)`, *optional*) â€” å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä½¿ç”¨é›¶å¼ é‡åˆå§‹åŒ–æŸ¥è¯¢ã€‚

+   `output_attentions` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§è¿”å›å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`, *optional*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

è¿”å›

`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModelOutput` æˆ– `tuple(torch.FloatTensor)`

ä¸€ä¸ª`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModelOutput`æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’äº†`return_dict=False`æˆ–`config.return_dict=False`ï¼Œåˆ™åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)ï¼‰å’Œè¾“å…¥çš„å„ç§å…ƒç´ ã€‚

+   `init_reference_points` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`) â€” é€šè¿‡Transformerè§£ç å™¨å‘é€çš„åˆå§‹å‚è€ƒç‚¹ã€‚

+   `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_queries, hidden_size)`) â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„è¾“å‡ºä¸­çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `intermediate_hidden_states` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, config.decoder_layers, num_queries, hidden_size)`) â€” å †å çš„ä¸­é—´éšè—çŠ¶æ€ï¼ˆè§£ç å™¨æ¯å±‚çš„è¾“å‡ºï¼‰ã€‚

+   `intermediate_reference_points` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, config.decoder_layers, num_queries, 4)`) â€” å †å çš„ä¸­é—´å‚è€ƒç‚¹ï¼ˆè§£ç å™¨æ¯å±‚çš„å‚è€ƒç‚¹ï¼‰ã€‚

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” æ¯ä¸ªå±‚çš„å½¢çŠ¶ä¸º`(batch_size, num_queries, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚è§£ç å™¨åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºåŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºçš„éšè—çŠ¶æ€ã€‚

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” æ¯ä¸ªå±‚çš„å½¢çŠ¶ä¸º`(batch_size, num_heads, num_queries, num_queries)`çš„`torch.FloatTensor`å…ƒç»„ã€‚è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” æ¯ä¸ªå±‚çš„å½¢çŠ¶ä¸º`(batch_size, num_queries, num_heads, 4, 4)`çš„`torch.FloatTensor`å…ƒç»„ã€‚è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `encoder_last_hidden_state` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*optional*) â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” æ¯ä¸ªå±‚çš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`çš„`torch.FloatTensor`å…ƒç»„ã€‚ç¼–ç å™¨åœ¨æ¯ä¸ªå±‚çš„è¾“å‡ºåŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºçš„éšè—çŠ¶æ€ã€‚

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” æ¯ä¸ªå±‚çš„å½¢çŠ¶ä¸º`(batch_size, num_queries, num_heads, 4, 4)`çš„`torch.FloatTensor`å…ƒç»„ã€‚ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `enc_outputs_class` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, config.num_labels)`ï¼Œ*optional*ï¼Œå½“`config.with_box_refine=True`å’Œ`config.two_stage=True`æ—¶è¿”å›) â€” é¢„æµ‹çš„è¾¹ç•Œæ¡†åˆ†æ•°ï¼Œç¬¬ä¸€é˜¶æ®µé€‰æ‹©å‰`config.two_stage_num_proposals`ä¸ªå¾—åˆ†æœ€é«˜çš„è¾¹ç•Œæ¡†ä½œä¸ºåŒºåŸŸæè®®ã€‚è¾¹ç•Œæ¡†äºŒå…ƒåˆ†ç±»çš„è¾“å‡ºï¼ˆå³å‰æ™¯å’ŒèƒŒæ™¯ï¼‰ã€‚

+   `enc_outputs_coord_logits` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, 4)`ï¼Œ*optional*ï¼Œå½“`config.with_box_refine=True`å’Œ`config.two_stage=True`æ—¶è¿”å›) â€” ç¬¬ä¸€é˜¶æ®µé¢„æµ‹çš„è¾¹ç•Œæ¡†åæ ‡çš„logitsã€‚

[DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)çš„forwardæ–¹æ³•ï¼Œè¦†ç›–äº†`__call__`ç‰¹æ®Šæ–¹æ³•ã€‚

è™½ç„¶å‰å‘ä¼ é€’çš„æ–¹æ³•éœ€è¦åœ¨æ­¤å‡½æ•°å†…å®šä¹‰ï¼Œä½†åº”è¯¥åœ¨æ­¤ä¹‹åè°ƒç”¨`Module`å®ä¾‹ï¼Œè€Œä¸æ˜¯åœ¨æ­¤å¤„è°ƒç”¨ï¼Œå› ä¸ºå‰è€…è´Ÿè´£è¿è¡Œé¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ï¼Œè€Œåè€…ä¼šé»˜é»˜åœ°å¿½ç•¥å®ƒä»¬ã€‚

ç¤ºä¾‹:

```py
>>> from transformers import AutoImageProcessor, DeformableDetrModel
>>> from PIL import Image
>>> import requests

>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> image_processor = AutoImageProcessor.from_pretrained("SenseTime/deformable-detr")
>>> model = DeformableDetrModel.from_pretrained("SenseTime/deformable-detr")

>>> inputs = image_processor(images=image, return_tensors="pt")

>>> outputs = model(**inputs)

>>> last_hidden_states = outputs.last_hidden_state
>>> list(last_hidden_states.shape)
[1, 300, 256]
```

## DeformableDetrForObjectDetection

### `class transformers.DeformableDetrForObjectDetection`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1802)

```py
( config: DeformableDetrConfig )
```

å‚æ•°

+   `config` ([DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)) â€” åŒ…å«æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¨¡å‹é…ç½®ç±»ã€‚ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ä¸ä¼šåŠ è½½ä¸æ¨¡å‹å…³è”çš„æƒé‡ï¼ŒåªåŠ è½½é…ç½®ã€‚æŸ¥çœ‹[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æ–¹æ³•ä»¥åŠ è½½æ¨¡å‹æƒé‡ã€‚

Deformable DETRæ¨¡å‹ï¼ˆç”±éª¨å¹²å’Œç¼–ç å™¨-è§£ç å™¨Transformerç»„æˆï¼‰ï¼Œé¡¶éƒ¨å¸¦æœ‰ç›®æ ‡æ£€æµ‹å¤´ï¼Œç”¨äºè¯¸å¦‚COCOæ£€æµ‹çš„ä»»åŠ¡ã€‚

è¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ª[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)ã€‚æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ï¼Œäº†è§£åº“ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ã€è°ƒæ•´è¾“å…¥åµŒå…¥ã€ä¿®å‰ªå¤´ç­‰ï¼‰ã€‚

è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)çš„å­ç±»ã€‚å°†å…¶ç”¨ä½œå¸¸è§„çš„PyTorchæ¨¡å—ï¼Œå¹¶å‚è€ƒPyTorchæ–‡æ¡£ä»¥è·å–ä¸ä¸€èˆ¬ç”¨æ³•å’Œè¡Œä¸ºç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚

#### `forward`

[<æ¥æº>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deformable_detr/modeling_deformable_detr.py#L1863)

```py
( pixel_values: FloatTensor pixel_mask: Optional = None decoder_attention_mask: Optional = None encoder_outputs: Optional = None inputs_embeds: Optional = None decoder_inputs_embeds: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) â†’ export const metadata = 'undefined';transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrObjectDetectionOutput or tuple(torch.FloatTensor)
```

å‚æ•°

+   `pixel_values` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_channels, height, width)`) â€” åƒç´ å€¼ã€‚é»˜è®¤æƒ…å†µä¸‹å°†å¿½ç•¥å¡«å……ã€‚

    åƒç´ å€¼å¯ä»¥ä½¿ç”¨[AutoImageProcessor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor)è·å–ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[DeformableDetrImageProcessor.`call`()](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor.__call__)ã€‚

+   `pixel_mask` (`torch.LongTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, height, width)`ï¼Œ*å¯é€‰*) â€” ç”¨äºé¿å…åœ¨å¡«å……åƒç´ å€¼ä¸Šæ‰§è¡Œæ³¨æ„åŠ›çš„æ©ç ã€‚é€‰æ‹©çš„æ©ç å€¼åœ¨`[0, 1]`ä¸­ã€‚

    +   1è¡¨ç¤ºçœŸå®åƒç´ ï¼ˆå³`æœªå±è”½`ï¼‰ï¼Œ

    +   0è¡¨ç¤ºå¡«å……åƒç´ ï¼ˆå³`masked`ï¼‰ã€‚

    [ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æ©ç ï¼Ÿ](../glossary#attention-mask)

+   `decoder_attention_mask` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_queries)`ï¼Œ*å¯é€‰*) â€” é»˜è®¤æƒ…å†µä¸‹ä¸ä½¿ç”¨ã€‚å¯ç”¨äºå±è”½å¯¹è±¡æŸ¥è¯¢ã€‚

+   `encoder_outputs` (`tuple(tuple(torch.FloatTensor)`ï¼Œ*å¯é€‰*) â€” å…ƒç»„åŒ…å«(`last_hidden_state`ï¼Œ*å¯é€‰*: `hidden_states`ï¼Œ*å¯é€‰*: `attentions`)ï¼Œ`last_hidden_state`çš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*)æ˜¯ç¼–ç å™¨æœ€åä¸€å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åºåˆ—ã€‚ç”¨äºè§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›ã€‚

+   `inputs_embeds` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, sequence_length, hidden_size)`ï¼Œ*å¯é€‰*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’æ‰å¹³åŒ–çš„ç‰¹å¾å›¾ï¼ˆéª¨å¹²+æŠ•å½±å±‚çš„è¾“å‡ºï¼‰ï¼Œè€Œä¸æ˜¯ä¼ é€’å›¾åƒçš„æ‰å¹³åŒ–è¡¨ç¤ºã€‚

+   `decoder_inputs_embeds` (`torch.FloatTensor`ï¼Œå½¢çŠ¶ä¸º`(batch_size, num_queries, hidden_size)`ï¼Œ*å¯é€‰*) â€” å¯é€‰åœ°ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åµŒå…¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ä½¿ç”¨é›¶å¼ é‡åˆå§‹åŒ–æŸ¥è¯¢ã€‚

+   `output_attentions` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›å¼ é‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›çš„å¼ é‡ä¸‹çš„`attentions`ã€‚

+   `output_hidden_states` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›æ‰€æœ‰å±‚çš„éšè—çŠ¶æ€ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¿”å›çš„å¼ é‡ä¸‹çš„`hidden_states`ã€‚

+   `return_dict` (`bool`ï¼Œ*å¯é€‰*) â€” æ˜¯å¦è¿”å›[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)è€Œä¸æ˜¯æ™®é€šå…ƒç»„ã€‚

+   `labels` (`List[Dict]` of len `(batch_size,)`, *optional*) â€” ç”¨äºè®¡ç®—äºŒéƒ¨åŒ¹é…æŸå¤±çš„æ ‡ç­¾ã€‚å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸è‡³å°‘åŒ…å«ä»¥ä¸‹2ä¸ªé”®ï¼š'class_labels'å’Œ'boxes'ï¼ˆåˆ†åˆ«æ˜¯æ‰¹å¤„ç†ä¸­å›¾åƒçš„ç±»æ ‡ç­¾å’Œè¾¹ç•Œæ¡†ï¼‰ã€‚ç±»æ ‡ç­¾æœ¬èº«åº”è¯¥æ˜¯é•¿åº¦ä¸º`(å›¾åƒä¸­è¾¹ç•Œæ¡†çš„æ•°é‡,)`çš„`torch.LongTensor`ï¼Œè€Œè¾¹ç•Œæ¡†åº”è¯¥æ˜¯å½¢çŠ¶ä¸º`(å›¾åƒä¸­è¾¹ç•Œæ¡†çš„æ•°é‡, 4)`çš„`torch.FloatTensor`ã€‚

è¿”å›

`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrObjectDetectionOutput` æˆ– `tuple(torch.FloatTensor)`

ä¸€ä¸ª`transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrObjectDetectionOutput`æˆ–ä¸€ä¸ª`torch.FloatTensor`å…ƒç»„ï¼ˆå¦‚æœä¼ é€’`return_dict=False`æˆ–`config.return_dict=False`ï¼‰åŒ…å«æ ¹æ®é…ç½®ï¼ˆ[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)ï¼‰å’Œè¾“å…¥è€Œå¼‚çš„å„ç§å…ƒç´ ã€‚

+   `loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, å½“æä¾›`labels`æ—¶è¿”å›) â€” ä½œä¸ºè´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆäº¤å‰ç†µï¼‰å’Œè¾¹ç•Œæ¡†æŸå¤±çš„çº¿æ€§ç»„åˆçš„æ€»æŸå¤±ã€‚åè€…è¢«å®šä¹‰ä¸ºL1æŸå¤±å’Œå¹¿ä¹‰æ¯”ä¾‹ä¸å˜IoUæŸå¤±çš„çº¿æ€§ç»„åˆã€‚

+   `loss_dict` (`Dict`, *optional*) â€” åŒ…å«å„ä¸ªæŸå¤±çš„å­—å…¸ã€‚ç”¨äºè®°å½•æ—¥å¿—ã€‚

+   `logits` (`torch.FloatTensor` of shape `(batch_size, num_queries, num_classes + 1)`) â€” æ‰€æœ‰æŸ¥è¯¢çš„åˆ†ç±»logitsï¼ˆåŒ…æ‹¬æ— å¯¹è±¡ï¼‰ã€‚

+   `pred_boxes` (`torch.FloatTensor` of shape `(batch_size, num_queries, 4)`) â€” æ‰€æœ‰æŸ¥è¯¢çš„è§„èŒƒåŒ–æ¡†åæ ‡ï¼Œè¡¨ç¤ºä¸ºï¼ˆä¸­å¿ƒ_xï¼Œä¸­å¿ƒ_yï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰ã€‚è¿™äº›å€¼åœ¨[0, 1]èŒƒå›´å†…è¿›è¡Œäº†è§„èŒƒåŒ–ï¼Œç›¸å¯¹äºæ‰¹å¤„ç†ä¸­æ¯ä¸ªå•ç‹¬å›¾åƒçš„å¤§å°ï¼ˆå¿½ç•¥å¯èƒ½çš„å¡«å……ï¼‰ã€‚æ‚¨å¯ä»¥ä½¿ç”¨`~DeformableDetrProcessor.post_process_object_detection`æ¥æ£€ç´¢æœªè§„èŒƒåŒ–çš„è¾¹ç•Œæ¡†ã€‚

+   `auxiliary_outputs` (`list[Dict]`, *optional*) â€” å¯é€‰ï¼Œä»…åœ¨æ¿€æ´»è¾…åŠ©æŸå¤±ï¼ˆå³`config.auxiliary_loss`è®¾ç½®ä¸º`True`ï¼‰å¹¶æä¾›æ ‡ç­¾æ—¶è¿”å›ã€‚è¿™æ˜¯ä¸€ä¸ªåŒ…å«æ¯ä¸ªè§£ç å™¨å±‚çš„ä¸Šè¿°ä¸¤ä¸ªé”®ï¼ˆ`logits`å’Œ`pred_boxes`ï¼‰çš„å­—å…¸åˆ—è¡¨ã€‚

+   `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, num_queries, hidden_size)`, *optional*) â€” æ¨¡å‹è§£ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_hidden_states=True`æˆ–`config.output_hidden_states=True`æ—¶è¿”å›) â€” ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«å½¢çŠ¶ä¸º`(batch_size, num_queries, hidden_size)`çš„`torch.FloatTensor`ï¼ˆä¸€ä¸ªç”¨äºåµŒå…¥è¾“å‡ºï¼Œä¸€ä¸ªç”¨äºæ¯å±‚è¾“å‡ºï¼‰ã€‚è§£ç å™¨åœ¨æ¯å±‚è¾“å‡ºçš„éšè—çŠ¶æ€åŠ ä¸Šåˆå§‹åµŒå…¥è¾“å‡ºã€‚

+   `decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«å½¢çŠ¶ä¸º`(batch_size, num_heads, num_queries, num_queries)`çš„`torch.FloatTensor`ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, å½“ä¼ é€’`output_attentions=True`æˆ–`config.output_attentions=True`æ—¶è¿”å›) â€” ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«å½¢çŠ¶ä¸º`(batch_size, num_queries, num_heads, 4, 4)`çš„`torch.FloatTensor`ï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ã€‚è§£ç å™¨çš„äº¤å‰æ³¨æ„åŠ›å±‚çš„æ³¨æ„åŠ›æƒé‡ï¼Œåœ¨æ³¨æ„åŠ›softmaxä¹‹åï¼Œç”¨äºè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¤´ä¸­çš„åŠ æƒå¹³å‡å€¼ã€‚

+   `encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) â€” æ¨¡å‹ç¼–ç å™¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€åºåˆ—ã€‚

+   `encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) â€” Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`. Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.

+   `encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) â€” Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, sequence_length, num_heads, 4, 4)`. Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the self-attention heads.

+   `intermediate_hidden_states` (`torch.FloatTensor` of shape `(batch_size, config.de`
