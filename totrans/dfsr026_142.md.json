["```py\n>>> import PIL\n>>> import requests\n>>> import torch\n>>> from io import BytesIO\n\n>>> from diffusers import StableDiffusionDiffEditPipeline\n\n>>> def download_image(url):\n...     response = requests.get(url)\n...     return PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")\n\n>>> img_url = \"https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png\"\n\n>>> init_image = download_image(img_url).resize((768, 768))\n\n>>> pipe = StableDiffusionDiffEditPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)\n>>> pipeline.inverse_scheduler = DDIMInverseScheduler.from_config(pipeline.scheduler.config)\n>>> pipeline.enable_model_cpu_offload()\n\n>>> mask_prompt = \"A bowl of fruits\"\n>>> prompt = \"A bowl of pears\"\n\n>>> mask_image = pipe.generate_mask(image=init_image, source_prompt=prompt, target_prompt=mask_prompt)\n>>> image_latents = pipe.invert(image=init_image, prompt=mask_prompt).latents\n>>> image = pipe(prompt=prompt, mask_image=mask_image, image_latents=image_latents).images[0]\n```", "```py\n>>> import PIL\n>>> import requests\n>>> import torch\n>>> from io import BytesIO\n\n>>> from diffusers import StableDiffusionDiffEditPipeline\n\n>>> def download_image(url):\n...     response = requests.get(url)\n...     return PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")\n\n>>> img_url = \"https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png\"\n\n>>> init_image = download_image(img_url).resize((768, 768))\n\n>>> pipe = StableDiffusionDiffEditPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)\n>>> pipeline.inverse_scheduler = DDIMInverseScheduler.from_config(pipeline.scheduler.config)\n>>> pipeline.enable_model_cpu_offload()\n\n>>> prompt = \"A bowl of fruits\"\n\n>>> inverted_latents = pipe.invert(image=init_image, prompt=prompt).latents\n```", "```py\n>>> import PIL\n>>> import requests\n>>> import torch\n>>> from io import BytesIO\n\n>>> from diffusers import StableDiffusionDiffEditPipeline\n\n>>> def download_image(url):\n...     response = requests.get(url)\n...     return PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")\n\n>>> img_url = \"https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png\"\n\n>>> init_image = download_image(img_url).resize((768, 768))\n\n>>> pipe = StableDiffusionDiffEditPipeline.from_pretrained(\n...     \"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16\n... )\n>>> pipe = pipe.to(\"cuda\")\n\n>>> pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)\n>>> pipeline.inverse_scheduler = DDIMInverseScheduler.from_config(pipeline.scheduler.config)\n>>> pipeline.enable_model_cpu_offload()\n\n>>> mask_prompt = \"A bowl of fruits\"\n>>> prompt = \"A bowl of pears\"\n\n>>> mask_image = pipe.generate_mask(image=init_image, source_prompt=prompt, target_prompt=mask_prompt)\n>>> image_latents = pipe.invert(image=init_image, prompt=mask_prompt).latents\n>>> image = pipe(prompt=prompt, mask_image=mask_image, image_latents=image_latents).images[0]\n```"]