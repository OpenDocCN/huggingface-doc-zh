- en: Process image data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/datasets/image_process](https://huggingface.co/docs/datasets/image_process)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/datasets/v2.17.0/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/entry/start.146395b0.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/scheduler.bdbef820.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/singletons.98dc5b8b.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/index.8a885b74.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/paths.a483fec8.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/entry/app.e612c4fb.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/index.c0aea24a.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/nodes/0.5e8dbda6.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/nodes/26.b7a8bbc2.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/Tip.31005f7d.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/CodeBlock.6ccca92e.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/Heading.2eb892cb.js">
  prefs: []
  type: TYPE_NORMAL
- en: 'This guide shows specific methods for processing image datasets. Learn how
    to:'
  prefs: []
  type: TYPE_NORMAL
- en: Use [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    with image dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply data augmentations to a dataset with [set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a guide on how to process any type of dataset, take a look at the [general
    process guide](./process).
  prefs: []
  type: TYPE_NORMAL
- en: Map
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    function can apply transforms over an entire dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, create a basic [`Resize`](https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html)
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now use the [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    function to resize the entire dataset, and set `batched=True` to speed up the
    process by accepting batches of examples. The transform returns `pixel_values`
    as a cacheable `PIL.Image` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The cache file saves time because you donâ€™t have to execute the same transform
    twice. The [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    function is best for operations you only run once per training - like resizing
    an image - instead of using it for operations executed for each epoch, like data
    augmentations.
  prefs: []
  type: TYPE_NORMAL
- en: '[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    takes up some memory, but you can reduce its memory requirements with the following
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[`batch_size`](./package_reference/main_classes#datasets.DatasetDict.map.batch_size)
    determines the number of examples that are processed in one call to the transform
    function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`writer_batch_size`](./package_reference/main_classes#datasets.DatasetDict.map.writer_batch_size)
    determines the number of processed examples that are kept in memory before they
    are stored away.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both parameter values default to 1000, which can be expensive if you are storing
    images. Lower these values to use less memory when you use [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map).
  prefs: []
  type: TYPE_NORMAL
- en: Apply transforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ðŸ¤— Datasets applies data augmentations from any library or package to your dataset.
    Transforms can be applied on-the-fly on batches of data with [set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform),
    which consumes less disk space.
  prefs: []
  type: TYPE_NORMAL
- en: The following example uses [torchvision](https://pytorch.org/vision/stable/index.html),
    but feel free to use other data augmentation libraries like [Albumentations](https://albumentations.ai/docs/),
    [Kornia](https://kornia.readthedocs.io/en/latest/), and [imgaug](https://imgaug.readthedocs.io/en/latest/).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if youâ€™d like to change the color properties of an image randomly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a function to apply the `ColorJitter` transform:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the transform with the [set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform)
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
