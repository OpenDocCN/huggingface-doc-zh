# T2I-Adapter

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/training/t2i_adapters](https://huggingface.co/docs/diffusers/training/t2i_adapters)

[T2I-Adapter](https://hf.co/papers/2302.08453) æ˜¯ä¸€ä¸ªè½»é‡çº§çš„é€‚é…å™¨æ¨¡å‹ï¼Œæä¾›é¢å¤–çš„æ¡ä»¶è¾“å…¥å›¾åƒï¼ˆçº¿æ¡è‰ºæœ¯ã€cannyã€ç´ æã€æ·±åº¦ã€å§¿åŠ¿ï¼‰ä»¥æ›´å¥½åœ°æ§åˆ¶å›¾åƒç”Ÿæˆã€‚å®ƒç±»ä¼¼äº ControlNetï¼Œä½†æ›´å°ï¼ˆ~77M å‚æ•°å’Œ ~300MB æ–‡ä»¶å¤§å°ï¼‰ï¼Œå› ä¸ºå®ƒåªå‘ UNet æ’å…¥æƒé‡ï¼Œè€Œä¸æ˜¯å¤åˆ¶å’Œè®­ç»ƒå®ƒã€‚

T2I-Adapter ä»…é€‚ç”¨äºä½¿ç”¨ Stable Diffusion XL (SDXL) æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚

æœ¬æŒ‡å—å°†æ¢è®¨ [train_t2i_adapter_sdxl.py](https://github.com/huggingface/diffusers/blob/main/examples/t2i_adapter/train_t2i_adapter_sdxl.py) è®­ç»ƒè„šæœ¬ï¼Œå¸®åŠ©æ‚¨ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•ä¸ºè‡ªå·±çš„ç”¨ä¾‹è¿›è¡Œé€‚åº”ã€‚

åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä»æºä»£ç å®‰è£…åº“ï¼š

```py
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```

ç„¶åå¯¼èˆªåˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶å®‰è£…æ‚¨æ­£åœ¨ä½¿ç”¨çš„è„šæœ¬æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š

```py
cd examples/t2i_adapter
pip install -r requirements.txt
```

ğŸ¤— Accelerate æ˜¯ä¸€ä¸ªå¸®åŠ©æ‚¨åœ¨å¤šä¸ª GPU/TPU æˆ–æ··åˆç²¾åº¦ä¸‹è®­ç»ƒçš„åº“ã€‚å®ƒä¼šæ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚æŸ¥çœ‹ ğŸ¤— Accelerate [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour) ä»¥äº†è§£æ›´å¤šã€‚

åˆå§‹åŒ–ä¸€ä¸ª ğŸ¤— Accelerate ç¯å¢ƒï¼š

```py
accelerate config
```

è¦è®¾ç½®ä¸€ä¸ªé»˜è®¤çš„ ğŸ¤— Accelerate ç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š

```py
accelerate config default
```

æˆ–è€…å¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼ shellï¼Œæ¯”å¦‚ç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

æœ€åï¼Œå¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹ [åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†](create_dataset) æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚

ä»¥ä¸‹éƒ¨åˆ†çªå‡ºæ˜¾ç¤ºäº†è®­ç»ƒè„šæœ¬ä¸­é‡è¦çš„éƒ¨åˆ†ï¼Œä»¥å¸®åŠ©æ‚¨äº†è§£å¦‚ä½•ä¿®æ”¹å®ƒï¼Œä½†å¹¶æœªè¯¦ç»†æ¶µç›–è„šæœ¬çš„æ¯ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·éšæ—¶é˜…è¯» [è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/t2i_adapter/train_t2i_adapter_sdxl.py)ï¼Œå¹¶å‘Šè¯‰æˆ‘ä»¬æ‚¨æ˜¯å¦æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ã€‚

## è„šæœ¬å‚æ•°

è®­ç»ƒè„šæœ¬æä¾›äº†è®¸å¤šå‚æ•°ï¼Œå¸®åŠ©æ‚¨è‡ªå®šä¹‰è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°éƒ½å¯ä»¥åœ¨ [`parse_args()`](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L233) å‡½æ•°ä¸­æ‰¾åˆ°ã€‚å®ƒä¸ºæ¯ä¸ªå‚æ•°æä¾›äº†é»˜è®¤å€¼ï¼Œå¦‚è®­ç»ƒæ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œä½†å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚

ä¾‹å¦‚ï¼Œè¦æ¿€æ´»æ¢¯åº¦ç´¯ç§¯ï¼Œå°† `--gradient_accumulation_steps` å‚æ•°æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ï¼š

```py
accelerate launch train_t2i_adapter_sdxl.py \
  ----gradient_accumulation_steps=4
```

è®¸å¤šåŸºæœ¬å’Œé‡è¦çš„å‚æ•°åœ¨ [Text-to-image](text2image#script-parameters) è®­ç»ƒæŒ‡å—ä¸­æœ‰æè¿°ï¼Œå› æ­¤æœ¬æŒ‡å—åªå…³æ³¨ç›¸å…³çš„ T2I-Adapter å‚æ•°ï¼š

+   `--pretrained_vae_model_name_or_path`ï¼šé¢„è®­ç»ƒ VAE çš„è·¯å¾„ï¼›SDXL VAE å·²çŸ¥å­˜åœ¨æ•°å€¼ä¸ç¨³å®šæ€§é—®é¢˜ï¼Œå› æ­¤æ­¤å‚æ•°å…è®¸æ‚¨æŒ‡å®šæ›´å¥½çš„ [VAE](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)

+   `--crops_coords_top_left_h` å’Œ `--crops_coords_top_left_w`ï¼šè¦åŒ…å«åœ¨ SDXL çš„è£å‰ªåæ ‡åµŒå…¥ä¸­çš„é«˜åº¦å’Œå®½åº¦åæ ‡

+   `--conditioning_image_column`ï¼šæ•°æ®é›†ä¸­æ¡ä»¶å›¾åƒçš„åˆ—

+   `--proportion_empty_prompts`ï¼šè¦æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²çš„å›¾åƒæç¤ºçš„æ¯”ä¾‹

## è®­ç»ƒè„šæœ¬

ä¸è„šæœ¬å‚æ•°ä¸€æ ·ï¼Œ[Text-to-image](text2image#training-script) è®­ç»ƒæŒ‡å—ä¸­æä¾›äº†è®­ç»ƒè„šæœ¬çš„è¯¦ç»†è¯´æ˜ã€‚ç›¸åï¼Œæœ¬æŒ‡å—å°†æŸ¥çœ‹è„šæœ¬ä¸­ä¸ T2I-Adapter ç›¸å…³çš„éƒ¨åˆ†ã€‚

è®­ç»ƒè„šæœ¬ä»å‡†å¤‡æ•°æ®é›†å¼€å§‹ã€‚è¿™åŒ…æ‹¬[tokenizing](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L674)æç¤ºå’Œ[åº”ç”¨å˜æ¢](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L714)åˆ°å›¾åƒå’Œè°ƒèŠ‚å›¾åƒã€‚

```py
conditioning_image_transforms = transforms.Compose(
    [
        transforms.Resize(args.resolution, interpolation=transforms.InterpolationMode.BILINEAR),
        transforms.CenterCrop(args.resolution),
        transforms.ToTensor(),
    ]
)
```

åœ¨[`main()`](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L770)å‡½æ•°ä¸­ï¼ŒT2I-Adapterè¦ä¹ˆä»é¢„è®­ç»ƒçš„é€‚é…å™¨åŠ è½½ï¼Œè¦ä¹ˆéšæœºåˆå§‹åŒ–ï¼š

```py
if args.adapter_model_name_or_path:
    logger.info("Loading existing adapter weights.")
    t2iadapter = T2IAdapter.from_pretrained(args.adapter_model_name_or_path)
else:
    logger.info("Initializing t2iadapter weights.")
    t2iadapter = T2IAdapter(
        in_channels=3,
        channels=(320, 640, 1280, 1280),
        num_res_blocks=2,
        downscale_factor=16,
        adapter_type="full_adapter_xl",
    )
```

[optimizer](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L952)å·²åˆå§‹åŒ–ä¸ºT2I-Adapterå‚æ•°ï¼š

```py
params_to_optimize = t2iadapter.parameters()
optimizer = optimizer_class(
    params_to_optimize,
    lr=args.learning_rate,
    betas=(args.adam_beta1, args.adam_beta2),
    weight_decay=args.adam_weight_decay,
    eps=args.adam_epsilon,
)
```

æœ€åï¼Œåœ¨[training loop](https://github.com/huggingface/diffusers/blob/aab6de22c33cc01fb7bc81c0807d6109e2c998c9/examples/t2i_adapter/train_t2i_adapter_sdxl.py#L1086)ä¸­ï¼Œé€‚é…å™¨è°ƒèŠ‚å›¾åƒå’Œæ–‡æœ¬åµŒå…¥è¢«ä¼ é€’ç»™UNetä»¥é¢„æµ‹å™ªå£°æ®‹å·®ï¼š

```py
t2iadapter_image = batch["conditioning_pixel_values"].to(dtype=weight_dtype)
down_block_additional_residuals = t2iadapter(t2iadapter_image)
down_block_additional_residuals = [
    sample.to(dtype=weight_dtype) for sample in down_block_additional_residuals
]

model_pred = unet(
    inp_noisy_latents,
    timesteps,
    encoder_hidden_states=batch["prompt_ids"],
    added_cond_kwargs=batch["unet_added_conditions"],
    down_block_additional_residuals=down_block_additional_residuals,
).sample
```

å¦‚æœæ‚¨æƒ³äº†è§£è®­ç»ƒå¾ªç¯çš„å·¥ä½œåŸç†ï¼Œè¯·æŸ¥çœ‹[Understanding pipelines, models and schedulers](../using-diffusers/write_own_pipeline)æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹è§£æäº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚

## å¯åŠ¨è„šæœ¬

ç°åœ¨æ‚¨å·²ç»å‡†å¤‡å¥½å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€

å¯¹äºè¿™ä¸ªç¤ºä¾‹è®­ç»ƒï¼Œæ‚¨å°†ä½¿ç”¨[fusing/fill50k](https://huggingface.co/datasets/fusing/fill50k)æ•°æ®é›†ã€‚å¦‚æœæ‚¨æ„¿æ„ï¼Œæ‚¨ä¹Ÿå¯ä»¥åˆ›å»ºå¹¶ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ï¼ˆè¯·å‚é˜…[Create a dataset for training](https://moon-ci-docs.huggingface.co/docs/diffusers/pr_5512/en/training/create_dataset)æŒ‡å—ï¼‰ã€‚

å°†ç¯å¢ƒå˜é‡`MODEL_DIR`è®¾ç½®ä¸ºHubä¸Šçš„æ¨¡å‹IDæˆ–æœ¬åœ°æ¨¡å‹çš„è·¯å¾„ï¼Œå°†`OUTPUT_DIR`è®¾ç½®ä¸ºæ‚¨æƒ³è¦ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚

ä¸‹è½½ä»¥ä¸‹å›¾åƒä»¥è°ƒèŠ‚æ‚¨çš„è®­ç»ƒï¼š

```py
wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png
wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png
```

ä½¿ç”¨Weights & Biasesç›‘æ§è®­ç»ƒè¿›åº¦ï¼Œå°†`--report_to=wandb`å‚æ•°æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ã€‚æ‚¨è¿˜éœ€è¦å°†`--validation_image`ï¼Œ`--validation_prompt`å’Œ`--validation_steps`æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ä»¥è·Ÿè¸ªç»“æœã€‚è¿™å¯¹äºè°ƒè¯•æ¨¡å‹å’ŒæŸ¥çœ‹ä¸­é—´ç»“æœéå¸¸æœ‰ç”¨ã€‚

```py
export MODEL_DIR="stabilityai/stable-diffusion-xl-base-1.0"
export OUTPUT_DIR="path to save model"

accelerate launch train_t2i_adapter_sdxl.py \
 --pretrained_model_name_or_path=$MODEL_DIR \
 --output_dir=$OUTPUT_DIR \
 --dataset_name=fusing/fill50k \
 --mixed_precision="fp16" \
 --resolution=1024 \
 --learning_rate=1e-5 \
 --max_train_steps=15000 \
 --validation_image "./conditioning_image_1.png" "./conditioning_image_2.png" \
 --validation_prompt "red circle with blue background" "cyan circle with brown floral background" \
 --validation_steps=100 \
 --train_batch_size=1 \
 --gradient_accumulation_steps=4 \
 --report_to="wandb" \
 --seed=42 \
 --push_to_hub
```

è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ‚¨çš„T2I-Adapterè¿›è¡Œæ¨æ–­ã€‚

```py
from diffusers import StableDiffusionXLAdapterPipeline, T2IAdapter, EulerAncestralDiscreteSchedulerTest
from diffusers.utils import load_image
import torch

adapter = T2IAdapter.from_pretrained("path/to/adapter", torch_dtype=torch.float16)
pipeline = StableDiffusionXLAdapterPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", adapter=adapter, torch_dtype=torch.float16
)

pipeline.scheduler = EulerAncestralDiscreteSchedulerTest.from_config(pipe.scheduler.config)
pipeline.enable_xformers_memory_efficient_attention()
pipeline.enable_model_cpu_offload()

control_image = load_image("./conditioning_image_1.png")
prompt = "pale golden rod circle with old lace background"

generator = torch.manual_seed(0)
image = pipeline(
    prompt, image=control_image, generator=generator
).images[0]
image.save("./output.png")
```

## ä¸‹ä¸€æ­¥

æ­å–œæ‚¨è®­ç»ƒäº†ä¸€ä¸ªT2I-Adapteræ¨¡å‹ï¼ğŸ‰ è¦äº†è§£æ›´å¤šï¼š

+   é˜…è¯»[Efficient Controllable Generation for SDXL with T2I-Adapters](https://huggingface.co/blog/t2i-sdxl-adapters)åšæ–‡ï¼Œäº†è§£T2I-Adapterå›¢é˜Ÿçš„å®éªŒç»“æœçš„æ›´å¤šç»†èŠ‚ã€‚
