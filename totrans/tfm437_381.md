# 轨迹Transformer

> 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer)

此模型仅处于维护模式，因此我们不会接受任何更改其代码的新PR。

如果您在运行此模型时遇到任何问题，请重新安装支持此模型的最后一个版本：v4.30.0。您可以通过运行以下命令来执行：`pip install -U transformers==4.30.0`。

## 概述

轨迹Transformer模型是由Michael Janner、Qiyang Li、Sergey Levine在[离线强化学习作为一个大的序列建模问题](https://arxiv.org/abs/2106.02039)中提出的。

该论文的摘要如下：

*强化学习（RL）通常涉及估计稳态策略或单步模型，利用马尔可夫性质在时间上分解问题。然而，我们也可以将RL视为一个通用的序列建模问题，目标是产生一系列导致高奖励序列的动作。从这个角度看，我们很容易考虑高容量序列预测模型在其他领域（如自然语言处理）中的良好工作是否也可以为RL问题提供有效的解决方案。为此，我们探讨了如何使用序列建模工具来解决RL问题，使用Transformer架构来建模轨迹分布，并将波束搜索重新用作规划算法。将RL作为序列建模问题来框定简化了一系列设计决策，使我们能够摒弃许多离线RL算法中常见的组件。我们展示了这种方法在长期动态预测、模仿学习、目标条件RL和离线RL等方面的灵活性。此外，我们展示了这种方法可以与现有的无模型算法结合，产生稀疏奖励、长期视野任务中的最先进规划器。*

这个模型是由[CarlCochet](https://huggingface.co/CarlCochet)贡献的。原始代码可以在[这里](https://github.com/jannerm/trajectory-transformer)找到。

## 使用提示

这个Transformer用于深度强化学习。要使用它，您需要从所有先前时间步的动作、状态和奖励创建序列。这个模型将把所有这些元素一起视为一个大序列（一个轨迹）。

## TrajectoryTransformerConfig

### `class transformers.TrajectoryTransformerConfig`

[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deprecated/trajectory_transformer/configuration_trajectory_transformer.py#L31)

```py
( vocab_size = 100 action_weight = 5 reward_weight = 1 value_weight = 1 block_size = 249 action_dim = 6 observation_dim = 17 transition_dim = 25 n_layer = 4 n_head = 4 n_embd = 128 embd_pdrop = 0.1 attn_pdrop = 0.1 resid_pdrop = 0.1 learning_rate = 0.0006 max_position_embeddings = 512 initializer_range = 0.02 layer_norm_eps = 1e-12 kaiming_initializer_range = 1 use_cache = True pad_token_id = 1 bos_token_id = 50256 eos_token_id = 50256 **kwargs )
```

参数

+   `vocab_size`（`int`，*可选*，默认为100）—TrajectoryTransformer模型的词汇量。定义了在调用[TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel)时可以表示的`trajectories`的不同标记数量。

+   `action_weight`（`int`，*可选*，默认为5）—损失函数中动作的权重

+   `reward_weight`（`int`，*可选*，默认为1）—损失函数中奖励的权重

+   `value_weight`（`int`，*可选*，默认为1）—损失函数中值的权重

+   `block_size`（`int`，*可选*，默认为249）—轨迹Transformer中块的大小。

+   `action_dim`（`int`，*可选*，默认为6）—动作空间的维度。

+   `observation_dim`（`int`，*可选*，默认为17）—观察空间的维度。

+   `transition_dim`（`int`，*可选*，默认为25）—转换空间的维度。

+   `n_layer`（`int`，*可选*，默认为4）—Transformer编码器中的隐藏层数。

+   `n_head`（`int`，*可选*，默认为4）—Transformer编码器中每个注意力层的注意力头数。

+   `n_embd` (`int`, *optional*, defaults to 128) — 嵌入和隐藏状态的维度。

+   `resid_pdrop` (`float`, *optional*, defaults to 0.1) — 嵌入层、编码器和池化器中所有全连接层的dropout概率。

+   `embd_pdrop` (`int`, *optional*, defaults to 0.1) — 嵌入的dropout比率。

+   `attn_pdrop` (`float`, *optional*, defaults to 0.1) — 注意力的dropout比率。

+   `hidden_act` (`str` or `function`, *optional*, defaults to `"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"selu"`和`"gelu_new"`。

+   `max_position_embeddings` (`int`, *optional*, defaults to 512) — 此模型可能使用的最大序列长度。通常将其设置为较大的值以防万一（例如，512或1024或2048）。

+   `initializer_range` (`float`, *optional*, defaults to 0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。

+   `layer_norm_eps` (`float`, *optional*, defaults to 1e-12) — 层归一化层使用的epsilon。

+   `kaiming_initializer_range` (`float, *optional*, defaults to 1) — 缩放kaiming初始化器整流器的负斜率的系数，用于EinLinear层。

+   `use_cache` (`bool`, *optional*, defaults to `True`) — 模型是否应返回最后的键/值注意力（不是所有模型都使用）。仅在`config.is_decoder=True`时相关。示例 —

这是用于存储[TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel)配置的配置类。根据指定的参数实例化TrajectoryTransformer模型，定义模型架构。使用默认值实例化配置将产生类似于TrajectoryTransformer [CarlCochet/trajectory-transformer-halfcheetah-medium-v2](https://huggingface.co/CarlCochet/trajectory-transformer-halfcheetah-medium-v2)架构的配置。

配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。

```py
>>> from transformers import TrajectoryTransformerConfig, TrajectoryTransformerModel

>>> # Initializing a TrajectoryTransformer CarlCochet/trajectory-transformer-halfcheetah-medium-v2 style configuration
>>> configuration = TrajectoryTransformerConfig()

>>> # Initializing a model (with random weights) from the CarlCochet/trajectory-transformer-halfcheetah-medium-v2 style configuration
>>> model = TrajectoryTransformerModel(configuration)

>>> # Accessing the model configuration
>>> configuration = model.config
```

## TrajectoryTransformerModel

### `class transformers.TrajectoryTransformerModel`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deprecated/trajectory_transformer/modeling_trajectory_transformer.py#L399)

```py
( config )
```

参数

+   `config` ([TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig)) — 模型配置类，包含模型的所有参数。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。

裸的TrajectoryTransformer模型，输出原始隐藏状态，没有特定的头部。此模型是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。

完整的GPT语言模型，上下文大小为block_size

#### `forward`

[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/deprecated/trajectory_transformer/modeling_trajectory_transformer.py#L464)

```py
( trajectories: Optional = None past_key_values: Optional = None targets: Optional = None attention_mask: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) → export const metadata = 'undefined';transformers.models.deprecated.trajectory_transformer.modeling_trajectory_transformer.TrajectoryTransformerOutput or tuple(torch.FloatTensor)
```

参数

+   `trajectories` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) — 轨迹的批次，其中轨迹是状态、动作和奖励的序列。

+   `past_key_values` (`Tuple[Tuple[torch.Tensor]]` 长度为`config.n_layers`, *optional*) — 包含由模型计算的预先计算的隐藏状态（注意力块中的键和值）（参见下面的`past_key_values`输出）。可用于加速顺序解码。将过去给定给该模型的`input_ids`不应作为`input_ids`传递，因为它们已经计算过。

+   `targets` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*) — 用于计算损失的目标值。

+   `attention_mask` (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*) — 用于避免在填充标记索引上执行注意力的掩码。掩码值选在`[0, 1]`之间：

    +   对于未被`masked`的标记为1。

    +   对于被`masked`的标记为0。

    [什么是注意力掩码？](../glossary#attention-mask)

+   `use_cache` (`bool`, *optional*) — 如果设置为`True`，则返回`past_key_values`键值状态，可用于加速解码（参见`past_key_values`）。

+   `output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。

+   `output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。

+   `return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。

返回

`transformers.models.deprecated.trajectory_transformer.modeling_trajectory_transformer.TrajectoryTransformerOutput` 或 `tuple(torch.FloatTensor)`

一个`transformers.models.deprecated.trajectory_transformer.modeling_trajectory_transformer.TrajectoryTransformerOutput`或一个`torch.FloatTensor`的元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig)）和输入的不同元素。

+   `loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供`labels`时返回) — 语言建模损失。

+   `logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`) — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。

+   `past_key_values` (`Tuple[Tuple[torch.Tensor]]`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回) — 长度为`config.n_layers`的元组，包含形状为`(batch_size, num_heads, sequence_length, embed_size_per_head)`的张量元组。包含预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码。

+   `hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回) — 长度为2的元组，包含形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`（一个用于嵌入的输出 + 一个用于每个层的输出）。模型在每个层的输出隐藏状态加上初始嵌入输出。

+   `attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回) — 长度为每层的元组，形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`。在注意力softmax之后的GPT2Attentions权重，用于计算自注意力头中的加权平均值。

[TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel)的前向方法，覆盖了`__call__`特殊方法。

虽然前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此之后调用，因为前者负责运行前处理和后处理步骤，而后者则会默默地忽略它们。

示例：

```py
>>> from transformers import TrajectoryTransformerModel
>>> import torch

>>> model = TrajectoryTransformerModel.from_pretrained(
...     "CarlCochet/trajectory-transformer-halfcheetah-medium-v2"
... )
>>> model.to(device)
>>> model.eval()

>>> observations_dim, action_dim, batch_size = 17, 6, 256
>>> seq_length = observations_dim + action_dim + 1

>>> trajectories = torch.LongTensor([np.random.permutation(self.seq_length) for _ in range(batch_size)]).to(
...     device
... )
>>> targets = torch.LongTensor([np.random.permutation(self.seq_length) for _ in range(batch_size)]).to(device)

>>> outputs = model(
...     trajectories,
...     targets=targets,
...     use_cache=True,
...     output_attentions=True,
...     output_hidden_states=True,
...     return_dict=True,
... )
```
