["```py\n!pip install transformers datasets\n```", "```py\npip install torch\n```", "```py\npip install tensorflow\n```", "```py\n>>> from transformers import pipeline\n\n>>> classifier = pipeline(\"sentiment-analysis\")\n```", "```py\n>>> classifier(\"We are very happy to show you the \ud83e\udd17 Transformers library.\")\n[{'label': 'POSITIVE', 'score': 0.9998}]\n```", "```py\n>>> results = classifier([\"We are very happy to show you the \ud83e\udd17 Transformers library.\", \"We hope you don't hate it.\"])\n>>> for result in results:\n...     print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\nlabel: POSITIVE, with score: 0.9998\nlabel: NEGATIVE, with score: 0.5309\n```", "```py\n>>> import torch\n>>> from transformers import pipeline\n\n>>> speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")\n```", "```py\n>>> from datasets import load_dataset, Audio\n\n>>> dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n```", "```py\n>>> dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))\n```", "```py\n>>> result = speech_recognizer(dataset[:4][\"audio\"])\n>>> print([d[\"text\"] for d in result])\n['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']\n```", "```py\n>>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n```", "```py\n>>> from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n>>> model = AutoModelForSequenceClassification.from_pretrained(model_name)\n>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n```", "```py\n>>> from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n\n>>> model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n```", "```py\n>>> classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n>>> classifier(\"Nous sommes tr\u00e8s heureux de vous pr\u00e9senter la biblioth\u00e8que \ud83e\udd17 Transformers.\")\n[{'label': '5 stars', 'score': 0.7273}]\n```", "```py\n>>> from transformers import AutoTokenizer\n\n>>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n```", "```py\n>>> encoding = tokenizer(\"We are very happy to show you the \ud83e\udd17 Transformers library.\")\n>>> print(encoding)\n{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n```", "```py\n>>> pt_batch = tokenizer(\n...     [\"We are very happy to show you the \ud83e\udd17 Transformers library.\", \"We hope you don't hate it.\"],\n...     padding=True,\n...     truncation=True,\n...     max_length=512,\n...     return_tensors=\"pt\",\n... )\n```", "```py\n>>> tf_batch = tokenizer(\n...     [\"We are very happy to show you the \ud83e\udd17 Transformers library.\", \"We hope you don't hate it.\"],\n...     padding=True,\n...     truncation=True,\n...     max_length=512,\n...     return_tensors=\"tf\",\n... )\n```", "```py\n>>> from transformers import AutoModelForSequenceClassification\n\n>>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n>>> pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n```", "```py\n>>> pt_outputs = pt_model(**pt_batch)\n```", "```py\n>>> from torch import nn\n\n>>> pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n>>> print(pt_predictions)\ntensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n```", "```py\n>>> from transformers import TFAutoModelForSequenceClassification\n\n>>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n```", "```py\n>>> tf_outputs = tf_model(tf_batch)\n```", "```py\n>>> import tensorflow as tf\n\n>>> tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)\n>>> tf_predictions\n```", "```py\n>>> pt_save_directory = \"./pt_save_pretrained\"\n>>> tokenizer.save_pretrained(pt_save_directory)\n>>> pt_model.save_pretrained(pt_save_directory)\n```", "```py\n>>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n```", "```py\n>>> tf_save_directory = \"./tf_save_pretrained\"\n>>> tokenizer.save_pretrained(tf_save_directory)\n>>> tf_model.save_pretrained(tf_save_directory)\n```", "```py\n>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"./tf_save_pretrained\")\n```", "```py\n>>> from transformers import AutoModel\n\n>>> tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)\n>>> pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)\n```", "```py\n>>> from transformers import TFAutoModel\n\n>>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n```", "```py\n>>> from transformers import AutoConfig\n\n>>> my_config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", n_heads=12)\n```", "```py\n>>> from transformers import AutoModel\n\n>>> my_model = AutoModel.from_config(my_config)\n```", "```py\n>>> from transformers import TFAutoModel\n\n>>> my_model = TFAutoModel.from_config(my_config)\n```", "```py\n    >>> from transformers import AutoModelForSequenceClassification\n\n    >>> model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n    ```", "```py\n    >>> from transformers import TrainingArguments\n\n    >>> training_args = TrainingArguments(\n    ...     output_dir=\"path/to/save/folder/\",\n    ...     learning_rate=2e-5,\n    ...     per_device_train_batch_size=8,\n    ...     per_device_eval_batch_size=8,\n    ...     num_train_epochs=2,\n    ... )\n    ```", "```py\n    >>> from transformers import AutoTokenizer\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n    ```", "```py\n    >>> from datasets import load_dataset\n\n    >>> dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT\n    ```", "```py\n    >>> def tokenize_dataset(dataset):\n    ...     return tokenizer(dataset[\"text\"])\n    ```", "```py\n    >>> dataset = dataset.map(tokenize_dataset, batched=True)\n    ```", "```py\n    >>> from transformers import DataCollatorWithPadding\n\n    >>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n    ```", "```py\n>>> from transformers import Trainer\n\n>>> trainer = Trainer(\n...     model=model,\n...     args=training_args,\n...     train_dataset=dataset[\"train\"],\n...     eval_dataset=dataset[\"test\"],\n...     tokenizer=tokenizer,\n...     data_collator=data_collator,\n... )  # doctest: +SKIP\n```", "```py\n>>> trainer.train()\n```", "```py\n    >>> from transformers import TFAutoModelForSequenceClassification\n\n    >>> model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n    ```", "```py\n    >>> from transformers import AutoTokenizer\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n    ```", "```py\n    >>> def tokenize_dataset(dataset):\n    ...     return tokenizer(dataset[\"text\"])  # doctest: +SKIP\n    ```", "```py\n    >>> dataset = dataset.map(tokenize_dataset)  # doctest: +SKIP\n    >>> tf_dataset = model.prepare_tf_dataset(\n    ...     dataset[\"train\"], batch_size=16, shuffle=True, tokenizer=tokenizer\n    ... )  # doctest: +SKIP\n    ```", "```py\n    >>> from tensorflow.keras.optimizers import Adam\n\n    >>> model.compile(optimizer=Adam(3e-5))  # No loss argument!\n    >>> model.fit(tf_dataset)  # doctest: +SKIP\n    ```"]