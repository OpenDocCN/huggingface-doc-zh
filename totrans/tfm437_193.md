# MADLAD-400

> 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/madlad-400](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/madlad-400)

## 概述

MADLAD-400模型在论文[MADLAD-400: A Multilingual And Document-Level Large Audited Dataset](MADLAD-400: A Multilingual And Document-Level Large Audited Dataset)中发布。

论文摘要如下：

我们介绍了MADLAD-400，这是一个基于CommonCrawl的手动审核的通用领域3T令牌单语数据集，涵盖了419种语言。我们讨论了自我审核MADLAD-400所揭示的限制，以及数据审核在数据集创建过程中的作用。然后，我们使用公开可用的数据训练并发布了一个覆盖450多种语言、共计2500亿令牌的10.7B参数多语言机器翻译模型，并发现它与规模更大的模型竞争力相当，并在不同领域报告了结果。此外，我们训练了一个8B参数的语言模型，并评估了少样本翻译的结果。我们将基线模型提供给研究社区。

此模型由[Juarez Bochi](https://huggingface.co/jbochi)添加。原始检查点可以在[这里](https://github.com/google-research/google-research/tree/master/madlad_400)找到。

这是一个支持许多低资源语言的机器翻译模型，并且与规模更大的模型具有竞争力。

可以直接使用MADLAD-400权重而无需微调模型：

```py
>>> from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

>>> model = AutoModelForSeq2SeqLM.from_pretrained("google/madlad400-3b-mt")
>>> tokenizer = AutoTokenizer.from_pretrained("google/madlad400-3b-mt")

>>> inputs = tokenizer("<2pt> I love pizza!", return_tensors="pt")
>>> outputs = model.generate(**inputs)
>>> print(tokenizer.batch_decode(outputs, skip_special_tokens=True))
['Eu amo pizza!']
```

Google发布了以下变体：

+   [google/madlad400-3b-mt](https://huggingface.co/google/madlad400-3b-mt)

+   [google/madlad400-7b-mt](https://huggingface.co/google/madlad400-7b-mt)

+   [google/madlad400-7b-mt-bt](https://huggingface.co/google/madlad400-7b-mt-bt)

+   [google/madlad400-10b-mt](https://huggingface.co/google/madlad400-10b-mt)

原始检查点可以在[这里](https://github.com/google-research/google-research/tree/master/madlad_400)找到。

有关所有API参考、代码示例和笔记本，请参考[T5的文档页面](t5)。有关MADLAD-400的训练和评估的更多详细信息，请参考模型卡片。
