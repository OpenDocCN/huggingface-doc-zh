- en: Process
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理
- en: 'Original text: [https://huggingface.co/docs/datasets/process](https://huggingface.co/docs/datasets/process)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/datasets/process](https://huggingface.co/docs/datasets/process)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 🤗 Datasets provides many tools for modifying the structure and content of a
    dataset. These tools are important for tidying up a dataset, creating additional
    columns, converting between features and formats, and much more.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Datasets提供了许多工具来修改数据集的结构和内容。这些工具对于整理数据集、创建额外列、在特征和格式之间转换等方面非常重要。
- en: 'This guide will show you how to:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将向您展示如何：
- en: Reorder rows and split the dataset.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新排序行并拆分数据集。
- en: Rename and remove columns, and other common column operations.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重命名和删除列，以及其他常见的列操作。
- en: Apply processing functions to each example in a dataset.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据集中的每个示例应用处理函数。
- en: Concatenate datasets.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接数据集。
- en: Apply a custom formatting transform.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用自定义格式转换。
- en: Save and export processed datasets.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存和导出处理过的数据集。
- en: For more details specific to processing other dataset modalities, take a look
    at the [process audio dataset guide](./audio_process), the [process image dataset
    guide](./image_process), or the [process text dataset guide](./nlp_process).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有关处理其他数据集模态的详细信息，请查看[处理音频数据集指南](./audio_process)、[处理图像数据集指南](./image_process)或[处理文本数据集指南](./nlp_process)。
- en: The examples in this guide use the MRPC dataset, but feel free to load any dataset
    of your choice and follow along!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南中的示例使用MRPC数据集，但请随意加载您选择的任何数据集并跟随操作！
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: All processing methods in this guide return a new [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    object. Modification is not done in-place. Be careful about overriding your previous
    dataset!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南中的所有处理方法都会返回一个新的[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)对象。修改不是就地进行的。请注意不要覆盖您之前的数据集！
- en: Sort, shuffle, select, split, and shard
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排序、洗牌、选择、拆分和分片
- en: There are several functions for rearranging the structure of a dataset. These
    functions are useful for selecting only the rows you want, creating train and
    test splits, and sharding very large datasets into smaller chunks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个函数用于重新排列数据集的结构。这些函数对于仅选择您想要的行、创建训练和测试拆分以及将非常大的数据集分成较小的块非常有用。
- en: Sort
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 排序
- en: Use [sort()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.sort)
    to sort column values according to their numerical values. The provided column
    must be NumPy compatible.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[sort()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.sort)根据其数值值对列值进行排序。提供的列必须是NumPy兼容的。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Under the hood, this creates a list of indices that is sorted according to values
    of the column. This indices mapping is then used to access the right rows in the
    underlying Arrow table.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在内部，这会创建一个根据列的值排序的索引列表。然后使用这个索引映射来访问底层Arrow表中的正确行。
- en: Shuffle
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 洗牌
- en: The [shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.shuffle)
    function randomly rearranges the column values. You can specify the `generator`
    parameter in this function to use a different `numpy.random.Generator` if you
    want more control over the algorithm used to shuffle the dataset.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.shuffle)函数会随机重新排列列值。您可以在此函数中指定`generator`参数，以使用不同的`numpy.random.Generator`来更好地控制用于洗牌数据集的算法。'
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Shuffling takes the list of indices `[0:len(my_dataset)]` and shuffles it to
    create an indices mapping. However as soon as your [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    has an indices mapping, the speed can become 10x slower. This is because there
    is an extra step to get the row index to read using the indices mapping, and most
    importantly, you aren’t reading contiguous chunks of data anymore. To restore
    the speed, you’d need to rewrite the entire dataset on your disk again using [Dataset.flatten_indices()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.flatten_indices),
    which removes the indices mapping. Alternatively, you can switch to an [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    and leverage its fast approximate shuffling [IterableDataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 洗牌会取得索引列表`[0:len(my_dataset)]`并对其进行洗牌以创建一个索引映射。然而，一旦您的[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)有了一个索引映射，速度可能会变慢10倍。这是因为需要额外的步骤来使用索引映射获取要读取的行索引，最重要的是，您不再读取连续的数据块。为恢复速度，您需要再次使用[Dataset.flatten_indices()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.flatten_indices)将整个数据集重写到磁盘上，以删除索引映射。或者，您可以切换到[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)并利用其快速的近似洗牌[IterableDataset.shuffle()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle)：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Select and Filter
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择和过滤
- en: 'There are two options for filtering rows in a dataset: [select()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.select)
    and [filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集中有两种过滤行的选项：[select()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.select)和[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)。
- en: '[select()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.select)
    returns rows according to a list of indices:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[select()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.select)根据索引列表返回行：'
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)
    returns rows that match a specified condition:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)返回符合指定条件的行：'
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)
    can also filter by indices if you set `with_indices=True`:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[filter()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.filter)也可以通过设置`with_indices=True`来按索引进行过滤：'
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Unless the list of indices to keep is contiguous, those methods also create
    an indices mapping under the hood.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 除非要保留的索引列表是连续的，否则这些方法在内部也会创建一个索引映射。
- en: Split
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拆分
- en: 'The [train_test_split()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.train_test_split)
    function creates train and test splits if your dataset doesn’t already have them.
    This allows you to adjust the relative proportions or an absolute number of samples
    in each split. In the example below, use the `test_size` parameter to create a
    test split that is 10% of the original dataset:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[train_test_split()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.train_test_split)函数在数据集没有训练和测试拆分时创建训练和测试拆分。这允许您调整每个拆分中的相对比例或绝对数量的样本。在下面的示例中，使用`test_size`参数创建一个原始数据集的10%的测试拆分：'
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The splits are shuffled by default, but you can set `shuffle=False` to prevent
    shuffling.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下拆分是随机的，但您可以设置`shuffle=False`来防止洗牌。
- en: Shard
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分片
- en: 🤗 Datasets supports sharding to divide a very large dataset into a predefined
    number of chunks. Specify the `num_shards` parameter in [shard()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.shard)
    to determine the number of shards to split the dataset into. You’ll also need
    to provide the shard you want to return with the `index` parameter.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 数据集支持分片，将一个非常大的数据集分成预定义数量的块。在[shard()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.shard)中指定`num_shards`参数以确定要将数据集分割成的分片数。您还需要提供要返回的分片的`index`参数。
- en: 'For example, the [imdb](https://huggingface.co/datasets/imdb) dataset has 25000
    examples:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[imdb](https://huggingface.co/datasets/imdb)数据集有25000个示例：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After sharding the dataset into four chunks, the first shard will only have
    6250 examples:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集分成四个块后，第一个块将只有6250个示例：
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Rename, remove, cast, and flatten
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重命名、移除、转换和展平
- en: The following functions allow you to modify the columns of a dataset. These
    functions are useful for renaming or removing columns, changing columns to a new
    set of features, and flattening nested column structures.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数允许您修改数据集的列。这些函数对重命名或移除列、将列更改为新的特征集以及展平嵌套列结构很有用。
- en: Rename
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重命名
- en: Use [rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)
    when you need to rename a column in your dataset. Features associated with the
    original column are actually moved under the new column name, instead of just
    replacing the original column in-place.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要在数据集中重命名列时，请使用[rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)。与原始列相关的特征实际上被移动到新列名下，而不仅仅是替换原始列。
- en: 'Provide [rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)
    with the name of the original column, and the new column name:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原始列的名称和新列名称提供[rename_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.rename_column)：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Remove
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 移除
- en: 'When you need to remove one or more columns, provide the column name to remove
    to the [remove_columns()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.remove_columns)
    function. Remove more than one column by providing a list of column names:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要移除一个或多个列时，提供要移除的列名给[remove_columns()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.remove_columns)函数。通过提供列名列表来移除多个列：
- en: '[PRE11]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Conversely, [select_columns()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.select_columns)
    selects one or more columns to keep and removes the rest. This function takes
    either one or a list of column names:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，[select_columns()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.select_columns)选择要保留的一个或多个列，并移除其余列。此函数接受一个或列名列表：
- en: '[PRE12]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Cast
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转换
- en: 'The [cast()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast)
    function transforms the feature type of one or more columns. This function accepts
    your new [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    as its argument. The example below demonstrates how to change the [ClassLabel](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel)
    and [Value](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Value)
    features:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[cast()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast)函数转换一个或多个列的特征类型。此函数接受您的新[Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)作为其参数。下面的示例演示了如何更改[ClassLabel](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.ClassLabel)和[Value](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Value)特征：'
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Casting only works if the original feature type and new feature type are compatible.
    For example, you can cast a column with the feature type `Value("int32")` to `Value("bool")`
    if the original column only contains ones and zeros.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 仅当原始特征类型和新特征类型兼容时，转换才起作用。例如，如果原始列仅包含1和0，则可以将具有特征类型`Value("int32")`的列转换为`Value("bool")`。
- en: 'Use the [cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)
    function to change the feature type of a single column. Pass the column name and
    its new feature type as arguments:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[cast_column()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.cast_column)函数来更改单个列的特征类型。将列名和其新特征类型作为参数传递：
- en: '[PRE14]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Flatten
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 展平
- en: 'Sometimes a column can be a nested structure of several types. Take a look
    at the nested structure below from the SQuAD dataset:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，一列可以是几种类型的嵌套结构。看一下来自SQuAD数据集的下面的嵌套结构：
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `answers` field contains two subfields: `text` and `answer_start`. Use
    the [flatten()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.flatten)
    function to extract the subfields into their own separate columns:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`answers`字段包含两个子字段：`text`和`answer_start`。使用[flatten()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.flatten)函数将子字段提取到它们自己的独立列中：'
- en: '[PRE16]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Notice how the subfields are now their own independent columns: `answers.text`
    and `answers.answer_start`.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注意子字段现在是独立的列：`answers.text`和`answers.answer_start`。
- en: Map
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 映射
- en: Some of the more powerful applications of 🤗 Datasets come from using the [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    function. The primary purpose of [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    is to speed up processing functions. It allows you to apply a processing function
    to each example in a dataset, independently or in batches. This function can even
    create new rows and columns.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Datasets的一些更强大的应用来自于使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)函数。[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)的主要目的是加速处理函数。它允许您将处理函数应用于数据集中的每个示例，独立地或批处理。该函数甚至可以创建新的行和列。
- en: 'In the following example, prefix each `sentence1` value in the dataset with
    `''My sentence: ''`.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '在以下示例中，将数据集中每个`sentence1`值的前缀设置为''My sentence: ''。'
- en: 'Start by creating a function that adds `''My sentence: ''` to the beginning
    of each sentence. The function needs to accept and output a `dict`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '首先创建一个函数，将''My sentence: ''添加到每个句子的开头。该函数需要接受并输出一个`dict`：'
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now use [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    to apply the `add_prefix` function to the entire dataset:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)将`add_prefix`函数应用于整个数据集：
- en: '[PRE18]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Let’s take a look at another example, except this time, you’ll remove a column
    with [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map).
    When you remove a column, it is only removed after the example has been provided
    to the mapped function. This allows the mapped function to use the content of
    the columns before they are removed.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看另一个例子，除了这次，您将使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)删除一个列。当您删除一列时，只有在提供示例给映射函数后才会删除。这使得映射函数可以在删除之前使用列的内容。
- en: 'Specify the column to remove with the `remove_columns` parameter in [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)中的`remove_columns`参数指定要移除的列：
- en: '[PRE19]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 🤗 Datasets also has a [remove_columns()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.remove_columns)
    function which is faster because it doesn’t copy the data of the remaining columns.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 Datasets还有一个[remove_columns()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.remove_columns)函数，它更快，因为它不会复制剩余列的数据。
- en: 'You can also use [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    with indices if you set `with_indices=True`. The example below adds the index
    to the beginning of each sentence:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果设置`with_indices=True`，还可以使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)与索引一起使用。下面的示例将索引添加到每个句子的开头：
- en: '[PRE20]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Multiprocessing
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多进程
- en: 'Multiprocessing significantly speeds up processing by parallelizing processes
    on the CPU. Set the `num_proc` parameter in [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    to set the number of processes to use:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程通过在CPU上并行处理进程显著加快处理速度。在[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)中设置`num_proc`参数以设置要使用的进程数：
- en: '[PRE21]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    also works with the rank of the process if you set `with_rank=True`. This is analogous
    to the `with_indices` parameter. The `with_rank` parameter in the mapped function
    goes after the `index` one if it is already present.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果设置`with_rank=True`，[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)还可以与进程的等级一起使用。这类似于`with_indices`参数。如果已经存在`index`，则映射函数中的`with_rank`参数在`index`之后。
- en: '[PRE22]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The main use-case for rank is to parallelize computation across several GPUs.
    This requires setting `multiprocess.set_start_method("spawn")`. If you don’t you’ll
    receive the following CUDA error:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 等级的主要用例是在多个GPU上并行计算。这需要设置`multiprocess.set_start_method("spawn")`。如果不这样做，您将收到以下CUDA错误：
- en: '[PRE23]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Batch processing
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 批处理
- en: The [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    function supports working with batches of examples. Operate on batches by setting
    `batched=True`. The default batch size is 1000, but you can adjust it with the
    `batch_size` parameter. Batch processing enables interesting applications such
    as splitting long sentences into shorter chunks and data augmentation.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)函数支持处理示例批次。通过设置`batched=True`来操作批次。默认批处理大小为1000，但您可以使用`batch_size`参数进行调整。批处理使得可以将长句子拆分为较短的块和数据增强等有趣的应用。'
- en: Split long examples
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 拆分长示例
- en: 'When examples are too long, you may want to split them into several smaller
    chunks. Begin by creating a function that:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当示例太长时，您可能希望将其拆分为几个较小的块。首先创建一个函数：
- en: Splits the `sentence1` field into chunks of 50 characters.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`sentence1`字段拆分为50个字符的块。
- en: Stacks all the chunks together to create the new dataset.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有块堆叠在一起以创建新数据集。
- en: '[PRE24]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Apply the function with [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)函数应用该函数：
- en: '[PRE25]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Notice how the sentences are split into shorter chunks now, and there are more
    rows in the dataset.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在句子被拆分为较短的块，并且数据集中有更多的行。
- en: '[PRE26]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Data augmentation
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据增强
- en: The [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    function could also be used for data augmentation. The following example generates
    additional words for a masked token in a sentence.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)函数也可以用于数据增强。下面的示例为句子中的一个掩码标记生成额外的单词。'
- en: 'Load and use the [RoBERTA](https://huggingface.co/roberta-base) model in 🤗
    Transformers’ [FillMaskPipeline](https://huggingface.co/transformers/main_classes/pipelines#transformers.FillMaskPipeline):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在🤗 Transformers的[FillMaskPipeline](https://huggingface.co/transformers/main_classes/pipelines#transformers.FillMaskPipeline)中加载并使用[RoBERTA](https://huggingface.co/roberta-base)模型：
- en: '[PRE27]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Create a function to randomly select a word to mask in the sentence. The function
    should also return the original sentence and the top two replacements generated
    by RoBERTA.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个函数来随机选择要在句子中屏蔽的单词。该函数还应返回原始句子以及RoBERTA生成的前两个替代词。
- en: '[PRE28]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Use [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    to apply the function over the whole dataset:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)在整个数据集上应用函数：
- en: '[PRE29]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: For each original sentence, RoBERTA augmented a random word with three alternatives.
    The original word `distorting` is supplemented by `withholding`, `suppressing`,
    and `destroying`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个原始句子，RoBERTA使用三个备选词对一个随机单词进行增强。原始单词`distorting`被`withholding`、`suppressing`和`destroying`补充。
- en: Process multiple splits
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理多个拆分
- en: 'Many datasets have splits that can be processed simultaneously with [DatasetDict.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetDict.map).
    For example, tokenize the `sentence1` field in the train and test split by:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据集具有可以使用[DatasetDict.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.DatasetDict.map)同时处理的拆分。例如，通过以下方式对训练集和测试集中的`sentence1`字段进行标记化：
- en: '[PRE30]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Distributed usage
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分布式使用
- en: When you use [map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    in a distributed setting, you should also use [torch.distributed.barrier](https://pytorch.org/docs/stable/distributed?highlight=barrier#torch.distributed.barrier).
    This ensures the main process performs the mapping, while the other processes
    load the results, thereby avoiding duplicate work.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式设置中使用[map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)时，还应使用[torch.distributed.barrier](https://pytorch.org/docs/stable/distributed?highlight=barrier#torch.distributed.barrier)。这确保主进程执行映射，而其他进程加载结果，从而避免重复工作。
- en: 'The following example shows how you can use `torch.distributed.barrier` to
    synchronize the processes:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了如何使用`torch.distributed.barrier`来同步进程：
- en: '[PRE31]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Concatenate
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接
- en: 'Separate datasets can be concatenated if they share the same column types.
    Concatenate datasets with [concatenate_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.concatenate_datasets):'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不同数据集共享相同的列类型，则可以将它们连接在一起。使用[concatenate_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.concatenate_datasets)连接数据集：
- en: '[PRE32]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You can also concatenate two datasets horizontally by setting `axis=1` as long
    as the datasets have the same number of rows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过设置`axis=1`来水平连接两个数据集，只要这些数据集具有相同数量的行：
- en: '[PRE33]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Interleave
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交错
- en: You can also mix several datasets together by taking alternating examples from
    each one to create a new dataset. This is known as *interleaving*, which is enabled
    by the [interleave_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.interleave_datasets)
    function. Both [interleave_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.interleave_datasets)
    and [concatenate_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.concatenate_datasets)
    work with regular [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    and [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    objects. Refer to the [Stream](./stream#interleave) guide for an example of how
    to interleave [IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)
    objects.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过从每个数据集中交替获取示例来将多个数据集混合在一起，从而创建一个新数据集。这被称为*交错*，可以通过[interleave_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.interleave_datasets)函数实现。[interleave_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.interleave_datasets)和[concatenate_datasets()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.concatenate_datasets)都适用于常规[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)和[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)对象。请参考[Stream](./stream#interleave)指南，了解如何交错[IterableDataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.IterableDataset)对象的示例。
- en: You can define sampling probabilities for each of the original datasets to specify
    how to interleave the datasets. In this case, the new dataset is constructed by
    getting examples one by one from a random dataset until one of the datasets runs
    out of samples.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为每个原始数据集定义采样概率，以指定如何交错这些数据集。在这种情况下，新数据集是通过从随机数据集逐个获取示例构建的，直到其中一个数据集耗尽样本。
- en: '[PRE34]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: You can also specify the `stopping_strategy`. The default strategy, `first_exhausted`,
    is a subsampling strategy, i.e the dataset construction is stopped as soon one
    of the dataset runs out of samples. You can specify `stopping_strategy=all_exhausted`
    to execute an oversampling strategy. In this case, the dataset construction is
    stopped as soon as every samples in every dataset has been added at least once.
    In practice, it means that if a dataset is exhausted, it will return to the beginning
    of this dataset until the stop criterion has been reached. Note that if no sampling
    probabilities are specified, the new dataset will have `max_length_datasets*nb_dataset
    samples`.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以指定`stopping_strategy`。默认策略`first_exhausted`是一种子采样策略，即数据集构建在其中一个数据集耗尽样本时停止。您可以指定`stopping_strategy=all_exhausted`来执行一种过采样策略。在这种情况下，数据集构建将在每个数据集的每个样本至少添加一次后停止。实际上，这意味着如果一个数据集耗尽，它将返回到该数据集的开头，直到达到停止条件。请注意，如果未指定采样概率，则新数据集将具有`max_length_datasets*nb_dataset`个样本。
- en: '[PRE35]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Format
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 格式
- en: The [set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format)
    function changes the format of a column to be compatible with some common data
    formats. Specify the output you’d like in the `type` parameter and the columns
    you want to format. Formatting is applied on-the-fly.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[set_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_format)函数可更改列的格式，使其与一些常见数据格式兼容。在`type`参数中指定您想要的输出以及要格式化的列。格式化是即时应用的。'
- en: 'For example, create PyTorch tensors by setting `type="torch"`:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，通过设置`type="torch"`创建PyTorch张量：
- en: '[PRE36]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The [with_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_format)
    function also changes the format of a column, except it returns a new [Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)
    object:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[with_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.with_format)函数还可以更改列的格式，但它返回一个新的[Dataset](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset)对象：'
- en: '[PRE37]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 🤗 Datasets also provides support for other common data formats such as NumPy,
    Pandas, and JAX. Check out the [Using Datasets with TensorFlow](https://huggingface.co/docs/datasets/master/en/use_with_tensorflow#using-totfdataset)
    guide for more details on how to efficiently create a TensorFlow dataset.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 数据集还支持其他常见数据格式，如NumPy、Pandas和JAX。查看[使用 TensorFlow 与数据集](https://huggingface.co/docs/datasets/master/en/use_with_tensorflow#using-totfdataset)指南，了解如何高效创建
    TensorFlow 数据集的更多细节。
- en: 'If you need to reset the dataset to its original format, use the [reset_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.reset_format)
    function:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要将数据集重置为其原始格式，请使用[reset_format()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.reset_format)函数：
- en: '[PRE38]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Format transform
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 格式转换
- en: 'The [set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform)
    function applies a custom formatting transform on-the-fly. This function replaces
    any previously specified format. For example, you can use this function to tokenize
    and pad tokens on-the-fly. Tokenization is only applied when examples are accessed:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform)函数在运行时应用自定义格式转换。此函数将替换任何先前指定的格式。例如，您可以使用此函数在运行时对标记进行标记化和填充。仅当访问示例时才应用标记化：'
- en: '[PRE39]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: You can also use the [set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform)
    function to decode formats not supported by [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features).
    For example, the [Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)
    feature uses [`soundfile`](https://python-soundfile.readthedocs.io/en/0.11.0/)
    - a fast and simple library to install - but it does not provide support for less
    common audio formats. Here is where you can use [set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform)
    to apply a custom decoding transform on the fly. You’re free to use any library
    you like to decode the audio files.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用[set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform)函数解码不受[Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)支持的格式。例如，[Audio](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Audio)特征使用[`soundfile`](https://python-soundfile.readthedocs.io/en/0.11.0/)
    - 一个快速简单的安装库 - 但它不支持较少常见的音频格式。在这里，您可以使用[set_transform()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.set_transform)在运行时应用自定义解码转换。您可以自由选择任何库来解码音频文件。
- en: 'The example below uses the [`pydub`](http://pydub.com/) package to open an
    audio format not supported by `soundfile`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例使用[`pydub`](http://pydub.com/)包打开一个`soundfile`不支持的音频格式：
- en: '[PRE40]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Save
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存
- en: Once you are done processing your dataset, you can save and reuse it later with
    [save_to_disk()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您完成处理数据集，您可以使用[save_to_disk()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk)保存并以后重复使用。
- en: 'Save your dataset by providing the path to the directory you wish to save it
    to:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提供要保存数据集的目录路径来保存数据集：
- en: '[PRE41]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Use the [load_from_disk()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_from_disk)
    function to reload the dataset:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[load_from_disk()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_from_disk)函数重新加载数据集：
- en: '[PRE42]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Want to save your dataset to a cloud storage provider? Read our [Cloud Storage](./filesystems)
    guide to learn how to save your dataset to AWS or Google Cloud Storage.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 想要将数据集保存到云存储提供商吗？阅读我们的[云存储](./filesystems)指南，了解如何将数据集保存到 AWS 或 Google Cloud
    Storage。
- en: Export
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出
- en: '🤗 Datasets supports exporting as well so you can work with your dataset in
    other applications. The following table shows currently supported file formats
    you can export to:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 🤗 数据集还支持导出，这样您就可以在其他应用程序中使用数据集。以下表格显示当前支持的文件格式，您可以导出到这些格式：
- en: '| File type | Export method |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 文件类型 | 导出方法 |'
- en: '| --- | --- |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| CSV | [Dataset.to_csv()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_csv)
    |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| CSV | [Dataset.to_csv()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_csv)
    |'
- en: '| JSON | [Dataset.to_json()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_json)
    |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| JSON | [Dataset.to_json()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_json)
    |'
- en: '| Parquet | [Dataset.to_parquet()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_parquet)
    |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| Parquet | [Dataset.to_parquet()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_parquet)
    |'
- en: '| SQL | [Dataset.to_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_sql)
    |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| SQL | [Dataset.to_sql()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_sql)
    |'
- en: '| In-memory Python object | [Dataset.to_pandas()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_pandas)
    or [Dataset.to_dict()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_dict)
    |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 内存中的 Python 对象 | [Dataset.to_pandas()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_pandas)
    或 [Dataset.to_dict()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.to_dict)
    |'
- en: 'For example, export your dataset to a CSV file like this:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，像这样将数据集导出到 CSV 文件：
- en: '[PRE43]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
