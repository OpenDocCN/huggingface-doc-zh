- en: Evaluate predictions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¯„ä¼°é¢„æµ‹
- en: 'Original text: [https://huggingface.co/docs/datasets/metrics](https://huggingface.co/docs/datasets/metrics)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/datasets/metrics](https://huggingface.co/docs/datasets/metrics)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Metrics is deprecated in ğŸ¤— Datasets. To learn more about how to use metrics,
    take a look at the library ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index)!
    In addition to metrics, you can find more tools for evaluating models and datasets.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Datasetsä¸­çš„Metricså·²è¢«å¼ƒç”¨ã€‚è¦äº†è§£æœ‰å…³å¦‚ä½•ä½¿ç”¨æŒ‡æ ‡çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹åº“ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index)ï¼é™¤äº†æŒ‡æ ‡ï¼Œæ‚¨è¿˜å¯ä»¥æ‰¾åˆ°æ›´å¤šç”¨äºè¯„ä¼°æ¨¡å‹å’Œæ•°æ®é›†çš„å·¥å…·ã€‚
- en: ğŸ¤— Datasets provides various common and NLP-specific [metrics](https://huggingface.co/metrics)
    for you to measure your models performance. In this section of the tutorials,
    you will load a metric and use it to evaluate your models predictions.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— Datasetsæä¾›å„ç§å¸¸è§å’Œé¢å‘NLPçš„[æŒ‡æ ‡](https://huggingface.co/metrics)ï¼Œä¾›æ‚¨è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ã€‚åœ¨æœ¬æ•™ç¨‹çš„è¿™ä¸€éƒ¨åˆ†ï¼Œæ‚¨å°†åŠ è½½ä¸€ä¸ªæŒ‡æ ‡å¹¶ä½¿ç”¨å®ƒæ¥è¯„ä¼°æ‚¨çš„æ¨¡å‹é¢„æµ‹ã€‚
- en: 'You can see what metrics are available with [list_metrics()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.list_metrics):'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä½¿ç”¨[list_metrics()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.list_metrics)æŸ¥çœ‹å¯ç”¨çš„æŒ‡æ ‡ï¼š
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Load metric
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ è½½æŒ‡æ ‡
- en: 'It is very easy to load a metric with ğŸ¤— Datasets. In fact, you will notice
    that it is very similar to loading a dataset! Load a metric from the Hub with
    [load_metric()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_metric):'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ğŸ¤— DatasetsåŠ è½½æŒ‡æ ‡éå¸¸å®¹æ˜“ã€‚å®é™…ä¸Šï¼Œæ‚¨ä¼šæ³¨æ„åˆ°å®ƒä¸åŠ è½½æ•°æ®é›†éå¸¸ç›¸ä¼¼ï¼ä½¿ç”¨[load_metric()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_metric)ä»HubåŠ è½½æŒ‡æ ‡ï¼š
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will load the metric associated with the MRPC dataset from the GLUE benchmark.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†åŠ è½½ä¸GLUEåŸºå‡†æµ‹è¯•ä¸­çš„MRPCæ•°æ®é›†ç›¸å…³è”çš„æŒ‡æ ‡ã€‚
- en: Select a configuration
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é€‰æ‹©ä¸€ä¸ªé…ç½®
- en: 'If you are using a benchmark dataset, you need to select a metric that is associated
    with the configuration you are using. Select a metric configuration by providing
    the configuration name:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨åŸºå‡†æ•°æ®é›†ï¼Œåˆ™éœ€è¦é€‰æ‹©ä¸æ‚¨æ­£åœ¨ä½¿ç”¨çš„é…ç½®ç›¸å…³è”çš„æŒ‡æ ‡ã€‚é€šè¿‡æä¾›é…ç½®åç§°æ¥é€‰æ‹©æŒ‡æ ‡é…ç½®ï¼š
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Metrics object
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æŒ‡æ ‡å¯¹è±¡
- en: 'Before you begin using a [Metric](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Metric)
    object, you should get to know it a little better. As with a dataset, you can
    return some basic information about a metric. For example, access the `inputs_description`
    parameter in [datasets.MetricInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.MetricInfo)
    to get more information about a metrics expected input format and some usage examples:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹ä½¿ç”¨[Metric](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Metric)å¯¹è±¡ä¹‹å‰ï¼Œæ‚¨åº”è¯¥æ›´åŠ äº†è§£å®ƒã€‚ä¸æ•°æ®é›†ä¸€æ ·ï¼Œæ‚¨å¯ä»¥è¿”å›æœ‰å…³æŒ‡æ ‡çš„ä¸€äº›åŸºæœ¬ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œè®¿é—®[datasets.MetricInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.MetricInfo)ä¸­çš„`inputs_description`å‚æ•°ï¼Œä»¥è·å–æœ‰å…³æŒ‡æ ‡é¢„æœŸè¾“å…¥æ ¼å¼å’Œä¸€äº›ä½¿ç”¨ç¤ºä¾‹çš„æ›´å¤šä¿¡æ¯ï¼š
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice for the MRPC configuration, the metric expects the input format to be
    zero or one. For a complete list of attributes you can return with your metric,
    take a look at [MetricInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.MetricInfo).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå¯¹äºMRPCé…ç½®ï¼Œè¯¥æŒ‡æ ‡æœŸæœ›è¾“å…¥æ ¼å¼ä¸ºé›¶æˆ–ä¸€ã€‚è¦æŸ¥çœ‹æ‚¨çš„æŒ‡æ ‡å¯ä»¥è¿”å›çš„å±æ€§çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·æŸ¥çœ‹[MetricInfo](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.MetricInfo)ã€‚
- en: Compute metric
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¡ç®—æŒ‡æ ‡
- en: 'Once you have loaded a metric, you are ready to use it to evaluate a models
    predictions. Provide the model predictions and references to [compute()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Metric.compute):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨åŠ è½½äº†ä¸€ä¸ªæŒ‡æ ‡ï¼Œæ‚¨å°±å¯ä»¥ä½¿ç”¨å®ƒæ¥è¯„ä¼°æ¨¡å‹çš„é¢„æµ‹ã€‚å°†æ¨¡å‹é¢„æµ‹å’Œå‚è€ƒæä¾›ç»™[compute()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Metric.compute)ï¼š
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
