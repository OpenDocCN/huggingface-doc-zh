- en: Hands-on
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®è·µ
- en: 'Original text: [https://huggingface.co/learn/deep-rl-course/unit7/hands-on](https://huggingface.co/learn/deep-rl-course/unit7/hands-on)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/learn/deep-rl-course/unit7/hands-on](https://huggingface.co/learn/deep-rl-course/unit7/hands-on)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you learned the basics of multi-agents, youâ€™re ready to train your
    first agents in a multi-agent system: **a 2vs2 soccer team that needs to beat
    the opponent team**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²ç»äº†è§£äº†å¤šä»£ç†çš„åŸºç¡€çŸ¥è¯†ï¼Œæ‚¨å¯ä»¥å¼€å§‹è®­ç»ƒæ‚¨çš„ç¬¬ä¸€ä¸ªå¤šä»£ç†ç³»ç»Ÿä¸­çš„ä»£ç†ï¼š**ä¸€ä¸ª2å¯¹2çš„è¶³çƒå›¢é˜Ÿéœ€è¦å‡»è´¥å¯¹æ‰‹å›¢é˜Ÿ**ã€‚
- en: And youâ€™re going to participate in AI vs. AI challenges where your trained agent
    will compete against other classmatesâ€™ **agents every day and be ranked on a new
    leaderboard.**
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å°†å‚åŠ AI vs. AIæŒ‘æˆ˜ï¼Œæ‚¨è®­ç»ƒçš„ä»£ç†å°†æ¯å¤©ä¸å…¶ä»–åŒå­¦çš„**ä»£ç†ç«äº‰ï¼Œå¹¶åœ¨æ–°çš„æ’è¡Œæ¦œä¸Šæ’åã€‚**
- en: To validate this hands-on for the certification process, you just need to push
    a trained model. There **are no minimal results to attain to validate it.**
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¦éªŒè¯è¿™ä¸ªå®è·µé¡¹ç›®æ˜¯å¦ç¬¦åˆè®¤è¯è¦æ±‚ï¼Œæ‚¨åªéœ€è¦æ¨é€ä¸€ä¸ªç»è¿‡è®­ç»ƒçš„æ¨¡å‹ã€‚**æ²¡æœ‰æœ€ä½è¦æ±‚æ¥éªŒè¯å®ƒã€‚**
- en: For more information about the certification process, check this section ğŸ‘‰ [https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…³è®¤è¯è¿‡ç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ†ğŸ‘‰[https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)
- en: 'This hands-on will be different since to get correct results **you need to
    train your agents from 4 hours to 8 hours**. And given the risk of timeout in
    Colab, we advise you to train on your computer. You donâ€™t need a supercomputer:
    a simple laptop is good enough for this exercise.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå®è·µé¡¹ç›®å°†ä¼šæœ‰æ‰€ä¸åŒï¼Œå› ä¸ºä¸ºäº†è·å¾—æ­£ç¡®çš„ç»“æœ**æ‚¨éœ€è¦è®­ç»ƒæ‚¨çš„ä»£ç†ä»4å°æ—¶åˆ°8å°æ—¶**ã€‚é‰´äºåœ¨Colabä¸­è¶…æ—¶çš„é£é™©ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨åœ¨æ‚¨çš„è®¡ç®—æœºä¸Šè¿›è¡Œè®­ç»ƒã€‚æ‚¨ä¸éœ€è¦è¶…çº§è®¡ç®—æœºï¼šä¸€å°ç®€å•çš„ç¬”è®°æœ¬ç”µè„‘å°±è¶³å¤Ÿäº†ã€‚
- en: Letâ€™s get started! ğŸ”¥
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ï¼ğŸ”¥
- en: What is AI vs. AI?
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯AI vs. AIï¼Ÿ
- en: AI vs. AI is an open-source tool we developed at Hugging Face to compete agents
    on the Hub against one another in a multi-agent setting. These models are then
    ranked in a leaderboard.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: AI vs. AIæ˜¯æˆ‘ä»¬åœ¨Hugging Faceå¼€å‘çš„ä¸€ä¸ªå¼€æºå·¥å…·ï¼Œç”¨äºåœ¨Hubä¸Šçš„ä»£ç†ä¹‹é—´è¿›è¡Œå¤šä»£ç†è®¾ç½®ä¸­çš„ç«äº‰ã€‚ç„¶åè¿™äº›æ¨¡å‹å°†åœ¨æ’è¡Œæ¦œä¸Šæ’åã€‚
- en: 'The idea of this tool is to have a robust evaluation tool: **by evaluating
    your agent with a lot of others, youâ€™ll get a good idea of the quality of your
    policy.**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå·¥å…·çš„æƒ³æ³•æ˜¯æ‹¥æœ‰ä¸€ä¸ªå¼ºå¤§çš„è¯„ä¼°å·¥å…·ï¼š**é€šè¿‡å°†æ‚¨çš„ä»£ç†ä¸è®¸å¤šå…¶ä»–ä»£ç†è¿›è¡Œè¯„ä¼°ï¼Œæ‚¨å°†å¯¹æ‚¨çš„ç­–ç•¥è´¨é‡æœ‰ä¸€ä¸ªå¾ˆå¥½çš„äº†è§£**ã€‚
- en: 'More precisely, AI vs. AI is three tools:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å‡†ç¡®åœ°è¯´ï¼ŒAI vs. AIåŒ…æ‹¬ä¸‰ä¸ªå·¥å…·ï¼š
- en: A *matchmaking process* defining the matches (which model against which) and
    running the model fights using a background task in the Space.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª*åŒ¹é…è¿‡ç¨‹*å®šä¹‰æ¯”èµ›ï¼ˆå“ªä¸ªæ¨¡å‹å¯¹å“ªä¸ªæ¨¡å‹ï¼‰å¹¶åœ¨ç©ºé—´ä¸­ä½¿ç”¨åå°ä»»åŠ¡è¿è¡Œæ¨¡å‹å¯¹æŠ—ã€‚
- en: 'A *leaderboard* getting the match history results and displaying the modelsâ€™
    ELO ratings: [https://huggingface.co/spaces/huggingface-projects/AIvsAI-SoccerTwos](https://huggingface.co/spaces/huggingface-projects/AIvsAI-SoccerTwos)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª*æ’è¡Œæ¦œ*è·å–æ¯”èµ›å†å²ç»“æœå¹¶æ˜¾ç¤ºæ¨¡å‹çš„ELOè¯„åˆ†ï¼š[https://huggingface.co/spaces/huggingface-projects/AIvsAI-SoccerTwos](https://huggingface.co/spaces/huggingface-projects/AIvsAI-SoccerTwos)
- en: 'A *Space demo* to visualize your agents playing against others: [https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos](https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª*Spaceæ¼”ç¤º*ï¼Œå¯è§†åŒ–æ‚¨çš„ä»£ç†ä¸å…¶ä»–ä»£ç†çš„å¯¹æˆ˜ï¼š[https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos](https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos)
- en: 'In addition to these three tools, your classmate cyllum created a ğŸ¤— SoccerTwos
    Challenge Analytics where you can check the detailed match results of a model:
    [https://huggingface.co/spaces/cyllum/soccertwos-analytics](https://huggingface.co/spaces/cyllum/soccertwos-analytics)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†è¿™ä¸‰ä¸ªå·¥å…·ï¼Œæ‚¨çš„åŒå­¦cyllumåˆ›å»ºäº†ä¸€ä¸ªğŸ¤— SoccerTwos Challenge Analyticsï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­æŸ¥çœ‹æ¨¡å‹çš„è¯¦ç»†æ¯”èµ›ç»“æœï¼š[https://huggingface.co/spaces/cyllum/soccertwos-analytics](https://huggingface.co/spaces/cyllum/soccertwos-analytics)
- en: 'Weâ€™re [wrote a blog post to explain this AI vs. AI tool in detail](https://huggingface.co/blog/aivsai),
    but to give you the big picture it works this way:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬[æ’°å†™äº†ä¸€ç¯‡åšæ–‡è¯¦ç»†è§£é‡Šè¿™ä¸ªAI vs. AIå·¥å…·](https://huggingface.co/blog/aivsai)ï¼Œä½†ä¸ºäº†è®©æ‚¨æœ‰ä¸€ä¸ªå¤§è‡´çš„äº†è§£ï¼Œå®ƒçš„å·¥ä½œæ–¹å¼å¦‚ä¸‹ï¼š
- en: Every four hours, our algorithm **fetches all the available models for a given
    environment (in our case ML-Agents-SoccerTwos).**
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯å››å°æ—¶ï¼Œæˆ‘ä»¬çš„ç®—æ³•**è·å–ç»™å®šç¯å¢ƒï¼ˆåœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹æ˜¯ML-Agents-SoccerTwosï¼‰ä¸­çš„æ‰€æœ‰å¯ç”¨æ¨¡å‹ã€‚**
- en: It creates a **queue of matches with the matchmaking algorithm.**
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒä½¿ç”¨åŒ¹é…ç®—æ³•åˆ›å»ºä¸€ä¸ª**æ¯”èµ›é˜Ÿåˆ—ã€‚**
- en: We simulate the match in a Unity headless process and **gather the match result**
    (1 if the first model won, 0.5 if itâ€™s a draw, 0 if the second model won) in a
    Dataset.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨Unityæ— å¤´è¿›ç¨‹ä¸­æ¨¡æ‹Ÿæ¯”èµ›å¹¶**æ”¶é›†æ¯”èµ›ç»“æœ**ï¼ˆå¦‚æœç¬¬ä¸€ä¸ªæ¨¡å‹èµ¢å¾—æ¯”èµ›åˆ™ä¸º1ï¼Œå¦‚æœæ˜¯å¹³å±€åˆ™ä¸º0.5ï¼Œå¦‚æœç¬¬äºŒä¸ªæ¨¡å‹èµ¢å¾—æ¯”èµ›åˆ™ä¸º0ï¼‰ã€‚
- en: Then, when all matches from the matches queue are done, **we update the ELO
    score for each model and update the leaderboard.**
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå½“æ‰€æœ‰æ¯”èµ›é˜Ÿåˆ—ä¸­çš„æ¯”èµ›éƒ½å®Œæˆæ—¶ï¼Œ**æˆ‘ä»¬æ›´æ–°æ¯ä¸ªæ¨¡å‹çš„ELOåˆ†æ•°å¹¶æ›´æ–°æ’è¡Œæ¦œã€‚**
- en: Competition Rules
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¯”èµ›è§„åˆ™
- en: 'This first AI vs. AI competition **is an experiment**: the goal is to improve
    the tool in the future with your feedback. So some **breakups can happen during
    the challenge**. But donâ€™t worry **all the results are saved in a dataset so we
    can always restart the calculation correctly without losing information**.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç¬¬ä¸€ä¸ªAI vs. AIæ¯”èµ›**æ˜¯ä¸€ä¸ªå®éªŒ**ï¼šç›®æ ‡æ˜¯é€šè¿‡æ‚¨çš„åé¦ˆæ¥æ”¹è¿›æœªæ¥çš„å·¥å…·ã€‚å› æ­¤åœ¨æŒ‘æˆ˜ä¸­å¯èƒ½ä¼šå‘ç”Ÿä¸€äº›**ä¸­æ–­**ã€‚ä½†ä¸ç”¨æ‹…å¿ƒ**æ‰€æœ‰ç»“æœéƒ½ä¿å­˜åœ¨æ•°æ®é›†ä¸­ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å§‹ç»ˆæ­£ç¡®é‡æ–°å¯åŠ¨è®¡ç®—è€Œä¸ä¼šä¸¢å¤±ä¿¡æ¯**ã€‚
- en: 'In order for your model to get correctly evaluated against others you need
    to follow these rules:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿æ‚¨çš„æ¨¡å‹èƒ½å¤Ÿæ­£ç¡®åœ°ä¸å…¶ä»–æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œæ‚¨éœ€è¦éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
- en: '**You canâ€™t change the observation space or action space of the agent.** By
    doing that your model will not work during evaluation.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ‚¨ä¸èƒ½æ›´æ”¹ä»£ç†çš„è§‚å¯Ÿç©ºé—´æˆ–è¡ŒåŠ¨ç©ºé—´ã€‚**è¿™æ ·åšä¼šå¯¼è‡´æ‚¨çš„æ¨¡å‹åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­æ— æ³•å·¥ä½œã€‚'
- en: You **canâ€™t use a custom trainer for now,** you need to use the Unity MLAgents
    ones.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç›®å‰ä¸èƒ½ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒå™¨**ï¼Œæ‚¨éœ€è¦ä½¿ç”¨Unity MLAgentsã€‚'
- en: We provide executables to train your agents. You can also use the Unity Editor
    if you prefer **, but to avoid bugs, we advise that you use our executables**.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æä¾›å¯æ‰§è¡Œæ–‡ä»¶æ¥è®­ç»ƒæ‚¨çš„ä»£ç†ã€‚æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨Unityç¼–è¾‘å™¨ï¼Œå¦‚æœæ‚¨æ„¿æ„**ï¼Œä½†ä¸ºäº†é¿å…é”™è¯¯ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ä½¿ç”¨æˆ‘ä»¬çš„å¯æ‰§è¡Œæ–‡ä»¶**ã€‚
- en: What will make the difference during this challenge are **the hyperparameters
    you choose**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªæŒ‘æˆ˜ä¸­å°†ä¼šæœ‰ä»€ä¹ˆä¸åŒçš„æ˜¯**æ‚¨é€‰æ‹©çš„è¶…å‚æ•°**ã€‚
- en: Weâ€™re constantly trying to improve our tutorials, soÂ **if you find some issues
    in this notebook**, pleaseÂ [open an issue on the GitHub Repo](https://github.com/huggingface/deep-rl-class/issues).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸æ–­åŠªåŠ›æ”¹è¿›æˆ‘ä»¬çš„æ•™ç¨‹ï¼Œæ‰€ä»¥**å¦‚æœæ‚¨åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­å‘ç°äº†ä¸€äº›é—®é¢˜**ï¼Œè¯·åœ¨GitHub Repoä¸Š[æå‡ºé—®é¢˜](https://github.com/huggingface/deep-rl-class/issues)ã€‚
- en: Chat with your classmates, share advice and ask questions on Discord
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨Discordä¸Šä¸åŒå­¦èŠå¤©ï¼Œåˆ†äº«å»ºè®®å’Œæé—®
- en: We created a new channel called `ai-vs-ai-challenge` to exchange advice and
    ask questions.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåä¸º`ai-vs-ai-challenge`çš„æ–°é¢‘é“ï¼Œç”¨äºäº¤æµå»ºè®®å’Œæé—®ã€‚
- en: If you didnâ€™t join the discord server yet, you can [join here](https://discord.gg/ydHrjt3WP5)
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨è¿˜æ²¡æœ‰åŠ å…¥discordæœåŠ¡å™¨ï¼Œæ‚¨å¯ä»¥[åœ¨è¿™é‡ŒåŠ å…¥](https://discord.gg/ydHrjt3WP5)
- en: 'Step 0: Install MLAgents and download the correct executable'
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤0ï¼šå®‰è£…MLAgentså¹¶ä¸‹è½½æ­£ç¡®çš„å¯æ‰§è¡Œæ–‡ä»¶
- en: We advise you to use [conda](https://docs.conda.io/en/latest/) as a package
    manager and create a new environment.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å»ºè®®æ‚¨ä½¿ç”¨[conda](https://docs.conda.io/en/latest/)ä½œä¸ºåŒ…ç®¡ç†å™¨å¹¶åˆ›å»ºä¸€ä¸ªæ–°ç¯å¢ƒã€‚
- en: 'With conda, we create a new environment called rl with **Python 3.10.12**:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨condaï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåä¸ºrlçš„æ–°ç¯å¢ƒï¼Œå…¶ä¸­åŒ…å«**Python 3.10.12**ï¼š
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To be able to train our agents correctly and push to the Hub, we need to install
    ML-Agents
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†èƒ½å¤Ÿæ­£ç¡®è®­ç»ƒæˆ‘ä»¬çš„ä»£ç†å¹¶æ¨é€åˆ°Hubï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…ML-Agents
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: When the cloning is done (it takes 2.63 GB), we go inside the repository and
    install the package
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å…‹éš†å®Œæˆåï¼ˆéœ€è¦2.63 GBï¼‰ï¼Œæˆ‘ä»¬è¿›å…¥å­˜å‚¨åº“å¹¶å®‰è£…è½¯ä»¶åŒ…
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, you need to install git-lfs: [https://git-lfs.com/](https://git-lfs.com/)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæ‚¨éœ€è¦å®‰è£…git-lfsï¼š[https://git-lfs.com/](https://git-lfs.com/)
- en: Now that itâ€™s installed, we need to add the environment training executable.
    Based on your operating system you need to download one of them, unzip it and
    place it in a new folder inside `ml-agents` that you call `training-envs-executables`
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å·²ç»å®‰è£…å¥½äº†ï¼Œæˆ‘ä»¬éœ€è¦æ·»åŠ ç¯å¢ƒè®­ç»ƒå¯æ‰§è¡Œæ–‡ä»¶ã€‚æ ¹æ®æ‚¨çš„æ“ä½œç³»ç»Ÿï¼Œæ‚¨éœ€è¦ä¸‹è½½å…¶ä¸­ä¸€ä¸ªï¼Œè§£å‹ç¼©å¹¶å°†å…¶æ”¾åœ¨`ml-agents`ä¸­çš„ä¸€ä¸ªæ–°æ–‡ä»¶å¤¹ä¸­ï¼Œå‘½åä¸º`training-envs-executables`
- en: At the end your executable should be in `ml-agents/training-envs-executables/SoccerTwos`
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæ‚¨çš„å¯æ‰§è¡Œæ–‡ä»¶åº”è¯¥åœ¨`ml-agents/training-envs-executables/SoccerTwos`ä¸­
- en: 'Windows: Download [this executable](https://drive.google.com/file/d/1sqFxbEdTMubjVktnV4C6ICjp89wLhUcP/view?usp=sharing)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Windowsï¼šä¸‹è½½[è¿™ä¸ªå¯æ‰§è¡Œæ–‡ä»¶](https://drive.google.com/file/d/1sqFxbEdTMubjVktnV4C6ICjp89wLhUcP/view?usp=sharing)
- en: 'Linux (Ubuntu): Download [this executable](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view?usp=sharing)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Linuxï¼ˆUbuntuï¼‰ï¼šä¸‹è½½[è¿™ä¸ªå¯æ‰§è¡Œæ–‡ä»¶](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view?usp=sharing)
- en: 'Mac: Download [this executable](https://drive.google.com/drive/folders/1h7YB0qwjoxxghApQdEUQmk95ZwIDxrPG?usp=share_link)
    âš  For Mac you need also to call this `xattr -cr training-envs-executables/SoccerTwos/SoccerTwos.app`
    to be able to run SoccerTwos'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Macï¼šä¸‹è½½[è¿™ä¸ªå¯æ‰§è¡Œæ–‡ä»¶](https://drive.google.com/drive/folders/1h7YB0qwjoxxghApQdEUQmk95ZwIDxrPG?usp=share_link)
    âš  å¯¹äºMacï¼Œæ‚¨è¿˜éœ€è¦è°ƒç”¨`xattr -cr training-envs-executables/SoccerTwos/SoccerTwos.app`æ‰èƒ½è¿è¡ŒSoccerTwos
- en: 'Step 1: Understand the environment'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤1ï¼šäº†è§£ç¯å¢ƒ
- en: The environment is called `SoccerTwos`. The Unity MLAgents Team made it. You
    can find its documentation [here](https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md#soccer-twos)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç¯å¢ƒè¢«ç§°ä¸º`SoccerTwos`ã€‚Unity MLAgentså›¢é˜Ÿåˆ¶ä½œäº†å®ƒã€‚æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md#soccer-twos)æ‰¾åˆ°å®ƒçš„æ–‡æ¡£
- en: The goal in this environment **is to get the ball into the opponentâ€™s goal while
    preventing the ball from entering your own goal.**
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¯å¢ƒä¸­ï¼Œç›®æ ‡æ˜¯**å°†çƒè¿›å…¥å¯¹æ‰‹çš„çƒé—¨ï¼ŒåŒæ—¶é˜²æ­¢çƒè¿›å…¥è‡ªå·±çš„çƒé—¨ã€‚**
- en: '![SoccerTwos](../Images/b8d7d800c316a50a5f64472742088b73.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![SoccerTwos](../Images/b8d7d800c316a50a5f64472742088b73.png)'
- en: This environment was made by the [Unity MLAgents Team](https://github.com/Unity-Technologies/ml-agents)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç¯å¢ƒæ˜¯ç”±[Unity MLAgentså›¢é˜Ÿ](https://github.com/Unity-Technologies/ml-agents)åˆ¶ä½œçš„
- en: The reward function
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¥–åŠ±å‡½æ•°
- en: 'The reward function is:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å¥–åŠ±å‡½æ•°æ˜¯ï¼š
- en: '![SoccerTwos Reward](../Images/236ec2816e80441049618048e60a2b89.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![SoccerTwos Reward](../Images/236ec2816e80441049618048e60a2b89.png)'
- en: The observation space
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿç©ºé—´
- en: 'The observation space is composed of vectors of size 336:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿç©ºé—´ç”±å¤§å°ä¸º336çš„å‘é‡ç»„æˆï¼š
- en: 11 ray-casts forward distributed over 120 degrees (264 state dimensions)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 11ä¸ªå‘å‰çš„å°„çº¿åˆ†å¸ƒåœ¨120åº¦ä¸Šï¼ˆ264ä¸ªçŠ¶æ€ç»´åº¦ï¼‰
- en: 3 ray-casts backward distributed over 90 degrees (72 state dimensions)
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3ä¸ªå‘åçš„å°„çº¿åˆ†å¸ƒåœ¨90åº¦ä¸Šï¼ˆ72ä¸ªçŠ¶æ€ç»´åº¦ï¼‰
- en: 'Both of these ray-casts can detect 6 objects:'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ä¸ªå°„çº¿éƒ½å¯ä»¥æ£€æµ‹åˆ°6ä¸ªå¯¹è±¡ï¼š
- en: Ball
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: çƒ
- en: Blue Goal
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: è“è‰²ç›®æ ‡
- en: Purple Goal
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç´«è‰²ç›®æ ‡
- en: Wall
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢™
- en: Blue Agent
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: è“è‰²ä»£ç†
- en: Purple Agent
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç´«è‰²ä»£ç†
- en: The action space
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¡ŒåŠ¨ç©ºé—´
- en: 'The action space is three discrete branches:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¡ŒåŠ¨ç©ºé—´æœ‰ä¸‰ä¸ªç¦»æ•£åˆ†æ”¯ï¼š
- en: '![SoccerTwos Action](../Images/8afca8f83c98b99eae38b8072b97e32c.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![SoccerTwos Action](../Images/8afca8f83c98b99eae38b8072b97e32c.png)'
- en: 'Step 2: Understand MA-POCA'
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤2ï¼šäº†è§£MA-POCA
- en: 'We know how to train agents to play against others: **we can use self-play.**
    This is a perfect technique for a 1vs1.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çŸ¥é“å¦‚ä½•è®­ç»ƒä»£ç†ä¸å…¶ä»–äººå¯¹æˆ˜ï¼š**æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è‡ªæˆ‘å¯¹å¼ˆã€‚**è¿™æ˜¯ä¸€ä¸ªå®Œç¾çš„æŠ€æœ¯ï¼Œé€‚ç”¨äº1å¯¹1ã€‚
- en: But in our case weâ€™re 2vs2, and each team has 2 agents. How then can we **train
    cooperative behavior for groups of agents?**
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ˜¯2å¯¹2ï¼Œæ¯ä¸ªå›¢é˜Ÿæœ‰2ä¸ªä»£ç†ã€‚é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•**è®­ç»ƒä»£ç†ç»„çš„åˆä½œè¡Œä¸ºå‘¢ï¼Ÿ**
- en: As explained in the [Unity Blog](https://blog.unity.com/technology/ml-agents-v20-release-now-supports-training-complex-cooperative-behaviors),
    agents typically receive a reward as a group (+1 - penalty) when the team scores
    a goal. This implies that **every agent on the team is rewarded even if each agent
    didnâ€™t contribute the same to the win**, which makes it difficult to learn what
    to do independently.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚[Unity Blog](https://blog.unity.com/technology/ml-agents-v20-release-now-supports-training-complex-cooperative-behaviors)ä¸­æ‰€è§£é‡Šçš„ï¼Œå½“å›¢é˜Ÿè¿›çƒæ—¶ï¼Œä»£ç†é€šå¸¸ä½œä¸ºä¸€ä¸ªå›¢ä½“æ”¶åˆ°å¥–åŠ±ï¼ˆ+1
    - ç½šåˆ†ï¼‰ã€‚è¿™æ„å‘³ç€**å³ä½¿æ¯ä¸ªä»£ç†æ²¡æœ‰å¯¹èƒœåˆ©åšå‡ºç›¸åŒçš„è´¡çŒ®ï¼Œå›¢é˜Ÿä¸­çš„æ¯ä¸ªä»£ç†éƒ½ä¼šå—åˆ°å¥–åŠ±**ï¼Œè¿™ä½¿å¾—ç‹¬ç«‹å­¦ä¹ å˜å¾—å›°éš¾ã€‚
- en: The Unity MLAgents team developed the solution in a new multi-agent trainer
    called *MA-POCA (Multi-Agent POsthumous Credit Assignment)*.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Unity MLAgentså›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªæ–°çš„å¤šä»£ç†è®­ç»ƒå™¨è§£å†³æ–¹æ¡ˆï¼Œç§°ä¸º*MA-POCAï¼ˆå¤šä»£ç†åæœŸä¿¡ç”¨åˆ†é…ï¼‰*ã€‚
- en: 'The idea is simple but powerful: a centralized critic **processes the states
    of all agents in the team to estimate how well each agent is doing**. Think of
    this critic as a coach.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæƒ³æ³•ç®€å•ä½†å¼ºå¤§ï¼šä¸€ä¸ªé›†ä¸­çš„è¯„è®ºè€…**å¤„ç†å›¢é˜Ÿä¸­æ‰€æœ‰ä»£ç†çš„çŠ¶æ€ï¼Œä»¥ä¼°è®¡æ¯ä¸ªä»£ç†çš„è¡¨ç°**ã€‚æŠŠè¿™ä¸ªè¯„è®ºè€…æƒ³è±¡æˆä¸€ä¸ªæ•™ç»ƒã€‚
- en: This allows each agent to **make decisions based only on what it perceives locally**,
    and **simultaneously evaluate how good its behavior is in the context of the whole
    group**.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—æ¯ä¸ªä»£ç†**åªåŸºäºå…¶æœ¬åœ°æ„ŸçŸ¥åšå‡ºå†³ç­–**ï¼Œå¹¶**åŒæ—¶è¯„ä¼°å…¶è¡Œä¸ºåœ¨æ•´ä¸ªå›¢é˜Ÿç¯å¢ƒä¸­çš„è¡¨ç°**ã€‚
- en: '![MA POCA](../Images/7ad7814daeea1597757fe72e8d0ff01a.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![MA POCA](../Images/7ad7814daeea1597757fe72e8d0ff01a.png)'
- en: 'This illustrates MA-POCAâ€™s centralized learning and decentralized execution.
    Source: [MLAgents Plays Dodgeball](https://blog.unity.com/technology/ml-agents-plays-dodgeball)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¯´æ˜äº† MA-POCA çš„é›†ä¸­å¼å­¦ä¹ å’Œåˆ†æ•£å¼æ‰§è¡Œã€‚æ¥æºï¼š[MLAgents Plays Dodgeball](https://blog.unity.com/technology/ml-agents-plays-dodgeball)
- en: The solution then is to use Self-Play with an MA-POCA trainer (called poca).
    The poca trainer will help us to train cooperative behavior and self-play to win
    against an opponent team.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨è‡ªæˆ‘å¯¹å¼ˆå’Œ MA-POCA è®­ç»ƒå™¨ï¼ˆç§°ä¸º pocaï¼‰ã€‚poca è®­ç»ƒå™¨å°†å¸®åŠ©æˆ‘ä»¬è®­ç»ƒåˆä½œè¡Œä¸ºå’Œè‡ªæˆ‘å¯¹å¼ˆä»¥èµ¢å¾—å¯¹æ‰‹å›¢é˜Ÿã€‚
- en: If you want to dive deeper into this MA-POCA algorithm, you need to read the
    paper they published [here](https://arxiv.org/pdf/2111.05992.pdf) and the sources
    we put on the additional readings section.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³æ·±å…¥äº†è§£è¿™ä¸ª MA-POCA ç®—æ³•ï¼Œæ‚¨éœ€è¦é˜…è¯»ä»–ä»¬å‘è¡¨çš„è®ºæ–‡[è¿™é‡Œ](https://arxiv.org/pdf/2111.05992.pdf)ä»¥åŠæˆ‘ä»¬æ”¾åœ¨é™„åŠ é˜…è¯»éƒ¨åˆ†çš„æ¥æºã€‚
- en: 'Step 3: Define the config file'
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ 3 æ­¥ï¼šå®šä¹‰é…ç½®æ–‡ä»¶
- en: We already learned in [Unit 5](https://huggingface.co/deep-rl-course/unit5/introduction)
    that in ML-Agents, you define **the training hyperparameters in `config.yaml`
    files.**
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»åœ¨[Unit 5](https://huggingface.co/deep-rl-course/unit5/introduction)ä¸­å­¦åˆ°ï¼Œåœ¨
    ML-Agents ä¸­ï¼Œæ‚¨å¯ä»¥åœ¨ `config.yaml` æ–‡ä»¶ä¸­å®šä¹‰**è®­ç»ƒè¶…å‚æ•°ã€‚**
- en: There are multiple hyperparameters. To understand them better, you should read
    the explanations for each of them inÂ **[the documentation](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md)**
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å¤šä¸ªè¶…å‚æ•°ã€‚è¦æ›´å¥½åœ°ç†è§£å®ƒä»¬ï¼Œæ‚¨åº”è¯¥é˜…è¯»**[æ–‡æ¡£](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md)**ä¸­æ¯ä¸ªè¶…å‚æ•°çš„è§£é‡Šã€‚
- en: 'The config file weâ€™re going to use here is in `./config/poca/SoccerTwos.yaml`.
    It looks like this:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨çš„é…ç½®æ–‡ä»¶åœ¨ `./config/poca/SoccerTwos.yaml` ä¸­ã€‚å®ƒçœ‹èµ·æ¥åƒè¿™æ ·ï¼š
- en: '[PRE3]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Compared to Pyramids or SnowballTarget, we have new hyperparameters with a self-play
    part. How you modify them can be critical in getting good results.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ Pyramids æˆ– SnowballTarget ç›¸æ¯”ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«è‡ªæˆ‘å¯¹å¼ˆéƒ¨åˆ†çš„æ–°è¶…å‚æ•°ã€‚æ‚¨å¦‚ä½•ä¿®æ”¹å®ƒä»¬å¯èƒ½å¯¹è·å¾—è‰¯å¥½ç»“æœè‡³å…³é‡è¦ã€‚
- en: The advice I can give you here is to check the explanation and recommended value
    for each parameters (especially self-play ones) againstÂ **[the documentation](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md).**
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥ç»™æ‚¨çš„å»ºè®®æ˜¯æ£€æŸ¥æ¯ä¸ªå‚æ•°çš„è§£é‡Šå’Œæ¨èå€¼ï¼ˆç‰¹åˆ«æ˜¯è‡ªæˆ‘å¯¹å¼ˆå‚æ•°ï¼‰ä¸**[æ–‡æ¡£](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md)**è¿›è¡Œå¯¹æ¯”ã€‚
- en: Now that youâ€™ve modified our config file, youâ€™re ready to train your agents.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²ç»ä¿®æ”¹äº†æˆ‘ä»¬çš„é…ç½®æ–‡ä»¶ï¼Œå‡†å¤‡å¥½è®­ç»ƒæ‚¨çš„ä»£ç†äº†ã€‚
- en: 'Step 4: Start the training'
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ 4 æ­¥ï¼šå¼€å§‹è®­ç»ƒ
- en: To train the agents, we need toÂ **launch mlagents-learn and select the executable
    containing the environment.**
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒä»£ç†ï¼Œæˆ‘ä»¬éœ€è¦**å¯åŠ¨ mlagents-learn å¹¶é€‰æ‹©åŒ…å«ç¯å¢ƒçš„å¯æ‰§è¡Œæ–‡ä»¶ã€‚**
- en: 'We define four parameters:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®šä¹‰äº†å››ä¸ªå‚æ•°ï¼š
- en: '`mlagents-learn <config>`: the path where the hyperparameter config file is.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`mlagents-learn <config>`ï¼šè¶…å‚æ•°é…ç½®æ–‡ä»¶æ‰€åœ¨è·¯å¾„ã€‚'
- en: '`-env`: where the environment executable is.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`-env`ï¼šç¯å¢ƒå¯æ‰§è¡Œæ–‡ä»¶æ‰€åœ¨ä½ç½®ã€‚'
- en: '`-run_id`: the name you want to give to your training run id.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`-run_id`ï¼šæ‚¨è¦ä¸ºè®­ç»ƒè¿è¡Œ ID æŒ‡å®šçš„åç§°ã€‚'
- en: '`-no-graphics`: to not launch the visualization during the training.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`-no-graphics`ï¼šåœ¨è®­ç»ƒæœŸé—´ä¸å¯åŠ¨å¯è§†åŒ–ã€‚'
- en: Depending on your hardware, 5M timesteps (the recommended value, but you can
    also try 10M) will take 5 to 8 hours of training. You can continue using your
    computer in the meantime, but I advise deactivating the computer standby mode
    to prevent the training from being stopped.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æ‚¨çš„ç¡¬ä»¶ï¼Œ500 ä¸‡ä¸ªæ—¶é—´æ­¥ï¼ˆæ¨èå€¼ï¼Œä½†ä¹Ÿå¯ä»¥å°è¯• 1000 ä¸‡ï¼‰éœ€è¦ 5 åˆ° 8 å°æ—¶çš„è®­ç»ƒæ—¶é—´ã€‚åœ¨æ­¤æœŸé—´ï¼Œæ‚¨å¯ä»¥ç»§ç»­ä½¿ç”¨è®¡ç®—æœºï¼Œä½†æˆ‘å»ºè®®åœç”¨è®¡ç®—æœºå¾…æœºæ¨¡å¼ä»¥é˜²æ­¢è®­ç»ƒè¢«åœæ­¢ã€‚
- en: Depending on the executable you use (windows, ubuntu, mac) the training command
    will look like this (your executable path can be different so donâ€™t hesitate to
    check before running).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æ‚¨ä½¿ç”¨çš„å¯æ‰§è¡Œæ–‡ä»¶ï¼ˆwindowsã€ubuntuã€macï¼‰ï¼Œè®­ç»ƒå‘½ä»¤å°†å¦‚ä¸‹æ‰€ç¤ºï¼ˆæ‚¨çš„å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„å¯èƒ½ä¸åŒï¼Œå› æ­¤åœ¨è¿è¡Œä¹‹å‰è¯·åŠ¡å¿…æ£€æŸ¥ï¼‰ã€‚
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The executable contains 8 copies of SoccerTwos.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å¯æ‰§è¡Œæ–‡ä»¶åŒ…å« 8 ä¸ª SoccerTwos çš„å‰¯æœ¬ã€‚
- en: âš ï¸ Itâ€™s normal if you donâ€™t see a big increase of ELO score (and even a decrease
    below 1200) before 2M timesteps, since your agents will spend most of their time
    moving randomly on the field before being able to goal.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ å¦‚æœåœ¨ 200 ä¸‡ä¸ªæ—¶é—´æ­¥ä¹‹å‰çœ‹ä¸åˆ° ELO åˆ†æ•°çš„å¤§å¹…å¢åŠ ï¼ˆç”šè‡³åœ¨ 1200 ä»¥ä¸‹ä¸‹é™ï¼‰æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæ‚¨çš„ä»£ç†å°†åœ¨èƒ½å¤Ÿè¿›çƒä¹‹å‰å¤§éƒ¨åˆ†æ—¶é—´éšæœºç§»åŠ¨åœ¨åœºåœ°ä¸Šã€‚
- en: âš ï¸ You can stop the training with Ctrl + C but beware of typing this command
    only once to stop the training since MLAgents needs to generate a final .onnx
    file before closing the run.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸ æ‚¨å¯ä»¥ä½¿ç”¨ Ctrl + C åœæ­¢è®­ç»ƒï¼Œä½†è¦æ³¨æ„åªé”®å…¥æ­¤å‘½ä»¤ä¸€æ¬¡ä»¥åœæ­¢è®­ç»ƒï¼Œå› ä¸º MLAgents éœ€è¦åœ¨å…³é—­è¿è¡Œä¹‹å‰ç”Ÿæˆæœ€ç»ˆçš„ .onnx æ–‡ä»¶ã€‚
- en: 'Step 5: Push the agent to the Hugging Face Hub'
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ 5 æ­¥ï¼šå°†ä»£ç†æ¨é€åˆ° Hugging Face Hub
- en: Now that we trained our agents, weâ€™reÂ **ready to push them to the Hub to be
    able to participate in the AI vs. AI challenge and visualize them playing on your
    browserğŸ”¥.**
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»è®­ç»ƒäº†æˆ‘ä»¬çš„ä»£ç†ï¼Œæˆ‘ä»¬**å‡†å¤‡å°†å®ƒä»¬æ¨é€åˆ° Hubï¼Œä»¥ä¾¿å‚åŠ  AI å¯¹æŠ—èµ›å¹¶åœ¨æµè§ˆå™¨ä¸Šè§‚çœ‹å®ƒä»¬çš„æ¯”èµ›ğŸ”¥ã€‚**
- en: 'To be able to share your model with the community, there are three more steps
    to follow:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¦èƒ½å¤Ÿä¸ç¤¾åŒºå…±äº«æ‚¨çš„æ¨¡å‹ï¼Œè¿˜æœ‰ä¸‰ä¸ªæ­¥éª¤è¦éµå¾ªï¼š
- en: 1ï¸âƒ£ (If itâ€™s not already done) create an account to HF â¡Â [https://huggingface.co/join](https://huggingface.co/join)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰åˆ›å»ºä¸€ä¸ª HF å¸æˆ· â¡ [https://huggingface.co/join](https://huggingface.co/join)
- en: 2ï¸âƒ£ Sign in and store your authentication token from the Hugging Face website.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ ç™»å½•å¹¶å­˜å‚¨æ¥è‡ª Hugging Face ç½‘ç«™çš„èº«ä»½éªŒè¯ä»¤ç‰Œã€‚
- en: Create a new token ([https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))Â **with
    write role**
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªæ–°ä»¤ç‰Œï¼ˆ[https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)ï¼‰**å…·æœ‰å†™å…¥æƒé™**
- en: '![Create HF Token](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![åˆ›å»º HF ä»¤ç‰Œ](../Images/d21a97c736edaab9119d2d1c1da9deac.png)'
- en: Copy the token, run this, and paste the token
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å¤åˆ¶ä»¤ç‰Œï¼Œè¿è¡Œæ­¤å‘½ä»¤ï¼Œç„¶åç²˜è´´ä»¤ç‰Œ
- en: '[PRE5]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Then, we need to run `mlagents-push-to-hf`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬éœ€è¦è¿è¡Œ `mlagents-push-to-hf`ã€‚
- en: 'And we define four parameters:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®šä¹‰äº†å››ä¸ªå‚æ•°ï¼š
- en: '`-run-id`: the name of the training run id.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`-run-id`ï¼šè®­ç»ƒè¿è¡ŒIDçš„åç§°ã€‚'
- en: '`-local-dir`: where the agent was saved, itâ€™s results/<run_id name>, so in
    my case results/First Training.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`-local-dir`ï¼šä»£ç†ä¿å­˜çš„ä½ç½®ï¼Œæ˜¯results/<run_idåç§°>ï¼Œæ‰€ä»¥åœ¨æˆ‘çš„æƒ…å†µä¸‹æ˜¯results/First Trainingã€‚'
- en: '`-repo-id`: the name of the Hugging Face repo you want to create or update.
    Itâ€™s always <your huggingface username>/<the repo name> If the repo does not exist
    **it will be created automatically**'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`-repo-id`ï¼šæ‚¨è¦åˆ›å»ºæˆ–æ›´æ–°çš„Hugging Face repoçš„åç§°ã€‚å®ƒå§‹ç»ˆæ˜¯<æ‚¨çš„Hugging Faceç”¨æˆ·å>/<repoåç§°>å¦‚æœä»“åº“ä¸å­˜åœ¨**å°†è‡ªåŠ¨åˆ›å»º**'
- en: '`--commit-message`: since HF repos are git repositories you need to give a
    commit message.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`--commit-message`ï¼šç”±äºHFä»“åº“æ˜¯gitå­˜å‚¨åº“ï¼Œæ‚¨éœ€è¦æä¾›æäº¤æ¶ˆæ¯ã€‚'
- en: In my case
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘çš„æƒ…å†µä¸‹
- en: '[PRE6]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If everything worked you should see this at the end of the process (but with
    a different url ğŸ˜†) :'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œæ‚¨åº”è¯¥åœ¨è¿‡ç¨‹ç»“æŸæ—¶çœ‹åˆ°è¿™ä¸ªï¼ˆä½†ç½‘å€ä¸åŒğŸ˜†ï¼‰ï¼š
- en: 'Your model is pushed to the Hub. You can view your model here: [https://huggingface.co/ThomasSimonini/poca-SoccerTwos](https://huggingface.co/ThomasSimonini/poca-SoccerTwos)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨çš„æ¨¡å‹å·²æ¨é€åˆ°Hubã€‚æ‚¨å¯ä»¥åœ¨æ­¤æŸ¥çœ‹æ‚¨çš„æ¨¡å‹ï¼š[https://huggingface.co/ThomasSimonini/poca-SoccerTwos](https://huggingface.co/ThomasSimonini/poca-SoccerTwos)
- en: Itâ€™s the link to your model. It contains a model card that explains how to use
    it, your Tensorboard, and your config file. **Whatâ€™s awesome is that itâ€™s a git
    repository, which means you can have different commits, update your repository
    with a new push, etc.**
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ‚¨æ¨¡å‹çš„é“¾æ¥ã€‚å®ƒåŒ…å«ä¸€ä¸ªè§£é‡Šå¦‚ä½•ä½¿ç”¨å®ƒçš„æ¨¡å‹å¡ç‰‡ï¼Œæ‚¨çš„Tensorboardå’Œé…ç½®æ–‡ä»¶ã€‚**ä»¤äººæƒŠå¥‡çš„æ˜¯ï¼Œå®ƒæ˜¯ä¸€ä¸ªgitå­˜å‚¨åº“ï¼Œè¿™æ„å‘³ç€æ‚¨å¯ä»¥æœ‰ä¸åŒçš„æäº¤ï¼Œä½¿ç”¨æ–°çš„æ¨é€æ›´æ–°æ‚¨çš„å­˜å‚¨åº“ç­‰ã€‚**
- en: 'Step 6: Verify that your model is ready for AI vs AI Challenge'
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬6æ­¥ï¼šéªŒè¯æ‚¨çš„æ¨¡å‹æ˜¯å¦å‡†å¤‡å¥½å‚åŠ AI vs AIæŒ‘æˆ˜
- en: Now that your model is pushed to the Hub, **itâ€™s going to be added automatically
    to the AI vs AI Challenge model pool.** It can take a little bit of time before
    your model is added to the leaderboard given we do a run of matches every 4h.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨çš„æ¨¡å‹å·²æ¨é€åˆ°Hubï¼Œ**å®ƒå°†è‡ªåŠ¨æ·»åŠ åˆ°AI vs AIæŒ‘æˆ˜æ¨¡å‹æ± ä¸­ã€‚**åœ¨æ‚¨çš„æ¨¡å‹è¢«æ·»åŠ åˆ°æ’è¡Œæ¦œä¹‹å‰å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´ï¼Œå› ä¸ºæˆ‘ä»¬æ¯4å°æ—¶è¿›è¡Œä¸€æ¬¡æ¯”èµ›ã€‚
- en: 'But to ensure that everything works perfectly you need to check:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä¸ºäº†ç¡®ä¿ä¸€åˆ‡éƒ½èƒ½å®Œç¾è¿è¡Œï¼Œæ‚¨éœ€è¦æ£€æŸ¥ï¼š
- en: 'That you have this tag in your model: ML-Agents-SoccerTwos. This is the tag
    we use to select models to be added to the challenge pool. To do that go to your
    model and check the tags'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‚¨çš„æ¨¡å‹ä¸­æœ‰è¿™ä¸ªæ ‡ç­¾ï¼šML-Agents-SoccerTwosã€‚è¿™æ˜¯æˆ‘ä»¬ç”¨æ¥é€‰æ‹©è¦æ·»åŠ åˆ°æŒ‘æˆ˜æ± ä¸­çš„æ¨¡å‹çš„æ ‡ç­¾ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œè¯·è½¬åˆ°æ‚¨çš„æ¨¡å‹å¹¶æ£€æŸ¥æ ‡ç­¾
- en: '![Verify](../Images/f293f2ed5fa03cd6a2cd77086f6200a5.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![éªŒè¯](../Images/f293f2ed5fa03cd6a2cd77086f6200a5.png)'
- en: If itâ€™s not the case you just need to modify the readme and add it
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸æ˜¯è¿™ç§æƒ…å†µï¼Œæ‚¨åªéœ€è¦ä¿®æ”¹è‡ªè¿°æ–‡ä»¶å¹¶æ·»åŠ å®ƒ
- en: '![Verify](../Images/9cec0da6fa3195c208f23e9300898d7e.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![éªŒè¯](../Images/9cec0da6fa3195c208f23e9300898d7e.png)'
- en: That you have a `SoccerTwos.onnx` file
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‚¨æœ‰ä¸€ä¸ª`SoccerTwos.onnx`æ–‡ä»¶
- en: '![Verify](../Images/99478ac1cd0c73aef674a98bc5457f48.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![éªŒè¯](../Images/99478ac1cd0c73aef674a98bc5457f48.png)'
- en: We strongly suggest that you create a new model when you push to the Hub if
    you want to train it again or train a new version.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨åœ¨æ¨é€åˆ°Hubæ—¶åˆ›å»ºä¸€ä¸ªæ–°æ¨¡å‹ï¼Œå¦‚æœæ‚¨æƒ³å†æ¬¡è®­ç»ƒå®ƒæˆ–è®­ç»ƒä¸€ä¸ªæ–°ç‰ˆæœ¬ã€‚
- en: 'Step 7: Visualize some match in our demo'
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬7æ­¥ï¼šåœ¨æˆ‘ä»¬çš„æ¼”ç¤ºä¸­å¯è§†åŒ–ä¸€äº›åŒ¹é…
- en: 'Now that your model is part of AI vs AI Challenge, **you can visualize how
    good it is compared to others**: [https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos](https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨çš„æ¨¡å‹æ˜¯AI vs AIæŒ‘æˆ˜çš„ä¸€éƒ¨åˆ†ï¼Œ**æ‚¨å¯ä»¥å¯è§†åŒ–å®ƒä¸å…¶ä»–æ¨¡å‹çš„ä¼˜åŠ£**ï¼š[https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos](https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos)
- en: 'In order to do that, you just need to go to this demo:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæ‚¨åªéœ€è¦è½¬åˆ°æ­¤æ¼”ç¤ºï¼š
- en: Select your model as team blue (or team purple if you prefer) and another model
    to compete against. The best opponents to compare your model to are either whoever
    is on top of the leaderboard or the [baseline model](https://huggingface.co/unity/MLAgents-SoccerTwos)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€‰æ‹©æ‚¨çš„æ¨¡å‹ä½œä¸ºè“é˜Ÿï¼ˆæˆ–è€…å¦‚æœæ‚¨å–œæ¬¢ï¼Œä½œä¸ºç´«é˜Ÿï¼‰ï¼Œå¹¶é€‰æ‹©å¦ä¸€ä¸ªæ¨¡å‹è¿›è¡Œç«äº‰ã€‚ä¸æ‚¨çš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒçš„æœ€ä½³å¯¹æ‰‹è¦ä¹ˆæ˜¯æ’è¡Œæ¦œä¸Šçš„ç¬¬ä¸€åï¼Œè¦ä¹ˆæ˜¯[åŸºå‡†æ¨¡å‹](https://huggingface.co/unity/MLAgents-SoccerTwos)
- en: The matches you see live are not used in the calculation of your result **but
    they are a good way to visualize how good your agent is**.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å®æ—¶çœ‹åˆ°çš„æ¯”èµ›ä¸ä¼šç”¨äºè®¡ç®—æ‚¨çš„ç»“æœ**ä½†å®ƒä»¬æ˜¯å¯è§†åŒ–æ‚¨çš„ä»£ç†æœ‰å¤šå¥½çš„å¥½æ–¹æ³•**ã€‚
- en: 'And donâ€™t hesitate to share the best score your agent gets on discord in the
    #rl-i-made-this channel ğŸ”¥'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸”è¯·ä¸è¦çŠ¹è±«åœ¨discordçš„#rl-i-made-thisé¢‘é“ä¸­åˆ†äº«æ‚¨çš„ä»£ç†è·å¾—çš„æœ€ä½³åˆ†æ•°ğŸ”¥
