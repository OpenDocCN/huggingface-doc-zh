- en: Zero-shot image classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 零样本图像分类
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/tasks/zero_shot_image_classification](https://huggingface.co/docs/transformers/v4.37.2/en/tasks/zero_shot_image_classification)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://huggingface.co/docs/transformers/v4.37.2/en/tasks/zero_shot_image_classification](https://huggingface.co/docs/transformers/v4.37.2/en/tasks/zero_shot_image_classification)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot image classification is a task that involves classifying images into
    different categories using a model that was not explicitly trained on data containing
    labeled examples from those specific categories.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本图像分类是一个任务，涉及使用未明确训练包含来自这些特定类别的标记示例的数据的模型将图像分类为不同的类别。
- en: Traditionally, image classification requires training a model on a specific
    set of labeled images, and this model learns to “map” certain image features to
    labels. When there’s a need to use such model for a classification task that introduces
    a new set of labels, fine-tuning is required to “recalibrate” the model.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，图像分类需要在特定一组带标签的图像上训练模型，该模型学习将某些图像特征“映射”到标签。当需要将这样的模型用于引入新标签集的分类任务时，需要进行微调以“重新校准”模型。
- en: In contrast, zero-shot or open vocabulary image classification models are typically
    multi-modal models that have been trained on a large dataset of images and associated
    descriptions. These models learn aligned vision-language representations that
    can be used for many downstream tasks including zero-shot image classification.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，零样本或开放词汇图像分类模型通常是多模态模型，已经在大量图像和相关描述的数据集上进行了训练。这些模型学习了对齐的视觉-语言表示，可用于许多下游任务，包括零样本图像分类。
- en: This is a more flexible approach to image classification that allows models
    to generalize to new and unseen categories without the need for additional training
    data and enables users to query images with free-form text descriptions of their
    target objects .
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种更灵活的图像分类方法，允许模型推广到新的和未见过的类别，而无需额外的训练数据，并且使用户能够使用目标对象的自由形式文本描述查询图像。
- en: 'In this guide you’ll learn how to:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本指南中，您将学习如何：
- en: create a zero-shot image classification pipeline
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个零样本图像分类管道
- en: run zero-shot image classification inference by hand
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动运行零样本图像分类推理
- en: 'Before you begin, make sure you have all the necessary libraries installed:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保已安装所有必要的库：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Zero-shot image classification pipeline
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零样本图像分类管道
- en: 'The simplest way to try out inference with a model supporting zero-shot image
    classification is to use the corresponding [pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline).
    Instantiate a pipeline from a [checkpoint on the Hugging Face Hub](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&sort=downloads):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用支持零样本图像分类的模型进行推理的最简单方法是使用相应的[pipeline()](/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline)。从[Hugging
    Face Hub上的检查点](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&sort=downloads)实例化一个管道：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Next, choose an image you’d like to classify.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，选择一个您想要分类的图像。
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Photo of an owl](../Images/ceeab937a1338358216d31c99c500d27.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![猫头鹰的照片](../Images/ceeab937a1338358216d31c99c500d27.png)'
- en: Pass the image and the candidate object labels to the pipeline. Here we pass
    the image directly; other suitable options include a local path to an image or
    an image url. The candidate labels can be simple words like in this example, or
    more descriptive.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像和候选对象标签传递给管道。在这里，我们直接传递图像；其他合适的选项包括图像的本地路径或图像url。候选标签可以像这个例子中那样简单，也可以更具描述性。
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Zero-shot image classification by hand
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动进行零样本图像分类
- en: Now that you’ve seen how to use the zero-shot image classification pipeline,
    let’s take a look how you can run zero-shot image classification manually.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经看到如何使用零样本图像分类管道，让我们看看如何手动运行零样本图像分类。
- en: 'Start by loading the model and associated processor from a [checkpoint on the
    Hugging Face Hub](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&sort=downloads).
    Here we’ll use the same checkpoint as before:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先从[Hugging Face Hub上的检查点](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&sort=downloads)加载模型和相关处理器。在这里，我们将使用与之前相同的检查点：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let’s take a different image to switch things up.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们换一张不同的图片。
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Photo of a car](../Images/32d5d4f7954f70dbb6de697af5252857.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![汽车的照片](../Images/32d5d4f7954f70dbb6de697af5252857.png)'
- en: Use the processor to prepare the inputs for the model. The processor combines
    an image processor that prepares the image for the model by resizing and normalizing
    it, and a tokenizer that takes care of the text inputs.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用处理器为模型准备输入。处理器结合了一个图像处理器，通过调整大小和归一化来为模型准备图像，以及一个标记器，负责处理文本输入。
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Pass the inputs through the model, and post-process the results:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模型传递输入，并对结果进行后处理：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
