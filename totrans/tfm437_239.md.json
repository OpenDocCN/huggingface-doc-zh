["```py\n>>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n>>> import pandas as pd\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\")\n>>> model = AutoModelForSeq2SeqLM.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\")\n\n>>> # prepare table + question\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> table = pd.DataFrame.from_dict(data)\n>>> question = \"how many movies does Leonardo Di Caprio have?\"\n\n>>> encoding = tokenizer(table, question, return_tensors=\"pt\")\n\n>>> # let the model generate an answer autoregressively\n>>> outputs = model.generate(**encoding)\n\n>>> # decode back to text\n>>> predicted_answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n>>> print(predicted_answer)\n53\n```", "```py\n>>> # prepare table + question\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> table = pd.DataFrame.from_dict(data)\n>>> questions = [\n...     \"how many movies does Leonardo Di Caprio have?\",\n...     \"which actor has 69 movies?\",\n...     \"what's the first name of the actor who has 87 movies?\",\n... ]\n>>> encoding = tokenizer(table, questions, padding=True, return_tensors=\"pt\")\n\n>>> # let the model generate an answer autoregressively\n>>> outputs = model.generate(**encoding)\n\n>>> # decode back to text\n>>> tokenizer.batch_decode(outputs, skip_special_tokens=True)\n[' 53', ' george clooney', ' brad pitt']\n```", "```py\n>>> from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large-finetuned-tabfact\")\n>>> model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/tapex-large-finetuned-tabfact\")\n\n>>> # prepare table + sentence\n>>> data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n>>> table = pd.DataFrame.from_dict(data)\n>>> sentence = \"George Clooney has 30 movies\"\n\n>>> encoding = tokenizer(table, sentence, return_tensors=\"pt\")\n\n>>> # forward pass\n>>> outputs = model(**encoding)\n\n>>> # print prediction\n>>> predicted_class_idx = outputs.logits[0].argmax(dim=0).item()\n>>> print(model.config.id2label[predicted_class_idx])\nRefused\n```", "```py\n( vocab_file merges_file do_lower_case = True errors = 'replace' bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' add_prefix_space = False max_cell_length = 15 **kwargs )\n```", "```py\n( table: Union = None query: Union = None answer: Union = None add_special_tokens: bool = True padding: Union = False truncation: Union = None max_length: Optional = None stride: int = 0 pad_to_multiple_of: Optional = None return_tensors: Union = None return_token_type_ids: Optional = None return_attention_mask: Optional = None return_overflowing_tokens: bool = False return_special_tokens_mask: bool = False return_offsets_mapping: bool = False return_length: bool = False verbose: bool = True **kwargs )\n```", "```py\n( save_directory: str filename_prefix: Optional = None )\n```"]