["```py\n( num_attention_heads: int = 32 attention_head_dim: int = 64 num_layers: int = 20 embedding_dim: int = 768 num_embeddings = 77 additional_embeddings = 4 dropout: float = 0.0 time_embed_act_fn: str = 'silu' norm_in_type: Optional = None embedding_proj_norm_type: Optional = None encoder_hid_proj_type: Optional = 'linear' added_emb_type: Optional = 'prd' time_embed_dim: Optional = None embedding_proj_dim: Optional = None clip_embed_dim: Optional = None )\n```", "```py\n( hidden_states timestep: Union proj_embedding: FloatTensor encoder_hidden_states: Optional = None attention_mask: Optional = None return_dict: bool = True ) \u2192 export const metadata = 'undefined';~models.prior_transformer.PriorTransformerOutput or tuple\n```", "```py\n( processor: Union )\n```", "```py\n( )\n```", "```py\n( predicted_image_embedding: FloatTensor )\n```"]