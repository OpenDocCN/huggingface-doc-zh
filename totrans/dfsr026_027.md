# å›¾åƒåˆ°å›¾åƒ

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/using-diffusers/img2img](https://huggingface.co/docs/diffusers/using-diffusers/img2img)

å›¾åƒåˆ°å›¾åƒç±»ä¼¼äº [æ–‡æœ¬åˆ°å›¾åƒ](conditional_image_generation)ï¼Œä½†é™¤äº†ä¸€ä¸ªæç¤ºå¤–ï¼Œæ‚¨è¿˜å¯ä»¥ä¼ é€’ä¸€ä¸ªåˆå§‹å›¾åƒä½œä¸ºæ‰©æ•£è¿‡ç¨‹çš„èµ·ç‚¹ã€‚åˆå§‹å›¾åƒè¢«ç¼–ç åˆ°æ½œåœ¨ç©ºé—´ä¸­ï¼Œå¹¶å‘å…¶æ·»åŠ å™ªå£°ã€‚ç„¶åï¼Œæ½œåœ¨æ‰©æ•£æ¨¡å‹æ¥æ”¶ä¸€ä¸ªæç¤ºå’Œå˜ˆæ‚çš„æ½œåœ¨å›¾åƒï¼Œé¢„æµ‹æ·»åŠ çš„å™ªå£°ï¼Œå¹¶ä»åˆå§‹æ½œåœ¨å›¾åƒä¸­å»é™¤é¢„æµ‹çš„å™ªå£°ä»¥è·å¾—æ–°çš„æ½œåœ¨å›¾åƒã€‚æœ€åï¼Œè§£ç å™¨å°†æ–°çš„æ½œåœ¨å›¾åƒè§£ç å›å›¾åƒã€‚

ä½¿ç”¨ ğŸ¤— Diffusersï¼Œè¿™å°±åƒ 1-2-3 ä¸€æ ·ç®€å•ï¼š

1.  å°†æ£€æŸ¥ç‚¹åŠ è½½åˆ° [AutoPipelineForImage2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image) ç±»ä¸­ï¼›æ­¤ç®¡é“ä¼šæ ¹æ®æ£€æŸ¥ç‚¹è‡ªåŠ¨å¤„ç†åŠ è½½æ­£ç¡®çš„ç®¡é“ç±»ï¼š

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16, use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()
```

åœ¨æ•´ä¸ªæŒ‡å—ä¸­ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°æˆ‘ä»¬ä½¿ç”¨ [enable_model_cpu_offload()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload) å’Œ [enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention)ï¼Œä»¥èŠ‚çœå†…å­˜å¹¶å¢åŠ æ¨ç†é€Ÿåº¦ã€‚å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ PyTorch 2.0ï¼Œåˆ™ä¸éœ€è¦åœ¨ç®¡é“ä¸Šè°ƒç”¨ [enable_xformers_memory_efficient_attention()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_xformers_memory_efficient_attention)ï¼Œå› ä¸ºå®ƒå·²ç»åœ¨ä½¿ç”¨ PyTorch 2.0 çš„æœ¬æœº [scaled-dot product attention](../optimization/torch2.0#scaled-dot-product-attention)ã€‚

1.  åŠ è½½ä¸€ä¸ªå›¾åƒä¼ é€’ç»™ç®¡é“ï¼š

```py
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png")
```

1.  ä¼ é€’ä¸€ä¸ªæç¤ºå’Œå›¾åƒç»™ç®¡é“ä»¥ç”Ÿæˆä¸€ä¸ªå›¾åƒï¼š

```py
prompt = "cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k"
image = pipeline(prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![](../Images/b7dea39428bc1d2cd88a6400783552cb.png)

åˆå§‹å›¾åƒ

![](../Images/54142d2106911436dd03998048a92fad.png)

ç”Ÿæˆçš„å›¾åƒ

## æµè¡Œçš„æ¨¡å‹

æœ€å—æ¬¢è¿çš„å›¾åƒåˆ°å›¾åƒæ¨¡å‹æ˜¯ [ç¨³å®šæ‰©æ•£ v1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5)ã€[ç¨³å®šæ‰©æ•£ XL (SDXL)](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) å’Œ [Kandinsky 2.2](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder)ã€‚ç”±äºå®ƒä»¬çš„æ¶æ„å·®å¼‚å’Œè®­ç»ƒè¿‡ç¨‹çš„ä¸åŒï¼Œç¨³å®šæ‰©æ•£å’Œ Kandinsky æ¨¡å‹çš„ç»“æœä¼šæœ‰æ‰€ä¸åŒï¼›é€šå¸¸å¯ä»¥é¢„æœŸ SDXL ä¼šäº§ç”Ÿæ¯”ç¨³å®šæ‰©æ•£ v1.5 æ›´é«˜è´¨é‡çš„å›¾åƒã€‚è®©æˆ‘ä»¬å¿«é€Ÿçœ‹çœ‹å¦‚ä½•ä½¿ç”¨è¿™äº›æ¨¡å‹å¹¶æ¯”è¾ƒå®ƒä»¬çš„ç»“æœã€‚

### ç¨³å®šæ‰©æ•£ v1.5

ç¨³å®šæ‰©æ•£ v1.5 æ˜¯ä¸€ä¸ªä»æ—©æœŸæ£€æŸ¥ç‚¹åˆå§‹åŒ–çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¹¶åœ¨ 512x512 å›¾åƒä¸Šè¿›ä¸€æ­¥å¾®è°ƒäº† 595K æ­¥ã€‚è¦å°†æ­¤ç®¡é“ç”¨äºå›¾åƒåˆ°å›¾åƒï¼Œæ‚¨éœ€è¦å‡†å¤‡ä¸€ä¸ªåˆå§‹å›¾åƒä¼ é€’ç»™ç®¡é“ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ä¼ é€’ä¸€ä¸ªæç¤ºå’Œå›¾åƒç»™ç®¡é“ä»¥ç”Ÿæˆä¸€ä¸ªæ–°å›¾åƒï¼š

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![](../Images/36dc16e92be7b4f357b7201ad98da118.png)

åˆå§‹å›¾åƒ

![](../Images/0145794767dd4ef55a2071169ec77aa2.png)

ç”Ÿæˆçš„å›¾åƒ

### ç¨³å®šæ‰©æ•£ XL (SDXL)

SDXL æ˜¯ç¨³å®šæ‰©æ•£æ¨¡å‹çš„æ›´å¼ºå¤§ç‰ˆæœ¬ã€‚å®ƒä½¿ç”¨ä¸€ä¸ªæ›´å¤§çš„åŸºç¡€æ¨¡å‹ï¼Œä»¥åŠä¸€ä¸ªé¢å¤–çš„ç»†åŒ–æ¨¡å‹æ¥æé«˜åŸºç¡€æ¨¡å‹è¾“å‡ºçš„è´¨é‡ã€‚é˜…è¯» [SDXL](sdxl) æŒ‡å—ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨æ­¤æ¨¡å‹ä»¥åŠå®ƒç”¨äºç”Ÿæˆé«˜è´¨é‡å›¾åƒçš„å…¶ä»–æŠ€æœ¯ã€‚

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdxl-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, strength=0.5).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![](../Images/2fe2edb85787ba08991e059ff912c98c.png)

åˆå§‹å›¾åƒ

![](../Images/7ec0479f09a14b51ed59ccd01d6f93c9.png)

ç”Ÿæˆçš„å›¾åƒ

### Kandinsky 2.2

Kandinsky æ¨¡å‹ä¸ç¨³å®šæ‰©æ•£æ¨¡å‹ä¸åŒï¼Œå› ä¸ºå®ƒä½¿ç”¨å›¾åƒå…ˆéªŒæ¨¡å‹æ¥åˆ›å»ºå›¾åƒåµŒå…¥ã€‚è¿™äº›åµŒå…¥æœ‰åŠ©äºåœ¨æ–‡æœ¬å’Œå›¾åƒä¹‹é—´åˆ›å»ºæ›´å¥½çš„å¯¹é½ï¼Œä½¿æ½œåœ¨æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´å¥½çš„å›¾åƒã€‚

ä½¿ç”¨ Kandinsky 2.2 çš„æœ€ç®€å•æ–¹æ³•æ˜¯ï¼š

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16, use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![](../Images/36dc16e92be7b4f357b7201ad98da118.png)

åˆå§‹å›¾åƒ

![](../Images/97dcd8328035f392ab7d774997117ed0.png)

ç”Ÿæˆçš„å›¾åƒ

## é…ç½®ç®¡é“å‚æ•°

æ‚¨å¯ä»¥é…ç½®ç®¡é“ä¸­çš„å‡ ä¸ªé‡è¦å‚æ•°ï¼Œè¿™äº›å‚æ•°å°†å½±å“å›¾åƒç”Ÿæˆè¿‡ç¨‹å’Œå›¾åƒè´¨é‡ã€‚è®©æˆ‘ä»¬æ›´ä»”ç»†åœ°çœ‹çœ‹è¿™äº›å‚æ•°çš„ä½œç”¨ä»¥åŠå¦‚ä½•æ›´æ”¹å®ƒä»¬ä¼šå½±å“è¾“å‡ºã€‚

### å¼ºåº¦

`strength`æ˜¯è¦è€ƒè™‘çš„æœ€é‡è¦å‚æ•°ä¹‹ä¸€ï¼Œå®ƒå°†å¯¹ç”Ÿæˆçš„å›¾åƒäº§ç”Ÿå·¨å¤§å½±å“ã€‚å®ƒå†³å®šäº†ç”Ÿæˆçš„å›¾åƒä¸åˆå§‹å›¾åƒçš„ç›¸ä¼¼ç¨‹åº¦ã€‚æ¢å¥è¯è¯´ï¼š

+   ğŸ“ˆè¾ƒé«˜çš„`strength`å€¼ä½¿æ¨¡å‹æ›´å…·â€œåˆ›é€ åŠ›â€ï¼Œå¯ä»¥ç”Ÿæˆä¸åˆå§‹å›¾åƒä¸åŒçš„å›¾åƒï¼›`strength`å€¼ä¸º1.0æ„å‘³ç€åˆå§‹å›¾åƒæˆ–å¤šæˆ–å°‘è¢«å¿½ç•¥

+   ğŸ“‰è¾ƒä½çš„`strength`å€¼æ„å‘³ç€ç”Ÿæˆçš„å›¾åƒæ›´ç±»ä¼¼äºåˆå§‹å›¾åƒ

`strength`å’Œ`num_inference_steps`å‚æ•°ç›¸å…³ï¼Œå› ä¸º`strength`ç¡®å®šè¦æ·»åŠ çš„å™ªå£°æ­¥æ•°ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ`num_inference_steps`ä¸º50ï¼Œ`strength`ä¸º0.8ï¼Œåˆ™è¿™æ„å‘³ç€å‘åˆå§‹å›¾åƒæ·»åŠ 40ï¼ˆ50 * 0.8ï¼‰æ­¥å™ªå£°ï¼Œç„¶åå»å™ª40æ­¥ä»¥è·å¾—æ–°ç”Ÿæˆçš„å›¾åƒã€‚

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, strength=0.8).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![](../Images/b18d4d9ef1fda116b32a37eb344dd61d.png)

strength = 0.4

![](../Images/caabae187343ac728e132d95979f20d9.png)

strength = 0.6

![](../Images/6dd3ccf15afa5473f942682270943955.png)

strength = 1.0

### æŒ‡å¯¼å°ºåº¦

`guidance_scale`å‚æ•°ç”¨äºæ§åˆ¶ç”Ÿæˆçš„å›¾åƒå’Œæ–‡æœ¬æç¤ºä¹‹é—´çš„å¯¹é½ç¨‹åº¦ã€‚è¾ƒé«˜çš„`guidance_scale`å€¼æ„å‘³ç€æ‚¨ç”Ÿæˆçš„å›¾åƒä¸æç¤ºæ›´åŠ å¯¹é½ï¼Œè€Œè¾ƒä½çš„`guidance_scale`å€¼æ„å‘³ç€æ‚¨ç”Ÿæˆçš„å›¾åƒæœ‰æ›´å¤šçš„ç©ºé—´åç¦»æç¤ºã€‚

æ‚¨å¯ä»¥å°†`guidance_scale`ä¸`strength`ç»“åˆä½¿ç”¨ï¼Œä»¥æ›´ç²¾ç¡®åœ°æ§åˆ¶æ¨¡å‹çš„è¡¨ç°åŠ›ã€‚ä¾‹å¦‚ï¼Œç»“åˆé«˜`strength + guidance_scale`ä»¥è·å¾—æœ€å¤§åˆ›é€ åŠ›ï¼Œæˆ–è€…ä½¿ç”¨ä½`strength`å’Œä½`guidance_scale`çš„ç»„åˆç”Ÿæˆç±»ä¼¼äºåˆå§‹å›¾åƒä½†ä¸ä¸¥æ ¼å—é™äºæç¤ºçš„å›¾åƒã€‚

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, guidance_scale=8.0).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![](../Images/8f312f9d19115eba39cce061ca99ee11.png)

guidance_scale = 0.1

![](../Images/ee6aee8a1bb3c419a6a94dd5b4a870b8.png)

guidance_scale = 5.0

![](../Images/94e53acaee818fe2a3dddf5671819e4e.png)

guidance_scale = 10.0

### è´Ÿæç¤º

è´Ÿæç¤ºæ¡ä»¶æ¨¡å‹*ä¸*åœ¨å›¾åƒä¸­åŒ…å«æŸäº›å†…å®¹ï¼Œå¯ç”¨äºæ”¹å–„å›¾åƒè´¨é‡æˆ–ä¿®æ”¹å›¾åƒã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€šè¿‡åŒ…å«â€œç»†èŠ‚å·®â€æˆ–â€œæ¨¡ç³Šâ€ç­‰è´Ÿæç¤ºæ¥æ”¹å–„å›¾åƒè´¨é‡ï¼Œä»¥é¼“åŠ±æ¨¡å‹ç”Ÿæˆæ›´é«˜è´¨é‡çš„å›¾åƒã€‚æˆ–è€…æ‚¨å¯ä»¥é€šè¿‡æŒ‡å®šè¦ä»å›¾åƒä¸­æ’é™¤çš„å†…å®¹æ¥ä¿®æ”¹å›¾åƒã€‚

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
negative_prompt = "ugly, deformed, disfigured, poor details, bad anatomy"

# pass prompt and image to pipeline
image = pipeline(prompt, negative_prompt=negative_prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![](../Images/b0371dfac3fc42c122a50da2e48f809a.png)

negative_prompt = "ä¸‘é™‹ï¼Œç•¸å½¢ï¼Œæ¯å®¹ï¼Œç»†èŠ‚å·®ï¼Œè§£å‰–ä¸è‰¯"

![](../Images/420cf48fd86187c0fb09679e8d6a92bd.png)

negative_prompt = "ä¸›æ—"

## é“¾å¼å›¾åƒåˆ°å›¾åƒç®¡é“

é™¤äº†ç”Ÿæˆå›¾åƒä¹‹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥ä»¥å…¶ä»–æœ‰è¶£çš„æ–¹å¼ä½¿ç”¨å›¾åƒåˆ°å›¾åƒç®¡é“ï¼ˆå°½ç®¡ç”Ÿæˆå›¾åƒä¹Ÿå¾ˆé…·ï¼‰ã€‚æ‚¨å¯ä»¥è¿›ä¸€æ­¥å°†å…¶ä¸å…¶ä»–ç®¡é“é“¾æ¥èµ·æ¥ã€‚

### æ–‡æœ¬åˆ°å›¾åƒåˆ°å›¾åƒ

å°†æ–‡æœ¬åˆ°å›¾åƒå’Œå›¾åƒåˆ°å›¾åƒç®¡é“é“¾æ¥åœ¨ä¸€èµ·ï¼Œå¯ä»¥ä»æ–‡æœ¬ç”Ÿæˆå›¾åƒï¼Œå¹¶å°†ç”Ÿæˆçš„å›¾åƒç”¨ä½œå›¾åƒåˆ°å›¾åƒç®¡é“çš„åˆå§‹å›¾åƒã€‚å¦‚æœæ‚¨æƒ³å®Œå…¨ä»å¤´å¼€å§‹ç”Ÿæˆå›¾åƒï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬é“¾æ¥ä¸€ä¸ªç¨³å®šæ‰©æ•£å’Œä¸€ä¸ªåº·å®šæ–¯åŸºæ¨¡å‹ã€‚

é¦–å…ˆä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒç®¡é“ç”Ÿæˆä¸€ä¸ªå›¾åƒï¼š

```py
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
import torch
from diffusers.utils import make_image_grid

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

text2image = pipeline("Astronaut in a jungle, cold color palette, muted colors, detailed, 8k").images[0]
text2image
```

ç°åœ¨æ‚¨å¯ä»¥å°†ç”Ÿæˆçš„å›¾åƒä¼ é€’ç»™å›¾åƒåˆ°å›¾åƒç®¡é“ï¼š

```py
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16, use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image2image = pipeline("Astronaut in a jungle, cold color palette, muted colors, detailed, 8k", image=text2image).images[0]
make_image_grid([text2image, image2image], rows=1, cols=2)
```

### å›¾åƒåˆ°å›¾åƒåˆ°å›¾åƒ

æ‚¨è¿˜å¯ä»¥å°†å¤šä¸ªå›¾åƒåˆ°å›¾åƒç®¡é“é“¾æ¥åœ¨ä¸€èµ·ï¼Œä»¥åˆ›å»ºæ›´æœ‰è¶£çš„å›¾åƒã€‚è¿™å¯¹äºåœ¨å›¾åƒä¸Šè¿­ä»£æ‰§è¡Œé£æ ¼è½¬ç§»ã€ç”ŸæˆçŸ­GIFã€æ¢å¤å›¾åƒçš„é¢œè‰²æˆ–æ¢å¤å›¾åƒä¸­ç¼ºå¤±çš„åŒºåŸŸéå¸¸æœ‰ç”¨ã€‚

é¦–å…ˆç”Ÿæˆä¸€ä¸ªå›¾åƒï¼š

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, output_type="latent").images[0]
```

åœ¨ç®¡é“ä¸­æŒ‡å®š`output_type="latent"`æ˜¯å¾ˆé‡è¦çš„ï¼Œä»¥ä¿æŒæ‰€æœ‰è¾“å‡ºåœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œé¿å…ä¸å¿…è¦çš„è§£ç -ç¼–ç æ­¥éª¤ã€‚åªæœ‰å½“é“¾æ¥çš„ç®¡é“ä½¿ç”¨ç›¸åŒçš„VAEæ—¶æ‰æœ‰æ•ˆã€‚

å°†æ­¤ç®¡é“çš„æ½œåœ¨è¾“å‡ºä¼ é€’ç»™ä¸‹ä¸€ä¸ªç®¡é“ï¼Œä»¥ç”Ÿæˆ[æ¼«ç”»é£æ ¼çš„å›¾åƒ](https://huggingface.co/ogkalu/Comic-Diffusion)ï¼š

```py
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "ogkalu/Comic-Diffusion", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# need to include the token "charliebo artstyle" in the prompt to use this checkpoint
image = pipeline("Astronaut in a jungle, charliebo artstyle", image=image, output_type="latent").images[0]
```

å†é‡å¤ä¸€æ¬¡ï¼Œä»¥ç”Ÿæˆæœ€ç»ˆå›¾åƒï¼Œé‡‡ç”¨[åƒç´ è‰ºæœ¯é£æ ¼](https://huggingface.co/kohbanye/pixel-art-style)ï¼š

```py
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "kohbanye/pixel-art-style", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# need to include the token "pixelartstyle" in the prompt to use this checkpoint
image = pipeline("Astronaut in a jungle, pixelartstyle", image=image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

### å›¾åƒåˆ°ä¸Šé‡‡æ ·å™¨åˆ°è¶…åˆ†è¾¨ç‡

æ‚¨å¯ä»¥å°†å›¾åƒåˆ°å›¾åƒç®¡é“ä¸ä¸Šé‡‡æ ·å™¨å’Œè¶…åˆ†è¾¨ç‡ç®¡é“é“¾æ¥ï¼Œä»¥çœŸæ­£å¢åŠ å›¾åƒä¸­çš„ç»†èŠ‚çº§åˆ«ã€‚

ä»å›¾åƒåˆ°å›¾åƒç®¡é“å¼€å§‹ï¼š

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image_1 = pipeline(prompt, image=init_image, output_type="latent").images[0]
```

åœ¨ç®¡é“ä¸­æŒ‡å®š`output_type="latent"`æ˜¯å¾ˆé‡è¦çš„ï¼Œä»¥ä¿æŒæ‰€æœ‰è¾“å‡ºåœ¨*æ½œåœ¨*ç©ºé—´ä¸­ï¼Œé¿å…ä¸å¿…è¦çš„è§£ç -ç¼–ç æ­¥éª¤ã€‚åªæœ‰å½“é“¾æ¥çš„ç®¡é“ä½¿ç”¨ç›¸åŒçš„VAEæ—¶æ‰æœ‰æ•ˆã€‚

å°†å…¶é“¾æ¥åˆ°ä¸€ä¸ªä¸Šé‡‡æ ·å™¨ç®¡é“ï¼Œä»¥å¢åŠ å›¾åƒåˆ†è¾¨ç‡ï¼š

```py
from diffusers import StableDiffusionLatentUpscalePipeline

upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(
    "stabilityai/sd-x2-latent-upscaler", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
upscaler.enable_model_cpu_offload()
upscaler.enable_xformers_memory_efficient_attention()

image_2 = upscaler(prompt, image=image_1, output_type="latent").images[0]
```

æœ€åï¼Œå°†å…¶é“¾æ¥åˆ°ä¸€ä¸ªè¶…åˆ†è¾¨ç‡ç®¡é“ï¼Œè¿›ä¸€æ­¥å¢å¼ºåˆ†è¾¨ç‡ï¼š

```py
from diffusers import StableDiffusionUpscalePipeline

super_res = StableDiffusionUpscalePipeline.from_pretrained(
    "stabilityai/stable-diffusion-x4-upscaler", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
super_res.enable_model_cpu_offload()
super_res.enable_xformers_memory_efficient_attention()

image_3 = super_res(prompt, image=image_2).images[0]
make_image_grid([init_image, image_3.resize((512, 512))], rows=1, cols=2)
```

## æ§åˆ¶å›¾åƒç”Ÿæˆ

å°è¯•ç”Ÿæˆå®Œå…¨ç¬¦åˆæ‚¨è¦æ±‚çš„å›¾åƒå¯èƒ½å¾ˆå›°éš¾ï¼Œè¿™å°±æ˜¯å—æ§ç”ŸæˆæŠ€æœ¯å’Œæ¨¡å‹å¦‚æ­¤æœ‰ç”¨çš„åŸå› ã€‚è™½ç„¶æ‚¨å¯ä»¥ä½¿ç”¨`negative_prompt`éƒ¨åˆ†æ§åˆ¶å›¾åƒç”Ÿæˆï¼Œä½†è¿˜æœ‰æ›´å¥å£®çš„æ–¹æ³•ï¼Œå¦‚æç¤ºåŠ æƒå’ŒControlNetsã€‚

### æç¤ºåŠ æƒ

æç¤ºåŠ æƒå…è®¸æ‚¨è°ƒæ•´æç¤ºä¸­æ¯ä¸ªæ¦‚å¿µçš„è¡¨ç¤ºã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ªæç¤ºä¸­ï¼Œâ€œå¤ªç©ºäººåœ¨ä¸›æ—ä¸­ï¼Œå†·è‰²è°ƒï¼ŒæŸ”å’Œçš„é¢œè‰²ï¼Œè¯¦ç»†ï¼Œ8kâ€ï¼Œæ‚¨å¯ä»¥é€‰æ‹©å¢åŠ æˆ–å‡å°‘â€œå¤ªç©ºäººâ€å’Œâ€œä¸›æ—â€çš„åµŒå…¥ã€‚[Compel](https://github.com/damian0815/compel)åº“æä¾›äº†ä¸€ä¸ªç®€å•çš„è¯­æ³•ï¼Œç”¨äºè°ƒæ•´æç¤ºæƒé‡å’Œç”ŸæˆåµŒå…¥ã€‚æ‚¨å¯ä»¥å­¦ä¹ å¦‚ä½•åœ¨[æç¤ºåŠ æƒ](weighted_prompts)æŒ‡å—ä¸­åˆ›å»ºåµŒå…¥ã€‚

[AutoPipelineForImage2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image)æœ‰ä¸€ä¸ª`prompt_embeds`ï¼ˆå¦‚æœæ‚¨ä½¿ç”¨è´Ÿå‘æç¤ºï¼Œåˆ™è¿˜æœ‰`negative_prompt_embeds`å‚æ•°ï¼‰ï¼Œæ‚¨å¯ä»¥ä¼ é€’åµŒå…¥ï¼Œæ›¿æ¢`prompt`å‚æ•°ã€‚

```py
from diffusers import AutoPipelineForImage2Image
import torch

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt_embeds=prompt_embeds, # generated from Compel
    negative_prompt_embeds=negative_prompt_embeds, # generated from Compel
    image=init_image,
).images[0]
```

### ControlNet

ControlNetsæä¾›äº†ä¸€ç§æ›´çµæ´»å’Œå‡†ç¡®çš„æ§åˆ¶å›¾åƒç”Ÿæˆçš„æ–¹å¼ï¼Œå› ä¸ºæ‚¨å¯ä»¥ä½¿ç”¨é¢å¤–çš„æ¡ä»¶å›¾åƒã€‚æ¡ä»¶å›¾åƒå¯ä»¥æ˜¯cannyå›¾åƒã€æ·±åº¦å›¾ã€å›¾åƒåˆ†å‰²ï¼Œç”šè‡³æ˜¯æ¶‚é¸¦ï¼æ— è®ºæ‚¨é€‰æ‹©å“ªç§ç±»å‹çš„æ¡ä»¶å›¾åƒï¼ŒControlNetéƒ½ä¼šç”Ÿæˆä¿ç•™å…¶ä¸­ä¿¡æ¯çš„å›¾åƒã€‚

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨æ·±åº¦å›¾å¯¹å›¾åƒè¿›è¡Œæ¡ä»¶å¤„ç†ï¼Œä»¥ä¿ç•™å›¾åƒä¸­çš„ç©ºé—´ä¿¡æ¯ã€‚

```py
from diffusers.utils import load_image, make_image_grid

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)
init_image = init_image.resize((958, 960)) # resize to depth image dimensions
depth_image = load_image("https://huggingface.co/lllyasviel/control_v11f1p_sd15_depth/resolve/main/images/control.png")
make_image_grid([init_image, depth_image], rows=1, cols=2)
```

åŠ è½½ä¸€ä¸ªåœ¨æ·±åº¦å›¾ä¸Šè¿›è¡Œæ¡ä»¶å¤„ç†çš„ControlNetæ¨¡å‹å’Œ[AutoPipelineForImage2Image](/docs/diffusers/v0.26.3/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image)ï¼š

```py
from diffusers import ControlNetModel, AutoPipelineForImage2Image
import torch

controlnet = ControlNetModel.from_pretrained("lllyasviel/control_v11f1p_sd15_depth", torch_dtype=torch.float16, variant="fp16", use_safetensors=True)
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()
```

ç°åœ¨ç”Ÿæˆä¸€ä¸ªæ–°çš„å›¾åƒï¼Œä»¥æ·±åº¦å›¾ã€åˆå§‹å›¾åƒå’Œæç¤ºä¸ºæ¡ä»¶ï¼š

```py
prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image_control_net = pipeline(prompt, image=init_image, control_image=depth_image).images[0]
make_image_grid([init_image, depth_image, image_control_net], rows=1, cols=3)
```

![](../Images/36dc16e92be7b4f357b7201ad98da118.png)

åˆå§‹å›¾åƒ

![](../Images/795c4016502683bcda2f00fa33a84c2d.png)

æ·±åº¦å›¾åƒ

![](../Images/e425aa0e6403b0304599567d11b91a4d.png)

ControlNetå›¾åƒ

è®©æˆ‘ä»¬å¯¹ä»ControlNetç”Ÿæˆçš„å›¾åƒåº”ç”¨ä¸€ä¸ªæ–°çš„[é£æ ¼](https://huggingface.co/nitrosocke/elden-ring-diffusion)ï¼Œé€šè¿‡å°†å…¶ä¸å›¾åƒåˆ°å›¾åƒç®¡é“é“¾æ¥ï¼š

```py
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "nitrosocke/elden-ring-diffusion", torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "elden ring style astronaut in a jungle" # include the token "elden ring style" in the prompt
negative_prompt = "ugly, deformed, disfigured, poor details, bad anatomy"

image_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image_control_net, strength=0.45, guidance_scale=10.5).images[0]
make_image_grid([init_image, depth_image, image_control_net, image_elden_ring], rows=2, cols=2)
```

![](../Images/3d19fb4449a5e38b2448796e3bf6cf11.png)

## ä¼˜åŒ–

è¿è¡Œæ‰©æ•£æ¨¡å‹åœ¨è®¡ç®—ä¸Šæ˜¯æ˜‚è´µä¸”å¯†é›†çš„ï¼Œä½†é€šè¿‡ä¸€äº›ä¼˜åŒ–æŠ€å·§ï¼Œå®Œå…¨å¯ä»¥åœ¨æ¶ˆè´¹è€…å’Œå…è´¹çº§åˆ«çš„GPUä¸Šè¿è¡Œå®ƒä»¬ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ›´èŠ‚çœå†…å­˜çš„æ³¨æ„åŠ›å½¢å¼ï¼Œå¦‚PyTorch 2.0çš„[ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›](../optimization/torch2.0#scaled-dot-product-attention)æˆ–[xFormers](../optimization/xformers)ï¼ˆæ‚¨å¯ä»¥ä½¿ç”¨å…¶ä¸­ä¸€ä¸ªï¼Œä½†æ²¡æœ‰å¿…è¦åŒæ—¶ä½¿ç”¨ä¸¤è€…ï¼‰ã€‚æ‚¨è¿˜å¯ä»¥å°†æ¨¡å‹å¸è½½åˆ°GPUï¼Œè€Œå…¶ä»–ç®¡é“ç»„ä»¶åœ¨CPUä¸Šç­‰å¾…ã€‚

```py
+ pipeline.enable_model_cpu_offload()
+ pipeline.enable_xformers_memory_efficient_attention()
```

ä½¿ç”¨[`torch.compile`](../optimization/torch2.0#torchcompile)ï¼Œæ‚¨å¯ä»¥é€šè¿‡å°†UNetä¸å…¶åŒ…è£…æ¥è¿›ä¸€æ­¥æé«˜æ¨ç†é€Ÿåº¦ï¼š

```py
pipeline.unet = torch.compile(pipeline.unet, mode="reduce-overhead", fullgraph=True)
```

è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[å‡å°‘å†…å­˜ä½¿ç”¨](../optimization/memory)å’Œ[Torch 2.0](../optimization/torch2.0)æŒ‡å—ã€‚
