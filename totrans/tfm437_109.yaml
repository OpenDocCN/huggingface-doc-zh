- en: Auto Classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/transformers/v4.37.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/start.1af50ed5.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/scheduler.9bc65507.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/singletons.a2d7fdf1.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.3b203c72.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/paths.b8f1dad4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/app.59e74a31.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.707bf1b6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/0.dbd8cc12.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/60.cac6bdeb.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Tip.c2ecdbf4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Docstring.17db21ae.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/globals.7f7f1b26.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Heading.342b1fa6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/CodeBlock.54a9f38d.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/ExampleCodeBlock.4f515aa9.js">
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, the architecture you want to use can be guessed from the name
    or the path of the pretrained model you are supplying to the `from_pretrained()`
    method. AutoClasses are here to do this job for you so that you automatically
    retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: Instantiating one of [AutoConfig](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig),
    [AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel),
    and [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    will directly create a class of the relevant architecture. For instance
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: will create a model that is an instance of [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel).
  prefs: []
  type: TYPE_NORMAL
- en: There is one class of `AutoModel` for each task, and for each backend (PyTorch,
    TensorFlow, or Flax).
  prefs: []
  type: TYPE_NORMAL
- en: Extending the Auto Classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each of the auto classes has a method to be extended with your custom classes.
    For instance, if you have defined a custom class of model `NewModel`, make sure
    you have a `NewModelConfig` then you can add those to the auto classes like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You will then be able to use the auto classes like you would usually do!
  prefs: []
  type: TYPE_NORMAL
- en: If your `NewModelConfig` is a subclass of [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    make sure its `model_type` attribute is set to the same key you use when registering
    the config (here `"new-model"`).
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, if your `NewModel` is a subclass of [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel),
    make sure its `config_class` attribute is set to the same class you use when registering
    the model (here `NewModelConfig`).
  prefs: []
  type: TYPE_NORMAL
- en: AutoConfig
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class transformers.AutoConfig'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L975)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic configuration class that will be instantiated as one of the
    configuration classes of the library when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig.from_pretrained)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L998)'
  prefs: []
  type: TYPE_NORMAL
- en: ( pretrained_model_name_or_path **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model configuration hosted inside a
    model repo on huggingface.co. Valid model ids can be located at the root-level,
    like `bert-base-uncased`, or namespaced under a user or organization name, like
    `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing a configuration file saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained)
    method, or the [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    method, e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a saved configuration JSON *file*, e.g., `./my_model_directory/configuration.json`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download the model weights and configuration files and override
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_unused_kwargs** (`bool`, *optional*, defaults to `False`) — If `False`,
    then this function returns just the final configuration object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If `True`, then this functions returns a `Tuple(config, unused_kwargs)` where
    *unused_kwargs* is a dictionary consisting of the key/value pairs whose keys are
    not configuration attributes: i.e., the part of `kwargs` which has not been used
    to update `config` and is otherwise ignored.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs(additional** keyword arguments, *optional*) — The values in kwargs
    of any keys which are configuration attributes will be used to override the loaded
    values. Behavior concerning key/value pairs whose keys are *not* configuration
    attributes is controlled by the `return_unused_kwargs` keyword parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the configuration classes of the library from a pretrained
    model configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration class to instantiate is selected based on the `model_type`
    property of the config object that is loaded, or when it’s missing, by falling
    back to using pattern matching on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**align** — [AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)
    (ALIGN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**altclip** — [AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)
    (AltCLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**audio-spectrogram-transformer** — [ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)
    (Audio Spectrogram Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**autoformer** — [AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)
    (Autoformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bark** — [BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)
    (Bark model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**beit** — [BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    (BEiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert-generation** — [BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)
    (Bert Generation model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bigbird_pegasus** — [BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**biogpt** — [BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    (BioGpt model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bit** — [BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig)
    (BiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot** — [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    (Blenderbot model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot-small** — [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    (BlenderbotSmall model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip** — [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip-2** — [Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    (BLIP-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bridgetower** — [BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)
    (BridgeTower model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bros** — [BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig)
    (BROS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**canine** — [CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    (CANINE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**chinese_clip** — [ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig)
    (Chinese-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clap** — [ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)
    (CLAP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip_vision_model** — [CLIPVisionConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionConfig)
    (CLIPVisionModel model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clipseg** — [CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig)
    (CLIPSeg model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clvp** — [ClvpConfig](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpConfig)
    (CLVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_llama** — [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    (CodeLlama model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**codegen** — [CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig)
    (CodeGen model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**conditional_detr** — [ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig)
    (Conditional DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnext** — [ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    (ConvNeXT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnextv2** — [ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cpmant** — [CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig)
    (CPM-Ant model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cvt** — [CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    (CvT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-audio** — [Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    (Data2VecAudio model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-vision** — [Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    (Data2VecVision model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**decision_transformer** — [DecisionTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig)
    (Decision Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deformable_detr** — [DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)
    (Deformable DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deit** — [DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    (DeiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deta** — [DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)
    (DETA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**detr** — [DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    (DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dinat** — [DinatConfig](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatConfig)
    (DiNAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dinov2** — [Dinov2Config](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Config)
    (DINOv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**donut-swin** — [DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig)
    (DonutSwin model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dpr** — [DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig)
    (DPR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dpt** — [DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    (DPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientformer** — [EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    (EfficientFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientnet** — [EfficientNetConfig](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetConfig)
    (EfficientNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encodec** — [EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig)
    (EnCodec model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder-decoder** — [EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    (Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie_m** — [ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    (ErnieM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**falcon** — [FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    (Falcon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fastspeech2_conformer** — [FastSpeech2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerConfig)
    (FastSpeech2Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flava** — [FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    (FLAVA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**focalnet** — [FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)
    (FocalNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fsmt** — [FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    (FairSeq Machine-Translation model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fuyu** — [FuyuConfig](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuConfig)
    (Fuyu model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**git** — [GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    (GIT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**glpn** — [GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig)
    (GLPN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_bigcode** — [GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    (GPTBigCode model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neo** — [GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    (GPT Neo model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox** — [GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    (GPT NeoX model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox_japanese** — [GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig)
    (GPT NeoX Japanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptsan-japanese** — [GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    (GPTSAN-japanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**graphormer** — [GraphormerConfig](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerConfig)
    (Graphormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**groupvit** — [GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)
    (GroupViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hubert** — [HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    (Hubert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ibert** — [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    (I-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**idefics** — [IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)
    (IDEFICS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**imagegpt** — [ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig)
    (ImageGPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**informer** — [InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig)
    (Informer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**instructblip** — [InstructBlipConfig](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipConfig)
    (InstructBLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**jukebox** — [JukeboxConfig](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxConfig)
    (Jukebox model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kosmos-2** — [Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config)
    (KOSMOS-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**led** — [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    (LED model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**levit** — [LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig)
    (LeViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lilt** — [LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    (LiLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llama** — [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    (LLaMA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llava** — [LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig)
    (LLaVa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longt5** — [LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    (LongT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**luke** — [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    (LUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lxmert** — [LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    (LXMERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**m2m_100** — [M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)
    (M2M100 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**marian** — [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    (Marian model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**markuplm** — [MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    (MarkupLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mask2former** — [Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)
    (Mask2Former model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**maskformer** — [MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    (MaskFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**maskformer-swin** — `MaskFormerSwinConfig` (MaskFormerSwin model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mctct** — [MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)
    (M-CTC-T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mgp-str** — [MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig)
    (MGP-STR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mistral** — [MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    (Mistral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mixtral** — [MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    (Mixtral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v1** — [MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config)
    (MobileNetV1 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v2** — [MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    (MobileNetV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevit** — [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    (MobileViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevitv2** — [MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    (MobileViTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpt** — [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    (MPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mra** — [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    (MRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**musicgen** — [MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)
    (MusicGen model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mvp** — [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    (MVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nat** — [NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig)
    (NAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nllb-moe** — [NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    (NLLB-MOE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nougat** — [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    (Nougat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nystromformer** — [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    (Nyströmformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**oneformer** — [OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)
    (OneFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**open-llama** — [OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    (OpenLlama model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlv2** — [Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)
    (OWLv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlvit** — [OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)
    (OWL-ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**patchtsmixer** — [PatchTSMixerConfig](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerConfig)
    (PatchTSMixer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**patchtst** — [PatchTSTConfig](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTConfig)
    (PatchTST model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus** — [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    (Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus_x** — [PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig)
    (PEGASUS-X model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceiver** — [PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    (Perceiver model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**persimmon** — [PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    (Persimmon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**phi** — [PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    (Phi model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pix2struct** — [Pix2StructConfig](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructConfig)
    (Pix2Struct model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**plbart** — [PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    (PLBart model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**poolformer** — [PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)
    (PoolFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pop2piano** — [Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig)
    (Pop2Piano model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**prophetnet** — [ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    (ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pvt** — [PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig)
    (PVT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qwen2** — [Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    (Qwen2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rag** — [RagConfig](/docs/transformers/v4.37.2/en/model_doc/rag#transformers.RagConfig)
    (RAG model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**realm** — [RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig)
    (REALM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**reformer** — [ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    (Reformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**regnet** — [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    (RegNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resnet** — [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    (ResNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**retribert** — [RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig)
    (RetriBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rwkv** — [RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    (RWKV model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sam** — [SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig)
    (SAM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t** — [SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    (SeamlessM4T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t_v2** — [SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    (SeamlessM4Tv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**segformer** — [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    (SegFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew** — [SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    (SEW model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew-d** — [SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    (SEW-D model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**siglip** — [SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig)
    (SigLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**siglip_vision_model** — [SiglipVisionConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionConfig)
    (SiglipVisionModel model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech-encoder-decoder** — [SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig)
    (Speech Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text** — [Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    (Speech2Text model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text_2** — [Speech2Text2Config](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config)
    (Speech2Text2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speecht5** — [SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)
    (SpeechT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**splinter** — [SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    (Splinter model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**squeezebert** — [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    (SqueezeBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swiftformer** — [SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig)
    (SwiftFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin** — [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    (Swin Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin2sr** — [Swin2SRConfig](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRConfig)
    (Swin2SR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swinv2** — [Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    (Swin Transformer V2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**switch_transformers** — [SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    (SwitchTransformers model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**table-transformer** — [TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)
    (Table Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**time_series_transformer** — [TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig)
    (Time Series Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timesformer** — [TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig)
    (TimeSformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timm_backbone** — `TimmBackboneConfig` (TimmBackbone model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trajectory_transformer** — [TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig)
    (Trajectory Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trocr** — [TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig)
    (TrOCR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvlt** — [TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig)
    (TVLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvp** — [TvpConfig](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpConfig)
    (TVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**umt5** — [UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    (UMT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech** — [UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    (UniSpeech model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech-sat** — [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    (UniSpeechSat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**univnet** — [UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig)
    (UnivNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**upernet** — [UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig)
    (UPerNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**van** — [VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig)
    (VAN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**videomae** — [VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    (VideoMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vilt** — [ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig)
    (ViLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vipllava** — [VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig)
    (VipLlava model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vision-encoder-decoder** — [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    (Vision Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vision-text-dual-encoder** — [VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    (VisionTextDualEncoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**visual_bert** — [VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)
    (VisualBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_hybrid** — [ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)
    (ViT Hybrid model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_mae** — [ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    (ViTMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_msn** — [ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)
    (ViTMSN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vitdet** — [VitDetConfig](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetConfig)
    (VitDet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vitmatte** — [VitMatteConfig](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteConfig)
    (ViTMatte model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vits** — [VitsConfig](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsConfig)
    (VITS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vivit** — [VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)
    (ViViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-bert** — [Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wavlm** — [WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    (WavLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xclip** — [XCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPConfig)
    (X-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xglm** — [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    (XGLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-prophetnet** — [XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    (XLM-ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yolos** — [YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)
    (YOLOS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yoso** — [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    (YOSO model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#### register'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L1138)'
  prefs: []
  type: TYPE_NORMAL
- en: ( model_type config exist_ok = False )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**model_type** (`str`) — The model type like “bert” or “gpt”.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The config to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Register a new configuration for this class.
  prefs: []
  type: TYPE_NORMAL
- en: AutoTokenizer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class transformers.AutoTokenizer'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L616)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic tokenizer class that will be instantiated as one of the tokenizer
    classes of the library when created with the [AutoTokenizer.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L630)'
  prefs: []
  type: TYPE_NORMAL
- en: ( pretrained_model_name_or_path *inputs **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a predefined tokenizer hosted inside a model repo
    on huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing vocabulary files required by the tokenizer,
    for instance saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)
    method, e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A path or url to a single saved vocabulary file if and only if the tokenizer
    only requires a single vocabulary file (like Bert or XLNet), e.g.: `./my_model_directory/vocab.txt`.
    (Not applicable to all derived classes)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**inputs** (additional positional arguments, *optional*) — Will be passed along
    to the Tokenizer `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — The configuration object used to determine the tokenizer class to
    instantiate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download the model weights and configuration files and override
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**subfolder** (`str`, *optional*) — In case the relevant files are located
    inside a subfolder of the model repo on huggingface.co (e.g. for facebook/rag-token-base),
    specify it here.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**use_fast** (`bool`, *optional*, defaults to `True`) — Use a [fast Rust-based
    tokenizer](https://huggingface.co/docs/tokenizers/index) if it is supported for
    a given model. If a fast tokenizer is not available for a given model, a normal
    Python-based tokenizer is returned instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tokenizer_type** (`str`, *optional*) — Tokenizer type to be loaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Will be passed to the
    Tokenizer `__init__()` method. Can be used to set special tokens like `bos_token`,
    `eos_token`, `unk_token`, `sep_token`, `pad_token`, `cls_token`, `mask_token`,
    `additional_special_tokens`. See parameters in the `__init__()` for more details.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the tokenizer classes of the library from a pretrained model
    vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tokenizer class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)
    or [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**align** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (ALIGN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bark** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Bark model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [BartTokenizer](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartTokenizer)
    or [BartTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartTokenizerFast)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**barthez** — [BarthezTokenizer](/docs/transformers/v4.37.2/en/model_doc/barthez#transformers.BarthezTokenizer)
    or [BarthezTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/barthez#transformers.BarthezTokenizerFast)
    (BARThez model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bartpho** — [BartphoTokenizer](/docs/transformers/v4.37.2/en/model_doc/bartpho#transformers.BartphoTokenizer)
    (BARTpho model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert-generation** — [BertGenerationTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationTokenizer)
    (Bert Generation model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert-japanese** — [BertJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer)
    (BertJapanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bertweet** — [BertweetTokenizer](/docs/transformers/v4.37.2/en/model_doc/bertweet#transformers.BertweetTokenizer)
    (BERTweet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdTokenizer](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdTokenizer)
    or [BigBirdTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdTokenizerFast)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bigbird_pegasus** — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer)
    or [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**biogpt** — [BioGptTokenizer](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptTokenizer)
    (BioGpt model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot** — [BlenderbotTokenizer](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizer)
    or [BlenderbotTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast)
    (Blenderbot model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot-small** — [BlenderbotSmallTokenizer](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer)
    (BlenderbotSmall model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip-2** — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (BLIP-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [BloomTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomTokenizerFast)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bridgetower** — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (BridgeTower model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bros** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (BROS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**byt5** — [ByT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/byt5#transformers.ByT5Tokenizer)
    (ByT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertTokenizer](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertTokenizer)
    or [CamembertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertTokenizerFast)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**canine** — [CanineTokenizer](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineTokenizer)
    (CANINE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**chinese_clip** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Chinese-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clap** — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (CLAP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clipseg** — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (CLIPSeg model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clvp** — [ClvpTokenizer](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpTokenizer)
    (CLVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_llama** — [CodeLlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/code_llama#transformers.CodeLlamaTokenizer)
    or [CodeLlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/code_llama#transformers.CodeLlamaTokenizerFast)
    (CodeLlama model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**codegen** — [CodeGenTokenizer](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizer)
    or [CodeGenTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizerFast)
    (CodeGen model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [ConvBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertTokenizer)
    or [ConvBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertTokenizerFast)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cpm** — [CpmTokenizer](/docs/transformers/v4.37.2/en/model_doc/cpm#transformers.CpmTokenizer)
    or [CpmTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/cpm#transformers.CpmTokenizerFast)
    (CPM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cpmant** — [CpmAntTokenizer](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntTokenizer)
    (CPM-Ant model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [CTRLTokenizer](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLTokenizer)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-audio** — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Data2VecAudio model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [DebertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaTokenizer)
    or [DebertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaTokenizerFast)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [DebertaV2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer)
    or [DebertaV2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [DistilBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertTokenizer)
    or [DistilBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertTokenizerFast)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dpr** — [DPRQuestionEncoderTokenizer](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer)
    or [DPRQuestionEncoderTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast)
    (DPR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraTokenizer](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraTokenizer)
    or [ElectraTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraTokenizerFast)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie_m** — [ErnieMTokenizer](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMTokenizer)
    (ErnieM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [EsmTokenizer](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmTokenizer)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**falcon** — [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    (Falcon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fastspeech2_conformer** — (FastSpeech2Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [FlaubertTokenizer](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertTokenizer)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetTokenizer)
    or [FNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetTokenizerFast)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fsmt** — [FSMTTokenizer](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTTokenizer)
    (FairSeq Machine-Translation model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [FunnelTokenizer](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelTokenizer)
    or [FunnelTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelTokenizerFast)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**git** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (GIT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [GPTSw3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt-sw3#transformers.GPTSw3Tokenizer)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_bigcode** — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (GPTBigCode model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neo** — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (GPT Neo model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox** — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast)
    (GPT NeoX model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox_japanese** — [GPTNeoXJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer)
    (GPT NeoX Japanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptsan-japanese** — [GPTSanJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseTokenizer)
    (GPTSAN-japanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**groupvit** — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (GroupViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**herbert** — [HerbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/herbert#transformers.HerbertTokenizer)
    or [HerbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/herbert#transformers.HerbertTokenizerFast)
    (HerBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hubert** — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Hubert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ibert** — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (I-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**idefics** — [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (IDEFICS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**instructblip** — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (InstructBLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**jukebox** — [JukeboxTokenizer](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxTokenizer)
    (Jukebox model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kosmos-2** — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    or [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (KOSMOS-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [LayoutLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizer)
    or [LayoutLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    or [LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    or [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutxlm** — [LayoutXLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer)
    or [LayoutXLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast)
    (LayoutXLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**led** — [LEDTokenizer](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDTokenizer)
    or [LEDTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDTokenizerFast)
    (LED model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lilt** — [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    or [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)
    (LiLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llama** — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (LLaMA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llava** — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (LLaVa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [LongformerTokenizer](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerTokenizer)
    or [LongformerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerTokenizerFast)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longt5** — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (LongT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**luke** — [LukeTokenizer](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeTokenizer)
    (LUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lxmert** — [LxmertTokenizer](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertTokenizer)
    or [LxmertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertTokenizerFast)
    (LXMERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**m2m_100** — [M2M100Tokenizer](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Tokenizer)
    (M2M100 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**marian** — [MarianTokenizer](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianTokenizer)
    (Marian model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [MBartTokenizer](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartTokenizer)
    or [MBartTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartTokenizerFast)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart50** — [MBart50Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBart50Tokenizer)
    or [MBart50TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBart50TokenizerFast)
    (mBART-50 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mgp-str** — [MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer)
    (MGP-STR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mistral** — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (Mistral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mixtral** — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (Mixtral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mluke** — [MLukeTokenizer](/docs/transformers/v4.37.2/en/model_doc/mluke#transformers.MLukeTokenizer)
    (mLUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertTokenizer)
    or [MobileBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [MPNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetTokenizer)
    or [MPNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetTokenizerFast)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpt** — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast)
    (MPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mra** — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (MRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [MT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [MT5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**musicgen** — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (MusicGen model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mvp** — [MvpTokenizer](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpTokenizer)
    or [MvpTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpTokenizerFast)
    (MVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nllb** — [NllbTokenizer](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizer)
    or [NllbTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizerFast)
    (NLLB model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nllb-moe** — [NllbTokenizer](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizer)
    or [NllbTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizerFast)
    (NLLB-MOE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nystromformer** — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)
    or [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)
    (Nyströmformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**oneformer** — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (OneFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [OpenAIGPTTokenizer](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer)
    or [OpenAIGPTTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlv2** — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (OWLv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlvit** — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (OWL-ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus** — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer)
    or [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)
    (Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus_x** — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer)
    or [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)
    (PEGASUS-X model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceiver** — [PerceiverTokenizer](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverTokenizer)
    (Perceiver model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**persimmon** — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (Persimmon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**phi** — [CodeGenTokenizer](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizer)
    or [CodeGenTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizerFast)
    (Phi model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**phobert** — [PhobertTokenizer](/docs/transformers/v4.37.2/en/model_doc/phobert#transformers.PhobertTokenizer)
    (PhoBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pix2struct** — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (Pix2Struct model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**plbart** — [PLBartTokenizer](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartTokenizer)
    (PLBart model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**prophetnet** — [ProphetNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetTokenizer)
    (ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qwen2** — [Qwen2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Tokenizer)
    or [Qwen2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2TokenizerFast)
    (Qwen2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rag** — [RagTokenizer](/docs/transformers/v4.37.2/en/model_doc/rag#transformers.RagTokenizer)
    (RAG model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**realm** — [RealmTokenizer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizer)
    or [RealmTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizerFast)
    (REALM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**reformer** — [ReformerTokenizer](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerTokenizer)
    or [ReformerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerTokenizerFast)
    (Reformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [RemBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertTokenizer)
    or [RemBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertTokenizerFast)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**retribert** — [RetriBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertTokenizer)
    or [RetriBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertTokenizerFast)
    (RetriBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertTokenizer)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [RoFormerTokenizer](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerTokenizer)
    or [RoFormerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerTokenizerFast)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rwkv** — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast)
    (RWKV model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t** — [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    or [SeamlessM4TTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizerFast)
    (SeamlessM4T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t_v2** — [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    or [SeamlessM4TTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizerFast)
    (SeamlessM4Tv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**siglip** — [SiglipTokenizer](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipTokenizer)
    (SigLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text** — [Speech2TextTokenizer](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer)
    (Speech2Text model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text_2** — [Speech2Text2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer)
    (Speech2Text2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speecht5** — [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer)
    (SpeechT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**splinter** — [SplinterTokenizer](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterTokenizer)
    or [SplinterTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterTokenizerFast)
    (Splinter model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**squeezebert** — [SqueezeBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer)
    or [SqueezeBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast)
    (SqueezeBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**switch_transformers** — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (SwitchTransformers model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TapasTokenizer](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasTokenizer)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapex** — [TapexTokenizer](/docs/transformers/v4.37.2/en/model_doc/tapex#transformers.TapexTokenizer)
    (TAPEX model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TransfoXLTokenizer](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvp** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (TVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**umt5** — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (UMT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vilt** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (ViLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vipllava** — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (VipLlava model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**visual_bert** — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (VisualBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vits** — [VitsTokenizer](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsTokenizer)
    (VITS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-bert** — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2_phoneme** — [Wav2Vec2PhonemeCTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer)
    (Wav2Vec2Phoneme model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)
    or [WhisperTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizerFast)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xclip** — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (X-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xglm** — [XGLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMTokenizer)
    or [XGLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMTokenizerFast)
    (XGLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMTokenizer)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-prophetnet** — [XLMProphetNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer)
    (XLM-ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    or [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    or [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [XLNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizer)
    or [XLNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizerFast)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    or [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yoso** — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)
    or [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)
    (YOSO model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '#### register'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L847)'
  prefs: []
  type: TYPE_NORMAL
- en: ( config_class slow_tokenizer_class = None fast_tokenizer_class = None exist_ok
    = False )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config_class** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration corresponding to the model to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**slow_tokenizer_class** (`PretrainedTokenizer`, *optional*) — The slow tokenizer
    to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fast_tokenizer_class** (`PretrainedTokenizerFast`, *optional*) — The fast
    tokenizer to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Register a new tokenizer in this mapping.
  prefs: []
  type: TYPE_NORMAL
- en: AutoFeatureExtractor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class transformers.AutoFeatureExtractor'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L239)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic feature extractor class that will be instantiated as one of
    the feature extractor classes of the library when created with the [AutoFeatureExtractor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L253)'
  prefs: []
  type: TYPE_NORMAL
- en: ( pretrained_model_name_or_path **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — This can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a path to a *directory* containing a feature extractor file saved using the
    [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model feature extractor should be cached if the
    standard cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force to (re-)download the feature extractor files and override the cached
    versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received file. Attempts to resume the download if such
    a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}.` The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**token** (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_unused_kwargs** (`bool`, *optional*, defaults to `False`) — If `False`,
    then this function returns just the final feature extractor object. If `True`,
    then this functions returns a `Tuple(feature_extractor, unused_kwargs)` where
    *unused_kwargs* is a dictionary consisting of the key/value pairs whose keys are
    not feature extractor attributes: i.e., the part of `kwargs` which has not been
    used to update `feature_extractor` and is otherwise ignored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (`Dict[str, Any]`, *optional*) — The values in kwargs of any keys
    which are feature extractor attributes will be used to override the loaded values.
    Behavior concerning key/value pairs whose keys are *not* feature extractor attributes
    is controlled by the `return_unused_kwargs` keyword parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the feature extractor classes of the library from a pretrained
    model vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: 'The feature extractor class to instantiate is selected based on the `model_type`
    property of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**audio-spectrogram-transformer** — [ASTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTFeatureExtractor)
    (Audio Spectrogram Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**beit** — [BeitFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitFeatureExtractor)
    (BEiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**chinese_clip** — [ChineseCLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPFeatureExtractor)
    (Chinese-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clap** — [ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)
    (CLAP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clipseg** — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (CLIPSeg model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clvp** — [ClvpFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpFeatureExtractor)
    (CLVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**conditional_detr** — [ConditionalDetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor)
    (Conditional DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnext** — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (ConvNeXT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cvt** — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (CvT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-audio** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Data2VecAudio model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-vision** — [BeitFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitFeatureExtractor)
    (Data2VecVision model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deformable_detr** — [DeformableDetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor)
    (Deformable DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deit** — [DeiTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTFeatureExtractor)
    (DeiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**detr** — [DetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrFeatureExtractor)
    (DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dinat** — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (DiNAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**donut-swin** — [DonutFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutFeatureExtractor)
    (DonutSwin model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dpt** — [DPTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTFeatureExtractor)
    (DPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encodec** — [EncodecFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecFeatureExtractor)
    (EnCodec model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flava** — [FlavaFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaFeatureExtractor)
    (FLAVA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**glpn** — [GLPNFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor)
    (GLPN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**groupvit** — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor)
    (GroupViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hubert** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Hubert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**imagegpt** — [ImageGPTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor)
    (ImageGPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**levit** — [LevitFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitFeatureExtractor)
    (LeViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**maskformer** — [MaskFormerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor)
    (MaskFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mctct** — [MCTCTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTFeatureExtractor)
    (M-CTC-T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v1** — [MobileNetV1FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1FeatureExtractor)
    (MobileNetV1 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v2** — [MobileNetV2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2FeatureExtractor)
    (MobileNetV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevit** — [MobileViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor)
    (MobileViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nat** — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (NAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlvit** — [OwlViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor)
    (OWL-ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceiver** — [PerceiverFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor)
    (Perceiver model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**poolformer** — [PoolFormerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor)
    (PoolFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pop2piano** — [Pop2PianoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoFeatureExtractor)
    (Pop2Piano model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**regnet** — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (RegNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resnet** — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (ResNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t** — [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    (SeamlessM4T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t_v2** — [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    (SeamlessM4Tv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**segformer** — [SegformerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerFeatureExtractor)
    (SegFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (SEW model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew-d** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (SEW-D model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text** — [Speech2TextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor)
    (Speech2Text model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speecht5** — [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor)
    (SpeechT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swiftformer** — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (SwiftFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin** — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (Swin Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swinv2** — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (Swin Transformer V2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**table-transformer** — [DetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrFeatureExtractor)
    (Table Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timesformer** — [VideoMAEFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor)
    (TimeSformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvlt** — [TvltFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltFeatureExtractor)
    (TVLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (UniSpeech model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech-sat** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (UniSpeechSat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**univnet** — [UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)
    (UnivNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**van** — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (VAN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**videomae** — [VideoMAEFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor)
    (VideoMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vilt** — [ViltFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltFeatureExtractor)
    (ViLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_mae** — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (ViTMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_msn** — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (ViTMSN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-bert** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wavlm** — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (WavLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xclip** — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor)
    (X-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yolos** — [YolosFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosFeatureExtractor)
    (YOLOS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Passing `token=True` is required when you want to use a private model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '#### register'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L388)'
  prefs: []
  type: TYPE_NORMAL
- en: ( config_class feature_extractor_class exist_ok = False )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config_class** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration corresponding to the model to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**feature_extractor_class** (`FeatureExtractorMixin`) — The feature extractor
    to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Register a new feature extractor for this class.
  prefs: []
  type: TYPE_NORMAL
- en: AutoImageProcessor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class transformers.AutoImageProcessor'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L251)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic image processor class that will be instantiated as one of
    the image processor classes of the library when created with the [AutoImageProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor.from_pretrained)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L265)'
  prefs: []
  type: TYPE_NORMAL
- en: ( pretrained_model_name_or_path **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — This can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a string, the *model id* of a pretrained image_processor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a path to a *directory* containing a image processor file saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a path or url to a saved image processor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model image processor should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force to (re-)download the image processor files and override the cached versions
    if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received file. Attempts to resume the download if such
    a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}.` The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**token** (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_unused_kwargs** (`bool`, *optional*, defaults to `False`) — If `False`,
    then this function returns just the final image processor object. If `True`, then
    this functions returns a `Tuple(image_processor, unused_kwargs)` where *unused_kwargs*
    is a dictionary consisting of the key/value pairs whose keys are not image processor
    attributes: i.e., the part of `kwargs` which has not been used to update `image_processor`
    and is otherwise ignored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (`Dict[str, Any]`, *optional*) — The values in kwargs of any keys
    which are image processor attributes will be used to override the loaded values.
    Behavior concerning key/value pairs whose keys are *not* image processor attributes
    is controlled by the `return_unused_kwargs` keyword parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the image processor classes of the library from a pretrained
    model vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: 'The image processor class to instantiate is selected based on the `model_type`
    property of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**align** — [EfficientNetImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetImageProcessor)
    (ALIGN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**beit** — [BeitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitImageProcessor)
    (BEiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bit** — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor)
    (BiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip** — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip-2** — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor)
    (BLIP-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bridgetower** — [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)
    (BridgeTower model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**chinese_clip** — [ChineseCLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPImageProcessor)
    (Chinese-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clipseg** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (CLIPSeg model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**conditional_detr** — [ConditionalDetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrImageProcessor)
    (Conditional DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnext** — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (ConvNeXT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnextv2** — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cvt** — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (CvT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-vision** — [BeitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitImageProcessor)
    (Data2VecVision model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deformable_detr** — [DeformableDetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrImageProcessor)
    (Deformable DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deit** — [DeiTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTImageProcessor)
    (DeiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deta** — [DetaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaImageProcessor)
    (DETA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**detr** — [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor)
    (DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dinat** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (DiNAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dinov2** — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor)
    (DINOv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**donut-swin** — [DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor)
    (DonutSwin model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dpt** — [DPTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTImageProcessor)
    (DPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientformer** — [EfficientFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerImageProcessor)
    (EfficientFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientnet** — [EfficientNetImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetImageProcessor)
    (EfficientNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flava** — [FlavaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageProcessor)
    (FLAVA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**focalnet** — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor)
    (FocalNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fuyu** — [FuyuImageProcessor](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuImageProcessor)
    (Fuyu model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**git** — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (GIT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**glpn** — [GLPNImageProcessor](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNImageProcessor)
    (GLPN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**groupvit** — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (GroupViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**idefics** — [IdeficsImageProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsImageProcessor)
    (IDEFICS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**imagegpt** — [ImageGPTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor)
    (ImageGPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**instructblip** — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor)
    (InstructBLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kosmos-2** — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (KOSMOS-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**levit** — [LevitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitImageProcessor)
    (LeViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llava** — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (LLaVa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mask2former** — [Mask2FormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor)
    (Mask2Former model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**maskformer** — [MaskFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerImageProcessor)
    (MaskFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mgp-str** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (MGP-STR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v1** — [MobileNetV1ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ImageProcessor)
    (MobileNetV1 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v2** — [MobileNetV2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ImageProcessor)
    (MobileNetV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevit** — [MobileViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTImageProcessor)
    (MobileViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevitv2** — [MobileViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTImageProcessor)
    (MobileViTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nat** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (NAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nougat** — [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    (Nougat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**oneformer** — [OneFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerImageProcessor)
    (OneFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlv2** — [Owlv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ImageProcessor)
    (OWLv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlvit** — [OwlViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTImageProcessor)
    (OWL-ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceiver** — [PerceiverImageProcessor](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverImageProcessor)
    (Perceiver model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pix2struct** — [Pix2StructImageProcessor](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructImageProcessor)
    (Pix2Struct model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**poolformer** — [PoolFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerImageProcessor)
    (PoolFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pvt** — [PvtImageProcessor](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtImageProcessor)
    (PVT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**regnet** — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (RegNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resnet** — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (ResNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sam** — [SamImageProcessor](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamImageProcessor)
    (SAM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**segformer** — [SegformerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerImageProcessor)
    (SegFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**siglip** — [SiglipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipImageProcessor)
    (SigLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swiftformer** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (SwiftFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (Swin Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin2sr** — [Swin2SRImageProcessor](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRImageProcessor)
    (Swin2SR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swinv2** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (Swin Transformer V2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**table-transformer** — [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor)
    (Table Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timesformer** — [VideoMAEImageProcessor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEImageProcessor)
    (TimeSformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvlt** — [TvltImageProcessor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltImageProcessor)
    (TVLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvp** — [TvpImageProcessor](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpImageProcessor)
    (TVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**upernet** — [SegformerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerImageProcessor)
    (UPerNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**van** — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (VAN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**videomae** — [VideoMAEImageProcessor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEImageProcessor)
    (VideoMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vilt** — [ViltImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltImageProcessor)
    (ViLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vipllava** — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (VipLlava model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_hybrid** — [ViTHybridImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridImageProcessor)
    (ViT Hybrid model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_mae** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (ViTMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_msn** — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (ViTMSN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vitmatte** — [VitMatteImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteImageProcessor)
    (ViTMatte model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xclip** — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (X-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yolos** — [YolosImageProcessor](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosImageProcessor)
    (YOLOS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Passing `token=True` is required when you want to use a private model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '#### register'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L422)'
  prefs: []
  type: TYPE_NORMAL
- en: ( config_class image_processor_class exist_ok = False )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config_class** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration corresponding to the model to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**image_processor_class** ([ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin))
    — The image processor to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Register a new image processor for this class.
  prefs: []
  type: TYPE_NORMAL
- en: AutoProcessor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class transformers.AutoProcessor'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L129)'
  prefs: []
  type: TYPE_NORMAL
- en: ( )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic processor class that will be instantiated as one of the processor
    classes of the library when created with the [AutoProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoProcessor.from_pretrained)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L143)'
  prefs: []
  type: TYPE_NORMAL
- en: ( pretrained_model_name_or_path **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — This can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: a path to a *directory* containing a processor files saved using the `save_pretrained()`
    method, e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model feature extractor should be cached if the
    standard cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force to (re-)download the feature extractor files and override the cached
    versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received file. Attempts to resume the download if such
    a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}.` The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**token** (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_unused_kwargs** (`bool`, *optional*, defaults to `False`) — If `False`,
    then this function returns just the final feature extractor object. If `True`,
    then this functions returns a `Tuple(feature_extractor, unused_kwargs)` where
    *unused_kwargs* is a dictionary consisting of the key/value pairs whose keys are
    not feature extractor attributes: i.e., the part of `kwargs` which has not been
    used to update `feature_extractor` and is otherwise ignored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (`Dict[str, Any]`, *optional*) — The values in kwargs of any keys
    which are feature extractor attributes will be used to override the loaded values.
    Behavior concerning key/value pairs whose keys are *not* feature extractor attributes
    is controlled by the `return_unused_kwargs` keyword parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the processor classes of the library from a pretrained model
    vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: 'The processor class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible):'
  prefs: []
  type: TYPE_NORMAL
- en: '**align** — [AlignProcessor](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignProcessor)
    (ALIGN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**altclip** — [AltCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPProcessor)
    (AltCLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bark** — [BarkProcessor](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor)
    (Bark model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip** — [BlipProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipProcessor)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip-2** — [Blip2Processor](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Processor)
    (BLIP-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bridgetower** — [BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)
    (BridgeTower model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**chinese_clip** — [ChineseCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPProcessor)
    (Chinese-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clap** — [ClapProcessor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapProcessor)
    (CLAP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [CLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clipseg** — [CLIPSegProcessor](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegProcessor)
    (CLIPSeg model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clvp** — [ClvpProcessor](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpProcessor)
    (CLVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flava** — [FlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaProcessor)
    (FLAVA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fuyu** — [FuyuProcessor](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuProcessor)
    (Fuyu model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**git** — [GitProcessor](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitProcessor)
    (GIT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**groupvit** — [CLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor)
    (GroupViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hubert** — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (Hubert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**idefics** — [IdeficsProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsProcessor)
    (IDEFICS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**instructblip** — [InstructBlipProcessor](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipProcessor)
    (InstructBLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kosmos-2** — [Kosmos2Processor](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Processor)
    (KOSMOS-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llava** — [LlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaProcessor)
    (LLaVa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**markuplm** — [MarkupLMProcessor](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMProcessor)
    (MarkupLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mctct** — [MCTCTProcessor](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTProcessor)
    (M-CTC-T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mgp-str** — [MgpstrProcessor](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor)
    (MGP-STR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**oneformer** — [OneFormerProcessor](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerProcessor)
    (OneFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlv2** — [Owlv2Processor](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Processor)
    (OWLv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlvit** — [OwlViTProcessor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTProcessor)
    (OWL-ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pix2struct** — [Pix2StructProcessor](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructProcessor)
    (Pix2Struct model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pop2piano** — [Pop2PianoProcessor](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoProcessor)
    (Pop2Piano model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sam** — [SamProcessor](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamProcessor)
    (SAM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t** — [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)
    (SeamlessM4T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew** — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (SEW model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew-d** — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (SEW-D model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**siglip** — [SiglipProcessor](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipProcessor)
    (SigLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text** — [Speech2TextProcessor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextProcessor)
    (Speech2Text model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text_2** — [Speech2Text2Processor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor)
    (Speech2Text2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speecht5** — [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)
    (SpeechT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trocr** — [TrOCRProcessor](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor)
    (TrOCR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvlt** — [TvltProcessor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltProcessor)
    (TVLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvp** — [TvpProcessor](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpProcessor)
    (TVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech** — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (UniSpeech model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech-sat** — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (UniSpeechSat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vilt** — [ViltProcessor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltProcessor)
    (ViLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vipllava** — [LlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaProcessor)
    (VipLlava model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vision-text-dual-encoder** — [VisionTextDualEncoderProcessor](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor)
    (VisionTextDualEncoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-bert** — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wavlm** — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (WavLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [WhisperProcessor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xclip** — [XCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPProcessor)
    (X-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Passing `token=True` is required when you want to use a private model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '#### register'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L347)'
  prefs: []
  type: TYPE_NORMAL
- en: ( config_class processor_class exist_ok = False )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config_class** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration corresponding to the model to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**processor_class** (`FeatureExtractorMixin`) — The processor to register.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Register a new processor for this class.
  prefs: []
  type: TYPE_NORMAL
- en: Generic model classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following auto classes are available for instantiating a base model class
    without a specific head.
  prefs: []
  type: TYPE_NORMAL
- en: AutoModel
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModel'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1304)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the base model
    classes of the library when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)
    configuration class: [ASTModel](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTModel)
    (Audio Spectrogram Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertModel)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)
    configuration class: [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)
    configuration class: [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)
    configuration class: [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel)
    (Autoformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)
    configuration class: [BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel)
    (Bark model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartModel)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [BeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitModel)
    (BEiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)
    configuration class: [BertGenerationEncoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder)
    (Bert Generation model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdModel)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusModel](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    configuration class: [BioGptModel](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptModel)
    (BioGpt model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig)
    configuration class: [BitModel](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitModel)
    (BiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [BlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotModel)
    (Blenderbot model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [BlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel)
    (BlenderbotSmall model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    configuration class: [Blip2Model](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Model)
    (BLIP-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomModel)
    (BLOOM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)
    configuration class: [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)
    (BridgeTower model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig)
    configuration class: [BrosModel](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosModel)
    (BROS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig)
    configuration class: [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CLIPVisionConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionConfig)
    configuration class: [CLIPVisionModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel)
    (CLIPVisionModel model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [CTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLModel)
    (CTRL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertModel)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineModel](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineModel)
    (CANINE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig)
    configuration class: [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)
    configuration class: [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    (CLAP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ClvpConfig](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpConfig)
    configuration class: [ClvpModelForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpModelForConditionalGeneration)
    (CLVP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig)
    configuration class: [CodeGenModel](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenModel)
    (CodeGen model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig)
    configuration class: [ConditionalDetrModel](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrModel)
    (Conditional DETR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertModel)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    configuration class: [ConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextModel)
    (ConvNeXT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    configuration class: [ConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Model)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig)
    configuration class: [CpmAntModel](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntModel)
    (CPM-Ant model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    configuration class: [CvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtModel)
    (CvT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig)
    configuration class: [DPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoder)
    (DPR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    configuration class: [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel)
    (DPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioModel)
    (Data2VecAudio model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextModel)
    (Data2VecText model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [Data2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionModel)
    (Data2VecVision model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaModel)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Model)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DecisionTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig)
    configuration class: [DecisionTransformerModel](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerModel)
    (Decision Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)
    configuration class: [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)
    (Deformable DETR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel)
    (DeiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)
    configuration class: [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)
    (DETA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    configuration class: [DetrModel](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrModel)
    (DETR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DinatConfig](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatConfig)
    configuration class: [DinatModel](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatModel)
    (DiNAT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dinov2Config](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Config)
    configuration class: [Dinov2Model](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Model)
    (DINOv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertModel)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig)
    configuration class: [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel)
    (DonutSwin model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    configuration class: [EfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerModel)
    (EfficientFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EfficientNetConfig](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetConfig)
    configuration class: [EfficientNetModel](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetModel)
    (EfficientNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraModel)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig)
    configuration class: [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)
    (EnCodec model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieModel](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieModel)
    (ERNIE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMModel](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMModel)
    (ErnieM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [EsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmModel)
    (ESM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    (FNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    configuration class: [FSMTModel](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTModel)
    (FairSeq Machine-Translation model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconModel](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconModel)
    (Falcon model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FastSpeech2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerConfig)
    configuration class: [FastSpeech2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerModel)
    (FastSpeech2Conformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertModel)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    configuration class: [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    (FLAVA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)
    configuration class: [FocalNetModel](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetModel)
    (FocalNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelModel)
    or [FunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelBaseModel)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig)
    configuration class: [GLPNModel](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNModel)
    (GLPN model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeModel](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeModel)
    (GPTBigCode model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [GPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJModel)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoModel)
    (GPT Neo model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXModel)
    (GPT NeoX model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig)
    configuration class: [GPTNeoXJapaneseModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel)
    (GPT NeoX Japanese model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    configuration class: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    configuration class: [GitModel](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitModel)
    (GIT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GraphormerConfig](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerConfig)
    configuration class: [GraphormerModel](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerModel)
    (Graphormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)
    configuration class: [GroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTModel)
    (GroupViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    configuration class: [HubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertModel)
    (Hubert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertModel](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertModel)
    (I-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)
    configuration class: [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)
    (IDEFICS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig)
    configuration class: [ImageGPTModel](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTModel)
    (ImageGPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig)
    configuration class: [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel)
    (Informer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[JukeboxConfig](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxConfig)
    configuration class: [JukeboxModel](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxModel)
    (Jukebox model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config)
    configuration class: [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model)
    (KOSMOS-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [LEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDModel)
    (LED model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    (LayoutLMv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig)
    configuration class: [LevitModel](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitModel)
    (LeViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    configuration class: [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)
    (LiLT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel)
    (LLaMA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [LongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Model)
    (LongT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerModel)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeModel](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeModel)
    (LUKE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    (LXMERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)
    configuration class: [M2M100Model](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Model)
    (M2M100 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartModel)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)
    configuration class: [MCTCTModel](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTModel)
    (M-CTC-T model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetModel)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [MT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Model)
    (MT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [MarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianModel)
    (Marian model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    configuration class: [MarkupLMModel](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMModel)
    (MarkupLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)
    configuration class: [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)
    (Mask2Former model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    configuration class: [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)
    (MaskFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MaskFormerSwinConfig` configuration class: `MaskFormerSwinModel` (MaskFormerSwin
    model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaModel](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaModel)
    (MEGA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertModel](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertModel)
    (Megatron-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig)
    configuration class: [MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition)
    (MGP-STR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    configuration class: [MistralModel](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralModel)
    (Mistral model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    configuration class: [MixtralModel](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralModel)
    (Mixtral model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertModel)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config)
    configuration class: [MobileNetV1Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Model)
    (MobileNetV1 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    configuration class: [MobileNetV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model)
    (MobileNetV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [MobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTModel)
    (MobileViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    configuration class: [MobileViTV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Model)
    (MobileViTV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptModel](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptModel)
    (MPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraModel](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraModel)
    (MRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpModel](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpModel)
    (MVP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig)
    configuration class: [NatModel](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatModel)
    (NAT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaModel](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaModel)
    (Nezha model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    configuration class: [NllbMoeModel](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeModel)
    (NLLB-MOE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerModel](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerModel)
    (Nyströmformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [OPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTModel)
    (OPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)
    configuration class: [OneFormerModel](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerModel)
    (OneFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [OpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    configuration class: [OpenLlamaModel](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaModel)
    (OpenLlama model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)
    configuration class: [OwlViTModel](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTModel)
    (OWL-ViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)
    configuration class: [Owlv2Model](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Model)
    (OWLv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    configuration class: [PLBartModel](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartModel)
    (PLBart model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PatchTSMixerConfig](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerConfig)
    configuration class: [PatchTSMixerModel](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerModel)
    (PatchTSMixer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PatchTSTConfig](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTConfig)
    configuration class: [PatchTSTModel](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTModel)
    (PatchTST model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [PegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusModel)
    (Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig)
    configuration class: [PegasusXModel](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXModel)
    (PEGASUS-X model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    configuration class: [PerceiverModel](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverModel)
    (Perceiver model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    configuration class: [PersimmonModel](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonModel)
    (Persimmon model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    configuration class: [PhiModel](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiModel)
    (Phi model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)
    configuration class: [PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel)
    (PoolFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    configuration class: [ProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetModel)
    (ProphetNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig)
    configuration class: [PvtModel](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtModel)
    (PVT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertModel)
    (QDQBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    configuration class: [Qwen2Model](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Model)
    (Qwen2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerModel](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModel)
    (Reformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)
    (RegNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertModel)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)
    (ResNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig)
    configuration class: [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertModel](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertModel)
    (RoCBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerModel)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaModel)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    configuration class: [RwkvModel](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvModel)
    (RWKV model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    configuration class: [SEWModel](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWModel)
    (SEW model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    configuration class: [SEWDModel](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDModel)
    (SEW-D model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig)
    configuration class: [SamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamModel)
    (SAM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    configuration class: [SeamlessM4TModel](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TModel)
    (SeamlessM4T model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    configuration class: [SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    (SeamlessM4Tv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [SegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerModel)
    (SegFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig)
    configuration class: [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SiglipVisionConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionConfig)
    configuration class: [SiglipVisionModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionModel)
    (SiglipVisionModel model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    configuration class: [Speech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextModel)
    (Speech2Text model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)
    configuration class: [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)
    (SpeechT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    configuration class: [SplinterModel](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterModel)
    (Splinter model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertModel](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertModel)
    (SqueezeBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig)
    configuration class: [SwiftFormerModel](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerModel)
    (SwiftFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Swin2SRConfig](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRConfig)
    configuration class: [Swin2SRModel](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRModel)
    (Swin2SR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [SwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinModel)
    (Swin Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    configuration class: [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model)
    (Swin Transformer V2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    configuration class: [SwitchTransformersModel](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersModel)
    (SwitchTransformers model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)
    configuration class: [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel)
    (Table Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasModel)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig)
    configuration class: [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)
    (Time Series Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig)
    configuration class: [TimesformerModel](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerModel)
    (TimeSformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TimmBackboneConfig` configuration class: `TimmBackbone` (TimmBackbone model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig)
    configuration class: [TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel)
    (Trajectory Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLModel)
    (Transformer-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig)
    configuration class: [TvltModel](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltModel)
    (TVLT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TvpConfig](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpConfig)
    configuration class: [TvpModel](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpModel)
    (TVP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    configuration class: [UMT5Model](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Model)
    (UMT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    configuration class: [UniSpeechModel](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechModel)
    (UniSpeech model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatModel](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel)
    (UniSpeechSat model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig)
    configuration class: [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)
    (UnivNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig)
    configuration class: [VanModel](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanModel)
    (VAN model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel)
    (ViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)
    configuration class: [ViTHybridModel](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridModel)
    (ViT Hybrid model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    configuration class: [ViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEModel)
    (ViTMAE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)
    configuration class: [ViTMSNModel](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNModel)
    (ViTMSN model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    configuration class: [VideoMAEModel](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEModel)
    (VideoMAE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig)
    configuration class: [ViltModel](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltModel)
    (ViLT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    configuration class: [VisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)
    configuration class: [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    (VisualBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VitDetConfig](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetConfig)
    configuration class: [VitDetModel](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetModel)
    (VitDet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VitsConfig](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsConfig)
    configuration class: [VitsModel](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsModel)
    (VITS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)
    configuration class: [VivitModel](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitModel)
    (ViViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertModel)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMModel](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMModel)
    (WavLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)
    (Whisper model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPConfig)
    configuration class: [XCLIPModel](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPModel)
    (X-CLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [XGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMModel)
    (XGLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMModel)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    configuration class: [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel)
    (XLM-ProphetNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetModel)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodModel](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodModel)
    (X-MOD model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)
    configuration class: [YolosModel](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosModel)
    (YOLOS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoModel](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoModel)
    (YOSO model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the base model classes of the library from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the base model classes of the library from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [AlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertModel)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**align** — [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**altclip** — [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**audio-spectrogram-transformer** — [ASTModel](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTModel)
    (Audio Spectrogram Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**autoformer** — [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel)
    (Autoformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bark** — [BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel)
    (Bark model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [BartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartModel)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**beit** — [BeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitModel)
    (BEiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert-generation** — [BertGenerationEncoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder)
    (Bert Generation model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdModel)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bigbird_pegasus** — [BigBirdPegasusModel](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**biogpt** — [BioGptModel](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptModel)
    (BioGpt model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bit** — [BitModel](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitModel)
    (BiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot** — [BlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotModel)
    (Blenderbot model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot-small** — [BlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel)
    (BlenderbotSmall model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip** — [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip-2** — [Blip2Model](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Model)
    (BLIP-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [BloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomModel)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bridgetower** — [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)
    (BridgeTower model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bros** — [BrosModel](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosModel)
    (BROS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertModel)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**canine** — [CanineModel](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineModel)
    (CANINE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**chinese_clip** — [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clap** — [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    (CLAP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip_vision_model** — [CLIPVisionModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel)
    (CLIPVisionModel model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clipseg** — [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clvp** — [ClvpModelForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpModelForConditionalGeneration)
    (CLVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_llama** — [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel)
    (CodeLlama model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**codegen** — [CodeGenModel](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenModel)
    (CodeGen model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**conditional_detr** — [ConditionalDetrModel](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrModel)
    (Conditional DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [ConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertModel)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnext** — [ConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextModel)
    (ConvNeXT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnextv2** — [ConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Model)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cpmant** — [CpmAntModel](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntModel)
    (CPM-Ant model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [CTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLModel)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cvt** — [CvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtModel)
    (CvT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-audio** — [Data2VecAudioModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioModel)
    (Data2VecAudio model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [Data2VecTextModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextModel)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-vision** — [Data2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionModel)
    (Data2VecVision model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [DebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaModel)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [DebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Model)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**decision_transformer** — [DecisionTransformerModel](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerModel)
    (Decision Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deformable_detr** — [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)
    (Deformable DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deit** — [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel)
    (DeiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deta** — [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)
    (DETA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**detr** — [DetrModel](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrModel)
    (DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dinat** — [DinatModel](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatModel)
    (DiNAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dinov2** — [Dinov2Model](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Model)
    (DINOv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [DistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertModel)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**donut-swin** — [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel)
    (DonutSwin model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dpr** — [DPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoder)
    (DPR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dpt** — [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel)
    (DPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientformer** — [EfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerModel)
    (EfficientFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientnet** — [EfficientNetModel](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetModel)
    (EfficientNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraModel)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encodec** — [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)
    (EnCodec model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieModel](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieModel)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie_m** — [ErnieMModel](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMModel)
    (ErnieM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [EsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmModel)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**falcon** — [FalconModel](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconModel)
    (Falcon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fastspeech2_conformer** — [FastSpeech2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerModel)
    (FastSpeech2Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [FlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertModel)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flava** — [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    (FLAVA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**focalnet** — [FocalNetModel](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetModel)
    (FocalNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fsmt** — [FSMTModel](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTModel)
    (FairSeq Machine-Translation model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [FunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelModel)
    or [FunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelBaseModel)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**git** — [GitModel](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitModel)
    (GIT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**glpn** — [GLPNModel](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNModel)
    (GLPN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_bigcode** — [GPTBigCodeModel](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeModel)
    (GPTBigCode model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neo** — [GPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoModel)
    (GPT Neo model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox** — [GPTNeoXModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXModel)
    (GPT NeoX model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox_japanese** — [GPTNeoXJapaneseModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel)
    (GPT NeoX Japanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [GPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJModel)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptsan-japanese** — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**graphormer** — [GraphormerModel](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerModel)
    (Graphormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**groupvit** — [GroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTModel)
    (GroupViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hubert** — [HubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertModel)
    (Hubert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ibert** — [IBertModel](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertModel)
    (I-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**idefics** — [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)
    (IDEFICS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**imagegpt** — [ImageGPTModel](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTModel)
    (ImageGPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**informer** — [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel)
    (Informer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**jukebox** — [JukeboxModel](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxModel)
    (Jukebox model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kosmos-2** — [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model)
    (KOSMOS-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**led** — [LEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDModel)
    (LED model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**levit** — [LevitModel](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitModel)
    (LeViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lilt** — [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)
    (LiLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llama** — [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel)
    (LLaMA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [LongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerModel)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longt5** — [LongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Model)
    (LongT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**luke** — [LukeModel](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeModel)
    (LUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lxmert** — [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    (LXMERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**m2m_100** — [M2M100Model](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Model)
    (M2M100 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**marian** — [MarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianModel)
    (Marian model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**markuplm** — [MarkupLMModel](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMModel)
    (MarkupLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mask2former** — [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)
    (Mask2Former model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**maskformer** — [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)
    (MaskFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**maskformer-swin** — `MaskFormerSwinModel` (MaskFormerSwin model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [MBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartModel)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mctct** — [MCTCTModel](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTModel)
    (M-CTC-T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [MegaModel](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaModel)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertModel](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertModel)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mgp-str** — [MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition)
    (MGP-STR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mistral** — [MistralModel](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralModel)
    (Mistral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mixtral** — [MixtralModel](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralModel)
    (Mixtral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertModel)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v1** — [MobileNetV1Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Model)
    (MobileNetV1 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v2** — [MobileNetV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model)
    (MobileNetV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevit** — [MobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTModel)
    (MobileViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevitv2** — [MobileViTV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Model)
    (MobileViTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [MPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetModel)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpt** — [MptModel](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptModel)
    (MPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mra** — [MraModel](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraModel)
    (MRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [MT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Model)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mvp** — [MvpModel](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpModel)
    (MVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nat** — [NatModel](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatModel)
    (NAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [NezhaModel](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaModel)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nllb-moe** — [NllbMoeModel](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeModel)
    (NLLB-MOE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nystromformer** — [NystromformerModel](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerModel)
    (Nyströmformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**oneformer** — [OneFormerModel](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerModel)
    (OneFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**open-llama** — [OpenLlamaModel](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaModel)
    (OpenLlama model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [OpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [OPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTModel)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlv2** — [Owlv2Model](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Model)
    (OWLv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlvit** — [OwlViTModel](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTModel)
    (OWL-ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**patchtsmixer** — [PatchTSMixerModel](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerModel)
    (PatchTSMixer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**patchtst** — [PatchTSTModel](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTModel)
    (PatchTST model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus** — [PegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusModel)
    (Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus_x** — [PegasusXModel](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXModel)
    (PEGASUS-X model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceiver** — [PerceiverModel](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverModel)
    (Perceiver model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**persimmon** — [PersimmonModel](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonModel)
    (Persimmon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**phi** — [PhiModel](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiModel)
    (Phi model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**plbart** — [PLBartModel](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartModel)
    (PLBart model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**poolformer** — [PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel)
    (PoolFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**prophetnet** — [ProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetModel)
    (ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pvt** — [PvtModel](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtModel)
    (PVT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [QDQBertModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertModel)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qwen2** — [Qwen2Model](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Model)
    (Qwen2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**reformer** — [ReformerModel](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModel)
    (Reformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**regnet** — [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)
    (RegNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [RemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertModel)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resnet** — [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)
    (ResNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**retribert** — [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaModel)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertModel](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertModel)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [RoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerModel)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rwkv** — [RwkvModel](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvModel)
    (RWKV model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sam** — [SamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamModel)
    (SAM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t** — [SeamlessM4TModel](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TModel)
    (SeamlessM4T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t_v2** — [SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    (SeamlessM4Tv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**segformer** — [SegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerModel)
    (SegFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew** — [SEWModel](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWModel)
    (SEW model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew-d** — [SEWDModel](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDModel)
    (SEW-D model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**siglip** — [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**siglip_vision_model** — [SiglipVisionModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionModel)
    (SiglipVisionModel model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text** — [Speech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextModel)
    (Speech2Text model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speecht5** — [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)
    (SpeechT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**splinter** — [SplinterModel](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterModel)
    (Splinter model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**squeezebert** — [SqueezeBertModel](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertModel)
    (SqueezeBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swiftformer** — [SwiftFormerModel](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerModel)
    (SwiftFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin** — [SwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinModel)
    (Swin Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin2sr** — [Swin2SRModel](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRModel)
    (Swin2SR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swinv2** — [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model)
    (Swin Transformer V2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**switch_transformers** — [SwitchTransformersModel](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersModel)
    (SwitchTransformers model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**table-transformer** — [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel)
    (Table Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasModel)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**time_series_transformer** — [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)
    (Time Series Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timesformer** — [TimesformerModel](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerModel)
    (TimeSformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timm_backbone** — `TimmBackbone` (TimmBackbone model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trajectory_transformer** — [TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel)
    (Trajectory Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLModel)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvlt** — [TvltModel](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltModel)
    (TVLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvp** — [TvpModel](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpModel)
    (TVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**umt5** — [UMT5Model](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Model)
    (UMT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech** — [UniSpeechModel](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechModel)
    (UniSpeech model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech-sat** — [UniSpeechSatModel](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel)
    (UniSpeechSat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**univnet** — [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)
    (UnivNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**van** — [VanModel](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanModel)
    (VAN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**videomae** — [VideoMAEModel](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEModel)
    (VideoMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vilt** — [ViltModel](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltModel)
    (ViLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vision-text-dual-encoder** — [VisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**visual_bert** — [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    (VisualBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_hybrid** — [ViTHybridModel](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridModel)
    (ViT Hybrid model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_mae** — [ViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEModel)
    (ViTMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_msn** — [ViTMSNModel](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNModel)
    (ViTMSN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vitdet** — [VitDetModel](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetModel)
    (VitDet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vits** — [VitsModel](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsModel)
    (VITS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vivit** — [VivitModel](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitModel)
    (ViViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-bert** — [Wav2Vec2BertModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertModel)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wavlm** — [WavLMModel](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMModel)
    (WavLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xclip** — [XCLIPModel](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPModel)
    (X-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xglm** — [XGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMModel)
    (XGLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMModel)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-prophetnet** — [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel)
    (XLM-ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaXLModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [XLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetModel)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XmodModel](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodModel)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yolos** — [YolosModel](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosModel)
    (YOLOS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yoso** — [YosoModel](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoModel)
    (YOSO model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModel
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModel'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L531)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the base model
    classes of the library when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertModel)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [TFBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartModel)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertModel)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [TFBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel)
    (Blenderbot model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [TFBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel)
    (BlenderbotSmall model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [TFCTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLModel)
    (CTRL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertModel)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertModel)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    configuration class: [TFConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextModel)
    (ConvNeXT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    configuration class: [TFConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2Model)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    configuration class: [TFCvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtModel)
    (CvT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig)
    configuration class: [TFDPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder)
    (DPR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [TFData2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionModel)
    (Data2VecVision model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaModel)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel)
    (DeiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertModel)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    configuration class: [TFEfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerModel)
    (EfficientFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraModel)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [TFEsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmModel)
    (ESM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertModel)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelModel)
    or [TFFunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelBaseModel)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [TFGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJModel)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)
    configuration class: [TFGroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.TFGroupViTModel)
    (GroupViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    configuration class: [TFHubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.TFHubertModel)
    (Hubert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [TFLEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDModel)
    (LED model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerModel)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)
    (LXMERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [TFMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartModel)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetModel)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [TFMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5Model)
    (MT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [TFMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianModel)
    (Marian model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertModel)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [TFMobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTModel)
    (MobileViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [TFOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTModel)
    (OPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [TFOpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [TFPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusModel)
    (Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)
    (RegNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertModel)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel)
    (ResNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerModel)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaModel)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig)
    configuration class: [TFSamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.TFSamModel)
    (SAM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [TFSegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerModel)
    (SegFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    configuration class: [TFSpeech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel)
    (Speech2Text model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [TFSwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinModel)
    (Swin Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasModel)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TFTransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel)
    (Transformer-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [TFViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTModel)
    (ViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    configuration class: [TFViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEModel)
    (ViTMAE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    configuration class: [TFVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.TFVisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [TFWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel)
    (Whisper model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [TFXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMModel)
    (XGLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMModel)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetModel)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the base model classes of the library from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the base model classes of the library from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [TFAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertModel)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [TFBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartModel)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [TFBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertModel)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot** — [TFBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel)
    (Blenderbot model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot-small** — [TFBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel)
    (BlenderbotSmall model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip** — [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [TFCamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertModel)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [TFConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertModel)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnext** — [TFConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextModel)
    (ConvNeXT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnextv2** — [TFConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2Model)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [TFCTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLModel)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cvt** — [TFCvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtModel)
    (CvT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-vision** — [TFData2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionModel)
    (Data2VecVision model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [TFDebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaModel)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [TFDebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deit** — [TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel)
    (DeiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [TFDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertModel)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dpr** — [TFDPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder)
    (DPR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientformer** — [TFEfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerModel)
    (EfficientFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [TFElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraModel)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [TFEsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmModel)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [TFFlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertModel)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [TFFunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelModel)
    or [TFFunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelBaseModel)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [TFGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJModel)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**groupvit** — [TFGroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.TFGroupViTModel)
    (GroupViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hubert** — [TFHubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.TFHubertModel)
    (Hubert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [TFLayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**led** — [TFLEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDModel)
    (LED model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [TFLongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerModel)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lxmert** — [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)
    (LXMERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**marian** — [TFMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianModel)
    (Marian model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [TFMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartModel)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [TFMobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertModel)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevit** — [TFMobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTModel)
    (MobileViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [TFMPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetModel)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [TFMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5Model)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [TFOpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [TFOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTModel)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus** — [TFPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusModel)
    (Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**regnet** — [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)
    (RegNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [TFRemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertModel)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resnet** — [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel)
    (ResNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [TFRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaModel)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [TFRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [TFRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerModel)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sam** — [TFSamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.TFSamModel)
    (SAM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**segformer** — [TFSegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerModel)
    (SegFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text** — [TFSpeech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel)
    (Speech2Text model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin** — [TFSwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinModel)
    (Swin Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TFTapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasModel)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TFTransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vision-text-dual-encoder** — [TFVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.TFVisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [TFViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTModel)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_mae** — [TFViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEModel)
    (ViTMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [TFWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xglm** — [TFXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMModel)
    (XGLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [TFXLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMModel)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [TFXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [TFXLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetModel)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModel
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModel'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L276)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the base model
    classes of the library when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertModel)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartModel)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [FlaxBeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitModel)
    (BEiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertModel)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [FlaxBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel)
    (Blenderbot model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [FlaxBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel)
    (BlenderbotSmall model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [FlaxBloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomModel)
    (BLOOM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [FlaxCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPModel)
    (CLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraModel)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [FlaxGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJModel)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [FlaxGPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel)
    (GPT Neo model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [FlaxLlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaModel)
    (LLaMA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [FlaxLongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5Model)
    (LongT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartModel)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [FlaxMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5Model)
    (MT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [FlaxMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianModel)
    (Marian model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [FlaxOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTModel)
    (OPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [FlaxPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusModel)
    (Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [FlaxRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetModel)
    (RegNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [FlaxResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetModel)
    (ResNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerModel)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaModel)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [FlaxT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5Model)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [FlaxViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTModel)
    (ViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    configuration class: [FlaxVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [FlaxWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [FlaxWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperModel)
    (Whisper model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [FlaxXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMModel)
    (XGLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the base model classes of the library from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the base model classes of the library from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [FlaxAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertModel)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [FlaxBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartModel)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**beit** — [FlaxBeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitModel)
    (BEiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [FlaxBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertModel)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [FlaxBigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot** — [FlaxBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel)
    (Blenderbot model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot-small** — [FlaxBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel)
    (BlenderbotSmall model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [FlaxBloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomModel)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [FlaxCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPModel)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [FlaxDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [FlaxElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraModel)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neo** — [FlaxGPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel)
    (GPT Neo model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [FlaxGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJModel)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llama** — [FlaxLlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaModel)
    (LLaMA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longt5** — [FlaxLongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5Model)
    (LongT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**marian** — [FlaxMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianModel)
    (Marian model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [FlaxMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartModel)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [FlaxMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5Model)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [FlaxOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTModel)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus** — [FlaxPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusModel)
    (Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**regnet** — [FlaxRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetModel)
    (RegNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resnet** — [FlaxResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetModel)
    (ResNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [FlaxRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaModel)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [FlaxRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [FlaxRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerModel)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [FlaxT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5Model)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vision-text-dual-encoder** — [FlaxVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [FlaxViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTModel)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [FlaxWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [FlaxWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperModel)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xglm** — [FlaxXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMModel)
    (XGLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [FlaxXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Generic pretraining classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following auto classes are available for instantiating a model with a pretraining
    head.
  prefs: []
  type: TYPE_NORMAL
- en: AutoModelForPreTraining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForPreTraining'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1311)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a pretraining head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForPreTraining)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForPreTraining)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForPreTraining)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForPreTraining)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForPreTraining](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForPreTraining)
    (ERNIE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForPreTraining](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForPreTraining)
    (FNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    configuration class: [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq Machine-Translation model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    configuration class: [FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining)
    (FLAVA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForPreTraining)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    configuration class: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)
    configuration class: [IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text)
    (IDEFICS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig)
    configuration class: [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)
    (LXMERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining)
    (Megatron-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForPreTraining)
    (Nezha model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    configuration class: [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig)
    configuration class: [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForPreTraining)
    (RoCBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    configuration class: [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    configuration class: [SplinterForPreTraining](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForPreTraining)
    (Splinter model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    configuration class: [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig)
    configuration class: [TvltForPreTraining](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltForPreTraining)
    (TVLT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    configuration class: [UniSpeechForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining)
    (UniSpeech model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining)
    (UniSpeechSat model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    configuration class: [ViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining)
    (ViTMAE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    configuration class: [VideoMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForPreTraining)
    (VideoMAE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig)
    configuration class: [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)
    configuration class: [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)
    (VisualBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a pretraining head)
    from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a pretraining head)
    from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [AlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForPreTraining)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForPreTraining)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForPreTraining)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForPreTraining)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieForPreTraining](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForPreTraining)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flava** — [FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining)
    (FLAVA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetForPreTraining](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForPreTraining)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fsmt** — [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq Machine-Translation model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [FunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForPreTraining)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_bigcode** — [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptsan-japanese** — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ibert** — [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**idefics** — [IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text)
    (IDEFICS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llava** — [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**luke** — [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lxmert** — [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)
    (LXMERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpt** — [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mra** — [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mvp** — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [NezhaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForPreTraining)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nllb-moe** — [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**retribert** — [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForPreTraining)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rwkv** — [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**splinter** — [SplinterForPreTraining](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForPreTraining)
    (Splinter model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**squeezebert** — [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**switch_transformers** — [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tvlt** — [TvltForPreTraining](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltForPreTraining)
    (TVLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech** — [UniSpeechForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining)
    (UniSpeech model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech-sat** — [UniSpeechSatForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining)
    (UniSpeechSat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**videomae** — [VideoMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForPreTraining)
    (VideoMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vipllava** — [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**visual_bert** — [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)
    (VisualBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_mae** — [ViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining)
    (ViTMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2ConformerForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForPreTraining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForPreTraining'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L547)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a pretraining head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForPreTraining)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForPreTraining)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForPreTraining)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining)
    (LXMERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    configuration class: [TFViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining)
    (ViTMAE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a pretraining head)
    from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a pretraining head)
    from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [TFAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForPreTraining)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [TFBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForPreTraining)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [TFElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForPreTraining)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [TFFunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lxmert** — [TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining)
    (LXMERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [TFMobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_mae** — [TFViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining)
    (ViTMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForPreTraining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForPreTraining'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L283)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a pretraining head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForPreTraining)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [FlaxWav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a pretraining head)
    from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a pretraining head)
    from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [FlaxAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [FlaxBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForPreTraining)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [FlaxBigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [FlaxElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longt5** — [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [FlaxWav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Natural Language Processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following auto classes are available for the following natural language
    processing tasks.
  prefs: []
  type: TYPE_NORMAL
- en: AutoModelForCausalLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForCausalLM'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1326)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a causal language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForCausalLM)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertLMHeadModel)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)
    configuration class: [BertGenerationDecoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder)
    (Bert Generation model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    configuration class: [BioGptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForCausalLM)
    (BioGpt model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [BlenderbotForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM)
    (Blenderbot model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [BlenderbotSmallForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM)
    (BlenderbotSmall model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForCausalLM)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig)
    configuration class: [CodeGenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenForCausalLM)
    (CodeGen model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig)
    configuration class: [CpmAntForCausalLM](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntForCausalLM)
    (CPM-Ant model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForCausalLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM)
    (Data2VecText model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForCausalLM)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForCausalLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForCausalLM)
    (ERNIE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconForCausalLM](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForCausalLM)
    (Falcon model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FuyuConfig](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuConfig)
    configuration class: [FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM)
    (Fuyu model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [GPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForCausalLM)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM)
    (GPT Neo model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM)
    (GPT NeoX model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig)
    configuration class: [GPTNeoXJapaneseForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM)
    (GPT NeoX Japanese model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    configuration class: [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM)
    (LLaMA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForCausalLM)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [MarianForCausalLM](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianForCausalLM)
    (Marian model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForCausalLM)
    (MEGA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM)
    (Megatron-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    configuration class: [MistralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForCausalLM)
    (Mistral model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    configuration class: [MixtralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForCausalLM)
    (Mixtral model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)
    configuration class: [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)
    (MusicGen model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForCausalLM)
    (MVP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [OPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForCausalLM)
    (OPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    configuration class: [OpenLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForCausalLM)
    (OpenLlama model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    configuration class: [PLBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForCausalLM)
    (PLBart model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [PegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForCausalLM)
    (Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    configuration class: [PersimmonForCausalLM](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForCausalLM)
    (Persimmon model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    configuration class: [PhiForCausalLM](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForCausalLM)
    (Phi model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    configuration class: [ProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM)
    (ProphetNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel)
    (QDQBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    configuration class: [Qwen2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForCausalLM)
    (Qwen2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerModelWithLMHead](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead)
    (Reformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForCausalLM)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForCausalLM)
    (RoCBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForCausalLM)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForCausalLM)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    configuration class: [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Speech2Text2Config](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config)
    configuration class: [Speech2Text2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM)
    (Speech2Text2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig)
    configuration class: [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM)
    (TrOCR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [WhisperForCausalLM](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForCausalLM)
    (Whisper model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [XGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMForCausalLM)
    (XGLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    configuration class: [XLMProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM)
    (XLM-ProphetNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForCausalLM)
    (X-MOD model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a causal language
    modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a causal language
    modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bart** — [BartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForCausalLM)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertLMHeadModel)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert-generation** — [BertGenerationDecoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder)
    (Bert Generation model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bigbird_pegasus** — [BigBirdPegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**biogpt** — [BioGptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForCausalLM)
    (BioGpt model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot** — [BlenderbotForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM)
    (Blenderbot model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot-small** — [BlenderbotSmallForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM)
    (BlenderbotSmall model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForCausalLM)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_llama** — [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM)
    (CodeLlama model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**codegen** — [CodeGenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenForCausalLM)
    (CodeGen model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cpmant** — [CpmAntForCausalLM](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntForCausalLM)
    (CPM-Ant model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [Data2VecTextForCausalLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForCausalLM)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieForCausalLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForCausalLM)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**falcon** — [FalconForCausalLM](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForCausalLM)
    (Falcon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fuyu** — [FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM)
    (Fuyu model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**git** — [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_bigcode** — [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neo** — [GPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM)
    (GPT Neo model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox** — [GPTNeoXForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM)
    (GPT NeoX model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox_japanese** — [GPTNeoXJapaneseForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM)
    (GPT NeoX Japanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [GPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForCausalLM)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llama** — [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM)
    (LLaMA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**marian** — [MarianForCausalLM](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianForCausalLM)
    (Marian model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [MBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForCausalLM)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [MegaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForCausalLM)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mistral** — [MistralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForCausalLM)
    (Mistral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mixtral** — [MixtralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForCausalLM)
    (Mixtral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpt** — [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**musicgen** — [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)
    (MusicGen model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mvp** — [MvpForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForCausalLM)
    (MVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**open-llama** — [OpenLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForCausalLM)
    (OpenLlama model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [OPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForCausalLM)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus** — [PegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForCausalLM)
    (Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**persimmon** — [PersimmonForCausalLM](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForCausalLM)
    (Persimmon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**phi** — [PhiForCausalLM](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForCausalLM)
    (Phi model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**plbart** — [PLBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForCausalLM)
    (PLBart model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**prophetnet** — [ProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM)
    (ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [QDQBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qwen2** — [Qwen2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForCausalLM)
    (Qwen2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**reformer** — [ReformerModelWithLMHead](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead)
    (Reformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [RemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForCausalLM)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForCausalLM)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForCausalLM)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [RoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForCausalLM)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rwkv** — [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text_2** — [Speech2Text2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM)
    (Speech2Text2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trocr** — [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM)
    (TrOCR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [WhisperForCausalLM](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForCausalLM)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xglm** — [XGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMForCausalLM)
    (XGLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-prophetnet** — [XLMProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM)
    (XLM-ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaXLForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XmodForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForCausalLM)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForCausalLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForCausalLM'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L562)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a causal language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertLMHeadModel)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForCausalLM)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [TFGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForCausalLM)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [TFOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTForCausalLM)
    (OPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [TFXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMForCausalLM)
    (XGLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a causal language
    modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a causal language
    modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bert** — [TFBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertLMHeadModel)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [TFCamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForCausalLM)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [TFGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForCausalLM)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [TFOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTForCausalLM)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [TFRemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [TFRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [TFRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [TFRoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xglm** — [TFXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMForCausalLM)
    (XGLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [TFXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForCausalLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForCausalLM'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L290)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a causal language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForCausalLM)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForCausalLM)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [FlaxBloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomForCausalLM)
    (BLOOM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForCausalLM)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [FlaxGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [FlaxGPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM)
    (GPT Neo model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [FlaxLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaForCausalLM)
    (LLaMA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [FlaxOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTForCausalLM)
    (OPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [FlaxXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM)
    (XGLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a causal language
    modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a causal language
    modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bart** — [FlaxBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForCausalLM)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [FlaxBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForCausalLM)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [FlaxBigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [FlaxBloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomForCausalLM)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [FlaxElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForCausalLM)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neo** — [FlaxGPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM)
    (GPT Neo model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [FlaxGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llama** — [FlaxLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaForCausalLM)
    (LLaMA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [FlaxOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTForCausalLM)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [FlaxRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [FlaxRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xglm** — [FlaxXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM)
    (XGLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [FlaxXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForMaskedLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForMaskedLM'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1333)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMaskedLM)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMaskedLM)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMaskedLM)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMaskedLM)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMaskedLM)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMaskedLM)
    (ERNIE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [EsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForMaskedLM)
    (ESM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMaskedLM)
    (FNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMaskedLM)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM)
    (Megatron-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMaskedLM)
    (Nezha model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM)
    (Nyströmformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    configuration class: [PerceiverForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM)
    (Perceiver model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM)
    (QDQBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForMaskedLM)
    (Reformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMaskedLM)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM)
    (RoCBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: `Wav2Vec2ForMaskedLM` (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMaskedLM)
    (YOSO model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a masked language
    modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a masked language
    modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [AlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMaskedLM)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMaskedLM)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMaskedLM)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [ConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMaskedLM)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMaskedLM)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMaskedLM)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [EsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForMaskedLM)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMaskedLM)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [FunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMaskedLM)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ibert** — [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**luke** — [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mra** — [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mvp** — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [NezhaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMaskedLM)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nystromformer** — [NystromformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM)
    (Nyströmformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceiver** — [PerceiverForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM)
    (Perceiver model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [QDQBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**reformer** — [ReformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForMaskedLM)
    (Reformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [RemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMaskedLM)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [RoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**squeezebert** — [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — `Wav2Vec2ForMaskedLM` (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yoso** — [YosoForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMaskedLM)
    (YOSO model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForMaskedLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForMaskedLM'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L612)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMaskedLM)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMaskedLM)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMaskedLM)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForMaskedLM)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMaskedLM)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [TFEsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForMaskedLM)
    (ESM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMaskedLM)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMaskedLM)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a masked language
    modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a masked language
    modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [TFAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMaskedLM)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [TFBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMaskedLM)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [TFConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMaskedLM)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [TFDebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForMaskedLM)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [TFDebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [TFElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMaskedLM)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [TFEsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForMaskedLM)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [TFFunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMaskedLM)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [TFLongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMaskedLM)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [TFMobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [TFRemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [TFRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForMaskedLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForMaskedLM'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L297)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a masked language
    modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a masked language
    modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [FlaxAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [FlaxBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [FlaxBigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [FlaxDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [FlaxElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForMaskGeneration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForMaskGeneration'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1292)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: TFAutoModelForMaskGeneration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForMaskGeneration'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L523)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: AutoModelForSeq2SeqLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForSeq2SeqLM'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1340)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence language modeling head) when
    created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [BlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration)
    (Blenderbot model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [BlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    configuration class: [EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel)
    (Encoder decoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    configuration class: [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq Machine-Translation model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    configuration class: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [LEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForConditionalGeneration)
    (LED model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [LongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration)
    (LongT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)
    configuration class: [M2M100ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration)
    (M2M100 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [MT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration)
    (MT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [MarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianMTModel)
    (Marian model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    configuration class: [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    configuration class: [PLBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForConditionalGeneration)
    (PLBart model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [PegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration)
    (Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig)
    configuration class: [PegasusXForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration)
    (PEGASUS-X model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    configuration class: [ProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration)
    (ProphetNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    configuration class: [SeamlessM4TForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForTextToText)
    (SeamlessM4T model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    configuration class: [SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText)
    (SeamlessM4Tv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    configuration class: [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    configuration class: [UMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForConditionalGeneration)
    (UMT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    configuration class: [XLMProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration)
    (XLM-ProphetNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bart** — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bigbird_pegasus** — [BigBirdPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot** — [BlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration)
    (Blenderbot model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot-small** — [BlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder-decoder** — [EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel)
    (Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fsmt** — [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq Machine-Translation model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptsan-japanese** — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**led** — [LEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForConditionalGeneration)
    (LED model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longt5** — [LongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration)
    (LongT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**m2m_100** — [M2M100ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration)
    (M2M100 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**marian** — [MarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianMTModel)
    (Marian model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [MT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mvp** — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nllb-moe** — [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus** — [PegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration)
    (Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus_x** — [PegasusXForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration)
    (PEGASUS-X model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**plbart** — [PLBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForConditionalGeneration)
    (PLBart model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**prophetnet** — [ProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration)
    (ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t** — [SeamlessM4TForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForTextToText)
    (SeamlessM4T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t_v2** — [SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText)
    (SeamlessM4Tv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**switch_transformers** — [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**umt5** — [UMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForConditionalGeneration)
    (UMT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-prophetnet** — [XLMProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration)
    (XLM-ProphetNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForSeq2SeqLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForSeq2SeqLM'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L619)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence language modeling head) when
    created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [TFBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration)
    (Blenderbot model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [TFBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    configuration class: [TFEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel)
    (Encoder decoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [TFLEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration)
    (LED model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [TFMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [TFMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration)
    (MT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [TFMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianMTModel)
    (Marian model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [TFPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration)
    (Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bart** — [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot** — [TFBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration)
    (Blenderbot model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot-small** — [TFBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder-decoder** — [TFEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel)
    (Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**led** — [TFLEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration)
    (LED model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**marian** — [TFMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianMTModel)
    (Marian model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [TFMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [TFMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus** — [TFPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration)
    (Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForSeq2SeqLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForSeq2SeqLM'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L304)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence language modeling head) when
    created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [FlaxBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration)
    (Blenderbot model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [FlaxBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    configuration class: [FlaxEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel)
    (Encoder decoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [FlaxMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianMTModel)
    (Marian model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [FlaxPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration)
    (Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bart** — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot** — [FlaxBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration)
    (Blenderbot model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blenderbot-small** — [FlaxBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder-decoder** — [FlaxEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel)
    (Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longt5** — [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**marian** — [FlaxMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianMTModel)
    (Marian model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pegasus** — [FlaxPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration)
    (Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForSequenceClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForSequenceClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1351)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence classification head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForSequenceClassification)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForSequenceClassification)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForSequenceClassification)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    configuration class: [BioGptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForSequenceClassification)
    (BioGpt model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForSequenceClassification)
    (BLOOM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [CTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification)
    (CTRL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForSequenceClassification)
    (CANINE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification)
    (Data2VecText model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForSequenceClassification)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForSequenceClassification)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForSequenceClassification)
    (ERNIE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForSequenceClassification)
    (ErnieM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [EsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForSequenceClassification)
    (ESM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForSequenceClassification)
    (FNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForSequenceClassification)
    (Falcon model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForSequenceClassification)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForSequenceClassification)
    (GPTBigCode model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [GPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForSequenceClassification)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification)
    (GPT Neo model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForSequenceClassification)
    (GPT NeoX model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForSequenceClassification)
    (I-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [LEDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForSequenceClassification)
    (LED model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)
    (LayoutLMv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    configuration class: [LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification)
    (LiLT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification)
    (LLaMA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForSequenceClassification)
    (LUKE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForSequenceClassification)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [MT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForSequenceClassification)
    (MT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    configuration class: [MarkupLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification)
    (MarkupLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForSequenceClassification)
    (MEGA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification)
    (Megatron-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    configuration class: [MistralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForSequenceClassification)
    (Mistral model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    configuration class: [MixtralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForSequenceClassification)
    (Mixtral model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForSequenceClassification)
    (MPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForSequenceClassification)
    (MRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForSequenceClassification)
    (MVP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForSequenceClassification)
    (Nezha model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification)
    (Nyströmformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [OPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForSequenceClassification)
    (OPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [OpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification)
    (OpenAI GPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    configuration class: [OpenLlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForSequenceClassification)
    (OpenLlama model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    configuration class: [PLBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForSequenceClassification)
    (PLBart model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    configuration class: [PerceiverForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification)
    (Perceiver model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    configuration class: [PersimmonForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForSequenceClassification)
    (Persimmon model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    configuration class: [PhiForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForSequenceClassification)
    (Phi model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification)
    (QDQBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    configuration class: [Qwen2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForSequenceClassification)
    (Qwen2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForSequenceClassification)
    (Reformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForSequenceClassification)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification)
    (RoCBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForSequenceClassification)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForSequenceClassification)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification)
    (SqueezeBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForSequenceClassification)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForSequenceClassification)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification)
    (Transformer-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    configuration class: [UMT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForSequenceClassification)
    (UMT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForSequenceClassification)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForSequenceClassification)
    (X-MOD model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForSequenceClassification)
    (YOSO model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a sequence classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a sequence classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [AlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForSequenceClassification)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [BartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForSequenceClassification)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForSequenceClassification)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bigbird_pegasus** — [BigBirdPegasusForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**biogpt** — [BioGptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForSequenceClassification)
    (BioGpt model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [BloomForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForSequenceClassification)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**canine** — [CanineForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForSequenceClassification)
    (CANINE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_llama** — [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification)
    (CodeLlama model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [ConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [CTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [Data2VecTextForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [DebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForSequenceClassification)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [DebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [DistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForSequenceClassification)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForSequenceClassification)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie_m** — [ErnieMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForSequenceClassification)
    (ErnieM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [EsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForSequenceClassification)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**falcon** — [FalconForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForSequenceClassification)
    (Falcon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [FlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForSequenceClassification)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [FunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForSequenceClassification)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_bigcode** — [GPTBigCodeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForSequenceClassification)
    (GPTBigCode model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neo** — [GPTNeoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification)
    (GPT Neo model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox** — [GPTNeoXForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForSequenceClassification)
    (GPT NeoX model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [GPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForSequenceClassification)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ibert** — [IBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForSequenceClassification)
    (I-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [LayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**led** — [LEDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForSequenceClassification)
    (LED model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lilt** — [LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification)
    (LiLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llama** — [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification)
    (LLaMA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [LongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**luke** — [LukeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForSequenceClassification)
    (LUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**markuplm** — [MarkupLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification)
    (MarkupLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [MBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForSequenceClassification)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [MegaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForSequenceClassification)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mistral** — [MistralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForSequenceClassification)
    (Mistral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mixtral** — [MixtralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForSequenceClassification)
    (Mixtral model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [MPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpt** — [MptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForSequenceClassification)
    (MPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mra** — [MraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForSequenceClassification)
    (MRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [MT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForSequenceClassification)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mvp** — [MvpForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForSequenceClassification)
    (MVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [NezhaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForSequenceClassification)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nystromformer** — [NystromformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification)
    (Nyströmformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**open-llama** — [OpenLlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForSequenceClassification)
    (OpenLlama model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [OpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [OPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForSequenceClassification)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceiver** — [PerceiverForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification)
    (Perceiver model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**persimmon** — [PersimmonForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForSequenceClassification)
    (Persimmon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**phi** — [PhiForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForSequenceClassification)
    (Phi model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**plbart** — [PLBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForSequenceClassification)
    (PLBart model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [QDQBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qwen2** — [Qwen2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForSequenceClassification)
    (Qwen2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**reformer** — [ReformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForSequenceClassification)
    (Reformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [RemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForSequenceClassification)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForSequenceClassification)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [RoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForSequenceClassification)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**squeezebert** — [SqueezeBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification)
    (SqueezeBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [T5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForSequenceClassification)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForSequenceClassification)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**umt5** — [UMT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForSequenceClassification)
    (UMT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForSequenceClassification)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [XLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XmodForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForSequenceClassification)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yoso** — [YosoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForSequenceClassification)
    (YOSO model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForSequenceClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForSequenceClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L628)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence classification head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForSequenceClassification)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [TFBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForSequenceClassification)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForSequenceClassification)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [TFCTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification)
    (CTRL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForSequenceClassification)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [TFEsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForSequenceClassification)
    (ESM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [TFGPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [TFOpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification)
    (OpenAI GPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TFTransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification)
    (Transformer-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a sequence classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a sequence classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [TFAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForSequenceClassification)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [TFBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForSequenceClassification)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [TFBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForSequenceClassification)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [TFCamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [TFConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ctrl** — [TFCTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification)
    (CTRL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [TFDebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [TFDebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [TFDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [TFElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForSequenceClassification)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [TFEsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForSequenceClassification)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [TFFlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [TFFunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [TFGPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [TFLayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [TFLongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [TFMobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [TFMPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openai-gpt** — [TFOpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification)
    (OpenAI GPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [TFRemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [TFRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [TFRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [TFRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tapas** — [TFTapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**transfo-xl** — [TFTransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification)
    (Transformer-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [TFXLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [TFXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [TFXLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForSequenceClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForSequenceClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L313)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence classification head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a sequence classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a sequence classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [FlaxAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [FlaxBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [FlaxBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [FlaxBigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [FlaxDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [FlaxElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [FlaxMBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [FlaxRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [FlaxRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [FlaxRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [FlaxXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForMultipleChoice
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForMultipleChoice'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1407)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a multiple choice head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMultipleChoice)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMultipleChoice)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMultipleChoice)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForMultipleChoice)
    (CANINE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMultipleChoice)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice)
    (Data2VecText model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMultipleChoice)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMultipleChoice)
    (ERNIE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForMultipleChoice)
    (ErnieM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMultipleChoice)
    (FNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMultipleChoice)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMultipleChoice)
    (I-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMultipleChoice)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMultipleChoice)
    (LUKE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMultipleChoice)
    (MEGA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice)
    (Megatron-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMultipleChoice)
    (MRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMultipleChoice)
    (Nezha model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice)
    (Nyströmformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice)
    (QDQBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMultipleChoice)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice)
    (RoCBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMultipleChoice)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMultipleChoice)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice)
    (SqueezeBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForMultipleChoice)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForMultipleChoice)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMultipleChoice)
    (X-MOD model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMultipleChoice)
    (YOSO model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a multiple choice
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a multiple choice
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [AlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMultipleChoice)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMultipleChoice)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMultipleChoice)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**canine** — [CanineForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForMultipleChoice)
    (CANINE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [ConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMultipleChoice)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [Data2VecTextForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [DebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [DistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMultipleChoice)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMultipleChoice)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie_m** — [ErnieMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForMultipleChoice)
    (ErnieM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [FlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMultipleChoice)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [FunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMultipleChoice)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ibert** — [IBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMultipleChoice)
    (I-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [LongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMultipleChoice)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**luke** — [LukeForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMultipleChoice)
    (LUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [MegaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMultipleChoice)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [MPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mra** — [MraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMultipleChoice)
    (MRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [NezhaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMultipleChoice)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nystromformer** — [NystromformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice)
    (Nyströmformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [QDQBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [RemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMultipleChoice)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMultipleChoice)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [RoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMultipleChoice)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**squeezebert** — [SqueezeBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice)
    (SqueezeBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForMultipleChoice)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaXLForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [XLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForMultipleChoice)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XmodForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMultipleChoice)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yoso** — [YosoForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMultipleChoice)
    (YOSO model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForMultipleChoice
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForMultipleChoice'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L675)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a multiple choice head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMultipleChoice)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMultipleChoice)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMultipleChoice)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a multiple choice
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a multiple choice
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [TFAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMultipleChoice)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [TFBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMultipleChoice)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [TFCamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [TFConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [TFDebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMultipleChoice)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [TFDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [TFElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [TFFlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [TFFunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [TFLongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [TFMobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [TFMPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [TFRemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [TFRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [TFRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [TFRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [TFXLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [TFXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [TFXLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForMultipleChoice
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForMultipleChoice'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L338)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a multiple choice head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a multiple choice
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a multiple choice
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [FlaxAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [FlaxBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [FlaxBigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [FlaxDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [FlaxElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [FlaxRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [FlaxRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [FlaxRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [FlaxXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForNextSentencePrediction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForNextSentencePrediction'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1414)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a next sentence prediction head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForNextSentencePrediction)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction)
    (ERNIE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForNextSentencePrediction)
    (FNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction)
    (Megatron-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction)
    (Nezha model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction)
    (QDQBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a next sentence prediction
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a next sentence prediction
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bert** — [BertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForNextSentencePrediction)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForNextSentencePrediction)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [NezhaForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [QDQBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForNextSentencePrediction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForNextSentencePrediction'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L682)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a next sentence prediction head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForNextSentencePrediction)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a next sentence prediction
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a next sentence prediction
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bert** — [TFBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForNextSentencePrediction)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [TFMobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForNextSentencePrediction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForNextSentencePrediction'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L345)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a next sentence prediction head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a next sentence prediction
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a next sentence prediction
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**bert** — [FlaxBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForTokenClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForTokenClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1400)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a token classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForTokenClassification)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForTokenClassification)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForTokenClassification)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    configuration class: [BioGptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForTokenClassification)
    (BioGpt model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForTokenClassification)
    (BLOOM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig)
    configuration class: [BrosForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosForTokenClassification)
    (BROS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForTokenClassification)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForTokenClassification)
    (CANINE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForTokenClassification)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification)
    (Data2VecText model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForTokenClassification)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForTokenClassification)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForTokenClassification)
    (ERNIE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForTokenClassification)
    (ErnieM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [EsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForTokenClassification)
    (ESM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForTokenClassification)
    (FNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForTokenClassification)
    (Falcon model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForTokenClassification)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForTokenClassification)
    (GPTBigCode model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForTokenClassification)
    (GPT Neo model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForTokenClassification)
    (GPT NeoX model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForTokenClassification)
    (I-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)
    (LayoutLMv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    configuration class: [LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification)
    (LiLT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForTokenClassification)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForTokenClassification)
    (LUKE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    configuration class: [MarkupLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification)
    (MarkupLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForTokenClassification)
    (MEGA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification)
    (Megatron-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForTokenClassification)
    (MPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForTokenClassification)
    (MRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForTokenClassification)
    (Nezha model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification)
    (Nyströmformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    configuration class: [PhiForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForTokenClassification)
    (Phi model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification)
    (QDQBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForTokenClassification)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification)
    (RoCBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForTokenClassification)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForTokenClassification)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification)
    (SqueezeBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForTokenClassification)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForTokenClassification)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForTokenClassification)
    (X-MOD model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForTokenClassification)
    (YOSO model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a token classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a token classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [AlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForTokenClassification)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForTokenClassification)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForTokenClassification)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**biogpt** — [BioGptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForTokenClassification)
    (BioGpt model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [BloomForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForTokenClassification)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bros** — [BrosForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosForTokenClassification)
    (BROS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForTokenClassification)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**canine** — [CanineForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForTokenClassification)
    (CANINE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [ConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForTokenClassification)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [Data2VecTextForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [DebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForTokenClassification)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [DebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [DistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForTokenClassification)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForTokenClassification)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie_m** — [ErnieMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForTokenClassification)
    (ErnieM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [EsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForTokenClassification)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**falcon** — [FalconForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForTokenClassification)
    (Falcon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [FlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForTokenClassification)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [FunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForTokenClassification)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt-sw3** — [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification)
    (GPT-Sw3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_bigcode** — [GPTBigCodeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForTokenClassification)
    (GPTBigCode model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neo** — [GPTNeoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForTokenClassification)
    (GPT Neo model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox** — [GPTNeoXForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForTokenClassification)
    (GPT NeoX model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ibert** — [IBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForTokenClassification)
    (I-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lilt** — [LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification)
    (LiLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [LongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForTokenClassification)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**luke** — [LukeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForTokenClassification)
    (LUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**markuplm** — [MarkupLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification)
    (MarkupLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [MegaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForTokenClassification)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [MPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpt** — [MptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForTokenClassification)
    (MPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mra** — [MraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForTokenClassification)
    (MRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [NezhaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForTokenClassification)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nystromformer** — [NystromformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification)
    (Nyströmformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**phi** — [PhiForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForTokenClassification)
    (Phi model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [QDQBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [RemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForTokenClassification)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForTokenClassification)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [RoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForTokenClassification)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**squeezebert** — [SqueezeBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification)
    (SqueezeBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForTokenClassification)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaXLForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [XLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForTokenClassification)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XmodForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForTokenClassification)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yoso** — [YosoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForTokenClassification)
    (YOSO model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForTokenClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForTokenClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L666)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a token classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForTokenClassification)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForTokenClassification)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForTokenClassification)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForTokenClassification)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForTokenClassification)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForTokenClassification)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [TFEsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForTokenClassification)
    (ESM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForTokenClassification)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForTokenClassification)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a token classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a token classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [TFAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForTokenClassification)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [TFBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForTokenClassification)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [TFCamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForTokenClassification)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [TFConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForTokenClassification)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [TFDebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForTokenClassification)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [TFDebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [TFDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [TFElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForTokenClassification)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**esm** — [TFEsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForTokenClassification)
    (ESM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [TFFlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [TFFunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForTokenClassification)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlm** — [TFLayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [TFLayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [TFLongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForTokenClassification)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [TFMobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [TFMPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [TFRemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [TFRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [TFRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [TFRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [TFXLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [TFXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [TFXLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForTokenClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForTokenClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L329)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a token classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a token classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a token classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [FlaxAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [FlaxBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [FlaxBigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [FlaxDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [FlaxElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [FlaxRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [FlaxRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [FlaxRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [FlaxXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForQuestionAnswering'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1360)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a question answering head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForQuestionAnswering)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForQuestionAnswering)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForQuestionAnswering)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForQuestionAnswering)
    (BLOOM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForQuestionAnswering)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForQuestionAnswering)
    (CANINE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering)
    (Data2VecText model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForQuestionAnswering)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForQuestionAnswering)
    (ERNIE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForQuestionAnswering)
    (ErnieM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering)
    (FNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForQuestionAnswering)
    (Falcon model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForQuestionAnswering)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [GPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForQuestionAnswering)
    (GPT Neo model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForQuestionAnswering)
    (GPT NeoX model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering)
    (I-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [LEDForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForQuestionAnswering)
    (LED model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    configuration class: [LiltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForQuestionAnswering)
    (LiLT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForQuestionAnswering)
    (LUKE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering)
    (LXMERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [MT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForQuestionAnswering)
    (MT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    configuration class: [MarkupLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering)
    (MarkupLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForQuestionAnswering)
    (MEGA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering)
    (Megatron-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForQuestionAnswering)
    (MPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForQuestionAnswering)
    (MRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForQuestionAnswering)
    (MVP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForQuestionAnswering)
    (Nezha model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering)
    (Nyströmformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [OPTForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForQuestionAnswering)
    (OPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering)
    (QDQBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering)
    (Reformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering)
    (RoCBert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    configuration class: [SplinterForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering)
    (Splinter model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering)
    (SqueezeBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForQuestionAnswering)
    (T5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    configuration class: [UMT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForQuestionAnswering)
    (UMT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForQuestionAnswering)
    (X-MOD model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering)
    (YOSO model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a question answering
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a question answering
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [AlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForQuestionAnswering)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [BartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForQuestionAnswering)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [BertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForQuestionAnswering)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [BigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bigbird_pegasus** — [BigBirdPegasusForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering)
    (BigBird-Pegasus model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bloom** — [BloomForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForQuestionAnswering)
    (BLOOM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [CamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForQuestionAnswering)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**canine** — [CanineForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForQuestionAnswering)
    (CANINE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [ConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-text** — [Data2VecTextForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering)
    (Data2VecText model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [DebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForQuestionAnswering)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [DebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [DistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [ElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie** — [ErnieForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForQuestionAnswering)
    (ERNIE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ernie_m** — [ErnieMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForQuestionAnswering)
    (ErnieM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**falcon** — [FalconForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForQuestionAnswering)
    (Falcon model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [FlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fnet** — [FNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering)
    (FNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [FunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt2** — [GPT2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForQuestionAnswering)
    (OpenAI GPT-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neo** — [GPTNeoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForQuestionAnswering)
    (GPT Neo model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gpt_neox** — [GPTNeoXForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForQuestionAnswering)
    (GPT NeoX model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [GPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ibert** — [IBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering)
    (I-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**led** — [LEDForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForQuestionAnswering)
    (LED model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lilt** — [LiltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForQuestionAnswering)
    (LiLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [LongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**luke** — [LukeForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForQuestionAnswering)
    (LUKE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lxmert** — [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering)
    (LXMERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**markuplm** — [MarkupLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering)
    (MarkupLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [MBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mega** — [MegaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForQuestionAnswering)
    (MEGA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**megatron-bert** — [MegatronBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering)
    (Megatron-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [MobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [MPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpt** — [MptForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForQuestionAnswering)
    (MPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mra** — [MraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForQuestionAnswering)
    (MRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mt5** — [MT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForQuestionAnswering)
    (MT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mvp** — [MvpForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForQuestionAnswering)
    (MVP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nezha** — [NezhaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForQuestionAnswering)
    (Nezha model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nystromformer** — [NystromformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering)
    (Nyströmformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**opt** — [OPTForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForQuestionAnswering)
    (OPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**qdqbert** — [QDQBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering)
    (QDQBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**reformer** — [ReformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering)
    (Reformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [RemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [RobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [RobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roc_bert** — [RoCBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering)
    (RoCBert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [RoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**splinter** — [SplinterForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering)
    (Splinter model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**squeezebert** — [SqueezeBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering)
    (SqueezeBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t5** — [T5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForQuestionAnswering)
    (T5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**umt5** — [UMT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForQuestionAnswering)
    (UMT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [XLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [XLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta-xl** — [XLMRobertaXLForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering)
    (XLM-RoBERTa-XL model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [XLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xmod** — [XmodForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForQuestionAnswering)
    (X-MOD model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yoso** — [YosoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering)
    (YOSO model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForQuestionAnswering'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L637)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a question answering head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering)
    (CamemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering)
    (ConvBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering)
    (DeBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple)
    (FlauBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering)
    (Funnel Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [TFGPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering)
    (GPT-J model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering)
    (Longformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering)
    (MPNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering)
    (MobileBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering)
    (RemBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple)
    (XLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple)
    (XLNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a question answering
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a question answering
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [TFAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [TFBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**camembert** — [TFCamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering)
    (CamemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convbert** — [TFConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering)
    (ConvBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta** — [TFDebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering)
    (DeBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deberta-v2** — [TFDebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering)
    (DeBERTa-v2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [TFDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [TFElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**flaubert** — [TFFlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple)
    (FlauBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**funnel** — [TFFunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering)
    (Funnel Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gptj** — [TFGPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering)
    (GPT-J model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**longformer** — [TFLongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering)
    (Longformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilebert** — [TFMobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering)
    (MobileBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mpnet** — [TFMPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering)
    (MPNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rembert** — [TFRemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering)
    (RemBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [TFRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [TFRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [TFRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm** — [TFXLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple)
    (XLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [TFXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlnet** — [TFXLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple)
    (XLNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForQuestionAnswering'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L322)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a question answering head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering)
    (ALBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering)
    (BART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering)
    (BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering)
    (BigBird model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering)
    (DistilBERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering)
    (ELECTRA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering)
    (mBART model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering)
    (RoFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering)
    (RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a question answering
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a question answering
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**albert** — [FlaxAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering)
    (ALBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bart** — [FlaxBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering)
    (BART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bert** — [FlaxBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering)
    (BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**big_bird** — [FlaxBigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering)
    (BigBird model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distilbert** — [FlaxDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering)
    (DistilBERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**electra** — [FlaxElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering)
    (ELECTRA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mbart** — [FlaxMBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering)
    (mBART model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta** — [FlaxRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering)
    (RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roberta-prelayernorm** — [FlaxRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**roformer** — [FlaxRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering)
    (RoFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xlm-roberta** — [FlaxXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForTextEncoding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForTextEncoding'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1296)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: TFAutoModelForTextEncoding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForTextEncoding'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L527)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Computer vision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following auto classes are available for the following computer vision tasks.
  prefs: []
  type: TYPE_NORMAL
- en: AutoModelForDepthEstimation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForDepthEstimation'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1489)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a depth estimation head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    configuration class: [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)
    (DPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig)
    configuration class: [GLPNForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNForDepthEstimation)
    (GLPN model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a depth estimation
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a depth estimation
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**dpt** — [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)
    (DPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**glpn** — [GLPNForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNForDepthEstimation)
    (GLPN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForImageClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForImageClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1423)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a image classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [BeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForImageClassification)
    (BEiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig)
    configuration class: [BitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitForImageClassification)
    (BiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    configuration class: [ConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextForImageClassification)
    (ConvNeXT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    configuration class: [ConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2ForImageClassification)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    configuration class: [CvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtForImageClassification)
    (CvT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [Data2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification)
    (Data2VecVision model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)
    or [DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)
    (DeiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DinatConfig](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatConfig)
    configuration class: [DinatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatForImageClassification)
    (DiNAT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dinov2Config](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Config)
    configuration class: [Dinov2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2ForImageClassification)
    (DINOv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    configuration class: [EfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassification)
    or [EfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassificationWithTeacher)
    (EfficientFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EfficientNetConfig](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetConfig)
    configuration class: [EfficientNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetForImageClassification)
    (EfficientNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)
    configuration class: [FocalNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForImageClassification)
    (FocalNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig)
    configuration class: [ImageGPTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification)
    (ImageGPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig)
    configuration class: [LevitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassification)
    or [LevitForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher)
    (LeViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config)
    configuration class: [MobileNetV1ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ForImageClassification)
    (MobileNetV1 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    configuration class: [MobileNetV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification)
    (MobileNetV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [MobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForImageClassification)
    (MobileViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    configuration class: [MobileViTV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForImageClassification)
    (MobileViTV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig)
    configuration class: [NatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatForImageClassification)
    (NAT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    configuration class: [PerceiverForImageClassificationLearned](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned)
    or [PerceiverForImageClassificationFourier](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier)
    or [PerceiverForImageClassificationConvProcessing](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing)
    (Perceiver model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)
    configuration class: [PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification)
    (PoolFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig)
    configuration class: [PvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtForImageClassification)
    (PVT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)
    (RegNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)
    (ResNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [SegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForImageClassification)
    (SegFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig)
    configuration class: [SwiftFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerForImageClassification)
    (SwiftFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [SwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForImageClassification)
    (Swin Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    configuration class: [Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)
    (Swin Transformer V2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig)
    configuration class: [VanForImageClassification](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanForImageClassification)
    (VAN model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification)
    (ViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)
    configuration class: [ViTHybridForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridForImageClassification)
    (ViT Hybrid model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)
    configuration class: [ViTMSNForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification)
    (ViTMSN model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a image classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a image classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**beit** — [BeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForImageClassification)
    (BEiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**bit** — [BitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitForImageClassification)
    (BiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnext** — [ConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextForImageClassification)
    (ConvNeXT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnextv2** — [ConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2ForImageClassification)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cvt** — [CvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtForImageClassification)
    (CvT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-vision** — [Data2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification)
    (Data2VecVision model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deit** — [DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)
    or [DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)
    (DeiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dinat** — [DinatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatForImageClassification)
    (DiNAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dinov2** — [Dinov2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2ForImageClassification)
    (DINOv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientformer** — [EfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassification)
    or [EfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassificationWithTeacher)
    (EfficientFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientnet** — [EfficientNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetForImageClassification)
    (EfficientNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**focalnet** — [FocalNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForImageClassification)
    (FocalNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**imagegpt** — [ImageGPTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification)
    (ImageGPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**levit** — [LevitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassification)
    or [LevitForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher)
    (LeViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v1** — [MobileNetV1ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ForImageClassification)
    (MobileNetV1 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v2** — [MobileNetV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification)
    (MobileNetV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevit** — [MobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForImageClassification)
    (MobileViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevitv2** — [MobileViTV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForImageClassification)
    (MobileViTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nat** — [NatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatForImageClassification)
    (NAT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceiver** — [PerceiverForImageClassificationLearned](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned)
    or [PerceiverForImageClassificationFourier](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier)
    or [PerceiverForImageClassificationConvProcessing](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing)
    (Perceiver model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**poolformer** — [PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification)
    (PoolFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pvt** — [PvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtForImageClassification)
    (PVT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**regnet** — [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)
    (RegNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resnet** — [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)
    (ResNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**segformer** — [SegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForImageClassification)
    (SegFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swiftformer** — [SwiftFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerForImageClassification)
    (SwiftFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin** — [SwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForImageClassification)
    (Swin Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swinv2** — [Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)
    (Swin Transformer V2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**van** — [VanForImageClassification](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanForImageClassification)
    (VAN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_hybrid** — [ViTHybridForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridForImageClassification)
    (ViT Hybrid model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit_msn** — [ViTMSNForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification)
    (ViTMSN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForImageClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForImageClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L578)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a image classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    configuration class: [TFConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextForImageClassification)
    (ConvNeXT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    configuration class: [TFConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2ForImageClassification)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    configuration class: [TFCvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtForImageClassification)
    (CvT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [TFData2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification)
    (Data2VecVision model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)
    or [TFDeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher)
    (DeiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    configuration class: [TFEfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassification)
    or [TFEfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassificationWithTeacher)
    (EfficientFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [TFMobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification)
    (MobileViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)
    (RegNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)
    (ResNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [TFSegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForImageClassification)
    (SegFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [TFSwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForImageClassification)
    (Swin Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [TFViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTForImageClassification)
    (ViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a image classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a image classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**convnext** — [TFConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextForImageClassification)
    (ConvNeXT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convnextv2** — [TFConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2ForImageClassification)
    (ConvNeXTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cvt** — [TFCvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtForImageClassification)
    (CvT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-vision** — [TFData2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification)
    (Data2VecVision model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deit** — [TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)
    or [TFDeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher)
    (DeiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**efficientformer** — [TFEfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassification)
    or [TFEfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassificationWithTeacher)
    (EfficientFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevit** — [TFMobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification)
    (MobileViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**regnet** — [TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)
    (RegNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resnet** — [TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)
    (ResNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**segformer** — [TFSegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForImageClassification)
    (SegFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin** — [TFSwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForImageClassification)
    (Swin Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [TFViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTForImageClassification)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForImageClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForImageClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L354)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a image classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [FlaxBeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification)
    (BEiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [FlaxRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetForImageClassification)
    (RegNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [FlaxResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetForImageClassification)
    (ResNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [FlaxViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTForImageClassification)
    (ViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a image classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a image classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**beit** — [FlaxBeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification)
    (BEiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**regnet** — [FlaxRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetForImageClassification)
    (RegNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resnet** — [FlaxResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetForImageClassification)
    (ResNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [FlaxViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTForImageClassification)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForVideoClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForVideoClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1496)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a video classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig)
    configuration class: [TimesformerForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerForVideoClassification)
    (TimeSformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    configuration class: [VideoMAEForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForVideoClassification)
    (VideoMAE model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)
    configuration class: [VivitForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitForVideoClassification)
    (ViViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a video classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a video classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**timesformer** — [TimesformerForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerForVideoClassification)
    (TimeSformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**videomae** — [VideoMAEForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForVideoClassification)
    (VideoMAE model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vivit** — [VivitForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitForVideoClassification)
    (ViViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForMaskedImageModeling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForMaskedImageModeling'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1561)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked image modeling head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)
    (DeiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)
    configuration class: [FocalNetForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForMaskedImageModeling)
    (FocalNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [SwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForMaskedImageModeling)
    (Swin Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    configuration class: [Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)
    (Swin Transformer V2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [ViTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForMaskedImageModeling)
    (ViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a masked image modeling
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a masked image modeling
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**deit** — [DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)
    (DeiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**focalnet** — [FocalNetForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForMaskedImageModeling)
    (FocalNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin** — [SwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForMaskedImageModeling)
    (Swin Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swinv2** — [Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)
    (Swin Transformer V2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vit** — [ViTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForMaskedImageModeling)
    (ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForMaskedImageModeling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForMaskedImageModeling'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L569)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked image modeling head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)
    (DeiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [TFSwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForMaskedImageModeling)
    (Swin Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a masked image modeling
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a masked image modeling
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**deit** — [TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)
    (DeiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**swin** — [TFSwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForMaskedImageModeling)
    (Swin Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForObjectDetection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForObjectDetection'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1473)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a object detection head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig)
    configuration class: [ConditionalDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection)
    (Conditional DETR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)
    configuration class: [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)
    (Deformable DETR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)
    configuration class: [DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)
    (DETA model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    configuration class: [DetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForObjectDetection)
    (DETR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)
    configuration class: [TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)
    (Table Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)
    configuration class: [YolosForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosForObjectDetection)
    (YOLOS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a object detection
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a object detection
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**conditional_detr** — [ConditionalDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection)
    (Conditional DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deformable_detr** — [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)
    (Deformable DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**deta** — [DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)
    (DETA model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**detr** — [DetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForObjectDetection)
    (DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**table-transformer** — [TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)
    (Table Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**yolos** — [YolosForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosForObjectDetection)
    (YOLOS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForImageSegmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForImageSegmentation'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1439)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a image segmentation head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    configuration class: [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)
    (DETR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a image segmentation
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a image segmentation
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**detr** — [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)
    (DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForImageToImage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForImageToImage'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1300)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: AutoModelForSemanticSegmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForSemanticSegmentation'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1446)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a semantic segmentation head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [BeitForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForSemanticSegmentation)
    (BEiT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    configuration class: [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)
    (DPT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [Data2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation)
    (Data2VecVision model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    configuration class: [MobileNetV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation)
    (MobileNetV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [MobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation)
    (MobileViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    configuration class: [MobileViTV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForSemanticSegmentation)
    (MobileViTV2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [SegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation)
    (SegFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig)
    configuration class: [UperNetForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetForSemanticSegmentation)
    (UPerNet model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a semantic segmentation
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a semantic segmentation
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**beit** — [BeitForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForSemanticSegmentation)
    (BEiT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-vision** — [Data2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation)
    (Data2VecVision model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dpt** — [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)
    (DPT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilenet_v2** — [MobileNetV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation)
    (MobileNetV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevit** — [MobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation)
    (MobileViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevitv2** — [MobileViTV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForSemanticSegmentation)
    (MobileViTV2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**segformer** — [SegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation)
    (SegFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**upernet** — [UperNetForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetForSemanticSegmentation)
    (UPerNet model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForSemanticSegmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForSemanticSegmentation'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L596)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a semantic segmentation head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [TFData2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation)
    (Data2VecVision model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [TFMobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation)
    (MobileViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [TFSegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation)
    (SegFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a semantic segmentation
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a semantic segmentation
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**data2vec-vision** — [TFData2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation)
    (Data2VecVision model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mobilevit** — [TFMobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation)
    (MobileViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**segformer** — [TFSegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation)
    (SegFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForInstanceSegmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForInstanceSegmentation'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1464)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a instance segmentation head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    configuration class: [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    (MaskFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a instance segmentation
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a instance segmentation
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**maskformer** — [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    (MaskFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForUniversalSegmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForUniversalSegmentation'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1455)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a universal image segmentation head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    configuration class: [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)
    (DETR model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)
    configuration class: [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)
    (Mask2Former model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    configuration class: [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    (MaskFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)
    configuration class: [OneFormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerForUniversalSegmentation)
    (OneFormer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a universal image
    segmentation head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a universal image
    segmentation head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**detr** — [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)
    (DETR model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mask2former** — [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)
    (Mask2Former model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**maskformer** — [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    (MaskFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**oneformer** — [OneFormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerForUniversalSegmentation)
    (OneFormer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForZeroShotImageClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForZeroShotImageClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1430)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a zero-shot image classification head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)
    configuration class: [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)
    configuration class: [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig)
    configuration class: [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig)
    configuration class: [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig)
    configuration class: [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a zero-shot image
    classification head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a zero-shot image
    classification head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**align** — [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**altclip** — [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip** — [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**chinese_clip** — [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clipseg** — [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**siglip** — [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForZeroShotImageClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForZeroShotImageClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L587)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a zero-shot image classification head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a zero-shot image
    classification head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a zero-shot image
    classification head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**blip** — [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**clip** — [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForZeroShotObjectDetection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForZeroShotObjectDetection'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1480)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a zero-shot object detection head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)
    configuration class: [OwlViTForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTForObjectDetection)
    (OWL-ViT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)
    configuration class: [Owlv2ForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ForObjectDetection)
    (OWLv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a zero-shot object
    detection head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a zero-shot object
    detection head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**owlv2** — [Owlv2ForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ForObjectDetection)
    (OWLv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**owlvit** — [OwlViTForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTForObjectDetection)
    (OWL-ViT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: Audio
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following auto classes are available for the following audio tasks.
  prefs: []
  type: TYPE_NORMAL
- en: AutoModelForAudioClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForAudioClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1510)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a audio classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)
    configuration class: [ASTForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTForAudioClassification)
    (Audio Spectrogram Transformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification)
    (Data2VecAudio model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    configuration class: [HubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForSequenceClassification)
    (Hubert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    configuration class: [SEWForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForSequenceClassification)
    (SEW model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    configuration class: [SEWDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification)
    (SEW-D model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    configuration class: [UniSpeechForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification)
    (UniSpeech model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification)
    (UniSpeechSat model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForSequenceClassification)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification)
    (WavLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)
    (Whisper model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a audio classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a audio classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**audio-spectrogram-transformer** — [ASTForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTForAudioClassification)
    (Audio Spectrogram Transformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data2vec-audio** — [Data2VecAudioForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification)
    (Data2VecAudio model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hubert** — [HubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForSequenceClassification)
    (Hubert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew** — [SEWForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForSequenceClassification)
    (SEW model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew-d** — [SEWDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification)
    (SEW-D model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech** — [UniSpeechForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification)
    (UniSpeech model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech-sat** — [UniSpeechSatForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification)
    (UniSpeechSat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-bert** — [Wav2Vec2BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForSequenceClassification)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2ConformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wavlm** — [WavLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification)
    (WavLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForAudioFrameClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForAudioClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L538)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a audio classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [TFWav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2ForSequenceClassification)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a audio classification
    head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a audio classification
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**wav2vec2** — [TFWav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2ForSequenceClassification)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForAudioFrameClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForAudioFrameClassification'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1533)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a audio frame (token) classification head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification)
    (Data2VecAudio model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification)
    (UniSpeechSat model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForAudioFrameClassification)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification)
    (WavLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a audio frame (token)
    classification head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a audio frame (token)
    classification head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**data2vec-audio** — [Data2VecAudioForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification)
    (Data2VecAudio model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech-sat** — [UniSpeechSatForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification)
    (UniSpeechSat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2ForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-bert** — [Wav2Vec2BertForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForAudioFrameClassification)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2ConformerForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wavlm** — [WavLMForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification)
    (WavLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForCTC
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForCTC'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1517)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a connectionist temporal classification head) when
    created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioForCTC](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForCTC)
    (Data2VecAudio model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    configuration class: [HubertForCTC](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForCTC)
    (Hubert model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)
    configuration class: [MCTCTForCTC](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTForCTC)
    (M-CTC-T model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    configuration class: [SEWForCTC](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForCTC)
    (SEW model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    configuration class: [SEWDForCTC](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForCTC)
    (SEW-D model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    configuration class: [UniSpeechForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForCTC)
    (UniSpeech model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC)
    (UniSpeechSat model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForCTC)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMForCTC](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForCTC)
    (WavLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a connectionist temporal
    classification head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a connectionist temporal
    classification head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**data2vec-audio** — [Data2VecAudioForCTC](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForCTC)
    (Data2VecAudio model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**hubert** — [HubertForCTC](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForCTC)
    (Hubert model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mctct** — [MCTCTForCTC](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTForCTC)
    (M-CTC-T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew** — [SEWForCTC](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForCTC)
    (SEW model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sew-d** — [SEWDForCTC](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForCTC)
    (SEW-D model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech** — [UniSpeechForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForCTC)
    (UniSpeech model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech-sat** — [UniSpeechSatForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC)
    (UniSpeechSat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2ForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-bert** — [Wav2Vec2BertForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForCTC)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2ConformerForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wavlm** — [WavLMForCTC](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForCTC)
    (WavLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForSpeechSeq2Seq
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForSpeechSeq2Seq'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1524)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence speech-to-text modeling head)
    when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig)
    configuration class: [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)
    (Pop2Piano model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    configuration class: [SeamlessM4TForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForSpeechToText)
    (SeamlessM4T model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    configuration class: [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)
    (SeamlessM4Tv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    configuration class: [Speech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration)
    (Speech2Text model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig)
    configuration class: [SpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel)
    (Speech Encoder decoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)
    configuration class: [SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText)
    (SpeechT5 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration)
    (Whisper model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**pop2piano** — [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)
    (Pop2Piano model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t** — [SeamlessM4TForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForSpeechToText)
    (SeamlessM4T model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**seamless_m4t_v2** — [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)
    (SeamlessM4Tv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech-encoder-decoder** — [SpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel)
    (Speech Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speech_to_text** — [Speech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration)
    (Speech2Text model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**speecht5** — [SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText)
    (SpeechT5 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForSpeechSeq2Seq
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForSpeechSeq2Seq'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L691)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence speech-to-text modeling head)
    when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    configuration class: [TFSpeech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration)
    (Speech2Text model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)
    (Whisper model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**speech_to_text** — [TFSpeech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration)
    (Speech2Text model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForSpeechSeq2Seq
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForSpeechSeq2Seq'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L370)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence speech-to-text modeling head)
    when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig)
    configuration class: [FlaxSpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel)
    (Speech Encoder decoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**speech-encoder-decoder** — [FlaxSpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel)
    (Speech Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**whisper** — [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForAudioXVector
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForAudioXVector'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1542)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a audio retrieval via x-vector head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioForXVector](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForXVector)
    (Data2VecAudio model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForXVector](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector)
    (UniSpeechSat model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForXVector)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector)
    (Wav2Vec2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMForXVector](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForXVector)
    (WavLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a audio retrieval
    via x-vector head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a audio retrieval
    via x-vector head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**data2vec-audio** — [Data2VecAudioForXVector](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForXVector)
    (Data2VecAudio model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unispeech-sat** — [UniSpeechSatForXVector](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector)
    (UniSpeechSat model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2** — [Wav2Vec2ForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector)
    (Wav2Vec2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-bert** — [Wav2Vec2BertForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForXVector)
    (Wav2Vec2-BERT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wav2vec2-conformer** — [Wav2Vec2ConformerForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector)
    (Wav2Vec2-Conformer model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**wavlm** — [WavLMForXVector](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForXVector)
    (WavLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForTextToSpectrogram
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForTextToSpectrogram'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1546)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: AutoModelForTextToWaveform
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForTextToWaveform'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1550)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following auto classes are available for the following multimodal tasks.
  prefs: []
  type: TYPE_NORMAL
- en: AutoModelForTableQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForTableQuestionAnswering'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1367)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a table question answering head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a table question
    answering head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a table question answering
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**tapas** — [TapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForTableQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForTableQuestionAnswering'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L655)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a table question answering head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering)
    (TAPAS model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a table question
    answering head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a table question answering
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**tapas** — [TFTapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering)
    (TAPAS model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForDocumentQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForDocumentQuestionAnswering'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1389)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a document question answering head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a document question
    answering head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a document question
    answering head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**layoutlm** — [LayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv2** — [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForDocumentQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForDocumentQuestionAnswering'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L644)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a document question answering head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering)
    (LayoutLM model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a document question
    answering head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a document question
    answering head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**layoutlm** — [TFLayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering)
    (LayoutLM model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**layoutlmv3** — [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForVisualQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForVisualQuestionAnswering'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1378)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a visual question answering head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    configuration class: [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)
    (BLIP-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig)
    configuration class: [ViltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltForQuestionAnswering)
    (ViLT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a visual question
    answering head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a visual question
    answering head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**blip-2** — [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)
    (BLIP-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vilt** — [ViltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltForQuestionAnswering)
    (ViLT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: AutoModelForVision2Seq
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.AutoModelForVision2Seq'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1503)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a vision-to-text modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    configuration class: [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)
    (BLIP-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [BlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipForConditionalGeneration)
    (BLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    configuration class: [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[InstructBlipConfig](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipConfig)
    configuration class: [InstructBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipForConditionalGeneration)
    (InstructBLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config)
    configuration class: [Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration)
    (KOSMOS-2 model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig)
    configuration class: [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pix2StructConfig](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructConfig)
    configuration class: [Pix2StructForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructForConditionalGeneration)
    (Pix2Struct model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig)
    configuration class: [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    configuration class: [VisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a vision-to-text
    modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**state_dict** (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary
    to use instead of a state dictionary loaded from saved weights file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_tf** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a vision-to-text modeling
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**blip** — [BlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipForConditionalGeneration)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**blip-2** — [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)
    (BLIP-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**git** — [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**instructblip** — [InstructBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipForConditionalGeneration)
    (InstructBLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kosmos-2** — [Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration)
    (KOSMOS-2 model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**llava** — [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pix2struct** — [Pix2StructForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructForConditionalGeneration)
    (Pix2Struct model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vipllava** — [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vision-encoder-decoder** — [VisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: TFAutoModelForVision2Seq
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.TFAutoModelForVision2Seq'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L605)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a vision-to-text modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [TFBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipForConditionalGeneration)
    (BLIP model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    configuration class: [TFVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a vision-to-text
    modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a vision-to-text modeling
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**blip** — [TFBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipForConditionalGeneration)
    (BLIP model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vision-encoder-decoder** — [TFVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: FlaxAutoModelForVision2Seq
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### class transformers.FlaxAutoModelForVision2Seq'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L363)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a vision-to-text modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  prefs: []
  type: TYPE_NORMAL
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  prefs: []
  type: TYPE_NORMAL
- en: '#### from_config'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  prefs: []
  type: TYPE_NORMAL
- en: ( **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    configuration class: [FlaxVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiates one of the model classes of the library (with a vision-to-text
    modeling head) from a configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: '#### from_pretrained'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  prefs: []
  type: TYPE_NORMAL
- en: ( *model_args **kwargs )
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**model_args** (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**config** ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in
    which a downloaded pretrained model configuration should be cached if the standard
    cache should not be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**from_pt** (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**force_download** (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**resume_download** (`bool`, *optional*, defaults to `False`) — Whether or
    not to delete incompletely received files. Will attempt to resume the download
    if such a file exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers
    to use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_loading_info(`bool`,** *optional*, defaults to `False`) — Whether
    ot not to also return a dictionary containing missing keys, unexpected keys and
    error messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**local_files_only(`bool`,** *optional*, defaults to `False`) — Whether or
    not to only look at local files (e.g., not try downloading the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**revision** (`str`, *optional*, defaults to `"main"`) — The specific model
    version to use. It can be a branch name, a tag name, or a commit id, since we
    use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**code_revision** (`str`, *optional*, defaults to `"main"`) — The specific
    revision to use for the code on the Hub, if the code leaves in a different repository
    than the rest of the model. It can be a branch name, a tag name, or a commit id,
    since we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kwargs** (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library (with a vision-to-text modeling
    head) from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**vision-encoder-decoder** — [FlaxVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
