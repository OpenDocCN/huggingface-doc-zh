- en: Auto Classes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动类
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/auto)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, the architecture you want to use can be guessed from the name
    or the path of the pretrained model you are supplying to the `from_pretrained()`
    method. AutoClasses are here to do this job for you so that you automatically
    retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，您想要使用的架构可以从您提供给`from_pretrained()`方法的预训练模型的名称或路径中猜出。AutoClasses在这里为您执行此操作，以便根据预训练权重/配置/词汇的名称/路径自动检索相关模型。
- en: Instantiating one of [AutoConfig](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig),
    [AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel),
    and [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    will directly create a class of the relevant architecture. For instance
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化[AutoConfig](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig)、[AutoModel](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoModel)和[AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)中的一个将直接创建相关架构的类。例如
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: will create a model that is an instance of [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 将创建一个[BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel)的实例模型。
- en: There is one class of `AutoModel` for each task, and for each backend (PyTorch,
    TensorFlow, or Flax).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 每个任务和每个后端（PyTorch、TensorFlow或Flax）都有一个`AutoModel`类。
- en: Extending the Auto Classes
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展自动类
- en: 'Each of the auto classes has a method to be extended with your custom classes.
    For instance, if you have defined a custom class of model `NewModel`, make sure
    you have a `NewModelConfig` then you can add those to the auto classes like this:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 每个自动类都有一个方法可以用来扩展您的自定义类。例如，如果您定义了一个名为`NewModel`的自定义模型类，请确保有一个`NewModelConfig`，然后您可以像这样将它们添加到自动类中：
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You will then be able to use the auto classes like you would usually do!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然后您就可以像通常一样使用自动类了！
- en: If your `NewModelConfig` is a subclass of [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    make sure its `model_type` attribute is set to the same key you use when registering
    the config (here `"new-model"`).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的`NewModelConfig`是[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的子类，请确保其`model_type`属性设置为注册配置时使用的相同键（这里是`"new-model"`）。
- en: Likewise, if your `NewModel` is a subclass of [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel),
    make sure its `config_class` attribute is set to the same class you use when registering
    the model (here `NewModelConfig`).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果您的`NewModel`是[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)的子类，请确保其`config_class`属性设置为注册模型时使用的相同类（这里是`NewModelConfig`）。
- en: AutoConfig
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoConfig
- en: '### `class transformers.AutoConfig`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L975)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L975)'
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This is a generic configuration class that will be instantiated as one of the
    configuration classes of the library when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig.from_pretrained)
    class method.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的配置类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoConfig.from_pretrained)类方法创建时，将实例化为库的配置类之一。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_pretrained`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L998)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L998)'
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model configuration hosted inside a
    model repo on huggingface.co. Valid model ids can be located at the root-level,
    like `bert-base-uncased`, or namespaced under a user or organization name, like
    `dbmdz/bert-base-german-cased`.
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型配置的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing a configuration file saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained)
    method, or the [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained)方法保存的配置文件，或者[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)方法，例如
    `./my_model_directory/`。
- en: A path or url to a saved configuration JSON *file*, e.g., `./my_model_directory/configuration.json`.
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个保存的配置JSON *文件*的路径或url，例如 `./my_model_directory/configuration.json`。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download the model weights and configuration files and override
    the cached versions if they exist.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，并覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求上使用。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`return_unused_kwargs` (`bool`, *optional*, defaults to `False`) — If `False`,
    then this function returns just the final configuration object.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_unused_kwargs`（`bool`，*可选*，默认为`False`）— 如果为`False`，则此函数仅返回最终配置对象。'
- en: 'If `True`, then this functions returns a `Tuple(config, unused_kwargs)` where
    *unused_kwargs* is a dictionary consisting of the key/value pairs whose keys are
    not configuration attributes: i.e., the part of `kwargs` which has not been used
    to update `config` and is otherwise ignored.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果为`True`，则此函数返回一个`Tuple(config, unused_kwargs)`，其中*unused_kwargs*是一个字典，由那些键/值对组成，其键不是配置属性：即`kwargs`的一部分，未被用于更新`config`且被忽略的部分。
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`kwargs(additional` keyword arguments, *optional*) — The values in kwargs of
    any keys which are configuration attributes will be used to override the loaded
    values. Behavior concerning key/value pairs whose keys are *not* configuration
    attributes is controlled by the `return_unused_kwargs` keyword parameter.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*）— kwargs中任何键的值，其为配置属性，将用于覆盖加载的值。关于键/值对中键不是配置属性的行为由`return_unused_kwargs`关键字参数控制。'
- en: Instantiate one of the configuration classes of the library from a pretrained
    model configuration.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型配置中实例化库的配置类之一。
- en: 'The configuration class to instantiate is selected based on the `model_type`
    property of the config object that is loaded, or when it’s missing, by falling
    back to using pattern matching on `pretrained_model_name_or_path`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化的配置类是根据加载的配置对象的`model_type`属性选择的，或者当它缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`albert` — [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    (ALBERT model)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)（ALBERT模型）'
- en: '`align` — [AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)
    (ALIGN model)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`align` — [AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)（ALIGN模型）'
- en: '`altclip` — [AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)
    (AltCLIP model)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`altclip` — [AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)（AltCLIP模型）'
- en: '`audio-spectrogram-transformer` — [ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)
    (Audio Spectrogram Transformer model)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio-spectrogram-transformer` — [ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)（音频频谱变换器模型）'
- en: '`autoformer` — [AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)
    (Autoformer model)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autoformer` — [AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)（Autoformer模型）'
- en: '`bark` — [BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)
    (Bark model)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bark` — [BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)（Bark模型）'
- en: '`bart` — [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    (BART model)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)（BART模型）'
- en: '`beit` — [BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    (BEiT model)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beit` — [BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)（BEiT模型）'
- en: '`bert` — [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    (BERT model)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)（BERT模型）'
- en: '`bert-generation` — [BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)
    (Bert Generation model)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert-generation` — [BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)（Bert生成模型）'
- en: '`big_bird` — [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    (BigBird model)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)（BigBird模型）'
- en: '`bigbird_pegasus` — [BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    (BigBird-Pegasus model)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bigbird_pegasus` — [BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)（BigBird-Pegasus模型）'
- en: '`biogpt` — [BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    (BioGpt model)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`biogpt` — [BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)（BioGpt模型）'
- en: '`bit` — [BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig)
    (BiT model)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bit` — [BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig)（BiT模型）'
- en: '`blenderbot` — [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    (Blenderbot model)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot` — [BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)（Blenderbot模型）'
- en: '`blenderbot-small` — [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    (BlenderbotSmall model)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot-small` — [BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)（BlenderbotSmall模型）'
- en: '`blip` — [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    (BLIP model)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    (BLIP 模型)'
- en: '`blip-2` — [Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    (BLIP-2 model)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip-2` — [Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    (BLIP-2 模型)'
- en: '`bloom` — [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    (BLOOM model)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    (BLOOM 模型)'
- en: '`bridgetower` — [BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)
    (BridgeTower model)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bridgetower` — [BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)
    (BridgeTower 模型)'
- en: '`bros` — [BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig)
    (BROS model)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bros` — [BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig)
    (BROS 模型)'
- en: '`camembert` — [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    (CamemBERT model)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    (CamemBERT 模型)'
- en: '`canine` — [CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    (CANINE model)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`canine` — [CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    (CANINE 模型)'
- en: '`chinese_clip` — [ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig)
    (Chinese-CLIP model)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chinese_clip` — [ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig)
    (Chinese-CLIP 模型)'
- en: '`clap` — [ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)
    (CLAP model)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clap` — [ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)
    (CLAP 模型)'
- en: '`clip` — [CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    (CLIP model)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    (CLIP 模型)'
- en: '`clip_vision_model` — [CLIPVisionConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionConfig)
    (CLIPVisionModel model)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_vision_model` — [CLIPVisionConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionConfig)
    (CLIPVisionModel 模型)'
- en: '`clipseg` — [CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig)
    (CLIPSeg model)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clipseg` — [CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig)
    (CLIPSeg 模型)'
- en: '`clvp` — [ClvpConfig](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpConfig)
    (CLVP model)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clvp` — [ClvpConfig](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpConfig)
    (CLVP 模型)'
- en: '`code_llama` — [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    (CodeLlama model)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_llama` — [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    (CodeLlama 模型)'
- en: '`codegen` — [CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig)
    (CodeGen model)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codegen` — [CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig)
    (CodeGen 模型)'
- en: '`conditional_detr` — [ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig)
    (Conditional DETR model)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conditional_detr` — [ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig)
    (Conditional DETR 模型)'
- en: '`convbert` — [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    (ConvBERT model)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    (ConvBERT 模型)'
- en: '`convnext` — [ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    (ConvNeXT model)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnext` — [ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    (ConvNeXT 模型)'
- en: '`convnextv2` — [ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    (ConvNeXTV2 model)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnextv2` — [ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    (ConvNeXTV2 模型)'
- en: '`cpmant` — [CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig)
    (CPM-Ant model)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cpmant` — [CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig)
    (CPM-Ant 模型)'
- en: '`ctrl` — [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    (CTRL model)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    (CTRL 模型)'
- en: '`cvt` — [CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    (CvT model)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cvt` — [CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    (CvT 模型)'
- en: '`data2vec-audio` — [Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    (Data2VecAudio model)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-audio` — [Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    (Data2VecAudio 模型)'
- en: '`data2vec-text` — [Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    (Data2VecText model)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    (Data2VecText 模型)'
- en: '`data2vec-vision` — [Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    (Data2VecVision model)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-vision` — [Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    (Data2VecVision 模型)'
- en: '`deberta` — [DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    (DeBERTa model)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    (DeBERTa-v2 model)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    (DeBERTa-v2 模型)'
- en: '`decision_transformer` — [DecisionTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig)
    (Decision Transformer model)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decision_transformer` — [DecisionTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig)
    (Decision Transformer 模型)'
- en: '`deformable_detr` — [DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)
    (Deformable DETR model)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deformable_detr` — [DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)
    (Deformable DETR 模型)'
- en: '`deit` — [DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    (DeiT model)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deit` — [DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    (DeiT 模型)'
- en: '`deta` — [DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)
    (DETA model)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deta` — [DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)
    (DETA 模型)'
- en: '`detr` — [DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    (DETR model)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detr` — [DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    (DETR 模型)'
- en: '`dinat` — [DinatConfig](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatConfig)
    (DiNAT model)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dinat` — [DinatConfig](/docs/transformers/v4.37.2/zh/model_doc/dinat#transformers.DinatConfig)
    (DiNAT 模型)'
- en: '`dinov2` — [Dinov2Config](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Config)
    (DINOv2 model)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dinov2` — [Dinov2Config](/docs/transformers/v4.37.2/zh/model_doc/dinov2#transformers.Dinov2Config)
    (DINOv2 模型)'
- en: '`distilbert` — [DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    (DistilBERT model)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig)
    (DistilBERT 模型)'
- en: '`donut-swin` — [DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig)
    (DonutSwin model)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`donut-swin` — [DonutSwinConfig](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutSwinConfig)
    (DonutSwin 模型)'
- en: '`dpr` — [DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig)
    (DPR model)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpr` — [DPRConfig](/docs/transformers/v4.37.2/zh/model_doc/dpr#transformers.DPRConfig)
    (DPR 模型)'
- en: '`dpt` — [DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    (DPT model)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpt` — [DPTConfig](/docs/transformers/v4.37.2/zh/model_doc/dpt#transformers.DPTConfig)
    (DPT 模型)'
- en: '`efficientformer` — [EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    (EfficientFormer model)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientformer` — [EfficientFormerConfig](/docs/transformers/v4.37.2/zh/model_doc/efficientformer#transformers.EfficientFormerConfig)
    (EfficientFormer 模型)'
- en: '`efficientnet` — [EfficientNetConfig](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetConfig)
    (EfficientNet model)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientnet` — [EfficientNetConfig](/docs/transformers/v4.37.2/zh/model_doc/efficientnet#transformers.EfficientNetConfig)
    (EfficientNet 模型)'
- en: '`electra` — [ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    (ELECTRA model)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraConfig](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraConfig)
    (ELECTRA 模型)'
- en: '`encodec` — [EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig)
    (EnCodec model)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encodec` — [EncodecConfig](/docs/transformers/v4.37.2/zh/model_doc/encodec#transformers.EncodecConfig)
    (EnCodec 模型)'
- en: '`encoder-decoder` — [EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    (Encoder decoder model)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder-decoder` — [EncoderDecoderConfig](/docs/transformers/v4.37.2/zh/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    (编码器解码器模型)'
- en: '`ernie` — [ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    (ERNIE model)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [ErnieConfig](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieConfig)
    (ERNIE 模型)'
- en: '`ernie_m` — [ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    (ErnieM model)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie_m` — [ErnieMConfig](/docs/transformers/v4.37.2/zh/model_doc/ernie_m#transformers.ErnieMConfig)
    (ErnieM 模型)'
- en: '`esm` — [EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    (ESM model)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [EsmConfig](/docs/transformers/v4.37.2/zh/model_doc/esm#transformers.EsmConfig)
    (ESM 模型)'
- en: '`falcon` — [FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    (Falcon model)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`falcon` — [FalconConfig](/docs/transformers/v4.37.2/zh/model_doc/falcon#transformers.FalconConfig)
    (Falcon 模型)'
- en: '`fastspeech2_conformer` — [FastSpeech2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerConfig)
    (FastSpeech2Conformer model)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fastspeech2_conformer` — [FastSpeech2ConformerConfig](/docs/transformers/v4.37.2/zh/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerConfig)
    (FastSpeech2Conformer 模型)'
- en: '`flaubert` — [FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    (FlauBERT model)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [FlaubertConfig](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.FlaubertConfig)
    (FlauBERT 模型)'
- en: '`flava` — [FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    (FLAVA model)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flava` — [FlavaConfig](/docs/transformers/v4.37.2/zh/model_doc/flava#transformers.FlavaConfig)
    (FLAVA 模型)'
- en: '`fnet` — [FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    (FNet model)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` — [FNetConfig](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetConfig)
    (FNet 模型)'
- en: '`focalnet` — [FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)
    (FocalNet model)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`focalnet` — [FocalNetConfig](/docs/transformers/v4.37.2/zh/model_doc/focalnet#transformers.FocalNetConfig)
    (FocalNet 模型)'
- en: '`fsmt` — [FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    (FairSeq Machine-Translation model)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fsmt` — [FSMTConfig](/docs/transformers/v4.37.2/zh/model_doc/fsmt#transformers.FSMTConfig)
    (FairSeq 机器翻译模型)'
- en: '`funnel` — [FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    (Funnel Transformer model)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [FunnelConfig](/docs/transformers/v4.37.2/zh/model_doc/funnel#transformers.FunnelConfig)
    (Funnel Transformer 模型)'
- en: '`fuyu` — [FuyuConfig](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuConfig)
    (Fuyu model)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fuyu` — [FuyuConfig](/docs/transformers/v4.37.2/zh/model_doc/fuyu#transformers.FuyuConfig)
    (Fuyu 模型)'
- en: '`git` — [GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    (GIT model)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` — [GitConfig](/docs/transformers/v4.37.2/zh/model_doc/git#transformers.GitConfig)
    (GIT 模型)'
- en: '`glpn` — [GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig)
    (GLPN model)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glpn` — [GLPNConfig](/docs/transformers/v4.37.2/zh/model_doc/glpn#transformers.GLPNConfig)
    (GLPN 模型)'
- en: '`gpt-sw3` — [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    (GPT-Sw3 model)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [GPT2Config](/docs/transformers/v4.37.2/zh/model_doc/gpt2#transformers.GPT2Config)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    (OpenAI GPT-2 model)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [GPT2Config](/docs/transformers/v4.37.2/zh/model_doc/gpt2#transformers.GPT2Config)
    (OpenAI GPT-2 模型)'
- en: '`gpt_bigcode` — [GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    (GPTBigCode model)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_bigcode` — [GPTBigCodeConfig](/docs/transformers/v4.37.2/zh/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    (GPTBigCode 模型)'
- en: '`gpt_neo` — [GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    (GPT Neo model)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neo` — [GPTNeoConfig](/docs/transformers/v4.37.2/zh/model_doc/gpt_neo#transformers.GPTNeoConfig)
    (GPT Neo 模型)'
- en: '`gpt_neox` — [GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    (GPT NeoX model)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox` — [GPTNeoXConfig](/docs/transformers/v4.37.2/zh/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    (GPT NeoX 模型)'
- en: '`gpt_neox_japanese` — [GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig)
    (GPT NeoX Japanese model)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox_japanese` — [GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/zh/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig)
    (GPT NeoX 日语模型)'
- en: '`gptj` — [GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    (GPT-J model)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [GPTJConfig](/docs/transformers/v4.37.2/zh/model_doc/gptj#transformers.GPTJConfig)
    (GPT-J 模型)'
- en: '`gptsan-japanese` — [GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    (GPTSAN-japanese model)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptsan-japanese` — [GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)（GPTSAN-japanese
    模型）'
- en: '`graphormer` — [GraphormerConfig](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerConfig)
    (Graphormer model)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`graphormer` — [GraphormerConfig](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerConfig)（Graphormer
    模型）'
- en: '`groupvit` — [GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)
    (GroupViT model)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupvit` — [GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)（GroupViT
    模型）'
- en: '`hubert` — [HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    (Hubert model)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hubert` — [HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)（Hubert
    模型）'
- en: '`ibert` — [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    (I-BERT model)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ibert` — [IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)（I-BERT
    模型）'
- en: '`idefics` — [IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)
    (IDEFICS model)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`idefics` — [IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)（IDEFICS
    模型）'
- en: '`imagegpt` — [ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig)
    (ImageGPT model)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imagegpt` — [ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig)（ImageGPT
    模型）'
- en: '`informer` — [InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig)
    (Informer model)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`informer` — [InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig)（Informer
    模型）'
- en: '`instructblip` — [InstructBlipConfig](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipConfig)
    (InstructBLIP model)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instructblip` — [InstructBlipConfig](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipConfig)（InstructBLIP
    模型）'
- en: '`jukebox` — [JukeboxConfig](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxConfig)
    (Jukebox model)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jukebox` — [JukeboxConfig](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxConfig)（Jukebox
    模型）'
- en: '`kosmos-2` — [Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config)
    (KOSMOS-2 model)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kosmos-2` — [Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config)（KOSMOS-2
    模型）'
- en: '`layoutlm` — [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    (LayoutLM model)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)（LayoutLM
    模型）'
- en: '`layoutlmv2` — [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    (LayoutLMv2 model)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)（LayoutLMv2
    模型）'
- en: '`layoutlmv3` — [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    (LayoutLMv3 model)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)（LayoutLMv3
    模型）'
- en: '`led` — [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    (LED model)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`led` — [LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)（LED
    模型）'
- en: '`levit` — [LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig)
    (LeViT model)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`levit` — [LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig)（LeViT
    模型）'
- en: '`lilt` — [LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    (LiLT model)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lilt` — [LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)（LiLT
    模型）'
- en: '`llama` — [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    (LLaMA model)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llama` — [LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)（LLaMA
    模型）'
- en: '`llava` — [LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig)
    (LLaVa model)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llava` — [LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig)（LLaVa
    模型）'
- en: '`longformer` — [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    (Longformer model)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)（Longformer
    模型）'
- en: '`longt5` — [LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    (LongT5 model)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longt5` — [LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)（LongT5
    模型）'
- en: '`luke` — [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    (LUKE model)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`luke` — [LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)（LUKE
    模型）'
- en: '`lxmert` — [LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    (LXMERT model)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lxmert` — [LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)（LXMERT
    模型）'
- en: '`m2m_100` — [M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)
    (M2M100 model)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`m2m_100` — [M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)（M2M100
    模型）'
- en: '`marian` — [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    (Marian model)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marian` — [MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)（Marian
    模型）'
- en: '`markuplm` — [MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    (MarkupLM model)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`markuplm` — [MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)（MarkupLM
    模型）'
- en: '`mask2former` — [Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)
    (Mask2Former model)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask2former` — [Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)（Mask2Former
    模型）'
- en: '`maskformer` — [MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    (MaskFormer model)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maskformer` — [MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)（MaskFormer
    模型）'
- en: '`maskformer-swin` — `MaskFormerSwinConfig` (MaskFormerSwin model)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maskformer-swin` — `MaskFormerSwinConfig`（MaskFormerSwin 模型）'
- en: '`mbart` — [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    (mBART model)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)（mBART
    模型）'
- en: '`mctct` — [MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)
    (M-CTC-T model)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mctct` — [MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)（M-CTC-T
    模型）'
- en: '`mega` — [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    (MEGA model)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)（MEGA
    模型）'
- en: '`megatron-bert` — [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    (Megatron-BERT model)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)（Megatron-BERT
    模型）'
- en: '`mgp-str` — [MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig)
    (MGP-STR model)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mgp-str` — [MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig)
    (MGP-STR 模型)'
- en: '`mistral` — [MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    (Mistral model)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mistral` — [MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    (Mistral 模型)'
- en: '`mixtral` — [MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    (Mixtral model)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mixtral` — [MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    (Mixtral 模型)'
- en: '`mobilebert` — [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    (MobileBERT model)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    (MobileBERT 模型)'
- en: '`mobilenet_v1` — [MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config)
    (MobileNetV1 model)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v1` — [MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config)
    (MobileNetV1 模型)'
- en: '`mobilenet_v2` — [MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    (MobileNetV2 model)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v2` — [MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    (MobileNetV2 模型)'
- en: '`mobilevit` — [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    (MobileViT model)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevit` — [MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    (MobileViT 模型)'
- en: '`mobilevitv2` — [MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    (MobileViTV2 model)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevitv2` — [MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    (MobileViTV2 模型)'
- en: '`mpnet` — [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    (MPNet model)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    (MPNet 模型)'
- en: '`mpt` — [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    (MPT model)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpt` — [MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    (MPT 模型)'
- en: '`mra` — [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    (MRA model)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mra` — [MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    (MRA 模型)'
- en: '`mt5` — [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    (MT5 model)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    (MT5 模型)'
- en: '`musicgen` — [MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)
    (MusicGen model)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`musicgen` — [MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)
    (MusicGen 模型)'
- en: '`mvp` — [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    (MVP model)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mvp` — [MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    (MVP 模型)'
- en: '`nat` — [NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig)
    (NAT model)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nat` — [NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig)
    (NAT 模型)'
- en: '`nezha` — [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    (Nezha model)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` — [NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    (Nezha 模型)'
- en: '`nllb-moe` — [NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    (NLLB-MOE model)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nllb-moe` — [NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    (NLLB-MOE 模型)'
- en: '`nougat` — [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    (Nougat model)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nougat` — [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    (Nougat 模型)'
- en: '`nystromformer` — [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    (Nyströmformer model)'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nystromformer` — [NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    (Nyströmformer 模型)'
- en: '`oneformer` — [OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)
    (OneFormer model)'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oneformer` — [OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)
    (OneFormer 模型)'
- en: '`open-llama` — [OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    (OpenLlama model)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`open-llama` — [OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    (OpenLlama 模型)'
- en: '`openai-gpt` — [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    (OpenAI GPT model)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    (OpenAI GPT 模型)'
- en: '`opt` — [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    (OPT model)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    (OPT 模型)'
- en: '`owlv2` — [Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)
    (OWLv2 model)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlv2` — [Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)
    (OWLv2 模型)'
- en: '`owlvit` — [OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)
    (OWL-ViT model)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlvit` — [OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)
    (OWL-ViT 模型)'
- en: '`patchtsmixer` — [PatchTSMixerConfig](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerConfig)
    (PatchTSMixer model)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patchtsmixer` — [PatchTSMixerConfig](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerConfig)
    (PatchTSMixer 模型)'
- en: '`patchtst` — [PatchTSTConfig](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTConfig)
    (PatchTST model)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patchtst` — [PatchTSTConfig](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTConfig)
    (PatchTST 模型)'
- en: '`pegasus` — [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    (Pegasus model)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus` — [PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    (Pegasus 模型)'
- en: '`pegasus_x` — [PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig)
    (PEGASUS-X model)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus_x` — [PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig)
    (PEGASUS-X 模型)'
- en: '`perceiver` — [PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    (Perceiver model)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perceiver` — [PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    (Perceiver 模型)'
- en: '`persimmon` — [PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    (Persimmon model)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`persimmon` — [PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    (Persimmon 模型)'
- en: '`phi` — [PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    (Phi model)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`phi` — [PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    (Phi 模型)'
- en: '`pix2struct` — [Pix2StructConfig](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructConfig)
    (Pix2Struct model)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pix2struct` — [Pix2StructConfig](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructConfig)
    (Pix2Struct 模型)'
- en: '`plbart` — [PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    (PLBart model)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plbart` — [PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    (PLBart 模型)'
- en: '`poolformer` — [PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)
    (PoolFormer model)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`poolformer` — [PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)
    (PoolFormer 模型)'
- en: '`pop2piano` — [Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig)
    (Pop2Piano model)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pop2piano` — [Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig)
    (Pop2Piano 模型)'
- en: '`prophetnet` — [ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    (ProphetNet model)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prophetnet` — [ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    (ProphetNet 模型)'
- en: '`pvt` — [PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig)
    (PVT model)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pvt` — [PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig)
    (PVT 模型)'
- en: '`qdqbert` — [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    (QDQBert model)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` — [QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    (QDQBert 模型)'
- en: '`qwen2` — [Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    (Qwen2 model)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qwen2` — [Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    (Qwen2 模型)'
- en: '`rag` — [RagConfig](/docs/transformers/v4.37.2/en/model_doc/rag#transformers.RagConfig)
    (RAG model)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rag` — [RagConfig](/docs/transformers/v4.37.2/en/model_doc/rag#transformers.RagConfig)
    (RAG 模型)'
- en: '`realm` — [RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig)
    (REALM model)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`realm` — [RealmConfig](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmConfig)
    (REALM 模型)'
- en: '`reformer` — [ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    (Reformer model)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reformer` — [ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    (Reformer 模型)'
- en: '`regnet` — [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    (RegNet model)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regnet` — [RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    (RegNet 模型)'
- en: '`rembert` — [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    (RemBERT model)'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    (RemBERT 模型)'
- en: '`resnet` — [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    (ResNet model)'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resnet` — [ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    (ResNet 模型)'
- en: '`retribert` — [RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig)
    (RetriBERT model)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`retribert` — [RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig)
    (RetriBERT 模型)'
- en: '`roberta` — [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    (RoBERTa model)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roc_bert` — [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    (RoCBert model)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    (RoCBert 模型)'
- en: '`roformer` — [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    (RoFormer model)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    (RoFormer 模型)'
- en: '`rwkv` — [RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    (RWKV model)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rwkv` — [RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    (RWKV 模型)'
- en: '`sam` — [SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig)
    (SAM model)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sam` — [SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig)
    (SAM 模型)'
- en: '`seamless_m4t` — [SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    (SeamlessM4T model)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t` — [SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    (SeamlessM4T 模型)'
- en: '`seamless_m4t_v2` — [SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    (SeamlessM4Tv2 model)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t_v2` — [SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    (SeamlessM4Tv2 模型)'
- en: '`segformer` — [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    (SegFormer model)'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segformer` — [SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    (SegFormer 模型)'
- en: '`sew` — [SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    (SEW model)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew` — [SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    (SEW 模型)'
- en: '`sew-d` — [SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    (SEW-D model)'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew-d` — [SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    (SEW-D 模型)'
- en: '`siglip` — [SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig)
    (SigLIP model)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`siglip` — [SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig)
    (SigLIP 模型)'
- en: '`siglip_vision_model` — [SiglipVisionConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionConfig)
    (SiglipVisionModel model)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`siglip_vision_model` — [SiglipVisionConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionConfig)
    (SiglipVisionModel 模型)'
- en: '`speech-encoder-decoder` — [SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig)
    (Speech Encoder decoder model)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech-encoder-decoder` — [SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig)
    (Speech 编码器解码器模型)'
- en: '`speech_to_text` — [Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    (Speech2Text model)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text` — [Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    (Speech2Text 模型)'
- en: '`speech_to_text_2` — [Speech2Text2Config](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config)
    (Speech2Text2 model)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text_2` — [Speech2Text2Config](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config)
    (Speech2Text2 模型)'
- en: '`speecht5` — [SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)
    (SpeechT5 model)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speecht5` — [SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)
    (SpeechT5 模型)'
- en: '`splinter` — [SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    (Splinter model)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`splinter` — [SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    (Splinter 模型)'
- en: '`squeezebert` — [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    (SqueezeBERT model)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`squeezebert` — [SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    (SqueezeBERT 模型)'
- en: '`swiftformer` — [SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig)
    (SwiftFormer model)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swiftformer` — [SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig)
    (SwiftFormer 模型)'
- en: '`swin` — [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    (Swin Transformer model)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin` — [SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    (Swin Transformer 模型)'
- en: '`swin2sr` — [Swin2SRConfig](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRConfig)
    (Swin2SR model)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin2sr` — [Swin2SRConfig](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRConfig)
    (Swin2SR 模型)'
- en: '`swinv2` — [Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    (Swin Transformer V2 model)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swinv2` — [Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    (Swin Transformer V2 模型)'
- en: '`switch_transformers` — [SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    (SwitchTransformers model)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`switch_transformers` — [SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    (SwitchTransformers 模型)'
- en: '`t5` — [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    (T5 model)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    (T5 模型)'
- en: '`table-transformer` — [TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)
    (Table Transformer model)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table-transformer` — [TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)
    (Table Transformer 模型)'
- en: '`tapas` — [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    (TAPAS model)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    (TAPAS 模型)'
- en: '`time_series_transformer` — [TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig)
    (Time Series Transformer model)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_series_transformer` — [TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig)
    (Time Series Transformer 模型)'
- en: '`timesformer` — [TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig)
    (TimeSformer model)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesformer` — [TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig)
    (TimeSformer 模型)'
- en: '`timm_backbone` — `TimmBackboneConfig` (TimmBackbone model)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timm_backbone` — `TimmBackboneConfig` (TimmBackbone 模型)'
- en: '`trajectory_transformer` — [TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig)
    (Trajectory Transformer model)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trajectory_transformer` — [TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig)
    (Trajectory Transformer 模型)'
- en: '`transfo-xl` — [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    (Transformer-XL model)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    (Transformer-XL 模型)'
- en: '`trocr` — [TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig)
    (TrOCR model)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trocr` — [TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig)
    (TrOCR 模型)'
- en: '`tvlt` — [TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig)
    (TVLT model)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvlt` — [TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig)
    (TVLT 模型)'
- en: '`tvp` — [TvpConfig](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpConfig)
    (TVP model)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvp` — [TvpConfig](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpConfig)
    (TVP 模型)'
- en: '`umt5` — [UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    (UMT5 model)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`umt5` — [UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    (UMT5 模型)'
- en: '`unispeech` — [UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    (UniSpeech model)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech` — [UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    (UniSpeech 模型)'
- en: '`unispeech-sat` — [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    (UniSpeechSat model)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech-sat` — [UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    (UniSpeechSat 模型)'
- en: '`univnet` — [UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig)
    (UnivNet model)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`univnet` — [UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig)
    (UnivNet 模型)'
- en: '`upernet` — [UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig)
    (UPerNet model)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upernet` — [UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig)
    (UPerNet 模型)'
- en: '`van` — [VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig)
    (VAN model)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`van` — [VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig)
    (VAN 模型)'
- en: '`videomae` — [VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    (VideoMAE model)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`videomae` — [VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    (VideoMAE 模型)'
- en: '`vilt` — [ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig)
    (ViLT model)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vilt` — [ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig)
    (ViLT 模型)'
- en: '`vipllava` — [VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig)
    (VipLlava model)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vipllava` — [VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig)
    (VipLlava 模型)'
- en: '`vision-encoder-decoder` — [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    (Vision Encoder decoder model)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision-encoder-decoder` — [VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    (Vision Encoder decoder 模型)'
- en: '`vision-text-dual-encoder` — [VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    (VisionTextDualEncoder model)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision-text-dual-encoder` — [VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    (VisionTextDualEncoder 模型)'
- en: '`visual_bert` — [VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)
    (VisualBERT model)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_bert` — [VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)（VisualBERT模型）'
- en: '`vit` — [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    (ViT model)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)（ViT模型）'
- en: '`vit_hybrid` — [ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)
    (ViT Hybrid model)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_hybrid` — [ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)（ViT混合模型）'
- en: '`vit_mae` — [ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    (ViTMAE model)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_mae` — [ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)（ViTMAE模型）'
- en: '`vit_msn` — [ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)
    (ViTMSN model)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_msn` — [ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)（ViTMSN模型）'
- en: '`vitdet` — [VitDetConfig](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetConfig)
    (VitDet model)'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vitdet` — [VitDetConfig](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetConfig)（VitDet模型）'
- en: '`vitmatte` — [VitMatteConfig](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteConfig)
    (ViTMatte model)'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vitmatte` — [VitMatteConfig](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteConfig)（ViTMatte模型）'
- en: '`vits` — [VitsConfig](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsConfig)
    (VITS model)'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vits` — [VitsConfig](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsConfig)（VITS模型）'
- en: '`vivit` — [VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)
    (ViViT model)'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vivit` — [VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)（ViViT模型）'
- en: '`wav2vec2` — [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    (Wav2Vec2 model)'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)（Wav2Vec2模型）'
- en: '`wav2vec2-bert` — [Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    (Wav2Vec2-BERT model)'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-bert` — [Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)（Wav2Vec2-BERT模型）'
- en: '`wav2vec2-conformer` — [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    (Wav2Vec2-Conformer model)'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)（Wav2Vec2-Conformer模型）'
- en: '`wavlm` — [WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    (WavLM model)'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wavlm` — [WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)（WavLM模型）'
- en: '`whisper` — [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    (Whisper model)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)（Whisper模型）'
- en: '`xclip` — [XCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPConfig)
    (X-CLIP model)'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xclip` — [XCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPConfig)（X-CLIP模型）'
- en: '`xglm` — [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    (XGLM model)'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xglm` — [XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)（XGLM模型）'
- en: '`xlm` — [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    (XLM model)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)（XLM模型）'
- en: '`xlm-prophetnet` — [XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    (XLM-ProphetNet model)'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-prophetnet` — [XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)（XLM-ProphetNet模型）'
- en: '`xlm-roberta` — [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    (XLM-RoBERTa model)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)（XLM-RoBERTa模型）'
- en: '`xlm-roberta-xl` — [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    (XLM-RoBERTa-XL model)'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)（XLM-RoBERTa-XL模型）'
- en: '`xlnet` — [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    (XLNet model)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)（XLNet模型）'
- en: '`xmod` — [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    (X-MOD model)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)（X-MOD模型）'
- en: '`yolos` — [YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)
    (YOLOS model)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yolos` — [YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)（YOLOS模型）'
- en: '`yoso` — [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    (YOSO model)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yoso` — [YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)（YOSO模型）'
- en: 'Examples:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `register`'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L1138)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/configuration_auto.py#L1138)'
- en: '[PRE5]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model_type` (`str`) — The model type like “bert” or “gpt”.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_type`（`str`）— 模型类型，如“bert”或“gpt”。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The config to register.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    要注册的配置。'
- en: Register a new configuration for this class.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 为这个类注册一个新的配置。
- en: AutoTokenizer
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoTokenizer
- en: '### `class transformers.AutoTokenizer`'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoTokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L616)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L616)'
- en: '[PRE6]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is a generic tokenizer class that will be instantiated as one of the tokenizer
    classes of the library when created with the [AutoTokenizer.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained)
    class method.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的分词器类，当使用[AutoTokenizer.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained)类方法创建时，将实例化为库中的分词器类之一。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会报错）。
- en: '#### `from_pretrained`'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L630)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L630)'
- en: '[PRE7]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：'
- en: A string, the *model id* of a predefined tokenizer hosted inside a model repo
    on huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预定义的分词器的*模型ID*，托管在huggingface.co上的模型存储库内。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing vocabulary files required by the tokenizer,
    for instance saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含分词器所需的词汇文件的*目录*路径，例如使用[save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)方法保存的，例如，`./my_model_directory/`。
- en: 'A path or url to a single saved vocabulary file if and only if the tokenizer
    only requires a single vocabulary file (like Bert or XLNet), e.g.: `./my_model_directory/vocab.txt`.
    (Not applicable to all derived classes)'
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果且仅当分词器只需要单个词汇文件（如Bert或XLNet）时，可以是单个保存的词汇文件的路径或url，例如：`./my_model_directory/vocab.txt`。（不适用于所有派生类）
- en: '`inputs` (additional positional arguments, *optional*) — Will be passed along
    to the Tokenizer `__init__()` method.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs`（额外的位置参数，*可选*）- 将传递给分词器`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — The configuration object used to determine the tokenizer class to
    instantiate.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）-
    用于确定要实例化的分词器类的配置对象。'
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）- 如果不应使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download the model weights and configuration files and override
    the cached versions if they exist.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）- 是否强制（重新）下载模型权重和配置文件，并覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）- 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）- 要按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`subfolder` (`str`, *optional*) — In case the relevant files are located inside
    a subfolder of the model repo on huggingface.co (e.g. for facebook/rag-token-base),
    specify it here.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subfolder`（`str`，*可选*）- 如果相关文件位于huggingface.co上模型存储库的子文件夹中（例如对于facebook/rag-token-base），请在此处指定。'
- en: '`use_fast` (`bool`, *optional*, defaults to `True`) — Use a [fast Rust-based
    tokenizer](https://huggingface.co/docs/tokenizers/index) if it is supported for
    a given model. If a fast tokenizer is not available for a given model, a normal
    Python-based tokenizer is returned instead.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_fast`（`bool`，*可选*，默认为`True`）- 如果给定模型支持，使用[快速基于Rust的分词器](https://huggingface.co/docs/tokenizers/index)。如果给定模型不支持快速分词器，则将返回普通的基于Python的分词器。'
- en: '`tokenizer_type` (`str`, *optional*) — Tokenizer type to be loaded.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer_type`（`str`，*可选*）- 要加载的分词器类型。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地计算机上执行Hub上存在的代码。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    Tokenizer `__init__()` method. Can be used to set special tokens like `bos_token`,
    `eos_token`, `unk_token`, `sep_token`, `pad_token`, `cls_token`, `mask_token`,
    `additional_special_tokens`. See parameters in the `__init__()` for more details.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）- 将传递给分词器`__init__()`方法。可用于设置特殊标记，如`bos_token`、`eos_token`、`unk_token`、`sep_token`、`pad_token`、`cls_token`、`mask_token`、`additional_special_tokens`。有关更多详细信息，请参阅`__init__()`中的参数。'
- en: Instantiate one of the tokenizer classes of the library from a pretrained model
    vocabulary.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型词汇实例化库中的一个分词器类。
- en: 'The tokenizer class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的分词器类是根据配置对象的`model_type`属性（如果可能作为参数传递或从`pretrained_model_name_or_path`加载）选择的，或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退选择：
- en: '`albert` — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)
    or [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)
    (ALBERT model)'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)
    或 [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)
    (ALBERT 模型)'
- en: '`align` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (ALIGN model)'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`align` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (ALIGN 模型)'
- en: '`bark` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Bark model)'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bark` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Bark 模型)'
- en: '`bart` — [BartTokenizer](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartTokenizer)
    or [BartTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartTokenizerFast)
    (BART model)'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [BartTokenizer](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartTokenizer)
    或 [BartTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartTokenizerFast)
    (BART 模型)'
- en: '`barthez` — [BarthezTokenizer](/docs/transformers/v4.37.2/en/model_doc/barthez#transformers.BarthezTokenizer)
    or [BarthezTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/barthez#transformers.BarthezTokenizerFast)
    (BARThez model)'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`barthez` — [BarthezTokenizer](/docs/transformers/v4.37.2/en/model_doc/barthez#transformers.BarthezTokenizer)
    或 [BarthezTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/barthez#transformers.BarthezTokenizerFast)
    (BARThez 模型)'
- en: '`bartpho` — [BartphoTokenizer](/docs/transformers/v4.37.2/en/model_doc/bartpho#transformers.BartphoTokenizer)
    (BARTpho model)'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bartpho` — [BartphoTokenizer](/docs/transformers/v4.37.2/en/model_doc/bartpho#transformers.BartphoTokenizer)
    (BARTpho 模型)'
- en: '`bert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (BERT model)'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (BERT 模型)'
- en: '`bert-generation` — [BertGenerationTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationTokenizer)
    (Bert Generation model)'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert-generation` — [BertGenerationTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationTokenizer)
    (Bert Generation 模型)'
- en: '`bert-japanese` — [BertJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer)
    (BertJapanese model)'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert-japanese` — [BertJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer)
    (BertJapanese 模型)'
- en: '`bertweet` — [BertweetTokenizer](/docs/transformers/v4.37.2/en/model_doc/bertweet#transformers.BertweetTokenizer)
    (BERTweet model)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bertweet` — [BertweetTokenizer](/docs/transformers/v4.37.2/en/model_doc/bertweet#transformers.BertweetTokenizer)
    (BERTweet 模型)'
- en: '`big_bird` — [BigBirdTokenizer](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdTokenizer)
    or [BigBirdTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdTokenizerFast)
    (BigBird model)'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdTokenizer](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdTokenizer)
    或 [BigBirdTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdTokenizerFast)
    (BigBird 模型)'
- en: '`bigbird_pegasus` — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer)
    or [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)
    (BigBird-Pegasus model)'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bigbird_pegasus` — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer)
    或 [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)
    (BigBird-Pegasus 模型)'
- en: '`biogpt` — [BioGptTokenizer](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptTokenizer)
    (BioGpt model)'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`biogpt` — [BioGptTokenizer](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptTokenizer)
    (BioGpt 模型)'
- en: '`blenderbot` — [BlenderbotTokenizer](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizer)
    or [BlenderbotTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast)
    (Blenderbot model)'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot` — [BlenderbotTokenizer](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizer)
    或 [BlenderbotTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast)
    (Blenderbot 模型)'
- en: '`blenderbot-small` — [BlenderbotSmallTokenizer](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer)
    (BlenderbotSmall model)'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot-small` — [BlenderbotSmallTokenizer](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer)
    (BlenderbotSmall 模型)'
- en: '`blip` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (BLIP model)'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (BLIP 模型)'
- en: '`blip-2` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (BLIP-2 model)'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip-2` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (BLIP-2 模型)'
- en: '`bloom` — [BloomTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomTokenizerFast)
    (BLOOM model)'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [BloomTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomTokenizerFast)
    (BLOOM 模型)'
- en: '`bridgetower` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (BridgeTower model)'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bridgetower` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (BridgeTower 模型)'
- en: '`bros` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (BROS model)'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bros` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (BROS 模型)'
- en: '`byt5` — [ByT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/byt5#transformers.ByT5Tokenizer)
    (ByT5 model)'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`byt5` — [ByT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/byt5#transformers.ByT5Tokenizer)
    (ByT5 模型)'
- en: '`camembert` — [CamembertTokenizer](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertTokenizer)
    or [CamembertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertTokenizerFast)
    (CamemBERT model)'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertTokenizer](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertTokenizer)
    或 [CamembertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertTokenizerFast)
    (CamemBERT 模型)'
- en: '`canine` — [CanineTokenizer](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineTokenizer)
    (CANINE model)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`canine` — [CanineTokenizer](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineTokenizer)
    (CANINE 模型)'
- en: '`chinese_clip` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Chinese-CLIP model)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chinese_clip` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Chinese-CLIP 模型)'
- en: '`clap` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (CLAP model)'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clap` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (CLAP 模型)'
- en: '`clip` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (CLIP model)'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (CLIP 模型)'
- en: '`clipseg` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (CLIPSeg model)'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clipseg` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (CLIPSeg 模型)'
- en: '`clvp` — [ClvpTokenizer](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpTokenizer)
    (CLVP model)'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clvp` — [ClvpTokenizer](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpTokenizer)
    (CLVP 模型)'
- en: '`code_llama` — [CodeLlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/code_llama#transformers.CodeLlamaTokenizer)
    or [CodeLlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/code_llama#transformers.CodeLlamaTokenizerFast)
    (CodeLlama model)'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_llama` — [CodeLlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/code_llama#transformers.CodeLlamaTokenizer)
    或 [CodeLlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/code_llama#transformers.CodeLlamaTokenizerFast)
    (CodeLlama 模型)'
- en: '`codegen` — [CodeGenTokenizer](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizer)
    or [CodeGenTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizerFast)
    (CodeGen model)'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codegen` — [CodeGenTokenizer](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizer)
    或 [CodeGenTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizerFast)
    (CodeGen 模型)'
- en: '`convbert` — [ConvBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertTokenizer)
    or [ConvBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertTokenizerFast)
    (ConvBERT model)'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [ConvBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertTokenizer)
    或 [ConvBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertTokenizerFast)
    (ConvBERT 模型)'
- en: '`cpm` — [CpmTokenizer](/docs/transformers/v4.37.2/en/model_doc/cpm#transformers.CpmTokenizer)
    or [CpmTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/cpm#transformers.CpmTokenizerFast)
    (CPM model)'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cpm` — [CpmTokenizer](/docs/transformers/v4.37.2/en/model_doc/cpm#transformers.CpmTokenizer)
    或 [CpmTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/cpm#transformers.CpmTokenizerFast)
    (CPM 模型)'
- en: '`cpmant` — [CpmAntTokenizer](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntTokenizer)
    (CPM-Ant model)'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cpmant` — [CpmAntTokenizer](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntTokenizer)
    (CPM-Ant 模型)'
- en: '`ctrl` — [CTRLTokenizer](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLTokenizer)
    (CTRL model)'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [CTRLTokenizer](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLTokenizer)
    (CTRL 模型)'
- en: '`data2vec-audio` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Data2VecAudio model)'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-audio` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Data2VecAudio 模型)'
- en: '`data2vec-text` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (Data2VecText model)'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (Data2VecText 模型)'
- en: '`deberta` — [DebertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaTokenizer)
    or [DebertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaTokenizerFast)
    (DeBERTa model)'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [DebertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaTokenizer)
    或 [DebertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaTokenizerFast)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [DebertaV2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer)
    or [DebertaV2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast)
    (DeBERTa-v2 model)'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [DebertaV2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer)
    或 [DebertaV2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [DistilBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertTokenizer)
    or [DistilBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertTokenizerFast)
    (DistilBERT model)'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [DistilBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertTokenizer)
    或 [DistilBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertTokenizerFast)
    (DistilBERT 模型)'
- en: '`dpr` — [DPRQuestionEncoderTokenizer](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer)
    or [DPRQuestionEncoderTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast)
    (DPR model)'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpr` — [DPRQuestionEncoderTokenizer](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer)
    或 [DPRQuestionEncoderTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast)
    (DPR 模型)'
- en: '`electra` — [ElectraTokenizer](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraTokenizer)
    or [ElectraTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraTokenizerFast)
    (ELECTRA model)'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraTokenizer](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraTokenizer)
    或 [ElectraTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraTokenizerFast)
    (ELECTRA 模型)'
- en: '`ernie` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (ERNIE model)'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (ERNIE 模型)'
- en: '`ernie_m` — [ErnieMTokenizer](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMTokenizer)
    (ErnieM model)'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie_m` — [ErnieMTokenizer](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMTokenizer)
    (ErnieM 模型)'
- en: '`esm` — [EsmTokenizer](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmTokenizer)
    (ESM model)'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [EsmTokenizer](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmTokenizer)
    (ESM 模型)'
- en: '`falcon` — [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    (Falcon model)'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`falcon` — [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    (Falcon 模型)'
- en: '`fastspeech2_conformer` — (FastSpeech2Conformer model)'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fastspeech2_conformer` — (FastSpeech2Conformer 模型)'
- en: '`flaubert` — [FlaubertTokenizer](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertTokenizer)
    (FlauBERT model)'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [FlaubertTokenizer](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertTokenizer)
    (FlauBERT 模型)'
- en: '`fnet` — [FNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetTokenizer)
    or [FNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetTokenizerFast)
    (FNet model)'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` — [FNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetTokenizer)
    或 [FNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetTokenizerFast)
    (FNet 模型)'
- en: '`fsmt` — [FSMTTokenizer](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTTokenizer)
    (FairSeq Machine-Translation model)'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fsmt` — [FSMTTokenizer](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTTokenizer)
    (FairSeq 机器翻译模型)'
- en: '`funnel` — [FunnelTokenizer](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelTokenizer)
    or [FunnelTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelTokenizerFast)
    (Funnel Transformer model)'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [FunnelTokenizer](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelTokenizer)
    或 [FunnelTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelTokenizerFast)
    (Funnel Transformer 模型)'
- en: '`git` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (GIT model)'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (GIT 模型)'
- en: '`gpt-sw3` — [GPTSw3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt-sw3#transformers.GPTSw3Tokenizer)
    (GPT-Sw3 model)'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [GPTSw3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt-sw3#transformers.GPTSw3Tokenizer)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (OpenAI GPT-2 model)'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (OpenAI GPT-2 模型)'
- en: '`gpt_bigcode` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (GPTBigCode model)'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_bigcode` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (GPTBigCode 模型)'
- en: '`gpt_neo` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (GPT Neo model)'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neo` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (GPT Neo 模型)'
- en: '`gpt_neox` — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast)
    (GPT NeoX model)'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox` — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast)
    (GPT NeoX 模型)'
- en: '`gpt_neox_japanese` — [GPTNeoXJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer)
    (GPT NeoX Japanese model)'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox_japanese` — [GPTNeoXJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer)
    (GPT NeoX Japanese 模型)'
- en: '`gptj` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (GPT-J model)'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (GPT-J 模型)'
- en: '`gptsan-japanese` — [GPTSanJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseTokenizer)
    (GPTSAN-japanese model)'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptsan-japanese` — [GPTSanJapaneseTokenizer](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseTokenizer)
    (GPTSAN-japanese 模型)'
- en: '`groupvit` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (GroupViT model)'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupvit` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (GroupViT 模型)'
- en: '`herbert` — [HerbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/herbert#transformers.HerbertTokenizer)
    or [HerbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/herbert#transformers.HerbertTokenizerFast)
    (HerBERT model)'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`herbert` — [HerbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/herbert#transformers.HerbertTokenizer)
    或 [HerbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/herbert#transformers.HerbertTokenizerFast)
    (HerBERT 模型)'
- en: '`hubert` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Hubert model)'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hubert` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Hubert 模型)'
- en: '`ibert` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (I-BERT model)'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ibert` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (I-BERT 模型)'
- en: '`idefics` — [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (IDEFICS model)'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`idefics` — [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (IDEFICS 模型)'
- en: '`instructblip` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (InstructBLIP model)'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instructblip` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (InstructBLIP 模型)'
- en: '`jukebox` — [JukeboxTokenizer](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxTokenizer)
    (Jukebox model)'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jukebox` — [JukeboxTokenizer](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxTokenizer)
    (Jukebox 模型)'
- en: '`kosmos-2` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    or [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (KOSMOS-2 model)'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kosmos-2` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    或 [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (KOSMOS-2 模型)'
- en: '`layoutlm` — [LayoutLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizer)
    or [LayoutLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast)
    (LayoutLM model)'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [LayoutLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizer)
    或 [LayoutLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast)
    (LayoutLM 模型)'
- en: '`layoutlmv2` — [LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    or [LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast)
    (LayoutLMv2 model)'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer)
    或 [LayoutLMv2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast)
    (LayoutLMv2 模型)'
- en: '`layoutlmv3` — [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    or [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)
    (LayoutLMv3 model)'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    或 [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)
    (LayoutLMv3 模型)'
- en: '`layoutxlm` — [LayoutXLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer)
    or [LayoutXLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast)
    (LayoutXLM model)'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutxlm` — [LayoutXLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer)
    或 [LayoutXLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast)
    (LayoutXLM 模型)'
- en: '`led` — [LEDTokenizer](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDTokenizer)
    or [LEDTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDTokenizerFast)
    (LED model)'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`led` — [LEDTokenizer](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDTokenizer)
    或 [LEDTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDTokenizerFast)
    (LED 模型)'
- en: '`lilt` — [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    or [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)
    (LiLT model)'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lilt` — [LayoutLMv3Tokenizer](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer)
    或 [LayoutLMv3TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast)
    (LiLT 模型)'
- en: '`llama` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (LLaMA model)'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llama` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (LLaMA 模型)'
- en: '`llava` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (LLaVa model)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llava` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (LLaVa 模型)'
- en: '`longformer` — [LongformerTokenizer](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerTokenizer)
    or [LongformerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerTokenizerFast)
    (Longformer model)'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [LongformerTokenizer](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerTokenizer)
    或 [LongformerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerTokenizerFast)
    (Longformer 模型)'
- en: '`longt5` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (LongT5 model)'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longt5` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (LongT5 模型)'
- en: '`luke` — [LukeTokenizer](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeTokenizer)
    (LUKE model)'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`luke` — [LukeTokenizer](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeTokenizer)
    (LUKE 模型)'
- en: '`lxmert` — [LxmertTokenizer](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertTokenizer)
    or [LxmertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertTokenizerFast)
    (LXMERT model)'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lxmert` — [LxmertTokenizer](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertTokenizer)
    或 [LxmertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertTokenizerFast)
    (LXMERT 模型)'
- en: '`m2m_100` — [M2M100Tokenizer](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Tokenizer)
    (M2M100 model)'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`m2m_100` — [M2M100Tokenizer](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Tokenizer)
    (M2M100 模型)'
- en: '`marian` — [MarianTokenizer](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianTokenizer)
    (Marian model)'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marian` — [MarianTokenizer](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianTokenizer)
    (Marian 模型)'
- en: '`mbart` — [MBartTokenizer](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartTokenizer)
    or [MBartTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartTokenizerFast)
    (mBART model)'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [MBartTokenizer](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartTokenizer)
    或 [MBartTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartTokenizerFast)
    (mBART 模型)'
- en: '`mbart50` — [MBart50Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBart50Tokenizer)
    or [MBart50TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBart50TokenizerFast)
    (mBART-50 model)'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart50` — [MBart50Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBart50Tokenizer)
    或 [MBart50TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBart50TokenizerFast)
    (mBART-50 模型)'
- en: '`mega` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (MEGA model)'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (MEGA 模型)'
- en: '`megatron-bert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Megatron-BERT model)'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Megatron-BERT 模型)'
- en: '`mgp-str` — [MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer)
    (MGP-STR model)'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mgp-str` — [MgpstrTokenizer](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrTokenizer)
    (MGP-STR 模型)'
- en: '`mistral` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (Mistral model)'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mistral` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (Mistral 模型)'
- en: '`mixtral` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (Mixtral model)'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mixtral` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (Mixtral 模型)'
- en: '`mluke` — [MLukeTokenizer](/docs/transformers/v4.37.2/en/model_doc/mluke#transformers.MLukeTokenizer)
    (mLUKE model)'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mluke` — [MLukeTokenizer](/docs/transformers/v4.37.2/en/model_doc/mluke#transformers.MLukeTokenizer)
    (mLUKE 模型)'
- en: '`mobilebert` — [MobileBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertTokenizer)
    or [MobileBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast)
    (MobileBERT model)'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [MobileBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertTokenizer)
    或 [MobileBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast)
    (MobileBERT 模型)'
- en: '`mpnet` — [MPNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetTokenizer)
    or [MPNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetTokenizerFast)
    (MPNet model)'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [MPNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetTokenizer)
    或 [MPNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetTokenizerFast)
    (MPNet 模型)'
- en: '`mpt` — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast)
    (MPT model)'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpt` — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast)
    (MPT 模型)'
- en: '`mra` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (MRA model)'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mra` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (MRA 模型)'
- en: '`mt5` — [MT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [MT5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (MT5 model)'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [MT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    或 [MT5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (MT5 模型)'
- en: '`musicgen` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (MusicGen model)'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`musicgen` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (MusicGen 模型)'
- en: '`mvp` — [MvpTokenizer](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpTokenizer)
    or [MvpTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpTokenizerFast)
    (MVP model)'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mvp` — [MvpTokenizer](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpTokenizer)
    或 [MvpTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpTokenizerFast)
    (MVP 模型)'
- en: '`nezha` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Nezha model)'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (Nezha 模型)'
- en: '`nllb` — [NllbTokenizer](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizer)
    or [NllbTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizerFast)
    (NLLB model)'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nllb` — [NllbTokenizer](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizer)
    或 [NllbTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizerFast)
    (NLLB 模型)'
- en: '`nllb-moe` — [NllbTokenizer](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizer)
    or [NllbTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizerFast)
    (NLLB-MOE model)'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nllb-moe` — [NllbTokenizer](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizer)
    或 [NllbTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/nllb#transformers.NllbTokenizerFast)
    (NLLB-MOE 模型)'
- en: '`nystromformer` — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)
    or [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)
    (Nyströmformer model)'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nystromformer` — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)
    或 [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)（Nyströmformer
    模型）'
- en: '`oneformer` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (OneFormer model)'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oneformer` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)（OneFormer
    模型）'
- en: '`openai-gpt` — [OpenAIGPTTokenizer](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer)
    or [OpenAIGPTTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast)
    (OpenAI GPT model)'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [OpenAIGPTTokenizer](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer)
    或 [OpenAIGPTTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast)（OpenAI
    GPT 模型）'
- en: '`opt` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    or [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)
    (OPT model)'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [GPT2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Tokenizer)
    或 [GPT2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2TokenizerFast)（OPT
    模型）'
- en: '`owlv2` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (OWLv2 model)'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlv2` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)（OWLv2
    模型）'
- en: '`owlvit` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (OWL-ViT model)'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlvit` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)（OWL-ViT
    模型）'
- en: '`pegasus` — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer)
    or [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)
    (Pegasus model)'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus` — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer)
    或 [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)（Pegasus
    模型）'
- en: '`pegasus_x` — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer)
    or [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)
    (PEGASUS-X model)'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus_x` — [PegasusTokenizer](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizer)
    或 [PegasusTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusTokenizerFast)（PEGASUS-X
    模型）'
- en: '`perceiver` — [PerceiverTokenizer](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverTokenizer)
    (Perceiver model)'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perceiver` — [PerceiverTokenizer](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverTokenizer)（Perceiver
    模型）'
- en: '`persimmon` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (Persimmon model)'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`persimmon` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)（Persimmon
    模型）'
- en: '`phi` — [CodeGenTokenizer](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizer)
    or [CodeGenTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizerFast)
    (Phi model)'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`phi` — [CodeGenTokenizer](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizer)
    或 [CodeGenTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenTokenizerFast)（Phi
    模型）'
- en: '`phobert` — [PhobertTokenizer](/docs/transformers/v4.37.2/en/model_doc/phobert#transformers.PhobertTokenizer)
    (PhoBERT model)'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`phobert` — [PhobertTokenizer](/docs/transformers/v4.37.2/en/model_doc/phobert#transformers.PhobertTokenizer)（PhoBERT
    模型）'
- en: '`pix2struct` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (Pix2Struct model)'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pix2struct` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)（Pix2Struct
    模型）'
- en: '`plbart` — [PLBartTokenizer](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartTokenizer)
    (PLBart model)'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plbart` — [PLBartTokenizer](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartTokenizer)（PLBart
    模型）'
- en: '`prophetnet` — [ProphetNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetTokenizer)
    (ProphetNet model)'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prophetnet` — [ProphetNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetTokenizer)（ProphetNet
    模型）'
- en: '`qdqbert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (QDQBert model)'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)（QDQBert
    模型）'
- en: '`qwen2` — [Qwen2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Tokenizer)
    or [Qwen2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2TokenizerFast)
    (Qwen2 model)'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qwen2` — [Qwen2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Tokenizer)
    或 [Qwen2TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2TokenizerFast)（Qwen2
    模型）'
- en: '`rag` — [RagTokenizer](/docs/transformers/v4.37.2/en/model_doc/rag#transformers.RagTokenizer)
    (RAG model)'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rag` — [RagTokenizer](/docs/transformers/v4.37.2/en/model_doc/rag#transformers.RagTokenizer)（RAG
    模型）'
- en: '`realm` — [RealmTokenizer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizer)
    or [RealmTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizerFast)
    (REALM model)'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`realm` — [RealmTokenizer](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizer)
    或 [RealmTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/realm#transformers.RealmTokenizerFast)（REALM
    模型）'
- en: '`reformer` — [ReformerTokenizer](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerTokenizer)
    or [ReformerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerTokenizerFast)
    (Reformer model)'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reformer` — [ReformerTokenizer](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerTokenizer)
    或 [ReformerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerTokenizerFast)
    (Reformer 模型)'
- en: '`rembert` — [RemBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertTokenizer)
    or [RemBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertTokenizerFast)
    (RemBERT model)'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [RemBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertTokenizer)
    或 [RemBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertTokenizerFast)
    (RemBERT 模型)'
- en: '`retribert` — [RetriBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertTokenizer)
    or [RetriBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertTokenizerFast)
    (RetriBERT model)'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`retribert` — [RetriBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertTokenizer)
    或 [RetriBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertTokenizerFast)
    (RetriBERT 模型)'
- en: '`roberta` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (RoBERTa model)'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    or [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizer)
    或 [RobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaTokenizerFast)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roc_bert` — [RoCBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertTokenizer)
    (RoCBert model)'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertTokenizer)
    (RoCBert 模型)'
- en: '`roformer` — [RoFormerTokenizer](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerTokenizer)
    or [RoFormerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerTokenizerFast)
    (RoFormer model)'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [RoFormerTokenizer](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerTokenizer)
    或 [RoFormerTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerTokenizerFast)
    (RoFormer 模型)'
- en: '`rwkv` — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast)
    (RWKV model)'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rwkv` — [GPTNeoXTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast)
    (RWKV 模型)'
- en: '`seamless_m4t` — [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    or [SeamlessM4TTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizerFast)
    (SeamlessM4T model)'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t` — [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    或 [SeamlessM4TTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizerFast)
    (SeamlessM4T 模型)'
- en: '`seamless_m4t_v2` — [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    or [SeamlessM4TTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizerFast)
    (SeamlessM4Tv2 model)'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t_v2` — [SeamlessM4TTokenizer](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizer)
    或 [SeamlessM4TTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TTokenizerFast)
    (SeamlessM4Tv2 模型)'
- en: '`siglip` — [SiglipTokenizer](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipTokenizer)
    (SigLIP model)'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`siglip` — [SiglipTokenizer](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipTokenizer)
    (SigLIP 模型)'
- en: '`speech_to_text` — [Speech2TextTokenizer](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer)
    (Speech2Text model)'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text` — [Speech2TextTokenizer](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer)
    (Speech2Text 模型)'
- en: '`speech_to_text_2` — [Speech2Text2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer)
    (Speech2Text2 model)'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text_2` — [Speech2Text2Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer)
    (Speech2Text2 模型)'
- en: '`speecht5` — [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer)
    (SpeechT5 model)'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speecht5` — [SpeechT5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Tokenizer)
    (SpeechT5 模型)'
- en: '`splinter` — [SplinterTokenizer](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterTokenizer)
    or [SplinterTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterTokenizerFast)
    (Splinter model)'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`splinter` — [SplinterTokenizer](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterTokenizer)
    或 [SplinterTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterTokenizerFast)
    (Splinter 模型)'
- en: '`squeezebert` — [SqueezeBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer)
    or [SqueezeBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast)
    (SqueezeBERT model)'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`squeezebert` — [SqueezeBertTokenizer](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer)
    或 [SqueezeBertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast)
    (SqueezeBERT 模型)'
- en: '`switch_transformers` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (SwitchTransformers model)'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`switch_transformers` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (SwitchTransformers 模型)'
- en: '`t5` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (T5 model)'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (T5 模型)'
- en: '`tapas` — [TapasTokenizer](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasTokenizer)
    (TAPAS model)'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TapasTokenizer](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasTokenizer)
    (TAPAS 模型)'
- en: '`tapex` — [TapexTokenizer](/docs/transformers/v4.37.2/en/model_doc/tapex#transformers.TapexTokenizer)
    (TAPEX model)'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapex` — [TapexTokenizer](/docs/transformers/v4.37.2/en/model_doc/tapex#transformers.TapexTokenizer)
    (TAPEX 模型)'
- en: '`transfo-xl` — [TransfoXLTokenizer](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer)
    (Transformer-XL model)'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TransfoXLTokenizer](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer)
    (Transformer-XL 模型)'
- en: '`tvp` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (TVP model)'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvp` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (TVP 模型)'
- en: '`umt5` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    or [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (UMT5 model)'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`umt5` — [T5Tokenizer](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5Tokenizer)
    或 [T5TokenizerFast](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.T5TokenizerFast)
    (UMT5 模型)'
- en: '`vilt` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (ViLT model)'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vilt` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (ViLT 模型)'
- en: '`vipllava` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    or [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (VipLlava model)'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vipllava` — [LlamaTokenizer](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizer)
    或 [LlamaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaTokenizerFast)
    (VipLlava 模型)'
- en: '`visual_bert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    or [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (VisualBERT model)'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_bert` — [BertTokenizer](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizer)
    或 [BertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertTokenizerFast)
    (VisualBERT 模型)'
- en: '`vits` — [VitsTokenizer](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsTokenizer)
    (VITS model)'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vits` — [VitsTokenizer](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsTokenizer)
    (VITS 模型)'
- en: '`wav2vec2` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Wav2Vec2 model)'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Wav2Vec2 模型)'
- en: '`wav2vec2-bert` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Wav2Vec2-BERT model)'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-bert` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Wav2Vec2-BERT 模型)'
- en: '`wav2vec2-conformer` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Wav2Vec2-Conformer model)'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2CTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer)
    (Wav2Vec2-Conformer 模型)'
- en: '`wav2vec2_phoneme` — [Wav2Vec2PhonemeCTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer)
    (Wav2Vec2Phoneme model)'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2_phoneme` — [Wav2Vec2PhonemeCTCTokenizer](/docs/transformers/v4.37.2/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer)
    (Wav2Vec2Phoneme 模型)'
- en: '`whisper` — [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)
    or [WhisperTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizerFast)
    (Whisper model)'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)
    或 [WhisperTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizerFast)
    (Whisper 模型)'
- en: '`xclip` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    or [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (X-CLIP model)'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xclip` — [CLIPTokenizer](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer)
    或 [CLIPTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizerFast)
    (X-CLIP 模型)'
- en: '`xglm` — [XGLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMTokenizer)
    or [XGLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMTokenizerFast)
    (XGLM model)'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xglm` — [XGLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMTokenizer)
    或 [XGLMTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMTokenizerFast)
    (XGLM 模型)'
- en: '`xlm` — [XLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMTokenizer)
    (XLM model)'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMTokenizer)
    (XLM 模型)'
- en: '`xlm-prophetnet` — [XLMProphetNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer)
    (XLM-ProphetNet model)'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-prophetnet` — [XLMProphetNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer)
    (XLM-ProphetNet 模型)'
- en: '`xlm-roberta` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    or [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (XLM-RoBERTa model)'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    或 [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (XLM-RoBERTa 模型)'
- en: '`xlm-roberta-xl` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    or [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (XLM-RoBERTa-XL model)'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    或 [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (XLM-RoBERTa-XL 模型)'
- en: '`xlnet` — [XLNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizer)
    or [XLNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizerFast)
    (XLNet model)'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [XLNetTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizer)
    或 [XLNetTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetTokenizerFast)
    (XLNet 模型)'
- en: '`xmod` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    or [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (X-MOD model)'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XLMRobertaTokenizer](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer)
    或 [XLMRobertaTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast)
    (X-MOD 模型)'
- en: '`yoso` — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)
    or [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)
    (YOSO model)'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yoso` — [AlbertTokenizer](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizer)
    或 [AlbertTokenizerFast](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertTokenizerFast)（YOSO
    模型）'
- en: 'Examples:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE8]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#### `register`'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L847)'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/tokenization_auto.py#L847)'
- en: '[PRE9]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration corresponding to the model to register.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 与要注册的模型对应的配置。'
- en: '`slow_tokenizer_class` (`PretrainedTokenizer`, *optional*) — The slow tokenizer
    to register.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`slow_tokenizer_class` (`PretrainedTokenizer`, *optional*) — 要注册的慢速分词器。'
- en: '`fast_tokenizer_class` (`PretrainedTokenizerFast`, *optional*) — The fast tokenizer
    to register.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fast_tokenizer_class` (`PretrainedTokenizerFast`, *optional*) — 要注册的快速分词器。'
- en: Register a new tokenizer in this mapping.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 在此映射中注册一个新的分词器。
- en: AutoFeatureExtractor
  id: totrans-475
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoFeatureExtractor
- en: '### `class transformers.AutoFeatureExtractor`'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L239)'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L239)'
- en: '[PRE10]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This is a generic feature extractor class that will be instantiated as one of
    the feature extractor classes of the library when created with the [AutoFeatureExtractor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained)
    class method.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的特征提取器类，在使用 [AutoFeatureExtractor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained)
    类方法创建时，将实例化为库的特征提取器类之一。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_pretrained`'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L253)'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L253)'
- en: '[PRE11]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 这可以是：'
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-486
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练特征提取器的 *模型 ID*，托管在 huggingface.co 上的模型存储库中。有效的模型 ID 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: a path to a *directory* containing a feature extractor file saved using the
    [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-487
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    方法保存的特征提取器文件的 *目录* 路径，例如 `./my_model_directory/`。
- en: a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
  id: totrans-488
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个保存的特征提取器 JSON *文件* 的路径或 URL，例如 `./my_model_directory/preprocessor_config.json`。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model feature extractor should be cached if the standard
    cache should not be used.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载的预训练模型特征提取器应该缓存在其中的目录路径，如果不想使用标准缓存。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force to (re-)download the feature extractor files and override the cached
    versions if they exist.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载特征提取器文件并覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received file. Attempts to resume the download if such
    a file exists.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，则尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}.` The proxies are used on each request.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如 `{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`).'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 *bool*, *optional*) — 用作远程文件的 HTTP 令牌授权的令牌。如果为 `True`，将使用运行
    `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`return_unused_kwargs` (`bool`, *optional*, defaults to `False`) — If `False`,
    then this function returns just the final feature extractor object. If `True`,
    then this functions returns a `Tuple(feature_extractor, unused_kwargs)` where
    *unused_kwargs* is a dictionary consisting of the key/value pairs whose keys are
    not feature extractor attributes: i.e., the part of `kwargs` which has not been
    used to update `feature_extractor` and is otherwise ignored.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_unused_kwargs` (`bool`, *optional*, defaults to `False`) — 如果为 `False`，则此函数仅返回最终的特征提取器对象。如果为
    `True`，则此函数返回一个 `Tuple(feature_extractor, unused_kwargs)`，其中 *unused_kwargs* 是一个字典，包含那些未被用于更新
    `feature_extractor` 的键/值对：即 `kwargs` 的一部分，未被用于更新 `feature_extractor` 且被忽略的部分。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。只有对您信任的存储库以及您已阅读代码的情况下，才应将此选项设置为
    `True`，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — The values in kwargs of any keys
    which are feature extractor attributes will be used to override the loaded values.
    Behavior concerning key/value pairs whose keys are *not* feature extractor attributes
    is controlled by the `return_unused_kwargs` keyword parameter.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *optional*) — 任何键为特征提取器属性的 kwargs 中的值将用于覆盖加载的值。关于键/值对中键不是特征提取器属性的行为由
    `return_unused_kwargs` 关键参数控制。'
- en: Instantiate one of the feature extractor classes of the library from a pretrained
    model vocabulary.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型词汇表中实例化库中的特征提取器类之一。
- en: 'The feature extractor class to instantiate is selected based on the `model_type`
    property of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的特征提取器类是根据配置对象的 `model_type` 属性（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载）选择的，或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`audio-spectrogram-transformer` — [ASTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTFeatureExtractor)
    (Audio Spectrogram Transformer model)'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio-spectrogram-transformer` — [ASTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/audio-spectrogram-transformer#transformers.ASTFeatureExtractor)
    (Audio Spectrogram Transformer 模型)'
- en: '`beit` — [BeitFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitFeatureExtractor)
    (BEiT model)'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beit` — [BeitFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/beit#transformers.BeitFeatureExtractor)
    (BEiT 模型)'
- en: '`chinese_clip` — [ChineseCLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPFeatureExtractor)
    (Chinese-CLIP model)'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chinese_clip` — [ChineseCLIPFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/chinese_clip#transformers.ChineseCLIPFeatureExtractor)
    (Chinese-CLIP 模型)'
- en: '`clap` — [ClapFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapFeatureExtractor)
    (CLAP model)'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clap` — [ClapFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/clap#transformers.ClapFeatureExtractor)
    (CLAP 模型)'
- en: '`clip` — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor)
    (CLIP model)'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/clip#transformers.CLIPFeatureExtractor)
    (CLIP 模型)'
- en: '`clipseg` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (CLIPSeg model)'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clipseg` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/vit#transformers.ViTFeatureExtractor)
    (CLIPSeg 模型)'
- en: '`clvp` — [ClvpFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpFeatureExtractor)
    (CLVP model)'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clvp` — [ClvpFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/clvp#transformers.ClvpFeatureExtractor)
    (CLVP 模型)'
- en: '`conditional_detr` — [ConditionalDetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor)
    (Conditional DETR model)'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conditional_detr` — [ConditionalDetrFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor)
    (Conditional DETR 模型)'
- en: '`convnext` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (ConvNeXT model)'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnext` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (ConvNeXT 模型)'
- en: '`cvt` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (CvT model)'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cvt` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (CvT 模型)'
- en: '`data2vec-audio` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Data2VecAudio model)'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-audio` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Data2VecAudio 模型)'
- en: '`data2vec-vision` — [BeitFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitFeatureExtractor)
    (Data2VecVision model)'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-vision` — [BeitFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/beit#transformers.BeitFeatureExtractor)
    (Data2VecVision 模型)'
- en: '`deformable_detr` — [DeformableDetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor)
    (Deformable DETR model)'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deformable_detr` — [DeformableDetrFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor)
    (Deformable DETR 模型)'
- en: '`deit` — [DeiTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTFeatureExtractor)
    (DeiT model)'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deit` — [DeiTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/deit#transformers.DeiTFeatureExtractor)
    (DeiT 模型)'
- en: '`detr` — [DetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrFeatureExtractor)
    (DETR model)'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detr` — [DetrFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/detr#transformers.DetrFeatureExtractor)
    (DETR 模型)'
- en: '`dinat` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (DiNAT model)'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dinat` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/vit#transformers.ViTFeatureExtractor)
    (DiNAT 模型)'
- en: '`donut-swin` — [DonutFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutFeatureExtractor)
    (DonutSwin model)'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`donut-swin` — [DonutFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/donut#transformers.DonutFeatureExtractor)
    (DonutSwin 模型)'
- en: '`dpt` — [DPTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTFeatureExtractor)
    (DPT model)'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpt` — [DPTFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/dpt#transformers.DPTFeatureExtractor)
    (DPT 模型)'
- en: '`encodec` — [EncodecFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecFeatureExtractor)
    (EnCodec model)'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encodec` — [EncodecFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/encodec#transformers.EncodecFeatureExtractor)
    (EnCodec 模型)'
- en: '`flava` — [FlavaFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaFeatureExtractor)
    (FLAVA model)'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flava` — [FlavaFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/flava#transformers.FlavaFeatureExtractor)
    (FLAVA 模型)'
- en: '`glpn` — [GLPNFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNFeatureExtractor)
    (GLPN model)'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glpn` — [GLPNFeatureExtractor](/docs/transformers/v4.37.2/zh/model_doc/glpn#transformers.GLPNFeatureExtractor)
    (GLPN 模型)'
- en: '`groupvit` — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor)
    (GroupViT model)'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupvit` — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor)
    (GroupViT 模型)'
- en: '`hubert` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Hubert model)'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hubert` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Hubert 模型)'
- en: '`imagegpt` — [ImageGPTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor)
    (ImageGPT model)'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imagegpt` — [ImageGPTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor)
    (ImageGPT 模型)'
- en: '`layoutlmv2` — [LayoutLMv2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor)
    (LayoutLMv2 model)'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor)
    (LayoutLMv2 模型)'
- en: '`layoutlmv3` — [LayoutLMv3FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor)
    (LayoutLMv3 model)'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor)
    (LayoutLMv3 模型)'
- en: '`levit` — [LevitFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitFeatureExtractor)
    (LeViT model)'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`levit` — [LevitFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitFeatureExtractor)
    (LeViT 模型)'
- en: '`maskformer` — [MaskFormerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor)
    (MaskFormer model)'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maskformer` — [MaskFormerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor)
    (MaskFormer 模型)'
- en: '`mctct` — [MCTCTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTFeatureExtractor)
    (M-CTC-T model)'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mctct` — [MCTCTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTFeatureExtractor)
    (M-CTC-T 模型)'
- en: '`mobilenet_v1` — [MobileNetV1FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1FeatureExtractor)
    (MobileNetV1 model)'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v1` — [MobileNetV1FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1FeatureExtractor)
    (MobileNetV1 模型)'
- en: '`mobilenet_v2` — [MobileNetV2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2FeatureExtractor)
    (MobileNetV2 model)'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v2` — [MobileNetV2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2FeatureExtractor)
    (MobileNetV2 模型)'
- en: '`mobilevit` — [MobileViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor)
    (MobileViT model)'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevit` — [MobileViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor)
    (MobileViT 模型)'
- en: '`nat` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (NAT model)'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nat` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (NAT 模型)'
- en: '`owlvit` — [OwlViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor)
    (OWL-ViT model)'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlvit` — [OwlViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor)
    (OWL-ViT 模型)'
- en: '`perceiver` — [PerceiverFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor)
    (Perceiver model)'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perceiver` — [PerceiverFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor)
    (Perceiver 模型)'
- en: '`poolformer` — [PoolFormerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor)
    (PoolFormer model)'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`poolformer` — [PoolFormerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor)
    (PoolFormer 模型)'
- en: '`pop2piano` — [Pop2PianoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoFeatureExtractor)
    (Pop2Piano model)'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pop2piano` — [Pop2PianoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoFeatureExtractor)
    (Pop2Piano 模型)'
- en: '`regnet` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (RegNet model)'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regnet` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (RegNet 模型)'
- en: '`resnet` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (ResNet model)'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resnet` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (ResNet 模型)'
- en: '`seamless_m4t` — [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    (SeamlessM4T model)'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t` — [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    (SeamlessM4T 模型)'
- en: '`seamless_m4t_v2` — [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    (SeamlessM4Tv2 model)'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t_v2` — [SeamlessM4TFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TFeatureExtractor)
    (SeamlessM4Tv2 模型)'
- en: '`segformer` — [SegformerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerFeatureExtractor)
    (SegFormer model)'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segformer` — [SegformerFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerFeatureExtractor)
    (SegFormer 模型)'
- en: '`sew` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (SEW model)'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (SEW 模型)'
- en: '`sew-d` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (SEW-D model)'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew-d` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (SEW-D 模型)'
- en: '`speech_to_text` — [Speech2TextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor)
    (Speech2Text model)'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text` — [Speech2TextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor)
    (Speech2Text 模型)'
- en: '`speecht5` — [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor)
    (SpeechT5 model)'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speecht5` — [SpeechT5FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5FeatureExtractor)
    (SpeechT5 模型)'
- en: '`swiftformer` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (SwiftFormer model)'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swiftformer` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (SwiftFormer 模型)'
- en: '`swin` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (Swin Transformer model)'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (Swin Transformer 模型)'
- en: '`swinv2` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (Swin Transformer V2 model)'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swinv2` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (Swin Transformer V2 模型)'
- en: '`table-transformer` — [DetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrFeatureExtractor)
    (Table Transformer model)'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table-transformer` — [DetrFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrFeatureExtractor)
    (Table Transformer 模型)'
- en: '`timesformer` — [VideoMAEFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor)
    (TimeSformer model)'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesformer` — [VideoMAEFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor)
    (TimeSformer 模型)'
- en: '`tvlt` — [TvltFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltFeatureExtractor)
    (TVLT model)'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvlt` — [TvltFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltFeatureExtractor)
    (TVLT 模型)'
- en: '`unispeech` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (UniSpeech model)'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (UniSpeech 模型)'
- en: '`unispeech-sat` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (UniSpeechSat model)'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech-sat` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (UniSpeechSat 模型)'
- en: '`univnet` — [UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)
    (UnivNet model)'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`univnet` — [UnivNetFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetFeatureExtractor)
    (UnivNet 模型)'
- en: '`van` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (VAN model)'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`van` — [ConvNextFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextFeatureExtractor)
    (VAN 模型)'
- en: '`videomae` — [VideoMAEFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor)
    (VideoMAE model)'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`videomae` — [VideoMAEFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor)
    (VideoMAE 模型)'
- en: '`vilt` — [ViltFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltFeatureExtractor)
    (ViLT model)'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vilt` — [ViltFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltFeatureExtractor)
    (ViLT 模型)'
- en: '`vit` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (ViT model)'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (ViT 模型)'
- en: '`vit_mae` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (ViTMAE model)'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_mae` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (ViTMAE 模型)'
- en: '`vit_msn` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (ViTMSN model)'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_msn` — [ViTFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTFeatureExtractor)
    (ViTMSN 模型)'
- en: '`wav2vec2` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Wav2Vec2 model)'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Wav2Vec2 模型)'
- en: '`wav2vec2-bert` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Wav2Vec2-BERT model)'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-bert` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Wav2Vec2-BERT 模型)'
- en: '`wav2vec2-conformer` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Wav2Vec2-Conformer model)'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (Wav2Vec2-Conformer 模型)'
- en: '`wavlm` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (WavLM model)'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wavlm` — [Wav2Vec2FeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor)
    (WavLM 模型)'
- en: '`whisper` — [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)
    (Whisper model)'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)
    (Whisper 模型)'
- en: '`xclip` — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor)
    (X-CLIP model)'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xclip` — [CLIPFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPFeatureExtractor)
    (X-CLIP 模型)'
- en: '`yolos` — [YolosFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosFeatureExtractor)
    (YOLOS model)'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yolos` — [YolosFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosFeatureExtractor)
    (YOLOS 模型)'
- en: Passing `token=True` is required when you want to use a private model.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想使用私有模型时，需要传递 `token=True`。
- en: 'Examples:'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE12]'
  id: totrans-570
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#### `register`'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L388)'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/feature_extraction_auto.py#L388)'
- en: '[PRE13]'
  id: totrans-573
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration corresponding to the model to register.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 要注册的模型对应的配置。'
- en: '`feature_extractor_class` (`FeatureExtractorMixin`) — The feature extractor
    to register.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor_class` (`FeatureExtractorMixin`) — 要注册的特征提取器。'
- en: Register a new feature extractor for this class.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 为此类注册一个新的特征提取器。
- en: AutoImageProcessor
  id: totrans-578
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoImageProcessor
- en: '### `class transformers.AutoImageProcessor`'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoImageProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L251)'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L251)'
- en: '[PRE14]'
  id: totrans-581
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This is a generic image processor class that will be instantiated as one of
    the image processor classes of the library when created with the [AutoImageProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor.from_pretrained)
    class method.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的图像处理器类，在使用 [AutoImageProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoImageProcessor.from_pretrained)
    类方法创建时，将被实例化为库中的图像处理器类之一。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_pretrained`'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L265)'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L265)'
- en: '[PRE15]'
  id: totrans-586
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 这可以是：'
- en: a string, the *model id* of a pretrained image_processor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-589
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个预训练图像处理器的 *模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: a path to a *directory* containing a image processor file saved using the [save_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-590
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained)
    方法保存的图像处理器文件的 *目录* 路径，例如，`./my_model_directory/`。
- en: a path or url to a saved image processor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
  id: totrans-591
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个保存的图像处理器 JSON *文件* 的路径或 URL，例如，`./my_model_directory/preprocessor_config.json`。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model image processor should be cached if the standard
    cache should not be used.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *可选*) — 预下载的预训练模型图像处理器应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force to (re-)download the image processor files and override the cached versions
    if they exist.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载图像处理器文件并覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received file. Attempts to resume the download if such
    a file exists.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，则尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}.` The proxies are used on each request.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求上使用。'
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`).'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str` 或 *bool*, *可选*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，将使用运行
    `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 id，因为我们在
    huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`return_unused_kwargs` (`bool`, *optional*, defaults to `False`) — If `False`,
    then this function returns just the final image processor object. If `True`, then
    this functions returns a `Tuple(image_processor, unused_kwargs)` where *unused_kwargs*
    is a dictionary consisting of the key/value pairs whose keys are not image processor
    attributes: i.e., the part of `kwargs` which has not been used to update `image_processor`
    and is otherwise ignored.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_unused_kwargs` (`bool`, *可选*, 默认为 `False`) — 如果为 `False`，则此函数仅返回最终的图像处理器对象。如果为
    `True`，则此函数返回一个 `Tuple(image_processor, unused_kwargs)`，其中 *unused_kwargs* 是一个字典，包含那些键/值对，其键不是图像处理器属性：即
    `kwargs` 中未被用于更新 `image_processor` 且被忽略的部分。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — The values in kwargs of any keys
    which are image processor attributes will be used to override the loaded values.
    Behavior concerning key/value pairs whose keys are *not* image processor attributes
    is controlled by the `return_unused_kwargs` keyword parameter.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (`Dict[str, Any]`, *可选*) — 任何键为图像处理器属性的 kwargs 中的值将用于覆盖加载的值。关于键/值对中键
    *不是* 图像处理器属性的行为由 `return_unused_kwargs` 关键字参数控制。'
- en: Instantiate one of the image processor classes of the library from a pretrained
    model vocabulary.
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型词汇表中实例化库中的一个图像处理器类。
- en: 'The image processor class to instantiate is selected based on the `model_type`
    property of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的图像处理器类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`align` — [EfficientNetImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetImageProcessor)
    (ALIGN model)'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`align` — [EfficientNetImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetImageProcessor)
    (ALIGN 模型)'
- en: '`beit` — [BeitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitImageProcessor)
    (BEiT model)'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beit` — [BeitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitImageProcessor)
    (BEiT 模型)'
- en: '`bit` — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor)
    (BiT model)'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bit` — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor)
    (BiT 模型)'
- en: '`blip` — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor)
    (BLIP model)'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor)
    (BLIP 模型)'
- en: '`blip-2` — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor)
    (BLIP-2 model)'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip-2` — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor)
    (BLIP-2 模型)'
- en: '`bridgetower` — [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)
    (BridgeTower model)'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bridgetower` — [BridgeTowerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerImageProcessor)
    (BridgeTower 模型)'
- en: '`chinese_clip` — [ChineseCLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPImageProcessor)
    (Chinese-CLIP model)'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chinese_clip` — [ChineseCLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPImageProcessor)
    (Chinese-CLIP 模型)'
- en: '`clip` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (CLIP model)'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (CLIP 模型)'
- en: '`clipseg` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (CLIPSeg model)'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clipseg` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (CLIPSeg 模型)'
- en: '`conditional_detr` — [ConditionalDetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrImageProcessor)
    (Conditional DETR model)'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conditional_detr` — [ConditionalDetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrImageProcessor)
    (Conditional DETR 模型)'
- en: '`convnext` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (ConvNeXT model)'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnext` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (ConvNeXT 模型)'
- en: '`convnextv2` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (ConvNeXTV2 model)'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnextv2` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (ConvNeXTV2 模型)'
- en: '`cvt` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (CvT model)'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cvt` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (CvT 模型)'
- en: '`data2vec-vision` — [BeitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitImageProcessor)
    (Data2VecVision model)'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-vision` — [BeitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitImageProcessor)
    (Data2VecVision 模型)'
- en: '`deformable_detr` — [DeformableDetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrImageProcessor)
    (Deformable DETR model)'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deformable_detr` — [DeformableDetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrImageProcessor)
    (Deformable DETR 模型)'
- en: '`deit` — [DeiTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTImageProcessor)
    (DeiT model)'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deit` — [DeiTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTImageProcessor)
    (DeiT 模型)'
- en: '`deta` — [DetaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaImageProcessor)
    (DETA model)'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deta` — [DetaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaImageProcessor)
    (DETA 模型)'
- en: '`detr` — [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor)
    (DETR model)'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detr` — [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor)
    (DETR 模型)'
- en: '`dinat` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (DiNAT model)'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dinat` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (DiNAT 模型)'
- en: '`dinov2` — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor)
    (DINOv2 model)'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dinov2` — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor)
    (DINOv2 模型)'
- en: '`donut-swin` — [DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor)
    (DonutSwin model)'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`donut-swin` — [DonutImageProcessor](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutImageProcessor)
    (DonutSwin 模型)'
- en: '`dpt` — [DPTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTImageProcessor)
    (DPT model)'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpt` — [DPTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTImageProcessor)
    (DPT 模型)'
- en: '`efficientformer` — [EfficientFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerImageProcessor)
    (EfficientFormer model)'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientformer` — [EfficientFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerImageProcessor)
    (EfficientFormer 模型)'
- en: '`efficientnet` — [EfficientNetImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetImageProcessor)
    (EfficientNet model)'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientnet` — [EfficientNetImageProcessor](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetImageProcessor)
    (EfficientNet 模型)'
- en: '`flava` — [FlavaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageProcessor)
    (FLAVA model)'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flava` — [FlavaImageProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaImageProcessor)
    (FLAVA 模型)'
- en: '`focalnet` — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor)
    (FocalNet model)'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`focalnet` — [BitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitImageProcessor)
    (FocalNet 模型)'
- en: '`fuyu` — [FuyuImageProcessor](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuImageProcessor)
    (Fuyu model)'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fuyu` — [FuyuImageProcessor](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuImageProcessor)
    (Fuyu 模型)'
- en: '`git` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (GIT model)'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (GIT 模型)'
- en: '`glpn` — [GLPNImageProcessor](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNImageProcessor)
    (GLPN model)'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glpn` — [GLPNImageProcessor](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNImageProcessor)
    (GLPN 模型)'
- en: '`groupvit` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (GroupViT model)'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupvit` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (GroupViT 模型)'
- en: '`idefics` — [IdeficsImageProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsImageProcessor)
    (IDEFICS model)'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`idefics` — [IdeficsImageProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsImageProcessor)
    (IDEFICS 模型)'
- en: '`imagegpt` — [ImageGPTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor)
    (ImageGPT model)'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imagegpt` — [ImageGPTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor)
    (ImageGPT 模型)'
- en: '`instructblip` — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor)
    (InstructBLIP model)'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instructblip` — [BlipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipImageProcessor)
    (InstructBLIP 模型)'
- en: '`kosmos-2` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (KOSMOS-2 model)'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kosmos-2` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (KOSMOS-2 模型)'
- en: '`layoutlmv2` — [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)
    (LayoutLMv2 model)'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor)
    (LayoutLMv2 模型)'
- en: '`layoutlmv3` — [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)
    (LayoutLMv3 model)'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor)
    (LayoutLMv3 模型)'
- en: '`levit` — [LevitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitImageProcessor)
    (LeViT model)'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`levit` — [LevitImageProcessor](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitImageProcessor)
    (LeViT 模型)'
- en: '`llava` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (LLaVa model)'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llava` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (LLaVa 模型)'
- en: '`mask2former` — [Mask2FormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor)
    (Mask2Former model)'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask2former` — [Mask2FormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerImageProcessor)
    (Mask2Former 模型)'
- en: '`maskformer` — [MaskFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerImageProcessor)
    (MaskFormer model)'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maskformer` — [MaskFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerImageProcessor)
    (MaskFormer 模型)'
- en: '`mgp-str` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (MGP-STR model)'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mgp-str` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (MGP-STR 模型)'
- en: '`mobilenet_v1` — [MobileNetV1ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ImageProcessor)
    (MobileNetV1 model)'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v1` — [MobileNetV1ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ImageProcessor)
    (MobileNetV1 模型)'
- en: '`mobilenet_v2` — [MobileNetV2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ImageProcessor)
    (MobileNetV2 model)'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v2` — [MobileNetV2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ImageProcessor)
    (MobileNetV2 模型)'
- en: '`mobilevit` — [MobileViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTImageProcessor)
    (MobileViT model)'
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevit` — [MobileViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTImageProcessor)
    (MobileViT 模型)'
- en: '`mobilevitv2` — [MobileViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTImageProcessor)
    (MobileViTV2 model)'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevitv2` — [MobileViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTImageProcessor)
    (MobileViTV2 模型)'
- en: '`nat` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (NAT model)'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nat` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (NAT 模型)'
- en: '`nougat` — [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    (Nougat model)'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nougat` — [NougatImageProcessor](/docs/transformers/v4.37.2/en/model_doc/nougat#transformers.NougatImageProcessor)
    (Nougat 模型)'
- en: '`oneformer` — [OneFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerImageProcessor)
    (OneFormer model)'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oneformer` — [OneFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerImageProcessor)
    (OneFormer 模型)'
- en: '`owlv2` — [Owlv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ImageProcessor)
    (OWLv2 model)'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlv2` — [Owlv2ImageProcessor](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ImageProcessor)
    (OWLv2 模型)'
- en: '`owlvit` — [OwlViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTImageProcessor)
    (OWL-ViT model)'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlvit` — [OwlViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTImageProcessor)
    (OWL-ViT 模型)'
- en: '`perceiver` — [PerceiverImageProcessor](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverImageProcessor)
    (Perceiver model)'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perceiver` — [PerceiverImageProcessor](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverImageProcessor)
    (Perceiver 模型)'
- en: '`pix2struct` — [Pix2StructImageProcessor](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructImageProcessor)
    (Pix2Struct model)'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pix2struct` — [Pix2StructImageProcessor](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructImageProcessor)
    (Pix2Struct 模型)'
- en: '`poolformer` — [PoolFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerImageProcessor)
    (PoolFormer model)'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`poolformer` — [PoolFormerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerImageProcessor)
    (PoolFormer 模型)'
- en: '`pvt` — [PvtImageProcessor](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtImageProcessor)
    (PVT model)'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pvt` — [PvtImageProcessor](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtImageProcessor)
    (PVT 模型)'
- en: '`regnet` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (RegNet model)'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regnet` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (RegNet 模型)'
- en: '`resnet` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (ResNet model)'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resnet` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (ResNet 模型)'
- en: '`sam` — [SamImageProcessor](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamImageProcessor)
    (SAM model)'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sam` — [SamImageProcessor](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamImageProcessor)
    (SAM 模型)'
- en: '`segformer` — [SegformerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerImageProcessor)
    (SegFormer model)'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segformer` — [SegformerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerImageProcessor)
    (SegFormer 模型)'
- en: '`siglip` — [SiglipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipImageProcessor)
    (SigLIP model)'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`siglip` — [SiglipImageProcessor](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipImageProcessor)
    (SigLIP 模型)'
- en: '`swiftformer` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (SwiftFormer model)'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swiftformer` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (SwiftFormer 模型)'
- en: '`swin` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (Swin Transformer model)'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (Swin Transformer model)'
- en: '`swin2sr` — [Swin2SRImageProcessor](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRImageProcessor)
    (Swin2SR model)'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin2sr` — [Swin2SRImageProcessor](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRImageProcessor)
    (Swin2SR model)'
- en: '`swinv2` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (Swin Transformer V2 model)'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swinv2` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (Swin Transformer V2 model)'
- en: '`table-transformer` — [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor)
    (Table Transformer model)'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table-transformer` — [DetrImageProcessor](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrImageProcessor)
    (Table Transformer model)'
- en: '`timesformer` — [VideoMAEImageProcessor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEImageProcessor)
    (TimeSformer model)'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesformer` — [VideoMAEImageProcessor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEImageProcessor)
    (TimeSformer model)'
- en: '`tvlt` — [TvltImageProcessor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltImageProcessor)
    (TVLT model)'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvlt` — [TvltImageProcessor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltImageProcessor)
    (TVLT model)'
- en: '`tvp` — [TvpImageProcessor](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpImageProcessor)
    (TVP model)'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvp` — [TvpImageProcessor](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpImageProcessor)
    (TVP model)'
- en: '`upernet` — [SegformerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerImageProcessor)
    (UPerNet model)'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upernet` — [SegformerImageProcessor](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerImageProcessor)
    (UPerNet model)'
- en: '`van` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (VAN model)'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`van` — [ConvNextImageProcessor](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextImageProcessor)
    (VAN model)'
- en: '`videomae` — [VideoMAEImageProcessor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEImageProcessor)
    (VideoMAE model)'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`videomae` — [VideoMAEImageProcessor](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEImageProcessor)
    (VideoMAE model)'
- en: '`vilt` — [ViltImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltImageProcessor)
    (ViLT model)'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vilt` — [ViltImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltImageProcessor)
    (ViLT model)'
- en: '`vipllava` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (VipLlava model)'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vipllava` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (VipLlava model)'
- en: '`vit` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (ViT model)'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (ViT model)'
- en: '`vit_hybrid` — [ViTHybridImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridImageProcessor)
    (ViT Hybrid model)'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_hybrid` — [ViTHybridImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridImageProcessor)
    (ViT Hybrid model)'
- en: '`vit_mae` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (ViTMAE model)'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_mae` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (ViTMAE model)'
- en: '`vit_msn` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (ViTMSN model)'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_msn` — [ViTImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTImageProcessor)
    (ViTMSN model)'
- en: '`vitmatte` — [VitMatteImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteImageProcessor)
    (ViTMatte model)'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vitmatte` — [VitMatteImageProcessor](/docs/transformers/v4.37.2/en/model_doc/vitmatte#transformers.VitMatteImageProcessor)
    (ViTMatte model)'
- en: '`xclip` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (X-CLIP model)'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xclip` — [CLIPImageProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor)
    (X-CLIP model)'
- en: '`yolos` — [YolosImageProcessor](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosImageProcessor)
    (YOLOS model)'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yolos` — [YolosImageProcessor](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosImageProcessor)
    (YOLOS model)'
- en: Passing `token=True` is required when you want to use a private model.
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想使用私有模型时，需要传递`token=True`。
- en: 'Examples:'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE16]'
  id: totrans-684
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#### `register`'
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L422)'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/image_processing_auto.py#L422)'
- en: '[PRE17]'
  id: totrans-687
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parameters
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration corresponding to the model to register.'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 与要注册的模型对应的配置。'
- en: '`image_processor_class` ([ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin))
    — The image processor to register.'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_processor_class` ([ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin))
    — 要注册的图像处理器。'
- en: Register a new image processor for this class.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 为这个类注册一个新的图像处理器。
- en: AutoProcessor
  id: totrans-692
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoProcessor
- en: '### `class transformers.AutoProcessor`'
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L129)'
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L129)'
- en: '[PRE18]'
  id: totrans-695
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This is a generic processor class that will be instantiated as one of the processor
    classes of the library when created with the [AutoProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoProcessor.from_pretrained)
    class method.
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的处理器类，在使用[AutoProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoProcessor.from_pretrained)类方法创建时，将作为库的处理器类之一实例化。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_pretrained`'
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L143)'
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L143)'
- en: '[PRE19]'
  id: totrans-700
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 这可以是：'
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-703
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练特征提取器的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: a path to a *directory* containing a processor files saved using the `save_pretrained()`
    method, e.g., `./my_model_directory/`.
  id: totrans-704
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用`save_pretrained()`方法保存的处理器文件，例如`./my_model_directory/`。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model feature extractor should be cached if the standard
    cache should not be used.'
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*） — 下载的预训练模型特征提取器应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force to (re-)download the feature extractor files and override the cached
    versions if they exist.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`） — 是否强制（重新）下载特征提取器文件并覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received file. Attempts to resume the download if such
    a file exists.'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`） — 是否删除接收不完整的文件。如果存在这样的文件，则尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}.` The proxies are used on each request.'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*） — 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128''，''http://hostname'':
    ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`token` (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization
    for remote files. If `True`, will use the token generated when running `huggingface-cli
    login` (stored in `~/.huggingface`).'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`（`str`或*bool*，*可选*） — 用作远程文件的HTTP bearer授权的令牌。如果为`True`，将使用运行`huggingface-cli
    login`时生成的令牌（存储在`~/.huggingface`）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`） — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`return_unused_kwargs` (`bool`, *optional*, defaults to `False`) — If `False`,
    then this function returns just the final feature extractor object. If `True`,
    then this functions returns a `Tuple(feature_extractor, unused_kwargs)` where
    *unused_kwargs* is a dictionary consisting of the key/value pairs whose keys are
    not feature extractor attributes: i.e., the part of `kwargs` which has not been
    used to update `feature_extractor` and is otherwise ignored.'
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_unused_kwargs`（`bool`，*可选*，默认为`False`） — 如果为`False`，则此函数仅返回最终特征提取器对象。如果为`True`，则此函数返回一个`Tuple(feature_extractor,
    unused_kwargs)`，其中*unused_kwargs*是一个字典，包含未使用的键/值对，这些键不是特征提取器属性：即`kwargs`的一部分，未用于更新`feature_extractor`且被忽略。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在Hub上定义自定义模型的代码。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地计算机上执行Hub上存在的代码。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — The values in kwargs of any keys
    which are feature extractor attributes will be used to override the loaded values.
    Behavior concerning key/value pairs whose keys are *not* feature extractor attributes
    is controlled by the `return_unused_kwargs` keyword parameter.'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（`Dict[str, Any]`，*可选*） — 任何键为特征提取器属性的kwargs中的值将用于覆盖加载的值。关于键/值对中键不是特征提取器属性的行为由`return_unused_kwargs`关键字参数控制。'
- en: Instantiate one of the processor classes of the library from a pretrained model
    vocabulary.
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型词汇表中实例化库中的处理器类之一。
- en: 'The processor class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible):'
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的处理器类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载）：
- en: '`align` — [AlignProcessor](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignProcessor)
    (ALIGN model)'
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`align` — [AlignProcessor](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignProcessor)（ALIGN模型）'
- en: '`altclip` — [AltCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPProcessor)
    (AltCLIP model)'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`altclip` — [AltCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPProcessor)（AltCLIP模型）'
- en: '`bark` — [BarkProcessor](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor)
    (Bark model)'
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bark` — [BarkProcessor](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkProcessor)（Bark模型）'
- en: '`blip` — [BlipProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipProcessor)
    (BLIP model)'
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [BlipProcessor](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipProcessor)（BLIP模型）'
- en: '`blip-2` — [Blip2Processor](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Processor)
    (BLIP-2 model)'
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip-2` — [Blip2Processor](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Processor)（BLIP-2模型）'
- en: '`bridgetower` — [BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)
    (BridgeTower model)'
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bridgetower` — [BridgeTowerProcessor](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerProcessor)（BridgeTower模型）'
- en: '`chinese_clip` — [ChineseCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPProcessor)
    (Chinese-CLIP model)'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chinese_clip` — [ChineseCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPProcessor)（Chinese-CLIP模型）'
- en: '`clap` — [ClapProcessor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapProcessor)
    (CLAP model)'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clap` — [ClapProcessor](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapProcessor)
    (CLAP 模型)'
- en: '`clip` — [CLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor)
    (CLIP model)'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [CLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor)
    (CLIP 模型)'
- en: '`clipseg` — [CLIPSegProcessor](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegProcessor)
    (CLIPSeg model)'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clipseg` — [CLIPSegProcessor](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegProcessor)
    (CLIPSeg 模型)'
- en: '`clvp` — [ClvpProcessor](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpProcessor)
    (CLVP model)'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clvp` — [ClvpProcessor](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpProcessor)
    (CLVP 模型)'
- en: '`flava` — [FlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaProcessor)
    (FLAVA model)'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flava` — [FlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaProcessor)
    (FLAVA 模型)'
- en: '`fuyu` — [FuyuProcessor](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuProcessor)
    (Fuyu model)'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fuyu` — [FuyuProcessor](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuProcessor)
    (Fuyu 模型)'
- en: '`git` — [GitProcessor](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitProcessor)
    (GIT model)'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` — [GitProcessor](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitProcessor)
    (GIT 模型)'
- en: '`groupvit` — [CLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor)
    (GroupViT model)'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupvit` — [CLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPProcessor)
    (GroupViT 模型)'
- en: '`hubert` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (Hubert model)'
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hubert` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (Hubert 模型)'
- en: '`idefics` — [IdeficsProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsProcessor)
    (IDEFICS model)'
  id: totrans-732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`idefics` — [IdeficsProcessor](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsProcessor)
    (IDEFICS 模型)'
- en: '`instructblip` — [InstructBlipProcessor](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipProcessor)
    (InstructBLIP model)'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instructblip` — [InstructBlipProcessor](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipProcessor)
    (InstructBLIP 模型)'
- en: '`kosmos-2` — [Kosmos2Processor](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Processor)
    (KOSMOS-2 model)'
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kosmos-2` — [Kosmos2Processor](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Processor)
    (KOSMOS-2 模型)'
- en: '`layoutlmv2` — [LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)
    (LayoutLMv2 model)'
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor)
    (LayoutLMv2 模型)'
- en: '`layoutlmv3` — [LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)
    (LayoutLMv3 model)'
  id: totrans-736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3Processor](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor)
    (LayoutLMv3 模型)'
- en: '`llava` — [LlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaProcessor)
    (LLaVa model)'
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llava` — [LlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaProcessor)
    (LLaVa 模型)'
- en: '`markuplm` — [MarkupLMProcessor](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMProcessor)
    (MarkupLM model)'
  id: totrans-738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`markuplm` — [MarkupLMProcessor](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMProcessor)
    (MarkupLM 模型)'
- en: '`mctct` — [MCTCTProcessor](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTProcessor)
    (M-CTC-T model)'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mctct` — [MCTCTProcessor](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTProcessor)
    (M-CTC-T 模型)'
- en: '`mgp-str` — [MgpstrProcessor](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor)
    (MGP-STR model)'
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mgp-str` — [MgpstrProcessor](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrProcessor)
    (MGP-STR 模型)'
- en: '`oneformer` — [OneFormerProcessor](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerProcessor)
    (OneFormer model)'
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oneformer` — [OneFormerProcessor](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerProcessor)
    (OneFormer 模型)'
- en: '`owlv2` — [Owlv2Processor](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Processor)
    (OWLv2 model)'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlv2` — [Owlv2Processor](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Processor)
    (OWLv2 模型)'
- en: '`owlvit` — [OwlViTProcessor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTProcessor)
    (OWL-ViT model)'
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlvit` — [OwlViTProcessor](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTProcessor)
    (OWL-ViT 模型)'
- en: '`pix2struct` — [Pix2StructProcessor](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructProcessor)
    (Pix2Struct model)'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pix2struct` — [Pix2StructProcessor](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructProcessor)
    (Pix2Struct 模型)'
- en: '`pop2piano` — [Pop2PianoProcessor](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoProcessor)
    (Pop2Piano model)'
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pop2piano` — [Pop2PianoProcessor](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoProcessor)
    (Pop2Piano 模型)'
- en: '`sam` — [SamProcessor](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamProcessor)
    (SAM model)'
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sam` — [SamProcessor](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamProcessor)
    (SAM 模型)'
- en: '`seamless_m4t` — [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)
    (SeamlessM4T model)'
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t` — [SeamlessM4TProcessor](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TProcessor)
    (SeamlessM4T 模型)'
- en: '`sew` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (SEW model)'
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (SEW 模型)'
- en: '`sew-d` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (SEW-D model)'
  id: totrans-749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew-d` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (SEW-D 模型)'
- en: '`siglip` — [SiglipProcessor](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipProcessor)
    (SigLIP model)'
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`siglip` — [SiglipProcessor](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipProcessor)
    (SigLIP 模型)'
- en: '`speech_to_text` — [Speech2TextProcessor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextProcessor)
    (Speech2Text model)'
  id: totrans-751
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text` — [Speech2TextProcessor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextProcessor)
    (Speech2Text 模型)'
- en: '`speech_to_text_2` — [Speech2Text2Processor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor)
    (Speech2Text2 model)'
  id: totrans-752
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text_2` — [Speech2Text2Processor](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor)
    (Speech2Text2 模型)'
- en: '`speecht5` — [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)
    (SpeechT5 model)'
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speecht5` — [SpeechT5Processor](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Processor)
    (SpeechT5 模型)'
- en: '`trocr` — [TrOCRProcessor](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor)
    (TrOCR model)'
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trocr` — [TrOCRProcessor](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRProcessor)（TrOCR模型）'
- en: '`tvlt` — [TvltProcessor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltProcessor)
    (TVLT model)'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvlt` — [TvltProcessor](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltProcessor)（TVLT模型）'
- en: '`tvp` — [TvpProcessor](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpProcessor)
    (TVP model)'
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvp` — [TvpProcessor](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpProcessor)（TVP模型）'
- en: '`unispeech` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (UniSpeech model)'
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（UniSpeech模型）'
- en: '`unispeech-sat` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (UniSpeechSat model)'
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech-sat` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（UniSpeechSat模型）'
- en: '`vilt` — [ViltProcessor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltProcessor)
    (ViLT model)'
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vilt` — [ViltProcessor](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltProcessor)（ViLT模型）'
- en: '`vipllava` — [LlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaProcessor)
    (VipLlava model)'
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vipllava` — [LlavaProcessor](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaProcessor)（VipLlava模型）'
- en: '`vision-text-dual-encoder` — [VisionTextDualEncoderProcessor](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor)
    (VisionTextDualEncoder model)'
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision-text-dual-encoder` — [VisionTextDualEncoderProcessor](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor)（VisionTextDualEncoder模型）'
- en: '`wav2vec2` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (Wav2Vec2 model)'
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（Wav2Vec2模型）'
- en: '`wav2vec2-bert` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (Wav2Vec2-BERT model)'
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-bert` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（Wav2Vec2-BERT模型）'
- en: '`wav2vec2-conformer` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (Wav2Vec2-Conformer model)'
  id: totrans-764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（Wav2Vec2-Conformer模型）'
- en: '`wavlm` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)
    (WavLM model)'
  id: totrans-765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wavlm` — [Wav2Vec2Processor](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor)（WavLM模型）'
- en: '`whisper` — [WhisperProcessor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor)
    (Whisper model)'
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [WhisperProcessor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor)（Whisper模型）'
- en: '`xclip` — [XCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPProcessor)
    (X-CLIP model)'
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xclip` — [XCLIPProcessor](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPProcessor)（X-CLIP模型）'
- en: Passing `token=True` is required when you want to use a private model.
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想使用私有模型时，需要传递`token=True`。
- en: 'Examples:'
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE20]'
  id: totrans-770
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#### `register`'
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `register`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L347)'
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/processing_auto.py#L347)'
- en: '[PRE21]'
  id: totrans-773
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config_class` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration corresponding to the model to register.'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config_class`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 与要注册的模型对应的配置。'
- en: '`processor_class` (`FeatureExtractorMixin`) — The processor to register.'
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`processor_class` (`FeatureExtractorMixin`) — 要注册的处理器。'
- en: Register a new processor for this class.
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: 为这个类注册一个新的处理器。
- en: Generic model classes
  id: totrans-778
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通用模型类
- en: The following auto classes are available for instantiating a base model class
    without a specific head.
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: 以下自动类可用于实例化一个基本模型类，而无需特定头部。
- en: AutoModel
  id: totrans-780
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModel
- en: '### `class transformers.AutoModel`'
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1304)'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1304)'
- en: '[PRE22]'
  id: totrans-783
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This is a generic model class that will be instantiated as one of the base model
    classes of the library when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的基本模型类之一实例化。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE23]'
  id: totrans-788
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 选择要实例化的模型类基于配置类：'
- en: '[ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)
    configuration class: [ASTModel](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTModel)
    (Audio Spectrogram Transformer model)'
  id: totrans-791
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)配置类：[ASTModel](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTModel)（音频频谱变换器模型）'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertModel)
    (ALBERT model)'
  id: totrans-792
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[AlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertModel)（ALBERT模型）'
- en: '[AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)
    configuration class: [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN model)'
  id: totrans-793
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)
    配置类: [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN 模型)'
- en: '[AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)
    configuration class: [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP model)'
  id: totrans-794
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)
    配置类: [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP 模型)'
- en: '[AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)
    configuration class: [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel)
    (Autoformer model)'
  id: totrans-795
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AutoformerConfig](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerConfig)
    配置类: [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel)
    (Autoformer 模型)'
- en: '[BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)
    configuration class: [BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel)
    (Bark model)'
  id: totrans-796
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BarkConfig](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkConfig)
    配置类: [BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel)
    (Bark 模型)'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartModel)
    (BART model)'
  id: totrans-797
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    配置类: [BartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartModel)
    (BART 模型)'
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [BeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitModel)
    (BEiT model)'
  id: totrans-798
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    配置类: [BeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitModel)
    (BEiT 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel)
    (BERT model)'
  id: totrans-799
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类: [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel)
    (BERT 模型)'
- en: '[BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)
    configuration class: [BertGenerationEncoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder)
    (Bert Generation model)'
  id: totrans-800
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)
    配置类: [BertGenerationEncoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder)
    (Bert Generation 模型)'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdModel)
    (BigBird model)'
  id: totrans-801
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    配置类: [BigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdModel)
    (BigBird 模型)'
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusModel](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel)
    (BigBird-Pegasus model)'
  id: totrans-802
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    配置类: [BigBirdPegasusModel](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel)
    (BigBird-Pegasus 模型)'
- en: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    configuration class: [BioGptModel](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptModel)
    (BioGpt model)'
  id: totrans-803
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    配置类: [BioGptModel](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptModel)
    (BioGpt 模型)'
- en: '[BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig)
    configuration class: [BitModel](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitModel)
    (BiT model)'
  id: totrans-804
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig)
    配置类: [BitModel](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitModel)
    (BiT 模型)'
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [BlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotModel)
    (Blenderbot model)'
  id: totrans-805
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    配置类: [BlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotModel)
    (Blenderbot 模型)'
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [BlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel)
    (BlenderbotSmall model)'
  id: totrans-806
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    配置类: [BlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel)
    (BlenderbotSmall 模型)'
- en: '[Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    configuration class: [Blip2Model](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Model)
    (BLIP-2 model)'
  id: totrans-807
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    配置类: [Blip2Model](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Model)
    (BLIP-2 模型)'
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP model)'
  id: totrans-808
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    配置类: [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP 模型)'
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomModel)
    (BLOOM model)'
  id: totrans-809
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    配置类: [BloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomModel)
    (BLOOM 模型)'
- en: '[BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)
    configuration class: [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)
    (BridgeTower model)'
  id: totrans-810
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BridgeTowerConfig](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerConfig)
    配置类: [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)
    (BridgeTower 模型)'
- en: '[BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig)
    configuration class: [BrosModel](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosModel)
    (BROS model)'
  id: totrans-811
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig)
    配置类: [BrosModel](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosModel)
    (BROS 模型)'
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP model)'
  id: totrans-812
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    配置类: [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP 模型)'
- en: '[CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig)
    configuration class: [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg model)'
  id: totrans-813
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig)
    配置类: [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg 模型)'
- en: '[CLIPVisionConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionConfig)
    configuration class: [CLIPVisionModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel)
    (CLIPVisionModel model)'
  id: totrans-814
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CLIPVisionConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionConfig)
    配置类: [CLIPVisionModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel)
    (CLIPVisionModel 模型)'
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [CTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLModel)
    (CTRL model)'
  id: totrans-815
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    配置类: [CTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLModel)
    (CTRL 模型)'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertModel)
    (CamemBERT model)'
  id: totrans-816
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    配置类: [CamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertModel)
    (CamemBERT 模型)'
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineModel](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineModel)
    (CANINE model)'
  id: totrans-817
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    配置类: [CanineModel](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineModel)
    (CANINE 模型)'
- en: '[ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig)
    configuration class: [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP model)'
  id: totrans-818
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig)
    配置类: [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP 模型)'
- en: '[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)
    configuration class: [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    (CLAP model)'
  id: totrans-819
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ClapConfig](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapConfig)
    配置类: [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    (CLAP 模型)'
- en: '[ClvpConfig](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpConfig)
    configuration class: [ClvpModelForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpModelForConditionalGeneration)
    (CLVP model)'
  id: totrans-820
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ClvpConfig](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpConfig)
    配置类: [ClvpModelForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpModelForConditionalGeneration)
    (CLVP 模型)'
- en: '[CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig)
    configuration class: [CodeGenModel](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenModel)
    (CodeGen model)'
  id: totrans-821
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig)
    配置类: [CodeGenModel](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenModel)
    (CodeGen 模型)'
- en: '[ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig)
    configuration class: [ConditionalDetrModel](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrModel)
    (Conditional DETR model)'
  id: totrans-822
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig)
    配置类: [ConditionalDetrModel](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrModel)
    (Conditional DETR 模型)'
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertModel)
    (ConvBERT model)'
  id: totrans-823
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    配置类: [ConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertModel)
    (ConvBERT 模型)'
- en: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    configuration class: [ConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextModel)
    (ConvNeXT model)'
  id: totrans-824
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    配置类: [ConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextModel)
    (ConvNeXT 模型)'
- en: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    configuration class: [ConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Model)
    (ConvNeXTV2 model)'
  id: totrans-825
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    配置类: [ConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Model)
    (ConvNeXTV2 模型)'
- en: '[CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig)
    configuration class: [CpmAntModel](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntModel)
    (CPM-Ant model)'
  id: totrans-826
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig)
    配置类: [CpmAntModel](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntModel)
    (CPM-Ant 模型)'
- en: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    configuration class: [CvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtModel)
    (CvT model)'
  id: totrans-827
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    配置类: [CvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtModel)
    (CvT 模型)'
- en: '[DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig)
    configuration class: [DPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoder)
    (DPR model)'
  id: totrans-828
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig)
    配置类: [DPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoder)
    (DPR 模型)'
- en: '[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    configuration class: [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel)
    (DPT model)'
  id: totrans-829
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    配置类: [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel)
    (DPT 模型)'
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioModel)
    (Data2VecAudio model)'
  id: totrans-830
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    配置类: [Data2VecAudioModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioModel)
    (Data2VecAudio 模型)'
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextModel)
    (Data2VecText model)'
  id: totrans-831
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    配置类: [Data2VecTextModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextModel)
    (Data2VecText 模型)'
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [Data2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionModel)
    (Data2VecVision model)'
  id: totrans-832
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    配置类: [Data2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionModel)
    (Data2VecVision 模型)'
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaModel)
    (DeBERTa model)'
  id: totrans-833
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    配置类: [DebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaModel)
    (DeBERTa 模型)'
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Model)
    (DeBERTa-v2 model)'
  id: totrans-834
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    配置类: [DebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Model)
    (DeBERTa-v2 模型)'
- en: '[DecisionTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig)
    configuration class: [DecisionTransformerModel](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerModel)
    (Decision Transformer model)'
  id: totrans-835
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DecisionTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig)
    配置类: [DecisionTransformerModel](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerModel)
    (Decision Transformer 模型)'
- en: '[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)
    configuration class: [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)
    (Deformable DETR model)'
  id: totrans-836
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)
    配置类: [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)
    (Deformable DETR 模型)'
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel)
    (DeiT model)'
  id: totrans-837
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    配置类: [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel)
    (DeiT 模型)'
- en: '[DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)
    configuration class: [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)
    (DETA model)'
  id: totrans-838
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)
    配置类: [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)
    (DETA 模型)'
- en: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    configuration class: [DetrModel](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrModel)
    (DETR model)'
  id: totrans-839
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    配置类: [DetrModel](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrModel)
    (DETR 模型)'
- en: '[DinatConfig](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatConfig)
    configuration class: [DinatModel](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatModel)
    (DiNAT model)'
  id: totrans-840
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DinatConfig](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatConfig)
    配置类: [DinatModel](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatModel)
    (DiNAT 模型)'
- en: '[Dinov2Config](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Config)
    configuration class: [Dinov2Model](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Model)
    (DINOv2 model)'
  id: totrans-841
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Dinov2Config](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Config)
    配置类: [Dinov2Model](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Model)
    (DINOv2 模型)'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertModel)
    (DistilBERT model)'
  id: totrans-842
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [DistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertModel)
    (DistilBERT 模型)'
- en: '[DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig)
    configuration class: [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel)
    (DonutSwin model)'
  id: totrans-843
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DonutSwinConfig](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinConfig)
    配置类: [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel)
    (DonutSwin 模型)'
- en: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    configuration class: [EfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerModel)
    (EfficientFormer model)'
  id: totrans-844
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    配置类: [EfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerModel)
    (EfficientFormer 模型)'
- en: '[EfficientNetConfig](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetConfig)
    configuration class: [EfficientNetModel](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetModel)
    (EfficientNet model)'
  id: totrans-845
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EfficientNetConfig](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetConfig)
    配置类: [EfficientNetModel](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetModel)
    (EfficientNet 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraModel)
    (ELECTRA model)'
  id: totrans-846
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [ElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraModel)
    (ELECTRA 模型)'
- en: '[EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig)
    configuration class: [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)
    (EnCodec model)'
  id: totrans-847
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EncodecConfig](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecConfig)
    配置类: [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)
    (EnCodec 模型)'
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieModel](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieModel)
    (ERNIE model)'
  id: totrans-848
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    配置类: [ErnieModel](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieModel)
    (ERNIE 模型)'
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMModel](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMModel)
    (ErnieM model)'
  id: totrans-849
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    配置类: [ErnieMModel](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMModel)
    (ErnieM 模型)'
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [EsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmModel)
    (ESM model)'
  id: totrans-850
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    配置类: [EsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmModel)
    (ESM 模型)'
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    (FNet model)'
  id: totrans-851
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    配置类: [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    (FNet 模型)'
- en: '[FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    configuration class: [FSMTModel](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTModel)
    (FairSeq Machine-Translation model)'
  id: totrans-852
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    配置类: [FSMTModel](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTModel)
    (FairSeq 机器翻译模型)'
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconModel](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconModel)
    (Falcon model)'
  id: totrans-853
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    配置类: [FalconModel](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconModel)
    (Falcon 模型)'
- en: '[FastSpeech2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerConfig)
    configuration class: [FastSpeech2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerModel)
    (FastSpeech2Conformer model)'
  id: totrans-854
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FastSpeech2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerConfig)
    配置类: [FastSpeech2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerModel)
    (FastSpeech2Conformer 模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertModel)
    (FlauBERT model)'
  id: totrans-855
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [FlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertModel)
    (FlauBERT 模型)'
- en: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    configuration class: [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    (FLAVA model)'
  id: totrans-856
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    配置类: [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    (FLAVA 模型)'
- en: '[FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)
    configuration class: [FocalNetModel](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetModel)
    (FocalNet model)'
  id: totrans-857
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)
    配置类: [FocalNetModel](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetModel)
    (FocalNet 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelModel)
    or [FunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelBaseModel)
    (Funnel Transformer model)'
  id: totrans-858
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [FunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelModel)
    或 [FunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelBaseModel)
    (Funnel Transformer 模型)'
- en: '[GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig)
    configuration class: [GLPNModel](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNModel)
    (GLPN model)'
  id: totrans-859
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig)
    配置类: [GLPNModel](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNModel)
    (GLPN 模型)'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model)
    (OpenAI GPT-2 model)'
  id: totrans-860
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    配置类: [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model)
    (OpenAI GPT-2 模型)'
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeModel](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeModel)
    (GPTBigCode model)'
  id: totrans-861
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    配置类: [GPTBigCodeModel](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeModel)
    (GPTBigCode 模型)'
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [GPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJModel)
    (GPT-J model)'
  id: totrans-862
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    配置类: [GPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJModel)
    (GPT-J 模型)'
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoModel)
    (GPT Neo model)'
  id: totrans-863
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    配置类: [GPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoModel)
    (GPT Neo 模型)'
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXModel)
    (GPT NeoX model)'
  id: totrans-864
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    配置类: [GPTNeoXModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXModel)
    (GPT NeoX 模型)'
- en: '[GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig)
    configuration class: [GPTNeoXJapaneseModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel)
    (GPT NeoX Japanese model)'
  id: totrans-865
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig)
    配置类: [GPTNeoXJapaneseModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel)
    (GPT NeoX 日语模型)'
- en: '[GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    configuration class: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  id: totrans-866
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    配置类: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese 模型)'
- en: '[GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    configuration class: [GitModel](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitModel)
    (GIT model)'
  id: totrans-867
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    配置类: [GitModel](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitModel)
    (GIT 模型)'
- en: '[GraphormerConfig](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerConfig)
    configuration class: [GraphormerModel](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerModel)
    (Graphormer model)'
  id: totrans-868
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GraphormerConfig](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerConfig)
    配置类: [GraphormerModel](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerModel)
    (Graphormer 模型)'
- en: '[GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)
    configuration class: [GroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTModel)
    (GroupViT model)'
  id: totrans-869
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)
    配置类: [GroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTModel)
    (GroupViT 模型)'
- en: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    configuration class: [HubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertModel)
    (Hubert model)'
  id: totrans-870
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    配置类: [HubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertModel)
    (Hubert 模型)'
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertModel](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertModel)
    (I-BERT model)'
  id: totrans-871
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    配置类: [IBertModel](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertModel)
    (I-BERT 模型)'
- en: '[IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)
    configuration class: [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)
    (IDEFICS model)'
  id: totrans-872
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)
    配置类: [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)
    (IDEFICS 模型)'
- en: '[ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig)
    configuration class: [ImageGPTModel](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTModel)
    (ImageGPT model)'
  id: totrans-873
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig)
    配置类: [ImageGPTModel](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTModel)
    (ImageGPT 模型)'
- en: '[InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig)
    configuration class: [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel)
    (Informer model)'
  id: totrans-874
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig)
    配置类: [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel)
    (Informer 模型)'
- en: '[JukeboxConfig](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxConfig)
    configuration class: [JukeboxModel](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxModel)
    (Jukebox model)'
  id: totrans-875
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[JukeboxConfig](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxConfig)
    配置类: [JukeboxModel](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxModel)
    (Jukebox 模型)'
- en: '[Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config)
    configuration class: [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model)
    (KOSMOS-2 model)'
  id: totrans-876
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config)
    配置类: [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model)
    (KOSMOS-2 模型)'
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [LEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDModel)
    (LED model)'
  id: totrans-877
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    配置类: [LEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDModel)
    (LED 模型)'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)
    (LayoutLM model)'
  id: totrans-878
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类: [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)
    (LayoutLM 模型)'
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    (LayoutLMv2 model)'
  id: totrans-879
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    配置类: [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    (LayoutLMv2 模型)'
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)
    (LayoutLMv3 model)'
  id: totrans-880
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    配置类: [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)
    (LayoutLMv3 模型)'
- en: '[LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig)
    configuration class: [LevitModel](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitModel)
    (LeViT model)'
  id: totrans-881
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig)
    配置类: [LevitModel](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitModel)
    (LeViT 模型)'
- en: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    configuration class: [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)
    (LiLT model)'
  id: totrans-882
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    配置类: [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)
    (LiLT 模型)'
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel)
    (LLaMA model)'
  id: totrans-883
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    配置类: [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel)
    (LLaMA 模型)'
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [LongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Model)
    (LongT5 model)'
  id: totrans-884
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    配置类: [LongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Model)
    (LongT5 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerModel)
    (Longformer model)'
  id: totrans-885
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [LongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerModel)
    (Longformer 模型)'
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeModel](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeModel)
    (LUKE model)'
  id: totrans-886
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    配置类: [LukeModel](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeModel)
    (LUKE 模型)'
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    (LXMERT model)'
  id: totrans-887
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    配置类: [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    (LXMERT 模型)'
- en: '[M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)
    configuration class: [M2M100Model](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Model)
    (M2M100 model)'
  id: totrans-888
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)
    配置类: [M2M100Model](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Model)
    (M2M100 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartModel)
    (mBART model)'
  id: totrans-889
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类: [MBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartModel)
    (mBART 模型)'
- en: '[MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)
    configuration class: [MCTCTModel](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTModel)
    (M-CTC-T model)'
  id: totrans-890
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)
    配置类: [MCTCTModel](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTModel)
    (M-CTC-T 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetModel)
    (MPNet model)'
  id: totrans-891
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [MPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetModel)
    (MPNet 模型)'
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [MT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Model)
    (MT5 model)'
  id: totrans-892
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    配置类: [MT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Model)
    (MT5 模型)'
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [MarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianModel)
    (Marian model)'
  id: totrans-893
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    配置类: [MarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianModel)
    (Marian 模型)'
- en: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    configuration class: [MarkupLMModel](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMModel)
    (MarkupLM model)'
  id: totrans-894
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    配置类: [MarkupLMModel](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMModel)
    (MarkupLM 模型)'
- en: '[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)
    configuration class: [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)
    (Mask2Former model)'
  id: totrans-895
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)
    配置类: [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)
    (Mask2Former 模型)'
- en: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    configuration class: [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)
    (MaskFormer model)'
  id: totrans-896
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    配置类: [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)
    (MaskFormer 模型)'
- en: '`MaskFormerSwinConfig` configuration class: `MaskFormerSwinModel` (MaskFormerSwin
    model)'
  id: totrans-897
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MaskFormerSwinConfig` 配置类: `MaskFormerSwinModel` (MaskFormerSwin 模型)'
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaModel](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaModel)
    (MEGA model)'
  id: totrans-898
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    配置类: [MegaModel](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaModel)
    (MEGA 模型)'
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertModel](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertModel)
    (Megatron-BERT model)'
  id: totrans-899
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    配置类: [MegatronBertModel](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertModel)
    (Megatron-BERT 模型)'
- en: '[MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig)
    configuration class: [MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition)
    (MGP-STR model)'
  id: totrans-900
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MgpstrConfig](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrConfig)
    配置类: [MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition)
    (MGP-STR 模型)'
- en: '[MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    configuration class: [MistralModel](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralModel)
    (Mistral model)'
  id: totrans-901
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    配置类: [MistralModel](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralModel)
    (Mistral 模型)'
- en: '[MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    configuration class: [MixtralModel](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralModel)
    (Mixtral model)'
  id: totrans-902
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    配置类: [MixtralModel](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralModel)
    (Mixtral 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertModel)
    (MobileBERT model)'
  id: totrans-903
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [MobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertModel)
    (MobileBERT 模型)'
- en: '[MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config)
    configuration class: [MobileNetV1Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Model)
    (MobileNetV1 model)'
  id: totrans-904
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config)
    配置类: [MobileNetV1Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Model)
    (MobileNetV1 模型)'
- en: '[MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    configuration class: [MobileNetV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model)
    (MobileNetV2 model)'
  id: totrans-905
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    配置类: [MobileNetV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model)
    (MobileNetV2 模型)'
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [MobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTModel)
    (MobileViT model)'
  id: totrans-906
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    配置类: [MobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTModel)
    (MobileViT 模型)'
- en: '[MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    configuration class: [MobileViTV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Model)
    (MobileViTV2 model)'
  id: totrans-907
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    配置类: [MobileViTV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Model)
    (MobileViTV2 模型)'
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptModel](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptModel)
    (MPT model)'
  id: totrans-908
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    配置类: [MptModel](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptModel)
    (MPT 模型)'
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraModel](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraModel)
    (MRA model)'
  id: totrans-909
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    配置类: [MraModel](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraModel)
    (MRA 模型)'
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpModel](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpModel)
    (MVP model)'
  id: totrans-910
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    配置类: [MvpModel](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpModel)
    (MVP 模型)'
- en: '[NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig)
    configuration class: [NatModel](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatModel)
    (NAT model)'
  id: totrans-911
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig)
    配置类: [NatModel](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatModel)
    (NAT 模型)'
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaModel](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaModel)
    (Nezha model)'
  id: totrans-912
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    配置类: [NezhaModel](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaModel)
    (Nezha 模型)'
- en: '[NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    configuration class: [NllbMoeModel](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeModel)
    (NLLB-MOE model)'
  id: totrans-913
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    配置类: [NllbMoeModel](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeModel)
    (NLLB-MOE 模型)'
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerModel](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerModel)
    (Nyströmformer model)'
  id: totrans-914
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    配置类: [NystromformerModel](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerModel)
    (Nyströmformer 模型)'
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [OPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTModel)
    (OPT model)'
  id: totrans-915
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    配置类: [OPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTModel)
    (OPT 模型)'
- en: '[OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)
    configuration class: [OneFormerModel](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerModel)
    (OneFormer model)'
  id: totrans-916
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)
    配置类: [OneFormerModel](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerModel)
    (OneFormer 模型)'
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [OpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel)
    (OpenAI GPT model)'
  id: totrans-917
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    配置类: [OpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel)
    (OpenAI GPT 模型)'
- en: '[OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    configuration class: [OpenLlamaModel](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaModel)
    (OpenLlama model)'
  id: totrans-918
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    配置类: [OpenLlamaModel](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaModel)
    (OpenLlama 模型)'
- en: '[OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)
    configuration class: [OwlViTModel](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTModel)
    (OWL-ViT model)'
  id: totrans-919
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)
    配置类: [OwlViTModel](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTModel)
    (OWL-ViT 模型)'
- en: '[Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)
    configuration class: [Owlv2Model](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Model)
    (OWLv2 model)'
  id: totrans-920
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)
    配置类: [Owlv2Model](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Model)
    (OWLv2 模型)'
- en: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    configuration class: [PLBartModel](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartModel)
    (PLBart model)'
  id: totrans-921
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    配置类: [PLBartModel](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartModel)
    (PLBart 模型)'
- en: '[PatchTSMixerConfig](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerConfig)
    configuration class: [PatchTSMixerModel](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerModel)
    (PatchTSMixer model)'
  id: totrans-922
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PatchTSMixerConfig](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerConfig)
    配置类: [PatchTSMixerModel](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerModel)
    (PatchTSMixer 模型)'
- en: '[PatchTSTConfig](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTConfig)
    configuration class: [PatchTSTModel](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTModel)
    (PatchTST model)'
  id: totrans-923
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PatchTSTConfig](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTConfig)
    配置类: [PatchTSTModel](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTModel)
    (PatchTST 模型)'
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [PegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusModel)
    (Pegasus model)'
  id: totrans-924
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    配置类: [PegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusModel)
    (Pegasus 模型)'
- en: '[PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig)
    configuration class: [PegasusXModel](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXModel)
    (PEGASUS-X model)'
  id: totrans-925
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig)
    配置类: [PegasusXModel](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXModel)
    (PEGASUS-X 模型)'
- en: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    configuration class: [PerceiverModel](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverModel)
    (Perceiver model)'
  id: totrans-926
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    配置类: [PerceiverModel](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverModel)
    (Perceiver 模型)'
- en: '[PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    configuration class: [PersimmonModel](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonModel)
    (Persimmon model)'
  id: totrans-927
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    配置类: [PersimmonModel](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonModel)
    (Persimmon 模型)'
- en: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    configuration class: [PhiModel](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiModel)
    (Phi model)'
  id: totrans-928
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    配置类: [PhiModel](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiModel)
    (Phi 模型)'
- en: '[PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)
    configuration class: [PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel)
    (PoolFormer model)'
  id: totrans-929
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)
    配置类: [PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel)
    (PoolFormer 模型)'
- en: '[ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    configuration class: [ProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetModel)
    (ProphetNet model)'
  id: totrans-930
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    配置类: [ProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetModel)
    (ProphetNet 模型)'
- en: '[PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig)
    configuration class: [PvtModel](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtModel)
    (PVT model)'
  id: totrans-931
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig)
    配置类: [PvtModel](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtModel)
    (PVT 模型)'
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertModel)
    (QDQBert model)'
  id: totrans-932
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    配置类: [QDQBertModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertModel)
    (QDQBert 模型)'
- en: '[Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    configuration class: [Qwen2Model](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Model)
    (Qwen2 model)'
  id: totrans-933
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    配置类: [Qwen2Model](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Model)
    (Qwen2 模型)'
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerModel](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModel)
    (Reformer model)'
  id: totrans-934
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    配置类: [ReformerModel](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModel)
    (Reformer 模型)'
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)
    (RegNet model)'
  id: totrans-935
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    配置类: [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)
    (RegNet 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertModel)
    (RemBERT model)'
  id: totrans-936
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [RemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertModel)
    (RemBERT 模型)'
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)
    (ResNet model)'
  id: totrans-937
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    配置类: [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)
    (ResNet 模型)'
- en: '[RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig)
    configuration class: [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT model)'
  id: totrans-938
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig)
    配置类: [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT 模型)'
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertModel](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertModel)
    (RoCBert model)'
  id: totrans-939
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    配置类: [RoCBertModel](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertModel)
    (RoCBert 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerModel)
    (RoFormer model)'
  id: totrans-940
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [RoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerModel)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaModel)
    (RoBERTa model)'
  id: totrans-941
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [RobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaModel)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-942
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [RobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    configuration class: [RwkvModel](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvModel)
    (RWKV model)'
  id: totrans-943
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    配置类: [RwkvModel](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvModel)
    (RWKV 模型)'
- en: '[SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    configuration class: [SEWModel](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWModel)
    (SEW model)'
  id: totrans-944
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    配置类: [SEWModel](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWModel)
    (SEW 模型)'
- en: '[SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    configuration class: [SEWDModel](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDModel)
    (SEW-D model)'
  id: totrans-945
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    配置类: [SEWDModel](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDModel)
    (SEW-D 模型)'
- en: '[SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig)
    configuration class: [SamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamModel)
    (SAM model)'
  id: totrans-946
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig)
    配置类: [SamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamModel)
    (SAM 模型)'
- en: '[SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    configuration class: [SeamlessM4TModel](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TModel)
    (SeamlessM4T model)'
  id: totrans-947
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    配置类: [SeamlessM4TModel](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TModel)
    (SeamlessM4T 模型)'
- en: '[SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    configuration class: [SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    (SeamlessM4Tv2 model)'
  id: totrans-948
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    配置类: [SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    (SeamlessM4Tv2 模型)'
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [SegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerModel)
    (SegFormer model)'
  id: totrans-949
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    配置类: [SegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerModel)
    (SegFormer 模型)'
- en: '[SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig)
    configuration class: [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP model)'
  id: totrans-950
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig)
    配置类: [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP 模型)'
- en: '[SiglipVisionConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionConfig)
    configuration class: [SiglipVisionModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionModel)
    (SiglipVisionModel model)'
  id: totrans-951
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SiglipVisionConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionConfig)
    配置类: [SiglipVisionModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionModel)
    (SiglipVisionModel 模型)'
- en: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    configuration class: [Speech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextModel)
    (Speech2Text model)'
  id: totrans-952
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    配置类: [Speech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextModel)
    (Speech2Text 模型)'
- en: '[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)
    configuration class: [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)
    (SpeechT5 model)'
  id: totrans-953
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)
    配置类: [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)
    (SpeechT5 模型)'
- en: '[SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    configuration class: [SplinterModel](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterModel)
    (Splinter model)'
  id: totrans-954
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    配置类: [SplinterModel](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterModel)
    (Splinter 模型)'
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertModel](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertModel)
    (SqueezeBERT model)'
  id: totrans-955
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    配置类: [SqueezeBertModel](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertModel)
    (SqueezeBERT 模型)'
- en: '[SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig)
    configuration class: [SwiftFormerModel](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerModel)
    (SwiftFormer model)'
  id: totrans-956
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig)
    配置类: [SwiftFormerModel](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerModel)
    (SwiftFormer 模型)'
- en: '[Swin2SRConfig](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRConfig)
    configuration class: [Swin2SRModel](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRModel)
    (Swin2SR model)'
  id: totrans-957
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Swin2SRConfig](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRConfig)
    配置类: [Swin2SRModel](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRModel)
    (Swin2SR 模型)'
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [SwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinModel)
    (Swin Transformer model)'
  id: totrans-958
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    配置类: [SwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinModel)
    (Swin Transformer 模型)'
- en: '[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    configuration class: [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model)
    (Swin Transformer V2 model)'
  id: totrans-959
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    配置类: [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model)
    (Swin Transformer V2 模型)'
- en: '[SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    configuration class: [SwitchTransformersModel](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersModel)
    (SwitchTransformers model)'
  id: totrans-960
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    配置类: [SwitchTransformersModel](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersModel)
    (SwitchTransformers 模型)'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)
    (T5 model)'
  id: totrans-961
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    配置类: [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)
    (T5 模型)'
- en: '[TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)
    configuration class: [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel)
    (Table Transformer model)'
  id: totrans-962
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)
    配置类: [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel)
    (Table Transformer 模型)'
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasModel)
    (TAPAS model)'
  id: totrans-963
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    配置类: [TapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasModel)
    (TAPAS 模型)'
- en: '[TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig)
    configuration class: [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)
    (Time Series Transformer model)'
  id: totrans-964
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig)
    配置类: [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)
    (Time Series Transformer 模型)'
- en: '[TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig)
    configuration class: [TimesformerModel](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerModel)
    (TimeSformer model)'
  id: totrans-965
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig)
    配置类: [TimesformerModel](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerModel)
    (TimeSformer 模型)'
- en: '`TimmBackboneConfig` configuration class: `TimmBackbone` (TimmBackbone model)'
  id: totrans-966
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TimmBackboneConfig` 配置类: `TimmBackbone` (TimmBackbone 模型)'
- en: '[TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig)
    configuration class: [TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel)
    (Trajectory Transformer model)'
  id: totrans-967
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TrajectoryTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig)
    配置类: [TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel)
    (轨迹Transformer模型)'
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLModel)
    (Transformer-XL model)'
  id: totrans-968
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    配置类: [TransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLModel)
    (Transformer-XL模型)'
- en: '[TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig)
    configuration class: [TvltModel](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltModel)
    (TVLT model)'
  id: totrans-969
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig)
    配置类: [TvltModel](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltModel)
    (TVLT模型)'
- en: '[TvpConfig](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpConfig)
    configuration class: [TvpModel](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpModel)
    (TVP model)'
  id: totrans-970
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TvpConfig](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpConfig)
    配置类: [TvpModel](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpModel)
    (TVP模型)'
- en: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    configuration class: [UMT5Model](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Model)
    (UMT5 model)'
  id: totrans-971
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    配置类: [UMT5Model](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Model)
    (UMT5模型)'
- en: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    configuration class: [UniSpeechModel](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechModel)
    (UniSpeech model)'
  id: totrans-972
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    配置类: [UniSpeechModel](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechModel)
    (UniSpeech模型)'
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatModel](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel)
    (UniSpeechSat model)'
  id: totrans-973
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    配置类: [UniSpeechSatModel](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel)
    (UniSpeechSat模型)'
- en: '[UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig)
    configuration class: [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)
    (UnivNet model)'
  id: totrans-974
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UnivNetConfig](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetConfig)
    配置类: [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)
    (UnivNet模型)'
- en: '[VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig)
    configuration class: [VanModel](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanModel)
    (VAN model)'
  id: totrans-975
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig)
    配置类: [VanModel](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanModel)
    (VAN模型)'
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel)
    (ViT model)'
  id: totrans-976
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    配置类: [ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel)
    (ViT模型)'
- en: '[ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)
    configuration class: [ViTHybridModel](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridModel)
    (ViT Hybrid model)'
  id: totrans-977
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)
    配置类: [ViTHybridModel](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridModel)
    (ViT混合模型)'
- en: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    configuration class: [ViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEModel)
    (ViTMAE model)'
  id: totrans-978
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    配置类: [ViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEModel)
    (ViTMAE模型)'
- en: '[ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)
    configuration class: [ViTMSNModel](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNModel)
    (ViTMSN model)'
  id: totrans-979
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)
    配置类: [ViTMSNModel](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNModel)
    (ViTMSN模型)'
- en: '[VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    configuration class: [VideoMAEModel](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEModel)
    (VideoMAE model)'
  id: totrans-980
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    配置类: [VideoMAEModel](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEModel)
    (VideoMAE模型)'
- en: '[ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig)
    configuration class: [ViltModel](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltModel)
    (ViLT model)'
  id: totrans-981
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig)
    配置类: [ViltModel](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltModel)
    (ViLT模型)'
- en: '[VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    configuration class: [VisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  id: totrans-982
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    配置类: [VisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel)
    (VisionTextDualEncoder模型)'
- en: '[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)
    configuration class: [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    (VisualBERT model)'
  id: totrans-983
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)
    配置类: [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    (VisualBERT模型)'
- en: '[VitDetConfig](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetConfig)
    configuration class: [VitDetModel](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetModel)
    (VitDet model)'
  id: totrans-984
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VitDetConfig](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetConfig)
    配置类: [VitDetModel](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetModel)
    (VitDet 模型)'
- en: '[VitsConfig](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsConfig)
    configuration class: [VitsModel](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsModel)
    (VITS model)'
  id: totrans-985
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VitsConfig](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsConfig)
    配置类: [VitsModel](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsModel)
    (VITS 模型)'
- en: '[VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)
    configuration class: [VivitModel](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitModel)
    (ViViT model)'
  id: totrans-986
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)
    配置类: [VivitModel](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitModel)
    (ViViT 模型)'
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertModel)
    (Wav2Vec2-BERT model)'
  id: totrans-987
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    配置类: [Wav2Vec2BertModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertModel)
    (Wav2Vec2-BERT 模型)'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model)
    (Wav2Vec2 model)'
  id: totrans-988
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类: [Wav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model)
    (Wav2Vec2 模型)'
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel)
    (Wav2Vec2-Conformer model)'
  id: totrans-989
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    配置类: [Wav2Vec2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel)
    (Wav2Vec2-Conformer 模型)'
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMModel](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMModel)
    (WavLM model)'
  id: totrans-990
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    配置类: [WavLMModel](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMModel)
    (WavLM 模型)'
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)
    (Whisper model)'
  id: totrans-991
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    配置类: [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)
    (Whisper 模型)'
- en: '[XCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPConfig)
    configuration class: [XCLIPModel](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPModel)
    (X-CLIP model)'
  id: totrans-992
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPConfig)
    配置类: [XCLIPModel](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPModel)
    (X-CLIP 模型)'
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [XGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMModel)
    (XGLM model)'
  id: totrans-993
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    配置类: [XGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMModel)
    (XGLM 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMModel)
    (XLM model)'
  id: totrans-994
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [XLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMModel)
    (XLM 模型)'
- en: '[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    configuration class: [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel)
    (XLM-ProphetNet model)'
  id: totrans-995
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    配置类: [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel)
    (XLM-ProphetNet 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel)
    (XLM-RoBERTa model)'
  id: totrans-996
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [XLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel)
    (XLM-RoBERTa 模型)'
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel)
    (XLM-RoBERTa-XL model)'
  id: totrans-997
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    配置类: [XLMRobertaXLModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel)
    (XLM-RoBERTa-XL 模型)'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetModel)
    (XLNet model)'
  id: totrans-998
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类: [XLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetModel)
    (XLNet 模型)'
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodModel](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodModel)
    (X-MOD model)'
  id: totrans-999
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    配置类: [XmodModel](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodModel)
    (X-MOD 模型)'
- en: '[YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)
    configuration class: [YolosModel](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosModel)
    (YOLOS model)'
  id: totrans-1000
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)
    配置类: [YolosModel](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosModel)
    (YOLOS 模型)'
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoModel](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoModel)
    (YOSO model)'
  id: totrans-1001
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    配置类: [YosoModel](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoModel)
    (YOSO 模型)'
- en: Instantiates one of the base model classes of the library from a configuration.
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库的基础模型类。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE24]'
  id: totrans-1005
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '#### `from_pretrained`'
  id: totrans-1006
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-1007
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE25]'
  id: totrans-1008
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-1009
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-1010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-1011
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-1012
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-1013
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*tensorflow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应该将配置对象作为`config`参数提供。使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型的加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-1014
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-1015
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    模型使用的配置，而不是自动加载的配置。当以下情况发生时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-1016
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-1017
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-1018
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-1019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-1020
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-1021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 下载预训练模型配置应该被缓存的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-1022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`）— 从TensorFlow检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-1023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-1024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-1025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-1026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-1027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-1028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-1029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的代码。只有在您信任的存储库中并且已阅读代码的情况下，才应将此选项设置为
    `True`，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-1030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-1031
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了
    `config` 或自动加载，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-1032
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-1033
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the base model classes of the library from a pretrained model.
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库的基本模型类之一。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [AlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertModel)
    (ALBERT model)'
  id: totrans-1036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [AlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertModel)
    (ALBERT 模型)'
- en: '`align` — [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN model)'
  id: totrans-1037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`align` — [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN 模型)'
- en: '`altclip` — [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP model)'
  id: totrans-1038
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`altclip` — [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP 模型)'
- en: '`audio-spectrogram-transformer` — [ASTModel](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTModel)
    (Audio Spectrogram Transformer model)'
  id: totrans-1039
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio-spectrogram-transformer` — [ASTModel](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTModel)
    (音频频谱变换器模型)'
- en: '`autoformer` — [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel)
    (Autoformer model)'
  id: totrans-1040
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autoformer` — [AutoformerModel](/docs/transformers/v4.37.2/en/model_doc/autoformer#transformers.AutoformerModel)
    (Autoformer 模型)'
- en: '`bark` — [BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel)
    (Bark model)'
  id: totrans-1041
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bark` — [BarkModel](/docs/transformers/v4.37.2/en/model_doc/bark#transformers.BarkModel)
    (Bark 模型)'
- en: '`bart` — [BartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartModel)
    (BART model)'
  id: totrans-1042
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [BartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartModel)
    (BART 模型)'
- en: '`beit` — [BeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitModel)
    (BEiT model)'
  id: totrans-1043
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beit` — [BeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitModel)
    (BEiT 模型)'
- en: '`bert` — [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel)
    (BERT model)'
  id: totrans-1044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertModel)
    (BERT 模型)'
- en: '`bert-generation` — [BertGenerationEncoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder)
    (Bert Generation model)'
  id: totrans-1045
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert-generation` — [BertGenerationEncoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationEncoder)
    (Bert Generation 模型)'
- en: '`big_bird` — [BigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdModel)
    (BigBird model)'
  id: totrans-1046
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdModel)
    (BigBird 模型)'
- en: '`bigbird_pegasus` — [BigBirdPegasusModel](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel)
    (BigBird-Pegasus model)'
  id: totrans-1047
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bigbird_pegasus` — [BigBirdPegasusModel](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel)
    (BigBird-Pegasus 模型)'
- en: '`biogpt` — [BioGptModel](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptModel)
    (BioGpt model)'
  id: totrans-1048
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`biogpt` — [BioGptModel](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptModel)
    (BioGpt 模型)'
- en: '`bit` — [BitModel](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitModel)
    (BiT model)'
  id: totrans-1049
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bit` — [BitModel](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitModel)
    (BiT 模型)'
- en: '`blenderbot` — [BlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotModel)
    (Blenderbot model)'
  id: totrans-1050
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot` — [BlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotModel)
    (Blenderbot 模型)'
- en: '`blenderbot-small` — [BlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel)
    (BlenderbotSmall model)'
  id: totrans-1051
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot-small` — [BlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel)
    (BlenderbotSmall 模型)'
- en: '`blip` — [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP model)'
  id: totrans-1052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP 模型)'
- en: '`blip-2` — [Blip2Model](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Model)
    (BLIP-2 model)'
  id: totrans-1053
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip-2` — [Blip2Model](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Model)
    (BLIP-2 模型)'
- en: '`bloom` — [BloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomModel)
    (BLOOM model)'
  id: totrans-1054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [BloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomModel)
    (BLOOM 模型)'
- en: '`bridgetower` — [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)
    (BridgeTower model)'
  id: totrans-1055
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bridgetower` — [BridgeTowerModel](/docs/transformers/v4.37.2/en/model_doc/bridgetower#transformers.BridgeTowerModel)
    (BridgeTower 模型)'
- en: '`bros` — [BrosModel](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosModel)
    (BROS model)'
  id: totrans-1056
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bros` — [BrosModel](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosModel)
    (BROS 模型)'
- en: '`camembert` — [CamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertModel)
    (CamemBERT model)'
  id: totrans-1057
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertModel)
    (CamemBERT 模型)'
- en: '`canine` — [CanineModel](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineModel)
    (CANINE model)'
  id: totrans-1058
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`canine` — [CanineModel](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineModel)
    (CANINE 模型)'
- en: '`chinese_clip` — [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP model)'
  id: totrans-1059
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chinese_clip` — [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP 模型)'
- en: '`clap` — [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    (CLAP model)'
  id: totrans-1060
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clap` — [ClapModel](/docs/transformers/v4.37.2/en/model_doc/clap#transformers.ClapModel)
    (CLAP 模型)'
- en: '`clip` — [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP model)'
  id: totrans-1061
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP 模型)'
- en: '`clip_vision_model` — [CLIPVisionModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel)
    (CLIPVisionModel model)'
  id: totrans-1062
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_vision_model` — [CLIPVisionModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPVisionModel)
    (CLIPVisionModel 模型)'
- en: '`clipseg` — [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg model)'
  id: totrans-1063
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clipseg` — [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg 模型)'
- en: '`clvp` — [ClvpModelForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpModelForConditionalGeneration)
    (CLVP model)'
  id: totrans-1064
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clvp` — [ClvpModelForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/clvp#transformers.ClvpModelForConditionalGeneration)
    (CLVP 模型)'
- en: '`code_llama` — [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel)
    (CodeLlama model)'
  id: totrans-1065
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_llama` — [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel)
    (CodeLlama 模型)'
- en: '`codegen` — [CodeGenModel](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenModel)
    (CodeGen model)'
  id: totrans-1066
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codegen` — [CodeGenModel](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenModel)
    (CodeGen 模型)'
- en: '`conditional_detr` — [ConditionalDetrModel](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrModel)
    (Conditional DETR model)'
  id: totrans-1067
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conditional_detr` — [ConditionalDetrModel](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrModel)
    (Conditional DETR 模型)'
- en: '`convbert` — [ConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertModel)
    (ConvBERT model)'
  id: totrans-1068
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [ConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertModel)
    (ConvBERT 模型)'
- en: '`convnext` — [ConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextModel)
    (ConvNeXT model)'
  id: totrans-1069
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnext` — [ConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextModel)
    (ConvNeXT 模型)'
- en: '`convnextv2` — [ConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Model)
    (ConvNeXTV2 model)'
  id: totrans-1070
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnextv2` — [ConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Model)
    (ConvNeXTV2 模型)'
- en: '`cpmant` — [CpmAntModel](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntModel)
    (CPM-Ant model)'
  id: totrans-1071
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cpmant` — [CpmAntModel](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntModel)
    (CPM-Ant 模型)'
- en: '`ctrl` — [CTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLModel)
    (CTRL model)'
  id: totrans-1072
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [CTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLModel)
    (CTRL 模型)'
- en: '`cvt` — [CvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtModel)
    (CvT model)'
  id: totrans-1073
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cvt` — [CvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtModel)
    (CvT 模型)'
- en: '`data2vec-audio` — [Data2VecAudioModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioModel)
    (Data2VecAudio model)'
  id: totrans-1074
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-audio` — [Data2VecAudioModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioModel)
    (Data2VecAudio 模型)'
- en: '`data2vec-text` — [Data2VecTextModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextModel)
    (Data2VecText model)'
  id: totrans-1075
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [Data2VecTextModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextModel)
    (Data2VecText 模型)'
- en: '`data2vec-vision` — [Data2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionModel)
    (Data2VecVision model)'
  id: totrans-1076
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-vision` — [Data2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionModel)
    (Data2VecVision 模型)'
- en: '`deberta` — [DebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaModel)
    (DeBERTa model)'
  id: totrans-1077
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [DebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaModel)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [DebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Model)
    (DeBERTa-v2 model)'
  id: totrans-1078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [DebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Model)
    (DeBERTa-v2 模型)'
- en: '`decision_transformer` — [DecisionTransformerModel](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerModel)
    (Decision Transformer model)'
  id: totrans-1079
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decision_transformer` — [DecisionTransformerModel](/docs/transformers/v4.37.2/en/model_doc/decision_transformer#transformers.DecisionTransformerModel)
    (Decision Transformer 模型)'
- en: '`deformable_detr` — [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)
    (Deformable DETR model)'
  id: totrans-1080
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deformable_detr` — [DeformableDetrModel](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrModel)
    (Deformable DETR 模型)'
- en: '`deit` — [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel)
    (DeiT model)'
  id: totrans-1081
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deit` — [DeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTModel)
    (DeiT 模型)'
- en: '`deta` — [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)
    (DETA model)'
  id: totrans-1082
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deta` — [DetaModel](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaModel)
    (DETA 模型)'
- en: '`detr` — [DetrModel](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrModel)
    (DETR model)'
  id: totrans-1083
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detr` — [DetrModel](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrModel)
    (DETR 模型)'
- en: '`dinat` — [DinatModel](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatModel)
    (DiNAT model)'
  id: totrans-1084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dinat` — [DinatModel](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatModel)
    (DiNAT 模型)'
- en: '`dinov2` — [Dinov2Model](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Model)
    (DINOv2 model)'
  id: totrans-1085
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dinov2` — [Dinov2Model](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Model)
    (DINOv2 模型)'
- en: '`distilbert` — [DistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertModel)
    (DistilBERT model)'
  id: totrans-1086
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [DistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertModel)
    (DistilBERT 模型)'
- en: '`donut-swin` — [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel)
    (DonutSwin model)'
  id: totrans-1087
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`donut-swin` — [DonutSwinModel](/docs/transformers/v4.37.2/en/model_doc/donut#transformers.DonutSwinModel)
    (DonutSwin 模型)'
- en: '`dpr` — [DPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoder)
    (DPR model)'
  id: totrans-1088
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpr` — [DPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRQuestionEncoder)
    (DPR 模型)'
- en: '`dpt` — [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel)
    (DPT model)'
  id: totrans-1089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpt` — [DPTModel](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTModel)
    (DPT 模型)'
- en: '`efficientformer` — [EfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerModel)
    (EfficientFormer model)'
  id: totrans-1090
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientformer` — [EfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerModel)
    (EfficientFormer 模型)'
- en: '`efficientnet` — [EfficientNetModel](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetModel)
    (EfficientNet model)'
  id: totrans-1091
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientnet` — [EfficientNetModel](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetModel)
    (EfficientNet 模型)'
- en: '`electra` — [ElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraModel)
    (ELECTRA model)'
  id: totrans-1092
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraModel)
    (ELECTRA 模型)'
- en: '`encodec` — [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)
    (EnCodec model)'
  id: totrans-1093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encodec` — [EncodecModel](/docs/transformers/v4.37.2/en/model_doc/encodec#transformers.EncodecModel)
    (EnCodec 模型)'
- en: '`ernie` — [ErnieModel](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieModel)
    (ERNIE model)'
  id: totrans-1094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [ErnieModel](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieModel)
    (ERNIE 模型)'
- en: '`ernie_m` — [ErnieMModel](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMModel)
    (ErnieM model)'
  id: totrans-1095
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie_m` — [ErnieMModel](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMModel)
    (ErnieM 模型)'
- en: '`esm` — [EsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmModel)
    (ESM model)'
  id: totrans-1096
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [EsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmModel)
    (ESM 模型)'
- en: '`falcon` — [FalconModel](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconModel)
    (Falcon model)'
  id: totrans-1097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`falcon` — [FalconModel](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconModel)
    (Falcon 模型)'
- en: '`fastspeech2_conformer` — [FastSpeech2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerModel)
    (FastSpeech2Conformer model)'
  id: totrans-1098
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fastspeech2_conformer` — [FastSpeech2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/fastspeech2_conformer#transformers.FastSpeech2ConformerModel)
    (FastSpeech2Conformer 模型)'
- en: '`flaubert` — [FlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertModel)
    (FlauBERT model)'
  id: totrans-1099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [FlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertModel)
    (FlauBERT 模型)'
- en: '`flava` — [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    (FLAVA model)'
  id: totrans-1100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flava` — [FlavaModel](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaModel)
    (FLAVA 模型)'
- en: '`fnet` — [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    (FNet model)'
  id: totrans-1101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` — [FNetModel](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetModel)
    (FNet 模型)'
- en: '`focalnet` — [FocalNetModel](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetModel)
    (FocalNet model)'
  id: totrans-1102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`focalnet` — [FocalNetModel](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetModel)
    (FocalNet 模型)'
- en: '`fsmt` — [FSMTModel](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTModel)
    (FairSeq Machine-Translation model)'
  id: totrans-1103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fsmt` — [FSMTModel](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTModel)
    (FairSeq 机器翻译模型)'
- en: '`funnel` — [FunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelModel)
    or [FunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelBaseModel)
    (Funnel Transformer model)'
  id: totrans-1104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [FunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelModel)
    或 [FunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelBaseModel)
    (Funnel Transformer 模型)'
- en: '`git` — [GitModel](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitModel)
    (GIT model)'
  id: totrans-1105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` — [GitModel](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitModel)
    (GIT 模型)'
- en: '`glpn` — [GLPNModel](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNModel)
    (GLPN model)'
  id: totrans-1106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glpn` — [GLPNModel](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNModel)
    (GLPN 模型)'
- en: '`gpt-sw3` — [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model)
    (GPT-Sw3 model)'
  id: totrans-1107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model)
    (OpenAI GPT-2 model)'
  id: totrans-1108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [GPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Model)
    (OpenAI GPT-2 模型)'
- en: '`gpt_bigcode` — [GPTBigCodeModel](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeModel)
    (GPTBigCode model)'
  id: totrans-1109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_bigcode` — [GPTBigCodeModel](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeModel)
    (GPTBigCode 模型)'
- en: '`gpt_neo` — [GPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoModel)
    (GPT Neo model)'
  id: totrans-1110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neo` — [GPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoModel)
    (GPT Neo 模型)'
- en: '`gpt_neox` — [GPTNeoXModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXModel)
    (GPT NeoX model)'
  id: totrans-1111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox` — [GPTNeoXModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXModel)
    (GPT NeoX 模型)'
- en: '`gpt_neox_japanese` — [GPTNeoXJapaneseModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel)
    (GPT NeoX Japanese model)'
  id: totrans-1112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox_japanese` — [GPTNeoXJapaneseModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel)
    (GPT NeoX Japanese 模型)'
- en: '`gptj` — [GPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJModel)
    (GPT-J model)'
  id: totrans-1113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [GPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJModel)
    (GPT-J 模型)'
- en: '`gptsan-japanese` — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  id: totrans-1114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptsan-japanese` — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese 模型)'
- en: '`graphormer` — [GraphormerModel](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerModel)
    (Graphormer model)'
  id: totrans-1115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`graphormer` — [GraphormerModel](/docs/transformers/v4.37.2/en/model_doc/graphormer#transformers.GraphormerModel)
    (Graphormer 模型)'
- en: '`groupvit` — [GroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTModel)
    (GroupViT model)'
  id: totrans-1116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupvit` — [GroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTModel)
    (GroupViT 模型)'
- en: '`hubert` — [HubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertModel)
    (Hubert model)'
  id: totrans-1117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hubert` — [HubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertModel)
    (Hubert 模型)'
- en: '`ibert` — [IBertModel](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertModel)
    (I-BERT model)'
  id: totrans-1118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ibert` — [IBertModel](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertModel)
    (I-BERT 模型)'
- en: '`idefics` — [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)
    (IDEFICS model)'
  id: totrans-1119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`idefics` — [IdeficsModel](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsModel)
    (IDEFICS 模型)'
- en: '`imagegpt` — [ImageGPTModel](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTModel)
    (ImageGPT model)'
  id: totrans-1120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imagegpt` — [ImageGPTModel](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTModel)
    (ImageGPT 模型)'
- en: '`informer` — [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel)
    (Informer model)'
  id: totrans-1121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`informer` — [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel)
    (Informer 模型)'
- en: '`jukebox` — [JukeboxModel](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxModel)
    (Jukebox model)'
  id: totrans-1122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jukebox` — [JukeboxModel](/docs/transformers/v4.37.2/en/model_doc/jukebox#transformers.JukeboxModel)
    (Jukebox 模型)'
- en: '`kosmos-2` — [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model)
    (KOSMOS-2 model)'
  id: totrans-1123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kosmos-2` — [Kosmos2Model](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Model)
    (KOSMOS-2 模型)'
- en: '`layoutlm` — [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)
    (LayoutLM model)'
  id: totrans-1124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [LayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMModel)
    (LayoutLM 模型)'
- en: '`layoutlmv2` — [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    (LayoutLMv2 model)'
  id: totrans-1125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model)
    (LayoutLMv2 模型)'
- en: '`layoutlmv3` — [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)
    (LayoutLMv3 model)'
  id: totrans-1126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model)
    (LayoutLMv3 模型)'
- en: '`led` — [LEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDModel)
    (LED model)'
  id: totrans-1127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`led` — [LEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDModel)
    (LED 模型)'
- en: '`levit` — [LevitModel](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitModel)
    (LeViT model)'
  id: totrans-1128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`levit` — [LevitModel](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitModel)
    (LeViT 模型)'
- en: '`lilt` — [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)
    (LiLT model)'
  id: totrans-1129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lilt` — [LiltModel](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltModel)
    (LiLT 模型)'
- en: '`llama` — [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel)
    (LLaMA model)'
  id: totrans-1130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llama` — [LlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaModel)
    (LLaMA 模型)'
- en: '`longformer` — [LongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerModel)
    (Longformer model)'
  id: totrans-1131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [LongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerModel)
    (Longformer 模型)'
- en: '`longt5` — [LongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Model)
    (LongT5 model)'
  id: totrans-1132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longt5` — [LongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Model)
    (LongT5 模型)'
- en: '`luke` — [LukeModel](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeModel)
    (LUKE model)'
  id: totrans-1133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`luke` — [LukeModel](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeModel)
    (LUKE 模型)'
- en: '`lxmert` — [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    (LXMERT model)'
  id: totrans-1134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lxmert` — [LxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertModel)
    (LXMERT 模型)'
- en: '`m2m_100` — [M2M100Model](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Model)
    (M2M100 model)'
  id: totrans-1135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`m2m_100` — [M2M100Model](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Model)
    (M2M100 模型)'
- en: '`marian` — [MarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianModel)
    (Marian model)'
  id: totrans-1136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marian` — [MarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianModel)
    (Marian 模型)'
- en: '`markuplm` — [MarkupLMModel](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMModel)
    (MarkupLM model)'
  id: totrans-1137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`markuplm` — [MarkupLMModel](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMModel)
    (MarkupLM 模型)'
- en: '`mask2former` — [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)
    (Mask2Former model)'
  id: totrans-1138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask2former` — [Mask2FormerModel](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerModel)
    (Mask2Former 模型)'
- en: '`maskformer` — [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)
    (MaskFormer model)'
  id: totrans-1139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maskformer` — [MaskFormerModel](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerModel)
    (MaskFormer 模型)'
- en: '`maskformer-swin` — `MaskFormerSwinModel` (MaskFormerSwin model)'
  id: totrans-1140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maskformer-swin` — `MaskFormerSwinModel` (MaskFormerSwin 模型)'
- en: '`mbart` — [MBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartModel)
    (mBART model)'
  id: totrans-1141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [MBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartModel)
    (mBART 模型)'
- en: '`mctct` — [MCTCTModel](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTModel)
    (M-CTC-T model)'
  id: totrans-1142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mctct` — [MCTCTModel](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTModel)
    (M-CTC-T 模型)'
- en: '`mega` — [MegaModel](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaModel)
    (MEGA model)'
  id: totrans-1143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [MegaModel](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaModel)
    (MEGA 模型)'
- en: '`megatron-bert` — [MegatronBertModel](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertModel)
    (Megatron-BERT model)'
  id: totrans-1144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [MegatronBertModel](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertModel)
    (Megatron-BERT模型)'
- en: '`mgp-str` — [MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition)
    (MGP-STR model)'
  id: totrans-1145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mgp-str` — [MgpstrForSceneTextRecognition](/docs/transformers/v4.37.2/en/model_doc/mgp-str#transformers.MgpstrForSceneTextRecognition)
    (MGP-STR模型)'
- en: '`mistral` — [MistralModel](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralModel)
    (Mistral model)'
  id: totrans-1146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mistral` — [MistralModel](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralModel)
    (Mistral模型)'
- en: '`mixtral` — [MixtralModel](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralModel)
    (Mixtral model)'
  id: totrans-1147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mixtral` — [MixtralModel](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralModel)
    (Mixtral模型)'
- en: '`mobilebert` — [MobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertModel)
    (MobileBERT model)'
  id: totrans-1148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [MobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertModel)
    (MobileBERT模型)'
- en: '`mobilenet_v1` — [MobileNetV1Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Model)
    (MobileNetV1 model)'
  id: totrans-1149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v1` — [MobileNetV1Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Model)
    (MobileNetV1模型)'
- en: '`mobilenet_v2` — [MobileNetV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model)
    (MobileNetV2 model)'
  id: totrans-1150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v2` — [MobileNetV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model)
    (MobileNetV2模型)'
- en: '`mobilevit` — [MobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTModel)
    (MobileViT model)'
  id: totrans-1151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevit` — [MobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTModel)
    (MobileViT模型)'
- en: '`mobilevitv2` — [MobileViTV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Model)
    (MobileViTV2 model)'
  id: totrans-1152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevitv2` — [MobileViTV2Model](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Model)
    (MobileViTV2模型)'
- en: '`mpnet` — [MPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetModel)
    (MPNet model)'
  id: totrans-1153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [MPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetModel)
    (MPNet模型)'
- en: '`mpt` — [MptModel](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptModel)
    (MPT model)'
  id: totrans-1154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpt` — [MptModel](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptModel)
    (MPT模型)'
- en: '`mra` — [MraModel](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraModel)
    (MRA model)'
  id: totrans-1155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mra` — [MraModel](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraModel)
    (MRA模型)'
- en: '`mt5` — [MT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Model)
    (MT5 model)'
  id: totrans-1156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [MT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Model)
    (MT5模型)'
- en: '`mvp` — [MvpModel](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpModel)
    (MVP model)'
  id: totrans-1157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mvp` — [MvpModel](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpModel)
    (MVP模型)'
- en: '`nat` — [NatModel](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatModel)
    (NAT model)'
  id: totrans-1158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nat` — [NatModel](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatModel)
    (NAT模型)'
- en: '`nezha` — [NezhaModel](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaModel)
    (Nezha model)'
  id: totrans-1159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` — [NezhaModel](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaModel)
    (Nezha模型)'
- en: '`nllb-moe` — [NllbMoeModel](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeModel)
    (NLLB-MOE model)'
  id: totrans-1160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nllb-moe` — [NllbMoeModel](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeModel)
    (NLLB-MOE模型)'
- en: '`nystromformer` — [NystromformerModel](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerModel)
    (Nyströmformer model)'
  id: totrans-1161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nystromformer` — [NystromformerModel](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerModel)
    (Nyströmformer模型)'
- en: '`oneformer` — [OneFormerModel](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerModel)
    (OneFormer model)'
  id: totrans-1162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oneformer` — [OneFormerModel](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerModel)
    (OneFormer模型)'
- en: '`open-llama` — [OpenLlamaModel](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaModel)
    (OpenLlama model)'
  id: totrans-1163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`open-llama` — [OpenLlamaModel](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaModel)
    (OpenLlama模型)'
- en: '`openai-gpt` — [OpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel)
    (OpenAI GPT model)'
  id: totrans-1164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [OpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTModel)
    (OpenAI GPT模型)'
- en: '`opt` — [OPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTModel)
    (OPT model)'
  id: totrans-1165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [OPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTModel)
    (OPT模型)'
- en: '`owlv2` — [Owlv2Model](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Model)
    (OWLv2 model)'
  id: totrans-1166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlv2` — [Owlv2Model](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Model)
    (OWLv2模型)'
- en: '`owlvit` — [OwlViTModel](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTModel)
    (OWL-ViT model)'
  id: totrans-1167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlvit` — [OwlViTModel](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTModel)
    (OWL-ViT模型)'
- en: '`patchtsmixer` — [PatchTSMixerModel](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerModel)
    (PatchTSMixer model)'
  id: totrans-1168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patchtsmixer` — [PatchTSMixerModel](/docs/transformers/v4.37.2/en/model_doc/patchtsmixer#transformers.PatchTSMixerModel)
    (PatchTSMixer模型)'
- en: '`patchtst` — [PatchTSTModel](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTModel)
    (PatchTST model)'
  id: totrans-1169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patchtst` — [PatchTSTModel](/docs/transformers/v4.37.2/en/model_doc/patchtst#transformers.PatchTSTModel)
    (PatchTST模型)'
- en: '`pegasus` — [PegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusModel)
    (Pegasus model)'
  id: totrans-1170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus` — [PegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusModel)
    (Pegasus模型)'
- en: '`pegasus_x` — [PegasusXModel](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXModel)
    (PEGASUS-X model)'
  id: totrans-1171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus_x` — [PegasusXModel](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXModel)
    (PEGASUS-X模型)'
- en: '`perceiver` — [PerceiverModel](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverModel)
    (Perceiver model)'
  id: totrans-1172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perceiver` — [PerceiverModel](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverModel)
    (感知器模型)'
- en: '`persimmon` — [PersimmonModel](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonModel)
    (Persimmon model)'
  id: totrans-1173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`persimmon` — [PersimmonModel](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonModel)
    (Persimmon模型)'
- en: '`phi` — [PhiModel](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiModel)
    (Phi model)'
  id: totrans-1174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`phi` — [PhiModel](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiModel)
    (Phi模型)'
- en: '`plbart` — [PLBartModel](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartModel)
    (PLBart model)'
  id: totrans-1175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plbart` — [PLBartModel](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartModel)
    (PLBart模型)'
- en: '`poolformer` — [PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel)
    (PoolFormer model)'
  id: totrans-1176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`poolformer` — [PoolFormerModel](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerModel)
    (PoolFormer 模型)'
- en: '`prophetnet` — [ProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetModel)
    (ProphetNet model)'
  id: totrans-1177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prophetnet` — [ProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetModel)
    (ProphetNet 模型)'
- en: '`pvt` — [PvtModel](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtModel)
    (PVT model)'
  id: totrans-1178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pvt` — [PvtModel](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtModel)
    (PVT 模型)'
- en: '`qdqbert` — [QDQBertModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertModel)
    (QDQBert model)'
  id: totrans-1179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` — [QDQBertModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertModel)
    (QDQBert 模型)'
- en: '`qwen2` — [Qwen2Model](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Model)
    (Qwen2 model)'
  id: totrans-1180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qwen2` — [Qwen2Model](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Model)
    (Qwen2 模型)'
- en: '`reformer` — [ReformerModel](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModel)
    (Reformer model)'
  id: totrans-1181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reformer` — [ReformerModel](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModel)
    (Reformer 模型)'
- en: '`regnet` — [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)
    (RegNet model)'
  id: totrans-1182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regnet` — [RegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetModel)
    (RegNet 模型)'
- en: '`rembert` — [RemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertModel)
    (RemBERT model)'
  id: totrans-1183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [RemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertModel)
    (RemBERT 模型)'
- en: '`resnet` — [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)
    (ResNet model)'
  id: totrans-1184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resnet` — [ResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetModel)
    (ResNet 模型)'
- en: '`retribert` — [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT model)'
  id: totrans-1185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`retribert` — [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT 模型)'
- en: '`roberta` — [RobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaModel)
    (RoBERTa model)'
  id: totrans-1186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaModel)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [RobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roc_bert` — [RoCBertModel](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertModel)
    (RoCBert model)'
  id: totrans-1188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertModel](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertModel)
    (RoCBert 模型)'
- en: '`roformer` — [RoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerModel)
    (RoFormer model)'
  id: totrans-1189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [RoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerModel)
    (RoFormer 模型)'
- en: '`rwkv` — [RwkvModel](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvModel)
    (RWKV model)'
  id: totrans-1190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rwkv` — [RwkvModel](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvModel)
    (RWKV 模型)'
- en: '`sam` — [SamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamModel)
    (SAM model)'
  id: totrans-1191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sam` — [SamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamModel)
    (SAM 模型)'
- en: '`seamless_m4t` — [SeamlessM4TModel](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TModel)
    (SeamlessM4T model)'
  id: totrans-1192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t` — [SeamlessM4TModel](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TModel)
    (SeamlessM4T 模型)'
- en: '`seamless_m4t_v2` — [SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    (SeamlessM4Tv2 model)'
  id: totrans-1193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t_v2` — [SeamlessM4Tv2Model](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Model)
    (SeamlessM4Tv2 模型)'
- en: '`segformer` — [SegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerModel)
    (SegFormer model)'
  id: totrans-1194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segformer` — [SegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerModel)
    (SegFormer 模型)'
- en: '`sew` — [SEWModel](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWModel)
    (SEW model)'
  id: totrans-1195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew` — [SEWModel](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWModel)
    (SEW 模型)'
- en: '`sew-d` — [SEWDModel](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDModel)
    (SEW-D model)'
  id: totrans-1196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew-d` — [SEWDModel](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDModel)
    (SEW-D 模型)'
- en: '`siglip` — [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP model)'
  id: totrans-1197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`siglip` — [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP 模型)'
- en: '`siglip_vision_model` — [SiglipVisionModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionModel)
    (SiglipVisionModel model)'
  id: totrans-1198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`siglip_vision_model` — [SiglipVisionModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipVisionModel)
    (SiglipVisionModel 模型)'
- en: '`speech_to_text` — [Speech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextModel)
    (Speech2Text model)'
  id: totrans-1199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text` — [Speech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextModel)
    (Speech2Text 模型)'
- en: '`speecht5` — [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)
    (SpeechT5 model)'
  id: totrans-1200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speecht5` — [SpeechT5Model](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Model)
    (SpeechT5 模型)'
- en: '`splinter` — [SplinterModel](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterModel)
    (Splinter model)'
  id: totrans-1201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`splinter` — [SplinterModel](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterModel)
    (Splinter 模型)'
- en: '`squeezebert` — [SqueezeBertModel](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertModel)
    (SqueezeBERT model)'
  id: totrans-1202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`squeezebert` — [SqueezeBertModel](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertModel)
    (SqueezeBERT 模型)'
- en: '`swiftformer` — [SwiftFormerModel](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerModel)
    (SwiftFormer model)'
  id: totrans-1203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swiftformer` — [SwiftFormerModel](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerModel)
    (SwiftFormer 模型)'
- en: '`swin` — [SwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinModel)
    (Swin Transformer model)'
  id: totrans-1204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin` — [SwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinModel)
    (Swin Transformer 模型)'
- en: '`swin2sr` — [Swin2SRModel](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRModel)
    (Swin2SR model)'
  id: totrans-1205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin2sr` — [Swin2SRModel](/docs/transformers/v4.37.2/en/model_doc/swin2sr#transformers.Swin2SRModel)
    (Swin2SR 模型)'
- en: '`swinv2` — [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model)
    (Swin Transformer V2 model)'
  id: totrans-1206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swinv2` — [Swinv2Model](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Model)
    (Swin Transformer V2 模型)'
- en: '`switch_transformers` — [SwitchTransformersModel](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersModel)
    (SwitchTransformers model)'
  id: totrans-1207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`switch_transformers` — [SwitchTransformersModel](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersModel)
    (SwitchTransformers 模型)'
- en: '`t5` — [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)
    (T5 model)'
  id: totrans-1208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [T5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Model)
    (T5 模型)'
- en: '`table-transformer` — [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel)
    (Table Transformer model)'
  id: totrans-1209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table-transformer` — [TableTransformerModel](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerModel)
    (Table Transformer 模型)'
- en: '`tapas` — [TapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasModel)
    (TAPAS model)'
  id: totrans-1210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasModel)
    (TAPAS 模型)'
- en: '`time_series_transformer` — [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)
    (Time Series Transformer model)'
  id: totrans-1211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_series_transformer` — [TimeSeriesTransformerModel](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel)
    (Time Series Transformer 模型)'
- en: '`timesformer` — [TimesformerModel](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerModel)
    (TimeSformer model)'
  id: totrans-1212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesformer` — [TimesformerModel](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerModel)
    (TimeSformer 模型)'
- en: '`timm_backbone` — `TimmBackbone` (TimmBackbone model)'
  id: totrans-1213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timm_backbone` — `TimmBackbone` (TimmBackbone 模型)'
- en: '`trajectory_transformer` — [TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel)
    (Trajectory Transformer model)'
  id: totrans-1214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trajectory_transformer` — [TrajectoryTransformerModel](/docs/transformers/v4.37.2/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel)
    (Trajectory Transformer 模型)'
- en: '`transfo-xl` — [TransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLModel)
    (Transformer-XL model)'
  id: totrans-1215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLModel)
    (Transformer-XL 模型)'
- en: '`tvlt` — [TvltModel](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltModel)
    (TVLT model)'
  id: totrans-1216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvlt` — [TvltModel](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltModel)
    (TVLT 模型)'
- en: '`tvp` — [TvpModel](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpModel)
    (TVP model)'
  id: totrans-1217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvp` — [TvpModel](/docs/transformers/v4.37.2/en/model_doc/tvp#transformers.TvpModel)
    (TVP 模型)'
- en: '`umt5` — [UMT5Model](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Model)
    (UMT5 model)'
  id: totrans-1218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`umt5` — [UMT5Model](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Model)
    (UMT5 模型)'
- en: '`unispeech` — [UniSpeechModel](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechModel)
    (UniSpeech model)'
  id: totrans-1219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech` — [UniSpeechModel](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechModel)
    (UniSpeech 模型)'
- en: '`unispeech-sat` — [UniSpeechSatModel](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel)
    (UniSpeechSat model)'
  id: totrans-1220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech-sat` — [UniSpeechSatModel](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel)
    (UniSpeechSat 模型)'
- en: '`univnet` — [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)
    (UnivNet model)'
  id: totrans-1221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`univnet` — [UnivNetModel](/docs/transformers/v4.37.2/en/model_doc/univnet#transformers.UnivNetModel)
    (UnivNet 模型)'
- en: '`van` — [VanModel](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanModel)
    (VAN model)'
  id: totrans-1222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`van` — [VanModel](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanModel)
    (VAN 模型)'
- en: '`videomae` — [VideoMAEModel](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEModel)
    (VideoMAE model)'
  id: totrans-1223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`videomae` — [VideoMAEModel](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEModel)
    (VideoMAE 模型)'
- en: '`vilt` — [ViltModel](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltModel)
    (ViLT model)'
  id: totrans-1224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vilt` — [ViltModel](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltModel)
    (ViLT 模型)'
- en: '`vision-text-dual-encoder` — [VisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  id: totrans-1225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision-text-dual-encoder` — [VisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel)
    (VisionTextDualEncoder 模型)'
- en: '`visual_bert` — [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    (VisualBERT model)'
  id: totrans-1226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_bert` — [VisualBertModel](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertModel)
    (VisualBERT 模型)'
- en: '`vit` — [ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel)
    (ViT model)'
  id: totrans-1227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [ViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTModel)
    (ViT 模型)'
- en: '`vit_hybrid` — [ViTHybridModel](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridModel)
    (ViT Hybrid model)'
  id: totrans-1228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_hybrid` — [ViTHybridModel](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridModel)
    (ViT Hybrid 模型)'
- en: '`vit_mae` — [ViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEModel)
    (ViTMAE model)'
  id: totrans-1229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_mae` — [ViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEModel)
    (ViTMAE 模型)'
- en: '`vit_msn` — [ViTMSNModel](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNModel)
    (ViTMSN model)'
  id: totrans-1230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_msn` — [ViTMSNModel](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNModel)
    (ViTMSN 模型)'
- en: '`vitdet` — [VitDetModel](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetModel)
    (VitDet model)'
  id: totrans-1231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vitdet` — [VitDetModel](/docs/transformers/v4.37.2/en/model_doc/vitdet#transformers.VitDetModel)
    (VitDet 模型)'
- en: '`vits` — [VitsModel](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsModel)
    (VITS model)'
  id: totrans-1232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vits` — [VitsModel](/docs/transformers/v4.37.2/en/model_doc/vits#transformers.VitsModel)
    (VITS 模型)'
- en: '`vivit` — [VivitModel](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitModel)
    (ViViT model)'
  id: totrans-1233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vivit` — [VivitModel](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitModel)
    (ViViT 模型)'
- en: '`wav2vec2` — [Wav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model)
    (Wav2Vec2 model)'
  id: totrans-1234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Model)
    (Wav2Vec2 模型)'
- en: '`wav2vec2-bert` — [Wav2Vec2BertModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertModel)
    (Wav2Vec2-BERT model)'
  id: totrans-1235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-bert` — [Wav2Vec2BertModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertModel)
    (Wav2Vec2-BERT 模型)'
- en: '`wav2vec2-conformer` — [Wav2Vec2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel)
    (Wav2Vec2-Conformer model)'
  id: totrans-1236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2ConformerModel](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel)
    (Wav2Vec2-Conformer 模型)'
- en: '`wavlm` — [WavLMModel](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMModel)
    (WavLM model)'
  id: totrans-1237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wavlm` — [WavLMModel](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMModel)
    (WavLM 模型)'
- en: '`whisper` — [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)
    (Whisper model)'
  id: totrans-1238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)
    (Whisper 模型)'
- en: '`xclip` — [XCLIPModel](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPModel)
    (X-CLIP model)'
  id: totrans-1239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xclip` — [XCLIPModel](/docs/transformers/v4.37.2/en/model_doc/xclip#transformers.XCLIPModel)
    (X-CLIP 模型)'
- en: '`xglm` — [XGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMModel)
    (XGLM model)'
  id: totrans-1240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xglm` — [XGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMModel)
    (XGLM 模型)'
- en: '`xlm` — [XLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMModel)
    (XLM model)'
  id: totrans-1241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMModel)
    (XLM 模型)'
- en: '`xlm-prophetnet` — [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel)
    (XLM-ProphetNet model)'
  id: totrans-1242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-prophetnet` — [XLMProphetNetModel](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel)
    (XLM-ProphetNet 模型)'
- en: '`xlm-roberta` — [XLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel)
    (XLM-RoBERTa model)'
  id: totrans-1243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaModel)
    (XLM-RoBERTa 模型)'
- en: '`xlm-roberta-xl` — [XLMRobertaXLModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel)
    (XLM-RoBERTa-XL model)'
  id: totrans-1244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaXLModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel)
    (XLM-RoBERTa-XL 模型)'
- en: '`xlnet` — [XLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetModel)
    (XLNet model)'
  id: totrans-1245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [XLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetModel)
    (XLNet 模型)'
- en: '`xmod` — [XmodModel](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodModel)
    (X-MOD model)'
  id: totrans-1246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XmodModel](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodModel)
    (X-MOD 模型)'
- en: '`yolos` — [YolosModel](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosModel)
    (YOLOS model)'
  id: totrans-1247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yolos` — [YolosModel](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosModel)
    (YOLOS 模型)'
- en: '`yoso` — [YosoModel](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoModel)
    (YOSO model)'
  id: totrans-1248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yoso` — [YosoModel](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoModel)
    (YOSO 模型)'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-1249
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-1250
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE26]'
  id: totrans-1251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: TFAutoModel
  id: totrans-1252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModel
- en: '### `class transformers.TFAutoModel`'
  id: totrans-1253
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L531)'
  id: totrans-1254
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L531)'
- en: '[PRE27]'
  id: totrans-1255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This is a generic model class that will be instantiated as one of the base model
    classes of the library when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-1256
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，会被实例化为库中的基础模型类之一。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-1257
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会报错）。
- en: '#### `from_config`'
  id: totrans-1258
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-1259
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE28]'
  id: totrans-1260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-1261
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-1262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类:'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertModel)
    (ALBERT model)'
  id: totrans-1263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    配置类: [TFAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertModel)
    (ALBERT 模型)'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [TFBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartModel)
    (BART model)'
  id: totrans-1264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    配置类: [TFBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartModel)
    (BART 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertModel)
    (BERT model)'
  id: totrans-1265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类: [TFBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertModel)
    (BERT 模型)'
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [TFBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel)
    (Blenderbot model)'
  id: totrans-1266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    配置类: [TFBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel)
    (Blenderbot 模型)'
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [TFBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel)
    (BlenderbotSmall model)'
  id: totrans-1267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    配置类: [TFBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel)
    (BlenderbotSmall 模型)'
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP model)'
  id: totrans-1268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    配置类: [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP 模型)'
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP model)'
  id: totrans-1269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    配置类: [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP 模型)'
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [TFCTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLModel)
    (CTRL model)'
  id: totrans-1270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    配置类: [TFCTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLModel)
    (CTRL 模型)'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertModel)
    (CamemBERT model)'
  id: totrans-1271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    配置类: [TFCamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertModel)
    (CamemBERT 模型)'
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertModel)
    (ConvBERT model)'
  id: totrans-1272
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    配置类: [TFConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertModel)
    (ConvBERT 模型)'
- en: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    configuration class: [TFConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextModel)
    (ConvNeXT model)'
  id: totrans-1273
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    配置类: [TFConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextModel)
    (ConvNeXT 模型)'
- en: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    configuration class: [TFConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2Model)
    (ConvNeXTV2 model)'
  id: totrans-1274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    配置类: [TFConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2Model)
    (ConvNeXTV2 模型)'
- en: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    configuration class: [TFCvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtModel)
    (CvT model)'
  id: totrans-1275
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    配置类: [TFCvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtModel)
    (CvT 模型)'
- en: '[DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig)
    configuration class: [TFDPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder)
    (DPR model)'
  id: totrans-1276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DPRConfig](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.DPRConfig)
    配置类: [TFDPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder)
    (DPR 模型)'
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [TFData2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionModel)
    (Data2VecVision model)'
  id: totrans-1277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    配置类: [TFData2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionModel)
    (Data2VecVision 模型)'
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaModel)
    (DeBERTa model)'
  id: totrans-1278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    配置类: [TFDebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaModel)
    (DeBERTa 模型)'
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model)
    (DeBERTa-v2 model)'
  id: totrans-1279
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    配置类: [TFDebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model)
    (DeBERTa-v2 模型)'
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel)
    (DeiT model)'
  id: totrans-1280
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    配置类: [TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel)
    (DeiT 模型)'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertModel)
    (DistilBERT model)'
  id: totrans-1281
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [TFDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertModel)
    (DistilBERT 模型)'
- en: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    configuration class: [TFEfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerModel)
    (EfficientFormer model)'
  id: totrans-1282
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    配置类: [TFEfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerModel)
    (EfficientFormer 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraModel)
    (ELECTRA model)'
  id: totrans-1283
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [TFElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraModel)
    (ELECTRA 模型)'
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [TFEsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmModel)
    (ESM model)'
  id: totrans-1284
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    配置类: [TFEsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmModel)
    (ESM 模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertModel)
    (FlauBERT model)'
  id: totrans-1285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [TFFlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertModel)
    (FlauBERT 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelModel)
    or [TFFunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelBaseModel)
    (Funnel Transformer model)'
  id: totrans-1286
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [TFFunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelModel)
    或 [TFFunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelBaseModel)
    (Funnel Transformer 模型)'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model)
    (OpenAI GPT-2 model)'
  id: totrans-1287
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    配置类: [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model)
    (OpenAI GPT-2 模型)'
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [TFGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJModel)
    (GPT-J model)'
  id: totrans-1288
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    配置类: [TFGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJModel)
    (GPT-J 模型)'
- en: '[GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)
    configuration class: [TFGroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.TFGroupViTModel)
    (GroupViT model)'
  id: totrans-1289
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GroupViTConfig](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.GroupViTConfig)
    配置类: [TFGroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.TFGroupViTModel)
    (GroupViT 模型)'
- en: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    configuration class: [TFHubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.TFHubertModel)
    (Hubert model)'
  id: totrans-1290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    配置类: [TFHubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.TFHubertModel)
    (Hubert 模型)'
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [TFLEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDModel)
    (LED model)'
  id: totrans-1291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    配置类: [TFLEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDModel)
    (LED 模型)'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel)
    (LayoutLM model)'
  id: totrans-1292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类: [TFLayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel)
    (LayoutLM 模型)'
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model)
    (LayoutLMv3 model)'
  id: totrans-1293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    配置类: [TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model)
    (LayoutLMv3 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerModel)
    (Longformer model)'
  id: totrans-1294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [TFLongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerModel)
    (Longformer 模型)'
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)
    (LXMERT model)'
  id: totrans-1295
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    配置类: [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)
    (LXMERT 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [TFMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartModel)
    (mBART model)'
  id: totrans-1296
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类: [TFMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartModel)
    (mBART 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetModel)
    (MPNet model)'
  id: totrans-1297
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [TFMPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetModel)
    (MPNet 模型)'
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [TFMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5Model)
    (MT5 model)'
  id: totrans-1298
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    配置类: [TFMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5Model)
    (MT5 模型)'
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [TFMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianModel)
    (Marian model)'
  id: totrans-1299
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    配置类: [TFMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianModel)
    (Marian 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertModel)
    (MobileBERT model)'
  id: totrans-1300
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [TFMobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertModel)
    (MobileBERT 模型)'
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [TFMobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTModel)
    (MobileViT model)'
  id: totrans-1301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    配置类: [TFMobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTModel)
    (MobileViT 模型)'
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [TFOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTModel)
    (OPT model)'
  id: totrans-1302
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    配置类: [TFOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTModel)
    (OPT 模型)'
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [TFOpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel)
    (OpenAI GPT model)'
  id: totrans-1303
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    配置类: [TFOpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel)
    (OpenAI GPT 模型)'
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [TFPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusModel)
    (Pegasus model)'
  id: totrans-1304
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    配置类: [TFPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusModel)
    (Pegasus 模型)'
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)
    (RegNet model)'
  id: totrans-1305
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    配置类: [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)
    (RegNet 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertModel)
    (RemBERT model)'
  id: totrans-1306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [TFRemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertModel)
    (RemBERT 模型)'
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel)
    (ResNet model)'
  id: totrans-1307
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    配置类: [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel)
    (ResNet 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerModel)
    (RoFormer model)'
  id: totrans-1308
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [TFRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerModel)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaModel)
    (RoBERTa model)'
  id: totrans-1309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [TFRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaModel)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [TFRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig)
    configuration class: [TFSamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.TFSamModel)
    (SAM model)'
  id: totrans-1311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SamConfig](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.SamConfig)
    配置类: [TFSamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.TFSamModel)
    (SAM 模型)'
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [TFSegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerModel)
    (SegFormer model)'
  id: totrans-1312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    配置类: [TFSegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerModel)
    (SegFormer 模型)'
- en: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    configuration class: [TFSpeech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel)
    (Speech2Text model)'
  id: totrans-1313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    配置类: [TFSpeech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel)
    (Speech2Text 模型)'
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [TFSwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinModel)
    (Swin Transformer model)'
  id: totrans-1314
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    配置类: [TFSwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinModel)
    (Swin Transformer 模型)'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model)
    (T5 model)'
  id: totrans-1315
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    配置类: [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model)
    (T5 模型)'
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasModel)
    (TAPAS model)'
  id: totrans-1316
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    配置类: [TFTapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasModel)
    (TAPAS 模型)'
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TFTransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel)
    (Transformer-XL model)'
  id: totrans-1317
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    配置类: [TFTransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel)
    (Transformer-XL 模型)'
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [TFViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTModel)
    (ViT model)'
  id: totrans-1318
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    配置类: [TFViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTModel)
    (ViT 模型)'
- en: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    configuration class: [TFViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEModel)
    (ViTMAE model)'
  id: totrans-1319
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    配置类: [TFViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEModel)
    (ViTMAE 模型)'
- en: '[VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    configuration class: [TFVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.TFVisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  id: totrans-1320
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    配置类：[TFVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.TFVisionTextDualEncoderModel)（VisionTextDualEncoder模型）'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [TFWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model)
    (Wav2Vec2 model)'
  id: totrans-1321
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类：[TFWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model)（Wav2Vec2模型）'
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel)
    (Whisper model)'
  id: totrans-1322
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    配置类：[TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel)（Whisper模型）'
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [TFXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMModel)
    (XGLM model)'
  id: totrans-1323
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    配置类：[TFXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMModel)（XGLM模型）'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMModel)
    (XLM model)'
  id: totrans-1324
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类：[TFXLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMModel)（XLM模型）'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel)
    (XLM-RoBERTa model)'
  id: totrans-1325
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类：[TFXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel)（XLM-RoBERTa模型）'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetModel)
    (XLNet model)'
  id: totrans-1326
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类：[TFXLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetModel)（XLNet模型）'
- en: Instantiates one of the base model classes of the library from a configuration.
  id: totrans-1327
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个基础模型类。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-1328
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只会影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-1329
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE29]'
  id: totrans-1330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '#### `from_pretrained`'
  id: totrans-1331
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-1332
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE30]'
  id: totrans-1333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parameters
  id: totrans-1334
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-1335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-1336
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-1337
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-1338
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并加载TensorFlow模型的加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-1339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）- 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-1340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）-
    模型使用的配置，而不是自动加载的配置。当以下情况发生时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-1341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库中提供的一个模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-1342
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-1343
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-1344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-1345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（参见
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-1346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-1347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-1348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如 `{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-1349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-1350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-1351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-1352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的模型文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-1353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上的代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-1354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*optional*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-1355
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-1356
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the base model classes of the library from a pretrained model.
  id: totrans-1357
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库的基本模型类之一。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-1358
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的 `model_type` 属性选择要实例化的模型类（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上进行模式匹配来回退：
- en: '`albert` — [TFAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertModel)
    (ALBERT model)'
  id: totrans-1359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [TFAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertModel)
    (ALBERT 模型)'
- en: '`bart` — [TFBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartModel)
    (BART model)'
  id: totrans-1360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [TFBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartModel)
    (BART 模型)'
- en: '`bert` — [TFBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertModel)
    (BERT model)'
  id: totrans-1361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [TFBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertModel)
    (BERT 模型)'
- en: '`blenderbot` — [TFBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel)
    (Blenderbot model)'
  id: totrans-1362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot` — [TFBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotModel)
    (Blenderbot 模型)'
- en: '`blenderbot-small` — [TFBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel)
    (BlenderbotSmall model)'
  id: totrans-1363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot-small` — [TFBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel)
    (BlenderbotSmall 模型)'
- en: '`blip` — [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP model)'
  id: totrans-1364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP 模型)'
- en: '`camembert` — [TFCamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertModel)
    (CamemBERT model)'
  id: totrans-1365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [TFCamembertModel](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertModel)
    (CamemBERT 模型)'
- en: '`clip` — [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP model)'
  id: totrans-1366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP 模型)'
- en: '`convbert` — [TFConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertModel)
    (ConvBERT model)'
  id: totrans-1367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [TFConvBertModel](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertModel)
    (ConvBERT 模型)'
- en: '`convnext` — [TFConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextModel)
    (ConvNeXT model)'
  id: totrans-1368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnext` — [TFConvNextModel](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextModel)
    (ConvNeXT 模型)'
- en: '`convnextv2` — [TFConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2Model)
    (ConvNeXTV2 model)'
  id: totrans-1369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnextv2` — [TFConvNextV2Model](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2Model)
    (ConvNeXTV2 模型)'
- en: '`ctrl` — [TFCTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLModel)
    (CTRL model)'
  id: totrans-1370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [TFCTRLModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLModel)
    (CTRL 模型)'
- en: '`cvt` — [TFCvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtModel)
    (CvT model)'
  id: totrans-1371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cvt` — [TFCvtModel](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtModel)
    (CvT 模型)'
- en: '`data2vec-vision` — [TFData2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionModel)
    (Data2VecVision model)'
  id: totrans-1372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-vision` — [TFData2VecVisionModel](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionModel)
    (Data2VecVision 模型)'
- en: '`deberta` — [TFDebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaModel)
    (DeBERTa model)'
  id: totrans-1373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [TFDebertaModel](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaModel)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [TFDebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model)
    (DeBERTa-v2 model)'
  id: totrans-1374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [TFDebertaV2Model](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2Model)
    (DeBERTa-v2 模型)'
- en: '`deit` — [TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel)
    (DeiT model)'
  id: totrans-1375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deit` — [TFDeiTModel](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTModel)
    (DeiT 模型)'
- en: '`distilbert` — [TFDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertModel)
    (DistilBERT model)'
  id: totrans-1376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [TFDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertModel)
    (DistilBERT 模型)'
- en: '`dpr` — [TFDPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder)
    (DPR model)'
  id: totrans-1377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpr` — [TFDPRQuestionEncoder](/docs/transformers/v4.37.2/en/model_doc/dpr#transformers.TFDPRQuestionEncoder)
    (DPR 模型)'
- en: '`efficientformer` — [TFEfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerModel)
    (EfficientFormer model)'
  id: totrans-1378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientformer` — [TFEfficientFormerModel](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerModel)
    (EfficientFormer 模型)'
- en: '`electra` — [TFElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraModel)
    (ELECTRA model)'
  id: totrans-1379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [TFElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraModel)
    (ELECTRA 模型)'
- en: '`esm` — [TFEsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmModel)
    (ESM model)'
  id: totrans-1380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [TFEsmModel](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmModel)
    (ESM 模型)'
- en: '`flaubert` — [TFFlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertModel)
    (FlauBERT model)'
  id: totrans-1381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [TFFlaubertModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertModel)
    (FlauBERT 模型)'
- en: '`funnel` — [TFFunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelModel)
    or [TFFunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelBaseModel)
    (Funnel Transformer model)'
  id: totrans-1382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [TFFunnelModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelModel)
    或 [TFFunnelBaseModel](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelBaseModel)
    (Funnel Transformer 模型)'
- en: '`gpt-sw3` — [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model)
    (GPT-Sw3 model)'
  id: totrans-1383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model)
    (OpenAI GPT-2 model)'
  id: totrans-1384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [TFGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2Model)
    (OpenAI GPT-2 模型)'
- en: '`gptj` — [TFGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJModel)
    (GPT-J model)'
  id: totrans-1385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [TFGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJModel)
    (GPT-J 模型)'
- en: '`groupvit` — [TFGroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.TFGroupViTModel)
    (GroupViT model)'
  id: totrans-1386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupvit` — [TFGroupViTModel](/docs/transformers/v4.37.2/en/model_doc/groupvit#transformers.TFGroupViTModel)
    (GroupViT 模型)'
- en: '`hubert` — [TFHubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.TFHubertModel)
    (Hubert model)'
  id: totrans-1387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hubert` — [TFHubertModel](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.TFHubertModel)
    (Hubert 模型)'
- en: '`layoutlm` — [TFLayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel)
    (LayoutLM model)'
  id: totrans-1388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [TFLayoutLMModel](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMModel)
    (LayoutLM 模型)'
- en: '`layoutlmv3` — [TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model)
    (LayoutLMv3 model)'
  id: totrans-1389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [TFLayoutLMv3Model](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model)
    (LayoutLMv3 模型)'
- en: '`led` — [TFLEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDModel)
    (LED model)'
  id: totrans-1390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`led` — [TFLEDModel](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDModel)
    (LED 模型)'
- en: '`longformer` — [TFLongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerModel)
    (Longformer model)'
  id: totrans-1391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [TFLongformerModel](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerModel)
    (Longformer 模型)'
- en: '`lxmert` — [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)
    (LXMERT model)'
  id: totrans-1392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lxmert` — [TFLxmertModel](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertModel)
    (LXMERT 模型)'
- en: '`marian` — [TFMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianModel)
    (Marian model)'
  id: totrans-1393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marian` — [TFMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianModel)
    (Marian 模型)'
- en: '`mbart` — [TFMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartModel)
    (mBART model)'
  id: totrans-1394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [TFMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartModel)
    (mBART 模型)'
- en: '`mobilebert` — [TFMobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertModel)
    (MobileBERT model)'
  id: totrans-1395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [TFMobileBertModel](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertModel)
    (MobileBERT 模型)'
- en: '`mobilevit` — [TFMobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTModel)
    (MobileViT model)'
  id: totrans-1396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevit` — [TFMobileViTModel](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTModel)
    (MobileViT 模型)'
- en: '`mpnet` — [TFMPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetModel)
    (MPNet model)'
  id: totrans-1397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [TFMPNetModel](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetModel)
    (MPNet 模型)'
- en: '`mt5` — [TFMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5Model)
    (MT5 model)'
  id: totrans-1398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [TFMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5Model)
    (MT5 模型)'
- en: '`openai-gpt` — [TFOpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel)
    (OpenAI GPT model)'
  id: totrans-1399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [TFOpenAIGPTModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel)
    (OpenAI GPT 模型)'
- en: '`opt` — [TFOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTModel)
    (OPT model)'
  id: totrans-1400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [TFOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTModel)
    (OPT 模型)'
- en: '`pegasus` — [TFPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusModel)
    (Pegasus model)'
  id: totrans-1401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus` — [TFPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusModel)
    (Pegasus 模型)'
- en: '`regnet` — [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)
    (RegNet model)'
  id: totrans-1402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regnet` — [TFRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetModel)
    (RegNet 模型)'
- en: '`rembert` — [TFRemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertModel)
    (RemBERT model)'
  id: totrans-1403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [TFRemBertModel](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertModel)
    (RemBERT 模型)'
- en: '`resnet` — [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel)
    (ResNet model)'
  id: totrans-1404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resnet` — [TFResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetModel)
    (ResNet 模型)'
- en: '`roberta` — [TFRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaModel)
    (RoBERTa model)'
  id: totrans-1405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [TFRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaModel)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [TFRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [TFRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [TFRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerModel)
    (RoFormer model)'
  id: totrans-1407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [TFRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerModel)
    (RoFormer 模型)'
- en: '`sam` — [TFSamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.TFSamModel)
    (SAM model)'
  id: totrans-1408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sam` — [TFSamModel](/docs/transformers/v4.37.2/en/model_doc/sam#transformers.TFSamModel)
    (SAM 模型)'
- en: '`segformer` — [TFSegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerModel)
    (SegFormer model)'
  id: totrans-1409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segformer` — [TFSegformerModel](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerModel)
    (SegFormer 模型)'
- en: '`speech_to_text` — [TFSpeech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel)
    (Speech2Text model)'
  id: totrans-1410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text` — [TFSpeech2TextModel](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel)
    (Speech2Text 模型)'
- en: '`swin` — [TFSwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinModel)
    (Swin Transformer model)'
  id: totrans-1411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin` — [TFSwinModel](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinModel)
    (Swin Transformer 模型)'
- en: '`t5` — [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model)
    (T5 model)'
  id: totrans-1412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [TFT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5Model)
    (T5 模型)'
- en: '`tapas` — [TFTapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasModel)
    (TAPAS model)'
  id: totrans-1413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TFTapasModel](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasModel)
    (TAPAS 模型)'
- en: '`transfo-xl` — [TFTransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel)
    (Transformer-XL model)'
  id: totrans-1414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TFTransfoXLModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLModel)
    (Transformer-XL 模型)'
- en: '`vision-text-dual-encoder` — [TFVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.TFVisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  id: totrans-1415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision-text-dual-encoder` — [TFVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.TFVisionTextDualEncoderModel)
    (VisionTextDualEncoder 模型)'
- en: '`vit` — [TFViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTModel)
    (ViT model)'
  id: totrans-1416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [TFViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTModel)
    (ViT 模型)'
- en: '`vit_mae` — [TFViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEModel)
    (ViTMAE model)'
  id: totrans-1417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_mae` — [TFViTMAEModel](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEModel)
    (ViTMAE 模型)'
- en: '`wav2vec2` — [TFWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model)
    (Wav2Vec2 model)'
  id: totrans-1418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [TFWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model)
    (Wav2Vec2 模型)'
- en: '`whisper` — [TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel)
    (Whisper model)'
  id: totrans-1419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel)
    (Whisper 模型)'
- en: '`xglm` — [TFXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMModel)
    (XGLM model)'
  id: totrans-1420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xglm` — [TFXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMModel)
    (XGLM 模型)'
- en: '`xlm` — [TFXLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMModel)
    (XLM model)'
  id: totrans-1421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [TFXLMModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMModel)
    (XLM 模型)'
- en: '`xlm-roberta` — [TFXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel)
    (XLM-RoBERTa model)'
  id: totrans-1422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [TFXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel)
    (XLM-RoBERTa 模型)'
- en: '`xlnet` — [TFXLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetModel)
    (XLNet model)'
  id: totrans-1423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [TFXLNetModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetModel)
    (XLNet 模型)'
- en: 'Examples:'
  id: totrans-1424
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE31]'
  id: totrans-1425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: FlaxAutoModel
  id: totrans-1426
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModel
- en: '### `class transformers.FlaxAutoModel`'
  id: totrans-1427
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L276)'
  id: totrans-1428
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L276)'
- en: '[PRE32]'
  id: totrans-1429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This is a generic model class that will be instantiated as one of the base model
    classes of the library when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-1430
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库的基础模型类之一。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-1431
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-1432
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-1433
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE33]'
  id: totrans-1434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Parameters
  id: totrans-1435
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-1436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertModel)
    (ALBERT model)'
  id: totrans-1437
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    配置类：[FlaxAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertModel)（ALBERT
    模型）'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartModel)
    (BART model)'
  id: totrans-1438
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    配置类：[FlaxBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartModel)（BART
    模型）'
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [FlaxBeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitModel)
    (BEiT model)'
  id: totrans-1439
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    配置类：[FlaxBeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitModel)（BEiT
    模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertModel)
    (BERT model)'
  id: totrans-1440
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类：[FlaxBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertModel)（BERT
    模型）'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel)
    (BigBird model)'
  id: totrans-1441
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    配置类：[FlaxBigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel)（BigBird
    模型）'
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [FlaxBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel)
    (Blenderbot model)'
  id: totrans-1442
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    配置类：[FlaxBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel)（Blenderbot
    模型）'
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [FlaxBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel)
    (BlenderbotSmall model)'
  id: totrans-1443
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    配置类：[FlaxBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel)（BlenderbotSmall
    模型）'
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [FlaxBloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomModel)
    (BLOOM model)'
  id: totrans-1444
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    配置类：[FlaxBloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomModel)（BLOOM
    模型）'
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [FlaxCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPModel)
    (CLIP model)'
  id: totrans-1445
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    配置类：[FlaxCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPModel)（CLIP
    模型）'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel)
    (DistilBERT model)'
  id: totrans-1446
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类：[FlaxDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel)（DistilBERT
    模型）'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraModel)
    (ELECTRA model)'
  id: totrans-1447
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类：[FlaxElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraModel)（ELECTRA
    模型）'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)
    (OpenAI GPT-2 model)'
  id: totrans-1448
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    配置类：[FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)（OpenAI
    GPT-2 模型）'
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [FlaxGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJModel)
    (GPT-J model)'
  id: totrans-1449
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    配置类：[FlaxGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJModel)（GPT-J
    模型）'
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [FlaxGPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel)
    (GPT Neo model)'
  id: totrans-1450
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    配置类: [FlaxGPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel)
    (GPT Neo 模型)'
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [FlaxLlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaModel)
    (LLaMA model)'
  id: totrans-1451
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    配置类: [FlaxLlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaModel)
    (LLaMA 模型)'
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [FlaxLongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5Model)
    (LongT5 model)'
  id: totrans-1452
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    配置类: [FlaxLongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5Model)
    (LongT5 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartModel)
    (mBART model)'
  id: totrans-1453
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类: [FlaxMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartModel)
    (mBART 模型)'
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [FlaxMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5Model)
    (MT5 model)'
  id: totrans-1454
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    配置类: [FlaxMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5Model)
    (MT5 模型)'
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [FlaxMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianModel)
    (Marian model)'
  id: totrans-1455
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    配置类: [FlaxMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianModel)
    (Marian 模型)'
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [FlaxOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTModel)
    (OPT model)'
  id: totrans-1456
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    配置类: [FlaxOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTModel)
    (OPT 模型)'
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [FlaxPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusModel)
    (Pegasus model)'
  id: totrans-1457
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    配置类: [FlaxPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusModel)
    (Pegasus 模型)'
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [FlaxRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetModel)
    (RegNet model)'
  id: totrans-1458
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    配置类: [FlaxRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetModel)
    (RegNet 模型)'
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [FlaxResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetModel)
    (ResNet model)'
  id: totrans-1459
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    配置类: [FlaxResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetModel)
    (ResNet 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerModel)
    (RoFormer model)'
  id: totrans-1460
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [FlaxRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerModel)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaModel)
    (RoBERTa model)'
  id: totrans-1461
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [FlaxRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaModel)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1462
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [FlaxRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [FlaxT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5Model)
    (T5 model)'
  id: totrans-1463
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    配置类: [FlaxT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5Model)
    (T5 模型)'
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [FlaxViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTModel)
    (ViT model)'
  id: totrans-1464
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    配置类: [FlaxViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTModel)
    (ViT 模型)'
- en: '[VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    configuration class: [FlaxVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  id: totrans-1465
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisionTextDualEncoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig)
    配置类: [FlaxVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel)
    (VisionTextDualEncoder 模型)'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [FlaxWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model)
    (Wav2Vec2 model)'
  id: totrans-1466
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类: [FlaxWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model)
    (Wav2Vec2 模型)'
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [FlaxWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperModel)
    (Whisper model)'
  id: totrans-1467
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    配置类: [FlaxWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperModel)
    (Whisper 模型)'
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [FlaxXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMModel)
    (XGLM model)'
  id: totrans-1468
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    配置类: [FlaxXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMModel)
    (XGLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel)
    (XLM-RoBERTa model)'
  id: totrans-1469
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [FlaxXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel)
    (XLM-RoBERTa 模型)'
- en: Instantiates one of the base model classes of the library from a configuration.
  id: totrans-1470
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库中的基础模型类之一。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-1471
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-1472
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE34]'
  id: totrans-1473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '#### `from_pretrained`'
  id: totrans-1474
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-1475
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE35]'
  id: totrans-1476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-1477
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-1478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是:'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-1479
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型存储库内。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-1480
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-1481
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *PyTorch state_dict save file* 的路径或 URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应提供配置对象作为 `config` 参数。这种加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow
    模型并随后加载 TensorFlow 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-1482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args` (额外的位置参数, *可选*) — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-1483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *可选*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载:'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-1484
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-1485
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-1486
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-1487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-1488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *可选*, 默认为 `False`) — 从 PyTorch checkpoint save 文件加载模型权重（参见
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-1489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-1490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-1491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-1492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-1493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-1494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于
    git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-1495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-1496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *可选*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-1497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了
    `config` 或自动加载，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-1498
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-1499
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个键对应于配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the base model classes of the library from a pretrained model.
  id: totrans-1500
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库的基本模型类之一。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-1501
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的 `model_type` 属性选择要实例化的模型类（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），或者当缺失时，通过在
    `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [FlaxAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertModel)
    (ALBERT model)'
  id: totrans-1502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [FlaxAlbertModel](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertModel)
    (ALBERT 模型)'
- en: '`bart` — [FlaxBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartModel)
    (BART model)'
  id: totrans-1503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [FlaxBartModel](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartModel)
    (BART 模型)'
- en: '`beit` — [FlaxBeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitModel)
    (BEiT model)'
  id: totrans-1504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beit` — [FlaxBeitModel](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitModel)
    (BEiT 模型)'
- en: '`bert` — [FlaxBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertModel)
    (BERT model)'
  id: totrans-1505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [FlaxBertModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertModel)
    (BERT 模型)'
- en: '`big_bird` — [FlaxBigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel)
    (BigBird model)'
  id: totrans-1506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [FlaxBigBirdModel](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdModel)
    (BigBird 模型)'
- en: '`blenderbot` — [FlaxBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel)
    (Blenderbot model)'
  id: totrans-1507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot` — [FlaxBlenderbotModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel)
    (Blenderbot 模型)'
- en: '`blenderbot-small` — [FlaxBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel)
    (BlenderbotSmall model)'
  id: totrans-1508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot-small` — [FlaxBlenderbotSmallModel](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel)
    (BlenderbotSmall 模型)'
- en: '`bloom` — [FlaxBloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomModel)
    (BLOOM model)'
  id: totrans-1509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [FlaxBloomModel](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomModel)
    (BLOOM 模型)'
- en: '`clip` — [FlaxCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPModel)
    (CLIP model)'
  id: totrans-1510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [FlaxCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.FlaxCLIPModel)
    (CLIP 模型)'
- en: '`distilbert` — [FlaxDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel)
    (DistilBERT model)'
  id: totrans-1511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [FlaxDistilBertModel](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertModel)
    (DistilBERT 模型)'
- en: '`electra` — [FlaxElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraModel)
    (ELECTRA model)'
  id: totrans-1512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [FlaxElectraModel](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraModel)（ELECTRA模型）'
- en: '`gpt-sw3` — [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)
    (GPT-Sw3 model)'
  id: totrans-1513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)（GPT-Sw3模型）'
- en: '`gpt2` — [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)
    (OpenAI GPT-2 model)'
  id: totrans-1514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [FlaxGPT2Model](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2Model)（OpenAI
    GPT-2模型）'
- en: '`gpt_neo` — [FlaxGPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel)
    (GPT Neo model)'
  id: totrans-1515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neo` — [FlaxGPTNeoModel](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel)（GPT
    Neo模型）'
- en: '`gptj` — [FlaxGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJModel)
    (GPT-J model)'
  id: totrans-1516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [FlaxGPTJModel](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJModel)（GPT-J模型）'
- en: '`llama` — [FlaxLlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaModel)
    (LLaMA model)'
  id: totrans-1517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llama` — [FlaxLlamaModel](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaModel)（LLaMA模型）'
- en: '`longt5` — [FlaxLongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5Model)
    (LongT5 model)'
  id: totrans-1518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longt5` — [FlaxLongT5Model](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5Model)（LongT5模型）'
- en: '`marian` — [FlaxMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianModel)
    (Marian model)'
  id: totrans-1519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marian` — [FlaxMarianModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianModel)（Marian模型）'
- en: '`mbart` — [FlaxMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartModel)
    (mBART model)'
  id: totrans-1520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [FlaxMBartModel](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartModel)（mBART模型）'
- en: '`mt5` — [FlaxMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5Model)
    (MT5 model)'
  id: totrans-1521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [FlaxMT5Model](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5Model)（MT5模型）'
- en: '`opt` — [FlaxOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTModel)
    (OPT model)'
  id: totrans-1522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [FlaxOPTModel](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTModel)（OPT模型）'
- en: '`pegasus` — [FlaxPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusModel)
    (Pegasus model)'
  id: totrans-1523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus` — [FlaxPegasusModel](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusModel)（Pegasus模型）'
- en: '`regnet` — [FlaxRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetModel)
    (RegNet model)'
  id: totrans-1524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regnet` — [FlaxRegNetModel](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetModel)（RegNet模型）'
- en: '`resnet` — [FlaxResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetModel)
    (ResNet model)'
  id: totrans-1525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resnet` — [FlaxResNetModel](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetModel)（ResNet模型）'
- en: '`roberta` — [FlaxRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaModel)
    (RoBERTa model)'
  id: totrans-1526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [FlaxRobertaModel](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaModel)（RoBERTa模型）'
- en: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormModel)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormModel](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormModel)（RoBERTa-PreLayerNorm模型）'
- en: '`roformer` — [FlaxRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerModel)
    (RoFormer model)'
  id: totrans-1528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [FlaxRoFormerModel](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerModel)（RoFormer模型）'
- en: '`t5` — [FlaxT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5Model)
    (T5 model)'
  id: totrans-1529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [FlaxT5Model](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5Model)（T5模型）'
- en: '`vision-text-dual-encoder` — [FlaxVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel)
    (VisionTextDualEncoder model)'
  id: totrans-1530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision-text-dual-encoder` — [FlaxVisionTextDualEncoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel)（VisionTextDualEncoder模型）'
- en: '`vit` — [FlaxViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTModel)
    (ViT model)'
  id: totrans-1531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [FlaxViTModel](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTModel)（ViT模型）'
- en: '`wav2vec2` — [FlaxWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model)
    (Wav2Vec2 model)'
  id: totrans-1532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [FlaxWav2Vec2Model](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model)（Wav2Vec2模型）'
- en: '`whisper` — [FlaxWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperModel)
    (Whisper model)'
  id: totrans-1533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [FlaxWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperModel)（Whisper模型）'
- en: '`xglm` — [FlaxXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMModel)
    (XGLM model)'
  id: totrans-1534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xglm` — [FlaxXGLMModel](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMModel)（XGLM模型）'
- en: '`xlm-roberta` — [FlaxXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel)
    (XLM-RoBERTa model)'
  id: totrans-1535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [FlaxXLMRobertaModel](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel)（XLM-RoBERTa模型）'
- en: 'Examples:'
  id: totrans-1536
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE36]'
  id: totrans-1537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Generic pretraining classes
  id: totrans-1538
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通用预训练类
- en: The following auto classes are available for instantiating a model with a pretraining
    head.
  id: totrans-1539
  prefs: []
  type: TYPE_NORMAL
  zh: 以下自动类可用于实例化带有预训练头部的模型。
- en: AutoModelForPreTraining
  id: totrans-1540
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForPreTraining
- en: '### `class transformers.AutoModelForPreTraining`'
  id: totrans-1541
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForPreTraining`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1311)'
  id: totrans-1542
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1311)'
- en: '[PRE37]'
  id: totrans-1543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a pretraining head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-1544
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有预训练头部）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-1545
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-1546
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-1547
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE38]'
  id: totrans-1548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Parameters
  id: totrans-1549
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-1550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类:'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForPreTraining)
    (ALBERT model)'
  id: totrans-1551
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig)
    配置类: [AlbertForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertForPreTraining)
    (ALBERT 模型)'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  id: totrans-1552
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartConfig)
    配置类: [BartForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForPreTraining)
    (BERT model)'
  id: totrans-1553
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig)
    配置类: [BertForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertForPreTraining)
    (BERT 模型)'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForPreTraining)
    (BigBird model)'
  id: totrans-1554
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdConfig)
    配置类: [BigBirdForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdForPreTraining)
    (BigBird 模型)'
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM model)'
  id: totrans-1555
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BloomConfig](/docs/transformers/v4.37.2/zh/model_doc/bloom#transformers.BloomConfig)
    配置类: [BloomForCausalLM](/docs/transformers/v4.37.2/zh/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM 模型)'
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL model)'
  id: totrans-1556
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CTRLConfig](/docs/transformers/v4.37.2/zh/model_doc/ctrl#transformers.CTRLConfig)
    配置类: [CTRLLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL 模型)'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT model)'
  id: totrans-1557
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertConfig)
    配置类: [CamembertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT 模型)'
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText model)'
  id: totrans-1558
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecTextConfig](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextConfig)
    配置类: [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText 模型)'
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa model)'
  id: totrans-1559
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaConfig](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaConfig)
    配置类: [DebertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa 模型)'
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  id: totrans-1560
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaV2Config](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2Config)
    配置类: [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 模型)'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-1561
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [DistilBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForPreTraining)
    (ELECTRA model)'
  id: totrans-1562
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraConfig)
    配置类: [ElectraForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraForPreTraining)
    (ELECTRA 模型)'
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForPreTraining](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForPreTraining)
    (ERNIE model)'
  id: totrans-1563
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieConfig](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieConfig)
    配置类: [ErnieForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieForPreTraining)
    (ERNIE 模型)'
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForPreTraining](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForPreTraining)
    (FNet model)'
  id: totrans-1564
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FNetConfig](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetConfig)
    配置类: [FNetForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetForPreTraining)
    (FNet 模型)'
- en: '[FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    configuration class: [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq Machine-Translation model)'
  id: totrans-1565
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FSMTConfig](/docs/transformers/v4.37.2/zh/model_doc/fsmt#transformers.FSMTConfig)
    配置类: [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq 机器翻译模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT model)'
  id: totrans-1566
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT 模型)'
- en: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    configuration class: [FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining)
    (FLAVA model)'
  id: totrans-1567
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlavaConfig](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaConfig)
    配置类: [FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining)
    (FLAVA 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForPreTraining)
    (Funnel Transformer model)'
  id: totrans-1568
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [FunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForPreTraining)
    (Funnel Transformer 模型)'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-1569
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    配置类: [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 模型)'
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode model)'
  id: totrans-1570
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    配置类: [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode 模型)'
- en: '[GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    configuration class: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  id: totrans-1571
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    配置类: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese 模型)'
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT model)'
  id: totrans-1572
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    配置类: [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT 模型)'
- en: '[IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)
    configuration class: [IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text)
    (IDEFICS model)'
  id: totrans-1573
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IdeficsConfig](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsConfig)
    配置类: [IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text)
    (IDEFICS 模型)'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM model)'
  id: totrans-1574
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类: [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM 模型)'
- en: '[LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig)
    configuration class: [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa model)'
  id: totrans-1575
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig)
    配置类: [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer model)'
  id: totrans-1576
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer 模型)'
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE model)'
  id: totrans-1577
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    配置类: [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE 模型)'
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)
    (LXMERT model)'
  id: totrans-1578
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    配置类: [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)
    (LXMERT 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet model)'
  id: totrans-1579
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet 模型)'
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA model)'
  id: totrans-1580
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    配置类: [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA 模型)'
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining)
    (Megatron-BERT model)'
  id: totrans-1581
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    配置类: [MegatronBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining)
    (Megatron-BERT 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining)
    (MobileBERT model)'
  id: totrans-1582
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [MobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining)
    (MobileBERT 模型)'
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT model)'
  id: totrans-1583
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    配置类: [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT 模型)'
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA model)'
  id: totrans-1584
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    配置类: [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA 模型)'
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  id: totrans-1585
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    配置类: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP 模型)'
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForPreTraining)
    (Nezha model)'
  id: totrans-1586
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    配置类: [NezhaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForPreTraining)
    (Nezha 模型)'
- en: '[NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    configuration class: [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE model)'
  id: totrans-1587
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    配置类: [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE 模型)'
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  id: totrans-1588
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    配置类: [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT 模型)'
- en: '[RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig)
    configuration class: [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT model)'
  id: totrans-1589
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RetriBertConfig](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertConfig)
    配置类: [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT 模型)'
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForPreTraining)
    (RoCBert model)'
  id: totrans-1590
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    配置类: [RoCBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForPreTraining)
    (RoCBert 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-1591
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1592
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    configuration class: [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV model)'
  id: totrans-1593
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    配置类: [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV 模型)'
- en: '[SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    configuration class: [SplinterForPreTraining](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForPreTraining)
    (Splinter model)'
  id: totrans-1594
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    配置类: [SplinterForPreTraining](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForPreTraining)
    (Splinter 模型)'
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT model)'
  id: totrans-1595
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    配置类: [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT 模型)'
- en: '[SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    configuration class: [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers model)'
  id: totrans-1596
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    配置类: [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers 模型)'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 model)'
  id: totrans-1597
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    配置类: [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 模型)'
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS model)'
  id: totrans-1598
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    配置类: [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS 模型)'
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL model)'
  id: totrans-1599
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    配置类: [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL 模型)'
- en: '[TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig)
    configuration class: [TvltForPreTraining](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltForPreTraining)
    (TVLT model)'
  id: totrans-1600
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TvltConfig](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltConfig)
    配置类: [TvltForPreTraining](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltForPreTraining)
    (TVLT 模型)'
- en: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    configuration class: [UniSpeechForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining)
    (UniSpeech model)'
  id: totrans-1601
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    配置类: [UniSpeechForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining)
    (UniSpeech 模型)'
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining)
    (UniSpeechSat model)'
  id: totrans-1602
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    配置类: [UniSpeechSatForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining)
    (UniSpeechSat 模型)'
- en: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    configuration class: [ViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining)
    (ViTMAE model)'
  id: totrans-1603
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    配置类: [ViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining)
    (ViTMAE 模型)'
- en: '[VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    configuration class: [VideoMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForPreTraining)
    (VideoMAE model)'
  id: totrans-1604
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    配置类: [VideoMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForPreTraining)
    (VideoMAE 模型)'
- en: '[VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig)
    configuration class: [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava model)'
  id: totrans-1605
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig)
    配置类: [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava 模型)'
- en: '[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)
    configuration class: [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)
    (VisualBERT model)'
  id: totrans-1606
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisualBertConfig](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertConfig)
    配置类: [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)
    (VisualBERT 模型)'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining)
    (Wav2Vec2 model)'
  id: totrans-1607
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类: [Wav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining)
    (Wav2Vec2 模型)'
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining)
    (Wav2Vec2-Conformer model)'
  id: totrans-1608
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    配置类: [Wav2Vec2ConformerForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining)
    (Wav2Vec2-Conformer 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  id: totrans-1609
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-1610
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa 模型)'
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL model)'
  id: totrans-1611
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    配置类: [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL 模型)'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet model)'
  id: totrans-1612
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类: [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet 模型)'
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD model)'
  id: totrans-1613
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    配置类: [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD 模型)'
- en: Instantiates one of the model classes of the library (with a pretraining head)
    from a configuration.
  id: totrans-1614
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有预训练头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-1615
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-1616
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE39]'
  id: totrans-1617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '#### `from_pretrained`'
  id: totrans-1618
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-1619
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE40]'
  id: totrans-1620
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Parameters
  id: totrans-1621
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-1622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-1623
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库内的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-1624
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-1625
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*TensorFlow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-1626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-1627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-1628
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-1629
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-1630
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-1631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-1632
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-1633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-1634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-1635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-1636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除未完全接收的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-1637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 要使用的代理服务器的字典，按协议或端点，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理将在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-1638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-1639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-1640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-1641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-1642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-1643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了
    `config` 或自动加载了 `config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-1644
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-1645
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个与配置属性对应的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a pretraining head)
    from a pretrained model.
  id: totrans-1646
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有预训练头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-1647
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path`
    加载，如果可能的话），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [AlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForPreTraining)
    (ALBERT model)'
  id: totrans-1648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [AlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForPreTraining)
    (ALBERT 模型)'
- en: '`bart` — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  id: totrans-1649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART 模型)'
- en: '`bert` — [BertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForPreTraining)
    (BERT model)'
  id: totrans-1650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForPreTraining)
    (BERT 模型)'
- en: '`big_bird` — [BigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForPreTraining)
    (BigBird model)'
  id: totrans-1651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForPreTraining)
    (BigBird 模型)'
- en: '`bloom` — [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM model)'
  id: totrans-1652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM 模型)'
- en: '`camembert` — [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT model)'
  id: totrans-1653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT 模型)'
- en: '`ctrl` — [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL model)'
  id: totrans-1654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL 模型)'
- en: '`data2vec-text` — [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText model)'
  id: totrans-1655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText 模型)'
- en: '`deberta` — [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa model)'
  id: totrans-1656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  id: totrans-1657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-1658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT 模型)'
- en: '`electra` — [ElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForPreTraining)
    (ELECTRA model)'
  id: totrans-1659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForPreTraining)
    (ELECTRA 模型)'
- en: '`ernie` — [ErnieForPreTraining](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForPreTraining)
    (ERNIE model)'
  id: totrans-1660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [ErnieForPreTraining](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForPreTraining)
    (ERNIE 模型)'
- en: '`flaubert` — [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT model)'
  id: totrans-1661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT 模型)'
- en: '`flava` — [FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining)
    (FLAVA model)'
  id: totrans-1662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flava` — [FlavaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/flava#transformers.FlavaForPreTraining)
    (FLAVA 模型)'
- en: '`fnet` — [FNetForPreTraining](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForPreTraining)
    (FNet model)'
  id: totrans-1663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` — [FNetForPreTraining](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForPreTraining)
    (FNet 模型)'
- en: '`fsmt` — [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq Machine-Translation model)'
  id: totrans-1664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fsmt` — [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq 机器翻译模型)'
- en: '`funnel` — [FunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForPreTraining)
    (Funnel Transformer model)'
  id: totrans-1665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [FunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForPreTraining)
    (Funnel Transformer 模型)'
- en: '`gpt-sw3` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (GPT-Sw3 model)'
  id: totrans-1666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-1667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 模型)'
- en: '`gpt_bigcode` — [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode model)'
  id: totrans-1668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_bigcode` — [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode 模型)'
- en: '`gptsan-japanese` — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  id: totrans-1669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptsan-japanese` — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese 模型)'
- en: '`ibert` — [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT model)'
  id: totrans-1670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ibert` — [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT 模型)'
- en: '`idefics` — [IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text)
    (IDEFICS model)'
  id: totrans-1671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`idefics` — [IdeficsForVisionText2Text](/docs/transformers/v4.37.2/en/model_doc/idefics#transformers.IdeficsForVisionText2Text)
    (IDEFICS 模型)'
- en: '`layoutlm` — [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM model)'
  id: totrans-1672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM 模型)'
- en: '`llava` — [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa model)'
  id: totrans-1673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llava` — [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa 模型)'
- en: '`longformer` — [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer model)'
  id: totrans-1674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer 模型)'
- en: '`luke` — [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE model)'
  id: totrans-1675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`luke` — [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE 模型)'
- en: '`lxmert` — [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)
    (LXMERT model)'
  id: totrans-1676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lxmert` — [LxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForPreTraining)
    (LXMERT 模型)'
- en: '`mega` — [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA model)'
  id: totrans-1677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA 模型)'
- en: '`megatron-bert` — [MegatronBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining)
    (Megatron-BERT model)'
  id: totrans-1678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [MegatronBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining)
    (Megatron-BERT 模型)'
- en: '`mobilebert` — [MobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining)
    (MobileBERT model)'
  id: totrans-1679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [MobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForPreTraining)
    (MobileBERT 模型)'
- en: '`mpnet` — [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet model)'
  id: totrans-1680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet 模型)'
- en: '`mpt` — [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT model)'
  id: totrans-1681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpt` — [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT 模型)'
- en: '`mra` — [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA model)'
  id: totrans-1682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mra` — [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA 模型)'
- en: '`mvp` — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  id: totrans-1683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mvp` — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP 模型)'
- en: '`nezha` — [NezhaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForPreTraining)
    (Nezha model)'
  id: totrans-1684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` — [NezhaForPreTraining](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForPreTraining)
    (Nezha 模型)'
- en: '`nllb-moe` — [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE model)'
  id: totrans-1685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nllb-moe` — [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE 模型)'
- en: '`openai-gpt` — [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  id: totrans-1686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT 模型)'
- en: '`retribert` — [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT model)'
  id: totrans-1687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`retribert` — [RetriBertModel](/docs/transformers/v4.37.2/en/model_doc/retribert#transformers.RetriBertModel)
    (RetriBERT 模型)'
- en: '`roberta` — [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-1688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roc_bert` — [RoCBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForPreTraining)
    (RoCBert model)'
  id: totrans-1690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForPreTraining)
    (RoCBert 模型)'
- en: '`rwkv` — [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV model)'
  id: totrans-1691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rwkv` — [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV 模型)'
- en: '`splinter` — [SplinterForPreTraining](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForPreTraining)
    (Splinter model)'
  id: totrans-1692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`splinter` — [SplinterForPreTraining](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForPreTraining)
    (Splinter 模型)'
- en: '`squeezebert` — [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT model)'
  id: totrans-1693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`squeezebert` — [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT 模型)'
- en: '`switch_transformers` — [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers model)'
  id: totrans-1694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`switch_transformers` — [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers 模型)'
- en: '`t5` — [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 model)'
  id: totrans-1695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 模型)'
- en: '`tapas` — [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS model)'
  id: totrans-1696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS 模型)'
- en: '`transfo-xl` — [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL model)'
  id: totrans-1697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL 模型)'
- en: '`tvlt` — [TvltForPreTraining](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltForPreTraining)
    (TVLT model)'
  id: totrans-1698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tvlt` — [TvltForPreTraining](/docs/transformers/v4.37.2/en/model_doc/tvlt#transformers.TvltForPreTraining)
    (TVLT 模型)'
- en: '`unispeech` — [UniSpeechForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining)
    (UniSpeech model)'
  id: totrans-1699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech` — [UniSpeechForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForPreTraining)
    (UniSpeech 模型)'
- en: '`unispeech-sat` — [UniSpeechSatForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining)
    (UniSpeechSat model)'
  id: totrans-1700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech-sat` — [UniSpeechSatForPreTraining](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining)
    (UniSpeechSat 模型)'
- en: '`videomae` — [VideoMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForPreTraining)
    (VideoMAE model)'
  id: totrans-1701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`videomae` — [VideoMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForPreTraining)
    (VideoMAE 模型)'
- en: '`vipllava` — [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava model)'
  id: totrans-1702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vipllava` — [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava 模型)'
- en: '`visual_bert` — [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)
    (VisualBERT model)'
  id: totrans-1703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visual_bert` — [VisualBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/visual_bert#transformers.VisualBertForPreTraining)
    (VisualBERT 模型)'
- en: '`vit_mae` — [ViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining)
    (ViTMAE model)'
  id: totrans-1704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_mae` — [ViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining)
    (ViTMAE 模型)'
- en: '`wav2vec2` — [Wav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining)
    (Wav2Vec2 model)'
  id: totrans-1705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining)
    (Wav2Vec2 模型)'
- en: '`wav2vec2-conformer` — [Wav2Vec2ConformerForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining)
    (Wav2Vec2-Conformer model)'
  id: totrans-1706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2ConformerForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining)
    (Wav2Vec2-Conformer 模型)'
- en: '`xlm` — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  id: totrans-1707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM 模型)'
- en: '`xlm-roberta` — [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-1708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa 模型)'
- en: '`xlm-roberta-xl` — [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL model)'
  id: totrans-1709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL 模型)'
- en: '`xlnet` — [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet model)'
  id: totrans-1710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet 模型)'
- en: '`xmod` — [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD model)'
  id: totrans-1711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD 模型)'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-1712
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-1713
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE41]'
  id: totrans-1714
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: TFAutoModelForPreTraining
  id: totrans-1715
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForPreTraining
- en: '### `class transformers.TFAutoModelForPreTraining`'
  id: totrans-1716
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForPreTraining`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L547)'
  id: totrans-1717
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L547)'
- en: '[PRE42]'
  id: totrans-1718
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a pretraining head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-1719
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有预训练头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-1720
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-1721
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-1722
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE43]'
  id: totrans-1723
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Parameters
  id: totrans-1724
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-1725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForPreTraining)
    (ALBERT model)'
  id: totrans-1726
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[TFAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForPreTraining)（ALBERT模型）'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART model)'
  id: totrans-1727
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)配置类：[TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)（BART模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForPreTraining)
    (BERT model)'
  id: totrans-1728
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[TFBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForPreTraining)（BERT模型）'
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL model)'
  id: totrans-1729
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)配置类：[TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)（CTRL模型）'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT model)'
  id: totrans-1730
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)配置类：[TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)（CamemBERT模型）'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-1731
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)配置类：[TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)（DistilBERT模型）'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForPreTraining)
    (ELECTRA model)'
  id: totrans-1732
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)配置类：[TFElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForPreTraining)（ELECTRA模型）'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT model)'
  id: totrans-1733
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)配置类：[TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)（FlauBERT模型）'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining)
    (Funnel Transformer model)'
  id: totrans-1734
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)配置类：[TFFunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining)（漏斗Transformer模型）'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-1735
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)配置类：[TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)（OpenAI
    GPT-2模型）'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM model)'
  id: totrans-1736
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)配置类：[TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)（LayoutLM模型）'
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining)
    (LXMERT model)'
  id: totrans-1737
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)配置类：[TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining)（LXMERT模型）'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet model)'
  id: totrans-1738
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)配置类：[TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)（MPNet模型）'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining)
    (MobileBERT model)'
  id: totrans-1739
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类：[TFMobileBertForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.TFMobileBertForPreTraining)（MobileBERT
    模型）'
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  id: totrans-1740
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/zh/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    配置类：[TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)（OpenAI
    GPT 模型）'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-1741
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.RobertaConfig)
    配置类：[TFRobertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.TFRobertaForMaskedLM)（RoBERTa
    模型）'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1742
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类：[TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)（RoBERTa-PreLayerNorm
    模型）'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 model)'
  id: totrans-1743
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/zh/model_doc/t5#transformers.T5Config)
    配置类：[TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/t5#transformers.TFT5ForConditionalGeneration)（T5
    模型）'
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS model)'
  id: totrans-1744
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TapasConfig](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TapasConfig)
    配置类：[TFTapasForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TFTapasForMaskedLM)（TAPAS
    模型）'
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL model)'
  id: totrans-1745
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TransfoXLConfig](/docs/transformers/v4.37.2/zh/model_doc/transfo-xl#transformers.TransfoXLConfig)
    配置类：[TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)（Transformer-XL
    模型）'
- en: '[ViTMAEConfig](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.ViTMAEConfig)
    configuration class: [TFViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining)
    (ViTMAE model)'
  id: totrans-1746
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTMAEConfig](/docs/transformers/v4.37.2/zh/model_doc/vit_mae#transformers.ViTMAEConfig)
    配置类：[TFViTMAEForPreTraining](/docs/transformers/v4.37.2/zh/model_doc/vit_mae#transformers.TFViTMAEForPreTraining)（ViTMAE
    模型）'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  id: totrans-1747
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.XLMConfig)
    配置类：[TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.TFXLMWithLMHeadModel)（XLM
    模型）'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-1748
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类：[TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)（XLM-RoBERTa
    模型）'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet model)'
  id: totrans-1749
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.XLNetConfig)
    配置类：[TFXLNetLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.TFXLNetLMHeadModel)（XLNet
    模型）'
- en: Instantiates one of the model classes of the library (with a pretraining head)
    from a configuration.
  id: totrans-1750
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有预训练头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-1751
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型 **不会** 加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-1752
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE44]'
  id: totrans-1753
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '#### `from_pretrained`'
  id: totrans-1754
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-1755
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE45]'
  id: totrans-1756
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Parameters
  id: totrans-1757
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-1758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-1759
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-1760
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-1761
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或 URL 指向 *PyTorch state_dict 保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应提供配置对象作为 `config` 参数。这种加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow
    模型并随后加载 TensorFlow 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-1762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-1763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*optional*）
    — 用于模型的配置，而不是自动加载的配置。当以下情况发生时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-1764
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-1765
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-1766
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为 *config.json* 的配置 JSON 文件加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-1767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-1768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-1769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制下载（重新下载）模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-1770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-1771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-1772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-1773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-1774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-1775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行
    Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-1776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-1777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*optional*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-1778
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-1779
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个对应配置属性的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a pretraining head)
    from a pretrained model.
  id: totrans-1780
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有预训练头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-1781
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path`
    加载，如果可能的话），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [TFAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForPreTraining)
    (ALBERT model)'
  id: totrans-1782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [TFAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForPreTraining)
    (ALBERT 模型)'
- en: '`bart` — [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART model)'
  id: totrans-1783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART 模型)'
- en: '`bert` — [TFBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForPreTraining)
    (BERT model)'
  id: totrans-1784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [TFBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForPreTraining)
    (BERT 模型)'
- en: '`camembert` — [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT model)'
  id: totrans-1785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT 模型)'
- en: '`ctrl` — [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL model)'
  id: totrans-1786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL 模型)'
- en: '`distilbert` — [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-1787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT 模型)'
- en: '`electra` — [TFElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForPreTraining)
    (ELECTRA model)'
  id: totrans-1788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [TFElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForPreTraining)
    (ELECTRA 模型)'
- en: '`flaubert` — [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT model)'
  id: totrans-1789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT 模型)'
- en: '`funnel` — [TFFunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining)
    (Funnel Transformer model)'
  id: totrans-1790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [TFFunnelForPreTraining](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForPreTraining)
    (Funnel Transformer 模型)'
- en: '`gpt-sw3` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (GPT-Sw3 model)'
  id: totrans-1791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-1792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 模型)'
- en: '`layoutlm` — [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM model)'
  id: totrans-1793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM 模型)'
- en: '`lxmert` — [TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining)
    (LXMERT model)'
  id: totrans-1794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lxmert` — [TFLxmertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.TFLxmertForPreTraining)
    (LXMERT 模型)'
- en: '`mobilebert` — [TFMobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining)
    (MobileBERT model)'
  id: totrans-1795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [TFMobileBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining)
    (MobileBERT 模型)'
- en: '`mpnet` — [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet model)'
  id: totrans-1796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet 模型)'
- en: '`openai-gpt` — [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  id: totrans-1797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT 模型)'
- en: '`roberta` — [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-1798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`t5` — [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 model)'
  id: totrans-1800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 模型)'
- en: '`tapas` — [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS model)'
  id: totrans-1801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS 模型)'
- en: '`transfo-xl` — [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL model)'
  id: totrans-1802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL 模型)'
- en: '`vit_mae` — [TFViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining)
    (ViTMAE model)'
  id: totrans-1803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_mae` — [TFViTMAEForPreTraining](/docs/transformers/v4.37.2/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining)
    (ViTMAE 模型)'
- en: '`xlm` — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  id: totrans-1804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)（XLM模型）'
- en: '`xlm-roberta` — [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-1805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)（XLM-RoBERTa模型）'
- en: '`xlnet` — [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet model)'
  id: totrans-1806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)（XLNet模型）'
- en: 'Examples:'
  id: totrans-1807
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE46]'
  id: totrans-1808
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: FlaxAutoModelForPreTraining
  id: totrans-1809
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForPreTraining
- en: '### `class transformers.FlaxAutoModelForPreTraining`'
  id: totrans-1810
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForPreTraining`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L283)'
  id: totrans-1811
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L283)'
- en: '[PRE47]'
  id: totrans-1812
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a pretraining head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-1813
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有预训练头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-1814
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-1815
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-1816
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE48]'
  id: totrans-1817
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Parameters
  id: totrans-1818
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-1819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 选择要实例化的模型类基于配置类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining)
    (ALBERT model)'
  id: totrans-1820
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[FlaxAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining)（ALBERT模型）'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  id: totrans-1821
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)配置类：[FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)（BART模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForPreTraining)
    (BERT model)'
  id: totrans-1822
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[FlaxBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForPreTraining)（BERT模型）'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining)
    (BigBird model)'
  id: totrans-1823
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)配置类：[FlaxBigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining)（BigBird模型）'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining)
    (ELECTRA model)'
  id: totrans-1824
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)配置类：[FlaxElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining)（ELECTRA模型）'
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 model)'
  id: totrans-1825
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)配置类：[FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)（LongT5模型）'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  id: totrans-1826
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)配置类：[FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)（mBART模型）'
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 model)'
  id: totrans-1827
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)配置类：[FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)（MT5模型）'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)
    (RoFormer model)'
  id: totrans-1828
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)配置类：[FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)（RoFormer模型）'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-1829
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)配置类：[FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)（RoBERTa模型）'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1830
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 model)'
  id: totrans-1831
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    配置类: [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 模型)'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [FlaxWav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining)
    (Wav2Vec2 model)'
  id: totrans-1832
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类: [FlaxWav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining)
    (Wav2Vec2 模型)'
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper model)'
  id: totrans-1833
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    配置类: [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-1834
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa 模型)'
- en: Instantiates one of the model classes of the library (with a pretraining head)
    from a configuration.
  id: totrans-1835
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有预训练头）时，可以自动加载配置。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-1836
  prefs: []
  type: TYPE_NORMAL
  zh: '注意: 从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。'
- en: 'Examples:'
  id: totrans-1837
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE49]'
  id: totrans-1838
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '#### `from_pretrained`'
  id: totrans-1839
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-1840
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE50]'
  id: totrans-1841
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Parameters
  id: totrans-1842
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-1843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是:'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-1844
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *model id*，托管在 huggingface.co 上的模型存储库内。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间在用户或组织名称下，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-1845
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-1846
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PyTorch state_dict save file* 的路径或 URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应将配置对象作为 `config` 参数提供。使用此加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow
    模型并随后加载 TensorFlow 模型要慢。'
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-1847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-1848
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*)
    — 用于替代自动加载的配置的模型配置。当:'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-1849
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是库提供的模型（使用预训练模型的 *model id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-1850
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-1851
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-1852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`，*可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-1853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *可选*, 默认为 `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path`
    参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-1854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-1855
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-1856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-1857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-1858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-1859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-1860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-1861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 在 Hub 上使用的特定代码修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-1862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，其行为有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-1863
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-1864
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a pretraining head)
    from a pretrained model.
  id: totrans-1865
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有预训练头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-1866
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的 `model_type` 属性选择要实例化的模型类（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能），或者当缺失时，通过在
    `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [FlaxAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining)
    (ALBERT model)'
  id: totrans-1867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [FlaxAlbertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForPreTraining)（ALBERT模型）'
- en: '`bart` — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  id: totrans-1868
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)（BART模型）'
- en: '`bert` — [FlaxBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForPreTraining)
    (BERT model)'
  id: totrans-1869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [FlaxBertForPreTraining](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForPreTraining)（BERT模型）'
- en: '`big_bird` — [FlaxBigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining)
    (BigBird model)'
  id: totrans-1870
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [FlaxBigBirdForPreTraining](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining)（BigBird模型）'
- en: '`electra` — [FlaxElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining)
    (ELECTRA model)'
  id: totrans-1871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [FlaxElectraForPreTraining](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForPreTraining)（ELECTRA模型）'
- en: '`longt5` — [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 model)'
  id: totrans-1872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longt5` — [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 模型)'
- en: '`mbart` — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  id: totrans-1873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART 模型)'
- en: '`mt5` — [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 model)'
  id: totrans-1874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 模型)'
- en: '`roberta` — [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-1875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)
    (RoFormer model)'
  id: totrans-1877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)
    (RoFormer 模型)'
- en: '`t5` — [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 model)'
  id: totrans-1878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 模型)'
- en: '`wav2vec2` — [FlaxWav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining)
    (Wav2Vec2 model)'
  id: totrans-1879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [FlaxWav2Vec2ForPreTraining](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining)
    (Wav2Vec2 模型)'
- en: '`whisper` — [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper model)'
  id: totrans-1880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper 模型)'
- en: '`xlm-roberta` — [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-1881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa 模型)'
- en: 'Examples:'
  id: totrans-1882
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE51]'
  id: totrans-1883
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Natural Language Processing
  id: totrans-1884
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自然语言处理
- en: The following auto classes are available for the following natural language
    processing tasks.
  id: totrans-1885
  prefs: []
  type: TYPE_NORMAL
  zh: 以下自动类适用于以下自然语言处理任务。
- en: AutoModelForCausalLM
  id: totrans-1886
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForCausalLM
- en: '### `class transformers.AutoModelForCausalLM`'
  id: totrans-1887
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForCausalLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1326)'
  id: totrans-1888
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1326)'
- en: '[PRE52]'
  id: totrans-1889
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a causal language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-1890
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将实例化为库中的一个模型类（带有因果语言建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-1891
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-1892
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-1893
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE53]'
  id: totrans-1894
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Parameters
  id: totrans-1895
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-1896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类:'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForCausalLM)
    (BART model)'
  id: totrans-1897
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    配置类: [BartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForCausalLM)
    (BART 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertLMHeadModel)
    (BERT model)'
  id: totrans-1898
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类: [BertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertLMHeadModel)
    (BERT 模型)'
- en: '[BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)
    configuration class: [BertGenerationDecoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder)
    (Bert Generation model)'
  id: totrans-1899
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertGenerationConfig](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationConfig)
    配置类: [BertGenerationDecoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder)
    (Bert Generation 模型)'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM)
    (BigBird model)'
  id: totrans-1900
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    配置类: [BigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM)
    (BigBird 模型)'
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM)
    (BigBird-Pegasus model)'
  id: totrans-1901
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    配置类: [BigBirdPegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM)
    (BigBird-Pegasus 模型)'
- en: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    configuration class: [BioGptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForCausalLM)
    (BioGpt model)'
  id: totrans-1902
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    配置类: [BioGptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForCausalLM)
    (BioGpt 模型)'
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [BlenderbotForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM)
    (Blenderbot model)'
  id: totrans-1903
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    配置类: [BlenderbotForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM)
    (Blenderbot 模型)'
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [BlenderbotSmallForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM)
    (BlenderbotSmall model)'
  id: totrans-1904
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    配置类: [BlenderbotSmallForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM)
    (BlenderbotSmall 模型)'
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM model)'
  id: totrans-1905
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    配置类: [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM 模型)'
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL model)'
  id: totrans-1906
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    配置类: [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL 模型)'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForCausalLM)
    (CamemBERT model)'
  id: totrans-1907
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    配置类: [CamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForCausalLM)
    (CamemBERT 模型)'
- en: '[CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig)
    configuration class: [CodeGenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenForCausalLM)
    (CodeGen model)'
  id: totrans-1908
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CodeGenConfig](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenConfig)
    配置类: [CodeGenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenForCausalLM)
    (CodeGen 模型)'
- en: '[CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig)
    configuration class: [CpmAntForCausalLM](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntForCausalLM)
    (CPM-Ant model)'
  id: totrans-1909
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CpmAntConfig](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntConfig)
    配置类: [CpmAntForCausalLM](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntForCausalLM)
    (CPM-Ant 模型)'
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForCausalLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM)
    (Data2VecText model)'
  id: totrans-1910
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    配置类: [Data2VecTextForCausalLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM)
    (Data2VecText 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForCausalLM)
    (ELECTRA model)'
  id: totrans-1911
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [ElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForCausalLM)
    (ELECTRA 模型)'
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForCausalLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForCausalLM)
    (ERNIE model)'
  id: totrans-1912
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    配置类: [ErnieForCausalLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForCausalLM)
    (ERNIE 模型)'
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconForCausalLM](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForCausalLM)
    (Falcon model)'
  id: totrans-1913
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    配置类: [FalconForCausalLM](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForCausalLM)
    (Falcon 模型)'
- en: '[FuyuConfig](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuConfig)
    configuration class: [FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM)
    (Fuyu model)'
  id: totrans-1914
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FuyuConfig](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuConfig)
    配置类: [FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM)
    (Fuyu 模型)'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-1915
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    配置类: [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 模型)'
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode model)'
  id: totrans-1916
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    配置类: [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode 模型)'
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [GPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForCausalLM)
    (GPT-J model)'
  id: totrans-1917
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    配置类: [GPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForCausalLM)
    (GPT-J 模型)'
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM)
    (GPT Neo model)'
  id: totrans-1918
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    配置类: [GPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM)
    (GPT Neo 模型)'
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM)
    (GPT NeoX model)'
  id: totrans-1919
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    配置类: [GPTNeoXForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM)
    (GPT NeoX 模型)'
- en: '[GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig)
    configuration class: [GPTNeoXJapaneseForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM)
    (GPT NeoX Japanese model)'
  id: totrans-1920
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoXJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig)
    配置类: [GPTNeoXJapaneseForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM)
    (GPT NeoX Japanese 模型)'
- en: '[GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    configuration class: [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT model)'
  id: totrans-1921
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    配置类: [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT 模型)'
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM)
    (LLaMA model)'
  id: totrans-1922
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    配置类: [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM)
    (LLaMA 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForCausalLM)
    (mBART model)'
  id: totrans-1923
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类: [MBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForCausalLM)
    (mBART 模型)'
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [MarianForCausalLM](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianForCausalLM)
    (Marian model)'
  id: totrans-1924
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    配置类: [MarianForCausalLM](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianForCausalLM)
    (Marian 模型)'
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForCausalLM)
    (MEGA model)'
  id: totrans-1925
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    配置类: [MegaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForCausalLM)
    (MEGA 模型)'
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM)
    (Megatron-BERT model)'
  id: totrans-1926
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    配置类: [MegatronBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM)
    (Megatron-BERT 模型)'
- en: '[MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    configuration class: [MistralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForCausalLM)
    (Mistral model)'
  id: totrans-1927
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    配置类: [MistralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForCausalLM)
    (Mistral 模型)'
- en: '[MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    configuration class: [MixtralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForCausalLM)
    (Mixtral model)'
  id: totrans-1928
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    配置类: [MixtralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForCausalLM)
    (Mixtral 模型)'
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT model)'
  id: totrans-1929
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    配置类: [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT 模型)'
- en: '[MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)
    configuration class: [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)
    (MusicGen model)'
  id: totrans-1930
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MusicgenConfig](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenConfig)
    配置类: [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)
    (MusicGen 模型)'
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForCausalLM)
    (MVP model)'
  id: totrans-1931
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    配置类: [MvpForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForCausalLM)
    (MVP 模型)'
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [OPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForCausalLM)
    (OPT model)'
  id: totrans-1932
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    配置类: [OPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForCausalLM)
    (OPT 模型)'
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  id: totrans-1933
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    配置类: [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT 模型)'
- en: '[OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    configuration class: [OpenLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForCausalLM)
    (OpenLlama model)'
  id: totrans-1934
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    配置类: [OpenLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForCausalLM)
    (OpenLlama 模型)'
- en: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    configuration class: [PLBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForCausalLM)
    (PLBart model)'
  id: totrans-1935
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    配置类: [PLBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForCausalLM)
    (PLBart 模型)'
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [PegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForCausalLM)
    (Pegasus model)'
  id: totrans-1936
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    配置类: [PegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForCausalLM)
    (Pegasus 模型)'
- en: '[PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    configuration class: [PersimmonForCausalLM](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForCausalLM)
    (Persimmon model)'
  id: totrans-1937
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    配置类: [PersimmonForCausalLM](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForCausalLM)
    (Persimmon 模型)'
- en: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    configuration class: [PhiForCausalLM](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForCausalLM)
    (Phi model)'
  id: totrans-1938
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    配置类: [PhiForCausalLM](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForCausalLM)
    (Phi 模型)'
- en: '[ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    configuration class: [ProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM)
    (ProphetNet model)'
  id: totrans-1939
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    配置类: [ProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM)
    (ProphetNet 模型)'
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel)
    (QDQBert model)'
  id: totrans-1940
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    配置类: [QDQBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel)
    (QDQBert 模型)'
- en: '[Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    configuration class: [Qwen2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForCausalLM)
    (Qwen2 model)'
  id: totrans-1941
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    配置类: [Qwen2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForCausalLM)
    (Qwen2 模型)'
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerModelWithLMHead](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead)
    (Reformer model)'
  id: totrans-1942
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    配置类: [ReformerModelWithLMHead](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead)
    (Reformer 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForCausalLM)
    (RemBERT model)'
  id: totrans-1943
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [RemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForCausalLM)
    (RemBERT 模型)'
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForCausalLM)
    (RoCBert model)'
  id: totrans-1944
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    配置类: [RoCBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForCausalLM)
    (RoCBert 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForCausalLM)
    (RoFormer model)'
  id: totrans-1945
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [RoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForCausalLM)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForCausalLM)
    (RoBERTa model)'
  id: totrans-1946
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [RobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForCausalLM)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-1947
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [RobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    configuration class: [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV model)'
  id: totrans-1948
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RwkvConfig](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvConfig)
    配置类: [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV 模型)'
- en: '[Speech2Text2Config](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config)
    configuration class: [Speech2Text2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM)
    (Speech2Text2 model)'
  id: totrans-1949
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Speech2Text2Config](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config)
    配置类: [Speech2Text2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM)
    (Speech2Text2 模型)'
- en: '[TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig)
    configuration class: [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM)
    (TrOCR model)'
  id: totrans-1950
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TrOCRConfig](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRConfig)
    配置类: [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM)
    (TrOCR 模型)'
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL model)'
  id: totrans-1951
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    配置类: [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL 模型)'
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [WhisperForCausalLM](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForCausalLM)
    (Whisper model)'
  id: totrans-1952
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    配置类：[WhisperForCausalLM](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForCausalLM)（Whisper
    模型）'
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [XGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMForCausalLM)
    (XGLM model)'
  id: totrans-1953
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    配置类：[XGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMForCausalLM)（XGLM
    模型）'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  id: totrans-1954
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类：[XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)（XLM
    模型）'
- en: '[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    configuration class: [XLMProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM)
    (XLM-ProphetNet model)'
  id: totrans-1955
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    配置类：[XLMProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM)（XLM-ProphetNet
    模型）'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  id: totrans-1956
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类：[XLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM)（XLM-RoBERTa
    模型）'
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM)
    (XLM-RoBERTa-XL model)'
  id: totrans-1957
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    配置类：[XLMRobertaXLForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM)（XLM-RoBERTa-XL
    模型）'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet model)'
  id: totrans-1958
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类：[XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)（XLNet
    模型）'
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForCausalLM)
    (X-MOD model)'
  id: totrans-1959
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    配置类：[XmodForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForCausalLM)（X-MOD
    模型）'
- en: Instantiates one of the model classes of the library (with a causal language
    modeling head) from a configuration.
  id: totrans-1960
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有因果语言建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-1961
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-1962
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE54]'
  id: totrans-1963
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '#### `from_pretrained`'
  id: totrans-1964
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-1965
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE55]'
  id: totrans-1966
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Parameters
  id: totrans-1967
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-1968
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str` 或 `os.PathLike`）- 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-1969
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间下的用户或组织名称，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-1970
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-1971
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*TensorFlow索引检查点文件*的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将 `from_tf`
    设置为 `True`，并且应提供配置对象作为 `config` 参数。使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并加载
    PyTorch 模型后，此加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-1972
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）- 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-1973
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）-
    用于替代自动加载的配置的模型配置。当：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-1974
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的*模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-1975
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-1976
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并在目录中找到名为 *config.json* 的配置
    JSON 文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-1977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-1978
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-1979
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *optional*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-1980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-1981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-1982
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-1983
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-1984
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-1985
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-1986
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在
    huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-1987
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-1988
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, 默认为`"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-1989
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs` (额外的关键字参数, *optional*) — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，其行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-1990
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-1991
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则首先将 `kwargs` 传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个键对应于一个配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a causal language
    modeling head) from a pretrained model.
  id: totrans-1992
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库中的一个模型类（带有因果语言建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-1993
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的 `model_type` 属性（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），选择要实例化的模型类，或者当缺失时，通过在
    `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`bart` — [BartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForCausalLM)
    (BART model)'
  id: totrans-1994
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [BartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForCausalLM)
    (BART 模型)'
- en: '`bert` — [BertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertLMHeadModel)
    (BERT model)'
  id: totrans-1995
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertLMHeadModel)
    (BERT 模型)'
- en: '`bert-generation` — [BertGenerationDecoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder)
    (Bert Generation model)'
  id: totrans-1996
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert-generation` — [BertGenerationDecoder](/docs/transformers/v4.37.2/en/model_doc/bert-generation#transformers.BertGenerationDecoder)
    (Bert Generation 模型)'
- en: '`big_bird` — [BigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM)
    (BigBird model)'
  id: totrans-1997
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForCausalLM)
    (BigBird 模型)'
- en: '`bigbird_pegasus` — [BigBirdPegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM)
    (BigBird-Pegasus model)'
  id: totrans-1998
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bigbird_pegasus` — [BigBirdPegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM)
    (BigBird-Pegasus 模型)'
- en: '`biogpt` — [BioGptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForCausalLM)
    (BioGpt model)'
  id: totrans-1999
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`biogpt` — [BioGptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForCausalLM)
    (BioGpt 模型)'
- en: '`blenderbot` — [BlenderbotForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM)
    (Blenderbot model)'
  id: totrans-2000
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot` — [BlenderbotForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM)
    (Blenderbot 模型)'
- en: '`blenderbot-small` — [BlenderbotSmallForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM)
    (BlenderbotSmall model)'
  id: totrans-2001
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot-small` — [BlenderbotSmallForCausalLM](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM)
    (BlenderbotSmall 模型)'
- en: '`bloom` — [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM model)'
  id: totrans-2002
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [BloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForCausalLM)
    (BLOOM 模型)'
- en: '`camembert` — [CamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForCausalLM)
    (CamemBERT model)'
  id: totrans-2003
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForCausalLM)
    (CamemBERT 模型)'
- en: '`code_llama` — [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM)
    (CodeLlama model)'
  id: totrans-2004
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_llama` — [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM)
    (CodeLlama 模型)'
- en: '`codegen` — [CodeGenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenForCausalLM)
    (CodeGen model)'
  id: totrans-2005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codegen` — [CodeGenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/codegen#transformers.CodeGenForCausalLM)
    (CodeGen 模型)'
- en: '`cpmant` — [CpmAntForCausalLM](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntForCausalLM)
    (CPM-Ant model)'
  id: totrans-2006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cpmant` — [CpmAntForCausalLM](/docs/transformers/v4.37.2/en/model_doc/cpmant#transformers.CpmAntForCausalLM)
    (CPM-Ant 模型)'
- en: '`ctrl` — [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL model)'
  id: totrans-2007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [CTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLLMHeadModel)
    (CTRL 模型)'
- en: '`data2vec-text` — [Data2VecTextForCausalLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM)
    (Data2VecText model)'
  id: totrans-2008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [Data2VecTextForCausalLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM)
    (Data2VecText 模型)'
- en: '`electra` — [ElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForCausalLM)
    (ELECTRA model)'
  id: totrans-2009
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForCausalLM)
    (ELECTRA 模型)'
- en: '`ernie` — [ErnieForCausalLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForCausalLM)
    (ERNIE model)'
  id: totrans-2010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [ErnieForCausalLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForCausalLM)
    (ERNIE 模型)'
- en: '`falcon` — [FalconForCausalLM](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForCausalLM)
    (Falcon model)'
  id: totrans-2011
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`falcon` — [FalconForCausalLM](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForCausalLM)
    (Falcon 模型)'
- en: '`fuyu` — [FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM)
    (Fuyu model)'
  id: totrans-2012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fuyu` — [FuyuForCausalLM](/docs/transformers/v4.37.2/en/model_doc/fuyu#transformers.FuyuForCausalLM)
    (Fuyu 模型)'
- en: '`git` — [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT model)'
  id: totrans-2013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` — [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT 模型)'
- en: '`gpt-sw3` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (GPT-Sw3 model)'
  id: totrans-2014
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-2015
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [GPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2LMHeadModel)
    (OpenAI GPT-2 模型)'
- en: '`gpt_bigcode` — [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode model)'
  id: totrans-2016
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_bigcode` — [GPTBigCodeForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForCausalLM)
    (GPTBigCode 模型)'
- en: '`gpt_neo` — [GPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM)
    (GPT Neo model)'
  id: totrans-2017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neo` — [GPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM)
    (GPT Neo 模型)'
- en: '`gpt_neox` — [GPTNeoXForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM)
    (GPT NeoX model)'
  id: totrans-2018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox` — [GPTNeoXForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM)
    (GPT NeoX 模型)'
- en: '`gpt_neox_japanese` — [GPTNeoXJapaneseForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM)
    (GPT NeoX Japanese model)'
  id: totrans-2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox_japanese` — [GPTNeoXJapaneseForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM)
    (GPT NeoX 日语模型)'
- en: '`gptj` — [GPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForCausalLM)
    (GPT-J model)'
  id: totrans-2020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [GPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForCausalLM)
    (GPT-J 模型)'
- en: '`llama` — [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM)
    (LLaMA model)'
  id: totrans-2021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llama` — [LlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForCausalLM)
    (LLaMA 模型)'
- en: '`marian` — [MarianForCausalLM](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianForCausalLM)
    (Marian model)'
  id: totrans-2022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marian` — [MarianForCausalLM](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianForCausalLM)
    (Marian 模型)'
- en: '`mbart` — [MBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForCausalLM)
    (mBART model)'
  id: totrans-2023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [MBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForCausalLM)
    (mBART 模型)'
- en: '`mega` — [MegaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForCausalLM)
    (MEGA model)'
  id: totrans-2024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [MegaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForCausalLM)
    (MEGA 模型)'
- en: '`megatron-bert` — [MegatronBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM)
    (Megatron-BERT model)'
  id: totrans-2025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [MegatronBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM)
    (Megatron-BERT 模型)'
- en: '`mistral` — [MistralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForCausalLM)
    (Mistral model)'
  id: totrans-2026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mistral` — [MistralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForCausalLM)
    (Mistral 模型)'
- en: '`mixtral` — [MixtralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForCausalLM)
    (Mixtral model)'
  id: totrans-2027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mixtral` — [MixtralForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForCausalLM)
    (Mixtral 模型)'
- en: '`mpt` — [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT model)'
  id: totrans-2028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpt` — [MptForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForCausalLM)
    (MPT 模型)'
- en: '`musicgen` — [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)
    (MusicGen model)'
  id: totrans-2029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`musicgen` — [MusicgenForCausalLM](/docs/transformers/v4.37.2/en/model_doc/musicgen#transformers.MusicgenForCausalLM)
    (MusicGen 模型)'
- en: '`mvp` — [MvpForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForCausalLM)
    (MVP model)'
  id: totrans-2030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mvp` — [MvpForCausalLM](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForCausalLM)
    (MVP 模型)'
- en: '`open-llama` — [OpenLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForCausalLM)
    (OpenLlama model)'
  id: totrans-2031
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`open-llama` — [OpenLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForCausalLM)
    (OpenLlama 模型)'
- en: '`openai-gpt` — [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  id: totrans-2032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [OpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel)
    (OpenAI GPT 模型)'
- en: '`opt` — [OPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForCausalLM)
    (OPT model)'
  id: totrans-2033
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [OPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForCausalLM)
    (OPT 模型)'
- en: '`pegasus` — [PegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForCausalLM)
    (Pegasus model)'
  id: totrans-2034
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus` — [PegasusForCausalLM](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForCausalLM)
    (Pegasus 模型)'
- en: '`persimmon` — [PersimmonForCausalLM](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForCausalLM)
    (Persimmon model)'
  id: totrans-2035
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`persimmon` — [PersimmonForCausalLM](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForCausalLM)
    (Persimmon 模型)'
- en: '`phi` — [PhiForCausalLM](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForCausalLM)
    (Phi model)'
  id: totrans-2036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`phi` — [PhiForCausalLM](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForCausalLM)
    (Phi 模型)'
- en: '`plbart` — [PLBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForCausalLM)
    (PLBart model)'
  id: totrans-2037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plbart` — [PLBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForCausalLM)
    (PLBart 模型)'
- en: '`prophetnet` — [ProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM)
    (ProphetNet model)'
  id: totrans-2038
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prophetnet` — [ProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM)
    (ProphetNet 模型)'
- en: '`qdqbert` — [QDQBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel)
    (QDQBert model)'
  id: totrans-2039
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` — [QDQBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel)
    (QDQBert 模型)'
- en: '`qwen2` — [Qwen2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForCausalLM)
    (Qwen2 model)'
  id: totrans-2040
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qwen2` — [Qwen2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForCausalLM)
    (Qwen2 模型)'
- en: '`reformer` — [ReformerModelWithLMHead](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead)
    (Reformer model)'
  id: totrans-2041
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reformer` — [ReformerModelWithLMHead](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerModelWithLMHead)
    (Reformer 模型)'
- en: '`rembert` — [RemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForCausalLM)
    (RemBERT model)'
  id: totrans-2042
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [RemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForCausalLM)
    (RemBERT 模型)'
- en: '`roberta` — [RobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForCausalLM)
    (RoBERTa model)'
  id: totrans-2043
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForCausalLM)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [RobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roc_bert` — [RoCBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForCausalLM)
    (RoCBert model)'
  id: totrans-2045
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForCausalLM)
    (RoCBert 模型)'
- en: '`roformer` — [RoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForCausalLM)
    (RoFormer model)'
  id: totrans-2046
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [RoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForCausalLM)
    (RoFormer 模型)'
- en: '`rwkv` — [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)
    (RWKV model)'
  id: totrans-2047
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rwkv` — [RwkvForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rwkv#transformers.RwkvForCausalLM)（RWKV模型）'
- en: '`speech_to_text_2` — [Speech2Text2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM)
    (Speech2Text2 model)'
  id: totrans-2048
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text_2` — [Speech2Text2ForCausalLM](/docs/transformers/v4.37.2/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM)（Speech2Text2模型）'
- en: '`transfo-xl` — [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)
    (Transformer-XL model)'
  id: totrans-2049
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel)（Transformer-XL模型）'
- en: '`trocr` — [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM)
    (TrOCR model)'
  id: totrans-2050
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trocr` — [TrOCRForCausalLM](/docs/transformers/v4.37.2/en/model_doc/trocr#transformers.TrOCRForCausalLM)（TrOCR模型）'
- en: '`whisper` — [WhisperForCausalLM](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForCausalLM)
    (Whisper model)'
  id: totrans-2051
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [WhisperForCausalLM](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForCausalLM)（Whisper模型）'
- en: '`xglm` — [XGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMForCausalLM)
    (XGLM model)'
  id: totrans-2052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xglm` — [XGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMForCausalLM)（XGLM模型）'
- en: '`xlm` — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  id: totrans-2053
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)（XLM模型）'
- en: '`xlm-prophetnet` — [XLMProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM)
    (XLM-ProphetNet model)'
  id: totrans-2054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-prophetnet` — [XLMProphetNetForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM)（XLM-ProphetNet模型）'
- en: '`xlm-roberta` — [XLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  id: totrans-2055
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM)（XLM-RoBERTa模型）'
- en: '`xlm-roberta-xl` — [XLMRobertaXLForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM)
    (XLM-RoBERTa-XL model)'
  id: totrans-2056
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaXLForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM)（XLM-RoBERTa-XL模型）'
- en: '`xlnet` — [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)
    (XLNet model)'
  id: totrans-2057
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [XLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetLMHeadModel)（XLNet模型）'
- en: '`xmod` — [XmodForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForCausalLM)
    (X-MOD model)'
  id: totrans-2058
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XmodForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForCausalLM)（X-MOD模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-2059
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，该模型处于评估模式，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-2060
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE56]'
  id: totrans-2061
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: TFAutoModelForCausalLM
  id: totrans-2062
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForCausalLM
- en: '### `class transformers.TFAutoModelForCausalLM`'
  id: totrans-2063
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForCausalLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L562)'
  id: totrans-2064
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L562)'
- en: '[PRE57]'
  id: totrans-2065
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a causal language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2066
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库中的模型类之一实例化（带有因果语言建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2067
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-2068
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2069
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE58]'
  id: totrans-2070
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Parameters
  id: totrans-2071
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2072
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—将要实例化的模型类是基于配置类选择的：'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertLMHeadModel)
    (BERT model)'
  id: totrans-2073
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[TFBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertLMHeadModel)（BERT模型）'
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL model)'
  id: totrans-2074
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)配置类：[TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)（CTRL模型）'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForCausalLM)
    (CamemBERT model)'
  id: totrans-2075
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)配置类：[TFCamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForCausalLM)（CamemBERT模型）'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-2076
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)配置类：[TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)（OpenAI
    GPT-2模型）'
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [TFGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForCausalLM)
    (GPT-J model)'
  id: totrans-2077
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)配置类：[TFGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForCausalLM)（GPT-J模型）'
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [TFOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTForCausalLM)
    (OPT model)'
  id: totrans-2078
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    配置类: [TFOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTForCausalLM)
    (OPT 模型)'
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  id: totrans-2079
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    配置类: [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM)
    (RemBERT model)'
  id: totrans-2080
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [TFRemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM)
    (RemBERT 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM)
    (RoFormer model)'
  id: totrans-2081
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [TFRoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM)
    (RoBERTa model)'
  id: totrans-2082
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [TFRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2083
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [TFRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL model)'
  id: totrans-2084
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    配置类: [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL 模型)'
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [TFXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMForCausalLM)
    (XGLM model)'
  id: totrans-2085
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    配置类: [TFXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMForCausalLM)
    (XGLM 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  id: totrans-2086
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  id: totrans-2087
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [TFXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForCausalLM)
    (XLM-RoBERTa 模型)'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet model)'
  id: totrans-2088
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类: [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet 模型)'
- en: Instantiates one of the model classes of the library (with a causal language
    modeling head) from a configuration.
  id: totrans-2089
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有因果语言建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2090
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-2091
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE59]'
  id: totrans-2092
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '#### `from_pretrained`'
  id: totrans-2093
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2094
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE60]'
  id: totrans-2095
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Parameters
  id: totrans-2096
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2098
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间在用户或组织名称下，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2099
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-2100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或url到*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象作为`config`参数提供。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-2101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-2102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    模型使用的配置，而不是自动加载的配置。当：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-2103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-2104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-2105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-2106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-2107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-2108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-2109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-2110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-2111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`）— 是否返回包含丢失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-2112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`）— 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-2113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-2114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-2115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-2116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 可以用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-2117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-2118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a causal language
    modeling head) from a pretrained model.
  id: totrans-2119
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有因果语言建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-2120
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的 `model_type` 属性选择要实例化的模型类（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`bert` — [TFBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertLMHeadModel)
    (BERT model)'
  id: totrans-2121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [TFBertLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertLMHeadModel)
    (BERT 模型)'
- en: '`camembert` — [TFCamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForCausalLM)
    (CamemBERT model)'
  id: totrans-2122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [TFCamembertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForCausalLM)
    (CamemBERT 模型)'
- en: '`ctrl` — [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL model)'
  id: totrans-2123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [TFCTRLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel)
    (CTRL 模型)'
- en: '`gpt-sw3` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (GPT-Sw3 model)'
  id: totrans-2124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-2125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [TFGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel)
    (OpenAI GPT-2 模型)'
- en: '`gptj` — [TFGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForCausalLM)
    (GPT-J model)'
  id: totrans-2126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [TFGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForCausalLM)
    (GPT-J 模型)'
- en: '`openai-gpt` — [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT model)'
  id: totrans-2127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [TFOpenAIGPTLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel)
    (OpenAI GPT 模型)'
- en: '`opt` — [TFOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTForCausalLM)
    (OPT model)'
  id: totrans-2128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [TFOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.TFOPTForCausalLM)
    (OPT 模型)'
- en: '`rembert` — [TFRemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM)
    (RemBERT model)'
  id: totrans-2129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [TFRemBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForCausalLM)
    (RemBERT 模型)'
- en: '`roberta` — [TFRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM)
    (RoBERTa model)'
  id: totrans-2130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [TFRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForCausalLM)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [TFRoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM)
    (RoFormer model)'
  id: totrans-2132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [TFRoFormerForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForCausalLM)
    (RoFormer 模型)'
- en: '`transfo-xl` — [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL model)'
  id: totrans-2133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TFTransfoXLLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel)
    (Transformer-XL 模型)'
- en: '`xglm` — [TFXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMForCausalLM)
    (XGLM model)'
  id: totrans-2134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xglm` — [TFXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.TFXGLMForCausalLM)
    (XGLM 模型)'
- en: '`xlm` — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  id: totrans-2135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM 模型)'
- en: '`xlm-roberta` — [TFXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  id: totrans-2136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [TFXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForCausalLM)
    (XLM-RoBERTa 模型)'
- en: '`xlnet` — [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet model)'
  id: totrans-2137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [TFXLNetLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel)
    (XLNet 模型)'
- en: 'Examples:'
  id: totrans-2138
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE61]'
  id: totrans-2139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: FlaxAutoModelForCausalLM
  id: totrans-2140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForCausalLM
- en: '### `class transformers.FlaxAutoModelForCausalLM`'
  id: totrans-2141
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForCausalLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L290)'
  id: totrans-2142
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L290)'
- en: '[PRE62]'
  id: totrans-2143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a causal language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将实例化为库中的一个模型类（带有因果语言建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2145
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-2146
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2147
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE63]'
  id: totrans-2148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Parameters
  id: totrans-2149
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类:'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForCausalLM)
    (BART model)'
  id: totrans-2151
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    配置类: [FlaxBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForCausalLM)
    (BART 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForCausalLM)
    (BERT model)'
  id: totrans-2152
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类: [FlaxBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForCausalLM)
    (BERT 模型)'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM)
    (BigBird model)'
  id: totrans-2153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    配置类: [FlaxBigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM)
    (BigBird 模型)'
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [FlaxBloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomForCausalLM)
    (BLOOM model)'
  id: totrans-2154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    配置类: [FlaxBloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomForCausalLM)
    (BLOOM 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForCausalLM)
    (ELECTRA model)'
  id: totrans-2155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [FlaxElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForCausalLM)
    (ELECTRA 模型)'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-2156
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    配置类: [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)
    (OpenAI GPT-2 模型)'
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [FlaxGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM)
    (GPT-J model)'
  id: totrans-2157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    配置类: [FlaxGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM)
    (GPT-J 模型)'
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [FlaxGPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM)
    (GPT Neo model)'
  id: totrans-2158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    配置类: [FlaxGPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM)
    (GPT Neo 模型)'
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [FlaxLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaForCausalLM)
    (LLaMA model)'
  id: totrans-2159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    配置类: [FlaxLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaForCausalLM)
    (LLaMA 模型)'
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [FlaxOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTForCausalLM)
    (OPT model)'
  id: totrans-2160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    配置类: [FlaxOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTForCausalLM)
    (OPT 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM)
    (RoBERTa model)'
  id: totrans-2161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [FlaxRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [FlaxRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    configuration class: [FlaxXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM)
    (XGLM model)'
  id: totrans-2163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGLMConfig](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.XGLMConfig)
    配置类: [FlaxXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM)
    (XGLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  id: totrans-2164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [FlaxXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForCausalLM)
    (XLM-RoBERTa 模型)'
- en: Instantiates one of the model classes of the library (with a causal language
    modeling head) from a configuration.
  id: totrans-2165
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库中的一个模型类（带有因果语言建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2166
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-2167
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE64]'
  id: totrans-2168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '#### `from_pretrained`'
  id: totrans-2169
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2170
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE65]'
  id: totrans-2171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Parameters
  id: totrans-2172
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型 ID*，托管在 huggingface.co 上的模型存储库中。有效的模型 ID 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-2176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch state_dict save file*的路径或 URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应该将配置对象作为 `config` 参数提供。使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并加载
    TensorFlow 模型后，此加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-2177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-2178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 用于模型的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-2179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型 ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-2180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-2181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-2182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-2183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-2184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-2185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-2186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理服务器在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-2187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-2188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否只查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-2189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-2190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-2191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`） — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-2192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-2193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用`config`提供了配置，则`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-2194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`中与配置属性对应的每个键将用于使用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a causal language
    modeling head) from a pretrained model.
  id: totrans-2195
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有因果语言建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-2196
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`bart` — [FlaxBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForCausalLM)
    (BART model)'
  id: totrans-2197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [FlaxBartForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForCausalLM)（BART模型）'
- en: '`bert` — [FlaxBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForCausalLM)
    (BERT model)'
  id: totrans-2198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [FlaxBertForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForCausalLM)（BERT模型）'
- en: '`big_bird` — [FlaxBigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM)
    (BigBird model)'
  id: totrans-2199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [FlaxBigBirdForCausalLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM)（BigBird模型）'
- en: '`bloom` — [FlaxBloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomForCausalLM)
    (BLOOM model)'
  id: totrans-2200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [FlaxBloomForCausalLM](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.FlaxBloomForCausalLM)（BLOOM模型）'
- en: '`electra` — [FlaxElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForCausalLM)
    (ELECTRA model)'
  id: totrans-2201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [FlaxElectraForCausalLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForCausalLM)（ELECTRA模型）'
- en: '`gpt-sw3` — [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)
    (GPT-Sw3 model)'
  id: totrans-2202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)（GPT-Sw3模型）'
- en: '`gpt2` — [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)
    (OpenAI GPT-2 model)'
  id: totrans-2203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [FlaxGPT2LMHeadModel](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel)（OpenAI
    GPT-2模型）'
- en: '`gpt_neo` — [FlaxGPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM)
    (GPT Neo model)'
  id: totrans-2204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neo` — [FlaxGPTNeoForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM)（GPT
    Neo模型）'
- en: '`gptj` — [FlaxGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM)
    (GPT-J model)'
  id: totrans-2205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [FlaxGPTJForCausalLM](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM)（GPT-J模型）'
- en: '`llama` — [FlaxLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaForCausalLM)
    (LLaMA model)'
  id: totrans-2206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llama` — [FlaxLlamaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/llama#transformers.FlaxLlamaForCausalLM)（LLaMA模型）'
- en: '`opt` — [FlaxOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTForCausalLM)
    (OPT model)'
  id: totrans-2207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [FlaxOPTForCausalLM](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.FlaxOPTForCausalLM)（OPT模型）'
- en: '`roberta` — [FlaxRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM)
    (RoBERTa model)'
  id: totrans-2208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [FlaxRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM)（RoBERTa模型）'
- en: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForCausalLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForCausalLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForCausalLM)（RoBERTa-PreLayerNorm模型）'
- en: '`xglm` — [FlaxXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM)
    (XGLM model)'
  id: totrans-2210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xglm` — [FlaxXGLMForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM)（XGLM模型）'
- en: '`xlm-roberta` — [FlaxXLMRobertaForCausalLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForCausalLM)
    (XLM-RoBERTa model)'
  id: totrans-2211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [FlaxXLMRobertaForCausalLM](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForCausalLM)（XLM-RoBERTa
    模型）'
- en: 'Examples:'
  id: totrans-2212
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE66]'
  id: totrans-2213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: AutoModelForMaskedLM
  id: totrans-2214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForMaskedLM
- en: '### `class transformers.AutoModelForMaskedLM`'
  id: totrans-2215
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForMaskedLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1333)'
  id: totrans-2216
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1333)'
- en: '[PRE67]'
  id: totrans-2217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2218
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有一个掩码语言建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2219
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-2220
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2221
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE68]'
  id: totrans-2222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Parameters
  id: totrans-2223
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)）
    — 根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMaskedLM)
    (ALBERT model)'
  id: totrans-2225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig)
    配置类：[AlbertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertForMaskedLM)（ALBERT
    模型）'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  id: totrans-2226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartConfig)
    配置类：[BartForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartForConditionalGeneration)（BART
    模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMaskedLM)
    (BERT model)'
  id: totrans-2227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig)
    配置类：[BertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertForMaskedLM)（BERT
    模型）'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMaskedLM)
    (BigBird model)'
  id: totrans-2228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdConfig)
    配置类：[BigBirdForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdForMaskedLM)（BigBird
    模型）'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT model)'
  id: totrans-2229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertConfig)
    配置类：[CamembertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertForMaskedLM)（CamemBERT
    模型）'
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMaskedLM)
    (ConvBERT model)'
  id: totrans-2230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvBertConfig](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.ConvBertConfig)
    配置类：[ConvBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.ConvBertForMaskedLM)（ConvBERT
    模型）'
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText model)'
  id: totrans-2231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecTextConfig](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextConfig)
    配置类：[Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)（Data2VecText
    模型）'
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa model)'
  id: totrans-2232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaConfig](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaConfig)
    配置类：[DebertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaForMaskedLM)（DeBERTa
    模型）'
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  id: totrans-2233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaV2Config](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2Config)
    配置类：[DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)（DeBERTa-v2
    模型）'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-2234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig)
    配置类：[DistilBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertForMaskedLM)（DistilBERT
    模型）'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMaskedLM)
    (ELECTRA model)'
  id: totrans-2235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraConfig)
    配置类：[ElectraForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.ElectraForMaskedLM)（ELECTRA
    模型）'
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMaskedLM)
    (ERNIE model)'
  id: totrans-2236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    配置类: [ErnieForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMaskedLM)
    (ERNIE 模型)'
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [EsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForMaskedLM)
    (ESM model)'
  id: totrans-2237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    配置类: [EsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForMaskedLM)
    (ESM 模型)'
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMaskedLM)
    (FNet model)'
  id: totrans-2238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    配置类: [FNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMaskedLM)
    (FNet 模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT model)'
  id: totrans-2239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMaskedLM)
    (Funnel Transformer model)'
  id: totrans-2240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [FunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMaskedLM)
    (Funnel Transformer 模型)'
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT model)'
  id: totrans-2241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    配置类: [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT 模型)'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM model)'
  id: totrans-2242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类: [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer model)'
  id: totrans-2243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer 模型)'
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE model)'
  id: totrans-2244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    配置类: [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类: [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet model)'
  id: totrans-2246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet 模型)'
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA model)'
  id: totrans-2247
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    配置类: [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA 模型)'
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM)
    (Megatron-BERT model)'
  id: totrans-2248
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    配置类: [MegatronBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM)
    (Megatron-BERT 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM)
    (MobileBERT model)'
  id: totrans-2249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [MobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM)
    (MobileBERT 模型)'
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA model)'
  id: totrans-2250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    配置类: [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA 模型)'
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  id: totrans-2251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    配置类: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP 模型)'
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMaskedLM)
    (Nezha model)'
  id: totrans-2252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    配置类: [NezhaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMaskedLM)
    (Nezha 模型)'
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM)
    (Nyströmformer model)'
  id: totrans-2253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    配置类: [NystromformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM)
    (Nyströmformer 模型)'
- en: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    configuration class: [PerceiverForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM)
    (Perceiver model)'
  id: totrans-2254
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    配置类: [PerceiverForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM)
    (Perceiver 模型)'
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM)
    (QDQBert model)'
  id: totrans-2255
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    配置类: [QDQBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM)
    (QDQBert 模型)'
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForMaskedLM)
    (Reformer model)'
  id: totrans-2256
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    配置类: [ReformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForMaskedLM)
    (Reformer 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMaskedLM)
    (RemBERT model)'
  id: totrans-2257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [RemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMaskedLM)
    (RemBERT 模型)'
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM)
    (RoCBert model)'
  id: totrans-2258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    配置类: [RoCBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM)
    (RoCBert 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM)
    (RoFormer model)'
  id: totrans-2259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [RoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-2260
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2261
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT model)'
  id: totrans-2262
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    配置类: [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT 模型)'
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS model)'
  id: totrans-2263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    配置类: [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS 模型)'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: `Wav2Vec2ForMaskedLM` (Wav2Vec2 model)'
  id: totrans-2264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类: `Wav2Vec2ForMaskedLM` (Wav2Vec2 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  id: totrans-2265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-2266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa 模型)'
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL model)'
  id: totrans-2267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    配置类: [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL 模型)'
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD model)'
  id: totrans-2268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    配置类: [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD 模型)'
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMaskedLM)
    (YOSO model)'
  id: totrans-2269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    配置类：[YosoForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMaskedLM)（YOSO模型）'
- en: Instantiates one of the model classes of the library (with a masked language
    modeling head) from a configuration.
  id: totrans-2270
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有掩码语言建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2271
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-2272
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE69]'
  id: totrans-2273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '#### `from_pretrained`'
  id: totrans-2274
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2275
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE70]'
  id: totrans-2276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Parameters
  id: totrans-2277
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str`或`os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2279
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2280
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-2281
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*TensorFlow索引检查点文件*的路径或URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-2282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-2283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *可选*) — 用于模型的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-2284
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-2285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-2286
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-2287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*） — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-2288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-2289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str`或`os.PathLike`, *可选*) — 下载预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-2290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *可选*, 默认为`False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-2291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*, 默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-2292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-2293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-2294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺少键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-2295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-2296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-2297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读了代码，因为它将在本地计算机上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-2298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 代码在Hub上使用的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-2299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*optional*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-2300
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-2301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a masked language
    modeling head) from a pretrained model.
  id: totrans-2302
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库中的一个模型类（带有掩码语言建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-2303
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`albert` — [AlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMaskedLM)
    (ALBERT model)'
  id: totrans-2304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [AlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMaskedLM)（ALBERT模型）'
- en: '`bart` — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  id: totrans-2305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)（BART模型）'
- en: '`bert` — [BertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMaskedLM)
    (BERT model)'
  id: totrans-2306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMaskedLM)（BERT模型）'
- en: '`big_bird` — [BigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMaskedLM)
    (BigBird model)'
  id: totrans-2307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMaskedLM)（BigBird模型）'
- en: '`camembert` — [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)
    (CamemBERT model)'
  id: totrans-2308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMaskedLM)（CamemBERT模型）'
- en: '`convbert` — [ConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMaskedLM)
    (ConvBERT model)'
  id: totrans-2309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [ConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMaskedLM)（ConvBERT模型）'
- en: '`data2vec-text` — [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)
    (Data2VecText model)'
  id: totrans-2310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [Data2VecTextForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM)（Data2VecText模型）'
- en: '`deberta` — [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)
    (DeBERTa model)'
  id: totrans-2311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [DebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForMaskedLM)（DeBERTa模型）'
- en: '`deberta-v2` — [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  id: totrans-2312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [DebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-2313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [DistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMaskedLM)
    (DistilBERT 模型)'
- en: '`electra` — [ElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMaskedLM)
    (ELECTRA model)'
  id: totrans-2314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMaskedLM)
    (ELECTRA 模型)'
- en: '`ernie` — [ErnieForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMaskedLM)
    (ERNIE model)'
  id: totrans-2315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [ErnieForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMaskedLM)
    (ERNIE 模型)'
- en: '`esm` — [EsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForMaskedLM)
    (ESM model)'
  id: totrans-2316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [EsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForMaskedLM)
    (ESM 模型)'
- en: '`flaubert` — [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT model)'
  id: totrans-2317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [FlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel)
    (FlauBERT 模型)'
- en: '`fnet` — [FNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMaskedLM)
    (FNet model)'
  id: totrans-2318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` — [FNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMaskedLM)
    (FNet 模型)'
- en: '`funnel` — [FunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMaskedLM)
    (Funnel Transformer model)'
  id: totrans-2319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [FunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMaskedLM)
    (Funnel Transformer 模型)'
- en: '`ibert` — [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT model)'
  id: totrans-2320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ibert` — [IBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMaskedLM)
    (I-BERT 模型)'
- en: '`layoutlm` — [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM model)'
  id: totrans-2321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [LayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM)
    (LayoutLM 模型)'
- en: '`longformer` — [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer model)'
  id: totrans-2322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [LongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMaskedLM)
    (Longformer 模型)'
- en: '`luke` — [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE model)'
  id: totrans-2323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`luke` — [LukeForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMaskedLM)
    (LUKE 模型)'
- en: '`mbart` — [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART 模型)'
- en: '`mega` — [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA model)'
  id: totrans-2325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [MegaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMaskedLM)
    (MEGA 模型)'
- en: '`megatron-bert` — [MegatronBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM)
    (Megatron-BERT model)'
  id: totrans-2326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [MegatronBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM)
    (Megatron-BERT 模型)'
- en: '`mobilebert` — [MobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM)
    (MobileBERT model)'
  id: totrans-2327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [MobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM)
    (MobileBERT 模型)'
- en: '`mpnet` — [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet model)'
  id: totrans-2328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [MPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMaskedLM)
    (MPNet 模型)'
- en: '`mra` — [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA model)'
  id: totrans-2329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mra` — [MraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMaskedLM)
    (MRA 模型)'
- en: '`mvp` — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  id: totrans-2330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mvp` — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP 模型)'
- en: '`nezha` — [NezhaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMaskedLM)
    (Nezha model)'
  id: totrans-2331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` — [NezhaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMaskedLM)
    (Nezha 模型)'
- en: '`nystromformer` — [NystromformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM)
    (Nyströmformer model)'
  id: totrans-2332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nystromformer` — [NystromformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM)
    (Nyströmformer 模型)'
- en: '`perceiver` — [PerceiverForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM)
    (Perceiver model)'
  id: totrans-2333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perceiver` — [PerceiverForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForMaskedLM)
    (Perceiver 模型)'
- en: '`qdqbert` — [QDQBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM)
    (QDQBert model)'
  id: totrans-2334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` — [QDQBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM)
    (QDQBert 模型)'
- en: '`reformer` — [ReformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForMaskedLM)
    (Reformer model)'
  id: totrans-2335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reformer` — [ReformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForMaskedLM)
    (Reformer 模型)'
- en: '`rembert` — [RemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMaskedLM)
    (RemBERT model)'
  id: totrans-2336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [RemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMaskedLM)
    (RemBERT 模型)'
- en: '`roberta` — [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-2337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMaskedLM)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roc_bert` — [RoCBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM)
    (RoCBert model)'
  id: totrans-2339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM)
    (RoCBert 模型)'
- en: '`roformer` — [RoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM)
    (RoFormer model)'
  id: totrans-2340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [RoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMaskedLM)
    (RoFormer 模型)'
- en: '`squeezebert` — [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)
    (SqueezeBERT model)'
  id: totrans-2341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`squeezebert` — [SqueezeBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM)（SqueezeBERT
    模型）'
- en: '`tapas` — [TapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForMaskedLM)
    (TAPAS model)'
  id: totrans-2342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TapasForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TapasForMaskedLM)（TAPAS
    模型）'
- en: '`wav2vec2` — `Wav2Vec2ForMaskedLM` (Wav2Vec2 model)'
  id: totrans-2343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — `Wav2Vec2ForMaskedLM`（Wav2Vec2 模型）'
- en: '`xlm` — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMWithLMHeadModel)
    (XLM model)'
  id: totrans-2344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMWithLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.XLMWithLMHeadModel)（XLM
    模型）'
- en: '`xlm-roberta` — [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-2345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM)（XLM-RoBERTa
    模型）'
- en: '`xlm-roberta-xl` — [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)
    (XLM-RoBERTa-XL model)'
  id: totrans-2346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaXLForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM)（XLM-RoBERTa-XL
    模型）'
- en: '`xmod` — [XmodForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMaskedLM)
    (X-MOD model)'
  id: totrans-2347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XmodForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/xmod#transformers.XmodForMaskedLM)（X-MOD
    模型）'
- en: '`yoso` — [YosoForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMaskedLM)
    (YOSO model)'
  id: totrans-2348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yoso` — [YosoForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/yoso#transformers.YosoForMaskedLM)（YOSO
    模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-2349
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用 `model.eval()` 将模型设置为评估模式（例如，关闭了 dropout 模块）。要训练模型，应该首先使用 `model.train()`
    将其设置回训练模式。
- en: 'Examples:'
  id: totrans-2350
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE71]'
  id: totrans-2351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: TFAutoModelForMaskedLM
  id: totrans-2352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForMaskedLM
- en: '### `class transformers.TFAutoModelForMaskedLM`'
  id: totrans-2353
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForMaskedLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L612)'
  id: totrans-2354
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L612)'
- en: '[PRE72]'
  id: totrans-2355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2356
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将作为库中的模型类之一实例化（带有掩码语言建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2357
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会报错）。
- en: '#### `from_config`'
  id: totrans-2358
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2359
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE73]'
  id: totrans-2360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Parameters
  id: totrans-2361
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)）
    — 根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMaskedLM)
    (ALBERT model)'
  id: totrans-2363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig)
    配置类：[TFAlbertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.TFAlbertForMaskedLM)（ALBERT
    模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMaskedLM)
    (BERT model)'
  id: totrans-2364
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig)
    配置类：[TFBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.TFBertForMaskedLM)（BERT
    模型）'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT model)'
  id: totrans-2365
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertConfig)
    配置类：[TFCamembertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.TFCamembertForMaskedLM)（CamemBERT
    模型）'
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMaskedLM)
    (ConvBERT model)'
  id: totrans-2366
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvBertConfig](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.ConvBertConfig)
    配置类：[TFConvBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.TFConvBertForMaskedLM)（ConvBERT
    模型）'
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForMaskedLM)
    (DeBERTa model)'
  id: totrans-2367
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaConfig](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaConfig)
    配置类：[TFDebertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.TFDebertaForMaskedLM)（DeBERTa
    模型）'
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  id: totrans-2368
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaV2Config](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2Config)
    配置类：[TFDebertaV2ForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM)（DeBERTa-v2
    模型）'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-2369
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig)
    配置类：[TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)（DistilBERT
    模型）'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMaskedLM)
    (ELECTRA model)'
  id: totrans-2370
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [TFElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMaskedLM)
    (ELECTRA 模型)'
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [TFEsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForMaskedLM)
    (ESM model)'
  id: totrans-2371
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    配置类: [TFEsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForMaskedLM)
    (ESM 模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT model)'
  id: totrans-2372
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMaskedLM)
    (Funnel Transformer model)'
  id: totrans-2373
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [TFFunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMaskedLM)
    (Funnel Transformer 模型)'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM model)'
  id: totrans-2374
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类: [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMaskedLM)
    (Longformer model)'
  id: totrans-2375
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [TFLongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMaskedLM)
    (Longformer 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet model)'
  id: totrans-2376
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM)
    (MobileBERT model)'
  id: totrans-2377
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [TFMobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM)
    (MobileBERT 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM)
    (RemBERT model)'
  id: totrans-2378
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [TFRemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM)
    (RemBERT 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM)
    (RoFormer model)'
  id: totrans-2379
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [TFRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-2380
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2381
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS model)'
  id: totrans-2382
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    配置类: [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  id: totrans-2383
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-2384
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa 模型)'
- en: Instantiates one of the model classes of the library (with a masked language
    modeling head) from a configuration.
  id: totrans-2385
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有掩码语言建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2386
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-2387
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE74]'
  id: totrans-2388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '#### `from_pretrained`'
  id: totrans-2389
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2390
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE75]'
  id: totrans-2391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Parameters
  id: totrans-2392
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2394
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预训练模型的 *model id* 字符串，托管在 huggingface.co 上的模型存储库内。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下进行命名空间，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2395
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 路径，例如 `./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-2396
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向 *PyTorch state_dict 保存文件* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow
    模型并随后加载 TensorFlow 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-2397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-2398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*)
    — 用于模型的配置，而不是自动加载的配置。当：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-2399
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *model id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-2400
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-2401
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在该目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-2402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`，*可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-2403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`，*可选*，默认为 `False`) — 从 PyTorch 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path`
    参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-2404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`，*可选*，默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖已存在的缓存版本。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-2405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`，*可选*，默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-2406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`，*可选*) — 要按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理将在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-2407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-2408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-2409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`，*可选*，默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 id，因为我们使用基于
    git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-2410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为 `False`） — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-2411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为 `"main"`） — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-2412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-2413
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给基础模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-2414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个对应于配置属性的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a masked language
    modeling head) from a pretrained model.
  id: totrans-2415
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有遮蔽语言建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-2416
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类基于配置对象的 `model_type` 属性（作为参数传递或从 `pretrained_model_name_or_path` 加载，如果可能的话），或者当缺少时，通过在
    `pretrained_model_name_or_path` 上使用模式匹配来选择：
- en: '`albert` — [TFAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMaskedLM)
    (ALBERT model)'
  id: totrans-2417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [TFAlbertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.TFAlbertForMaskedLM)
    (ALBERT 模型)'
- en: '`bert` — [TFBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMaskedLM)
    (BERT model)'
  id: totrans-2418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [TFBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.TFBertForMaskedLM)
    (BERT 模型)'
- en: '`camembert` — [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT model)'
  id: totrans-2419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [TFCamembertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.TFCamembertForMaskedLM)
    (CamemBERT 模型)'
- en: '`convbert` — [TFConvBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMaskedLM)
    (ConvBERT model)'
  id: totrans-2420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [TFConvBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.TFConvBertForMaskedLM)
    (ConvBERT 模型)'
- en: '`deberta` — [TFDebertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForMaskedLM)
    (DeBERTa model)'
  id: totrans-2421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [TFDebertaForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.TFDebertaForMaskedLM)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [TFDebertaV2ForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM)
    (DeBERTa-v2 model)'
  id: totrans-2422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [TFDebertaV2ForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-2423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [TFDistilBertForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.TFDistilBertForMaskedLM)
    (DistilBERT 模型)'
- en: '`electra` — [TFElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMaskedLM)
    (ELECTRA model)'
  id: totrans-2424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [TFElectraForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.TFElectraForMaskedLM)
    (ELECTRA 模型)'
- en: '`esm` — [TFEsmForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForMaskedLM)
    (ESM model)'
  id: totrans-2425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [TFEsmForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/esm#transformers.TFEsmForMaskedLM)
    (ESM 模型)'
- en: '`flaubert` — [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT model)'
  id: totrans-2426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [TFFlaubertWithLMHeadModel](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel)
    (FlauBERT 模型)'
- en: '`funnel` — [TFFunnelForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMaskedLM)
    (Funnel Transformer model)'
  id: totrans-2427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [TFFunnelForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/funnel#transformers.TFFunnelForMaskedLM)
    (Funnel Transformer 模型)'
- en: '`layoutlm` — [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM model)'
  id: totrans-2428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [TFLayoutLMForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM)
    (LayoutLM 模型)'
- en: '`longformer` — [TFLongformerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMaskedLM)
    (Longformer model)'
  id: totrans-2429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [TFLongformerForMaskedLM](/docs/transformers/v4.37.2/zh/model_doc/longformer#transformers.TFLongformerForMaskedLM)
    (Longformer 模型)'
- en: '`mobilebert` — [TFMobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM)
    (MobileBERT model)'
  id: totrans-2430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [TFMobileBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM)
    (MobileBERT 模型)'
- en: '`mpnet` — [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet model)'
  id: totrans-2431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [TFMPNetForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM)
    (MPNet 模型)'
- en: '`rembert` — [TFRemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM)
    (RemBERT model)'
  id: totrans-2432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [TFRemBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMaskedLM)
    (RemBERT 模型)'
- en: '`roberta` — [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-2433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [TFRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMaskedLM)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [TFRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM)
    (RoFormer model)'
  id: totrans-2435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [TFRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM)
    (RoFormer 模型)'
- en: '`tapas` — [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS model)'
  id: totrans-2436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TFTapasForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForMaskedLM)
    (TAPAS 模型)'
- en: '`xlm` — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM model)'
  id: totrans-2437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [TFXLMWithLMHeadModel](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel)
    (XLM 模型)'
- en: '`xlm-roberta` — [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-2438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [TFXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM)
    (XLM-RoBERTa 模型)'
- en: 'Examples:'
  id: totrans-2439
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE76]'
  id: totrans-2440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: FlaxAutoModelForMaskedLM
  id: totrans-2441
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForMaskedLM
- en: '### `class transformers.FlaxAutoModelForMaskedLM`'
  id: totrans-2442
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForMaskedLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L297)'
  id: totrans-2443
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L297)'
- en: '[PRE77]'
  id: totrans-2444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked language modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2445
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的模型类之一（带有遮蔽语言建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2446
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-2447
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2448
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE78]'
  id: totrans-2449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Parameters
  id: totrans-2450
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类:'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM)
    (ALBERT model)'
  id: totrans-2452
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    配置类: [FlaxAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM)
    (ALBERT 模型)'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  id: totrans-2453
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    配置类: [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM)
    (BERT model)'
  id: totrans-2454
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类: [FlaxBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM)
    (BERT 模型)'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM)
    (BigBird model)'
  id: totrans-2455
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    配置类: [FlaxBigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM)
    (BigBird 模型)'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-2456
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [FlaxDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM)
    (DistilBERT 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM)
    (ELECTRA model)'
  id: totrans-2457
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [FlaxElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM)
    (ELECTRA 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2458
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类：[FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)（mBART模型）'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)
    (RoFormer model)'
  id: totrans-2459
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类：[FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)（RoFormer模型）'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-2460
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类：[FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)（RoBERTa模型）'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2461
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类：[FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)（RoBERTa-PreLayerNorm模型）'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-2462
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类：[FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)（XLM-RoBERTa模型）'
- en: Instantiates one of the model classes of the library (with a masked language
    modeling head) from a configuration.
  id: totrans-2463
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有掩码语言建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2464
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-2465
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE79]'
  id: totrans-2466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '#### `from_pretrained`'
  id: totrans-2467
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2468
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE80]'
  id: totrans-2469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Parameters
  id: totrans-2470
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2472
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2473
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-2474
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-2475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-2476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    模型使用的配置，而不是自动加载的配置。当以下情况自动加载配置时：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-2477
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-2478
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-2479
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-2480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 预下载的模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-2481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-2482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-2483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-2484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-2485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-2486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-2487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-2488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`) — 是否允许在Hub上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-2489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码与模型的其余部分不在同一存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-2490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-2491
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`配置，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-2492
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a masked language
    modeling head) from a pretrained model.
  id: totrans-2493
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有掩码语言建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-2494
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：
- en: '`albert` — [FlaxAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM)
    (ALBERT model)'
  id: totrans-2495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [FlaxAlbertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM)（ALBERT模型）'
- en: '`bart` — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  id: totrans-2496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)（BART模型）'
- en: '`bert` — [FlaxBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM)
    (BERT model)'
  id: totrans-2497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [FlaxBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMaskedLM)（BERT模型）'
- en: '`big_bird` — [FlaxBigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM)
    (BigBird model)'
  id: totrans-2498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [FlaxBigBirdForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM)（BigBird模型）'
- en: '`distilbert` — [FlaxDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM)
    (DistilBERT model)'
  id: totrans-2499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [FlaxDistilBertForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM)（DistilBERT模型）'
- en: '`electra` — [FlaxElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM)
    (ELECTRA model)'
  id: totrans-2500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` - [FlaxElectraForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMaskedLM)（ELECTRA模型）'
- en: '`mbart` — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` - [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)（mBART模型）'
- en: '`roberta` — [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)
    (RoBERTa model)'
  id: totrans-2502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` - [FlaxRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM)（RoBERTa模型）'
- en: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` - [FlaxRobertaPreLayerNormForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMaskedLM)（RoBERTa-PreLayerNorm模型）'
- en: '`roformer` — [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)
    (RoFormer model)'
  id: totrans-2504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` - [FlaxRoFormerForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM)（RoFormer模型）'
- en: '`xlm-roberta` — [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)
    (XLM-RoBERTa model)'
  id: totrans-2505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` - [FlaxXLMRobertaForMaskedLM](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM)（XLM-RoBERTa模型）'
- en: 'Examples:'
  id: totrans-2506
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE81]'
  id: totrans-2507
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: AutoModelForMaskGeneration
  id: totrans-2508
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动模型用于生成口罩
- en: '### `class transformers.AutoModelForMaskGeneration`'
  id: totrans-2509
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForMaskGeneration`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1292)'
  id: totrans-2510
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1292)'
- en: '[PRE82]'
  id: totrans-2511
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: TFAutoModelForMaskGeneration
  id: totrans-2512
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForMaskGeneration
- en: '### `class transformers.TFAutoModelForMaskGeneration`'
  id: totrans-2513
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForMaskGeneration`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L523)'
  id: totrans-2514
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L523)'
- en: '[PRE83]'
  id: totrans-2515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: AutoModelForSeq2SeqLM
  id: totrans-2516
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForSeq2SeqLM
- en: '### `class transformers.AutoModelForSeq2SeqLM`'
  id: totrans-2517
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForSeq2SeqLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1340)'
  id: totrans-2518
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1340)'
- en: '[PRE84]'
  id: totrans-2519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence language modeling head) when
    created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2520
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库的模型类之一（带有序列到序列语言建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2521
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-2522
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2523
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE85]'
  id: totrans-2524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Parameters
  id: totrans-2525
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）-选择要实例化的模型类基于配置类：'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  id: totrans-2527
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)配置类：[BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)（BART模型）'
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration)
    (BigBird-Pegasus model)'
  id: totrans-2528
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)配置类：[BigBirdPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration)（BigBird-Pegasus模型）'
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [BlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration)
    (Blenderbot model)'
  id: totrans-2529
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)配置类：[BlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration)（Blenderbot模型）'
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [BlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  id: totrans-2530
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)配置类：[BlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration)（BlenderbotSmall模型）'
- en: '[EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    configuration class: [EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel)
    (Encoder decoder model)'
  id: totrans-2531
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)配置类：[EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel)（编码器解码器模型）'
- en: '[FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    configuration class: [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq Machine-Translation model)'
  id: totrans-2532
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FSMTConfig](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTConfig)
    配置类: [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq 机器翻译模型)'
- en: '[GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    configuration class: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  id: totrans-2533
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTSanJapaneseConfig](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseConfig)
    配置类: [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese 模型)'
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [LEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForConditionalGeneration)
    (LED model)'
  id: totrans-2534
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    配置类: [LEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForConditionalGeneration)
    (LED 模型)'
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [LongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration)
    (LongT5 model)'
  id: totrans-2535
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    配置类: [LongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration)
    (LongT5 模型)'
- en: '[M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)
    configuration class: [M2M100ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration)
    (M2M100 model)'
  id: totrans-2536
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[M2M100Config](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100Config)
    配置类: [M2M100ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration)
    (M2M100 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2537
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类: [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART 模型)'
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [MT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration)
    (MT5 model)'
  id: totrans-2538
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    配置类: [MT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration)
    (MT5 模型)'
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [MarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianMTModel)
    (Marian model)'
  id: totrans-2539
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    配置类: [MarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianMTModel)
    (Marian 模型)'
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  id: totrans-2540
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    配置类: [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP 模型)'
- en: '[NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    configuration class: [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE model)'
  id: totrans-2541
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NllbMoeConfig](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeConfig)
    配置类: [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE 模型)'
- en: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    configuration class: [PLBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForConditionalGeneration)
    (PLBart model)'
  id: totrans-2542
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    配置类: [PLBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForConditionalGeneration)
    (PLBart 模型)'
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [PegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration)
    (Pegasus model)'
  id: totrans-2543
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    配置类: [PegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration)
    (Pegasus 模型)'
- en: '[PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig)
    configuration class: [PegasusXForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration)
    (PEGASUS-X model)'
  id: totrans-2544
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PegasusXConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXConfig)
    配置类: [PegasusXForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration)
    (PEGASUS-X 模型)'
- en: '[ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    configuration class: [ProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration)
    (ProphetNet model)'
  id: totrans-2545
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetConfig)
    配置类: [ProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration)
    (ProphetNet 模型)'
- en: '[SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    configuration class: [SeamlessM4TForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForTextToText)
    (SeamlessM4T model)'
  id: totrans-2546
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    配置类: [SeamlessM4TForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForTextToText)
    (SeamlessM4T 模型)'
- en: '[SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    configuration class: [SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText)
    (SeamlessM4Tv2 model)'
  id: totrans-2547
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    配置类：[SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText)
    (SeamlessM4Tv2 模型)'
- en: '[SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    configuration class: [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers model)'
  id: totrans-2548
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwitchTransformersConfig](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersConfig)
    配置类：[SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers 模型)'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 model)'
  id: totrans-2549
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    配置类：[T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 模型)'
- en: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    configuration class: [UMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForConditionalGeneration)
    (UMT5 model)'
  id: totrans-2550
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    配置类：[UMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForConditionalGeneration)
    (UMT5 模型)'
- en: '[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    configuration class: [XLMProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration)
    (XLM-ProphetNet model)'
  id: totrans-2551
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMProphetNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig)
    配置类：[XLMProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration)
    (XLM-ProphetNet 模型)'
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a configuration.
  id: totrans-2552
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的模型类（带有序列到序列语言建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2553
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-2554
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE86]'
  id: totrans-2555
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '#### `from_pretrained`'
  id: totrans-2556
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2557
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE87]'
  id: totrans-2558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Parameters
  id: totrans-2559
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2561
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，即在 huggingface.co 上托管的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下进行命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2562
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如 `./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-2563
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向 *tensorflow 索引检查点文件* 的路径或 url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并加载
    PyTorch 模型后，此加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-2564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-2565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *可选*) — 用于模型的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-2566
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-2567
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-2568
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并且在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-2569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *可选*) — 用于替代从保存的权重文件加载的状态字典的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-2570
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型，但加载自己的权重，可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-2571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`，*可选*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-2572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *可选*, 默认为 `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-2573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-2574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-2575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-2576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*, 默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-2577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-2578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-2579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在Hub上定义自定义模型的代码。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-2580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *可选*, 默认为 `"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-2581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-2582
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了配置`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-2583
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a pretrained model.
  id: totrans-2584
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有序列到序列语言建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-2585
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类基于配置对象的 `model_type` 属性进行选择（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`bart` — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART model)'
  id: totrans-2586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [BartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForConditionalGeneration)
    (BART 模型)'
- en: '`bigbird_pegasus` — [BigBirdPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration)
    (BigBird-Pegasus model)'
  id: totrans-2587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bigbird_pegasus` — [BigBirdPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration)
    (BigBird-Pegasus 模型)'
- en: '`blenderbot` — [BlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration)
    (Blenderbot model)'
  id: totrans-2588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot` — [BlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration)
    (Blenderbot 模型)'
- en: '`blenderbot-small` — [BlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  id: totrans-2589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot-small` — [BlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall 模型)'
- en: '`encoder-decoder` — [EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel)
    (Encoder decoder model)'
  id: totrans-2590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder-decoder` — [EncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel)
    (编码器解码器模型)'
- en: '`fsmt` — [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq Machine-Translation model)'
  id: totrans-2591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fsmt` — [FSMTForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration)
    (FairSeq 机器翻译模型)'
- en: '`gptsan-japanese` — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese model)'
  id: totrans-2592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptsan-japanese` — [GPTSanJapaneseForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/gptsan-japanese#transformers.GPTSanJapaneseForConditionalGeneration)
    (GPTSAN-japanese 模型)'
- en: '`led` — [LEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForConditionalGeneration)
    (LED model)'
  id: totrans-2593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`led` — [LEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForConditionalGeneration)
    (LED 模型)'
- en: '`longt5` — [LongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration)
    (LongT5 model)'
  id: totrans-2594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longt5` — [LongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration)
    (LongT5 模型)'
- en: '`m2m_100` — [M2M100ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration)
    (M2M100 model)'
  id: totrans-2595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`m2m_100` — [M2M100ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration)
    (M2M100 模型)'
- en: '`marian` — [MarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianMTModel)
    (Marian model)'
  id: totrans-2596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marian` — [MarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianMTModel)
    (Marian 模型)'
- en: '`mbart` — [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [MBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForConditionalGeneration)
    (mBART 模型)'
- en: '`mt5` — [MT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration)
    (MT5 model)'
  id: totrans-2598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [MT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForConditionalGeneration)
    (MT5 模型)'
- en: '`mvp` — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP model)'
  id: totrans-2599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mvp` — [MvpForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForConditionalGeneration)
    (MVP 模型)'
- en: '`nllb-moe` — [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE model)'
  id: totrans-2600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nllb-moe` — [NllbMoeForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/nllb-moe#transformers.NllbMoeForConditionalGeneration)
    (NLLB-MOE 模型)'
- en: '`pegasus` — [PegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration)
    (Pegasus model)'
  id: totrans-2601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus` — [PegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration)
    (Pegasus 模型)'
- en: '`pegasus_x` — [PegasusXForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration)
    (PEGASUS-X model)'
  id: totrans-2602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus_x` — [PegasusXForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration)
    (PEGASUS-X 模型)'
- en: '`plbart` — [PLBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForConditionalGeneration)
    (PLBart model)'
  id: totrans-2603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plbart` — [PLBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForConditionalGeneration)
    (PLBart 模型)'
- en: '`prophetnet` — [ProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration)
    (ProphetNet model)'
  id: totrans-2604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prophetnet` — [ProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration)
    (ProphetNet 模型)'
- en: '`seamless_m4t` — [SeamlessM4TForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForTextToText)
    (SeamlessM4T model)'
  id: totrans-2605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t` — [SeamlessM4TForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForTextToText)
    (SeamlessM4T 模型)'
- en: '`seamless_m4t_v2` — [SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText)
    (SeamlessM4Tv2 model)'
  id: totrans-2606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t_v2` — [SeamlessM4Tv2ForTextToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForTextToText)
    (SeamlessM4Tv2 模型)'
- en: '`switch_transformers` — [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers model)'
  id: totrans-2607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`switch_transformers` — [SwitchTransformersForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/switch_transformers#transformers.SwitchTransformersForConditionalGeneration)
    (SwitchTransformers 模型)'
- en: '`t5` — [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 model)'
  id: totrans-2608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [T5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForConditionalGeneration)
    (T5 模型)'
- en: '`umt5` — [UMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForConditionalGeneration)
    (UMT5 model)'
  id: totrans-2609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`umt5` — [UMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForConditionalGeneration)
    (UMT5 模型)'
- en: '`xlm-prophetnet` — [XLMProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration)
    (XLM-ProphetNet model)'
  id: totrans-2610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-prophetnet` — [XLMProphetNetForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration)
    (XLM-ProphetNet 模型)'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-2611
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-2612
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE88]'
  id: totrans-2613
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: TFAutoModelForSeq2SeqLM
  id: totrans-2614
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForSeq2SeqLM
- en: '### `class transformers.TFAutoModelForSeq2SeqLM`'
  id: totrans-2615
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForSeq2SeqLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L619)'
  id: totrans-2616
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L619)'
- en: '[PRE89]'
  id: totrans-2617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence language modeling head) when
    created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2618
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将作为库中的模型类之一实例化（带有序列到序列语言建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2619
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会报错）。
- en: '#### `from_config`'
  id: totrans-2620
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2621
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE90]'
  id: totrans-2622
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Parameters
  id: totrans-2623
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类:'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART model)'
  id: totrans-2625
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    配置类: [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART 模型)'
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [TFBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration)
    (Blenderbot model)'
  id: totrans-2626
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    配置类: [TFBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration)
    (Blenderbot 模型)'
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [TFBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  id: totrans-2627
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    配置类: [TFBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall 模型)'
- en: '[EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    configuration class: [TFEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel)
    (Encoder decoder model)'
  id: totrans-2628
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    配置类: [TFEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel)
    (编码器解码器模型)'
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [TFLEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration)
    (LED model)'
  id: totrans-2629
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    配置类: [TFLEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration)
    (LED 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [TFMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2630
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类: [TFMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration)
    (mBART 模型)'
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [TFMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration)
    (MT5 model)'
  id: totrans-2631
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    配置类: [TFMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration)
    (MT5 模型)'
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [TFMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianMTModel)
    (Marian model)'
  id: totrans-2632
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    配置类: [TFMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianMTModel)
    (Marian 模型)'
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [TFPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration)
    (Pegasus model)'
  id: totrans-2633
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    配置类: [TFPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration)
    (Pegasus 模型)'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 model)'
  id: totrans-2634
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)配置类：[TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)（T5模型）'
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a configuration.
  id: totrans-2635
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库中的一个模型类（带有序列到序列语言建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2636
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-2637
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE91]'
  id: totrans-2638
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '#### `from_pretrained`'
  id: totrans-2639
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2640
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE92]'
  id: totrans-2641
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: Parameters
  id: totrans-2642
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2644
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或命名空间下的用户或组织名称，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2645
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-2646
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch状态字典保存文件*的路径或URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-2647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-2648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-2649
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是由库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-2650
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-2651
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-2652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-2653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-2654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-2655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除未完全接收的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-2656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-2657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-2658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-2659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 id，因为我们在
    huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-2660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-2661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *可选*, 默认为 `"main"`) — 用于 Hub 上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    id，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-2662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，行为会有所不同:'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-2663
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-2664
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个键对应一个配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a pretrained model.
  id: totrans-2665
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有序列到序列语言建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-2666
  prefs: []
  type: TYPE_NORMAL
  zh: '要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退:'
- en: '`bart` — [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART model)'
  id: totrans-2667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [TFBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForConditionalGeneration)
    (BART 模型)'
- en: '`blenderbot` — [TFBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration)
    (Blenderbot model)'
  id: totrans-2668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot` — [TFBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration)
    (Blenderbot 模型)'
- en: '`blenderbot-small` — [TFBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  id: totrans-2669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot-small` — [TFBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall 模型)'
- en: '`encoder-decoder` — [TFEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel)
    (Encoder decoder model)'
  id: totrans-2670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder-decoder` — [TFEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel)
    (编码器解码器模型)'
- en: '`led` — [TFLEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration)
    (LED model)'
  id: totrans-2671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`led` — [TFLEDForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/led#transformers.TFLEDForConditionalGeneration)
    (LED 模型)'
- en: '`marian` — [TFMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianMTModel)
    (Marian model)'
  id: totrans-2672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marian` — [TFMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.TFMarianMTModel)
    (Marian 模型)'
- en: '`mbart` — [TFMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [TFMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration)
    (mBART 模型)'
- en: '`mt5` — [TFMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration)
    (MT5 model)'
  id: totrans-2674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [TFMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration)
    (MT5 模型)'
- en: '`pegasus` — [TFPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration)
    (Pegasus model)'
  id: totrans-2675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus` — [TFPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration)
    (Pegasus 模型)'
- en: '`t5` — [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 model)'
  id: totrans-2676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [TFT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.TFT5ForConditionalGeneration)
    (T5 模型)'
- en: 'Examples:'
  id: totrans-2677
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE93]'
  id: totrans-2678
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: FlaxAutoModelForSeq2SeqLM
  id: totrans-2679
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForSeq2SeqLM
- en: '### `class transformers.FlaxAutoModelForSeq2SeqLM`'
  id: totrans-2680
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForSeq2SeqLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L304)'
  id: totrans-2681
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L304)'
- en: '[PRE94]'
  id: totrans-2682
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence language modeling head) when
    created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2683
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有序列到序列语言建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2684
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`进行实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-2685
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2686
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE95]'
  id: totrans-2687
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Parameters
  id: totrans-2688
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)）—
    选择要实例化的模型类基于配置类：'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  id: totrans-2690
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartConfig)
    配置类：[FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.FlaxBartForConditionalGeneration)（BART模型）'
- en: '[BlenderbotConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.BlenderbotConfig)
    configuration class: [FlaxBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration)
    (Blenderbot model)'
  id: totrans-2691
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotConfig](/docs/transformers/v4.37.2/zh/model_doc/blenderbot#transformers.BlenderbotConfig)
    配置类：[FlaxBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration)（Blenderbot模型）'
- en: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    configuration class: [FlaxBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  id: totrans-2692
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlenderbotSmallConfig](/docs/transformers/v4.37.2/zh/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig)
    配置类：[FlaxBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration)（BlenderbotSmall模型）'
- en: '[EncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    configuration class: [FlaxEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel)
    (Encoder decoder model)'
  id: totrans-2693
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EncoderDecoderConfig](/docs/transformers/v4.37.2/zh/model_doc/encoder-decoder#transformers.EncoderDecoderConfig)
    配置类：[FlaxEncoderDecoderModel](/docs/transformers/v4.37.2/zh/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel)（编码器解码器模型）'
- en: '[LongT5Config](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.LongT5Config)
    configuration class: [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 model)'
  id: totrans-2694
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongT5Config](/docs/transformers/v4.37.2/zh/model_doc/longt5#transformers.LongT5Config)
    配置类：[FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)（LongT5模型）'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2695
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/zh/model_doc/mbart#transformers.MBartConfig)
    配置类：[FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)（mBART模型）'
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 model)'
  id: totrans-2696
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MT5Config](/docs/transformers/v4.37.2/zh/model_doc/mt5#transformers.MT5Config)
    配置类：[FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)（MT5模型）'
- en: '[MarianConfig](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.MarianConfig)
    configuration class: [FlaxMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianMTModel)
    (Marian model)'
  id: totrans-2697
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarianConfig](/docs/transformers/v4.37.2/zh/model_doc/marian#transformers.MarianConfig)
    配置类：[FlaxMarianMTModel](/docs/transformers/v4.37.2/zh/model_doc/marian#transformers.FlaxMarianMTModel)（Marian模型）'
- en: '[PegasusConfig](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.PegasusConfig)
    configuration class: [FlaxPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration)
    (Pegasus model)'
  id: totrans-2698
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PegasusConfig](/docs/transformers/v4.37.2/zh/model_doc/pegasus#transformers.PegasusConfig)
    配置类：[FlaxPegasusForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration)（Pegasus模型）'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 model)'
  id: totrans-2699
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/zh/model_doc/t5#transformers.T5Config)
    配置类：[FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)（T5模型）'
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a configuration.
  id: totrans-2700
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库的模型类之一（带有序列到序列语言建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2701
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-2702
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE96]'
  id: totrans-2703
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '#### `from_pretrained`'
  id: totrans-2704
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2705
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE97]'
  id: totrans-2706
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: Parameters
  id: totrans-2707
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2709
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型标识符*，托管在huggingface.co上的模型存储库中。有效的模型标识符可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2710
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-2711
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将`from_pt`设置为`True`，并将配置对象提供为`config`参数。使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型的加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-2712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-2713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-2714
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型标识符*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-2715
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-2716
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-2717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 下载预训练模型配置应缓存的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-2718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-2719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-2720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-2721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。每个请求都会使用代理。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-2722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`）— 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-2723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`）— 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-2724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-2725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行
    Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-2726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`） — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-2727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-2728
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-2729
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    language modeling head) from a pretrained model.
  id: totrans-2730
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有序列到序列语言建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-2731
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`bart` — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART model)'
  id: totrans-2732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [FlaxBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration)
    (BART 模型)'
- en: '`blenderbot` — [FlaxBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration)
    (Blenderbot model)'
  id: totrans-2733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot` — [FlaxBlenderbotForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration)
    (Blenderbot 模型)'
- en: '`blenderbot-small` — [FlaxBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall model)'
  id: totrans-2734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blenderbot-small` — [FlaxBlenderbotSmallForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration)
    (BlenderbotSmall 模型)'
- en: '`encoder-decoder` — [FlaxEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel)
    (Encoder decoder model)'
  id: totrans-2735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder-decoder` — [FlaxEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel)
    (编码器解码器模型)'
- en: '`longt5` — [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 model)'
  id: totrans-2736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longt5` — [FlaxLongT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration)
    (LongT5 模型)'
- en: '`marian` — [FlaxMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianMTModel)
    (Marian model)'
  id: totrans-2737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marian` — [FlaxMarianMTModel](/docs/transformers/v4.37.2/en/model_doc/marian#transformers.FlaxMarianMTModel)
    (Marian 模型)'
- en: '`mbart` — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART model)'
  id: totrans-2738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [FlaxMBartForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration)
    (mBART 模型)'
- en: '`mt5` — [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 model)'
  id: totrans-2739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [FlaxMT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration)
    (MT5 模型)'
- en: '`pegasus` — [FlaxPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration)
    (Pegasus model)'
  id: totrans-2740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pegasus` — [FlaxPegasusForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration)
    (Pegasus 模型)'
- en: '`t5` — [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 model)'
  id: totrans-2741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [FlaxT5ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration)
    (T5 模型)'
- en: 'Examples:'
  id: totrans-2742
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE98]'
  id: totrans-2743
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: AutoModelForSequenceClassification
  id: totrans-2744
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForSequenceClassification
- en: '### `class transformers.AutoModelForSequenceClassification`'
  id: totrans-2745
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1351)'
  id: totrans-2746
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1351)'
- en: '[PRE99]'
  id: totrans-2747
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence classification head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2748
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将实例化为库的模型类之一（带有序列分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2749
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-2750
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2751
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE100]'
  id: totrans-2752
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Parameters
  id: totrans-2753
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    选择要实例化的模型类基于配置类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForSequenceClassification)
    (ALBERT model)'
  id: totrans-2755
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[AlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForSequenceClassification)（ALBERT模型）'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForSequenceClassification)
    (BART model)'
  id: totrans-2756
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)配置类：[BartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForSequenceClassification)（BART模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForSequenceClassification)
    (BERT model)'
  id: totrans-2757
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForSequenceClassification)（BERT模型）'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification)
    (BigBird model)'
  id: totrans-2758
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)配置类：[BigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification)（BigBird模型）'
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification)
    (BigBird-Pegasus model)'
  id: totrans-2759
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)配置类：[BigBirdPegasusForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification)（BigBird-Pegasus模型）'
- en: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    configuration class: [BioGptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForSequenceClassification)
    (BioGpt model)'
  id: totrans-2760
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)配置类：[BioGptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForSequenceClassification)（BioGpt模型）'
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForSequenceClassification)
    (BLOOM model)'
  id: totrans-2761
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)配置类：[BloomForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForSequenceClassification)（BLOOM模型）'
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [CTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification)
    (CTRL model)'
  id: totrans-2762
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)配置类：[CTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification)（CTRL模型）'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification)
    (CamemBERT model)'
  id: totrans-2763
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)配置类：[CamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification)（CamemBERT模型）'
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForSequenceClassification)
    (CANINE model)'
  id: totrans-2764
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)配置类：[CanineForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForSequenceClassification)（CANINE模型）'
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification)
    (ConvBERT model)'
  id: totrans-2765
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)配置类：[ConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification)（ConvBERT模型）'
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification)
    (Data2VecText model)'
  id: totrans-2766
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)配置类：[Data2VecTextForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification)（Data2VecText模型）'
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForSequenceClassification)
    (DeBERTa model)'
  id: totrans-2767
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DebertaConfig配置类：DebertaForSequenceClassification（DeBERTa模型）
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification)
    (DeBERTa-v2 model)'
  id: totrans-2768
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DebertaV2Config配置类：DebertaV2ForSequenceClassification（DeBERTa-v2模型）
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification)
    (DistilBERT model)'
  id: totrans-2769
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DistilBertConfig配置类：DistilBertForSequenceClassification（DistilBERT模型）
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForSequenceClassification)
    (ELECTRA model)'
  id: totrans-2770
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ElectraConfig配置类：ElectraForSequenceClassification（ELECTRA模型）
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForSequenceClassification)
    (ERNIE model)'
  id: totrans-2771
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ErnieConfig配置类：ErnieForSequenceClassification（ERNIE模型）
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForSequenceClassification)
    (ErnieM model)'
  id: totrans-2772
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ErnieMConfig配置类：ErnieMForSequenceClassification（ErnieM模型）
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [EsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForSequenceClassification)
    (ESM model)'
  id: totrans-2773
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: EsmConfig配置类：EsmForSequenceClassification（ESM模型）
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForSequenceClassification)
    (FNet model)'
  id: totrans-2774
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FNetConfig配置类：FNetForSequenceClassification（FNet模型）
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForSequenceClassification)
    (Falcon model)'
  id: totrans-2775
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FalconConfig配置类：FalconForSequenceClassification（Falcon模型）
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification)
    (FlauBERT model)'
  id: totrans-2776
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FlaubertConfig配置类：FlaubertForSequenceClassification（FlauBERT模型）
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForSequenceClassification)
    (Funnel Transformer model)'
  id: totrans-2777
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FunnelConfig配置类：FunnelForSequenceClassification（Funnel Transformer模型）
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification)
    (OpenAI GPT-2 model)'
  id: totrans-2778
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT2Config配置类：GPT2ForSequenceClassification（OpenAI GPT-2模型）
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForSequenceClassification)
    (GPTBigCode model)'
  id: totrans-2779
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPTBigCodeConfig配置类：GPTBigCodeForSequenceClassification（GPTBigCode模型）
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [GPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForSequenceClassification)
    (GPT-J model)'
  id: totrans-2780
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPTJConfig配置类：GPTJForSequenceClassification（GPT-J模型）
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification)
    (GPT Neo model)'
  id: totrans-2781
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPTNeoConfig配置类：GPTNeoForSequenceClassification（GPT Neo模型）
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForSequenceClassification)
    (GPT NeoX model)'
  id: totrans-2782
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    配置类: [GPTNeoXForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForSequenceClassification)
    (GPT NeoX 模型)'
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForSequenceClassification)
    (I-BERT model)'
  id: totrans-2783
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    配置类: [IBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForSequenceClassification)
    (I-BERT 模型)'
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [LEDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForSequenceClassification)
    (LED model)'
  id: totrans-2784
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    配置类: [LEDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForSequenceClassification)
    (LED 模型)'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification)
    (LayoutLM model)'
  id: totrans-2785
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类: [LayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification)
    (LayoutLM 模型)'
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)
    (LayoutLMv2 model)'
  id: totrans-2786
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    配置类: [LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)
    (LayoutLMv2 模型)'
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification)
    (LayoutLMv3 model)'
  id: totrans-2787
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    配置类: [LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification)
    (LayoutLMv3 模型)'
- en: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    configuration class: [LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification)
    (LiLT model)'
  id: totrans-2788
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    配置类: [LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification)
    (LiLT 模型)'
- en: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    configuration class: [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification)
    (LLaMA model)'
  id: totrans-2789
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LlamaConfig](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaConfig)
    配置类: [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification)
    (LLaMA 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification)
    (Longformer model)'
  id: totrans-2790
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [LongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification)
    (Longformer 模型)'
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForSequenceClassification)
    (LUKE model)'
  id: totrans-2791
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    配置类: [LukeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForSequenceClassification)
    (LUKE 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForSequenceClassification)
    (mBART model)'
  id: totrans-2792
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类: [MBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForSequenceClassification)
    (mBART 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification)
    (MPNet model)'
  id: totrans-2793
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [MPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification)
    (MPNet 模型)'
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [MT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForSequenceClassification)
    (MT5 model)'
  id: totrans-2794
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    配置类: [MT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForSequenceClassification)
    (MT5 模型)'
- en: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    configuration class: [MarkupLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification)
    (MarkupLM model)'
  id: totrans-2795
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    配置类: [MarkupLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification)
    (MarkupLM 模型)'
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForSequenceClassification)
    (MEGA model)'
  id: totrans-2796
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    配置类: [MegaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForSequenceClassification)
    (MEGA 模型)'
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification)
    (Megatron-BERT model)'
  id: totrans-2797
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    配置类: [MegatronBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification)
    (Megatron-BERT 模型)'
- en: '[MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    configuration class: [MistralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForSequenceClassification)
    (Mistral model)'
  id: totrans-2798
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MistralConfig](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralConfig)
    配置类: [MistralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForSequenceClassification)
    (Mistral 模型)'
- en: '[MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    configuration class: [MixtralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForSequenceClassification)
    (Mixtral model)'
  id: totrans-2799
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MixtralConfig](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralConfig)
    配置类: [MixtralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForSequenceClassification)
    (Mixtral 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification)
    (MobileBERT model)'
  id: totrans-2800
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [MobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification)
    (MobileBERT 模型)'
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForSequenceClassification)
    (MPT model)'
  id: totrans-2801
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    配置类: [MptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForSequenceClassification)
    (MPT 模型)'
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForSequenceClassification)
    (MRA model)'
  id: totrans-2802
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    配置类: [MraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForSequenceClassification)
    (MRA 模型)'
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForSequenceClassification)
    (MVP model)'
  id: totrans-2803
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    配置类: [MvpForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForSequenceClassification)
    (MVP 模型)'
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForSequenceClassification)
    (Nezha model)'
  id: totrans-2804
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    配置类: [NezhaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForSequenceClassification)
    (Nezha 模型)'
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification)
    (Nyströmformer model)'
  id: totrans-2805
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    配置类: [NystromformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification)
    (Nyströmformer 模型)'
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [OPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForSequenceClassification)
    (OPT model)'
  id: totrans-2806
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    配置类: [OPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForSequenceClassification)
    (OPT 模型)'
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [OpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification)
    (OpenAI GPT model)'
  id: totrans-2807
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    配置类: [OpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification)
    (OpenAI GPT 模型)'
- en: '[OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    configuration class: [OpenLlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForSequenceClassification)
    (OpenLlama model)'
  id: totrans-2808
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenLlamaConfig](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaConfig)
    配置类: [OpenLlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForSequenceClassification)
    (OpenLlama 模型)'
- en: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    configuration class: [PLBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForSequenceClassification)
    (PLBart model)'
  id: totrans-2809
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PLBartConfig](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartConfig)
    配置类: [PLBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForSequenceClassification)
    (PLBart 模型)'
- en: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    configuration class: [PerceiverForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification)
    (Perceiver model)'
  id: totrans-2810
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    配置类: [PerceiverForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification)
    (Perceiver 模型)'
- en: '[PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    configuration class: [PersimmonForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForSequenceClassification)
    (Persimmon model)'
  id: totrans-2811
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PersimmonConfig](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonConfig)
    配置类: [PersimmonForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForSequenceClassification)
    (Persimmon 模型)'
- en: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    configuration class: [PhiForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForSequenceClassification)
    (Phi model)'
  id: totrans-2812
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: PhiConfig配置类：PhiForSequenceClassification（Phi模型）
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification)
    (QDQBert model)'
  id: totrans-2813
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: QDQBertConfig配置类：QDQBertForSequenceClassification（QDQBert模型）
- en: '[Qwen2Config](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2Config)
    configuration class: [Qwen2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForSequenceClassification)
    (Qwen2 model)'
  id: totrans-2814
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qwen2Config配置类：Qwen2ForSequenceClassification（Qwen2模型）
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForSequenceClassification)
    (Reformer model)'
  id: totrans-2815
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReformerConfig配置类：ReformerForSequenceClassification（Reformer模型）
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForSequenceClassification)
    (RemBERT model)'
  id: totrans-2816
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: RemBertConfig配置类：RemBertForSequenceClassification（RemBERT模型）
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification)
    (RoCBert model)'
  id: totrans-2817
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: RoCBertConfig配置类：RoCBertForSequenceClassification（RoCBert模型）
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForSequenceClassification)
    (RoFormer model)'
  id: totrans-2818
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: RoFormerConfig配置类：RoFormerForSequenceClassification（RoFormer模型）
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForSequenceClassification)
    (RoBERTa model)'
  id: totrans-2819
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: RobertaConfig配置类：RobertaForSequenceClassification（RoBERTa模型）
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2820
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: RobertaPreLayerNormConfig配置类：RobertaPreLayerNormForSequenceClassification（RoBERTa-PreLayerNorm模型）
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification)
    (SqueezeBERT model)'
  id: totrans-2821
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: SqueezeBertConfig配置类：SqueezeBertForSequenceClassification（SqueezeBERT模型）
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForSequenceClassification)
    (T5 model)'
  id: totrans-2822
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: T5Config配置类：T5ForSequenceClassification（T5模型）
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForSequenceClassification)
    (TAPAS model)'
  id: totrans-2823
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: TapasConfig配置类：TapasForSequenceClassification（TAPAS模型）
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification)
    (Transformer-XL model)'
  id: totrans-2824
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: TransfoXLConfig配置类：TransfoXLForSequenceClassification（Transformer-XL模型）
- en: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    configuration class: [UMT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForSequenceClassification)
    (UMT5 model)'
  id: totrans-2825
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: UMT5Config配置类：UMT5ForSequenceClassification（UMT5模型）
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForSequenceClassification)
    (XLM model)'
  id: totrans-2826
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: XLMConfig配置类：XLMForSequenceClassification（XLM模型）
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  id: totrans-2827
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类：[XLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification)（XLM-RoBERTa模型）'
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification)
    (XLM-RoBERTa-XL model)'
  id: totrans-2828
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    配置类：[XLMRobertaXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification)（XLM-RoBERTa-XL模型）'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification)
    (XLNet model)'
  id: totrans-2829
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类：[XLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification)（XLNet模型）'
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForSequenceClassification)
    (X-MOD model)'
  id: totrans-2830
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    配置类：[XmodForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForSequenceClassification)（X-MOD模型）'
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForSequenceClassification)
    (YOSO model)'
  id: totrans-2831
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    配置类：[YosoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForSequenceClassification)（YOSO模型）'
- en: Instantiates one of the model classes of the library (with a sequence classification
    head) from a configuration.
  id: totrans-2832
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有序列分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2833
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-2834
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE101]'
  id: totrans-2835
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '#### `from_pretrained`'
  id: totrans-2836
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2837
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE102]'
  id: totrans-2838
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: Parameters
  id: totrans-2839
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2840
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2841
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库内。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2842
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-2843
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*TensorFlow索引检查点文件*的路径或URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-2844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-2845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-2846
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-2847
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录来重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-2848
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-2849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 用于替代从保存的权重文件加载的状态字典的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-2850
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-2851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-2852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, defaults to `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-2853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-2854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-2855
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器的协议或端点的字典，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理将用于每个请求。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-2856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-2857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-2858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-2859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅在您信任的存储库中设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-2860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-2861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-2862
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设所有相关的配置更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-2863
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a sequence classification
    head) from a pretrained model.
  id: totrans-2864
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有序列分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-2865
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [AlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForSequenceClassification)
    (ALBERT model)'
  id: totrans-2866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [AlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForSequenceClassification)
    (ALBERT 模型)'
- en: '`bart` — [BartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForSequenceClassification)
    (BART model)'
  id: totrans-2867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [BartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForSequenceClassification)
    (BART 模型)'
- en: '`bert` — [BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForSequenceClassification)
    (BERT model)'
  id: totrans-2868
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForSequenceClassification)
    (BERT 模型)'
- en: '`big_bird` — [BigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification)
    (BigBird model)'
  id: totrans-2869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification)
    (BigBird 模型)'
- en: '`bigbird_pegasus` — [BigBirdPegasusForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification)
    (BigBird-Pegasus model)'
  id: totrans-2870
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bigbird_pegasus` — [BigBirdPegasusForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification)
    (BigBird-Pegasus 模型)'
- en: '`biogpt` — [BioGptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForSequenceClassification)
    (BioGpt model)'
  id: totrans-2871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`biogpt` — [BioGptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForSequenceClassification)
    (BioGpt 模型)'
- en: '`bloom` — [BloomForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForSequenceClassification)
    (BLOOM model)'
  id: totrans-2872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [BloomForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForSequenceClassification)
    (BLOOM 模型)'
- en: '`camembert` — [CamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification)
    (CamemBERT model)'
  id: totrans-2873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForSequenceClassification)
    (CamemBERT 模型)'
- en: '`canine` — [CanineForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForSequenceClassification)
    (CANINE model)'
  id: totrans-2874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`canine` — [CanineForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForSequenceClassification)
    (CANINE 模型)'
- en: '`code_llama` — [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification)
    (CodeLlama model)'
  id: totrans-2875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_llama` — [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification)
    (CodeLlama 模型)'
- en: '`convbert` — [ConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification)
    (ConvBERT model)'
  id: totrans-2876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [ConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForSequenceClassification)
    (ConvBERT 模型)'
- en: '`ctrl` — [CTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification)
    (CTRL model)'
  id: totrans-2877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [CTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLForSequenceClassification)
    (CTRL 模型)'
- en: '`data2vec-text` — [Data2VecTextForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification)
    (Data2VecText model)'
  id: totrans-2878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [Data2VecTextForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification)
    (Data2VecText 模型)'
- en: '`deberta` — [DebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForSequenceClassification)
    (DeBERTa model)'
  id: totrans-2879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [DebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForSequenceClassification)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [DebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification)
    (DeBERTa-v2 model)'
  id: totrans-2880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [DebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [DistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification)
    (DistilBERT model)'
  id: totrans-2881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [DistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification)
    (DistilBERT 模型)'
- en: '`electra` — [ElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForSequenceClassification)
    (ELECTRA model)'
  id: totrans-2882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForSequenceClassification)
    (ELECTRA 模型)'
- en: '`ernie` — [ErnieForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForSequenceClassification)
    (ERNIE model)'
  id: totrans-2883
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [ErnieForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForSequenceClassification)
    (ERNIE 模型)'
- en: '`ernie_m` — [ErnieMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForSequenceClassification)
    (ErnieM model)'
  id: totrans-2884
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie_m` — [ErnieMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForSequenceClassification)
    (ErnieM 模型)'
- en: '`esm` — [EsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForSequenceClassification)
    (ESM model)'
  id: totrans-2885
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [EsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForSequenceClassification)
    (ESM 模型)'
- en: '`falcon` — [FalconForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForSequenceClassification)
    (Falcon model)'
  id: totrans-2886
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`falcon` — [FalconForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForSequenceClassification)
    (Falcon 模型)'
- en: '`flaubert` — [FlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification)
    (FlauBERT model)'
  id: totrans-2887
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [FlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification)
    (FlauBERT 模型)'
- en: '`fnet` — [FNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForSequenceClassification)
    (FNet model)'
  id: totrans-2888
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` — [FNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForSequenceClassification)
    (FNet 模型)'
- en: '`funnel` — [FunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForSequenceClassification)
    (Funnel Transformer model)'
  id: totrans-2889
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [FunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForSequenceClassification)
    (Funnel Transformer model)'
- en: '`gpt-sw3` — [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification)
    (GPT-Sw3 model)'
  id: totrans-2890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification)
    (GPT-Sw3 model)'
- en: '`gpt2` — [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification)
    (OpenAI GPT-2 model)'
  id: totrans-2891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [GPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification)
    (OpenAI GPT-2 model)'
- en: '`gpt_bigcode` — [GPTBigCodeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForSequenceClassification)
    (GPTBigCode model)'
  id: totrans-2892
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_bigcode` — [GPTBigCodeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForSequenceClassification)
    (GPTBigCode model)'
- en: '`gpt_neo` — [GPTNeoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification)
    (GPT Neo model)'
  id: totrans-2893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neo` — [GPTNeoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification)
    (GPT Neo model)'
- en: '`gpt_neox` — [GPTNeoXForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForSequenceClassification)
    (GPT NeoX model)'
  id: totrans-2894
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox` — [GPTNeoXForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForSequenceClassification)
    (GPT NeoX model)'
- en: '`gptj` — [GPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForSequenceClassification)
    (GPT-J model)'
  id: totrans-2895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [GPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForSequenceClassification)
    (GPT-J model)'
- en: '`ibert` — [IBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForSequenceClassification)
    (I-BERT model)'
  id: totrans-2896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ibert` — [IBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForSequenceClassification)
    (I-BERT model)'
- en: '`layoutlm` — [LayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification)
    (LayoutLM model)'
  id: totrans-2897
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [LayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification)
    (LayoutLM model)'
- en: '`layoutlmv2` — [LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)
    (LayoutLMv2 model)'
  id: totrans-2898
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification)
    (LayoutLMv2 model)'
- en: '`layoutlmv3` — [LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification)
    (LayoutLMv3 model)'
  id: totrans-2899
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification)
    (LayoutLMv3 model)'
- en: '`led` — [LEDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForSequenceClassification)
    (LED model)'
  id: totrans-2900
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`led` — [LEDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForSequenceClassification)
    (LED model)'
- en: '`lilt` — [LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification)
    (LiLT model)'
  id: totrans-2901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lilt` — [LiltForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForSequenceClassification)
    (LiLT model)'
- en: '`llama` — [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification)
    (LLaMA model)'
  id: totrans-2902
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llama` — [LlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/llama2#transformers.LlamaForSequenceClassification)
    (LLaMA model)'
- en: '`longformer` — [LongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification)
    (Longformer model)'
  id: totrans-2903
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [LongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForSequenceClassification)
    (Longformer model)'
- en: '`luke` — [LukeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForSequenceClassification)
    (LUKE model)'
  id: totrans-2904
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`luke` — [LukeForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForSequenceClassification)
    (LUKE model)'
- en: '`markuplm` — [MarkupLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification)
    (MarkupLM model)'
  id: totrans-2905
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`markuplm` — [MarkupLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification)
    (MarkupLM model)'
- en: '`mbart` — [MBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForSequenceClassification)
    (mBART model)'
  id: totrans-2906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [MBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForSequenceClassification)
    (mBART model)'
- en: '`mega` — [MegaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForSequenceClassification)
    (MEGA model)'
  id: totrans-2907
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [MegaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForSequenceClassification)
    (MEGA model)'
- en: '`megatron-bert` — [MegatronBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification)
    (Megatron-BERT model)'
  id: totrans-2908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [MegatronBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification)
    (Megatron-BERT model)'
- en: '`mistral` — [MistralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForSequenceClassification)
    (Mistral model)'
  id: totrans-2909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mistral` — [MistralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mistral#transformers.MistralForSequenceClassification)
    (Mistral model)'
- en: '`mixtral` — [MixtralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForSequenceClassification)
    (Mixtral model)'
  id: totrans-2910
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mixtral` — [MixtralForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mixtral#transformers.MixtralForSequenceClassification)
    (Mixtral model)'
- en: '`mobilebert` — [MobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification)
    (MobileBERT model)'
  id: totrans-2911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [MobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification)
    (MobileBERT model)'
- en: '`mpnet` — [MPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification)
    (MPNet model)'
  id: totrans-2912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [MPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForSequenceClassification)
    (MPNet model)'
- en: '`mpt` — [MptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForSequenceClassification)
    (MPT model)'
  id: totrans-2913
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpt` — [MptForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForSequenceClassification)
    (MPT model)'
- en: '`mra` — [MraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForSequenceClassification)
    (MRA model)'
  id: totrans-2914
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mra` — [MraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForSequenceClassification)
    (MRA 模型)'
- en: '`mt5` — [MT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForSequenceClassification)
    (MT5 model)'
  id: totrans-2915
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [MT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForSequenceClassification)
    (MT5 模型)'
- en: '`mvp` — [MvpForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForSequenceClassification)
    (MVP model)'
  id: totrans-2916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mvp` — [MvpForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForSequenceClassification)
    (MVP 模型)'
- en: '`nezha` — [NezhaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForSequenceClassification)
    (Nezha model)'
  id: totrans-2917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` — [NezhaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForSequenceClassification)
    (Nezha 模型)'
- en: '`nystromformer` — [NystromformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification)
    (Nyströmformer model)'
  id: totrans-2918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nystromformer` — [NystromformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification)
    (Nyströmformer 模型)'
- en: '`open-llama` — [OpenLlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForSequenceClassification)
    (OpenLlama model)'
  id: totrans-2919
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`open-llama` — [OpenLlamaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/open-llama#transformers.OpenLlamaForSequenceClassification)
    (OpenLlama 模型)'
- en: '`openai-gpt` — [OpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification)
    (OpenAI GPT model)'
  id: totrans-2920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [OpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification)
    (OpenAI GPT 模型)'
- en: '`opt` — [OPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForSequenceClassification)
    (OPT model)'
  id: totrans-2921
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [OPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForSequenceClassification)
    (OPT 模型)'
- en: '`perceiver` — [PerceiverForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification)
    (Perceiver model)'
  id: totrans-2922
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perceiver` — [PerceiverForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification)
    (Perceiver 模型)'
- en: '`persimmon` — [PersimmonForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForSequenceClassification)
    (Persimmon model)'
  id: totrans-2923
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`persimmon` — [PersimmonForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/persimmon#transformers.PersimmonForSequenceClassification)
    (Persimmon 模型)'
- en: '`phi` — [PhiForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForSequenceClassification)
    (Phi model)'
  id: totrans-2924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`phi` — [PhiForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForSequenceClassification)
    (Phi 模型)'
- en: '`plbart` — [PLBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForSequenceClassification)
    (PLBart model)'
  id: totrans-2925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plbart` — [PLBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/plbart#transformers.PLBartForSequenceClassification)
    (PLBart 模型)'
- en: '`qdqbert` — [QDQBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification)
    (QDQBert model)'
  id: totrans-2926
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` — [QDQBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification)
    (QDQBert 模型)'
- en: '`qwen2` — [Qwen2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForSequenceClassification)
    (Qwen2 model)'
  id: totrans-2927
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qwen2` — [Qwen2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/qwen2#transformers.Qwen2ForSequenceClassification)
    (Qwen2 模型)'
- en: '`reformer` — [ReformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForSequenceClassification)
    (Reformer model)'
  id: totrans-2928
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reformer` — [ReformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForSequenceClassification)
    (Reformer 模型)'
- en: '`rembert` — [RemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForSequenceClassification)
    (RemBERT model)'
  id: totrans-2929
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [RemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForSequenceClassification)
    (RemBERT 模型)'
- en: '`roberta` — [RobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForSequenceClassification)
    (RoBERTa model)'
  id: totrans-2930
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForSequenceClassification)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [RobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2931
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roc_bert` — [RoCBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification)
    (RoCBert model)'
  id: totrans-2932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification)
    (RoCBert 模型)'
- en: '`roformer` — [RoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForSequenceClassification)
    (RoFormer model)'
  id: totrans-2933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [RoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForSequenceClassification)
    (RoFormer 模型)'
- en: '`squeezebert` — [SqueezeBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification)
    (SqueezeBERT model)'
  id: totrans-2934
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`squeezebert` — [SqueezeBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification)
    (SqueezeBERT 模型)'
- en: '`t5` — [T5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForSequenceClassification)
    (T5 model)'
  id: totrans-2935
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [T5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForSequenceClassification)
    (T5 模型)'
- en: '`tapas` — [TapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForSequenceClassification)
    (TAPAS model)'
  id: totrans-2936
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForSequenceClassification)
    (TAPAS 模型)'
- en: '`transfo-xl` — [TransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification)
    (Transformer-XL model)'
  id: totrans-2937
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification)
    (Transformer-XL 模型)'
- en: '`umt5` — [UMT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForSequenceClassification)
    (UMT5 model)'
  id: totrans-2938
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`umt5` — [UMT5ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForSequenceClassification)
    (UMT5 模型)'
- en: '`xlm` — [XLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForSequenceClassification)
    (XLM model)'
  id: totrans-2939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForSequenceClassification)
    (XLM 模型)'
- en: '`xlm-roberta` — [XLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  id: totrans-2940
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification)
    (XLM-RoBERTa 模型)'
- en: '`xlm-roberta-xl` — [XLMRobertaXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification)
    (XLM-RoBERTa-XL model)'
  id: totrans-2941
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification)
    (XLM-RoBERTa-XL 模型)'
- en: '`xlnet` — [XLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification)
    (XLNet model)'
  id: totrans-2942
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [XLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForSequenceClassification)
    (XLNet 模型)'
- en: '`xmod` — [XmodForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForSequenceClassification)
    (X-MOD model)'
  id: totrans-2943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XmodForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForSequenceClassification)
    (X-MOD 模型)'
- en: '`yoso` — [YosoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForSequenceClassification)
    (YOSO model)'
  id: totrans-2944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yoso` — [YosoForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForSequenceClassification)
    (YOSO 模型)'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-2945
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，该模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-2946
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE103]'
  id: totrans-2947
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: TFAutoModelForSequenceClassification
  id: totrans-2948
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForSequenceClassification
- en: '### `class transformers.TFAutoModelForSequenceClassification`'
  id: totrans-2949
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L628)'
  id: totrans-2950
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L628)'
- en: '[PRE104]'
  id: totrans-2951
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence classification head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-2952
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有序列分类头）
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-2953
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-2954
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-2955
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE105]'
  id: totrans-2956
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: Parameters
  id: totrans-2957
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-2958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 实例化的模型类基于配置类进行选择:'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForSequenceClassification)
    (ALBERT model)'
  id: totrans-2959
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    配置类: [TFAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForSequenceClassification)
    (ALBERT 模型)'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [TFBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForSequenceClassification)
    (BART model)'
  id: totrans-2960
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    配置类: [TFBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForSequenceClassification)
    (BART 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForSequenceClassification)
    (BERT model)'
  id: totrans-2961
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类: [TFBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForSequenceClassification)
    (BERT 模型)'
- en: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    configuration class: [TFCTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification)
    (CTRL model)'
  id: totrans-2962
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CTRLConfig](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.CTRLConfig)
    配置类: [TFCTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification)
    (CTRL 模型)'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification)
    (CamemBERT model)'
  id: totrans-2963
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    配置类: [TFCamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification)
    (CamemBERT 模型)'
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification)
    (ConvBERT model)'
  id: totrans-2964
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    配置类: [TFConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification)
    (ConvBERT 模型)'
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification)
    (DeBERTa model)'
  id: totrans-2965
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    配置类: [TFDebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification)
    (DeBERTa 模型)'
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification)
    (DeBERTa-v2 model)'
  id: totrans-2966
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    配置类: [TFDebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification)
    (DeBERTa-v2 模型)'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification)
    (DistilBERT model)'
  id: totrans-2967
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [TFDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification)
    (DistilBERT 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForSequenceClassification)
    (ELECTRA model)'
  id: totrans-2968
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [TFElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForSequenceClassification)
    (ELECTRA 模型)'
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [TFEsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForSequenceClassification)
    (ESM model)'
  id: totrans-2969
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    配置类: [TFEsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForSequenceClassification)
    (ESM 模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification)
    (FlauBERT model)'
  id: totrans-2970
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [TFFlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification)
    (FlauBERT 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification)
    (Funnel Transformer model)'
  id: totrans-2971
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [TFFunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification)
    (Funnel Transformer 模型)'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification)
    (OpenAI GPT-2 model)'
  id: totrans-2972
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    配置类: [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification)
    (OpenAI GPT-2 模型)'
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [TFGPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification)
    (GPT-J model)'
  id: totrans-2973
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    配置类: [TFGPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification)
    (GPT-J 模型)'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification)
    (LayoutLM model)'
  id: totrans-2974
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类: [TFLayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification)
    (LayoutLM 模型)'
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification)
    (LayoutLMv3 model)'
  id: totrans-2975
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    配置类: [TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification)
    (LayoutLMv3 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification)
    (Longformer model)'
  id: totrans-2976
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [TFLongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification)
    (Longformer 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification)
    (MPNet model)'
  id: totrans-2977
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [TFMPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification)
    (MPNet 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification)
    (MobileBERT model)'
  id: totrans-2978
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [TFMobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification)
    (MobileBERT 模型)'
- en: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    configuration class: [TFOpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification)
    (OpenAI GPT model)'
  id: totrans-2979
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAIGPTConfig](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig)
    配置类: [TFOpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification)
    (OpenAI GPT 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification)
    (RemBERT model)'
  id: totrans-2980
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [TFRemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification)
    (RemBERT 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification)
    (RoFormer model)'
  id: totrans-2981
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [TFRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification)
    (RoBERTa model)'
  id: totrans-2982
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [TFRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-2983
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [TFRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification)
    (TAPAS model)'
  id: totrans-2984
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    配置类: [TFTapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification)
    (TAPAS 模型)'
- en: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    configuration class: [TFTransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification)
    (Transformer-XL model)'
  id: totrans-2985
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TransfoXLConfig](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TransfoXLConfig)
    配置类: [TFTransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification)
    (Transformer-XL 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification)
    (XLM model)'
  id: totrans-2986
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [TFXLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  id: totrans-2987
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [TFXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification)
    (XLM-RoBERTa 模型)'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification)
    (XLNet model)'
  id: totrans-2988
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类: [TFXLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification)
    (XLNet 模型)'
- en: Instantiates one of the model classes of the library (with a sequence classification
    head) from a configuration.
  id: totrans-2989
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有序列分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-2990
  prefs: []
  type: TYPE_NORMAL
  zh: '注意: 从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。'
- en: 'Examples:'
  id: totrans-2991
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE106]'
  id: totrans-2992
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '#### `from_pretrained`'
  id: totrans-2993
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-2994
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE107]'
  id: totrans-2995
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Parameters
  id: totrans-2996
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-2997
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是:'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-2998
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型 id*，托管在huggingface.co上的模型存储库中。有效的模型 id 可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-2999
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-3000
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或URL到*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3001
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3002
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）
    — 用于模型的配置，而不是自动加载的配置。当以下情况自动加载配置时：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3003
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3004
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3005
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*） — 下载预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, defaults to `False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3009
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3011
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回包含缺少键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3014
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3015
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3016
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3017
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3018
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个键对应一个配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a sequence classification
    head) from a pretrained model.
  id: totrans-3019
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有序列分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3020
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path`
    加载，如果可能的话），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [TFAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForSequenceClassification)
    (ALBERT model)'
  id: totrans-3021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [TFAlbertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.TFAlbertForSequenceClassification)
    (ALBERT 模型)'
- en: '`bart` — [TFBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.TFBartForSequenceClassification)
    (BART model)'
  id: totrans-3022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [TFBartForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.TFBartForSequenceClassification)
    (BART 模型)'
- en: '`bert` — [TFBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForSequenceClassification)
    (BERT model)'
  id: totrans-3023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [TFBertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.TFBertForSequenceClassification)
    (BERT 模型)'
- en: '`camembert` — [TFCamembertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification)
    (CamemBERT model)'
  id: totrans-3024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [TFCamembertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.TFCamembertForSequenceClassification)
    (CamemBERT 模型)'
- en: '`convbert` — [TFConvBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification)
    (ConvBERT model)'
  id: totrans-3025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [TFConvBertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.TFConvBertForSequenceClassification)
    (ConvBERT 模型)'
- en: '`ctrl` — [TFCTRLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification)
    (CTRL model)'
  id: totrans-3026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ctrl` — [TFCTRLForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/ctrl#transformers.TFCTRLForSequenceClassification)
    (CTRL 模型)'
- en: '`deberta` — [TFDebertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification)
    (DeBERTa model)'
  id: totrans-3027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [TFDebertaForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.TFDebertaForSequenceClassification)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [TFDebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification)
    (DeBERTa-v2 model)'
  id: totrans-3028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [TFDebertaV2ForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [TFDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification)
    (DistilBERT model)'
  id: totrans-3029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [TFDistilBertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification)
    (DistilBERT 模型)'
- en: '`electra` — [TFElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForSequenceClassification)
    (ELECTRA model)'
  id: totrans-3030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [TFElectraForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/electra#transformers.TFElectraForSequenceClassification)
    (ELECTRA 模型)'
- en: '`esm` — [TFEsmForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForSequenceClassification)
    (ESM model)'
  id: totrans-3031
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [TFEsmForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/esm#transformers.TFEsmForSequenceClassification)
    (ESM 模型)'
- en: '`flaubert` — [TFFlaubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification)
    (FlauBERT model)'
  id: totrans-3032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [TFFlaubertForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification)
    (FlauBERT 模型)'
- en: '`funnel` — [TFFunnelForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification)
    (Funnel Transformer model)'
  id: totrans-3033
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [TFFunnelForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/funnel#transformers.TFFunnelForSequenceClassification)
    (漏斗变换器模型)'
- en: '`gpt-sw3` — [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification)
    (GPT-Sw3 model)'
  id: totrans-3034
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification)
    (OpenAI GPT-2 model)'
  id: totrans-3035
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [TFGPT2ForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification)
    (OpenAI GPT-2 模型)'
- en: '`gptj` — [TFGPTJForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification)
    (GPT-J model)'
  id: totrans-3036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [TFGPTJForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/gptj#transformers.TFGPTJForSequenceClassification)
    (GPT-J 模型)'
- en: '`layoutlm` — [TFLayoutLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification)
    (LayoutLM model)'
  id: totrans-3037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [TFLayoutLMForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification)
    (LayoutLM 模型)'
- en: '`layoutlmv3` — [TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification)
    (LayoutLMv3 model)'
  id: totrans-3038
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [TFLayoutLMv3ForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification)
    (LayoutLMv3 模型)'
- en: '`longformer` — [TFLongformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification)
    (Longformer model)'
  id: totrans-3039
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [TFLongformerForSequenceClassification](/docs/transformers/v4.37.2/zh/model_doc/longformer#transformers.TFLongformerForSequenceClassification)
    (Longformer 模型)'
- en: '`mobilebert` — [TFMobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification)
    (MobileBERT model)'
  id: totrans-3040
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [TFMobileBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification)
    (MobileBERT 模型)'
- en: '`mpnet` — [TFMPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification)
    (MPNet model)'
  id: totrans-3041
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [TFMPNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification)
    (MPNet 模型)'
- en: '`openai-gpt` — [TFOpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification)
    (OpenAI GPT model)'
  id: totrans-3042
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai-gpt` — [TFOpenAIGPTForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification)
    (OpenAI GPT 模型)'
- en: '`rembert` — [TFRemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification)
    (RemBERT model)'
  id: totrans-3043
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [TFRemBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification)
    (RemBERT 模型)'
- en: '`roberta` — [TFRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification)
    (RoBERTa model)'
  id: totrans-3044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [TFRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3045
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [TFRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification)
    (RoFormer model)'
  id: totrans-3046
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [TFRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification)
    (RoFormer 模型)'
- en: '`tapas` — [TFTapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification)
    (TAPAS model)'
  id: totrans-3047
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TFTapasForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForSequenceClassification)
    (TAPAS 模型)'
- en: '`transfo-xl` — [TFTransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification)
    (Transformer-XL model)'
  id: totrans-3048
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transfo-xl` — [TFTransfoXLForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification)
    (Transformer-XL 模型)'
- en: '`xlm` — [TFXLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification)
    (XLM model)'
  id: totrans-3049
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [TFXLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForSequenceClassification)
    (XLM 模型)'
- en: '`xlm-roberta` — [TFXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  id: totrans-3050
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [TFXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification)
    (XLM-RoBERTa 模型)'
- en: '`xlnet` — [TFXLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification)
    (XLNet model)'
  id: totrans-3051
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [TFXLNetForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification)
    (XLNet 模型)'
- en: 'Examples:'
  id: totrans-3052
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE108]'
  id: totrans-3053
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: FlaxAutoModelForSequenceClassification
  id: totrans-3054
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForSequenceClassification
- en: '### `class transformers.FlaxAutoModelForSequenceClassification`'
  id: totrans-3055
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L313)'
  id: totrans-3056
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L313)'
- en: '[PRE109]'
  id: totrans-3057
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence classification head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3058
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有序列分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3059
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化 (会报错)。
- en: '#### `from_config`'
  id: totrans-3060
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3061
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE110]'
  id: totrans-3062
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: Parameters
  id: totrans-3063
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3064
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification)
    (ALBERT model)'
  id: totrans-3065
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    配置类: [FlaxAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification)
    (ALBERT 模型)'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification)
    (BART model)'
  id: totrans-3066
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    配置类: [FlaxBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification)
    (BART 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification)
    (BERT model)'
  id: totrans-3067
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类: [FlaxBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification)
    (BERT 模型)'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification)
    (BigBird model)'
  id: totrans-3068
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    配置类：[FlaxBigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification)（BigBird模型）'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification)
    (DistilBERT model)'
  id: totrans-3069
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类：[FlaxDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification)（DistilBERT模型）'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification)
    (ELECTRA model)'
  id: totrans-3070
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类：[FlaxElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification)（ELECTRA模型）'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification)
    (mBART model)'
  id: totrans-3071
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类：[FlaxMBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification)（mBART模型）'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification)
    (RoFormer model)'
  id: totrans-3072
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类：[FlaxRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification)（RoFormer模型）'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification)
    (RoBERTa model)'
  id: totrans-3073
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类：[FlaxRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification)（RoBERTa模型）'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3074
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类：[FlaxRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForSequenceClassification)（RoBERTa-PreLayerNorm模型）'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  id: totrans-3075
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类：[FlaxXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification)（XLM-RoBERTa模型）'
- en: Instantiates one of the model classes of the library (with a sequence classification
    head) from a configuration.
  id: totrans-3076
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有序列分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3077
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-3078
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE111]'
  id: totrans-3079
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '#### `from_pretrained`'
  id: totrans-3080
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3081
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE112]'
  id: totrans-3082
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: Parameters
  id: totrans-3083
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3085
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库内。有效的模型ID可以位于根级，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3086
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-3087
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch state_dict保存文件*的路径或URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3088
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）-
    模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3090
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3091
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3092
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）- 下载的预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）- 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3095
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）- 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3096
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）- 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）- 要使用的代理服务器的字典，按协议或端点划分，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理将在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3098
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`）- 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`）- 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的自定义建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）- 在Hub上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（在加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载的情况而表现不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a sequence classification
    head) from a pretrained model.
  id: totrans-3106
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库的模型类之一（带有序列分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3107
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`albert` — [FlaxAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification)
    (ALBERT model)'
  id: totrans-3108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [FlaxAlbertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification)（ALBERT模型）'
- en: '`bart` — [FlaxBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification)
    (BART model)'
  id: totrans-3109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [FlaxBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForSequenceClassification)（BART模型）'
- en: '`bert` — [FlaxBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification)
    (BERT model)'
  id: totrans-3110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [FlaxBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForSequenceClassification)（BERT模型）'
- en: '`big_bird` — [FlaxBigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification)
    (BigBird model)'
  id: totrans-3111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [FlaxBigBirdForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification)（BigBird模型）'
- en: '`distilbert` — [FlaxDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification)
    (DistilBERT model)'
  id: totrans-3112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [FlaxDistilBertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification)（DistilBERT模型）'
- en: '`electra` — [FlaxElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification)
    (ELECTRA model)'
  id: totrans-3113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [FlaxElectraForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification)（ELECTRA模型）'
- en: '`mbart` — [FlaxMBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification)
    (mBART model)'
  id: totrans-3114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [FlaxMBartForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification)（mBART模型）'
- en: '`roberta` — [FlaxRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification)
    (RoBERTa model)'
  id: totrans-3115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [FlaxRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification)（RoBERTa模型）'
- en: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForSequenceClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForSequenceClassification)（RoBERTa-PreLayerNorm模型）'
- en: '`roformer` — [FlaxRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification)
    (RoFormer model)'
  id: totrans-3117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [FlaxRoFormerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification)（RoFormer模型）'
- en: '`xlm-roberta` — [FlaxXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification)
    (XLM-RoBERTa model)'
  id: totrans-3118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [FlaxXLMRobertaForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification)（XLM-RoBERTa模型）'
- en: 'Examples:'
  id: totrans-3119
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE113]'
  id: totrans-3120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: AutoModelForMultipleChoice
  id: totrans-3121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForMultipleChoice
- en: '### `class transformers.AutoModelForMultipleChoice`'
  id: totrans-3122
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForMultipleChoice`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1407)'
  id: totrans-3123
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1407)'
- en: '[PRE114]'
  id: totrans-3124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a multiple choice head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3125
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库的模型类之一（带有多选头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3126
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3127
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3128
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE115]'
  id: totrans-3129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: Parameters
  id: totrans-3130
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 要实例化的模型类是根据配置类选择的：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMultipleChoice)
    (ALBERT model)'
  id: totrans-3132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[AlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMultipleChoice)（ALBERT模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMultipleChoice)
    (BERT model)'
  id: totrans-3133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[BertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMultipleChoice)（BERT模型）'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice)
    (BigBird model)'
  id: totrans-3134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: BigBirdConfig配置类：BigBirdForMultipleChoice（BigBird模型）
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMultipleChoice)
    (CamemBERT model)'
  id: totrans-3135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: CamembertConfig配置类：CamembertForMultipleChoice（CamemBERT模型）
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForMultipleChoice)
    (CANINE model)'
  id: totrans-3136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: CanineConfig配置类：CanineForMultipleChoice（CANINE模型）
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMultipleChoice)
    (ConvBERT model)'
  id: totrans-3137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ConvBertConfig配置类：ConvBertForMultipleChoice（ConvBERT模型）
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice)
    (Data2VecText model)'
  id: totrans-3138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Data2VecTextConfig配置类：Data2VecTextForMultipleChoice（Data2VecText模型）
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice)
    (DeBERTa-v2 model)'
  id: totrans-3139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DebertaV2Config配置类：DebertaV2ForMultipleChoice（DeBERTa-v2模型）
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice)
    (DistilBERT model)'
  id: totrans-3140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DistilBertConfig配置类：DistilBertForMultipleChoice（DistilBERT模型）
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMultipleChoice)
    (ELECTRA model)'
  id: totrans-3141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ElectraConfig配置类：ElectraForMultipleChoice（ELECTRA模型）
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMultipleChoice)
    (ERNIE model)'
  id: totrans-3142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ErnieConfig配置类：ErnieForMultipleChoice（ERNIE模型）
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForMultipleChoice)
    (ErnieM model)'
  id: totrans-3143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ErnieMConfig配置类：ErnieMForMultipleChoice（ErnieM模型）
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMultipleChoice)
    (FNet model)'
  id: totrans-3144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FNetConfig配置类：FNetForMultipleChoice（FNet模型）
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice)
    (FlauBERT model)'
  id: totrans-3145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FlaubertConfig配置类：FlaubertForMultipleChoice（FlauBERT模型）
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMultipleChoice)
    (Funnel Transformer model)'
  id: totrans-3146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FunnelConfig配置类：FunnelForMultipleChoice（Funnel Transformer模型）
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMultipleChoice)
    (I-BERT model)'
  id: totrans-3147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: IBertConfig配置类：IBertForMultipleChoice（I-BERT模型）
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMultipleChoice)
    (Longformer model)'
  id: totrans-3148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LongformerConfig配置类：LongformerForMultipleChoice（Longformer模型）
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMultipleChoice)
    (LUKE model)'
  id: totrans-3149
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LukeConfig配置类：LukeForMultipleChoice（LUKE模型）
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice)
    (MPNet model)'
  id: totrans-3150
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [MPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice)
    (MPNet 模型)'
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMultipleChoice)
    (MEGA model)'
  id: totrans-3151
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    配置类: [MegaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMultipleChoice)
    (MEGA 模型)'
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice)
    (Megatron-BERT model)'
  id: totrans-3152
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    配置类: [MegatronBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice)
    (Megatron-BERT 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice)
    (MobileBERT model)'
  id: totrans-3153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [MobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice)
    (MobileBERT 模型)'
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMultipleChoice)
    (MRA model)'
  id: totrans-3154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    配置类: [MraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMultipleChoice)
    (MRA 模型)'
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMultipleChoice)
    (Nezha model)'
  id: totrans-3155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    配置类: [NezhaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMultipleChoice)
    (Nezha 模型)'
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice)
    (Nyströmformer model)'
  id: totrans-3156
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    配置类: [NystromformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice)
    (Nyströmformer 模型)'
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice)
    (QDQBert model)'
  id: totrans-3157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    配置类: [QDQBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice)
    (QDQBert 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMultipleChoice)
    (RemBERT model)'
  id: totrans-3158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [RemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMultipleChoice)
    (RemBERT 模型)'
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice)
    (RoCBert model)'
  id: totrans-3159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    配置类: [RoCBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice)
    (RoCBert 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMultipleChoice)
    (RoFormer model)'
  id: totrans-3160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [RoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMultipleChoice)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMultipleChoice)
    (RoBERTa model)'
  id: totrans-3161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [RobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMultipleChoice)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [RobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice)
    (SqueezeBERT model)'
  id: totrans-3163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    配置类: [SqueezeBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice)
    (SqueezeBERT 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForMultipleChoice)
    (XLM model)'
  id: totrans-3164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [XLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForMultipleChoice)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  id: totrans-3165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)配置类：[XLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice)（XLM-RoBERTa模型）'
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice)
    (XLM-RoBERTa-XL model)'
  id: totrans-3166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)配置类：[XLMRobertaXLForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice)（XLM-RoBERTa-XL模型）'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForMultipleChoice)
    (XLNet model)'
  id: totrans-3167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)配置类：[XLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForMultipleChoice)（XLNet模型）'
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMultipleChoice)
    (X-MOD model)'
  id: totrans-3168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)配置类：[XmodForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMultipleChoice)（X-MOD模型）'
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMultipleChoice)
    (YOSO model)'
  id: totrans-3169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)配置类：[YosoForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMultipleChoice)（YOSO模型）'
- en: Instantiates one of the model classes of the library (with a multiple choice
    head) from a configuration.
  id: totrans-3170
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库中的一个模型类（带有多选头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3171
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-3172
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE116]'
  id: totrans-3173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '#### `from_pretrained`'
  id: totrans-3174
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3175
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE117]'
  id: totrans-3176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: Parameters
  id: totrans-3177
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-3181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个路径或url到一个*tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-3187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-3188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*） — 下载预训练模型配置应缓存的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，其行为有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`中与配置属性对应的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a multiple choice
    head) from a pretrained model.
  id: totrans-3202
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有多选头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3203
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [AlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMultipleChoice)
    (ALBERT model)'
  id: totrans-3204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [AlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForMultipleChoice)
    (ALBERT 模型)'
- en: '`bert` — [BertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMultipleChoice)
    (BERT model)'
  id: totrans-3205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForMultipleChoice)
    (BERT 模型)'
- en: '`big_bird` — [BigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice)
    (BigBird model)'
  id: totrans-3206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice)
    (BigBird 模型)'
- en: '`camembert` — [CamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMultipleChoice)
    (CamemBERT model)'
  id: totrans-3207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForMultipleChoice)
    (CamemBERT 模型)'
- en: '`canine` — [CanineForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForMultipleChoice)
    (CANINE model)'
  id: totrans-3208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`canine` — [CanineForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForMultipleChoice)
    (CANINE 模型)'
- en: '`convbert` — [ConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMultipleChoice)
    (ConvBERT model)'
  id: totrans-3209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [ConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForMultipleChoice)
    (ConvBERT 模型)'
- en: '`data2vec-text` — [Data2VecTextForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice)
    (Data2VecText model)'
  id: totrans-3210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [Data2VecTextForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice)
    (Data2VecText 模型)'
- en: '`deberta-v2` — [DebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice)
    (DeBERTa-v2 model)'
  id: totrans-3211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [DebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [DistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice)
    (DistilBERT model)'
  id: totrans-3212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [DistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice)
    (DistilBERT 模型)'
- en: '`electra` — [ElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMultipleChoice)
    (ELECTRA model)'
  id: totrans-3213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForMultipleChoice)
    (ELECTRA 模型)'
- en: '`ernie` — [ErnieForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMultipleChoice)
    (ERNIE model)'
  id: totrans-3214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [ErnieForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForMultipleChoice)
    (ERNIE 模型)'
- en: '`ernie_m` — [ErnieMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForMultipleChoice)
    (ErnieM model)'
  id: totrans-3215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie_m` — [ErnieMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForMultipleChoice)
    (ErnieM 模型)'
- en: '`flaubert` — [FlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice)
    (FlauBERT model)'
  id: totrans-3216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [FlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice)
    (FlauBERT 模型)'
- en: '`fnet` — [FNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMultipleChoice)
    (FNet model)'
  id: totrans-3217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` — [FNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForMultipleChoice)
    (FNet 模型)'
- en: '`funnel` — [FunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMultipleChoice)
    (Funnel Transformer model)'
  id: totrans-3218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [FunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForMultipleChoice)
    (Funnel Transformer 模型)'
- en: '`ibert` — [IBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMultipleChoice)
    (I-BERT model)'
  id: totrans-3219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ibert` — [IBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForMultipleChoice)
    (I-BERT 模型)'
- en: '`longformer` — [LongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMultipleChoice)
    (Longformer model)'
  id: totrans-3220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [LongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForMultipleChoice)
    (Longformer 模型)'
- en: '`luke` — [LukeForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMultipleChoice)
    (LUKE model)'
  id: totrans-3221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`luke` — [LukeForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForMultipleChoice)
    (LUKE 模型)'
- en: '`mega` — [MegaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMultipleChoice)
    (MEGA model)'
  id: totrans-3222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [MegaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForMultipleChoice)
    (MEGA 模型)'
- en: '`megatron-bert` — [MegatronBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice)
    (Megatron-BERT model)'
  id: totrans-3223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [MegatronBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice)
    (Megatron-BERT 模型)'
- en: '`mobilebert` — [MobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice)
    (MobileBERT model)'
  id: totrans-3224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [MobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice)
    (MobileBERT 模型)'
- en: '`mpnet` — [MPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice)
    (MPNet model)'
  id: totrans-3225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [MPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForMultipleChoice)
    (MPNet 模型)'
- en: '`mra` — [MraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMultipleChoice)
    (MRA model)'
  id: totrans-3226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mra` — [MraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForMultipleChoice)
    (MRA 模型)'
- en: '`nezha` — [NezhaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMultipleChoice)
    (Nezha model)'
  id: totrans-3227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` — [NezhaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForMultipleChoice)
    (Nezha 模型)'
- en: '`nystromformer` — [NystromformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice)
    (Nyströmformer model)'
  id: totrans-3228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nystromformer` — [NystromformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice)
    (Nyströmformer 模型)'
- en: '`qdqbert` — [QDQBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice)
    (QDQBert model)'
  id: totrans-3229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` — [QDQBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/qdqbert#transformers.QDQBertForMultipleChoice)（QDQBert
    模型）'
- en: '`rembert` — [RemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForMultipleChoice)
    (RemBERT model)'
  id: totrans-3230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [RemBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/rembert#transformers.RemBertForMultipleChoice)（RemBERT
    模型）'
- en: '`roberta` — [RobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForMultipleChoice)
    (RoBERTa model)'
  id: totrans-3231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.RobertaForMultipleChoice)（RoBERTa
    模型）'
- en: '`roberta-prelayernorm` — [RobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForMultipleChoice)（RoBERTa-PreLayerNorm
    模型）'
- en: '`roc_bert` — [RoCBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice)
    (RoCBert model)'
  id: totrans-3233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roc_bert#transformers.RoCBertForMultipleChoice)（RoCBert
    模型）'
- en: '`roformer` — [RoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForMultipleChoice)
    (RoFormer model)'
  id: totrans-3234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [RoFormerForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roformer#transformers.RoFormerForMultipleChoice)（RoFormer
    模型）'
- en: '`squeezebert` — [SqueezeBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice)
    (SqueezeBERT model)'
  id: totrans-3235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`squeezebert` — [SqueezeBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice)（SqueezeBERT
    模型）'
- en: '`xlm` — [XLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForMultipleChoice)
    (XLM model)'
  id: totrans-3236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.XLMForMultipleChoice)（XLM
    模型）'
- en: '`xlm-roberta` — [XLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  id: totrans-3237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice)（XLM-RoBERTa
    模型）'
- en: '`xlm-roberta-xl` — [XLMRobertaXLForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice)
    (XLM-RoBERTa-XL model)'
  id: totrans-3238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaXLForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice)（XLM-RoBERTa-XL
    模型）'
- en: '`xlnet` — [XLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForMultipleChoice)
    (XLNet model)'
  id: totrans-3239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [XLNetForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.XLNetForMultipleChoice)（XLNet
    模型）'
- en: '`xmod` — [XmodForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForMultipleChoice)
    (X-MOD model)'
  id: totrans-3240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XmodForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xmod#transformers.XmodForMultipleChoice)（X-MOD
    模型）'
- en: '`yoso` — [YosoForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForMultipleChoice)
    (YOSO model)'
  id: totrans-3241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yoso` — [YosoForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/yoso#transformers.YosoForMultipleChoice)（YOSO
    模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-3242
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型处于评估模式，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-3243
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE118]'
  id: totrans-3244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: TFAutoModelForMultipleChoice
  id: totrans-3245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForMultipleChoice
- en: '### `class transformers.TFAutoModelForMultipleChoice`'
  id: totrans-3246
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForMultipleChoice`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L675)'
  id: totrans-3247
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L675)'
- en: '[PRE119]'
  id: totrans-3248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a multiple choice head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3249
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将实例化为库中的模型类之一（带有多选头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3250
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3251
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3252
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE120]'
  id: totrans-3253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: Parameters
  id: totrans-3254
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMultipleChoice)
    (ALBERT model)'
  id: totrans-3256
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig)
    配置类：[TFAlbertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.TFAlbertForMultipleChoice)（ALBERT
    模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMultipleChoice)
    (BERT model)'
  id: totrans-3257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig)
    配置类：[TFBertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.TFBertForMultipleChoice)（BERT
    模型）'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice)
    (CamemBERT model)'
  id: totrans-3258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertConfig)
    配置类：[TFCamembertForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.TFCamembertForMultipleChoice)（CamemBERT
    模型）'
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice)
    (ConvBERT model)'
  id: totrans-3259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    配置类: [TFConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice)
    (ConvBERT 模型)'
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMultipleChoice)
    (DeBERTa-v2 model)'
  id: totrans-3260
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    配置类: [TFDebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMultipleChoice)
    (DeBERTa-v2 模型)'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice)
    (DistilBERT model)'
  id: totrans-3261
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [TFDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice)
    (DistilBERT 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice)
    (ELECTRA model)'
  id: totrans-3262
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [TFElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice)
    (ELECTRA 模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice)
    (FlauBERT model)'
  id: totrans-3263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [TFFlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice)
    (FlauBERT 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice)
    (Funnel Transformer model)'
  id: totrans-3264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [TFFunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice)
    (Funnel Transformer 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice)
    (Longformer model)'
  id: totrans-3265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [TFLongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice)
    (Longformer 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice)
    (MPNet model)'
  id: totrans-3266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [TFMPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice)
    (MPNet 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice)
    (MobileBERT model)'
  id: totrans-3267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [TFMobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice)
    (MobileBERT 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice)
    (RemBERT model)'
  id: totrans-3268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [TFRemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice)
    (RemBERT 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice)
    (RoFormer model)'
  id: totrans-3269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [TFRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice)
    (RoBERTa model)'
  id: totrans-3270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [TFRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [TFRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice)
    (XLM model)'
  id: totrans-3272
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [TFXLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  id: totrans-3273
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [TFXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice)
    (XLM-RoBERTa 模型)'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice)
    (XLNet model)'
  id: totrans-3274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类：[TFXLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice)（XLNet模型）'
- en: Instantiates one of the model classes of the library (with a multiple choice
    head) from a configuration.
  id: totrans-3275
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有多选头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3276
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-3277
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE121]'
  id: totrans-3278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '#### `from_pretrained`'
  id: totrans-3279
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3280
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE122]'
  id: totrans-3281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: Parameters
  id: totrans-3282
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3284
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *model id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-3286
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch state_dict保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3289
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是由库提供的模型（使用预训练模型的 *model id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并且在目录中找到名为 *config.json* 的配置文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载预训练模型配置文件应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, 默认为 `False`) — 从PyTorch检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path`
    参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`） — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co
    上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在 Hub 上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行
    Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`） — 用于 Hub 上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3303
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设所有相关的配置更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3304
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a multiple choice
    head) from a pretrained model.
  id: totrans-3305
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有多选头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3306
  prefs: []
  type: TYPE_NORMAL
  zh: '要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退： '
- en: '`albert` — [TFAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMultipleChoice)
    (ALBERT model)'
  id: totrans-3307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [TFAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForMultipleChoice)
    (ALBERT 模型)'
- en: '`bert` — [TFBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMultipleChoice)
    (BERT model)'
  id: totrans-3308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [TFBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForMultipleChoice)
    (BERT 模型)'
- en: '`camembert` — [TFCamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice)
    (CamemBERT model)'
  id: totrans-3309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [TFCamembertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice)
    (CamemBERT 模型)'
- en: '`convbert` — [TFConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice)
    (ConvBERT model)'
  id: totrans-3310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [TFConvBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice)
    (ConvBERT 模型)'
- en: '`deberta-v2` — [TFDebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMultipleChoice)
    (DeBERTa-v2 model)'
  id: totrans-3311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [TFDebertaV2ForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMultipleChoice)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [TFDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice)
    (DistilBERT model)'
  id: totrans-3312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [TFDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice)
    (DistilBERT 模型)'
- en: '`electra` — [TFElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice)
    (ELECTRA model)'
  id: totrans-3313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [TFElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForMultipleChoice)
    (ELECTRA 模型)'
- en: '`flaubert` — [TFFlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice)
    (FlauBERT model)'
  id: totrans-3314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [TFFlaubertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice)
    (FlauBERT 模型)'
- en: '`funnel` — [TFFunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice)
    (Funnel Transformer model)'
  id: totrans-3315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [TFFunnelForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice)
    (Funnel Transformer 模型)'
- en: '`longformer` — [TFLongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice)
    (Longformer model)'
  id: totrans-3316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [TFLongformerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice)
    (Longformer 模型)'
- en: '`mobilebert` — [TFMobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice)
    (MobileBERT model)'
  id: totrans-3317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [TFMobileBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice)
    (MobileBERT 模型)'
- en: '`mpnet` — [TFMPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice)
    (MPNet model)'
  id: totrans-3318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [TFMPNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice)
    (MPNet 模型)'
- en: '`rembert` — [TFRemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice)
    (RemBERT model)'
  id: totrans-3319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [TFRemBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice)
    (RemBERT 模型)'
- en: '`roberta` — [TFRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice)
    (RoBERTa model)'
  id: totrans-3320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [TFRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [TFRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice)
    (RoFormer model)'
  id: totrans-3322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [TFRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice)
    (RoFormer 模型)'
- en: '`xlm` — [TFXLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice)
    (XLM model)'
  id: totrans-3323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [TFXLMForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForMultipleChoice)
    (XLM 模型)'
- en: '`xlm-roberta` — [TFXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  id: totrans-3324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [TFXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice)
    (XLM-RoBERTa 模型)'
- en: '`xlnet` — [TFXLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice)
    (XLNet model)'
  id: totrans-3325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [TFXLNetForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice)
    (XLNet 模型)'
- en: 'Examples:'
  id: totrans-3326
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE123]'
  id: totrans-3327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: FlaxAutoModelForMultipleChoice
  id: totrans-3328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForMultipleChoice
- en: '### `class transformers.FlaxAutoModelForMultipleChoice`'
  id: totrans-3329
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForMultipleChoice`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L338)'
  id: totrans-3330
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L338)'
- en: '[PRE124]'
  id: totrans-3331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a multiple choice head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3332
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有多选头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3333
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3334
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3335
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE125]'
  id: totrans-3336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: Parameters
  id: totrans-3337
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类:'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice)
    (ALBERT model)'
  id: totrans-3339
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    配置类: [FlaxAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice)
    (ALBERT 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice)
    (BERT model)'
  id: totrans-3340
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类: [FlaxBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice)
    (BERT 模型)'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice)
    (BigBird model)'
  id: totrans-3341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    配置类: [FlaxBigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice)
    (BigBird 模型)'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice)
    (DistilBERT model)'
  id: totrans-3342
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [FlaxDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice)
    (DistilBERT 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice)
    (ELECTRA model)'
  id: totrans-3343
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [FlaxElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice)
    (ELECTRA 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice)
    (RoFormer model)'
  id: totrans-3344
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [FlaxRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice)
    (RoBERTa model)'
  id: totrans-3345
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类：[FlaxRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice)（RoBERTa
    模型）'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3346
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类：[FlaxRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMultipleChoice)（RoBERTa-PreLayerNorm
    模型）'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  id: totrans-3347
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类：[FlaxXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice)（XLM-RoBERTa
    模型）'
- en: Instantiates one of the model classes of the library (with a multiple choice
    head) from a configuration.
  id: totrans-3348
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有多选头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3349
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-3350
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE126]'
  id: totrans-3351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '#### `from_pretrained`'
  id: totrans-3352
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3353
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE127]'
  id: totrans-3354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: Parameters
  id: totrans-3355
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str` 或 `os.PathLike`） — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3357
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3358
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-3359
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch state_dict 保存文件*的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应将配置对象作为 `config` 参数提供。使用此加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow
    模型并随后加载 TensorFlow 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）
    — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3362
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3364
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并且在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str` 或 `os.PathLike`，*可选*） — 预训练模型配置应该被缓存的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为 `False`） — 从 PyTorch 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path`
    参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为 `False`） — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为 `False`） — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为`True`，并且您已阅读了代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3376
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3377
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a multiple choice
    head) from a pretrained model.
  id: totrans-3378
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有多选头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3379
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类基于配置对象的`model_type`属性（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`albert` — [FlaxAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice)
    (ALBERT model)'
  id: totrans-3380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [FlaxAlbertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice)（ALBERT模型）'
- en: '`bert` — [FlaxBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice)
    (BERT model)'
  id: totrans-3381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [FlaxBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForMultipleChoice)（BERT模型）'
- en: '`big_bird` — [FlaxBigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice)
    (BigBird model)'
  id: totrans-3382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [FlaxBigBirdForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice)（BigBird模型）'
- en: '`distilbert` — [FlaxDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice)
    (DistilBERT model)'
  id: totrans-3383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [FlaxDistilBertForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice)（DistilBERT模型）'
- en: '`electra` — [FlaxElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice)
    (ELECTRA model)'
  id: totrans-3384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [FlaxElectraForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice)（ELECTRA模型）'
- en: '`roberta` — [FlaxRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice)
    (RoBERTa model)'
  id: totrans-3385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [FlaxRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice)（RoBERTa模型）'
- en: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMultipleChoice)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForMultipleChoice)（RoBERTa-PreLayerNorm
    模型）'
- en: '`roformer` — [FlaxRoFormerForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice)
    (RoFormer model)'
  id: totrans-3387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [FlaxRoFormerForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice)（RoFormer
    模型）'
- en: '`xlm-roberta` — [FlaxXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice)
    (XLM-RoBERTa model)'
  id: totrans-3388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [FlaxXLMRobertaForMultipleChoice](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice)（XLM-RoBERTa
    模型）'
- en: 'Examples:'
  id: totrans-3389
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE128]'
  id: totrans-3390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: AutoModelForNextSentencePrediction
  id: totrans-3391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForNextSentencePrediction
- en: '### `class transformers.AutoModelForNextSentencePrediction`'
  id: totrans-3392
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForNextSentencePrediction`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1414)'
  id: totrans-3393
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1414)'
- en: '[PRE129]'
  id: totrans-3394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a next sentence prediction head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3395
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有下一个句子预测头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3396
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3397
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3398
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE130]'
  id: totrans-3399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: Parameters
  id: totrans-3400
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)）
    — 选择要实例化的模型类基于配置类：'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForNextSentencePrediction)
    (BERT model)'
  id: totrans-3402
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig)
    配置类：[BertForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertForNextSentencePrediction)（BERT
    模型）'
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction)
    (ERNIE model)'
  id: totrans-3403
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieConfig](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieConfig)
    配置类：[ErnieForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/ernie#transformers.ErnieForNextSentencePrediction)（ERNIE
    模型）'
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForNextSentencePrediction)
    (FNet model)'
  id: totrans-3404
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FNetConfig](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetConfig)
    配置类：[FNetForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/fnet#transformers.FNetForNextSentencePrediction)（FNet
    模型）'
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction)
    (Megatron-BERT model)'
  id: totrans-3405
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegatronBertConfig](/docs/transformers/v4.37.2/zh/model_doc/megatron-bert#transformers.MegatronBertConfig)
    配置类：[MegatronBertForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction)（Megatron-BERT
    模型）'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction)
    (MobileBERT model)'
  id: totrans-3406
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类：[MobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction)（MobileBERT
    模型）'
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction)
    (Nezha model)'
  id: totrans-3407
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NezhaConfig](/docs/transformers/v4.37.2/zh/model_doc/nezha#transformers.NezhaConfig)
    配置类：[NezhaForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/nezha#transformers.NezhaForNextSentencePrediction)（Nezha
    模型）'
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction)
    (QDQBert model)'
  id: totrans-3408
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[QDQBertConfig](/docs/transformers/v4.37.2/zh/model_doc/qdqbert#transformers.QDQBertConfig)
    配置类：[QDQBertForNextSentencePrediction](/docs/transformers/v4.37.2/zh/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction)（QDQBert
    模型）'
- en: Instantiates one of the model classes of the library (with a next sentence prediction
    head) from a configuration.
  id: totrans-3409
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有下一个句子预测头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3410
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型 **不会** 加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    加载模型权重。
- en: 'Examples:'
  id: totrans-3411
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE131]'
  id: totrans-3412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: '#### `from_pretrained`'
  id: totrans-3413
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3414
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE132]'
  id: totrans-3415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: Parameters
  id: totrans-3416
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3418
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型存储库内。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3419
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如 `./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-3420
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *tensorflow 索引检查点文件* 的路径或 url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch
    模型并随后加载 PyTorch 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3423
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3424
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3425
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在该目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-3426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-3427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如 `{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理服务器将在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    id，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）- 用于Hub上代码的特定修订版，如果代码与模型的其余部分位于不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统来存储模型和其他artifacts在huggingface.co上，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3439
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3440
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用于使用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a next sentence prediction
    head) from a pretrained model.
  id: totrans-3441
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有下一个句子预测头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3442
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`bert` — [BertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForNextSentencePrediction)
    (BERT model)'
  id: totrans-3443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` - [BertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForNextSentencePrediction)（BERT模型）'
- en: '`ernie` — [ErnieForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction)
    (ERNIE model)'
  id: totrans-3444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` - [ErnieForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction)（ERNIE模型）'
- en: '`fnet` — [FNetForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForNextSentencePrediction)
    (FNet model)'
  id: totrans-3445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` - [FNetForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForNextSentencePrediction)（FNet模型）'
- en: '`megatron-bert` — [MegatronBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction)
    (Megatron-BERT model)'
  id: totrans-3446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` - [MegatronBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction)（Megatron-BERT模型）'
- en: '`mobilebert` — [MobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction)
    (MobileBERT model)'
  id: totrans-3447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` - [MobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction)（MobileBERT模型）'
- en: '`nezha` — [NezhaForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction)
    (Nezha model)'
  id: totrans-3448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` - [NezhaForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction)（Nezha模型）'
- en: '`qdqbert` — [QDQBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction)
    (QDQBert model)'
  id: totrans-3449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` - [QDQBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction)（QDQBert模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-3450
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型将设置为评估模式，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-3451
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE133]'
  id: totrans-3452
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: TFAutoModelForNextSentencePrediction
  id: totrans-3453
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForNextSentencePrediction
- en: '### `class transformers.TFAutoModelForNextSentencePrediction`'
  id: totrans-3454
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForNextSentencePrediction`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L682)'
  id: totrans-3455
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L682)'
- en: '[PRE134]'
  id: totrans-3456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a next sentence prediction head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3457
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化库的模型类之一（带有下一个句子预测头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3458
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3459
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3460
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE135]'
  id: totrans-3461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: Parameters
  id: totrans-3462
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—根据配置类选择要实例化的模型类：'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForNextSentencePrediction)
    (BERT model)'
  id: totrans-3464
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[TFBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForNextSentencePrediction)（BERT模型）'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction)
    (MobileBERT model)'
  id: totrans-3465
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)配置类：[TFMobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction)（MobileBERT模型）'
- en: Instantiates one of the model classes of the library (with a next sentence prediction
    head) from a configuration.
  id: totrans-3466
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库的模型类之一（带有下一个句子预测头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3467
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-3468
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE136]'
  id: totrans-3469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: '#### `from_pretrained`'
  id: totrans-3470
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3471
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE137]'
  id: totrans-3472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: Parameters
  id: totrans-3473
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）—可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3475
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3476
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-3477
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或URL指向*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型，然后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）—将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3480
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3481
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3482
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）—下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`) — 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3494
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3495
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则首先将`kwargs`传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a next sentence prediction
    head) from a pretrained model.
  id: totrans-3496
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库中的一个模型类（带有下一个句子预测头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3497
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的`model_type`属性（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来选择要实例化的模型类：
- en: '`bert` — [TFBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForNextSentencePrediction)
    (BERT model)'
  id: totrans-3498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [TFBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForNextSentencePrediction)（BERT模型）'
- en: '`mobilebert` — [TFMobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction)
    (MobileBERT model)'
  id: totrans-3499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [TFMobileBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction)（MobileBERT模型）'
- en: 'Examples:'
  id: totrans-3500
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE138]'
  id: totrans-3501
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: FlaxAutoModelForNextSentencePrediction
  id: totrans-3502
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForNextSentencePrediction
- en: '### `class transformers.FlaxAutoModelForNextSentencePrediction`'
  id: totrans-3503
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForNextSentencePrediction`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L345)'
  id: totrans-3504
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L345)'
- en: '[PRE139]'
  id: totrans-3505
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a next sentence prediction head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3506
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的模型类之一（带有下一个句子预测头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3507
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3508
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3509
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE140]'
  id: totrans-3510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: Parameters
  id: totrans-3511
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）-
    实例化的模型类是根据配置类选择的：'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction)
    (BERT model)'
  id: totrans-3513
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[FlaxBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction)（BERT模型）'
- en: Instantiates one of the model classes of the library (with a next sentence prediction
    head) from a configuration.
  id: totrans-3514
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有下一个句子预测头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3515
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-3516
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE141]'
  id: totrans-3517
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '#### `from_pretrained`'
  id: totrans-3518
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3519
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE142]'
  id: totrans-3520
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: Parameters
  id: totrans-3521
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3523
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3524
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-3525
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）- 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）-
    用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3528
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3529
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3530
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为*config.json*的配置JSON文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）- 如果不使用标准缓存，则应将下载的预训练模型配置缓存到的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）- 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理将在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*, 默认为 `False`) — 是否还返回包含缺少键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *可选*, 默认为 `"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3542
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了配置`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3543
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a next sentence prediction
    head) from a pretrained model.
  id: totrans-3544
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有下一个句子预测头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3545
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`bert` — [FlaxBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction)
    (BERT model)'
  id: totrans-3546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [FlaxBertForNextSentencePrediction](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction)（BERT模型）'
- en: 'Examples:'
  id: totrans-3547
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE143]'
  id: totrans-3548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: AutoModelForTokenClassification
  id: totrans-3549
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动模型用于标记分类
- en: '### `class transformers.AutoModelForTokenClassification`'
  id: totrans-3550
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForTokenClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1400)'
  id: totrans-3551
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1400)'
- en: '[PRE144]'
  id: totrans-3552
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a token classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3553
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将作为库的模型类之一实例化（带有一个标记分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3554
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3555
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3556
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE145]'
  id: totrans-3557
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: Parameters
  id: totrans-3558
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForTokenClassification)
    (ALBERT model)'
  id: totrans-3560
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    配置类：[AlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForTokenClassification)（ALBERT
    模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForTokenClassification)
    (BERT model)'
  id: totrans-3561
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类：[BertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForTokenClassification)（BERT
    模型）'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForTokenClassification)
    (BigBird model)'
  id: totrans-3562
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    配置类：[BigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForTokenClassification)（BigBird
    模型）'
- en: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    configuration class: [BioGptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForTokenClassification)
    (BioGpt model)'
  id: totrans-3563
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BioGptConfig](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptConfig)
    配置类：[BioGptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForTokenClassification)（BioGpt
    模型）'
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForTokenClassification)
    (BLOOM model)'
  id: totrans-3564
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    配置类：[BloomForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForTokenClassification)（BLOOM
    模型）'
- en: '[BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig)
    configuration class: [BrosForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosForTokenClassification)
    (BROS model)'
  id: totrans-3565
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BrosConfig](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosConfig)
    配置类：[BrosForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosForTokenClassification)（BROS
    模型）'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForTokenClassification)
    (CamemBERT model)'
  id: totrans-3566
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    配置类：[CamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForTokenClassification)（CamemBERT
    模型）'
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForTokenClassification)
    (CANINE model)'
  id: totrans-3567
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    配置类：[CanineForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForTokenClassification)（CANINE
    模型）'
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForTokenClassification)
    (ConvBERT model)'
  id: totrans-3568
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    配置类：[ConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForTokenClassification)（ConvBERT
    模型）'
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification)
    (Data2VecText model)'
  id: totrans-3569
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    配置类：[Data2VecTextForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification)（Data2VecText
    模型）'
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForTokenClassification)
    (DeBERTa model)'
  id: totrans-3570
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    配置类：[DebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForTokenClassification)（DeBERTa
    模型）'
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification)
    (DeBERTa-v2 model)'
  id: totrans-3571
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    配置类：[DebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification)（DeBERTa-v2
    模型）'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification)
    (DistilBERT model)'
  id: totrans-3572
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [DistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification)
    (DistilBERT 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForTokenClassification)
    (ELECTRA model)'
  id: totrans-3573
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [ElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForTokenClassification)
    (ELECTRA 模型)'
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForTokenClassification)
    (ERNIE model)'
  id: totrans-3574
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    配置类: [ErnieForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForTokenClassification)
    (ERNIE 模型)'
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForTokenClassification)
    (ErnieM model)'
  id: totrans-3575
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    配置类: [ErnieMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForTokenClassification)
    (ErnieM 模型)'
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [EsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForTokenClassification)
    (ESM model)'
  id: totrans-3576
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    配置类: [EsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForTokenClassification)
    (ESM 模型)'
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForTokenClassification)
    (FNet model)'
  id: totrans-3577
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    配置类: [FNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForTokenClassification)
    (FNet 模型)'
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForTokenClassification)
    (Falcon model)'
  id: totrans-3578
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    配置类: [FalconForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForTokenClassification)
    (Falcon 模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification)
    (FlauBERT model)'
  id: totrans-3579
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [FlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification)
    (FlauBERT 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForTokenClassification)
    (Funnel Transformer model)'
  id: totrans-3580
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [FunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForTokenClassification)
    (Funnel Transformer 模型)'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification)
    (OpenAI GPT-2 model)'
  id: totrans-3581
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    配置类: [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification)
    (OpenAI GPT-2 模型)'
- en: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    configuration class: [GPTBigCodeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForTokenClassification)
    (GPTBigCode model)'
  id: totrans-3582
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTBigCodeConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeConfig)
    配置类: [GPTBigCodeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForTokenClassification)
    (GPTBigCode 模型)'
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForTokenClassification)
    (GPT Neo model)'
  id: totrans-3583
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    配置类: [GPTNeoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForTokenClassification)
    (GPT Neo 模型)'
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForTokenClassification)
    (GPT NeoX model)'
  id: totrans-3584
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    配置类: [GPTNeoXForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForTokenClassification)
    (GPT NeoX 模型)'
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForTokenClassification)
    (I-BERT model)'
  id: totrans-3585
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    配置类: [IBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForTokenClassification)
    (I-BERT 模型)'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification)
    (LayoutLM model)'
  id: totrans-3586
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类: [LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification)
    (LayoutLM 模型)'
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)
    (LayoutLMv2 model)'
  id: totrans-3587
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    配置类: [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)
    (LayoutLMv2 模型)'
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)
    (LayoutLMv3 model)'
  id: totrans-3588
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    配置类: [LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)
    (LayoutLMv3 模型)'
- en: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    configuration class: [LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification)
    (LiLT model)'
  id: totrans-3589
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    配置类: [LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification)
    (LiLT 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForTokenClassification)
    (Longformer model)'
  id: totrans-3590
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [LongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForTokenClassification)
    (Longformer 模型)'
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForTokenClassification)
    (LUKE model)'
  id: totrans-3591
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    配置类: [LukeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForTokenClassification)
    (LUKE 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification)
    (MPNet model)'
  id: totrans-3592
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [MPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification)
    (MPNet 模型)'
- en: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    configuration class: [MarkupLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification)
    (MarkupLM model)'
  id: totrans-3593
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    配置类: [MarkupLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification)
    (MarkupLM 模型)'
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForTokenClassification)
    (MEGA model)'
  id: totrans-3594
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    配置类: [MegaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForTokenClassification)
    (MEGA 模型)'
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification)
    (Megatron-BERT model)'
  id: totrans-3595
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    配置类: [MegatronBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification)
    (Megatron-BERT 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification)
    (MobileBERT model)'
  id: totrans-3596
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [MobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification)
    (MobileBERT 模型)'
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForTokenClassification)
    (MPT model)'
  id: totrans-3597
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    配置类: [MptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForTokenClassification)
    (MPT 模型)'
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForTokenClassification)
    (MRA model)'
  id: totrans-3598
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    配置类: [MraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForTokenClassification)
    (MRA 模型)'
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForTokenClassification)
    (Nezha model)'
  id: totrans-3599
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    配置类: [NezhaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForTokenClassification)
    (Nezha 模型)'
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification)
    (Nyströmformer model)'
  id: totrans-3600
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    配置类: [NystromformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification)
    (Nyströmformer 模型)'
- en: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    configuration class: [PhiForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForTokenClassification)
    (Phi model)'
  id: totrans-3601
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PhiConfig](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiConfig)
    配置类: [PhiForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForTokenClassification)
    (Phi 模型)'
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification)
    (QDQBert model)'
  id: totrans-3602
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    配置类: [QDQBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification)
    (QDQBert 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForTokenClassification)
    (RemBERT model)'
  id: totrans-3603
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [RemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForTokenClassification)
    (RemBERT 模型)'
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification)
    (RoCBert model)'
  id: totrans-3604
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    配置类: [RoCBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification)
    (RoCBert 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForTokenClassification)
    (RoFormer model)'
  id: totrans-3605
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [RoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForTokenClassification)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForTokenClassification)
    (RoBERTa model)'
  id: totrans-3606
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [RobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForTokenClassification)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3607
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [RobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification)
    (SqueezeBERT model)'
  id: totrans-3608
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    配置类: [SqueezeBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification)
    (SqueezeBERT 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForTokenClassification)
    (XLM model)'
  id: totrans-3609
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [XLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForTokenClassification)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  id: totrans-3610
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [XLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification)
    (XLM-RoBERTa 模型)'
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification)
    (XLM-RoBERTa-XL model)'
  id: totrans-3611
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    配置类: [XLMRobertaXLForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification)
    (XLM-RoBERTa-XL 模型)'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForTokenClassification)
    (XLNet model)'
  id: totrans-3612
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类: [XLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForTokenClassification)
    (XLNet 模型)'
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForTokenClassification)
    (X-MOD model)'
  id: totrans-3613
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    配置类: [XmodForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForTokenClassification)
    (X-MOD 模型)'
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForTokenClassification)
    (YOSO model)'
  id: totrans-3614
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    配置类: [YosoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForTokenClassification)
    (YOSO 模型)'
- en: Instantiates one of the model classes of the library (with a token classification
    head) from a configuration.
  id: totrans-3615
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有标记分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3616
  prefs: []
  type: TYPE_NORMAL
  zh: '注意: 从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。'
- en: 'Examples:'
  id: totrans-3617
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE146]'
  id: totrans-3618
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '#### `from_pretrained`'
  id: totrans-3619
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3620
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE147]'
  id: totrans-3621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: Parameters
  id: totrans-3622
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3624
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3625
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-3626
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或URL指向*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*） — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3629
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3630
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3631
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-3632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-3633
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, defaults to `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 要使用的代理服务器字典，按协议或端点划分，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为 `False`） — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为 `"main"`） — 用于 Hub 上代码的特定修订版，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了
    `config` 或自动加载了 `config`，其行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3645
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3646
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则首先将 `kwargs` 传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个键对应于配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a token classification
    head) from a pretrained model.
  id: totrans-3647
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库中的一个模型类（带有标记分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3648
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（可以作为参数传递，也可以从 `pretrained_model_name_or_path`
    中加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [AlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForTokenClassification)
    (ALBERT model)'
  id: totrans-3649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [AlbertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertForTokenClassification)
    (ALBERT 模型)'
- en: '`bert` — [BertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForTokenClassification)
    (BERT model)'
  id: totrans-3650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertForTokenClassification)
    (BERT 模型)'
- en: '`big_bird` — [BigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForTokenClassification)
    (BigBird model)'
  id: totrans-3651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdForTokenClassification)
    (BigBird 模型)'
- en: '`biogpt` — [BioGptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/biogpt#transformers.BioGptForTokenClassification)
    (BioGpt model)'
  id: totrans-3652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`biogpt` — [BioGptForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/biogpt#transformers.BioGptForTokenClassification)
    (BioGpt 模型)'
- en: '`bloom` — [BloomForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForTokenClassification)
    (BLOOM model)'
  id: totrans-3653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [BloomForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/bloom#transformers.BloomForTokenClassification)
    (BLOOM 模型)'
- en: '`bros` — [BrosForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bros#transformers.BrosForTokenClassification)
    (BROS model)'
  id: totrans-3654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bros` — [BrosForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/bros#transformers.BrosForTokenClassification)
    (BROS 模型)'
- en: '`camembert` — [CamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForTokenClassification)
    (CamemBERT model)'
  id: totrans-3655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/camembert#transformers.CamembertForTokenClassification)
    (CamemBERT 模型)'
- en: '`canine` — [CanineForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForTokenClassification)
    (CANINE model)'
  id: totrans-3656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`canine` — [CanineForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/canine#transformers.CanineForTokenClassification)
    (CANINE 模型)'
- en: '`convbert` — [ConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForTokenClassification)
    (ConvBERT model)'
  id: totrans-3657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [ConvBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/convbert#transformers.ConvBertForTokenClassification)
    (ConvBERT 模型)'
- en: '`data2vec-text` — [Data2VecTextForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification)
    (Data2VecText model)'
  id: totrans-3658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [Data2VecTextForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/data2vec#transformers.Data2VecTextForTokenClassification)
    (Data2VecText 模型)'
- en: '`deberta` — [DebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForTokenClassification)
    (DeBERTa model)'
  id: totrans-3659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [DebertaForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/deberta#transformers.DebertaForTokenClassification)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [DebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification)
    (DeBERTa-v2 model)'
  id: totrans-3660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [DebertaV2ForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [DistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification)
    (DistilBERT model)'
  id: totrans-3661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [DistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForTokenClassification)
    (DistilBERT 模型)'
- en: '`electra` — [ElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForTokenClassification)
    (ELECTRA model)'
  id: totrans-3662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForTokenClassification)
    (ELECTRA 模型)'
- en: '`ernie` — [ErnieForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForTokenClassification)
    (ERNIE model)'
  id: totrans-3663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [ErnieForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForTokenClassification)
    (ERNIE 模型)'
- en: '`ernie_m` — [ErnieMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForTokenClassification)
    (ErnieM model)'
  id: totrans-3664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie_m` — [ErnieMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForTokenClassification)
    (ErnieM 模型)'
- en: '`esm` — [EsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForTokenClassification)
    (ESM model)'
  id: totrans-3665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [EsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmForTokenClassification)
    (ESM 模型)'
- en: '`falcon` — [FalconForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForTokenClassification)
    (Falcon model)'
  id: totrans-3666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`falcon` — [FalconForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForTokenClassification)
    (Falcon 模型)'
- en: '`flaubert` — [FlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification)
    (FlauBERT model)'
  id: totrans-3667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [FlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForTokenClassification)
    (FlauBERT 模型)'
- en: '`fnet` — [FNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForTokenClassification)
    (FNet model)'
  id: totrans-3668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` — [FNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForTokenClassification)
    (FNet 模型)'
- en: '`funnel` — [FunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForTokenClassification)
    (Funnel Transformer model)'
  id: totrans-3669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [FunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForTokenClassification)
    (Funnel Transformer 模型)'
- en: '`gpt-sw3` — [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification)
    (GPT-Sw3 model)'
  id: totrans-3670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt-sw3` — [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification)
    (GPT-Sw3 模型)'
- en: '`gpt2` — [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification)
    (OpenAI GPT-2 model)'
  id: totrans-3671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [GPT2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForTokenClassification)
    (OpenAI GPT-2 模型)'
- en: '`gpt_bigcode` — [GPTBigCodeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForTokenClassification)
    (GPTBigCode model)'
  id: totrans-3672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_bigcode` — [GPTBigCodeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_bigcode#transformers.GPTBigCodeForTokenClassification)
    (GPTBigCode 模型)'
- en: '`gpt_neo` — [GPTNeoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForTokenClassification)
    (GPT Neo model)'
  id: totrans-3673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neo` — [GPTNeoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForTokenClassification)
    (GPT Neo 模型)'
- en: '`gpt_neox` — [GPTNeoXForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForTokenClassification)
    (GPT NeoX model)'
  id: totrans-3674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox` — [GPTNeoXForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForTokenClassification)
    (GPT NeoX 模型)'
- en: '`ibert` — [IBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForTokenClassification)
    (I-BERT model)'
  id: totrans-3675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ibert` — [IBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForTokenClassification)
    (I-BERT 模型)'
- en: '`layoutlm` — [LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification)
    (LayoutLM model)'
  id: totrans-3676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [LayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification)
    (LayoutLM 模型)'
- en: '`layoutlmv2` — [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)
    (LayoutLMv2 model)'
  id: totrans-3677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification)
    (LayoutLMv2 模型)'
- en: '`layoutlmv3` — [LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)
    (LayoutLMv3 model)'
  id: totrans-3678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification)
    (LayoutLMv3 模型)'
- en: '`lilt` — [LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification)
    (LiLT model)'
  id: totrans-3679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lilt` — [LiltForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForTokenClassification)
    (LiLT 模型)'
- en: '`longformer` — [LongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForTokenClassification)
    (Longformer model)'
  id: totrans-3680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [LongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForTokenClassification)
    (Longformer 模型)'
- en: '`luke` — [LukeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForTokenClassification)
    (LUKE model)'
  id: totrans-3681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`luke` — [LukeForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForTokenClassification)
    (LUKE 模型)'
- en: '`markuplm` — [MarkupLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification)
    (MarkupLM model)'
  id: totrans-3682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`markuplm` — [MarkupLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification)
    (MarkupLM 模型)'
- en: '`mega` — [MegaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForTokenClassification)
    (MEGA model)'
  id: totrans-3683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [MegaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForTokenClassification)
    (MEGA 模型)'
- en: '`megatron-bert` — [MegatronBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification)
    (Megatron-BERT model)'
  id: totrans-3684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [MegatronBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification)
    (Megatron-BERT 模型)'
- en: '`mobilebert` — [MobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification)
    (MobileBERT model)'
  id: totrans-3685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [MobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification)
    (MobileBERT 模型)'
- en: '`mpnet` — [MPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification)
    (MPNet model)'
  id: totrans-3686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [MPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForTokenClassification)
    (MPNet 模型)'
- en: '`mpt` — [MptForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForTokenClassification)
    (MPT model)'
  id: totrans-3687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpt` — [MptForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/mpt#transformers.MptForTokenClassification)
    (MPT 模型)'
- en: '`mra` — [MraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForTokenClassification)
    (MRA model)'
  id: totrans-3688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mra` — [MraForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/mra#transformers.MraForTokenClassification)
    (MRA 模型)'
- en: '`nezha` — [NezhaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForTokenClassification)
    (Nezha model)'
  id: totrans-3689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` — [NezhaForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/nezha#transformers.NezhaForTokenClassification)
    (Nezha 模型)'
- en: '`nystromformer` — [NystromformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification)
    (Nyströmformer model)'
  id: totrans-3690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nystromformer` — [NystromformerForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/nystromformer#transformers.NystromformerForTokenClassification)
    (Nyströmformer 模型)'
- en: '`phi` — [PhiForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/phi#transformers.PhiForTokenClassification)
    (Phi model)'
  id: totrans-3691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`phi` — [PhiForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/phi#transformers.PhiForTokenClassification)
    (Phi 模型)'
- en: '`qdqbert` — [QDQBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification)
    (QDQBert model)'
  id: totrans-3692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` — [QDQBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/qdqbert#transformers.QDQBertForTokenClassification)
    (QDQBert 模型)'
- en: '`rembert` — [RemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForTokenClassification)
    (RemBERT model)'
  id: totrans-3693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [RemBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/rembert#transformers.RemBertForTokenClassification)
    (RemBERT 模型)'
- en: '`roberta` — [RobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForTokenClassification)
    (RoBERTa model)'
  id: totrans-3694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.RobertaForTokenClassification)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [RobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roc_bert` — [RoCBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification)
    (RoCBert model)'
  id: totrans-3696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/roc_bert#transformers.RoCBertForTokenClassification)
    (RoCBert 模型)'
- en: '`roformer` — [RoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForTokenClassification)
    (RoFormer model)'
  id: totrans-3697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [RoFormerForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/roformer#transformers.RoFormerForTokenClassification)
    (RoFormer 模型)'
- en: '`squeezebert` — [SqueezeBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification)
    (SqueezeBERT model)'
  id: totrans-3698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`squeezebert` — [SqueezeBertForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification)
    (SqueezeBERT 模型)'
- en: '`xlm` — [XLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForTokenClassification)
    (XLM model)'
  id: totrans-3699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.XLMForTokenClassification)
    (XLM 模型)'
- en: '`xlm-roberta` — [XLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  id: totrans-3700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification)
    (XLM-RoBERTa 模型)'
- en: '`xlm-roberta-xl` — [XLMRobertaXLForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification)
    (XLM-RoBERTa-XL model)'
  id: totrans-3701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaXLForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification)
    (XLM-RoBERTa-XL 模型)'
- en: '`xlnet` — [XLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForTokenClassification)
    (XLNet model)'
  id: totrans-3702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [XLNetForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.XLNetForTokenClassification)
    (XLNet 模型)'
- en: '`xmod` — [XmodForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForTokenClassification)
    (X-MOD model)'
  id: totrans-3703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XmodForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/xmod#transformers.XmodForTokenClassification)
    (X-MOD 模型)'
- en: '`yoso` — [YosoForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForTokenClassification)
    (YOSO model)'
  id: totrans-3704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yoso` — [YosoForTokenClassification](/docs/transformers/v4.37.2/zh/model_doc/yoso#transformers.YosoForTokenClassification)
    (YOSO 模型)'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-3705
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-3706
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE148]'
  id: totrans-3707
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: TFAutoModelForTokenClassification
  id: totrans-3708
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForTokenClassification
- en: '### `class transformers.TFAutoModelForTokenClassification`'
  id: totrans-3709
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForTokenClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L666)'
  id: totrans-3710
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L666)'
- en: '[PRE149]'
  id: totrans-3711
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a token classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3712
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将实例化为库中的一个模型类（带有标记分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3713
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3714
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3715
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE150]'
  id: totrans-3716
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: Parameters
  id: totrans-3717
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（PretrainedConfig）-根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForTokenClassification)
    (ALBERT model)'
  id: totrans-3719
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: AlbertConfig配置类：TFAlbertForTokenClassification（ALBERT模型）
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForTokenClassification)
    (BERT model)'
  id: totrans-3720
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: BertConfig配置类：TFBertForTokenClassification（BERT模型）
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForTokenClassification)
    (CamemBERT model)'
  id: totrans-3721
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: CamembertConfig配置类：TFCamembertForTokenClassification（CamemBERT模型）
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForTokenClassification)
    (ConvBERT model)'
  id: totrans-3722
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ConvBertConfig配置类：TFConvBertForTokenClassification（ConvBERT模型）
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForTokenClassification)
    (DeBERTa model)'
  id: totrans-3723
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DebertaConfig配置类：TFDebertaForTokenClassification（DeBERTa模型）
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification)
    (DeBERTa-v2 model)'
  id: totrans-3724
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DebertaV2Config配置类：TFDebertaV2ForTokenClassification（DeBERTa-v2模型）
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification)
    (DistilBERT model)'
  id: totrans-3725
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DistilBertConfig配置类：TFDistilBertForTokenClassification（DistilBERT模型）
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForTokenClassification)
    (ELECTRA model)'
  id: totrans-3726
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ElectraConfig配置类：TFElectraForTokenClassification（ELECTRA模型）
- en: '[EsmConfig](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.EsmConfig)
    configuration class: [TFEsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForTokenClassification)
    (ESM model)'
  id: totrans-3727
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: EsmConfig配置类：TFEsmForTokenClassification（ESM模型）
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification)
    (FlauBERT model)'
  id: totrans-3728
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FlaubertConfig配置类：TFFlaubertForTokenClassification（FlauBERT模型）
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForTokenClassification)
    (Funnel Transformer model)'
  id: totrans-3729
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FunnelConfig配置类：TFFunnelForTokenClassification（漏斗变压器模型）
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification)
    (LayoutLM model)'
  id: totrans-3730
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LayoutLMConfig配置类：TFLayoutLMForTokenClassification（LayoutLM模型）
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification)
    (LayoutLMv3 model)'
  id: totrans-3731
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LayoutLMv3Config配置类：TFLayoutLMv3ForTokenClassification（LayoutLMv3模型）
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForTokenClassification)
    (Longformer model)'
  id: totrans-3732
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LongformerConfig配置类：TFLongformerForTokenClassification（Longformer模型）
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification)
    (MPNet model)'
  id: totrans-3733
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类：[TFMPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification)（MPNet
    模型）'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification)
    (MobileBERT model)'
  id: totrans-3734
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类：[TFMobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification)（MobileBERT
    模型）'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification)
    (RemBERT model)'
  id: totrans-3735
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类：[TFRemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification)（RemBERT
    模型）'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification)
    (RoFormer model)'
  id: totrans-3736
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类：[TFRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification)（RoFormer
    模型）'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification)
    (RoBERTa model)'
  id: totrans-3737
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类：[TFRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification)（RoBERTa
    模型）'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3738
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类：[TFRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForTokenClassification)（RoBERTa-PreLayerNorm
    模型）'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification)
    (XLM model)'
  id: totrans-3739
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类：[TFXLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification)（XLM
    模型）'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  id: totrans-3740
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类：[TFXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification)（XLM-RoBERTa
    模型）'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification)
    (XLNet model)'
  id: totrans-3741
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类：[TFXLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification)（XLNet
    模型）'
- en: Instantiates one of the model classes of the library (with a token classification
    head) from a configuration.
  id: totrans-3742
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有一个标记分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3743
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-3744
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE151]'
  id: totrans-3745
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '#### `from_pretrained`'
  id: totrans-3746
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3747
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE152]'
  id: totrans-3748
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: Parameters
  id: totrans-3749
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str` 或 `os.PathLike`）- 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3751
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，指定在 huggingface.co 上托管的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下进行命名空间划分，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3752
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如 `./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-3753
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *PyTorch state_dict save file* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应提供配置对象作为 `config` 参数。使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow 模型并加载
    TensorFlow 模型的加载路径比直接加载 PyTorch 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）- 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 用于模型的配置，而不是自动加载的配置。当以下情况自动加载配置时：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3756
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3757
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3758
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并且目录中找到名为 *config.json* 的配置
    JSON 文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 应在其中缓存下载的预训练模型配置的目录路径，如果不应使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读了代码，因为它将在本地计算机上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（其他关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了
    `config` 或自动加载：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3770
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了配置与 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3771
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a token classification
    head) from a pretrained model.
  id: totrans-3772
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有标记分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3773
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path`
    加载，如果可能的话），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [TFAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForTokenClassification)
    (ALBERT model)'
  id: totrans-3774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [TFAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForTokenClassification)
    (ALBERT 模型)'
- en: '`bert` — [TFBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForTokenClassification)
    (BERT model)'
  id: totrans-3775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [TFBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForTokenClassification)
    (BERT 模型)'
- en: '`camembert` — [TFCamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForTokenClassification)
    (CamemBERT model)'
  id: totrans-3776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [TFCamembertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForTokenClassification)
    (CamemBERT 模型)'
- en: '`convbert` — [TFConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForTokenClassification)
    (ConvBERT model)'
  id: totrans-3777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [TFConvBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForTokenClassification)
    (ConvBERT 模型)'
- en: '`deberta` — [TFDebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForTokenClassification)
    (DeBERTa model)'
  id: totrans-3778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [TFDebertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForTokenClassification)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [TFDebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification)
    (DeBERTa-v2 model)'
  id: totrans-3779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [TFDebertaV2ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [TFDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification)
    (DistilBERT model)'
  id: totrans-3780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [TFDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification)
    (DistilBERT 模型)'
- en: '`electra` — [TFElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForTokenClassification)
    (ELECTRA model)'
  id: totrans-3781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [TFElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForTokenClassification)
    (ELECTRA 模型)'
- en: '`esm` — [TFEsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForTokenClassification)
    (ESM model)'
  id: totrans-3782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esm` — [TFEsmForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/esm#transformers.TFEsmForTokenClassification)
    (ESM 模型)'
- en: '`flaubert` — [TFFlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification)
    (FlauBERT model)'
  id: totrans-3783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [TFFlaubertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification)
    (FlauBERT 模型)'
- en: '`funnel` — [TFFunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForTokenClassification)
    (Funnel Transformer model)'
  id: totrans-3784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [TFFunnelForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForTokenClassification)
    (Funnel Transformer 模型)'
- en: '`layoutlm` — [TFLayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification)
    (LayoutLM model)'
  id: totrans-3785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [TFLayoutLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification)
    (LayoutLM 模型)'
- en: '`layoutlmv3` — [TFLayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification)
    (LayoutLMv3 model)'
  id: totrans-3786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [TFLayoutLMv3ForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification)
    (LayoutLMv3 模型)'
- en: '`longformer` — [TFLongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForTokenClassification)
    (Longformer model)'
  id: totrans-3787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [TFLongformerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForTokenClassification)
    (Longformer 模型)'
- en: '`mobilebert` — [TFMobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification)
    (MobileBERT model)'
  id: totrans-3788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [TFMobileBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification)
    (MobileBERT 模型)'
- en: '`mpnet` — [TFMPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification)
    (MPNet model)'
  id: totrans-3789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [TFMPNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification)
    (MPNet 模型)'
- en: '`rembert` — [TFRemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification)
    (RemBERT model)'
  id: totrans-3790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [TFRemBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForTokenClassification)
    (RemBERT 模型)'
- en: '`roberta` — [TFRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification)
    (RoBERTa model)'
  id: totrans-3791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [TFRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForTokenClassification)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [TFRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification)
    (RoFormer model)'
  id: totrans-3793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [TFRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification)
    (RoFormer 模型)'
- en: '`xlm` — [TFXLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification)
    (XLM model)'
  id: totrans-3794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [TFXLMForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForTokenClassification)
    (XLM 模型)'
- en: '`xlm-roberta` — [TFXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  id: totrans-3795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [TFXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification)
    (XLM-RoBERTa 模型)'
- en: '`xlnet` — [TFXLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification)
    (XLNet model)'
  id: totrans-3796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet`—[TFXLNetForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification)（XLNet模型）'
- en: 'Examples:'
  id: totrans-3797
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE153]'
  id: totrans-3798
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: FlaxAutoModelForTokenClassification
  id: totrans-3799
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForTokenClassification
- en: '### `class transformers.FlaxAutoModelForTokenClassification`'
  id: totrans-3800
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForTokenClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L329)'
  id: totrans-3801
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L329)'
- en: '[PRE154]'
  id: totrans-3802
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a token classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3803
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有标记分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3804
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3805
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3806
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE155]'
  id: totrans-3807
  prefs: []
  type: TYPE_PRE
  zh: '[PRE155]'
- en: Parameters
  id: totrans-3808
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification)
    (ALBERT model)'
  id: totrans-3810
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)配置类：[FlaxAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification)（ALBERT模型）'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification)
    (BERT model)'
  id: totrans-3811
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)配置类：[FlaxBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification)（BERT模型）'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification)
    (BigBird model)'
  id: totrans-3812
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)配置类：[FlaxBigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification)（BigBird模型）'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification)
    (DistilBERT model)'
  id: totrans-3813
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)配置类：[FlaxDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification)（DistilBERT模型）'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification)
    (ELECTRA model)'
  id: totrans-3814
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)配置类：[FlaxElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification)（ELECTRA模型）'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification)
    (RoFormer model)'
  id: totrans-3815
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)配置类：[FlaxRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification)（RoFormer模型）'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification)
    (RoBERTa model)'
  id: totrans-3816
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)配置类：[FlaxRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification)（RoBERTa模型）'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3817
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)配置类：[FlaxRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForTokenClassification)（RoBERTa-PreLayerNorm模型）'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  id: totrans-3818
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)配置类：[FlaxXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification)（XLM-RoBERTa模型）'
- en: Instantiates one of the model classes of the library (with a token classification
    head) from a configuration.
  id: totrans-3819
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有标记分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3820
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-3821
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE156]'
  id: totrans-3822
  prefs: []
  type: TYPE_PRE
  zh: '[PRE156]'
- en: '#### `from_pretrained`'
  id: totrans-3823
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3824
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE157]'
  id: totrans-3825
  prefs: []
  type: TYPE_PRE
  zh: '[PRE157]'
- en: Parameters
  id: totrans-3826
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3828
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型ID*，托管在huggingface.co的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3829
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-3830
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个路径或URL指向一个*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应该设置为`True`，并且应该提供一个配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并在之后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    用于替代自动加载配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3833
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3834
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3835
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 下载预训练模型配置的目录路径，如果不使用标准缓存，则应该缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3840
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的模型文件。此选项应仅在您信任的存储库中设置为
    `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3846
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，其行为有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3847
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3848
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则 `kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a token classification
    head) from a pretrained model.
  id: totrans-3849
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库的一个模型类（带有标记分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3850
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载）选择的，或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [FlaxAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification)
    (ALBERT model)'
  id: totrans-3851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [FlaxAlbertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification)
    (ALBERT 模型)'
- en: '`bert` — [FlaxBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification)
    (BERT model)'
  id: totrans-3852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [FlaxBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForTokenClassification)
    (BERT 模型)'
- en: '`big_bird` — [FlaxBigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification)
    (BigBird model)'
  id: totrans-3853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [FlaxBigBirdForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification)
    (BigBird 模型)'
- en: '`distilbert` — [FlaxDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification)
    (DistilBERT model)'
  id: totrans-3854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [FlaxDistilBertForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification)
    (DistilBERT 模型)'
- en: '`electra` — [FlaxElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification)
    (ELECTRA model)'
  id: totrans-3855
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [FlaxElectraForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForTokenClassification)
    (ELECTRA 模型)'
- en: '`roberta` — [FlaxRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification)
    (RoBERTa model)'
  id: totrans-3856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [FlaxRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForTokenClassification)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [FlaxRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification)
    (RoFormer model)'
  id: totrans-3858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [FlaxRoFormerForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification)
    (RoFormer 模型)'
- en: '`xlm-roberta` — [FlaxXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification)
    (XLM-RoBERTa model)'
  id: totrans-3859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [FlaxXLMRobertaForTokenClassification](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification)
    (XLM-RoBERTa 模型)'
- en: 'Examples:'
  id: totrans-3860
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE158]'
  id: totrans-3861
  prefs: []
  type: TYPE_PRE
  zh: '[PRE158]'
- en: AutoModelForQuestionAnswering
  id: totrans-3862
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForQuestionAnswering
- en: '### `class transformers.AutoModelForQuestionAnswering`'
  id: totrans-3863
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1360)'
  id: totrans-3864
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1360)'
- en: '[PRE159]'
  id: totrans-3865
  prefs: []
  type: TYPE_PRE
  zh: '[PRE159]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a question answering head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-3866
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用from_pretrained()类方法或from_config()类方法创建时，将作为库的模型类之一实例化（带有问答头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-3867
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-3868
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-3869
  prefs: []
  type: TYPE_NORMAL
  zh: <来源>
- en: '[PRE160]'
  id: totrans-3870
  prefs: []
  type: TYPE_PRE
  zh: '[PRE160]'
- en: Parameters
  id: totrans-3871
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-3872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（PretrainedConfig）- 根据配置类选择要实例化的模型类：'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [AlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForQuestionAnswering)
    (ALBERT model)'
  id: totrans-3873
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: AlbertConfig配置类：AlbertForQuestionAnswering（ALBERT模型）
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [BartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForQuestionAnswering)
    (BART model)'
  id: totrans-3874
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: BartConfig配置类：BartForQuestionAnswering（BART模型）
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [BertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForQuestionAnswering)
    (BERT model)'
  id: totrans-3875
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: BertConfig配置类：BertForQuestionAnswering（BERT模型）
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [BigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering)
    (BigBird model)'
  id: totrans-3876
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: BigBirdConfig配置类：BigBirdForQuestionAnswering（BigBird模型）
- en: '[BigBirdPegasusConfig](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig)
    configuration class: [BigBirdPegasusForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering)
    (BigBird-Pegasus model)'
  id: totrans-3877
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: BigBirdPegasusConfig配置类：BigBirdPegasusForQuestionAnswering（BigBird-Pegasus模型）
- en: '[BloomConfig](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomConfig)
    configuration class: [BloomForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForQuestionAnswering)
    (BLOOM model)'
  id: totrans-3878
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: BloomConfig配置类：BloomForQuestionAnswering（BLOOM模型）
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [CamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForQuestionAnswering)
    (CamemBERT model)'
  id: totrans-3879
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: CamembertConfig配置类：CamembertForQuestionAnswering（CamemBERT模型）
- en: '[CanineConfig](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineConfig)
    configuration class: [CanineForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForQuestionAnswering)
    (CANINE model)'
  id: totrans-3880
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: CanineConfig配置类：CanineForQuestionAnswering（CANINE模型）
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [ConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering)
    (ConvBERT model)'
  id: totrans-3881
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ConvBertConfig配置类：ConvBertForQuestionAnswering（ConvBERT模型）
- en: '[Data2VecTextConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextConfig)
    configuration class: [Data2VecTextForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering)
    (Data2VecText model)'
  id: totrans-3882
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Data2VecTextConfig配置类：Data2VecTextForQuestionAnswering（Data2VecText模型）
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [DebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForQuestionAnswering)
    (DeBERTa model)'
  id: totrans-3883
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DebertaConfig配置类：DebertaForQuestionAnswering（DeBERTa模型）
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [DebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering)
    (DeBERTa-v2 model)'
  id: totrans-3884
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DebertaV2Config配置类：DebertaV2ForQuestionAnswering（DeBERTa-v2模型）
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [DistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering)
    (DistilBERT model)'
  id: totrans-3885
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [DistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering)
    (DistilBERT 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [ElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering)
    (ELECTRA model)'
  id: totrans-3886
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [ElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering)
    (ELECTRA 模型)'
- en: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    configuration class: [ErnieForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForQuestionAnswering)
    (ERNIE model)'
  id: totrans-3887
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieConfig](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieConfig)
    配置类: [ErnieForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForQuestionAnswering)
    (ERNIE 模型)'
- en: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    configuration class: [ErnieMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForQuestionAnswering)
    (ErnieM model)'
  id: totrans-3888
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ErnieMConfig](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMConfig)
    配置类: [ErnieMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForQuestionAnswering)
    (ErnieM 模型)'
- en: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    configuration class: [FNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering)
    (FNet model)'
  id: totrans-3889
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FNetConfig](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetConfig)
    配置类: [FNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering)
    (FNet 模型)'
- en: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    configuration class: [FalconForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForQuestionAnswering)
    (Falcon model)'
  id: totrans-3890
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FalconConfig](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconConfig)
    配置类: [FalconForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForQuestionAnswering)
    (Falcon 模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [FlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple)
    (FlauBERT model)'
  id: totrans-3891
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [FlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple)
    (FlauBERT 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [FunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering)
    (Funnel Transformer model)'
  id: totrans-3892
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [FunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering)
    (Funnel Transformer 模型)'
- en: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    configuration class: [GPT2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForQuestionAnswering)
    (OpenAI GPT-2 model)'
  id: totrans-3893
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT2Config](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2Config)
    配置类: [GPT2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForQuestionAnswering)
    (OpenAI GPT-2 模型)'
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [GPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering)
    (GPT-J model)'
  id: totrans-3894
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    配置类: [GPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering)
    (GPT-J 模型)'
- en: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    configuration class: [GPTNeoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForQuestionAnswering)
    (GPT Neo model)'
  id: totrans-3895
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoConfig)
    配置类: [GPTNeoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForQuestionAnswering)
    (GPT Neo 模型)'
- en: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    configuration class: [GPTNeoXForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForQuestionAnswering)
    (GPT NeoX model)'
  id: totrans-3896
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTNeoXConfig](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXConfig)
    配置类: [GPTNeoXForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForQuestionAnswering)
    (GPT NeoX 模型)'
- en: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    configuration class: [IBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering)
    (I-BERT model)'
  id: totrans-3897
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IBertConfig](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertConfig)
    配置类: [IBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering)
    (I-BERT 模型)'
- en: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    configuration class: [LEDForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForQuestionAnswering)
    (LED model)'
  id: totrans-3898
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LEDConfig](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDConfig)
    配置类: [LEDForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForQuestionAnswering)
    (LED 模型)'
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 model)'
  id: totrans-3899
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    配置类: [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 模型)'
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  id: totrans-3900
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    配置类: [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 模型)'
- en: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    configuration class: [LiltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForQuestionAnswering)
    (LiLT model)'
  id: totrans-3901
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LiltConfig](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltConfig)
    配置类: [LiltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForQuestionAnswering)
    (LiLT 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [LongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering)
    (Longformer model)'
  id: totrans-3902
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [LongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering)
    (Longformer 模型)'
- en: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    configuration class: [LukeForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForQuestionAnswering)
    (LUKE model)'
  id: totrans-3903
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LukeConfig](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeConfig)
    配置类: [LukeForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForQuestionAnswering)
    (LUKE 模型)'
- en: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    configuration class: [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering)
    (LXMERT model)'
  id: totrans-3904
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LxmertConfig](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertConfig)
    配置类: [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering)
    (LXMERT 模型)'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [MBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering)
    (mBART model)'
  id: totrans-3905
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类: [MBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering)
    (mBART 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [MPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering)
    (MPNet model)'
  id: totrans-3906
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [MPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering)
    (MPNet 模型)'
- en: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    configuration class: [MT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForQuestionAnswering)
    (MT5 model)'
  id: totrans-3907
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MT5Config](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5Config)
    配置类: [MT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForQuestionAnswering)
    (MT5 模型)'
- en: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    configuration class: [MarkupLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering)
    (MarkupLM model)'
  id: totrans-3908
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarkupLMConfig](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMConfig)
    配置类: [MarkupLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering)
    (MarkupLM 模型)'
- en: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    configuration class: [MegaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForQuestionAnswering)
    (MEGA model)'
  id: totrans-3909
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegaConfig](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaConfig)
    配置类: [MegaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForQuestionAnswering)
    (MEGA 模型)'
- en: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    configuration class: [MegatronBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering)
    (Megatron-BERT model)'
  id: totrans-3910
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MegatronBertConfig](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertConfig)
    配置类: [MegatronBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering)
    (Megatron-BERT 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [MobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering)
    (MobileBERT model)'
  id: totrans-3911
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [MobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering)
    (MobileBERT 模型)'
- en: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    configuration class: [MptForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForQuestionAnswering)
    (MPT model)'
  id: totrans-3912
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MptConfig](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptConfig)
    配置类: [MptForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForQuestionAnswering)
    (MPT 模型)'
- en: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    configuration class: [MraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForQuestionAnswering)
    (MRA model)'
  id: totrans-3913
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MraConfig](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraConfig)
    配置类: [MraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForQuestionAnswering)
    (MRA 模型)'
- en: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    configuration class: [MvpForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForQuestionAnswering)
    (MVP model)'
  id: totrans-3914
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MvpConfig](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpConfig)
    配置类: [MvpForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForQuestionAnswering)
    (MVP 模型)'
- en: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    configuration class: [NezhaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForQuestionAnswering)
    (Nezha model)'
  id: totrans-3915
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NezhaConfig](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaConfig)
    配置类: [NezhaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForQuestionAnswering)
    (Nezha 模型)'
- en: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    configuration class: [NystromformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering)
    (Nyströmformer model)'
  id: totrans-3916
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NystromformerConfig](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerConfig)
    配置类: [NystromformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering)
    (Nyströmformer 模型)'
- en: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    configuration class: [OPTForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForQuestionAnswering)
    (OPT model)'
  id: totrans-3917
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OPTConfig](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTConfig)
    配置类: [OPTForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForQuestionAnswering)
    (OPT 模型)'
- en: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    configuration class: [QDQBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering)
    (QDQBert model)'
  id: totrans-3918
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[QDQBertConfig](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertConfig)
    配置类: [QDQBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering)
    (QDQBert 模型)'
- en: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    configuration class: [ReformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering)
    (Reformer model)'
  id: totrans-3919
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ReformerConfig](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerConfig)
    配置类: [ReformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering)
    (Reformer 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [RemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering)
    (RemBERT model)'
  id: totrans-3920
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [RemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering)
    (RemBERT 模型)'
- en: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    configuration class: [RoCBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering)
    (RoCBert model)'
  id: totrans-3921
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoCBertConfig](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertConfig)
    配置类: [RoCBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering)
    (RoCBert 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [RoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering)
    (RoFormer model)'
  id: totrans-3922
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [RoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [RobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering)
    (RoBERTa model)'
  id: totrans-3923
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [RobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [RobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-3924
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [RobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    configuration class: [SplinterForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering)
    (Splinter model)'
  id: totrans-3925
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SplinterConfig](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterConfig)
    配置类: [SplinterForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering)
    (Splinter 模型)'
- en: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    configuration class: [SqueezeBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering)
    (SqueezeBERT model)'
  id: totrans-3926
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SqueezeBertConfig](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertConfig)
    配置类: [SqueezeBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering)
    (SqueezeBERT 模型)'
- en: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    configuration class: [T5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForQuestionAnswering)
    (T5 model)'
  id: totrans-3927
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[T5Config](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5Config)
    配置类: [T5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForQuestionAnswering)
    (T5 模型)'
- en: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    configuration class: [UMT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForQuestionAnswering)
    (UMT5 model)'
  id: totrans-3928
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UMT5Config](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5Config)
    配置类: [UMT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForQuestionAnswering)
    (UMT5 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [XLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple)
    (XLM model)'
  id: totrans-3929
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [XLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [XLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  id: totrans-3930
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [XLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering)
    (XLM-RoBERTa 模型)'
- en: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    configuration class: [XLMRobertaXLForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering)
    (XLM-RoBERTa-XL model)'
  id: totrans-3931
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaXLConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig)
    配置类: [XLMRobertaXLForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering)
    (XLM-RoBERTa-XL 模型)'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [XLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple)
    (XLNet model)'
  id: totrans-3932
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)配置类：[XLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple)（XLNet模型）'
- en: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)
    configuration class: [XmodForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForQuestionAnswering)
    (X-MOD model)'
  id: totrans-3933
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XmodConfig](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodConfig)配置类：[XmodForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForQuestionAnswering)（X-MOD模型）'
- en: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)
    configuration class: [YosoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering)
    (YOSO model)'
  id: totrans-3934
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YosoConfig](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoConfig)配置类：[YosoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering)（YOSO模型）'
- en: Instantiates one of the model classes of the library (with a question answering
    head) from a configuration.
  id: totrans-3935
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库中的一个模型类（带有问答头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-3936
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-3937
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE161]'
  id: totrans-3938
  prefs: []
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '#### `from_pretrained`'
  id: totrans-3939
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-3940
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE162]'
  id: totrans-3941
  prefs: []
  type: TYPE_PRE
  zh: '[PRE162]'
- en: Parameters
  id: totrans-3942
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-3943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-3944
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者命名空间下的用户或组织名称，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-3945
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-3946
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个路径或url到一个*tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该提供一个配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-3947
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-3948
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-3949
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-3950
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-3951
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-3952
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-3953
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建一个模型，但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-3954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-3955
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`）— 从TensorFlow检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-3956
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-3957
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-3958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-3959
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-3960
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-3961
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以
    `revision` 可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-3962
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在Hub上定义自定义模型并在其自己的建模文件中执行。此选项应仅针对您信任的存储库设置为
    `True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-3963
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以
    `revision` 可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-3964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-3965
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-3966
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a question answering
    head) from a pretrained model.
  id: totrans-3967
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库的一个模型类（带有问答头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-3968
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`albert` — [AlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForQuestionAnswering)
    (ALBERT model)'
  id: totrans-3969
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [AlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertForQuestionAnswering)
    (ALBERT模型)'
- en: '`bart` — [BartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForQuestionAnswering)
    (BART model)'
  id: totrans-3970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [BartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartForQuestionAnswering)
    (BART模型)'
- en: '`bert` — [BertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForQuestionAnswering)
    (BERT model)'
  id: totrans-3971
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [BertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertForQuestionAnswering)
    (BERT模型)'
- en: '`big_bird` — [BigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering)
    (BigBird model)'
  id: totrans-3972
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [BigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering)
    (BigBird模型)'
- en: '`bigbird_pegasus` — [BigBirdPegasusForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering)
    (BigBird-Pegasus model)'
  id: totrans-3973
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bigbird_pegasus` — [BigBirdPegasusForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering)
    (BigBird-Pegasus 模型)'
- en: '`bloom` — [BloomForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForQuestionAnswering)
    (BLOOM model)'
  id: totrans-3974
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bloom` — [BloomForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bloom#transformers.BloomForQuestionAnswering)
    (BLOOM 模型)'
- en: '`camembert` — [CamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForQuestionAnswering)
    (CamemBERT model)'
  id: totrans-3975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` — [CamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertForQuestionAnswering)
    (CamemBERT 模型)'
- en: '`canine` — [CanineForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForQuestionAnswering)
    (CANINE model)'
  id: totrans-3976
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`canine` — [CanineForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/canine#transformers.CanineForQuestionAnswering)
    (CANINE 模型)'
- en: '`convbert` — [ConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering)
    (ConvBERT model)'
  id: totrans-3977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` — [ConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering)
    (ConvBERT 模型)'
- en: '`data2vec-text` — [Data2VecTextForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering)
    (Data2VecText model)'
  id: totrans-3978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-text` — [Data2VecTextForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering)
    (Data2VecText 模型)'
- en: '`deberta` — [DebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForQuestionAnswering)
    (DeBERTa model)'
  id: totrans-3979
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` — [DebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaForQuestionAnswering)
    (DeBERTa 模型)'
- en: '`deberta-v2` — [DebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering)
    (DeBERTa-v2 model)'
  id: totrans-3980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` — [DebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering)
    (DeBERTa-v2 模型)'
- en: '`distilbert` — [DistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering)
    (DistilBERT model)'
  id: totrans-3981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [DistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering)
    (DistilBERT 模型)'
- en: '`electra` — [ElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering)
    (ELECTRA model)'
  id: totrans-3982
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [ElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraForQuestionAnswering)
    (ELECTRA 模型)'
- en: '`ernie` — [ErnieForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForQuestionAnswering)
    (ERNIE model)'
  id: totrans-3983
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie` — [ErnieForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie#transformers.ErnieForQuestionAnswering)
    (ERNIE 模型)'
- en: '`ernie_m` — [ErnieMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForQuestionAnswering)
    (ErnieM model)'
  id: totrans-3984
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ernie_m` — [ErnieMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ernie_m#transformers.ErnieMForQuestionAnswering)
    (ErnieM 模型)'
- en: '`falcon` — [FalconForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForQuestionAnswering)
    (Falcon model)'
  id: totrans-3985
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`falcon` — [FalconForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/falcon#transformers.FalconForQuestionAnswering)
    (Falcon 模型)'
- en: '`flaubert` — [FlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple)
    (FlauBERT model)'
  id: totrans-3986
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` — [FlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple)
    (FlauBERT 模型)'
- en: '`fnet` — [FNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering)
    (FNet model)'
  id: totrans-3987
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fnet` — [FNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/fnet#transformers.FNetForQuestionAnswering)
    (FNet 模型)'
- en: '`funnel` — [FunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering)
    (Funnel Transformer model)'
  id: totrans-3988
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` — [FunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelForQuestionAnswering)
    (Funnel Transformer 模型)'
- en: '`gpt2` — [GPT2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForQuestionAnswering)
    (OpenAI GPT-2 model)'
  id: totrans-3989
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2` — [GPT2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt2#transformers.GPT2ForQuestionAnswering)
    (OpenAI GPT-2 模型)'
- en: '`gpt_neo` — [GPTNeoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForQuestionAnswering)
    (GPT Neo model)'
  id: totrans-3990
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neo` — [GPTNeoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neo#transformers.GPTNeoForQuestionAnswering)
    (GPT Neo 模型)'
- en: '`gpt_neox` — [GPTNeoXForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForQuestionAnswering)
    (GPT NeoX model)'
  id: totrans-3991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt_neox` — [GPTNeoXForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gpt_neox#transformers.GPTNeoXForQuestionAnswering)
    (GPT NeoX 模型)'
- en: '`gptj` — [GPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering)
    (GPT-J model)'
  id: totrans-3992
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` — [GPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJForQuestionAnswering)
    (GPT-J 模型)'
- en: '`ibert` — [IBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering)
    (I-BERT model)'
  id: totrans-3993
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ibert` — [IBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/ibert#transformers.IBertForQuestionAnswering)
    (I-BERT 模型)'
- en: '`layoutlmv2` — [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 model)'
  id: totrans-3994
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 模型)'
- en: '`layoutlmv3` — [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  id: totrans-3995
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 模型)'
- en: '`led` — [LEDForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForQuestionAnswering)
    (LED model)'
  id: totrans-3996
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`led` — [LEDForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/led#transformers.LEDForQuestionAnswering)
    (LED 模型)'
- en: '`lilt` — [LiltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForQuestionAnswering)
    (LiLT model)'
  id: totrans-3997
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lilt` — [LiltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lilt#transformers.LiltForQuestionAnswering)
    (LiLT 模型)'
- en: '`longformer` — [LongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering)
    (Longformer model)'
  id: totrans-3998
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [LongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerForQuestionAnswering)
    (Longformer 模型)'
- en: '`luke` — [LukeForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForQuestionAnswering)
    (LUKE model)'
  id: totrans-3999
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`luke` — [LukeForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/luke#transformers.LukeForQuestionAnswering)
    (LUKE 模型)'
- en: '`lxmert` — [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering)
    (LXMERT model)'
  id: totrans-4000
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lxmert` — [LxmertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering)
    (LXMERT 模型)'
- en: '`markuplm` — [MarkupLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering)
    (MarkupLM model)'
  id: totrans-4001
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`markuplm` — [MarkupLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering)
    (MarkupLM 模型)'
- en: '`mbart` — [MBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering)
    (mBART model)'
  id: totrans-4002
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [MBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartForQuestionAnswering)
    (mBART 模型)'
- en: '`mega` — [MegaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForQuestionAnswering)
    (MEGA model)'
  id: totrans-4003
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mega` — [MegaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mega#transformers.MegaForQuestionAnswering)
    (MEGA 模型)'
- en: '`megatron-bert` — [MegatronBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering)
    (Megatron-BERT model)'
  id: totrans-4004
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`megatron-bert` — [MegatronBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering)
    (Megatron-BERT 模型)'
- en: '`mobilebert` — [MobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering)
    (MobileBERT model)'
  id: totrans-4005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [MobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering)
    (MobileBERT 模型)'
- en: '`mpnet` — [MPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering)
    (MPNet model)'
  id: totrans-4006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [MPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering)
    (MPNet 模型)'
- en: '`mpt` — [MptForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForQuestionAnswering)
    (MPT model)'
  id: totrans-4007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpt` — [MptForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpt#transformers.MptForQuestionAnswering)
    (MPT 模型)'
- en: '`mra` — [MraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForQuestionAnswering)
    (MRA model)'
  id: totrans-4008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mra` — [MraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mra#transformers.MraForQuestionAnswering)
    (MRA 模型)'
- en: '`mt5` — [MT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForQuestionAnswering)
    (MT5 model)'
  id: totrans-4009
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt5` — [MT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mt5#transformers.MT5ForQuestionAnswering)
    (MT5 模型)'
- en: '`mvp` — [MvpForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForQuestionAnswering)
    (MVP model)'
  id: totrans-4010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mvp` — [MvpForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mvp#transformers.MvpForQuestionAnswering)
    (MVP 模型)'
- en: '`nezha` — [NezhaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForQuestionAnswering)
    (Nezha model)'
  id: totrans-4011
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nezha` — [NezhaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nezha#transformers.NezhaForQuestionAnswering)
    (Nezha 模型)'
- en: '`nystromformer` — [NystromformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering)
    (Nyströmformer model)'
  id: totrans-4012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nystromformer` — [NystromformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering)
    (Nyströmformer 模型)'
- en: '`opt` — [OPTForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForQuestionAnswering)
    (OPT model)'
  id: totrans-4013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opt` — [OPTForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/opt#transformers.OPTForQuestionAnswering)
    (OPT 模型)'
- en: '`qdqbert` — [QDQBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering)
    (QDQBert model)'
  id: totrans-4014
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qdqbert` — [QDQBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering)
    (QDQBert 模型)'
- en: '`reformer` — [ReformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering)
    (Reformer model)'
  id: totrans-4015
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reformer` — [ReformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/reformer#transformers.ReformerForQuestionAnswering)
    (Reformer 模型)'
- en: '`rembert` — [RemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering)
    (RemBERT model)'
  id: totrans-4016
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [RemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertForQuestionAnswering)
    (RemBERT 模型)'
- en: '`roberta` — [RobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering)
    (RoBERTa model)'
  id: totrans-4017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [RobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaForQuestionAnswering)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [RobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-4018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [RobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roc_bert` — [RoCBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering)
    (RoCBert model)'
  id: totrans-4019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roc_bert` — [RoCBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering)
    (RoCBert 模型)'
- en: '`roformer` — [RoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering)
    (RoFormer model)'
  id: totrans-4020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [RoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering)
    (RoFormer 模型)'
- en: '`splinter` — [SplinterForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering)
    (Splinter model)'
  id: totrans-4021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`splinter` — [SplinterForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/splinter#transformers.SplinterForQuestionAnswering)
    (Splinter 模型)'
- en: '`squeezebert` — [SqueezeBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering)
    (SqueezeBERT model)'
  id: totrans-4022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`squeezebert` — [SqueezeBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering)
    (SqueezeBERT 模型)'
- en: '`t5` — [T5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForQuestionAnswering)
    (T5 model)'
  id: totrans-4023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t5` — [T5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/t5#transformers.T5ForQuestionAnswering)
    (T5 模型)'
- en: '`umt5` — [UMT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForQuestionAnswering)
    (UMT5 model)'
  id: totrans-4024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`umt5` — [UMT5ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/umt5#transformers.UMT5ForQuestionAnswering)
    (UMT5 模型)'
- en: '`xlm` — [XLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple)
    (XLM model)'
  id: totrans-4025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [XLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple)
    (XLM 模型)'
- en: '`xlm-roberta` — [XLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  id: totrans-4026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [XLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering)
    (XLM-RoBERTa 模型)'
- en: '`xlm-roberta-xl` — [XLMRobertaXLForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering)
    (XLM-RoBERTa-XL model)'
  id: totrans-4027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta-xl` — [XLMRobertaXLForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering)
    (XLM-RoBERTa-XL 模型)'
- en: '`xlnet` — [XLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple)
    (XLNet model)'
  id: totrans-4028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [XLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple)
    (XLNet 模型)'
- en: '`xmod` — [XmodForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForQuestionAnswering)
    (X-MOD model)'
  id: totrans-4029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xmod` — [XmodForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xmod#transformers.XmodForQuestionAnswering)
    (X-MOD 模型)'
- en: '`yoso` — [YosoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering)
    (YOSO model)'
  id: totrans-4030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yoso` — [YosoForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/yoso#transformers.YosoForQuestionAnswering)
    (YOSO 模型)'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4031
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型处于评估模式，使用 `model.eval()` (例如，dropout 模块被停用)。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-4032
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE163]'
  id: totrans-4033
  prefs: []
  type: TYPE_PRE
  zh: '[PRE163]'
- en: TFAutoModelForQuestionAnswering
  id: totrans-4034
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForQuestionAnswering
- en: '### `class transformers.TFAutoModelForQuestionAnswering`'
  id: totrans-4035
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L637)'
  id: totrans-4036
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L637)'
- en: '[PRE164]'
  id: totrans-4037
  prefs: []
  type: TYPE_PRE
  zh: '[PRE164]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a question answering head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4038
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将作为库中的模型类之一实例化 (带有一个问答头)。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4039
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化 (会抛出错误)。
- en: '#### `from_config`'
  id: totrans-4040
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4041
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE165]'
  id: totrans-4042
  prefs: []
  type: TYPE_PRE
  zh: '[PRE165]'
- en: Parameters
  id: totrans-4043
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 实例化的模型类基于配置类进行选择:'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [TFAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering)
    (ALBERT model)'
  id: totrans-4045
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    配置类: [TFAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering)
    (ALBERT 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [TFBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering)
    (BERT model)'
  id: totrans-4046
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    配置类: [TFBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering)
    (BERT 模型)'
- en: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    configuration class: [TFCamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering)
    (CamemBERT model)'
  id: totrans-4047
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CamembertConfig](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.CamembertConfig)
    配置类: [TFCamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering)
    (CamemBERT 模型)'
- en: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    configuration class: [TFConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering)
    (ConvBERT model)'
  id: totrans-4048
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvBertConfig](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.ConvBertConfig)
    配置类: [TFConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering)
    (ConvBERT 模型)'
- en: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    configuration class: [TFDebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering)
    (DeBERTa model)'
  id: totrans-4049
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaConfig](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.DebertaConfig)
    配置类: [TFDebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering)
    (DeBERTa 模型)'
- en: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    configuration class: [TFDebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering)
    (DeBERTa-v2 model)'
  id: totrans-4050
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DebertaV2Config](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.DebertaV2Config)
    配置类: [TFDebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering)
    (DeBERTa-v2 模型)'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [TFDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering)
    (DistilBERT model)'
  id: totrans-4051
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [TFDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering)
    (DistilBERT 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [TFElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering)
    (ELECTRA model)'
  id: totrans-4052
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类: [TFElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering)
    (ELECTRA 模型)'
- en: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    configuration class: [TFFlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple)
    (FlauBERT model)'
  id: totrans-4053
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FlaubertConfig](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.FlaubertConfig)
    配置类: [TFFlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple)
    (FlauBERT 模型)'
- en: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    configuration class: [TFFunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering)
    (Funnel Transformer model)'
  id: totrans-4054
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FunnelConfig](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.FunnelConfig)
    配置类: [TFFunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering)
    (Funnel Transformer 模型)'
- en: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    configuration class: [TFGPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering)
    (GPT-J model)'
  id: totrans-4055
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPTJConfig](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.GPTJConfig)
    配置类: [TFGPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering)
    (GPT-J 模型)'
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  id: totrans-4056
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    配置类: [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 模型)'
- en: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    configuration class: [TFLongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering)
    (Longformer model)'
  id: totrans-4057
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LongformerConfig](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.LongformerConfig)
    配置类: [TFLongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering)
    (Longformer 模型)'
- en: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    configuration class: [TFMPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering)
    (MPNet model)'
  id: totrans-4058
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MPNetConfig](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.MPNetConfig)
    配置类: [TFMPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering)
    (MPNet 模型)'
- en: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    configuration class: [TFMobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering)
    (MobileBERT model)'
  id: totrans-4059
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileBertConfig](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.MobileBertConfig)
    配置类: [TFMobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering)
    (MobileBERT 模型)'
- en: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    configuration class: [TFRemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering)
    (RemBERT model)'
  id: totrans-4060
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RemBertConfig](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.RemBertConfig)
    配置类: [TFRemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering)
    (RemBERT 模型)'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [TFRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering)
    (RoFormer model)'
  id: totrans-4061
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类: [TFRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering)
    (RoFormer 模型)'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [TFRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering)
    (RoBERTa model)'
  id: totrans-4062
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类: [TFRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering)
    (RoBERTa 模型)'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [TFRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-4063
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类: [TFRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm 模型)'
- en: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    configuration class: [TFXLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple)
    (XLM model)'
  id: totrans-4064
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMConfig](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.XLMConfig)
    配置类: [TFXLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple)
    (XLM 模型)'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [TFXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  id: totrans-4065
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类: [TFXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa 模型)'
- en: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    configuration class: [TFXLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple)
    (XLNet model)'
  id: totrans-4066
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNetConfig](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.XLNetConfig)
    配置类: [TFXLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple)
    (XLNet 模型)'
- en: Instantiates one of the model classes of the library (with a question answering
    head) from a configuration.
  id: totrans-4067
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有问答头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4068
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-4069
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE166]'
  id: totrans-4070
  prefs: []
  type: TYPE_PRE
  zh: '[PRE166]'
- en: '#### `from_pretrained`'
  id: totrans-4071
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4072
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE167]'
  id: totrans-4073
  prefs: []
  type: TYPE_PRE
  zh: '[PRE167]'
- en: Parameters
  id: totrans-4074
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4075
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4076
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4077
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-4078
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PyTorch state_dict save file* 的路径或 URL（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将`from_pt`设置为`True`，并且应将配置对象提供为`config`参数。使用提供的转换脚本将
    PyTorch 模型转换为 TensorFlow 模型并在加载 TensorFlow 模型之后，此加载路径比较慢。'
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4079
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4080
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4081
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4082
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存模型，并通过提供保存目录重新加载模型。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4083
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为*config.json*的配置 JSON 文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4085
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4086
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4087
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4088
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4090
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4091
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4092
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的自己的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地计算机上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）- 如果代码位于Hub上的不同存储库中，则用于代码的特定修订版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*）- 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4095
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4096
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a question answering
    head) from a pretrained model.
  id: totrans-4097
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库的模型类之一（带有问答头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4098
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`albert` — [TFAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering)
    (ALBERT model)'
  id: totrans-4099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` - [TFAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering)（ALBERT模型）'
- en: '`bert` — [TFBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering)
    (BERT model)'
  id: totrans-4100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` - [TFBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.TFBertForQuestionAnswering)（BERT模型）'
- en: '`camembert` — [TFCamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering)
    (CamemBERT model)'
  id: totrans-4101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camembert` - [TFCamembertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering)（CamemBERT模型）'
- en: '`convbert` — [TFConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering)
    (ConvBERT model)'
  id: totrans-4102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convbert` - [TFConvBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering)（ConvBERT模型）'
- en: '`deberta` — [TFDebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering)
    (DeBERTa model)'
  id: totrans-4103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta` - [TFDebertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering)（DeBERTa模型）'
- en: '`deberta-v2` — [TFDebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering)
    (DeBERTa-v2 model)'
  id: totrans-4104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deberta-v2` - [TFDebertaV2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering)（DeBERTa-v2模型）'
- en: '`distilbert` — [TFDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering)
    (DistilBERT model)'
  id: totrans-4105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` - [TFDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering)（DistilBERT模型）'
- en: '`electra` — [TFElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering)
    (ELECTRA model)'
  id: totrans-4106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` - [TFElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.TFElectraForQuestionAnswering)（ELECTRA模型）'
- en: '`flaubert` — [TFFlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple)
    (FlauBERT model)'
  id: totrans-4107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flaubert` - [TFFlaubertForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple)（FlauBERT模型）'
- en: '`funnel` — [TFFunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering)
    (Funnel Transformer model)'
  id: totrans-4108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`funnel` - [TFFunnelForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering)（Funnel
    Transformer模型）'
- en: '`gptj` — [TFGPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering)
    (GPT-J model)'
  id: totrans-4109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gptj` - [TFGPTJForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering)（GPT-J模型）'
- en: '`layoutlmv3` — [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  id: totrans-4110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` - [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)（LayoutLMv3模型）'
- en: '`longformer` — [TFLongformerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering)
    (Longformer model)'
  id: totrans-4111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`longformer` — [TFLongformerForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/longformer#transformers.TFLongformerForQuestionAnswering)
    (Longformer 模型)'
- en: '`mobilebert` — [TFMobileBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering)
    (MobileBERT model)'
  id: totrans-4112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilebert` — [TFMobileBertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering)
    (MobileBERT 模型)'
- en: '`mpnet` — [TFMPNetForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering)
    (MPNet model)'
  id: totrans-4113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mpnet` — [TFMPNetForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering)
    (MPNet 模型)'
- en: '`rembert` — [TFRemBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering)
    (RemBERT model)'
  id: totrans-4114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rembert` — [TFRemBertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/rembert#transformers.TFRemBertForQuestionAnswering)
    (RemBERT 模型)'
- en: '`roberta` — [TFRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering)
    (RoBERTa model)'
  id: totrans-4115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [TFRobertaForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/roberta#transformers.TFRobertaForQuestionAnswering)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-4116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [TFRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/roberta-prelayernorm#transformers.TFRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [TFRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering)
    (RoFormer model)'
  id: totrans-4117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [TFRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering)
    (RoFormer 模型)'
- en: '`xlm` — [TFXLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple)
    (XLM model)'
  id: totrans-4118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm` — [TFXLMForQuestionAnsweringSimple](/docs/transformers/v4.37.2/zh/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple)
    (XLM 模型)'
- en: '`xlm-roberta` — [TFXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  id: totrans-4119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [TFXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa 模型)'
- en: '`xlnet` — [TFXLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple)
    (XLNet model)'
  id: totrans-4120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlnet` — [TFXLNetForQuestionAnsweringSimple](/docs/transformers/v4.37.2/zh/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple)
    (XLNet 模型)'
- en: 'Examples:'
  id: totrans-4121
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE168]'
  id: totrans-4122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE168]'
- en: FlaxAutoModelForQuestionAnswering
  id: totrans-4123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForQuestionAnswering
- en: '### `class transformers.FlaxAutoModelForQuestionAnswering`'
  id: totrans-4124
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L322)'
  id: totrans-4125
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L322)'
- en: '[PRE169]'
  id: totrans-4126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE169]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a question answering head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4127
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将实例化为库中的一个模型类（带有问答头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4128
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4129
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4130
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE170]'
  id: totrans-4131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE170]'
- en: Parameters
  id: totrans-4132
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类:'
- en: '[AlbertConfig](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.AlbertConfig)
    configuration class: [FlaxAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering)
    (ALBERT model)'
  id: totrans-4134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlbertConfig](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.AlbertConfig)
    配置类: [FlaxAlbertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering)
    (ALBERT 模型)'
- en: '[BartConfig](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.BartConfig)
    configuration class: [FlaxBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering)
    (BART model)'
  id: totrans-4135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BartConfig](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.BartConfig)
    配置类: [FlaxBartForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/bart#transformers.FlaxBartForQuestionAnswering)
    (BART 模型)'
- en: '[BertConfig](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.BertConfig)
    configuration class: [FlaxBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering)
    (BERT model)'
  id: totrans-4136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BertConfig](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.BertConfig)
    配置类: [FlaxBertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/bert#transformers.FlaxBertForQuestionAnswering)
    (BERT 模型)'
- en: '[BigBirdConfig](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.BigBirdConfig)
    configuration class: [FlaxBigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering)
    (BigBird model)'
  id: totrans-4137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BigBirdConfig](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.BigBirdConfig)
    配置类: [FlaxBigBirdForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering)
    (BigBird 模型)'
- en: '[DistilBertConfig](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.DistilBertConfig)
    configuration class: [FlaxDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering)
    (DistilBERT model)'
  id: totrans-4138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DistilBertConfig](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.DistilBertConfig)
    配置类: [FlaxDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering)
    (DistilBERT 模型)'
- en: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    configuration class: [FlaxElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering)
    (ELECTRA model)'
  id: totrans-4139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ElectraConfig](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.ElectraConfig)
    配置类：[FlaxElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering)（ELECTRA
    模型）'
- en: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    configuration class: [FlaxMBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering)
    (mBART model)'
  id: totrans-4140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MBartConfig](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.MBartConfig)
    配置类：[FlaxMBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering)（mBART
    模型）'
- en: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    configuration class: [FlaxRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering)
    (RoFormer model)'
  id: totrans-4141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RoFormerConfig](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.RoFormerConfig)
    配置类：[FlaxRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering)（RoFormer
    模型）'
- en: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    configuration class: [FlaxRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering)
    (RoBERTa model)'
  id: totrans-4142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaConfig](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.RobertaConfig)
    配置类：[FlaxRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering)（RoBERTa
    模型）'
- en: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    configuration class: [FlaxRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-4143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RobertaPreLayerNormConfig](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.RobertaPreLayerNormConfig)
    配置类：[FlaxRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForQuestionAnswering)（RoBERTa-PreLayerNorm
    模型）'
- en: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    configuration class: [FlaxXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  id: totrans-4144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLMRobertaConfig](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig)
    配置类：[FlaxXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering)（XLM-RoBERTa
    模型）'
- en: Instantiates one of the model classes of the library (with a question answering
    head) from a configuration.
  id: totrans-4145
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置文件实例化库中的一个模型类（带有问答头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4146
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-4147
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE171]'
  id: totrans-4148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE171]'
- en: '#### `from_pretrained`'
  id: totrans-4149
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4150
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE172]'
  id: totrans-4151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE172]'
- en: Parameters
  id: totrans-4152
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-4156
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）- 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）-
    用于模型的配置，而不是自动加载的配置。当：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并且通过提供保存目录来重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供一个本地目录作为`pretrained_model_name_or_path`来加载模型，并且在该目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`，*可选*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`，*可选*，默认为 `False`) — 从 PyTorch 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path`
    参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`，*可选*，默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`，*可选*，默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`，*可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`，*可选*，默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在
    huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`，*可选*，默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`，*可选*，默认为 `"main"`) — 在 Hub 上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可以用来更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了
    `config` 或自动加载，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了一个带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设所有相关的配置更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a question answering
    head) from a pretrained model.
  id: totrans-4175
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有问答头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4176
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的 `model_type` 属性（如果可能作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在
    `pretrained_model_name_or_path` 上进行模式匹配来选择要实例化的模型类：
- en: '`albert` — [FlaxAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering)
    (ALBERT model)'
  id: totrans-4177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albert` — [FlaxAlbertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering)（ALBERT
    模型）'
- en: '`bart` — [FlaxBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering)
    (BART model)'
  id: totrans-4178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bart` — [FlaxBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering)（BART
    模型）'
- en: '`bert` — [FlaxBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering)
    (BERT model)'
  id: totrans-4179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bert` — [FlaxBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering)
    (BERT 模型)'
- en: '`big_bird` — [FlaxBigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering)
    (BigBird model)'
  id: totrans-4180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`big_bird` — [FlaxBigBirdForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering)
    (BigBird 模型)'
- en: '`distilbert` — [FlaxDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering)
    (DistilBERT model)'
  id: totrans-4181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distilbert` — [FlaxDistilBertForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering)
    (DistilBERT 模型)'
- en: '`electra` — [FlaxElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering)
    (ELECTRA model)'
  id: totrans-4182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`electra` — [FlaxElectraForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering)
    (ELECTRA 模型)'
- en: '`mbart` — [FlaxMBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering)
    (mBART model)'
  id: totrans-4183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mbart` — [FlaxMBartForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering)
    (mBART 模型)'
- en: '`roberta` — [FlaxRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering)
    (RoBERTa model)'
  id: totrans-4184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta` — [FlaxRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering)
    (RoBERTa 模型)'
- en: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm model)'
  id: totrans-4185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roberta-prelayernorm` — [FlaxRobertaPreLayerNormForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roberta-prelayernorm#transformers.FlaxRobertaPreLayerNormForQuestionAnswering)
    (RoBERTa-PreLayerNorm 模型)'
- en: '`roformer` — [FlaxRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering)
    (RoFormer model)'
  id: totrans-4186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roformer` — [FlaxRoFormerForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering)
    (RoFormer 模型)'
- en: '`xlm-roberta` — [FlaxXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa model)'
  id: totrans-4187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlm-roberta` — [FlaxXLMRobertaForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering)
    (XLM-RoBERTa 模型)'
- en: 'Examples:'
  id: totrans-4188
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE173]'
  id: totrans-4189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE173]'
- en: AutoModelForTextEncoding
  id: totrans-4190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForTextEncoding
- en: '### `class transformers.AutoModelForTextEncoding`'
  id: totrans-4191
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForTextEncoding`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1296)'
  id: totrans-4192
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1296)'
- en: '[PRE174]'
  id: totrans-4193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE174]'
- en: TFAutoModelForTextEncoding
  id: totrans-4194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForTextEncoding
- en: '### `class transformers.TFAutoModelForTextEncoding`'
  id: totrans-4195
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForTextEncoding`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L527)'
  id: totrans-4196
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L527)'
- en: '[PRE175]'
  id: totrans-4197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE175]'
- en: Computer vision
  id: totrans-4198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: The following auto classes are available for the following computer vision tasks.
  id: totrans-4199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下自动类适用于以下计算机视觉任务。
- en: AutoModelForDepthEstimation
  id: totrans-4200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForDepthEstimation
- en: '### `class transformers.AutoModelForDepthEstimation`'
  id: totrans-4201
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForDepthEstimation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1489)'
  id: totrans-4202
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1489)'
- en: '[PRE176]'
  id: totrans-4203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE176]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a depth estimation head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4204
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有深度估计头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4205
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会报错）。
- en: '#### `from_config`'
  id: totrans-4206
  prefs: []
  type: TYPE_NORMAL
  zh: '`from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4207
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE177]'
  id: totrans-4208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE177]'
- en: Parameters
  id: totrans-4209
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 实例化的模型类是根据配置类选择的:'
- en: '[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    configuration class: [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)
    (DPT model)'
  id: totrans-4211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    配置类: [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)
    (DPT 模型)'
- en: '[GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig)
    configuration class: [GLPNForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNForDepthEstimation)
    (GLPN model)'
  id: totrans-4212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GLPNConfig](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNConfig)
    配置类: [GLPNForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNForDepthEstimation)
    (GLPN 模型)'
- en: Instantiates one of the model classes of the library (with a depth estimation
    head) from a configuration.
  id: totrans-4213
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有深度估计头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4214
  prefs: []
  type: TYPE_NORMAL
  zh: '注意: 从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。'
- en: 'Examples:'
  id: totrans-4215
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE178]'
  id: totrans-4216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE178]'
- en: '#### `from_pretrained`'
  id: totrans-4217
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4218
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE179]'
  id: totrans-4219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE179]'
- en: Parameters
  id: totrans-4220
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在 huggingface.co 模型存储库内的预训练模型的 *模型 ID*。有效的模型 ID 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-4224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *tensorflow 索引检查点文件* 的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch
    模型并加载 PyTorch 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *可选*) — 用于模型的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-4230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *可选*) — 用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-4231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *可选*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *可选*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path`
    参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在
    huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型在其自己的建模文件中。此选项应仅设置为`True`，用于您信任的存储库，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统来存储模型和huggingface.co上的其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*）— 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a depth estimation
    head) from a pretrained model.
  id: totrans-4245
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有深度估计头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4246
  prefs: []
  type: TYPE_NORMAL
  zh: 基于配置对象的`model_type`属性选择要实例化的模型类（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`dpt` — [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)
    (DPT model)'
  id: totrans-4247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpt` — [DPTForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForDepthEstimation)（DPT模型）'
- en: '`glpn` — [GLPNForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNForDepthEstimation)
    (GLPN model)'
  id: totrans-4248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glpn` — [GLPNForDepthEstimation](/docs/transformers/v4.37.2/en/model_doc/glpn#transformers.GLPNForDepthEstimation)（GLPN模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4249
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-4250
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE180]'
  id: totrans-4251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE180]'
- en: AutoModelForImageClassification
  id: totrans-4252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForImageClassification
- en: '### `class transformers.AutoModelForImageClassification`'
  id: totrans-4253
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1423)'
  id: totrans-4254
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1423)'
- en: '[PRE181]'
  id: totrans-4255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE181]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a image classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4256
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将被实例化为库中的一个模型类（带有图像分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4257
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4258
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4259
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE182]'
  id: totrans-4260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE182]'
- en: Parameters
  id: totrans-4261
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    选择要实例化的模型类基于配置类：'
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [BeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForImageClassification)
    (BEiT model)'
  id: totrans-4263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)配置类：[BeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForImageClassification)（BEiT模型）'
- en: '[BitConfig](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitConfig)
    configuration class: [BitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitForImageClassification)
    (BiT model)'
  id: totrans-4264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: BitConfig配置类：BitForImageClassification（BiT模型）
- en: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    configuration class: [ConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextForImageClassification)
    (ConvNeXT model)'
  id: totrans-4265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ConvNextConfig配置类：ConvNextForImageClassification（ConvNeXT模型）
- en: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    configuration class: [ConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2ForImageClassification)
    (ConvNeXTV2 model)'
  id: totrans-4266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ConvNextV2Config配置类：ConvNextV2ForImageClassification（ConvNeXTV2模型）
- en: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    configuration class: [CvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtForImageClassification)
    (CvT model)'
  id: totrans-4267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: CvtConfig配置类：CvtForImageClassification（CvT模型）
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [Data2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification)
    (Data2VecVision model)'
  id: totrans-4268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Data2VecVisionConfig配置类：Data2VecVisionForImageClassification（Data2VecVision模型）
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)
    or [DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)
    (DeiT model)'
  id: totrans-4269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeiTConfig配置类：DeiTForImageClassification或DeiTForImageClassificationWithTeacher（DeiT模型）
- en: '[DinatConfig](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatConfig)
    configuration class: [DinatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatForImageClassification)
    (DiNAT model)'
  id: totrans-4270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DinatConfig配置类：DinatForImageClassification（DiNAT模型）
- en: '[Dinov2Config](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2Config)
    configuration class: [Dinov2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2ForImageClassification)
    (DINOv2 model)'
  id: totrans-4271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dinov2Config配置类：Dinov2ForImageClassification（DINOv2模型）
- en: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    configuration class: [EfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassification)
    or [EfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassificationWithTeacher)
    (EfficientFormer model)'
  id: totrans-4272
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: EfficientFormerConfig配置类：EfficientFormerForImageClassification或EfficientFormerForImageClassificationWithTeacher（EfficientFormer模型）
- en: '[EfficientNetConfig](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetConfig)
    configuration class: [EfficientNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetForImageClassification)
    (EfficientNet model)'
  id: totrans-4273
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: EfficientNetConfig配置类：EfficientNetForImageClassification（EfficientNet模型）
- en: '[FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)
    configuration class: [FocalNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForImageClassification)
    (FocalNet model)'
  id: totrans-4274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FocalNetConfig配置类：FocalNetForImageClassification（FocalNet模型）
- en: '[ImageGPTConfig](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTConfig)
    configuration class: [ImageGPTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification)
    (ImageGPT model)'
  id: totrans-4275
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ImageGPTConfig配置类：ImageGPTForImageClassification（ImageGPT模型）
- en: '[LevitConfig](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitConfig)
    configuration class: [LevitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassification)
    or [LevitForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher)
    (LeViT model)'
  id: totrans-4276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LevitConfig配置类：LevitForImageClassification或LevitForImageClassificationWithTeacher（LeViT模型）
- en: '[MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config)
    configuration class: [MobileNetV1ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ForImageClassification)
    (MobileNetV1 model)'
  id: totrans-4277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileNetV1Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1Config)
    配置类: [MobileNetV1ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ForImageClassification)
    (MobileNetV1 模型)'
- en: '[MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    configuration class: [MobileNetV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification)
    (MobileNetV2 model)'
  id: totrans-4278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    配置类: [MobileNetV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification)
    (MobileNetV2 模型)'
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [MobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForImageClassification)
    (MobileViT model)'
  id: totrans-4279
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    配置类: [MobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForImageClassification)
    (MobileViT 模型)'
- en: '[MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    configuration class: [MobileViTV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForImageClassification)
    (MobileViTV2 model)'
  id: totrans-4280
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    配置类: [MobileViTV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForImageClassification)
    (MobileViTV2 模型)'
- en: '[NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig)
    configuration class: [NatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatForImageClassification)
    (NAT model)'
  id: totrans-4281
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NatConfig](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatConfig)
    配置类: [NatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatForImageClassification)
    (NAT 模型)'
- en: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    configuration class: [PerceiverForImageClassificationLearned](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned)
    or [PerceiverForImageClassificationFourier](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier)
    or [PerceiverForImageClassificationConvProcessing](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing)
    (Perceiver model)'
  id: totrans-4282
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PerceiverConfig](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverConfig)
    配置类: [PerceiverForImageClassificationLearned](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned)
    或 [PerceiverForImageClassificationFourier](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier)
    或 [PerceiverForImageClassificationConvProcessing](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing)
    (Perceiver 模型)'
- en: '[PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)
    configuration class: [PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification)
    (PoolFormer model)'
  id: totrans-4283
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PoolFormerConfig](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerConfig)
    配置类: [PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification)
    (PoolFormer 模型)'
- en: '[PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig)
    configuration class: [PvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtForImageClassification)
    (PVT model)'
  id: totrans-4284
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PvtConfig](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtConfig)
    配置类: [PvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtForImageClassification)
    (PVT 模型)'
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)
    (RegNet model)'
  id: totrans-4285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    配置类: [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)
    (RegNet 模型)'
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)
    (ResNet model)'
  id: totrans-4286
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    配置类: [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)
    (ResNet 模型)'
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [SegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForImageClassification)
    (SegFormer model)'
  id: totrans-4287
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    配置类: [SegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForImageClassification)
    (SegFormer 模型)'
- en: '[SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig)
    configuration class: [SwiftFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerForImageClassification)
    (SwiftFormer model)'
  id: totrans-4288
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwiftFormerConfig](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerConfig)
    配置类: [SwiftFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerForImageClassification)
    (SwiftFormer 模型)'
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [SwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForImageClassification)
    (Swin Transformer model)'
  id: totrans-4289
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    配置类: [SwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForImageClassification)
    (Swin Transformer 模型)'
- en: '[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    configuration class: [Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)
    (Swin Transformer V2 model)'
  id: totrans-4290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    配置类: [Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)
    (Swin Transformer V2 模型)'
- en: '[VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig)
    configuration class: [VanForImageClassification](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanForImageClassification)
    (VAN model)'
  id: totrans-4291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VanConfig](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanConfig)
    配置类: [VanForImageClassification](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanForImageClassification)
    (VAN 模型)'
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification)
    (ViT model)'
  id: totrans-4292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    配置类: [ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification)
    (ViT 模型)'
- en: '[ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)
    configuration class: [ViTHybridForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridForImageClassification)
    (ViT Hybrid model)'
  id: totrans-4293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTHybridConfig](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridConfig)
    配置类: [ViTHybridForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridForImageClassification)
    (ViT Hybrid 模型)'
- en: '[ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)
    configuration class: [ViTMSNForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification)
    (ViTMSN model)'
  id: totrans-4294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTMSNConfig](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNConfig)
    配置类: [ViTMSNForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification)
    (ViTMSN 模型)'
- en: Instantiates one of the model classes of the library (with a image classification
    head) from a configuration.
  id: totrans-4295
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有图像分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4296
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-4297
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE183]'
  id: totrans-4298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE183]'
- en: '#### `from_pretrained`'
  id: totrans-4299
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4300
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE184]'
  id: totrans-4301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE184]'
- en: Parameters
  id: totrans-4302
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4304
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4305
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-4306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向*TensorFlow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应该设置为 `True`，并且应该提供一个配置对象作为 `config` 参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *可选*) — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库中提供的一个模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录来重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供一个本地目录作为 `pretrained_model_name_or_path` 并在目录中找到一个名为 *config.json* 的配置JSON文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-4312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *可选*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-4313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个选项可以用来从预训练配置创建一个模型，但加载自己的权重。在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *optional*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器的字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统来存储模型和其他工件在 huggingface.co 上，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中使用。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统来存储模型和其他工件在 huggingface.co 上，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4325
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设所有相关的配置更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4326
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a image classification
    head) from a pretrained model.
  id: totrans-4327
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有图像分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4328
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的 `model_type` 属性（如果可能作为参数传递或从 `pretrained_model_name_or_path` 加载），或者当缺失时，通过在
    `pretrained_model_name_or_path` 上使用模式匹配来选择要实例化的模型类：
- en: '`beit` — [BeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForImageClassification)
    (BEiT model)'
  id: totrans-4329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beit` — [BeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForImageClassification)（BEiT
    模型）'
- en: '`bit` — [BitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitForImageClassification)
    (BiT model)'
  id: totrans-4330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bit` — [BitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/bit#transformers.BitForImageClassification)（BiT
    模型）'
- en: '`convnext` — [ConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextForImageClassification)
    (ConvNeXT model)'
  id: totrans-4331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnext` — [ConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextForImageClassification)
    (ConvNeXT 模型)'
- en: '`convnextv2` — [ConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2ForImageClassification)
    (ConvNeXTV2 model)'
  id: totrans-4332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnextv2` — [ConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2ForImageClassification)
    (ConvNeXTV2 模型)'
- en: '`cvt` — [CvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtForImageClassification)
    (CvT model)'
  id: totrans-4333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cvt` — [CvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtForImageClassification)
    (CvT 模型)'
- en: '`data2vec-vision` — [Data2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification)
    (Data2VecVision model)'
  id: totrans-4334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-vision` — [Data2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification)
    (Data2VecVision 模型)'
- en: '`deit` — [DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)
    or [DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)
    (DeiT model)'
  id: totrans-4335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deit` — [DeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassification)
    或 [DeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher)
    (DeiT 模型)'
- en: '`dinat` — [DinatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatForImageClassification)
    (DiNAT model)'
  id: totrans-4336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dinat` — [DinatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinat#transformers.DinatForImageClassification)
    (DiNAT 模型)'
- en: '`dinov2` — [Dinov2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2ForImageClassification)
    (DINOv2 model)'
  id: totrans-4337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dinov2` — [Dinov2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/dinov2#transformers.Dinov2ForImageClassification)
    (DINOv2 模型)'
- en: '`efficientformer` — [EfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassification)
    or [EfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassificationWithTeacher)
    (EfficientFormer model)'
  id: totrans-4338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientformer` — [EfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassification)
    或 [EfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerForImageClassificationWithTeacher)
    (EfficientFormer 模型)'
- en: '`efficientnet` — [EfficientNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetForImageClassification)
    (EfficientNet model)'
  id: totrans-4339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientnet` — [EfficientNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientnet#transformers.EfficientNetForImageClassification)
    (EfficientNet 模型)'
- en: '`focalnet` — [FocalNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForImageClassification)
    (FocalNet model)'
  id: totrans-4340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`focalnet` — [FocalNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForImageClassification)
    (FocalNet 模型)'
- en: '`imagegpt` — [ImageGPTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification)
    (ImageGPT model)'
  id: totrans-4341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imagegpt` — [ImageGPTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification)
    (ImageGPT 模型)'
- en: '`levit` — [LevitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassification)
    or [LevitForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher)
    (LeViT model)'
  id: totrans-4342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`levit` — [LevitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassification)
    或 [LevitForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher)
    (LeViT 模型)'
- en: '`mobilenet_v1` — [MobileNetV1ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ForImageClassification)
    (MobileNetV1 model)'
  id: totrans-4343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v1` — [MobileNetV1ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v1#transformers.MobileNetV1ForImageClassification)
    (MobileNetV1 模型)'
- en: '`mobilenet_v2` — [MobileNetV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification)
    (MobileNetV2 model)'
  id: totrans-4344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v2` — [MobileNetV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification)
    (MobileNetV2 模型)'
- en: '`mobilevit` — [MobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForImageClassification)
    (MobileViT model)'
  id: totrans-4345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevit` — [MobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForImageClassification)
    (MobileViT 模型)'
- en: '`mobilevitv2` — [MobileViTV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForImageClassification)
    (MobileViTV2 model)'
  id: totrans-4346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevitv2` — [MobileViTV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForImageClassification)
    (MobileViTV2 模型)'
- en: '`nat` — [NatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatForImageClassification)
    (NAT model)'
  id: totrans-4347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nat` — [NatForImageClassification](/docs/transformers/v4.37.2/en/model_doc/nat#transformers.NatForImageClassification)
    (NAT 模型)'
- en: '`perceiver` — [PerceiverForImageClassificationLearned](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned)
    or [PerceiverForImageClassificationFourier](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier)
    or [PerceiverForImageClassificationConvProcessing](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing)
    (Perceiver model)'
  id: totrans-4348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perceiver` — [PerceiverForImageClassificationLearned](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned)
    或 [PerceiverForImageClassificationFourier](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier)
    或 [PerceiverForImageClassificationConvProcessing](/docs/transformers/v4.37.2/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing)
    (Perceiver 模型)'
- en: '`poolformer` — [PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification)
    (PoolFormer model)'
  id: totrans-4349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`poolformer` — [PoolFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/poolformer#transformers.PoolFormerForImageClassification)
    (PoolFormer 模型)'
- en: '`pvt` — [PvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtForImageClassification)
    (PVT model)'
  id: totrans-4350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pvt` — [PvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/pvt#transformers.PvtForImageClassification)
    (PVT 模型)'
- en: '`regnet` — [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)
    (RegNet model)'
  id: totrans-4351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regnet` — [RegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetForImageClassification)（RegNet模型）'
- en: '`resnet` — [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)
    (ResNet model)'
  id: totrans-4352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resnet` — [ResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetForImageClassification)（ResNet模型）'
- en: '`segformer` — [SegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForImageClassification)
    (SegFormer model)'
  id: totrans-4353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segformer` — [SegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForImageClassification)（SegFormer模型）'
- en: '`swiftformer` — [SwiftFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerForImageClassification)
    (SwiftFormer model)'
  id: totrans-4354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swiftformer` — [SwiftFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swiftformer#transformers.SwiftFormerForImageClassification)（SwiftFormer模型）'
- en: '`swin` — [SwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForImageClassification)
    (Swin Transformer model)'
  id: totrans-4355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin` — [SwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForImageClassification)（Swin
    Transformer模型）'
- en: '`swinv2` — [Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)
    (Swin Transformer V2 model)'
  id: totrans-4356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swinv2` — [Swinv2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForImageClassification)（Swin
    Transformer V2模型）'
- en: '`van` — [VanForImageClassification](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanForImageClassification)
    (VAN model)'
  id: totrans-4357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`van` — [VanForImageClassification](/docs/transformers/v4.37.2/en/model_doc/van#transformers.VanForImageClassification)（VAN模型）'
- en: '`vit` — [ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification)
    (ViT model)'
  id: totrans-4358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [ViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForImageClassification)（ViT模型）'
- en: '`vit_hybrid` — [ViTHybridForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridForImageClassification)
    (ViT Hybrid model)'
  id: totrans-4359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_hybrid` — [ViTHybridForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_hybrid#transformers.ViTHybridForImageClassification)（ViT混合模型）'
- en: '`vit_msn` — [ViTMSNForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification)
    (ViTMSN model)'
  id: totrans-4360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit_msn` — [ViTMSNForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification)（ViTMSN模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4361
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型处于评估模式，使用`model.eval()`（例如，dropout模块被停用）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-4362
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE185]'
  id: totrans-4363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE185]'
- en: TFAutoModelForImageClassification
  id: totrans-4364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForImageClassification
- en: '### `class transformers.TFAutoModelForImageClassification`'
  id: totrans-4365
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L578)'
  id: totrans-4366
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L578)'
- en: '[PRE186]'
  id: totrans-4367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE186]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a image classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4368
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库中的模型类之一（带有图像分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4369
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`进行实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4370
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4371
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE187]'
  id: totrans-4372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE187]'
- en: Parameters
  id: totrans-4373
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    实例化的模型类基于配置类进行选择：'
- en: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)
    configuration class: [TFConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextForImageClassification)
    (ConvNeXT model)'
  id: totrans-4375
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvNextConfig](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.ConvNextConfig)配置类：[TFConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextForImageClassification)（ConvNeXT模型）'
- en: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)
    configuration class: [TFConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2ForImageClassification)
    (ConvNeXTV2 model)'
  id: totrans-4376
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConvNextV2Config](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.ConvNextV2Config)配置类：[TFConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2ForImageClassification)（ConvNeXTV2模型）'
- en: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)
    configuration class: [TFCvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtForImageClassification)
    (CvT model)'
  id: totrans-4377
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CvtConfig](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.CvtConfig)配置类：[TFCvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtForImageClassification)（CvT模型）'
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [TFData2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification)
    (Data2VecVision model)'
  id: totrans-4378
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)配置类：[TFData2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification)（Data2VecVision模型）'
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)
    or [TFDeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher)
    (DeiT model)'
  id: totrans-4379
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    配置类：[TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)
    或 [TFDeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher)（DeiT
    模型）'
- en: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    configuration class: [TFEfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassification)
    or [TFEfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassificationWithTeacher)
    (EfficientFormer model)'
  id: totrans-4380
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EfficientFormerConfig](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.EfficientFormerConfig)
    配置类：[TFEfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassification)
    或 [TFEfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassificationWithTeacher)（EfficientFormer
    模型）'
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [TFMobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification)
    (MobileViT model)'
  id: totrans-4381
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    配置类：[TFMobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification)（MobileViT
    模型）'
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)
    (RegNet model)'
  id: totrans-4382
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    配置类：[TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)（RegNet
    模型）'
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)
    (ResNet model)'
  id: totrans-4383
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    配置类：[TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)（ResNet
    模型）'
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [TFSegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForImageClassification)
    (SegFormer model)'
  id: totrans-4384
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    配置类：[TFSegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForImageClassification)（SegFormer
    模型）'
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [TFSwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForImageClassification)
    (Swin Transformer model)'
  id: totrans-4385
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    配置类：[TFSwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForImageClassification)（Swin
    Transformer 模型）'
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [TFViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTForImageClassification)
    (ViT model)'
  id: totrans-4386
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    配置类：[TFViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTForImageClassification)（ViT
    模型）'
- en: Instantiates one of the model classes of the library (with a image classification
    head) from a configuration.
  id: totrans-4387
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有图像分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4388
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-4389
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE188]'
  id: totrans-4390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE188]'
- en: '#### `from_pretrained`'
  id: totrans-4391
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4392
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE189]'
  id: totrans-4393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE189]'
- en: Parameters
  id: totrans-4394
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4396
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型 id*，托管在huggingface.co上的模型存储库中。有效的模型 id 可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4397
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-4398
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch state_dict save file*的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将
    PyTorch 模型转换为 TensorFlow 模型并随后加载 TensorFlow 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）- 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 用于模型的配置，而不是自动加载的配置。当自动加载配置时：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4401
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4402
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4403
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并在目录中找到名为 *config.json* 的配置
    JSON 文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, defaults to `False`) — 从 PyTorch 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 要使用的代理服务器字典，按协议或端点，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理将用于每个请求。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 在 Hub 上使用的代码的特定修订版，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了
    `config` 或自动加载，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4415
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了配置`config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4416
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a image classification
    head) from a pretrained model.
  id: totrans-4417
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有图像分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4418
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性（作为参数传递或从`pretrained_model_name_or_path`加载）选择的，或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`convnext` — [TFConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextForImageClassification)
    (ConvNeXT model)'
  id: totrans-4419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnext` — [TFConvNextForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnext#transformers.TFConvNextForImageClassification)（ConvNeXT模型）'
- en: '`convnextv2` — [TFConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2ForImageClassification)
    (ConvNeXTV2 model)'
  id: totrans-4420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`convnextv2` — [TFConvNextV2ForImageClassification](/docs/transformers/v4.37.2/en/model_doc/convnextv2#transformers.TFConvNextV2ForImageClassification)（ConvNeXTV2模型）'
- en: '`cvt` — [TFCvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtForImageClassification)
    (CvT model)'
  id: totrans-4421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cvt` — [TFCvtForImageClassification](/docs/transformers/v4.37.2/en/model_doc/cvt#transformers.TFCvtForImageClassification)（CvT模型）'
- en: '`data2vec-vision` — [TFData2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification)
    (Data2VecVision model)'
  id: totrans-4422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-vision` — [TFData2VecVisionForImageClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification)（Data2VecVision模型）'
- en: '`deit` — [TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)
    or [TFDeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher)
    (DeiT model)'
  id: totrans-4423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deit` — [TFDeiTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassification)或[TFDeiTForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher)（DeiT模型）'
- en: '`efficientformer` — [TFEfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassification)
    or [TFEfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassificationWithTeacher)
    (EfficientFormer model)'
  id: totrans-4424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`efficientformer` — [TFEfficientFormerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassification)或[TFEfficientFormerForImageClassificationWithTeacher](/docs/transformers/v4.37.2/en/model_doc/efficientformer#transformers.TFEfficientFormerForImageClassificationWithTeacher)（EfficientFormer模型）'
- en: '`mobilevit` — [TFMobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification)
    (MobileViT model)'
  id: totrans-4425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevit` — [TFMobileViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification)（MobileViT模型）'
- en: '`regnet` — [TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)
    (RegNet model)'
  id: totrans-4426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regnet` — [TFRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.TFRegNetForImageClassification)（RegNet模型）'
- en: '`resnet` — [TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)
    (ResNet model)'
  id: totrans-4427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resnet` — [TFResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.TFResNetForImageClassification)（ResNet模型）'
- en: '`segformer` — [TFSegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForImageClassification)
    (SegFormer model)'
  id: totrans-4428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segformer` — [TFSegformerForImageClassification](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForImageClassification)（SegFormer模型）'
- en: '`swin` — [TFSwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForImageClassification)
    (Swin Transformer model)'
  id: totrans-4429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin` — [TFSwinForImageClassification](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForImageClassification)（Swin
    Transformer模型）'
- en: '`vit` — [TFViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTForImageClassification)
    (ViT model)'
  id: totrans-4430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [TFViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.TFViTForImageClassification)（ViT模型）'
- en: 'Examples:'
  id: totrans-4431
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE190]'
  id: totrans-4432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE190]'
- en: FlaxAutoModelForImageClassification
  id: totrans-4433
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForImageClassification
- en: '### `class transformers.FlaxAutoModelForImageClassification`'
  id: totrans-4434
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L354)'
  id: totrans-4435
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L354)'
- en: '[PRE191]'
  id: totrans-4436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE191]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a image classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4437
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有图像分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4438
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4439
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4440
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE192]'
  id: totrans-4441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE192]'
- en: Parameters
  id: totrans-4442
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 选择要实例化的模型类基于配置类：'
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [FlaxBeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification)
    (BEiT model)'
  id: totrans-4444
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)配置类：[FlaxBeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification)（BEiT模型）'
- en: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    configuration class: [FlaxRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetForImageClassification)
    (RegNet model)'
  id: totrans-4445
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RegNetConfig](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.RegNetConfig)
    配置类: [FlaxRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetForImageClassification)
    (RegNet 模型)'
- en: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    configuration class: [FlaxResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetForImageClassification)
    (ResNet model)'
  id: totrans-4446
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ResNetConfig](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.ResNetConfig)
    配置类: [FlaxResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetForImageClassification)
    (ResNet 模型)'
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [FlaxViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTForImageClassification)
    (ViT model)'
  id: totrans-4447
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    配置类: [FlaxViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTForImageClassification)
    (ViT 模型)'
- en: Instantiates one of the model classes of the library (with a image classification
    head) from a configuration.
  id: totrans-4448
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有图像分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4449
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-4450
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE193]'
  id: totrans-4451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE193]'
- en: '#### `from_pretrained`'
  id: totrans-4452
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4453
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE194]'
  id: totrans-4454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE194]'
- en: Parameters
  id: totrans-4455
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4457
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间在用户或组织名称下，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4458
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-4459
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *PyTorch state_dict save file* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow
    模型并加载 TensorFlow 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况发生时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4462
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4463
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并且通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4464
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并且在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 预下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, 默认为 `False`) — 从 PyTorch checkpoint 保存文件加载模型权重（参见
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4476
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4477
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a image classification
    head) from a pretrained model.
  id: totrans-4478
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有图像分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4479
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上进行模式匹配来回退：
- en: '`beit` — [FlaxBeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification)
    (BEiT model)'
  id: totrans-4480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beit` — [FlaxBeitForImageClassification](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.FlaxBeitForImageClassification)（BEiT
    模型）'
- en: '`regnet` — [FlaxRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetForImageClassification)
    (RegNet model)'
  id: totrans-4481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regnet` — [FlaxRegNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/regnet#transformers.FlaxRegNetForImageClassification)（RegNet
    模型）'
- en: '`resnet` — [FlaxResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetForImageClassification)
    (ResNet model)'
  id: totrans-4482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resnet` — [FlaxResNetForImageClassification](/docs/transformers/v4.37.2/en/model_doc/resnet#transformers.FlaxResNetForImageClassification)（ResNet
    模型）'
- en: '`vit` — [FlaxViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTForImageClassification)
    (ViT model)'
  id: totrans-4483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [FlaxViTForImageClassification](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.FlaxViTForImageClassification)（ViT
    模型）'
- en: 'Examples:'
  id: totrans-4484
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE195]'
  id: totrans-4485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE195]'
- en: AutoModelForVideoClassification
  id: totrans-4486
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForVideoClassification
- en: '### `class transformers.AutoModelForVideoClassification`'
  id: totrans-4487
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForVideoClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1496)'
  id: totrans-4488
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1496)'
- en: '[PRE196]'
  id: totrans-4489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE196]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a video classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4490
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有视频分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4491
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4492
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4493
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE197]'
  id: totrans-4494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE197]'
- en: Parameters
  id: totrans-4495
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    要实例化的模型类是基于配置类选择的：'
- en: '[TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig)
    configuration class: [TimesformerForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerForVideoClassification)
    (TimeSformer model)'
  id: totrans-4497
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TimesformerConfig](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerConfig)
    配置类：[TimesformerForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerForVideoClassification)（TimeSformer
    模型）'
- en: '[VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    configuration class: [VideoMAEForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForVideoClassification)
    (VideoMAE model)'
  id: totrans-4498
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VideoMAEConfig](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEConfig)
    配置类：[VideoMAEForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForVideoClassification)（VideoMAE
    模型）'
- en: '[VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)
    configuration class: [VivitForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitForVideoClassification)
    (ViViT model)'
  id: totrans-4499
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VivitConfig](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitConfig)
    配置类：[VivitForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitForVideoClassification)（ViViT
    模型）'
- en: Instantiates one of the model classes of the library (with a video classification
    head) from a configuration.
  id: totrans-4500
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库中的一个模型类（带有视频分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4501
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-4502
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE198]'
  id: totrans-4503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE198]'
- en: '#### `from_pretrained`'
  id: totrans-4504
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4505
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE199]'
  id: totrans-4506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE199]'
- en: Parameters
  id: totrans-4507
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4509
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型仓库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4510
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-4511
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个路径或url指向*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    用于替代自动加载的模型配置。当以下情况发生时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4514
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4515
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4516
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在该目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-4517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-4518
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，可以使用此选项。在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, defaults to `False`) — 从TensorFlow检查点保存文件加载模型权重。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器字典，按协议或端点划分，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的代码文件。此选项应仅设置为`True`，用于您信任的存储库，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 代码在Hub上使用的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4530
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4531
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a video classification
    head) from a pretrained model.
  id: totrans-4532
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有视频分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4533
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：
- en: '`timesformer` — [TimesformerForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerForVideoClassification)
    (TimeSformer model)'
  id: totrans-4534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesformer` - [TimesformerForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/timesformer#transformers.TimesformerForVideoClassification)（TimeSformer模型）'
- en: '`videomae` — [VideoMAEForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForVideoClassification)
    (VideoMAE model)'
  id: totrans-4535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`videomae` - [VideoMAEForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/videomae#transformers.VideoMAEForVideoClassification)（VideoMAE模型）'
- en: '`vivit` — [VivitForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitForVideoClassification)
    (ViViT model)'
  id: totrans-4536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vivit` - [VivitForVideoClassification](/docs/transformers/v4.37.2/en/model_doc/vivit#transformers.VivitForVideoClassification)（ViViT模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4537
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-4538
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE200]'
  id: totrans-4539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE200]'
- en: AutoModelForMaskedImageModeling
  id: totrans-4540
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForMaskedImageModeling
- en: '### `class transformers.AutoModelForMaskedImageModeling`'
  id: totrans-4541
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForMaskedImageModeling`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1561)'
  id: totrans-4542
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1561)'
- en: '[PRE201]'
  id: totrans-4543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE201]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked image modeling head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4544
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将作为库的模型类之一实例化（带有遮罩图像建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4545
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4546
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4547
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE202]'
  id: totrans-4548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE202]'
- en: Parameters
  id: totrans-4549
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）-
    要实例化的模型类是根据配置类选择的：'
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)
    (DeiT model)'
  id: totrans-4551
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)配置类：[DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)（DeiT模型）'
- en: '[FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)
    configuration class: [FocalNetForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForMaskedImageModeling)
    (FocalNet model)'
  id: totrans-4552
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FocalNetConfig](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetConfig)配置类：[FocalNetForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForMaskedImageModeling)（FocalNet模型）'
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [SwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForMaskedImageModeling)
    (Swin Transformer model)'
  id: totrans-4553
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)配置类：[SwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForMaskedImageModeling)（Swin
    Transformer模型）'
- en: '[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)
    configuration class: [Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)
    (Swin Transformer V2 model)'
  id: totrans-4554
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Swinv2Config](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2Config)配置类：[Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)（Swin
    Transformer V2模型）'
- en: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)
    configuration class: [ViTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForMaskedImageModeling)
    (ViT model)'
  id: totrans-4555
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViTConfig](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTConfig)配置类：[ViTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForMaskedImageModeling)（ViT模型）'
- en: Instantiates one of the model classes of the library (with a masked image modeling
    head) from a configuration.
  id: totrans-4556
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库的模型类之一（带有遮罩图像建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4557
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只会影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-4558
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE203]'
  id: totrans-4559
  prefs: []
  type: TYPE_PRE
  zh: '[PRE203]'
- en: '#### `from_pretrained`'
  id: totrans-4560
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4561
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE204]'
  id: totrans-4562
  prefs: []
  type: TYPE_PRE
  zh: '[PRE204]'
- en: Parameters
  id: totrans-4563
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4565
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，指向huggingface.co上模型存储库中预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4566
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-4567
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或url指向*tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4570
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4571
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4572
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-4573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-4574
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str`或`os.PathLike`, *optional*) — 下载预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, 默认为 `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为
    `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, 默认为`"main"`) — 在 Hub 上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了
    `config` 或自动加载，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4586
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了配置 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4587
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个键对应于配置属性，将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a masked image modeling
    head) from a pretrained model.
  id: totrans-4588
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有遮罩图像建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4589
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退选择：
- en: '`deit` — [DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)
    (DeiT model)'
  id: totrans-4590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deit` — [DeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTForMaskedImageModeling)（DeiT
    模型）'
- en: '`focalnet` — [FocalNetForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForMaskedImageModeling)
    (FocalNet model)'
  id: totrans-4591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`focalnet` — [FocalNetForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/focalnet#transformers.FocalNetForMaskedImageModeling)（FocalNet
    模型）'
- en: '`swin` — [SwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForMaskedImageModeling)
    (Swin Transformer model)'
  id: totrans-4592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin` — [SwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinForMaskedImageModeling)（Swin
    Transformer 模型）'
- en: '`swinv2` — [Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)
    (Swin Transformer V2 model)'
  id: totrans-4593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swinv2` — [Swinv2ForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling)（Swin
    Transformer V2 模型）'
- en: '`vit` — [ViTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForMaskedImageModeling)
    (ViT model)'
  id: totrans-4594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vit` — [ViTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/vit#transformers.ViTForMaskedImageModeling)（ViT
    模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4595
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，该模型被设置为评估模式，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式。
- en: 'Examples:'
  id: totrans-4596
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE205]'
  id: totrans-4597
  prefs: []
  type: TYPE_PRE
  zh: '[PRE205]'
- en: TFAutoModelForMaskedImageModeling
  id: totrans-4598
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForMaskedImageModeling
- en: '### `class transformers.TFAutoModelForMaskedImageModeling`'
  id: totrans-4599
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForMaskedImageModeling`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L569)'
  id: totrans-4600
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L569)'
- en: '[PRE206]'
  id: totrans-4601
  prefs: []
  type: TYPE_PRE
  zh: '[PRE206]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a masked image modeling head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4602
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有遮罩图像建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4603
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4604
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4605
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE207]'
  id: totrans-4606
  prefs: []
  type: TYPE_PRE
  zh: '[PRE207]'
- en: Parameters
  id: totrans-4607
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 实例化的模型类基于配置类进行选择：'
- en: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    configuration class: [TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)
    (DeiT model)'
  id: totrans-4609
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeiTConfig](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.DeiTConfig)
    配置类：[TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)（DeiT模型）'
- en: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    configuration class: [TFSwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForMaskedImageModeling)
    (Swin Transformer model)'
  id: totrans-4610
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SwinConfig](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.SwinConfig)
    配置类：[TFSwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForMaskedImageModeling)（Swin
    Transformer模型）'
- en: Instantiates one of the model classes of the library (with a masked image modeling
    head) from a configuration.
  id: totrans-4611
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有遮罩图像建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4612
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-4613
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE208]'
  id: totrans-4614
  prefs: []
  type: TYPE_PRE
  zh: '[PRE208]'
- en: '#### `from_pretrained`'
  id: totrans-4615
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4616
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE209]'
  id: totrans-4617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE209]'
- en: Parameters
  id: totrans-4618
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4620
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4621
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-4622
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch状态字典保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4625
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4626
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4627
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, defaults to `False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器字典，按协议或端点，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4639
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了配置`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4640
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a masked image modeling
    head) from a pretrained model.
  id: totrans-4641
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库的模型类之一（带有遮罩图像建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4642
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：
- en: '`deit` — [TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)
    (DeiT model)'
  id: totrans-4643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deit` — [TFDeiTForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/deit#transformers.TFDeiTForMaskedImageModeling)（DeiT模型）'
- en: '`swin` — [TFSwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForMaskedImageModeling)
    (Swin Transformer model)'
  id: totrans-4644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swin` — [TFSwinForMaskedImageModeling](/docs/transformers/v4.37.2/en/model_doc/swin#transformers.TFSwinForMaskedImageModeling)（Swin
    Transformer模型）'
- en: 'Examples:'
  id: totrans-4645
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE210]'
  id: totrans-4646
  prefs: []
  type: TYPE_PRE
  zh: '[PRE210]'
- en: AutoModelForObjectDetection
  id: totrans-4647
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForObjectDetection
- en: '### `class transformers.AutoModelForObjectDetection`'
  id: totrans-4648
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForObjectDetection`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1473)'
  id: totrans-4649
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1473)'
- en: '[PRE211]'
  id: totrans-4650
  prefs: []
  type: TYPE_PRE
  zh: '[PRE211]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a object detection head) when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4651
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库的模型类之一（带有对象检测头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4652
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接使用`__init__()`进行实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4653
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4654
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE212]'
  id: totrans-4655
  prefs: []
  type: TYPE_PRE
  zh: '[PRE212]'
- en: Parameters
  id: totrans-4656
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 选择要实例化的模型类基于配置类：'
- en: '[ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig)
    configuration class: [ConditionalDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection)
    (Conditional DETR model)'
  id: totrans-4658
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ConditionalDetrConfig](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig)
    配置类：[ConditionalDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection)（条件
    DETR 模型）'
- en: '[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)
    configuration class: [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)
    (Deformable DETR model)'
  id: totrans-4659
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeformableDetrConfig](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrConfig)
    配置类：[DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)（可变形
    DETR 模型）'
- en: '[DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)
    configuration class: [DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)
    (DETA model)'
  id: totrans-4660
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DetaConfig](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaConfig)
    配置类：[DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)（DETA
    模型）'
- en: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    configuration class: [DetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForObjectDetection)
    (DETR model)'
  id: totrans-4661
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    配置类：[DetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForObjectDetection)（DETR
    模型）'
- en: '[TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)
    configuration class: [TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)
    (Table Transformer model)'
  id: totrans-4662
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TableTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerConfig)
    配置类：[TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)（表格变换器模型）'
- en: '[YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)
    configuration class: [YolosForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosForObjectDetection)
    (YOLOS model)'
  id: totrans-4663
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YolosConfig](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosConfig)
    配置类：[YolosForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosForObjectDetection)（YOLOS
    模型）'
- en: Instantiates one of the model classes of the library (with a object detection
    head) from a configuration.
  id: totrans-4664
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库中的一个模型类（带有对象检测头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4665
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-4666
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE213]'
  id: totrans-4667
  prefs: []
  type: TYPE_PRE
  zh: '[PRE213]'
- en: '#### `from_pretrained`'
  id: totrans-4668
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4669
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE214]'
  id: totrans-4670
  prefs: []
  type: TYPE_PRE
  zh: '[PRE214]'
- en: Parameters
  id: totrans-4671
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4673
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，指向在 huggingface.co 模型仓库中托管的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4674
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-4675
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向 *tensorflow 索引检查点文件* 的路径或 url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将
    `from_tf` 设置为 `True`，并将配置对象作为 `config` 参数提供。使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch
    模型并加载 PyTorch 模型后，此加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）
    — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4678
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4679
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存模型，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4680
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-4681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-4682
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器字典，按协议或端点分组，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理将用于每个请求。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为
    `True`，并且您已阅读了代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，其行为有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4694
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给基础模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4695
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a object detection
    head) from a pretrained model.
  id: totrans-4696
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有对象检测头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4697
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性（作为参数传递或从`pretrained_model_name_or_path`加载（如果可能））选择的，或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来选择：
- en: '`conditional_detr` — [ConditionalDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection)
    (Conditional DETR model)'
  id: totrans-4698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conditional_detr` — [ConditionalDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection)（条件DETR模型）'
- en: '`deformable_detr` — [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)
    (Deformable DETR model)'
  id: totrans-4699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deformable_detr` — [DeformableDetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection)（可变形DETR模型）'
- en: '`deta` — [DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)
    (DETA model)'
  id: totrans-4700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deta` — [DetaForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/deta#transformers.DetaForObjectDetection)（DETA模型）'
- en: '`detr` — [DetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForObjectDetection)
    (DETR model)'
  id: totrans-4701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detr` — [DetrForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForObjectDetection)（DETR模型）'
- en: '`table-transformer` — [TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)
    (Table Transformer model)'
  id: totrans-4702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table-transformer` — [TableTransformerForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection)（表格变换器模型）'
- en: '`yolos` — [YolosForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosForObjectDetection)
    (YOLOS model)'
  id: totrans-4703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`yolos` — [YolosForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/yolos#transformers.YolosForObjectDetection)（YOLOS模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4704
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-4705
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE215]'
  id: totrans-4706
  prefs: []
  type: TYPE_PRE
  zh: '[PRE215]'
- en: AutoModelForImageSegmentation
  id: totrans-4707
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForImageSegmentation
- en: '### `class transformers.AutoModelForImageSegmentation`'
  id: totrans-4708
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForImageSegmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1439)'
  id: totrans-4709
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1439)'
- en: '[PRE216]'
  id: totrans-4710
  prefs: []
  type: TYPE_PRE
  zh: '[PRE216]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a image segmentation head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4711
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有图像分割头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4712
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4713
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4714
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE217]'
  id: totrans-4715
  prefs: []
  type: TYPE_PRE
  zh: '[PRE217]'
- en: Parameters
  id: totrans-4716
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 要实例化的模型类是根据配置类选择的：'
- en: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    configuration class: [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)
    (DETR model)'
  id: totrans-4718
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)配置类：[DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)（DETR模型）'
- en: Instantiates one of the model classes of the library (with a image segmentation
    head) from a configuration.
  id: totrans-4719
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库中的一个模型类（带有图像分割头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4720
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-4721
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE218]'
  id: totrans-4722
  prefs: []
  type: TYPE_PRE
  zh: '[PRE218]'
- en: '#### `from_pretrained`'
  id: totrans-4723
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4724
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE219]'
  id: totrans-4725
  prefs: []
  type: TYPE_PRE
  zh: '[PRE219]'
- en: Parameters
  id: totrans-4726
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4728
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库中。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4729
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-4730
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TensorFlow 索引检查点文件* 的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch
    模型并随后加载 PyTorch 模型要慢。'
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）
    — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4733
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4734
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4735
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-4736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*） — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-4737
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`，*可选*） — 下载预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`，*可选*） — 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含丢失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4749
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设所有相关的配置更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4750
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a image segmentation
    head) from a pretrained model.
  id: totrans-4751
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有图像分割头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4752
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`detr` — [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)
    (DETR model)'
  id: totrans-4753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detr` — [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)（DETR模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4754
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-4755
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE220]'
  id: totrans-4756
  prefs: []
  type: TYPE_PRE
  zh: '[PRE220]'
- en: AutoModelForImageToImage
  id: totrans-4757
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForImageToImage
- en: '### `class transformers.AutoModelForImageToImage`'
  id: totrans-4758
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForImageToImage`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1300)'
  id: totrans-4759
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1300)'
- en: '[PRE221]'
  id: totrans-4760
  prefs: []
  type: TYPE_PRE
  zh: '[PRE221]'
- en: AutoModelForSemanticSegmentation
  id: totrans-4761
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForSemanticSegmentation
- en: '### `class transformers.AutoModelForSemanticSegmentation`'
  id: totrans-4762
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForSemanticSegmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1446)'
  id: totrans-4763
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1446)'
- en: '[PRE222]'
  id: totrans-4764
  prefs: []
  type: TYPE_PRE
  zh: '[PRE222]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a semantic segmentation head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4765
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有语义分割头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4766
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4767
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4768
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE223]'
  id: totrans-4769
  prefs: []
  type: TYPE_PRE
  zh: '[PRE223]'
- en: Parameters
  id: totrans-4770
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    要实例化的模型类是根据配置类选择的：'
- en: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    configuration class: [BeitForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForSemanticSegmentation)
    (BEiT model)'
  id: totrans-4772
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BeitConfig](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitConfig)
    配置类：[BeitForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForSemanticSegmentation)（BEiT模型）'
- en: '[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    configuration class: [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)
    (DPT model)'
  id: totrans-4773
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DPTConfig](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTConfig)
    配置类：[DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)（DPT模型）'
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [Data2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation)
    (Data2VecVision model)'
  id: totrans-4774
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    配置类: [Data2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation)（Data2VecVision
    模型）'
- en: '[MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    configuration class: [MobileNetV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation)
    (MobileNetV2 model)'
  id: totrans-4775
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileNetV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config)
    配置类: [MobileNetV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation)（MobileNetV2
    模型）'
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [MobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation)
    (MobileViT model)'
  id: totrans-4776
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    配置类: [MobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation)（MobileViT
    模型）'
- en: '[MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    configuration class: [MobileViTV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForSemanticSegmentation)
    (MobileViTV2 model)'
  id: totrans-4777
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileViTV2Config](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2Config)
    配置类: [MobileViTV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForSemanticSegmentation)（MobileViTV2
    模型）'
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [SegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation)
    (SegFormer model)'
  id: totrans-4778
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    配置类: [SegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation)（SegFormer
    模型）'
- en: '[UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig)
    configuration class: [UperNetForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetForSemanticSegmentation)
    (UPerNet model)'
  id: totrans-4779
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UperNetConfig](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetConfig)
    配置类: [UperNetForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetForSemanticSegmentation)（UPerNet
    模型）'
- en: Instantiates one of the model classes of the library (with a semantic segmentation
    head) from a configuration.
  id: totrans-4780
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有语义分割头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4781
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：通过配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-4782
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE224]'
  id: totrans-4783
  prefs: []
  type: TYPE_PRE
  zh: '[PRE224]'
- en: '#### `from_pretrained`'
  id: totrans-4784
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4785
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE225]'
  id: totrans-4786
  prefs: []
  type: TYPE_PRE
  zh: '[PRE225]'
- en: Parameters
  id: totrans-4787
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str` 或 `os.PathLike`） — 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4789
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，一个托管在 huggingface.co 模型仓库中的预训练模型的 *模型id*。有效的模型id可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4790
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-4791
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个路径或url指向一个 *tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应该设置为 `True` 并且应该提供一个配置对象作为 `config` 参数。使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch 模型并在之后加载
    PyTorch 模型的加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）
    — 用于替代自动加载的配置的模型配置。当以下情况发生时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4794
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4795
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4796
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供一个本地目录作为 `pretrained_model_name_or_path` 并且在目录中找到一个名为 *config.json* 的配置
    JSON 文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-4797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 要使用的状态字典，而不是从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-4798
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, 默认为 `"main"`) — 在 Hub 上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*optional*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4810
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4811
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个与配置属性对应的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a semantic segmentation
    head) from a pretrained model.
  id: totrans-4812
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有语义分割头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4813
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退到：
- en: '`beit` — [BeitForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForSemanticSegmentation)
    (BEiT model)'
  id: totrans-4814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beit` - [BeitForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/beit#transformers.BeitForSemanticSegmentation)（BEiT模型）'
- en: '`data2vec-vision` — [Data2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation)
    (Data2VecVision model)'
  id: totrans-4815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-vision` - [Data2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation)（Data2VecVision模型）'
- en: '`dpt` — [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)
    (DPT model)'
  id: totrans-4816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dpt` - [DPTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/dpt#transformers.DPTForSemanticSegmentation)（DPT模型）'
- en: '`mobilenet_v2` — [MobileNetV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation)
    (MobileNetV2 model)'
  id: totrans-4817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilenet_v2` - [MobileNetV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation)（MobileNetV2模型）'
- en: '`mobilevit` — [MobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation)
    (MobileViT model)'
  id: totrans-4818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevit` - [MobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation)（MobileViT模型）'
- en: '`mobilevitv2` — [MobileViTV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForSemanticSegmentation)
    (MobileViTV2 model)'
  id: totrans-4819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevitv2` - [MobileViTV2ForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevitv2#transformers.MobileViTV2ForSemanticSegmentation)（MobileViTV2模型）'
- en: '`segformer` — [SegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation)
    (SegFormer model)'
  id: totrans-4820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segformer` - [SegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation)（SegFormer模型）'
- en: '`upernet` — [UperNetForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetForSemanticSegmentation)
    (UPerNet model)'
  id: totrans-4821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upernet` - [UperNetForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/upernet#transformers.UperNetForSemanticSegmentation)（UPerNet模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4822
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-4823
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE226]'
  id: totrans-4824
  prefs: []
  type: TYPE_PRE
  zh: '[PRE226]'
- en: TFAutoModelForSemanticSegmentation
  id: totrans-4825
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForSemanticSegmentation
- en: '### `class transformers.TFAutoModelForSemanticSegmentation`'
  id: totrans-4826
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForSemanticSegmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L596)'
  id: totrans-4827
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L596)'
- en: '[PRE227]'
  id: totrans-4828
  prefs: []
  type: TYPE_PRE
  zh: '[PRE227]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a semantic segmentation head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4829
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将实例化为库的模型类之一（带有语义分割头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4830
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4831
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4832
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE228]'
  id: totrans-4833
  prefs: []
  type: TYPE_PRE
  zh: '[PRE228]'
- en: Parameters
  id: totrans-4834
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4835
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）-
    选择要实例化的模型类基于配置类：'
- en: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)
    configuration class: [TFData2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation)
    (Data2VecVision model)'
  id: totrans-4836
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecVisionConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecVisionConfig)配置类：[TFData2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation)（Data2VecVision模型）'
- en: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)
    configuration class: [TFMobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation)
    (MobileViT model)'
  id: totrans-4837
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MobileViTConfig](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.MobileViTConfig)配置类：[TFMobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation)（MobileViT模型）'
- en: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)
    configuration class: [TFSegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation)
    (SegFormer model)'
  id: totrans-4838
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SegformerConfig](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.SegformerConfig)配置类：[TFSegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation)（SegFormer模型）'
- en: Instantiates one of the model classes of the library (with a semantic segmentation
    head) from a configuration.
  id: totrans-4839
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库的模型类之一（带有语义分割头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4840
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-4841
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE229]'
  id: totrans-4842
  prefs: []
  type: TYPE_PRE
  zh: '[PRE229]'
- en: '#### `from_pretrained`'
  id: totrans-4843
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4844
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE230]'
  id: totrans-4845
  prefs: []
  type: TYPE_PRE
  zh: '[PRE230]'
- en: Parameters
  id: totrans-4846
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4848
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串，托管在huggingface.co模型存储库内的预训练模型的*model id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4849
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-4850
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或url到*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并加载TensorFlow模型后，此加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4853
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是由库提供的模型（使用预训练模型的*model id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4854
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4855
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 下载预训练模型配置的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *optional*, defaults to `False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器字典，按协议或端点，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型在其自己的建模文件中。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4867
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设所有相关的配置更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4868
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a semantic segmentation
    head) from a pretrained model.
  id: totrans-4869
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有语义分割头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4870
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`data2vec-vision` — [TFData2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation)
    (Data2VecVision model)'
  id: totrans-4871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-vision` — [TFData2VecVisionForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation)（Data2VecVision模型）'
- en: '`mobilevit` — [TFMobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation)
    (MobileViT model)'
  id: totrans-4872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobilevit` — [TFMobileViTForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation)（MobileViT模型）'
- en: '`segformer` — [TFSegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation)
    (SegFormer model)'
  id: totrans-4873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segformer` — [TFSegformerForSemanticSegmentation](/docs/transformers/v4.37.2/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation)（SegFormer模型）'
- en: 'Examples:'
  id: totrans-4874
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE231]'
  id: totrans-4875
  prefs: []
  type: TYPE_PRE
  zh: '[PRE231]'
- en: AutoModelForInstanceSegmentation
  id: totrans-4876
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实例分割的自动模型
- en: '### `class transformers.AutoModelForInstanceSegmentation`'
  id: totrans-4877
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForInstanceSegmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1464)'
  id: totrans-4878
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1464)'
- en: '[PRE232]'
  id: totrans-4879
  prefs: []
  type: TYPE_PRE
  zh: '[PRE232]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a instance segmentation head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4880
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库中的一个模型类（带有实例分割头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4881
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4882
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4883
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE233]'
  id: totrans-4884
  prefs: []
  type: TYPE_PRE
  zh: '[PRE233]'
- en: Parameters
  id: totrans-4885
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4886
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    要实例化的模型类是根据配置类选择的：'
- en: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    configuration class: [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    (MaskFormer model)'
  id: totrans-4887
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)配置类：[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)（MaskFormer模型）'
- en: Instantiates one of the model classes of the library (with a instance segmentation
    head) from a configuration.
  id: totrans-4888
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的模型类（带有实例分割头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4889
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-4890
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE234]'
  id: totrans-4891
  prefs: []
  type: TYPE_PRE
  zh: '[PRE234]'
- en: '#### `from_pretrained`'
  id: totrans-4892
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4893
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE235]'
  id: totrans-4894
  prefs: []
  type: TYPE_PRE
  zh: '[PRE235]'
- en: Parameters
  id: totrans-4895
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4897
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在 huggingface.co 上的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4898
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-4899
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TensorFlow 索引检查点文件* 的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将 `from_tf`
    设置为 `True`，并将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch
    模型并随后加载 PyTorch 模型要慢。'
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4900
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 模型使用的配置，而不是自动加载的配置。当以下情况自动加载配置时：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4902
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4903
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4904
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-4905
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*, *optional*） — 用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-4906
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4907
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow checkpoint
    保存文件加载模型权重（请参阅 `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4910
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 用于每个请求的代理服务器的协议或端点的字典，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info` (`bool`, *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4913
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`）- 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4914
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4915
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的建模文件。此选项应仅在您信任的存储库中设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）- 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载了`config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4918
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4919
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a instance segmentation
    head) from a pretrained model.
  id: totrans-4920
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库中的模型类之一（带有实例分割头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4921
  prefs: []
  type: TYPE_NORMAL
  zh: 选择要实例化的模型类基于配置对象的`model_type`属性（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`maskformer` — [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    (MaskFormer model)'
  id: totrans-4922
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maskformer` - [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)（MaskFormer模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4923
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。
- en: 'Examples:'
  id: totrans-4924
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE236]'
  id: totrans-4925
  prefs: []
  type: TYPE_PRE
  zh: '[PRE236]'
- en: AutoModelForUniversalSegmentation
  id: totrans-4926
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForUniversalSegmentation
- en: '### `class transformers.AutoModelForUniversalSegmentation`'
  id: totrans-4927
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForUniversalSegmentation`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1455)'
  id: totrans-4928
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1455)'
- en: '[PRE237]'
  id: totrans-4929
  prefs: []
  type: TYPE_PRE
  zh: '[PRE237]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a universal image segmentation head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4930
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将作为库中的模型类之一实例化（带有通用图像分割头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4931
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4932
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4933
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE238]'
  id: totrans-4934
  prefs: []
  type: TYPE_PRE
  zh: '[PRE238]'
- en: Parameters
  id: totrans-4935
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4936
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）-
    选择要实例化的模型类基于配置类：'
- en: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)
    configuration class: [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)
    (DETR model)'
  id: totrans-4937
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DetrConfig](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrConfig)配置类：[DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)（DETR模型）'
- en: '[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)
    configuration class: [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)
    (Mask2Former model)'
  id: totrans-4938
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mask2FormerConfig](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerConfig)配置类：[Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)（Mask2Former模型）'
- en: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)
    configuration class: [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    (MaskFormer model)'
  id: totrans-4939
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MaskFormerConfig](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerConfig)配置类：[MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)（MaskFormer模型）'
- en: '[OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)
    configuration class: [OneFormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerForUniversalSegmentation)
    (OneFormer model)'
  id: totrans-4940
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OneFormerConfig](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerConfig)配置类：[OneFormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerForUniversalSegmentation)（OneFormer模型）'
- en: Instantiates one of the model classes of the library (with a universal image
    segmentation head) from a configuration.
  id: totrans-4941
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有通用图像分割头）时自动加载配置。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-4942
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-4943
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE239]'
  id: totrans-4944
  prefs: []
  type: TYPE_PRE
  zh: '[PRE239]'
- en: '#### `from_pretrained`'
  id: totrans-4945
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-4946
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE240]'
  id: totrans-4947
  prefs: []
  type: TYPE_PRE
  zh: '[PRE240]'
- en: Parameters
  id: totrans-4948
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-4949
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）—可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-4950
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-4951
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-4952
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个路径或URL指向一个*tensorflow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该提供一个配置对象作为`config`参数。使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型之后，这种加载路径比较慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-4953
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）—将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-4954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—要使用的模型配置，而不是自动加载的配置。当：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-4955
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-4956
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-4957
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供一个本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-4958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）—要使用的状态字典，而不是从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-4959
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建一个模型，但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否是一个更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-4960
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）- 如果不使用标准缓存，可以用于缓存下载的预训练模型配置的目录路径。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-4961
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`）- 从 TensorFlow 检查点保存文件中加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-4962
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）- 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-4963
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）- 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-4964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）- 要使用的代理服务器的协议或端点的字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理将在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-4965
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) - 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-4966
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) - 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-4967
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在 huggingface.co
    上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-4968
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行
    Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-4969
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）- 用于 Hub 上代码的特定修订版，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以`revision`可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-4970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载的情况，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-4971
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有`config`的配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-4972
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a universal image
    segmentation head) from a pretrained model.
  id: totrans-4973
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有通用图像分割头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-4974
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：
- en: '`detr` — [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)
    (DETR model)'
  id: totrans-4975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detr` - [DetrForSegmentation](/docs/transformers/v4.37.2/en/model_doc/detr#transformers.DetrForSegmentation)（DETR
    模型）'
- en: '`mask2former` — [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)
    (Mask2Former model)'
  id: totrans-4976
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask2former` - [Mask2FormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/mask2former#transformers.Mask2FormerForUniversalSegmentation)（Mask2Former
    模型）'
- en: '`maskformer` — [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)
    (MaskFormer model)'
  id: totrans-4977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maskformer` — [MaskFormerForInstanceSegmentation](/docs/transformers/v4.37.2/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation)（MaskFormer模型）'
- en: '`oneformer` — [OneFormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerForUniversalSegmentation)
    (OneFormer model)'
  id: totrans-4978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oneformer` — [OneFormerForUniversalSegmentation](/docs/transformers/v4.37.2/en/model_doc/oneformer#transformers.OneFormerForUniversalSegmentation)（OneFormer模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-4979
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用 `model.eval()` 将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式。
- en: 'Examples:'
  id: totrans-4980
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE241]'
  id: totrans-4981
  prefs: []
  type: TYPE_PRE
  zh: '[PRE241]'
- en: AutoModelForZeroShotImageClassification
  id: totrans-4982
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForZeroShotImageClassification
- en: '### `class transformers.AutoModelForZeroShotImageClassification`'
  id: totrans-4983
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForZeroShotImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1430)'
  id: totrans-4984
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1430)'
- en: '[PRE242]'
  id: totrans-4985
  prefs: []
  type: TYPE_PRE
  zh: '[PRE242]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a zero-shot image classification head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-4986
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，在使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将作为库中的模型类之一实例化（带有零样本图像分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-4987
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-4988
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-4989
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE243]'
  id: totrans-4990
  prefs: []
  type: TYPE_PRE
  zh: '[PRE243]'
- en: Parameters
  id: totrans-4991
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-4992
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    实例化的模型类基于配置类选择：'
- en: '[AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)
    configuration class: [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN model)'
  id: totrans-4993
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AlignConfig](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignConfig)
    配置类：[AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)（ALIGN模型）'
- en: '[AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)
    configuration class: [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP model)'
  id: totrans-4994
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AltCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPConfig)
    配置类：[AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)（AltCLIP模型）'
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP model)'
  id: totrans-4995
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    配置类：[BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)（BLIP模型）'
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP model)'
  id: totrans-4996
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    配置类：[CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)（CLIP模型）'
- en: '[CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig)
    configuration class: [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg model)'
  id: totrans-4997
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CLIPSegConfig](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegConfig)
    配置类：[CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)（CLIPSeg模型）'
- en: '[ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig)
    configuration class: [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP model)'
  id: totrans-4998
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChineseCLIPConfig](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPConfig)
    配置类：[ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)（中文-CLIP模型）'
- en: '[SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig)
    configuration class: [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP model)'
  id: totrans-4999
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SiglipConfig](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipConfig)
    配置类：[SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)（SigLIP模型）'
- en: Instantiates one of the model classes of the library (with a zero-shot image
    classification head) from a configuration.
  id: totrans-5000
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的模型类之一（带有零样本图像分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5001
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-5002
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE244]'
  id: totrans-5003
  prefs: []
  type: TYPE_PRE
  zh: '[PRE244]'
- en: '#### `from_pretrained`'
  id: totrans-5004
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5005
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE245]'
  id: totrans-5006
  prefs: []
  type: TYPE_PRE
  zh: '[PRE245]'
- en: Parameters
  id: totrans-5007
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str` 或 `os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5009
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *模型 ID*，托管在 huggingface.co 上的模型仓库中。有效的模型 ID 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下进行命名空间，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5010
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 路径，例如 `./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5011
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *tensorflow 索引检查点文件* 的路径或 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应设置为 `True`，并且应提供配置对象作为 `config` 参数。使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch
    模型并加载 PyTorch 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5014
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5015
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5016
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5018
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不想使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 要使用的代理服务器字典，按协议或端点，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, 默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在
    huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任并且已阅读代码的存储库设置为`True`，因为它将在本地计算机上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 代码在Hub上使用的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5030
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5031
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个键对应于配置属性，将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a zero-shot image
    classification head) from a pretrained model.
  id: totrans-5032
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有零样本图像分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5033
  prefs: []
  type: TYPE_NORMAL
  zh: 将要实例化的模型类基于配置对象的`model_type`属性选择（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`align` — [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)
    (ALIGN model)'
  id: totrans-5034
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`align` — [AlignModel](/docs/transformers/v4.37.2/en/model_doc/align#transformers.AlignModel)（ALIGN模型）'
- en: '`altclip` — [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)
    (AltCLIP model)'
  id: totrans-5035
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`altclip` — [AltCLIPModel](/docs/transformers/v4.37.2/en/model_doc/altclip#transformers.AltCLIPModel)（AltCLIP模型）'
- en: '`blip` — [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)
    (BLIP model)'
  id: totrans-5036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [BlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipModel)（BLIP模型）'
- en: '`chinese_clip` — [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)
    (Chinese-CLIP model)'
  id: totrans-5037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chinese_clip` — [ChineseCLIPModel](/docs/transformers/v4.37.2/en/model_doc/chinese_clip#transformers.ChineseCLIPModel)（Chinese-CLIP模型）'
- en: '`clip` — [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)
    (CLIP model)'
  id: totrans-5038
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [CLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPModel)（CLIP模型）'
- en: '`clipseg` — [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)
    (CLIPSeg model)'
  id: totrans-5039
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clipseg` — [CLIPSegModel](/docs/transformers/v4.37.2/en/model_doc/clipseg#transformers.CLIPSegModel)（CLIPSeg模型）'
- en: '`siglip` — [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)
    (SigLIP model)'
  id: totrans-5040
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`siglip` — [SiglipModel](/docs/transformers/v4.37.2/en/model_doc/siglip#transformers.SiglipModel)（SigLIP模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5041
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型以评估模式设置，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。
- en: 'Examples:'
  id: totrans-5042
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE246]'
  id: totrans-5043
  prefs: []
  type: TYPE_PRE
  zh: '[PRE246]'
- en: TFAutoModelForZeroShotImageClassification
  id: totrans-5044
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForZeroShotImageClassification
- en: '### `class transformers.TFAutoModelForZeroShotImageClassification`'
  id: totrans-5045
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForZeroShotImageClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L587)'
  id: totrans-5046
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L587)'
- en: '[PRE247]'
  id: totrans-5047
  prefs: []
  type: TYPE_PRE
  zh: '[PRE247]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a zero-shot image classification head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5048
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将实例化为库中的模型类之一（带有零样本图像分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5049
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5050
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5051
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE248]'
  id: totrans-5052
  prefs: []
  type: TYPE_PRE
  zh: '[PRE248]'
- en: Parameters
  id: totrans-5053
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    选择要实例化的模型类基于配置类：'
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP model)'
  id: totrans-5055
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)配置类：[TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)（BLIP模型）'
- en: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)
    configuration class: [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP model)'
  id: totrans-5056
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CLIPConfig](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPConfig)配置类：[TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)（CLIP模型）'
- en: Instantiates one of the model classes of the library (with a zero-shot image
    classification head) from a configuration.
  id: totrans-5057
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有零射击图像分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5058
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-5059
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE249]'
  id: totrans-5060
  prefs: []
  type: TYPE_PRE
  zh: '[PRE249]'
- en: '#### `from_pretrained`'
  id: totrans-5061
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5062
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE250]'
  id: totrans-5063
  prefs: []
  type: TYPE_PRE
  zh: '[PRE250]'
- en: Parameters
  id: totrans-5064
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5065
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5066
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，指向huggingface.co模型库中托管的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5067
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-5068
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个路径或URL指向一个*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供一个配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并在之后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5069
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5070
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    用于模型的配置而不是自动加载的配置。当以下情况时可以自动加载配置：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5071
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5072
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5073
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为*config.json*的配置JSON文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5074
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5075
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5076
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5077
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5079
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5080
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5081
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5082
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5083
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载
    `config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5085
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有 `config` 的配置，`**kwargs` 将直接传递给基础模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5086
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    中与配置属性对应的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a zero-shot image
    classification head) from a pretrained model.
  id: totrans-5087
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有零样本图像分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5088
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（作为参数传递或从 `pretrained_model_name_or_path`
    加载，如果可能的话），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`blip` — [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP model)'
  id: totrans-5089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [TFBlipModel](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipModel)
    (BLIP 模型)'
- en: '`clip` — [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP model)'
  id: totrans-5090
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip` — [TFCLIPModel](/docs/transformers/v4.37.2/en/model_doc/clip#transformers.TFCLIPModel)
    (CLIP 模型)'
- en: 'Examples:'
  id: totrans-5091
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE251]'
  id: totrans-5092
  prefs: []
  type: TYPE_PRE
  zh: '[PRE251]'
- en: AutoModelForZeroShotObjectDetection
  id: totrans-5093
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForZeroShotObjectDetection
- en: '### `class transformers.AutoModelForZeroShotObjectDetection`'
  id: totrans-5094
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForZeroShotObjectDetection`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1480)'
  id: totrans-5095
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1480)'
- en: '[PRE252]'
  id: totrans-5096
  prefs: []
  type: TYPE_PRE
  zh: '[PRE252]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a zero-shot object detection head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5097
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将实例化库中的一个模型类（带有零样本目标检测头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5098
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5099
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5100
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE253]'
  id: totrans-5101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE253]'
- en: Parameters
  id: totrans-5102
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    选择要实例化的模型类基于配置类：'
- en: '[OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)
    configuration class: [OwlViTForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTForObjectDetection)
    (OWL-ViT model)'
  id: totrans-5104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OwlViTConfig](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTConfig)配置类：[OwlViTForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTForObjectDetection)（OWL-ViT模型）'
- en: '[Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)
    configuration class: [Owlv2ForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ForObjectDetection)
    (OWLv2 model)'
  id: totrans-5105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Owlv2Config](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2Config)配置类：[Owlv2ForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ForObjectDetection)（OWLv2模型）'
- en: Instantiates one of the model classes of the library (with a zero-shot object
    detection head) from a configuration.
  id: totrans-5106
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的模型类（带有零射击目标检测头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5107
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-5108
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE254]'
  id: totrans-5109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE254]'
- en: '#### `from_pretrained`'
  id: totrans-5110
  prefs: []
  type: TYPE_NORMAL
  zh: '`from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5111
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE255]'
  id: totrans-5112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE255]'
- en: Parameters
  id: totrans-5113
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个路径或url到*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`）— 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）- 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）- 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）- 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`）- 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`）- 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）- 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）- 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）- 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）- 可用于更新配置对象（在加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有`config`的配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a zero-shot object
    detection head) from a pretrained model.
  id: totrans-5138
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有零样本目标检测头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5139
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：
- en: '`owlv2` — [Owlv2ForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ForObjectDetection)
    (OWLv2 model)'
  id: totrans-5140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlv2` - [Owlv2ForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlv2#transformers.Owlv2ForObjectDetection)（OWLv2模型）'
- en: '`owlvit` — [OwlViTForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTForObjectDetection)
    (OWL-ViT model)'
  id: totrans-5141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`owlvit` - [OwlViTForObjectDetection](/docs/transformers/v4.37.2/en/model_doc/owlvit#transformers.OwlViTForObjectDetection)（OWL-ViT模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5142
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型以评估模式设置，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-5143
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE256]'
  id: totrans-5144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE256]'
- en: Audio
  id: totrans-5145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音频
- en: The following auto classes are available for the following audio tasks.
  id: totrans-5146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下自动类适用于以下音频任务。
- en: AutoModelForAudioClassification
  id: totrans-5147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForAudioClassification
- en: '### `class transformers.AutoModelForAudioClassification`'
  id: totrans-5148
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForAudioClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1510)'
  id: totrans-5149
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1510)'
- en: '[PRE257]'
  id: totrans-5150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE257]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a audio classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5151
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有音频分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5152
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5153
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5154
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE258]'
  id: totrans-5155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE258]'
- en: Parameters
  id: totrans-5156
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类：'
- en: '[ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)
    configuration class: [ASTForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTForAudioClassification)
    (Audio Spectrogram Transformer model)'
  id: totrans-5158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ASTConfig](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig)
    配置类: [ASTForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTForAudioClassification)
    (音频频谱变换器模型)'
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification)
    (Data2VecAudio model)'
  id: totrans-5159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    配置类: [Data2VecAudioForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification)
    (Data2VecAudio 模型)'
- en: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    configuration class: [HubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForSequenceClassification)
    (Hubert model)'
  id: totrans-5160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    配置类: [HubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForSequenceClassification)
    (Hubert 模型)'
- en: '[SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    configuration class: [SEWForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForSequenceClassification)
    (SEW model)'
  id: totrans-5161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    配置类: [SEWForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForSequenceClassification)
    (SEW 模型)'
- en: '[SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    configuration class: [SEWDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification)
    (SEW-D model)'
  id: totrans-5162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    配置类: [SEWDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification)
    (SEW-D 模型)'
- en: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    configuration class: [UniSpeechForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification)
    (UniSpeech model)'
  id: totrans-5163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    配置类: [UniSpeechForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification)
    (UniSpeech 模型)'
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification)
    (UniSpeechSat model)'
  id: totrans-5164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    配置类: [UniSpeechSatForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification)
    (UniSpeechSat 模型)'
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForSequenceClassification)
    (Wav2Vec2-BERT model)'
  id: totrans-5165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    配置类: [Wav2Vec2BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForSequenceClassification)
    (Wav2Vec2-BERT 模型)'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)
    (Wav2Vec2 model)'
  id: totrans-5166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类: [Wav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)
    (Wav2Vec2 模型)'
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification)
    (Wav2Vec2-Conformer model)'
  id: totrans-5167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    配置类: [Wav2Vec2ConformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification)
    (Wav2Vec2-Conformer 模型)'
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification)
    (WavLM model)'
  id: totrans-5168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    配置类：[WavLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification)（WavLM模型）'
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)
    (Whisper model)'
  id: totrans-5169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    配置类：[WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)（Whisper模型）'
- en: Instantiates one of the model classes of the library (with a audio classification
    head) from a configuration.
  id: totrans-5170
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有音频分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5171
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-5172
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE259]'
  id: totrans-5173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE259]'
- en: '#### `from_pretrained`'
  id: totrans-5174
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5175
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE260]'
  id: totrans-5176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE260]'
- en: Parameters
  id: totrans-5177
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，huggingface.co上托管的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*TensorFlow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该提供一个配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*optional*）
    — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`和在该目录中找到名为*config.json*的配置JSON文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建一个模型，但加载自己的权重，可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是一个更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 预训练模型配置文件应该被缓存的目录路径，如果不想使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*optional*，默认为`False`） — 从TensorFlow检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*optional*，默认为`False`） — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为 `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们在
    huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, 默认为 `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了配置 `config`，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则首先将 `kwargs` 传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的
    `kwargs` 的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a audio classification
    head) from a pretrained model.
  id: totrans-5202
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有音频分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5203
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`audio-spectrogram-transformer` — [ASTForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTForAudioClassification)
    (Audio Spectrogram Transformer model)'
  id: totrans-5204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio-spectrogram-transformer` — [ASTForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/audio-spectrogram-transformer#transformers.ASTForAudioClassification)
    (音频频谱变换器模型)'
- en: '`data2vec-audio` — [Data2VecAudioForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification)
    (Data2VecAudio model)'
  id: totrans-5205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-audio` — [Data2VecAudioForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification)
    (Data2VecAudio 模型)'
- en: '`hubert` — [HubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForSequenceClassification)
    (Hubert model)'
  id: totrans-5206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hubert` — [HubertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForSequenceClassification)
    (Hubert 模型)'
- en: '`sew` — [SEWForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForSequenceClassification)
    (SEW model)'
  id: totrans-5207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew` — [SEWForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForSequenceClassification)
    (SEW 模型)'
- en: '`sew-d` — [SEWDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification)
    (SEW-D model)'
  id: totrans-5208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew-d` — [SEWDForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForSequenceClassification)
    (SEW-D 模型)'
- en: '`unispeech` — [UniSpeechForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification)
    (UniSpeech model)'
  id: totrans-5209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech` — [UniSpeechForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification)
    (UniSpeech 模型)'
- en: '`unispeech-sat` — [UniSpeechSatForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification)
    (UniSpeechSat model)'
  id: totrans-5210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech-sat` — [UniSpeechSatForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification)
    (UniSpeechSat 模型)'
- en: '`wav2vec2` — [Wav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)
    (Wav2Vec2 model)'
  id: totrans-5211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification)
    (Wav2Vec2 模型)'
- en: '`wav2vec2-bert` — [Wav2Vec2BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForSequenceClassification)
    (Wav2Vec2-BERT model)'
  id: totrans-5212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-bert` — [Wav2Vec2BertForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForSequenceClassification)
    (Wav2Vec2-BERT 模型)'
- en: '`wav2vec2-conformer` — [Wav2Vec2ConformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification)
    (Wav2Vec2-Conformer model)'
  id: totrans-5213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2ConformerForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification)
    (Wav2Vec2-Conformer 模型)'
- en: '`wavlm` — [WavLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification)
    (WavLM model)'
  id: totrans-5214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wavlm` — [WavLMForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForSequenceClassification)
    (WavLM 模型)'
- en: '`whisper` — [WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)
    (Whisper model)'
  id: totrans-5215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)
    (Whisper 模型)'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5216
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，该模型被设置为评估模式，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-5217
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE261]'
  id: totrans-5218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE261]'
- en: AutoModelForAudioFrameClassification
  id: totrans-5219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForAudioFrameClassification
- en: '### `class transformers.TFAutoModelForAudioClassification`'
  id: totrans-5220
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForAudioClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L538)'
  id: totrans-5221
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L538)'
- en: '[PRE262]'
  id: totrans-5222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE262]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a audio classification head) when created with the
    [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5223
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的模型类（带有音频分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5224
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5225
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5226
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE263]'
  id: totrans-5227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE263]'
- en: Parameters
  id: totrans-5228
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类：'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [TFWav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2ForSequenceClassification)
    (Wav2Vec2 model)'
  id: totrans-5230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类：[TFWav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2ForSequenceClassification)
    (Wav2Vec2 模型)'
- en: Instantiates one of the model classes of the library (with a audio classification
    head) from a configuration.
  id: totrans-5231
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库中的一个模型类（带有音频分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5232
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型 **不会** 加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-5233
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE264]'
  id: totrans-5234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE264]'
- en: '#### `from_pretrained`'
  id: totrans-5235
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5236
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE265]'
  id: totrans-5237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE265]'
- en: Parameters
  id: totrans-5238
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型存储库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如 `./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-5242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或URL到*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选的*） — 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *可选的*) — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是由库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5247
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *可选的*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *可选的*，默认为`False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选的*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选的*，默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *可选的*) — 要使用的代理服务器字典，按协议或端点，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选的*，默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选的*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选的*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *可选的*，默认为`False`) — 是否允许在Hub上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *可选的*，默认为`"main"`) — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选的*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5260
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    中对应配置属性的每个键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a audio classification
    head) from a pretrained model.
  id: totrans-5261
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库中的一个模型类（带有音频分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5262
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化的模型类是根据配置对象的 `model_type` 属性选择的（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺失时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退：
- en: '`wav2vec2` — [TFWav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2ForSequenceClassification)
    (Wav2Vec2 model)'
  id: totrans-5263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` - [TFWav2Vec2ForSequenceClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.TFWav2Vec2ForSequenceClassification)（Wav2Vec2
    模型）'
- en: 'Examples:'
  id: totrans-5264
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE266]'
  id: totrans-5265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE266]'
- en: TFAutoModelForAudioFrameClassification
  id: totrans-5266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForAudioFrameClassification
- en: '### `class transformers.AutoModelForAudioFrameClassification`'
  id: totrans-5267
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForAudioFrameClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1533)'
  id: totrans-5268
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1533)'
- en: '[PRE267]'
  id: totrans-5269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE267]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a audio frame (token) classification head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5270
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将实例化为库中的一个模型类（带有音频帧（标记）分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5271
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5272
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5273
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE268]'
  id: totrans-5274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE268]'
- en: Parameters
  id: totrans-5275
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）-
    实例化的模型类是根据配置类选择的：'
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification)
    (Data2VecAudio model)'
  id: totrans-5277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    配置类：[Data2VecAudioForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification)（Data2VecAudio
    模型）'
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification)
    (UniSpeechSat model)'
  id: totrans-5278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    配置类：[UniSpeechSatForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification)（UniSpeechSat
    模型）'
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForAudioFrameClassification)
    (Wav2Vec2-BERT model)'
  id: totrans-5279
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    配置类：[Wav2Vec2BertForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForAudioFrameClassification)（Wav2Vec2-BERT
    模型）'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification)
    (Wav2Vec2 model)'
  id: totrans-5280
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类：[Wav2Vec2ForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification)（Wav2Vec2
    模型）'
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification)
    (Wav2Vec2-Conformer model)'
  id: totrans-5281
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    配置类：[Wav2Vec2ConformerForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification)（Wav2Vec2-Conformer
    模型）'
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification)
    (WavLM model)'
  id: totrans-5282
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    配置类：[WavLMForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification)（WavLM
    模型）'
- en: Instantiates one of the model classes of the library (with a audio frame (token)
    classification head) from a configuration.
  id: totrans-5283
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有音频帧（令牌）分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5284
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从其配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-5285
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE269]'
  id: totrans-5286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE269]'
- en: '#### `from_pretrained`'
  id: totrans-5287
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5288
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE270]'
  id: totrans-5289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE270]'
- en: Parameters
  id: totrans-5290
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）—可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型ID*，托管在huggingface.co上的模型存储库内。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*TensorFlow索引检查点文件*的路径或URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将`from_tf`设置为`True`，并将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并随后加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）—将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—模型使用的配置，而不是自动加载的配置。当以下情况时，可以自动加载配置：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5297
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5298
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5299
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）—要使用的状态字典，而不是从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）—应在其中缓存下载的预训练模型配置的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`）—从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）—是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）—是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）—要使用的代理服务器字典，按协议或端点，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 代码在Hub上使用的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了配置`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5314
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a audio frame (token)
    classification head) from a pretrained model.
  id: totrans-5315
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有音频帧（标记）分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5316
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`data2vec-audio` — [Data2VecAudioForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification)
    (Data2VecAudio model)'
  id: totrans-5317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-audio` — [Data2VecAudioForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification)（Data2VecAudio模型）'
- en: '`unispeech-sat` — [UniSpeechSatForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification)
    (UniSpeechSat model)'
  id: totrans-5318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech-sat` — [UniSpeechSatForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification)（UniSpeechSat模型）'
- en: '`wav2vec2` — [Wav2Vec2ForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification)
    (Wav2Vec2 model)'
  id: totrans-5319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2ForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification)（Wav2Vec2模型）'
- en: '`wav2vec2-bert` — [Wav2Vec2BertForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForAudioFrameClassification)
    (Wav2Vec2-BERT model)'
  id: totrans-5320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-bert` — [Wav2Vec2BertForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForAudioFrameClassification)（Wav2Vec2-BERT模型）'
- en: '`wav2vec2-conformer` — [Wav2Vec2ConformerForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification)
    (Wav2Vec2-Conformer model)'
  id: totrans-5321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2ConformerForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification)（Wav2Vec2-Conformer模型）'
- en: '`wavlm` — [WavLMForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification)
    (WavLM model)'
  id: totrans-5322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wavlm` — [WavLMForAudioFrameClassification](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification)（WavLM模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5323
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，该模型以评估模式设置，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-5324
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE271]'
  id: totrans-5325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE271]'
- en: AutoModelForCTC
  id: totrans-5326
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForCTC
- en: '### `class transformers.AutoModelForCTC`'
  id: totrans-5327
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForCTC`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1517)'
  id: totrans-5328
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1517)'
- en: '[PRE272]'
  id: totrans-5329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE272]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a connectionist temporal classification head) when
    created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5330
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将作为库中的一个模型类实例化（带有连接主义时间分类头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5331
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5332
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5333
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE273]'
  id: totrans-5334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE273]'
- en: Parameters
  id: totrans-5335
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类：'
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioForCTC](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForCTC)
    (Data2VecAudio model)'
  id: totrans-5337
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    配置类：[Data2VecAudioForCTC](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForCTC)（Data2VecAudio
    模型）'
- en: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    configuration class: [HubertForCTC](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForCTC)
    (Hubert model)'
  id: totrans-5338
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HubertConfig](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertConfig)
    配置类：[HubertForCTC](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForCTC)（Hubert
    模型）'
- en: '[MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)
    configuration class: [MCTCTForCTC](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTForCTC)
    (M-CTC-T model)'
  id: totrans-5339
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MCTCTConfig](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTConfig)
    配置类：[MCTCTForCTC](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTForCTC)（M-CTC-T
    模型）'
- en: '[SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    configuration class: [SEWForCTC](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForCTC)
    (SEW model)'
  id: totrans-5340
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SEWConfig](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWConfig)
    配置类：[SEWForCTC](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForCTC)（SEW
    模型）'
- en: '[SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    configuration class: [SEWDForCTC](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForCTC)
    (SEW-D model)'
  id: totrans-5341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SEWDConfig](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDConfig)
    配置类：[SEWDForCTC](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForCTC)（SEW-D
    模型）'
- en: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    configuration class: [UniSpeechForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForCTC)
    (UniSpeech model)'
  id: totrans-5342
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechConfig)
    配置类：[UniSpeechForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForCTC)（UniSpeech
    模型）'
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC)
    (UniSpeechSat model)'
  id: totrans-5343
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    配置类：[UniSpeechSatForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC)（UniSpeechSat
    模型）'
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForCTC)
    (Wav2Vec2-BERT model)'
  id: totrans-5344
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    配置类：[Wav2Vec2BertForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForCTC)（Wav2Vec2-BERT
    模型）'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC)
    (Wav2Vec2 model)'
  id: totrans-5345
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类：[Wav2Vec2ForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC)（Wav2Vec2
    模型）'
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC)
    (Wav2Vec2-Conformer model)'
  id: totrans-5346
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    配置类：[Wav2Vec2ConformerForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC)（Wav2Vec2-Conformer
    模型）'
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMForCTC](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForCTC)
    (WavLM model)'
  id: totrans-5347
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    配置类：[WavLMForCTC](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForCTC)（WavLM
    模型）'
- en: Instantiates one of the model classes of the library (with a connectionist temporal
    classification head) from a configuration.
  id: totrans-5348
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有连接主义时间分类头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5349
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-5350
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE274]'
  id: totrans-5351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE274]'
- en: '#### `from_pretrained`'
  id: totrans-5352
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5353
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE275]'
  id: totrans-5354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE275]'
- en: Parameters
  id: totrans-5355
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5357
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *model id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5358
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的
    *目录* 路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5359
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或url指向*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型更慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*optional*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — 模型使用的配置，而不是自动加载的配置。当：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5362
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *model id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5364
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并在目录中找到名为 *config.json* 的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建一个模型，但加载自己的权重，可以使用此选项。不过，在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *optional*) — 下载预训练模型配置文件时应缓存的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, 默认为 `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`） — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`） — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`） — 是否允许在Hub上定义自定义模型的代码在其自己的建模文件中。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`） — 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，其行为有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5378
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用`config`提供了配置，则`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5379
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`中与配置属性对应的每个键将用于使用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a connectionist temporal
    classification head) from a pretrained model.
  id: totrans-5380
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有连接主义时间分类头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5381
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`data2vec-audio` — [Data2VecAudioForCTC](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForCTC)
    (Data2VecAudio model)'
  id: totrans-5382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-audio` — [Data2VecAudioForCTC](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForCTC)（Data2VecAudio模型）'
- en: '`hubert` — [HubertForCTC](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForCTC)
    (Hubert model)'
  id: totrans-5383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hubert` — [HubertForCTC](/docs/transformers/v4.37.2/en/model_doc/hubert#transformers.HubertForCTC)（Hubert模型）'
- en: '`mctct` — [MCTCTForCTC](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTForCTC)
    (M-CTC-T model)'
  id: totrans-5384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mctct` — [MCTCTForCTC](/docs/transformers/v4.37.2/en/model_doc/mctct#transformers.MCTCTForCTC)（M-CTC-T模型）'
- en: '`sew` — [SEWForCTC](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForCTC)
    (SEW model)'
  id: totrans-5385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew` — [SEWForCTC](/docs/transformers/v4.37.2/en/model_doc/sew#transformers.SEWForCTC)（SEW模型）'
- en: '`sew-d` — [SEWDForCTC](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForCTC)
    (SEW-D model)'
  id: totrans-5386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sew-d` — [SEWDForCTC](/docs/transformers/v4.37.2/en/model_doc/sew-d#transformers.SEWDForCTC)（SEW-D模型）'
- en: '`unispeech` — [UniSpeechForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForCTC)
    (UniSpeech model)'
  id: totrans-5387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech` — [UniSpeechForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech#transformers.UniSpeechForCTC)（UniSpeech模型）'
- en: '`unispeech-sat` — [UniSpeechSatForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC)
    (UniSpeechSat model)'
  id: totrans-5388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech-sat` — [UniSpeechSatForCTC](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC)（UniSpeechSat模型）'
- en: '`wav2vec2` — [Wav2Vec2ForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC)
    (Wav2Vec2 model)'
  id: totrans-5389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2ForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC)（Wav2Vec2模型）'
- en: '`wav2vec2-bert` — [Wav2Vec2BertForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForCTC)
    (Wav2Vec2-BERT model)'
  id: totrans-5390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-bert` — [Wav2Vec2BertForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForCTC)（Wav2Vec2-BERT模型）'
- en: '`wav2vec2-conformer` — [Wav2Vec2ConformerForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC)
    (Wav2Vec2-Conformer model)'
  id: totrans-5391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2ConformerForCTC](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC)（Wav2Vec2-Conformer模型）'
- en: '`wavlm` — [WavLMForCTC](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForCTC)
    (WavLM model)'
  id: totrans-5392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wavlm` — [WavLMForCTC](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForCTC)（WavLM模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5393
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型处于评估模式，使用 `model.eval()`（例如，dropout 模块被停用）。要训练模型，您应该首先使用 `model.train()`
    将其设置回训练模式
- en: 'Examples:'
  id: totrans-5394
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE276]'
  id: totrans-5395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE276]'
- en: AutoModelForSpeechSeq2Seq
  id: totrans-5396
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForSpeechSeq2Seq
- en: '### `class transformers.AutoModelForSpeechSeq2Seq`'
  id: totrans-5397
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForSpeechSeq2Seq`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1524)'
  id: totrans-5398
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1524)'
- en: '[PRE277]'
  id: totrans-5399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE277]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence speech-to-text modeling head)
    when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5400
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有序列到序列语音转文本建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5401
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5402
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5403
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE278]'
  id: totrans-5404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE278]'
- en: Parameters
  id: totrans-5405
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类:'
- en: '[Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig)
    configuration class: [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)
    (Pop2Piano model)'
  id: totrans-5407
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pop2PianoConfig](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoConfig)
    配置类: [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)
    (Pop2Piano 模型)'
- en: '[SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    configuration class: [SeamlessM4TForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForSpeechToText)
    (SeamlessM4T model)'
  id: totrans-5408
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SeamlessM4TConfig](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TConfig)
    配置类: [SeamlessM4TForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForSpeechToText)
    (SeamlessM4T 模型)'
- en: '[SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    configuration class: [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)
    (SeamlessM4Tv2 model)'
  id: totrans-5409
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SeamlessM4Tv2Config](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config)
    配置类: [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)
    (SeamlessM4Tv2 模型)'
- en: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    configuration class: [Speech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration)
    (Speech2Text model)'
  id: totrans-5410
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    配置类: [Speech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration)
    (语音转文本模型)'
- en: '[SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig)
    configuration class: [SpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel)
    (Speech Encoder decoder model)'
  id: totrans-5411
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig)
    配置类: [SpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel)
    (语音编码解码模型)'
- en: '[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)
    configuration class: [SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText)
    (SpeechT5 model)'
  id: totrans-5412
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SpeechT5Config](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5Config)
    配置类: [SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText)
    (SpeechT5 模型)'
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration)
    (Whisper model)'
  id: totrans-5413
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    配置类: [WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration)
    (Whisper 模型)'
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a configuration.
  id: totrans-5414
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有序列到序列语音转文本建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5415
  prefs: []
  type: TYPE_NORMAL
  zh: '注意: 从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。'
- en: 'Examples:'
  id: totrans-5416
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE279]'
  id: totrans-5417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE279]'
- en: '#### `from_pretrained`'
  id: totrans-5418
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5419
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE280]'
  id: totrans-5420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE280]'
- en: Parameters
  id: totrans-5421
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — 可以是:'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5423
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型ID*。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5424
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5425
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或url到一个*TensorFlow索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应该设置为`True`，并且应该提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）—将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5428
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5429
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5430
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）—要使用的状态字典，而不是从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5432
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型，但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)是否不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）—下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`）—从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）—是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）—是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）—要使用的代理服务器的字典，按协议或端点，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`）—是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`）—是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）—要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型在其自己的建模文件中。此选项应仅对您信任的存储库设置为
    `True`，并且您已经阅读了代码，因为它将在本地计算机上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, 默认为`"main"`) — 在 Hub 上使用的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们在 huggingface.co 上使用基于 git 的系统来存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，其行为有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5444
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了 `config` 配置，`**kwargs` 将直接传递给底层模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5445
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs` 将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`
    的每个对应于配置属性的键将用提供的 `kwargs` 值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的 `__init__` 函数。
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a pretrained model.
  id: totrans-5446
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有序列到序列语音转文本建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5447
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的 `model_type` 属性选择要实例化的模型类（如果可能，作为参数传递或从 `pretrained_model_name_or_path`
    加载），或者当缺少时，通过在 `pretrained_model_name_or_path` 上使用模式匹配来回退。
- en: '`pop2piano` — [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)
    (Pop2Piano model)'
  id: totrans-5448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pop2piano` — [Pop2PianoForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pop2piano#transformers.Pop2PianoForConditionalGeneration)
    (Pop2Piano 模型)'
- en: '`seamless_m4t` — [SeamlessM4TForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForSpeechToText)
    (SeamlessM4T model)'
  id: totrans-5449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t` — [SeamlessM4TForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t#transformers.SeamlessM4TForSpeechToText)
    (SeamlessM4T 模型)'
- en: '`seamless_m4t_v2` — [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)
    (SeamlessM4Tv2 model)'
  id: totrans-5450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seamless_m4t_v2` — [SeamlessM4Tv2ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2ForSpeechToText)
    (SeamlessM4Tv2 模型)'
- en: '`speech-encoder-decoder` — [SpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel)
    (Speech Encoder decoder model)'
  id: totrans-5451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech-encoder-decoder` — [SpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel)
    (Speech 编码器解码器模型)'
- en: '`speech_to_text` — [Speech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration)
    (Speech2Text model)'
  id: totrans-5452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text` — [Speech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration)
    (Speech2Text 模型)'
- en: '`speecht5` — [SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText)
    (SpeechT5 model)'
  id: totrans-5453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speecht5` — [SpeechT5ForSpeechToText](/docs/transformers/v4.37.2/en/model_doc/speecht5#transformers.SpeechT5ForSpeechToText)
    (SpeechT5 模型)'
- en: '`whisper` — [WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration)
    (Whisper model)'
  id: totrans-5454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration)
    (Whisper 模型)'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5455
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型设置为评估模式，使用 `model.eval()`（例如，关闭了 dropout 模块）。要训练模型，您应该首先将其设置回训练模式，使用
    `model.train()`
- en: 'Examples:'
  id: totrans-5456
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE281]'
  id: totrans-5457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE281]'
- en: TFAutoModelForSpeechSeq2Seq
  id: totrans-5458
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForSpeechSeq2Seq
- en: '### `class transformers.TFAutoModelForSpeechSeq2Seq`'
  id: totrans-5459
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForSpeechSeq2Seq`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L691)'
  id: totrans-5460
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L691)'
- en: '[PRE282]'
  id: totrans-5461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE282]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence speech-to-text modeling head)
    when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5462
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将作为库的模型类之一实例化（带有一个序列到序列语音到文本建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5463
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5464
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5465
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE283]'
  id: totrans-5466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE283]'
- en: Parameters
  id: totrans-5467
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）-
    选择要实例化的模型类取决于配置类：'
- en: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)
    configuration class: [TFSpeech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration)
    (Speech2Text model)'
  id: totrans-5469
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Speech2TextConfig](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.Speech2TextConfig)配置类：[TFSpeech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration)（Speech2Text模型）'
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)
    (Whisper model)'
  id: totrans-5470
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)配置类：[TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)（Whisper模型）'
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a configuration.
  id: totrans-5471
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库的模型类之一（带有一个序列到序列语音到文本建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5472
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-5473
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE284]'
  id: totrans-5474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE284]'
- en: '#### `from_pretrained`'
  id: totrans-5475
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5476
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE285]'
  id: totrans-5477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE285]'
- en: Parameters
  id: totrans-5478
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）- 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5480
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5481
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-5482
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或url指向*PyTorch状态字典保存文件*（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将`from_pt`设置为`True`，并将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）- 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）-
    用于替代自动加载的配置的模型使用的配置。当：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5485
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5486
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5487
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件时，可以自动加载配置。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）- 如果不使用标准缓存，则应将下载的预训练模型配置缓存到的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 要按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`）— 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`）— 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（其他关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5499
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5500
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a pretrained model.
  id: totrans-5501
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库中的一个模型类（带有序列到序列语音到文本建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5502
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：
- en: '`speech_to_text` — [TFSpeech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration)
    (Speech2Text model)'
  id: totrans-5503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech_to_text` — [TFSpeech2TextForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration)（Speech2Text模型）'
- en: '`whisper` — [TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)
    (Whisper model)'
  id: totrans-5504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)（Whisper模型）'
- en: 'Examples:'
  id: totrans-5505
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE286]'
  id: totrans-5506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE286]'
- en: FlaxAutoModelForSpeechSeq2Seq
  id: totrans-5507
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForSpeechSeq2Seq
- en: '### `class transformers.FlaxAutoModelForSpeechSeq2Seq`'
  id: totrans-5508
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForSpeechSeq2Seq`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L370)'
  id: totrans-5509
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L370)'
- en: '[PRE287]'
  id: totrans-5510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE287]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a sequence-to-sequence speech-to-text modeling head)
    when created with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5511
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将实例化为库的模型类之一（带有序列到序列语音转文本建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5512
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5513
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5514
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE288]'
  id: totrans-5515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE288]'
- en: Parameters
  id: totrans-5516
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）-
    要实例化的模型类是基于配置类选择的：'
- en: '[SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig)
    configuration class: [FlaxSpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel)
    (Speech Encoder decoder model)'
  id: totrans-5518
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SpeechEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig)
    配置类：[FlaxSpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel)（语音编码器解码器模型）'
- en: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    configuration class: [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper model)'
  id: totrans-5519
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)
    配置类：[FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)（Whisper
    模型）'
- en: Instantiates one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a configuration.
  id: totrans-5520
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中实例化库的模型类之一（带有序列到序列语音转文本建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5521
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    加载模型权重。
- en: 'Examples:'
  id: totrans-5522
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE289]'
  id: totrans-5523
  prefs: []
  type: TYPE_PRE
  zh: '[PRE289]'
- en: '#### `from_pretrained`'
  id: totrans-5524
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5525
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE290]'
  id: totrans-5526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE290]'
- en: Parameters
  id: totrans-5527
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str` 或 `os.PathLike`）- 可以是以下之一：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5529
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在 huggingface.co 模型存储库中的预训练模型的 *模型 id*。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5530
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 路径，例如 `./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-5531
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *PyTorch state_dict 保存文件* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow
    模型并加载 TensorFlow 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）- 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）-
    用于模型的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5534
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5535
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5536
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 加载模型，并且在目录中找到名为 *config.json* 的配置
    JSON 文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str`或`os.PathLike`, *可选*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *可选*, 默认为`False`) — 从PyTorch检查点保存文件加载模型权重（参见`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*, 默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*, 默认为`False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*, 默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *可选*, 默认为`False`) — 是否允许在Hub上定义自定义模型的自己的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *可选*, 默认为`"main"`) — 用于Hub上代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载而表现不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5548
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有`config`的配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）。
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5549
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a sequence-to-sequence
    speech-to-text modeling head) from a pretrained model.
  id: totrans-5550
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有序列到序列语音到文本建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5551
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退：
- en: '`speech-encoder-decoder` — [FlaxSpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel)
    (Speech Encoder decoder model)'
  id: totrans-5552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speech-encoder-decoder` — [FlaxSpeechEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel)（语音编码器解码器模型）'
- en: '`whisper` — [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)
    (Whisper model)'
  id: totrans-5553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whisper` — [FlaxWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForConditionalGeneration)（Whisper
    模型）'
- en: 'Examples:'
  id: totrans-5554
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE291]'
  id: totrans-5555
  prefs: []
  type: TYPE_PRE
  zh: '[PRE291]'
- en: AutoModelForAudioXVector
  id: totrans-5556
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForAudioXVector
- en: '### `class transformers.AutoModelForAudioXVector`'
  id: totrans-5557
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForAudioXVector`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1542)'
  id: totrans-5558
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1542)'
- en: '[PRE292]'
  id: totrans-5559
  prefs: []
  type: TYPE_PRE
  zh: '[PRE292]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a audio retrieval via x-vector head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5560
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将作为库中的模型类之一实例化（通过 x-vector 头进行音频检索）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5561
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5562
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5563
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE293]'
  id: totrans-5564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE293]'
- en: Parameters
  id: totrans-5565
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 要实例化的模型类是根据配置类选择的：'
- en: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    configuration class: [Data2VecAudioForXVector](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForXVector)
    (Data2VecAudio model)'
  id: totrans-5567
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data2VecAudioConfig](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioConfig)
    配置类：[Data2VecAudioForXVector](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForXVector)（Data2VecAudio
    模型）'
- en: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    configuration class: [UniSpeechSatForXVector](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector)
    (UniSpeechSat model)'
  id: totrans-5568
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UniSpeechSatConfig](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig)
    配置类：[UniSpeechSatForXVector](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector)（UniSpeechSat
    模型）'
- en: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    configuration class: [Wav2Vec2BertForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForXVector)
    (Wav2Vec2-BERT model)'
  id: totrans-5569
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2BertConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertConfig)
    配置类：[Wav2Vec2BertForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForXVector)（Wav2Vec2-BERT
    模型）'
- en: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    configuration class: [Wav2Vec2ForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector)
    (Wav2Vec2 model)'
  id: totrans-5570
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2Config](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Config)
    配置类：[Wav2Vec2ForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector)（Wav2Vec2
    模型）'
- en: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    configuration class: [Wav2Vec2ConformerForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector)
    (Wav2Vec2-Conformer model)'
  id: totrans-5571
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wav2Vec2ConformerConfig](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig)
    配置类：[Wav2Vec2ConformerForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector)（Wav2Vec2-Conformer
    模型）'
- en: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    configuration class: [WavLMForXVector](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForXVector)
    (WavLM model)'
  id: totrans-5572
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WavLMConfig](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMConfig)
    配置类：[WavLMForXVector](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForXVector)（WavLM
    模型）'
- en: Instantiates one of the model classes of the library (with a audio retrieval
    via x-vector head) from a configuration.
  id: totrans-5573
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的模型类之一（通过 x-vector 头进行音频检索）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5574
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-5575
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE294]'
  id: totrans-5576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE294]'
- en: '#### `from_pretrained`'
  id: totrans-5577
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5578
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE295]'
  id: totrans-5579
  prefs: []
  type: TYPE_PRE
  zh: '[PRE295]'
- en: Parameters
  id: totrans-5580
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str` 或 `os.PathLike`） — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5582
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5583
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *目录* 的路径，其中包含使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重，例如 `./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5584
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或指向 *tensorflow 索引检查点文件* 的 URL（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。这种加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch
    模型并随后加载 PyTorch 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*)
    — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5587
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5588
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5589
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*，*可选*) — 用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5591
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`，*可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存在其中的目录路径。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`，*可选*，默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅 `pretrained_model_name_or_path`
    参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`，*可选*，默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`，*可选*，默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`，*可选*) — 用于每个请求的代理服务器字典，按协议或端点分类，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为 `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`，*可选*，默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于
    git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`，*可选*，默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`） — 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供`config`或自动加载，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5603
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5604
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个与配置属性对应的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a audio retrieval
    via x-vector head) from a pretrained model.
  id: totrans-5605
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型中实例化库中的一个模型类（带有通过x-vector头进行音频检索）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5606
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`data2vec-audio` — [Data2VecAudioForXVector](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForXVector)
    (Data2VecAudio model)'
  id: totrans-5607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data2vec-audio` — [Data2VecAudioForXVector](/docs/transformers/v4.37.2/en/model_doc/data2vec#transformers.Data2VecAudioForXVector)（Data2VecAudio模型）'
- en: '`unispeech-sat` — [UniSpeechSatForXVector](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector)
    (UniSpeechSat model)'
  id: totrans-5608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unispeech-sat` — [UniSpeechSatForXVector](/docs/transformers/v4.37.2/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector)（UniSpeechSat模型）'
- en: '`wav2vec2` — [Wav2Vec2ForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector)
    (Wav2Vec2 model)'
  id: totrans-5609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2` — [Wav2Vec2ForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector)（Wav2Vec2模型）'
- en: '`wav2vec2-bert` — [Wav2Vec2BertForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForXVector)
    (Wav2Vec2-BERT model)'
  id: totrans-5610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-bert` — [Wav2Vec2BertForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-bert#transformers.Wav2Vec2BertForXVector)（Wav2Vec2-BERT模型）'
- en: '`wav2vec2-conformer` — [Wav2Vec2ConformerForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector)
    (Wav2Vec2-Conformer model)'
  id: totrans-5611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wav2vec2-conformer` — [Wav2Vec2ConformerForXVector](/docs/transformers/v4.37.2/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector)（Wav2Vec2-Conformer模型）'
- en: '`wavlm` — [WavLMForXVector](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForXVector)
    (WavLM model)'
  id: totrans-5612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wavlm` — [WavLMForXVector](/docs/transformers/v4.37.2/en/model_doc/wavlm#transformers.WavLMForXVector)（WavLM模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5613
  prefs: []
  type: TYPE_NORMAL
  zh: 模型默认使用`model.eval()`设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。
- en: 'Examples:'
  id: totrans-5614
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE296]'
  id: totrans-5615
  prefs: []
  type: TYPE_PRE
  zh: '[PRE296]'
- en: AutoModelForTextToSpectrogram
  id: totrans-5616
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForTextToSpectrogram
- en: '### `class transformers.AutoModelForTextToSpectrogram`'
  id: totrans-5617
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForTextToSpectrogram`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1546)'
  id: totrans-5618
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1546)'
- en: '[PRE297]'
  id: totrans-5619
  prefs: []
  type: TYPE_PRE
  zh: '[PRE297]'
- en: AutoModelForTextToWaveform
  id: totrans-5620
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForTextToWaveform
- en: '### `class transformers.AutoModelForTextToWaveform`'
  id: totrans-5621
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForTextToWaveform`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1550)'
  id: totrans-5622
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1550)'
- en: '[PRE298]'
  id: totrans-5623
  prefs: []
  type: TYPE_PRE
  zh: '[PRE298]'
- en: Multimodal
  id: totrans-5624
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多模态
- en: The following auto classes are available for the following multimodal tasks.
  id: totrans-5625
  prefs: []
  type: TYPE_NORMAL
  zh: 以下自动类适用于以下多模态任务。
- en: AutoModelForTableQuestionAnswering
  id: totrans-5626
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForTableQuestionAnswering
- en: '### `class transformers.AutoModelForTableQuestionAnswering`'
  id: totrans-5627
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForTableQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1367)'
  id: totrans-5628
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1367)'
- en: '[PRE299]'
  id: totrans-5629
  prefs: []
  type: TYPE_PRE
  zh: '[PRE299]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a table question answering head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5630
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将被实例化为库中的一个模型类（带有表格问答头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5631
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5632
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5633
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE300]'
  id: totrans-5634
  prefs: []
  type: TYPE_PRE
  zh: '[PRE300]'
- en: Parameters
  id: totrans-5635
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    要实例化的模型类是基于配置类选择的：'
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering)
    (TAPAS model)'
  id: totrans-5637
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)配置类：[TapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering)（TAPAS模型）'
- en: Instantiates one of the model classes of the library (with a table question
    answering head) from a configuration.
  id: totrans-5638
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有表格问答头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5639
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。
- en: 'Examples:'
  id: totrans-5640
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE301]'
  id: totrans-5641
  prefs: []
  type: TYPE_PRE
  zh: '[PRE301]'
- en: '#### `from_pretrained`'
  id: totrans-5642
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5643
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE302]'
  id: totrans-5644
  prefs: []
  type: TYPE_PRE
  zh: '[PRE302]'
- en: Parameters
  id: totrans-5645
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5647
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5648
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5649
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*tensorflow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`应设置为`True`，并且应将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5652
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5653
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5654
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*）— 用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5656
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。但在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是一个更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 下载的预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf`（`bool`，*可选*，默认为`False`）— 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`）— 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`）— 是否返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`）— 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的代码。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上代码的特定修订版本，如果代码与模型的其余部分不在同一存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*）— 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5668
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有`config`的配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5669
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a table question answering
    head) from a pretrained model.
  id: totrans-5670
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有表格问答头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5671
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的`model_type`属性（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上进行模式匹配来选择要实例化的模型类：
- en: '`tapas` — [TapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering)
    (TAPAS model)'
  id: totrans-5672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasForQuestionAnswering)（TAPAS模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5673
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。
- en: 'Examples:'
  id: totrans-5674
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE303]'
  id: totrans-5675
  prefs: []
  type: TYPE_PRE
  zh: '[PRE303]'
- en: TFAutoModelForTableQuestionAnswering
  id: totrans-5676
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForTableQuestionAnswering
- en: '### `class transformers.TFAutoModelForTableQuestionAnswering`'
  id: totrans-5677
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForTableQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L655)'
  id: totrans-5678
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L655)'
- en: '[PRE304]'
  id: totrans-5679
  prefs: []
  type: TYPE_PRE
  zh: '[PRE304]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a table question answering head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5680
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    类方法或 [from_config()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    类方法创建时，将被实例化为库中的一个模型类（带有表格问答头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5681
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用 `__init__()` 实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5682
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5683
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE305]'
  id: totrans-5684
  prefs: []
  type: TYPE_PRE
  zh: '[PRE305]'
- en: Parameters
  id: totrans-5685
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig))
    — 根据配置类选择要实例化的模型类：'
- en: '[TapasConfig](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TapasConfig)
    configuration class: [TFTapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering)
    (TAPAS model)'
  id: totrans-5687
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TapasConfig](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TapasConfig)
    配置类: [TFTapasForQuestionAnswering](/docs/transformers/v4.37.2/zh/model_doc/tapas#transformers.TFTapasForQuestionAnswering)
    (TAPAS 模型)'
- en: Instantiates one of the model classes of the library (with a table question
    answering head) from a configuration.
  id: totrans-5688
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有表格问答头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5689
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。
- en: 'Examples:'
  id: totrans-5690
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE306]'
  id: totrans-5691
  prefs: []
  type: TYPE_PRE
  zh: '[PRE306]'
- en: '#### `from_pretrained`'
  id: totrans-5692
  prefs: []
  type: TYPE_NORMAL
  zh: '`from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5693
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE307]'
  id: totrans-5694
  prefs: []
  type: TYPE_PRE
  zh: '[PRE307]'
- en: Parameters
  id: totrans-5695
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5697
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的 *模型 id*，托管在 huggingface.co 上的模型仓库中。有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者在用户或组织名称下命名空间化，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5698
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用 [save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-5699
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *PyTorch 状态字典保存文件* 的路径或 url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将
    `from_pt` 设置为 `True`，并且应该提供一个配置对象作为 `config` 参数。使用提供的转换脚本将 PyTorch 模型转换为 TensorFlow
    模型并随后加载 TensorFlow 模型，这种加载路径比直接加载 PyTorch 模型慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args` (额外的位置参数, *可选*) — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig),
    *可选*) — 用于替代自动加载的配置的模型配置。当以下情况时，配置可以被自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5702
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的一个模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5703
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5704
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *可选*) — 如果不使用标准缓存，则应将下载的预训练模型配置缓存到的目录路径。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt` (`bool`, *可选*, 默认为 `False`) — 从 PyTorch 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path`
    参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`) — 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为`True`，并且您已阅读代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上的代码的特定修订版本，如果代码存储在与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5716
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5717
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则首先将`kwargs`传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用于使用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a table question answering
    head) from a pretrained model.
  id: totrans-5718
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有表格问答头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5719
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性选择的（如果可能作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退选择。
- en: '`tapas` — [TFTapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering)
    (TAPAS model)'
  id: totrans-5720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tapas` — [TFTapasForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering)（TAPAS模型）'
- en: 'Examples:'
  id: totrans-5721
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE308]'
  id: totrans-5722
  prefs: []
  type: TYPE_PRE
  zh: '[PRE308]'
- en: AutoModelForDocumentQuestionAnswering
  id: totrans-5723
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForDocumentQuestionAnswering
- en: '### `class transformers.AutoModelForDocumentQuestionAnswering`'
  id: totrans-5724
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForDocumentQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1389)'
  id: totrans-5725
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1389)'
- en: '[PRE309]'
  id: totrans-5726
  prefs: []
  type: TYPE_PRE
  zh: '[PRE309]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a document question answering head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5727
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有文档问答头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5728
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5729
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5730
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE310]'
  id: totrans-5731
  prefs: []
  type: TYPE_PRE
  zh: '[PRE310]'
- en: Parameters
  id: totrans-5732
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 选择要实例化的模型类基于配置类:'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [LayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering)
    (LayoutLM model)'
  id: totrans-5734
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类: [LayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering)
    (LayoutLM 模型)'
- en: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    configuration class: [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 model)'
  id: totrans-5735
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv2Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config)
    配置类: [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 模型)'
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  id: totrans-5736
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    配置类: [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 模型)'
- en: Instantiates one of the model classes of the library (with a document question
    answering head) from a configuration.
  id: totrans-5737
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有文档问答头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5738
  prefs: []
  type: TYPE_NORMAL
  zh: '注意: 从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)来加载模型权重。'
- en: 'Examples:'
  id: totrans-5739
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE311]'
  id: totrans-5740
  prefs: []
  type: TYPE_PRE
  zh: '[PRE311]'
- en: '#### `from_pretrained`'
  id: totrans-5741
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5742
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE312]'
  id: totrans-5743
  prefs: []
  type: TYPE_PRE
  zh: '[PRE312]'
- en: Parameters
  id: totrans-5744
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是:'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5746
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库内的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5747
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5748
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*TensorFlow索引检查点文件*的路径或url（例如，`./tf_model/model.ckpt.index`）。在这种情况下，应将`from_tf`设置为`True`，并且应将配置对象作为`config`参数提供。使用此加载路径比使用提供的转换脚本将TensorFlow检查点转换为PyTorch模型并加载PyTorch模型更慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args` (额外的位置参数，*可选*) — 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *可选*) — 用于替代自动加载的配置的模型配置。当以下情况发生时，配置可以被自动加载:'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5751
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5752
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录来重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5753
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型通过提供一个本地目录作为`pretrained_model_name_or_path`来加载，并且在该目录中找到一个名为*config.json*的配置JSON文件。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（*Dict[str, torch.Tensor]*，*可选*） — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5755
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)和[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str`或`os.PathLike`，*可选*) — 下载的预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *可选*, 默认为 `False`) — 从TensorFlow检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`，*可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`，*可选*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在Hub上定义自定义模型并在其自己的建模文件中执行。此选项应仅在您信任的存储库中设置为`True`，并且您已阅读了代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`，*可选*，默认为`"main"`) — 用于Hub上的代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5767
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5768
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a document question
    answering head) from a pretrained model.
  id: totrans-5769
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有文档问答头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5770
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的`model_type`属性选择要实例化的模型类（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`layoutlm` — [LayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering)
    (LayoutLM model)'
  id: totrans-5771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [LayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering)（LayoutLM
    模型）'
- en: '`layoutlmv2` — [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)
    (LayoutLMv2 model)'
  id: totrans-5772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv2` — [LayoutLMv2ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering)（LayoutLMv2
    模型）'
- en: '`layoutlmv3` — [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  id: totrans-5773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [LayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering)（LayoutLMv3
    模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5774
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，首先应该使用`model.train()`将其设置回训练模式。
- en: 'Examples:'
  id: totrans-5775
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE313]'
  id: totrans-5776
  prefs: []
  type: TYPE_PRE
  zh: '[PRE313]'
- en: TFAutoModelForDocumentQuestionAnswering
  id: totrans-5777
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForDocumentQuestionAnswering
- en: '### `class transformers.TFAutoModelForDocumentQuestionAnswering`'
  id: totrans-5778
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForDocumentQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L644)'
  id: totrans-5779
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L644)'
- en: '[PRE314]'
  id: totrans-5780
  prefs: []
  type: TYPE_PRE
  zh: '[PRE314]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a document question answering head) when created
    with the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5781
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库中的一个模型类（带有文档问答头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5782
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5783
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5784
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE315]'
  id: totrans-5785
  prefs: []
  type: TYPE_PRE
  zh: '[PRE315]'
- en: Parameters
  id: totrans-5786
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 根据配置类选择要实例化的模型类：'
- en: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    configuration class: [TFLayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering)
    (LayoutLM model)'
  id: totrans-5788
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMConfig](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.LayoutLMConfig)
    配置类：[TFLayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering)（LayoutLM
    模型）'
- en: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    configuration class: [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  id: totrans-5789
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LayoutLMv3Config](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config)
    配置类：[TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)（LayoutLMv3
    模型）'
- en: Instantiates one of the model classes of the library (with a document question
    answering head) from a configuration.
  id: totrans-5790
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有文档问答头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5791
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型时**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-5792
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE316]'
  id: totrans-5793
  prefs: []
  type: TYPE_PRE
  zh: '[PRE316]'
- en: '#### `from_pretrained`'
  id: totrans-5794
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5795
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE317]'
  id: totrans-5796
  prefs: []
  type: TYPE_PRE
  zh: '[PRE317]'
- en: Parameters
  id: totrans-5797
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5799
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练模型的*模型id*，托管在huggingface.co上的模型存储库中。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5800
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*目录*的路径，其中包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-5801
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PyTorch state_dict保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。'
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型的`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    模型使用的配置，而不是自动加载的配置。当以下情况发生时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5804
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型ID*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5805
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5806
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并且在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*） — 下载的预训练模型配置应该缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`) — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*） — 要使用的代理服务器字典，按协议或端点，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`) — 是否允许在Hub上定义自定义模型的代码文件。此选项应仅对您信任的存储库设置为`True`，并且您已经阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`) — 在Hub上使用的特定代码修订版，如果代码与模型的其余部分存储在不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供了`config`或自动加载，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5818
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用`config`提供了配置，则`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5819
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a document question
    answering head) from a pretrained model.
  id: totrans-5820
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的模型类之一（带有文档问答头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5821
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的`model_type`属性（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），选择要实例化的模型类，或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`layoutlm` — [TFLayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering)
    (LayoutLM model)'
  id: totrans-5822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlm` — [TFLayoutLMForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering)（LayoutLM模型）'
- en: '`layoutlmv3` — [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)
    (LayoutLMv3 model)'
  id: totrans-5823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layoutlmv3` — [TFLayoutLMv3ForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering)（LayoutLMv3模型）'
- en: 'Examples:'
  id: totrans-5824
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE318]'
  id: totrans-5825
  prefs: []
  type: TYPE_PRE
  zh: '[PRE318]'
- en: AutoModelForVisualQuestionAnswering
  id: totrans-5826
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForVisualQuestionAnswering
- en: '### `class transformers.AutoModelForVisualQuestionAnswering`'
  id: totrans-5827
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForVisualQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1378)'
  id: totrans-5828
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1378)'
- en: '[PRE319]'
  id: totrans-5829
  prefs: []
  type: TYPE_PRE
  zh: '[PRE319]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a visual question answering head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5830
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将实例化为库中的模型类之一（带有视觉问答头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5831
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5832
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5833
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE320]'
  id: totrans-5834
  prefs: []
  type: TYPE_PRE
  zh: '[PRE320]'
- en: Parameters
  id: totrans-5835
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 根据配置类选择要实例化的模型类：'
- en: '[Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    configuration class: [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)
    (BLIP-2 model)'
  id: totrans-5837
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    配置类：[Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)（BLIP-2模型）'
- en: '[ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig)
    configuration class: [ViltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltForQuestionAnswering)
    (ViLT model)'
  id: totrans-5838
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ViltConfig](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltConfig)
    配置类：[ViltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltForQuestionAnswering)（ViLT模型）'
- en: Instantiates one of the model classes of the library (with a visual question
    answering head) from a configuration.
  id: totrans-5839
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的模型类之一（带有视觉问答头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5840
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-5841
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE321]'
  id: totrans-5842
  prefs: []
  type: TYPE_PRE
  zh: '[PRE321]'
- en: '#### `from_pretrained`'
  id: totrans-5843
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5844
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE322]'
  id: totrans-5845
  prefs: []
  type: TYPE_PRE
  zh: '[PRE322]'
- en: Parameters
  id: totrans-5846
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5848
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，位于huggingface.co模型存储库内的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5849
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5850
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径或 URL 到 *tensorflow 索引检查点文件*（例如，`./tf_model/model.ckpt.index`）。在这种情况下，`from_tf`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch
    模型并随后加载 PyTorch 模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *可选*) — 用于模型的配置，而不是自动加载的配置。当以下情况自动加载配置时：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5853
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的 *模型 ID* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5854
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5855
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *可选*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5857
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型但加载自己的权重，则可以使用此选项。不过，在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    不是更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` 或 `os.PathLike`, *可选*) — 下载的预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *可选*, 默认为 `False`) — 从 TensorFlow 检查点保存文件加载模型权重（参见 `pretrained_model_name_or_path`
    参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *可选*, 默认为 `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求中使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*, 默认为 `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *可选*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，因为我们使用基于
    git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *可选*, 默认为 `False`) — 是否允许在 Hub 上定义自定义模型的建模文件。此选项应仅对您信任的存储库设置为
    `True`，并且您已阅读代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`） — 用于Hub上的代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5868
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5869
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`配置，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5870
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个键对应一个配置属性，将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a visual question
    answering head) from a pretrained model.
  id: totrans-5871
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的模型类之一（带有视觉问答头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5872
  prefs: []
  type: TYPE_NORMAL
  zh: 选择要实例化的模型类基于配置对象的`model_type`属性（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`blip-2` — [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)
    (BLIP-2 model)'
  id: totrans-5873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip-2` — [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)（BLIP-2模型）'
- en: '`vilt` — [ViltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltForQuestionAnswering)
    (ViLT model)'
  id: totrans-5874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vilt` — [ViltForQuestionAnswering](/docs/transformers/v4.37.2/en/model_doc/vilt#transformers.ViltForQuestionAnswering)（ViLT模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5875
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型设置为评估模式，使用`model.eval()`（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式。
- en: 'Examples:'
  id: totrans-5876
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE323]'
  id: totrans-5877
  prefs: []
  type: TYPE_PRE
  zh: '[PRE323]'
- en: AutoModelForVision2Seq
  id: totrans-5878
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoModelForVision2Seq
- en: '### `class transformers.AutoModelForVision2Seq`'
  id: totrans-5879
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.AutoModelForVision2Seq`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1503)'
  id: totrans-5880
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_auto.py#L1503)'
- en: '[PRE324]'
  id: totrans-5881
  prefs: []
  type: TYPE_PRE
  zh: '[PRE324]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a vision-to-text modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5882
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class方法from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class方法from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将实例化为库中的模型类之一（带有视觉到文本建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5883
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5884
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5885
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE325]'
  id: totrans-5886
  prefs: []
  type: TYPE_PRE
  zh: '[PRE325]'
- en: Parameters
  id: totrans-5887
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5888
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 选择要实例化的模型类基于配置类：'
- en: '[Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)
    configuration class: [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)
    (BLIP-2 model)'
  id: totrans-5889
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Blip2Config](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2Config)配置类：[Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)（BLIP-2模型）'
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [BlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipForConditionalGeneration)
    (BLIP model)'
  id: totrans-5890
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)配置类：[BlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipForConditionalGeneration)（BLIP模型）'
- en: '[GitConfig](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitConfig)
    configuration class: [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT model)'
  id: totrans-5891
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GitConfig](/docs/transformers/v4.37.2/zh/model_doc/git#transformers.GitConfig)
    配置类: [GitForCausalLM](/docs/transformers/v4.37.2/zh/model_doc/git#transformers.GitForCausalLM)
    (GIT 模型)'
- en: '[InstructBlipConfig](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipConfig)
    configuration class: [InstructBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipForConditionalGeneration)
    (InstructBLIP model)'
  id: totrans-5892
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InstructBlipConfig](/docs/transformers/v4.37.2/zh/model_doc/instructblip#transformers.InstructBlipConfig)
    配置类: [InstructBlipForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/instructblip#transformers.InstructBlipForConditionalGeneration)
    (InstructBLIP 模型)'
- en: '[Kosmos2Config](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2Config)
    configuration class: [Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration)
    (KOSMOS-2 model)'
  id: totrans-5893
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kosmos2Config](/docs/transformers/v4.37.2/zh/model_doc/kosmos-2#transformers.Kosmos2Config)
    配置类: [Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration)
    (KOSMOS-2 模型)'
- en: '[LlavaConfig](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaConfig)
    configuration class: [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa model)'
  id: totrans-5894
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LlavaConfig](/docs/transformers/v4.37.2/zh/model_doc/llava#transformers.LlavaConfig)
    配置类: [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa 模型)'
- en: '[Pix2StructConfig](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructConfig)
    configuration class: [Pix2StructForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructForConditionalGeneration)
    (Pix2Struct model)'
  id: totrans-5895
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pix2StructConfig](/docs/transformers/v4.37.2/zh/model_doc/pix2struct#transformers.Pix2StructConfig)
    配置类: [Pix2StructForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/pix2struct#transformers.Pix2StructForConditionalGeneration)
    (Pix2Struct 模型)'
- en: '[VipLlavaConfig](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaConfig)
    configuration class: [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava model)'
  id: totrans-5896
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VipLlavaConfig](/docs/transformers/v4.37.2/zh/model_doc/vipllava#transformers.VipLlavaConfig)
    配置类: [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/zh/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava 模型)'
- en: '[VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    configuration class: [VisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  id: totrans-5897
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/zh/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    配置类: [VisionEncoderDecoderModel](/docs/transformers/v4.37.2/zh/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel)
    (Vision 编码器解码器模型)'
- en: Instantiates one of the model classes of the library (with a vision-to-text
    modeling head) from a configuration.
  id: totrans-5898
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有从视觉到文本的建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5899
  prefs: []
  type: TYPE_NORMAL
  zh: '注意: 从配置文件加载模型 **不会** 加载模型权重。 它只影响模型的配置。 使用 [from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    来加载模型权重。'
- en: 'Examples:'
  id: totrans-5900
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE326]'
  id: totrans-5901
  prefs: []
  type: TYPE_PRE
  zh: '[PRE326]'
- en: '#### `from_pretrained`'
  id: totrans-5902
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5903
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE327]'
  id: totrans-5904
  prefs: []
  type: TYPE_PRE
  zh: '[PRE327]'
- en: Parameters
  id: totrans-5905
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path` (`str` 或 `os.PathLike`) — 可以是以下之一:'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5907
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在 huggingface.co 模型存储库中的预训练模型的 *模型 id*。 有效的模型 id 可以位于根级别，如 `bert-base-uncased`，或者命名空间在用户或组织名称下，如
    `dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5908
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向使用 [save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的模型权重的 *目录* 的路径，例如，`./my_model_directory/`。
- en: A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`).
    In this case, `from_tf` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts
    and loading the PyTorch model afterwards.
  id: totrans-5909
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *tensorflow 索引检查点文件* 的路径或 url（例如，`./tf_model/model.ckpt.index`）。 在这种情况下，`from_tf`
    应设置为 `True`，并且应将配置对象提供为 `config` 参数。 使用此加载路径比使用提供的转换脚本将 TensorFlow 检查点转换为 PyTorch
    模型并随后加载 PyTorch 模型更慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5910
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args` (额外的位置参数, *可选*) — 将传递给底层模型的 `__init__()` 方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig),
    *可选*) — 模型使用的配置，而不是自动加载的配置。 当以下情况发生时，配置可以自动加载:'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5912
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库中提供的模型（使用预训练模型的 *模型 id* 字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5913
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5914
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为 `pretrained_model_name_or_path` 并在目录中找到名为 *config.json* 的配置 JSON
    文件来加载模型。
- en: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — A state dictionary to
    use instead of a state dictionary loaded from saved weights file.'
  id: totrans-5915
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict` (*Dict[str, torch.Tensor]*, *optional*) — 一个状态字典，用于替代从保存的权重文件加载的状态字典。'
- en: This option can be used if you want to create a model from a pretrained configuration
    but load your own weights. In this case though, you should check if using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    is not a simpler option.
  id: totrans-5916
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想从预训练配置创建模型，但加载自己的权重，可以使用此选项。在这种情况下，您应该检查是否使用 [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    和 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    不是一个更简单的选项。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir` (`str` or `os.PathLike`, *optional*) — 下载预训练模型配置应该缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_tf` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a TensorFlow checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_tf` (`bool`, *optional*, defaults to `False`) — 从 TensorFlow 检查点保存文件加载模型权重（请参阅
    `pretrained_model_name_or_path` 参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5919
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download` (`bool`, *optional*, defaults to `False`) — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5921
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies` (`Dict[str, str]`, *optional*) — 一个代理服务器字典，按协议或端点使用，例如，`{''http'':
    ''foo.bar:3128'', ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5922
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *optional*, defaults to `False`) — 是否还返回一个包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5923
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *optional*, defaults to `False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — 是否允许在 Hub 上定义自定义模型的自己的建模文件。此选项应仅设置为
    `True`，用于您信任的存储库，并且您已经阅读了代码，因为它将在本地机器上执行 Hub 上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5926
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision` (`str`, *optional*, defaults to `"main"`) — 用于 Hub 上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交
    ID，因为我们使用基于 git 的系统在 huggingface.co 上存储模型和其他工件，所以 `revision` 可以是 git 允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5927
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（其他关键字参数，*optional*） — 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了
    `config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5928
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了 `config`，`**kwargs` 将直接传递给基础模型的 `__init__` 方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5929
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，`kwargs`将首先传递给配置类的初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`的每个对应于配置属性的键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a vision-to-text modeling
    head) from a pretrained model.
  id: totrans-5930
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库的模型类之一（带有视觉到文本建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5931
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化的模型类是根据配置对象的`model_type`属性选择的（作为参数传递或从`pretrained_model_name_or_path`加载，如果可能的话），或者当缺失时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`blip` — [BlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipForConditionalGeneration)
    (BLIP model)'
  id: totrans-5932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [BlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipForConditionalGeneration)（BLIP模型）'
- en: '`blip-2` — [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)
    (BLIP-2 model)'
  id: totrans-5933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip-2` — [Blip2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip-2#transformers.Blip2ForConditionalGeneration)（BLIP-2模型）'
- en: '`git` — [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)
    (GIT model)'
  id: totrans-5934
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` — [GitForCausalLM](/docs/transformers/v4.37.2/en/model_doc/git#transformers.GitForCausalLM)（GIT模型）'
- en: '`instructblip` — [InstructBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipForConditionalGeneration)
    (InstructBLIP model)'
  id: totrans-5935
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instructblip` — [InstructBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/instructblip#transformers.InstructBlipForConditionalGeneration)（InstructBLIP模型）'
- en: '`kosmos-2` — [Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration)
    (KOSMOS-2 model)'
  id: totrans-5936
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kosmos-2` — [Kosmos2ForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/kosmos-2#transformers.Kosmos2ForConditionalGeneration)（KOSMOS-2模型）'
- en: '`llava` — [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)
    (LLaVa model)'
  id: totrans-5937
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`llava` — [LlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/llava#transformers.LlavaForConditionalGeneration)（LLaVa模型）'
- en: '`pix2struct` — [Pix2StructForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructForConditionalGeneration)
    (Pix2Struct model)'
  id: totrans-5938
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pix2struct` — [Pix2StructForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/pix2struct#transformers.Pix2StructForConditionalGeneration)（Pix2Struct模型）'
- en: '`vipllava` — [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)
    (VipLlava model)'
  id: totrans-5939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vipllava` — [VipLlavaForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/vipllava#transformers.VipLlavaForConditionalGeneration)（VipLlava模型）'
- en: '`vision-encoder-decoder` — [VisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  id: totrans-5940
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision-encoder-decoder` — [VisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel)（Vision编码器解码器模型）'
- en: The model is set in evaluation mode by default using `model.eval()` (so for
    instance, dropout modules are deactivated). To train the model, you should first
    set it back in training mode with `model.train()`
  id: totrans-5941
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，使用`model.eval()`将模型设置为评估模式（例如，关闭了dropout模块）。要训练模型，您应该首先使用`model.train()`将其设置回训练模式
- en: 'Examples:'
  id: totrans-5942
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE328]'
  id: totrans-5943
  prefs: []
  type: TYPE_PRE
  zh: '[PRE328]'
- en: TFAutoModelForVision2Seq
  id: totrans-5944
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFAutoModelForVision2Seq
- en: '### `class transformers.TFAutoModelForVision2Seq`'
  id: totrans-5945
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFAutoModelForVision2Seq`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L605)'
  id: totrans-5946
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_tf_auto.py#L605)'
- en: '[PRE329]'
  id: totrans-5947
  prefs: []
  type: TYPE_PRE
  zh: '[PRE329]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a vision-to-text modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5948
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的模型类，当使用[class method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)或[class
    method](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)创建时，将作为库的模型类之一实例化（带有视觉到文本建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5949
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5950
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-5951
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE330]'
  id: totrans-5952
  prefs: []
  type: TYPE_PRE
  zh: '[PRE330]'
- en: Parameters
  id: totrans-5953
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-5954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）
    — 选择要实例化的模型类基于配置类：'
- en: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)
    configuration class: [TFBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipForConditionalGeneration)
    (BLIP model)'
  id: totrans-5955
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BlipConfig](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.BlipConfig)配置类：[TFBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipForConditionalGeneration)（BLIP模型）'
- en: '[VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    configuration class: [TFVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  id: totrans-5956
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    配置类：[TFVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel)（视觉编码器解码器模型）'
- en: Instantiates one of the model classes of the library (with a vision-to-text
    modeling head) from a configuration.
  id: totrans-5957
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化库中的模型类之一（带有视觉到文本建模头部）从配置中。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-5958
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型不会加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-5959
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE331]'
  id: totrans-5960
  prefs: []
  type: TYPE_PRE
  zh: '[PRE331]'
- en: '#### `from_pretrained`'
  id: totrans-5961
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-5962
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE332]'
  id: totrans-5963
  prefs: []
  type: TYPE_PRE
  zh: '[PRE332]'
- en: Parameters
  id: totrans-5964
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-5965
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-5966
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库内的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或命名空间在用户或组织名称下，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-5967
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-5968
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch state_dict保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，应将`from_pt`设置为`True`，并将配置对象提供为`config`参数。这种加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-5969
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*）— 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-5970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，*可选*）—
    模型使用的配置，而不是自动加载的配置。当：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-5971
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-5972
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-5973
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`并在目录中找到名为*config.json*的配置JSON文件来加载模型。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-5974
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*）— 下载的预训练模型配置应缓存在其中的目录路径，如果不应使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-5975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`）— 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-5976
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-5977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`）— 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-5978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*）— 一个代理服务器字典，按协议或端点使用，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-5979
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-5980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`) — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-5981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-5982
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅在您信任的存储库中设置为`True`，并且您已阅读了代码，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-5983
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— Hub上代码的特定修订版本，如果代码位于与模型其余部分不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们使用基于git的系统在huggingface.co上存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-5984
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 可用于更新配置对象（加载后）并初始化模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-5985
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了带有`config`的配置，则`**kwargs`将直接传递给基础模型的`__init__`方法（我们假设所有相关的配置更新已经完成）。
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-5986
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则首先将`kwargs`传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。`kwargs`中与配置属性对应的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给基础模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a vision-to-text modeling
    head) from a pretrained model.
  id: totrans-5987
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有视觉到文本建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-5988
  prefs: []
  type: TYPE_NORMAL
  zh: 选择要实例化的模型类基于配置对象的`model_type`属性（作为参数传递或从`pretrained_model_name_or_path`加载（如果可能）），或者当缺少时，通过在`pretrained_model_name_or_path`上使用模式匹配来回退：
- en: '`blip` — [TFBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipForConditionalGeneration)
    (BLIP model)'
  id: totrans-5989
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blip` — [TFBlipForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/blip#transformers.TFBlipForConditionalGeneration)（BLIP模型）'
- en: '`vision-encoder-decoder` — [TFVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  id: totrans-5990
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision-encoder-decoder` — [TFVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel)（视觉编码器解码器模型）'
- en: 'Examples:'
  id: totrans-5991
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE333]'
  id: totrans-5992
  prefs: []
  type: TYPE_PRE
  zh: '[PRE333]'
- en: FlaxAutoModelForVision2Seq
  id: totrans-5993
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlaxAutoModelForVision2Seq
- en: '### `class transformers.FlaxAutoModelForVision2Seq`'
  id: totrans-5994
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxAutoModelForVision2Seq`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L363)'
  id: totrans-5995
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/modeling_flax_auto.py#L363)'
- en: '[PRE334]'
  id: totrans-5996
  prefs: []
  type: TYPE_PRE
  zh: '[PRE334]'
- en: This is a generic model class that will be instantiated as one of the model
    classes of the library (with a vision-to-text modeling head) when created with
    the [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    class method or the [from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)
    class method.
  id: totrans-5997
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用模型类，当使用[from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)类方法或[from_config()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config)类方法创建时，将被实例化为库中的一个模型类（带有视觉到文本建模头）。
- en: This class cannot be instantiated directly using `__init__()` (throws an error).
  id: totrans-5998
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不能直接使用`__init__()`实例化（会抛出错误）。
- en: '#### `from_config`'
  id: totrans-5999
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_config`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
  id: totrans-6000
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L417)'
- en: '[PRE335]'
  id: totrans-6001
  prefs: []
  type: TYPE_PRE
  zh: '[PRE335]'
- en: Parameters
  id: totrans-6002
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The model class to instantiate is selected based on the configuration class:'
  id: totrans-6003
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)）—
    选择要实例化的模型类基于配置类：'
- en: '[VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    configuration class: [FlaxVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  id: totrans-6004
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisionEncoderDecoderConfig](/docs/transformers/v4.37.2/zh/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig)
    配置类：[FlaxVisionEncoderDecoderModel](/docs/transformers/v4.37.2/zh/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel)（视觉编码器解码器模型）'
- en: Instantiates one of the model classes of the library (with a vision-to-text
    modeling head) from a configuration.
  id: totrans-6005
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置实例化库中的一个模型类（带有视觉到文本建模头）。
- en: 'Note: Loading a model from its configuration file does **not** load the model
    weights. It only affects the model’s configuration. Use [from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)
    to load the model weights.'
  id: totrans-6006
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：从配置文件加载模型**不会**加载模型权重。它只影响模型的配置。使用[from_pretrained()](/docs/transformers/v4.37.2/zh/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained)加载模型权重。
- en: 'Examples:'
  id: totrans-6007
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE336]'
  id: totrans-6008
  prefs: []
  type: TYPE_PRE
  zh: '[PRE336]'
- en: '#### `from_pretrained`'
  id: totrans-6009
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
  id: totrans-6010
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/auto/auto_factory.py#L448)'
- en: '[PRE337]'
  id: totrans-6011
  prefs: []
  type: TYPE_PRE
  zh: '[PRE337]'
- en: Parameters
  id: totrans-6012
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — Can be either:'
  id: totrans-6013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`） — 可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-6014
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained),
    e.g., `./my_model_directory/`.
  id: totrans-6015
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存的模型权重的*目录*路径，例如，`./my_model_directory/`。
- en: A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`).
    In this case, `from_pt` should be set to `True` and a configuration object should
    be provided as `config` argument. This loading path is slower than converting
    the PyTorch model in a TensorFlow model using the provided conversion scripts
    and loading the TensorFlow model afterwards.
  id: totrans-6016
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*PyTorch state_dict保存文件*的路径或url（例如，`./pt_model/pytorch_model.bin`）。在这种情况下，`from_pt`应设置为`True`，并且应提供配置对象作为`config`参数。使用此加载路径比使用提供的转换脚本将PyTorch模型转换为TensorFlow模型并随后加载TensorFlow模型要慢。
- en: '`model_args` (additional positional arguments, *optional*) — Will be passed
    along to the underlying model `__init__()` method.'
  id: totrans-6017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_args`（额外的位置参数，*可选*） — 将传递给底层模型`__init__()`方法。'
- en: '`config` ([PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig),
    *optional*) — Configuration for the model to use instead of an automatically loaded
    configuration. Configuration can be automatically loaded when:'
  id: totrans-6018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[PretrainedConfig](/docs/transformers/v4.37.2/zh/main_classes/configuration#transformers.PretrainedConfig)，*可选*）
    — 模型使用的配置，而不是自动加载的配置。当以下情况时，配置可以自动加载：'
- en: The model is a model provided by the library (loaded with the *model id* string
    of a pretrained model).
  id: totrans-6019
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型是库中提供的模型（使用预训练模型的*模型id*字符串加载）。
- en: The model was saved using [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)
    and is reloaded by supplying the save directory.
  id: totrans-6020
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型使用[save_pretrained()](/docs/transformers/v4.37.2/zh/main_classes/model#transformers.PreTrainedModel.save_pretrained)保存，并通过提供保存目录重新加载。
- en: The model is loaded by supplying a local directory as `pretrained_model_name_or_path`
    and a configuration JSON file named *config.json* is found in the directory.
  id: totrans-6021
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供本地目录作为`pretrained_model_name_or_path`加载模型，并在目录中找到名为*config.json*的配置JSON文件。
- en: '`cache_dir` (`str` or `os.PathLike`, *optional*) — Path to a directory in which
    a downloaded pretrained model configuration should be cached if the standard cache
    should not be used.'
  id: totrans-6022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cache_dir`（`str`或`os.PathLike`，*可选*） — 下载的预训练模型配置应缓存在其中的目录路径，如果不使用标准缓存。'
- en: '`from_pt` (`bool`, *optional*, defaults to `False`) — Load the model weights
    from a PyTorch checkpoint save file (see docstring of `pretrained_model_name_or_path`
    argument).'
  id: totrans-6023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from_pt`（`bool`，*可选*，默认为`False`） — 从PyTorch检查点保存文件加载模型权重（请参阅`pretrained_model_name_or_path`参数的文档字符串）。'
- en: '`force_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to force the (re-)download of the model weights and configuration files, overriding
    the cached versions if they exist.'
  id: totrans-6024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`force_download`（`bool`，*可选*，默认为`False`） — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。'
- en: '`resume_download` (`bool`, *optional*, defaults to `False`) — Whether or not
    to delete incompletely received files. Will attempt to resume the download if
    such a file exists.'
  id: totrans-6025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_download`（`bool`，*可选*，默认为`False`） — 是否删除接收不完整的文件。如果存在这样的文件，将尝试恢复下载。'
- en: '`proxies` (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to
    use by protocol or endpoint, e.g., `{''http'': ''foo.bar:3128'', ''http://hostname'':
    ''foo.bar:4012''}`. The proxies are used on each request.'
  id: totrans-6026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxies`（`Dict[str, str]`，*可选*） — 要按协议或端点使用的代理服务器字典，例如，`{''http'': ''foo.bar:3128'',
    ''http://hostname'': ''foo.bar:4012''}`。这些代理在每个请求上使用。'
- en: '`output_loading_info(bool,` *optional*, defaults to `False`) — Whether ot not
    to also return a dictionary containing missing keys, unexpected keys and error
    messages.'
  id: totrans-6027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_loading_info(bool,` *可选*，默认为`False`) — 是否还返回包含缺失键、意外键和错误消息的字典。'
- en: '`local_files_only(bool,` *optional*, defaults to `False`) — Whether or not
    to only look at local files (e.g., not try downloading the model).'
  id: totrans-6028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local_files_only(bool,` *可选*，默认为`False`） — 是否仅查看本地文件（例如，不尝试下载模型）。'
- en: '`revision` (`str`, *optional*, defaults to `"main"`) — The specific model version
    to use. It can be a branch name, a tag name, or a commit id, since we use a git-based
    system for storing models and other artifacts on huggingface.co, so `revision`
    can be any identifier allowed by git.'
  id: totrans-6029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`trust_remote_code` (`bool`, *optional*, defaults to `False`) — Whether or
    not to allow for custom models defined on the Hub in their own modeling files.
    This option should only be set to `True` for repositories you trust and in which
    you have read the code, as it will execute code present on the Hub on your local
    machine.'
  id: totrans-6030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trust_remote_code`（`bool`，*可选*，默认为`False`）— 是否允许在Hub上定义自定义模型的建模文件。此选项应仅对您信任并且已阅读代码的存储库设置为`True`，因为它将在本地机器上执行Hub上存在的代码。'
- en: '`code_revision` (`str`, *optional*, defaults to `"main"`) — The specific revision
    to use for the code on the Hub, if the code leaves in a different repository than
    the rest of the model. It can be a branch name, a tag name, or a commit id, since
    we use a git-based system for storing models and other artifacts on huggingface.co,
    so `revision` can be any identifier allowed by git.'
  id: totrans-6031
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code_revision`（`str`，*可选*，默认为`"main"`）— 用于Hub上代码的特定修订版本，如果代码与模型的其余部分存储在不同的存储库中。它可以是分支名称、标签名称或提交ID，因为我们在huggingface.co上使用基于git的系统来存储模型和其他工件，所以`revision`可以是git允许的任何标识符。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Can be used to update
    the configuration object (after it being loaded) and initiate the model (e.g.,
    `output_attentions=True`). Behaves differently depending on whether a `config`
    is provided or automatically loaded:'
  id: totrans-6032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（附加关键字参数，*可选*）— 可用于更新配置对象（加载后）并启动模型（例如，`output_attentions=True`）。根据是否提供或自动加载了`config`，其行为会有所不同：'
- en: If a configuration is provided with `config`, `**kwargs` will be directly passed
    to the underlying model’s `__init__` method (we assume all relevant updates to
    the configuration have already been done)
  id: totrans-6033
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了`config`，`**kwargs`将直接传递给底层模型的`__init__`方法（我们假设配置的所有相关更新已经完成）
- en: If a configuration is not provided, `kwargs` will be first passed to the configuration
    class initialization function ([from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)).
    Each key of `kwargs` that corresponds to a configuration attribute will be used
    to override said attribute with the supplied `kwargs` value. Remaining keys that
    do not correspond to any configuration attribute will be passed to the underlying
    model’s `__init__` function.
  id: totrans-6034
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果未提供配置，则`kwargs`将首先传递给配置类初始化函数（[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)）。与配置属性对应的`kwargs`的每个键将用提供的`kwargs`值覆盖该属性。不对应任何配置属性的剩余键将传递给底层模型的`__init__`函数。
- en: Instantiate one of the model classes of the library (with a vision-to-text modeling
    head) from a pretrained model.
  id: totrans-6035
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类（带有视觉到文本建模头）。
- en: 'The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible), or when it’s missing, by falling back to using pattern matching
    on `pretrained_model_name_or_path`:'
  id: totrans-6036
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化的模型类是根据配置对象的`model_type`属性（如果可能作为参数传递或从`pretrained_model_name_or_path`加载）选择的，或者当缺少时，通过在`pretrained_model_name_or_path`上进行模式匹配来回退选择。
- en: '`vision-encoder-decoder` — [FlaxVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel)
    (Vision Encoder decoder model)'
  id: totrans-6037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vision-encoder-decoder` — [FlaxVisionEncoderDecoderModel](/docs/transformers/v4.37.2/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel)（视觉编码器解码器模型）'
- en: 'Examples:'
  id: totrans-6038
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE338]'
  id: totrans-6039
  prefs: []
  type: TYPE_PRE
  zh: '[PRE338]'
