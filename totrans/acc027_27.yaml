- en: Amazon SageMaker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/accelerate/usage_guides/sagemaker](https://huggingface.co/docs/accelerate/usage_guides/sagemaker)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/accelerate/v0.27.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/entry/start.6e0fb178.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/scheduler.69131cc3.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/singletons.ac467c20.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/paths.b2f3aeca.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/entry/app.67e11fc0.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/index.e1f30d73.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/nodes/0.bfeed9f0.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/nodes/45.aef65220.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/Tip.22e79575.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/CodeBlock.30cef355.js">
    <link rel="modulepreload" href="/docs/accelerate/v0.27.2/en/_app/immutable/chunks/Heading.0aab6758.js">
  prefs: []
  type: TYPE_NORMAL
- en: Hugging Face and Amazon introduced new [Hugging Face Deep Learning Containers
    (DLCs)](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-training-containers)
    to make it easier than ever to train Hugging Face Transformer models in [Amazon
    SageMaker](https://aws.amazon.com/sagemaker/).
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Setup & Installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before you can run your ðŸ¤— Accelerate scripts on Amazon SageMaker you need to
    sign up for an AWS account. If you do not have an AWS account yet learn more [here](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'After you have your AWS Account you need to install the `sagemaker` sdk for
    ðŸ¤— Accelerate with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'ðŸ¤— Accelerate currently uses the ðŸ¤— DLCs, with `transformers`, `datasets` and
    `tokenizers` pre-installed. ðŸ¤— Accelerate is not in the DLC yet (will soon be added!)
    so to use it within Amazon SageMaker you need to create a `requirements.txt` in
    the same directory where your training script is located and add it as dependency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You should also add any other dependencies you have to this `requirements.txt`.
  prefs: []
  type: TYPE_NORMAL
- en: Configure ðŸ¤— Accelerate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can configure the launch configuration for Amazon SageMaker the same as
    you do for non SageMaker training jobs with the ðŸ¤— Accelerate CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: ðŸ¤— Accelerate will go through a questionnaire about your Amazon SageMaker setup
    and create a config file you can edit.
  prefs: []
  type: TYPE_NORMAL
- en: ðŸ¤— Accelerate is not saving any of your credentials.
  prefs: []
  type: TYPE_NORMAL
- en: Prepare a ðŸ¤— Accelerate fine-tuning script
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The training script is very similar to a training script you might run outside
    of SageMaker, but to save your model after training you need to specify either
    `/opt/ml/model` or use `os.environ["SM_MODEL_DIR"]` as your save directory. After
    training, artifacts in this directory are uploaded to S3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: SageMaker doesnâ€™t support argparse actions. If you want to use, for example,
    boolean hyperparameters, you need to specify type as bool in your script and provide
    an explicit True or False value for this hyperparameter. [[REF]](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#prepare-a-pytorch-training-script).
  prefs: []
  type: TYPE_NORMAL
- en: Launch Training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can launch your training with ðŸ¤— Accelerate CLI with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This will launch your training script using your configuration. The only thing
    you have to do is provide all the arguments needed by your training script as
    named arguments.
  prefs: []
  type: TYPE_NORMAL
- en: '**Examples**'
  prefs: []
  type: TYPE_NORMAL
- en: If you run one of the example scripts, donâ€™t forget to add `accelerator.save('/opt/ml/model')`
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Advanced Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Distributed Training: Data Parallelism'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Set up the accelerate config by running `accelerate config` and answer the
    SageMaker questions and set it up. To use SageMaker DDP, select it when asked
    `What is the distributed mode? ([0] No distributed training, [1] data parallelism):`.
    Example config below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Distributed Training: Model Parallelism'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*currently in development, will be supported soon.*'
  prefs: []
  type: TYPE_NORMAL
- en: Python packages and dependencies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ðŸ¤— Accelerate currently uses the ðŸ¤— DLCs, with `transformers`, `datasets` and
    `tokenizers` pre-installed. If you want to use different/other Python packages
    you can do this by adding them to the `requirements.txt`. These packages will
    be installed before your training script is started.
  prefs: []
  type: TYPE_NORMAL
- en: 'Local Training: SageMaker Local mode'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The local mode in the SageMaker SDK allows you to run your training script
    locally inside the HuggingFace DLC (Deep Learning container) or using your custom
    container image. This is useful for debugging and testing your training script
    inside the final container environment. Local mode uses Docker compose (*Note:
    Docker Compose V2 is not supported yet*). The SDK will handle the authentication
    against ECR to pull the DLC to your local environment. You can emulate CPU (single
    and multi-instance) and GPU (single instance) SageMaker training jobs.'
  prefs: []
  type: TYPE_NORMAL
- en: To use local mode, you need to set your `ec2_instance_type` to `local`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Advanced configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The configuration allows you to override parameters for the [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html).
    These settings have to be applied in the config file and are not part of `accelerate
    config`. You can control many additional aspects of the training job, e.g. use
    Spot instances, enable network isolation and many more.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You can find all available configuration [here](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html).
  prefs: []
  type: TYPE_NORMAL
- en: Use Spot Instances
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can use Spot Instances e.g. using (see [Advanced configuration](#advanced-configuration)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '*Note: Spot Instances are subject to be terminated and training to be continued
    from a checkpoint. This is not handled in ðŸ¤— Accelerate out of the box. Contact
    us if you would like this feature.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Remote scripts: Use scripts located on Github'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*undecided if feature is needed. Contact us if you would like this feature.*'
  prefs: []
  type: TYPE_NORMAL
