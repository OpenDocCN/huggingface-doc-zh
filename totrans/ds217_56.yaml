- en: Build and load
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„å»ºå’ŒåŠ è½½
- en: 'Original text: [https://huggingface.co/docs/datasets/about_dataset_load](https://huggingface.co/docs/datasets/about_dataset_load)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡é“¾æ¥ï¼š[https://huggingface.co/docs/datasets/about_dataset_load](https://huggingface.co/docs/datasets/about_dataset_load)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Nearly every deep learning workflow begins with loading a dataset, which makes
    it one of the most important steps. With ğŸ¤— Datasets, there are more than 900 datasets
    available to help you get started with your NLP task. All you have to do is call:
    [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    to take your first step. This function is a true workhorse in every sense because
    it builds and loads every dataset you use.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ ä¹æ¯ä¸ªæ·±åº¦å­¦ä¹ å·¥ä½œæµéƒ½å§‹äºåŠ è½½æ•°æ®é›†ï¼Œè¿™ä½¿å¾—å®ƒæˆä¸ºæœ€é‡è¦çš„æ­¥éª¤ä¹‹ä¸€ã€‚ä½¿ç”¨ğŸ¤— æ•°æ®é›†ï¼Œæœ‰è¶…è¿‡ 900 ä¸ªæ•°æ®é›†å¯ä¾›æ‚¨å¼€å§‹è¿›è¡Œ NLP ä»»åŠ¡ã€‚æ‚¨åªéœ€è°ƒç”¨ï¼š[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    æ¥è¿ˆå‡ºç¬¬ä¸€æ­¥ã€‚è¿™ä¸ªå‡½æ•°åœ¨å„ä¸ªæ–¹é¢éƒ½æ˜¯ä¸€ä¸ªçœŸæ­£çš„å·¥ä½œé©¬ï¼Œå› ä¸ºå®ƒä¼šæ„å»ºå’ŒåŠ è½½æ‚¨ä½¿ç”¨çš„æ¯ä¸ªæ•°æ®é›†ã€‚
- en: 'ELI5: load_dataset'
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ELI5ï¼šload_dataset
- en: Letâ€™s begin with a basic Explain Like Iâ€™m Five.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ä¸€ä¸ªåŸºæœ¬çš„äº”å²è§£é‡Šå¼€å§‹ã€‚
- en: 'A dataset is a directory that contains:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†æ˜¯ä¸€ä¸ªåŒ…å«ä»¥ä¸‹å†…å®¹çš„ç›®å½•ï¼š
- en: Some data files in generic formats (JSON, CSV, Parquet, text, etc.)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€äº›ä»¥é€šç”¨æ ¼å¼ï¼ˆJSONã€CSVã€Parquetã€æ–‡æœ¬ç­‰ï¼‰å­˜å‚¨çš„æ•°æ®æ–‡ä»¶
- en: A dataset card named `README.md` that contains documentation about the dataset
    as well as a YAML header to define the datasets tags and configurations
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªåä¸º`README.md`çš„æ•°æ®é›†å¡ç‰‡ï¼ŒåŒ…å«æœ‰å…³æ•°æ®é›†çš„æ–‡æ¡£ä»¥åŠä¸€ä¸ª YAML å¤´éƒ¨æ¥å®šä¹‰æ•°æ®é›†çš„æ ‡ç­¾å’Œé…ç½®
- en: An optional dataset script if it requires some code to read the data files.
    This is sometimes used to load files of specific formats and structures.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœéœ€è¦ä¸€äº›ä»£ç æ¥è¯»å–æ•°æ®æ–‡ä»¶ï¼Œåˆ™åŒ…å«ä¸€ä¸ªå¯é€‰çš„æ•°æ®é›†è„šæœ¬ã€‚æœ‰æ—¶ç”¨äºåŠ è½½ç‰¹å®šæ ¼å¼å’Œç»“æ„çš„æ–‡ä»¶ã€‚
- en: The [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    function fetches the requested dataset locally or from the Hugging Face Hub. The
    Hub is a central repository where all the Hugging Face datasets and models are
    stored.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)å‡½æ•°ä¼šåœ¨æœ¬åœ°æˆ–ä»
    Hugging Face Hub è·å–è¯·æ±‚çš„æ•°æ®é›†ã€‚Hub æ˜¯ä¸€ä¸ªä¸­å¤®å­˜å‚¨åº“ï¼Œå­˜å‚¨äº†æ‰€æœ‰ Hugging Face æ•°æ®é›†å’Œæ¨¡å‹ã€‚'
- en: 'If the dataset only contains data files, then [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    automatically infers how to load the data files from their extensions (json, csv,
    parquet, txt, etc.). Under the hood, ğŸ¤— Datasets will use an appropriate [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    based on the data files format. There exist one builder per data file format in
    ğŸ¤— Datasets:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ•°æ®é›†åªåŒ…å«æ•°æ®æ–‡ä»¶ï¼Œåˆ™[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)ä¼šè‡ªåŠ¨æ¨æ–­å¦‚ä½•ä»å…¶æ‰©å±•åï¼ˆjsonã€csvã€parquetã€txtç­‰ï¼‰åŠ è½½æ•°æ®æ–‡ä»¶ã€‚åœ¨å¹•åï¼ŒğŸ¤—
    æ•°æ®é›†å°†æ ¹æ®æ•°æ®æ–‡ä»¶æ ¼å¼ä½¿ç”¨é€‚å½“çš„[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)ã€‚ğŸ¤—
    æ•°æ®é›†ä¸­å­˜åœ¨ä¸€ä¸ªæ„å»ºå™¨å¯¹åº”äºæ¯ç§æ•°æ®æ–‡ä»¶æ ¼å¼ï¼š
- en: '[datasets.packaged_modules.text.Text](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.text.Text)
    for text'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.text.Text](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.text.Text)
    ç”¨äºæ–‡æœ¬'
- en: '[datasets.packaged_modules.csv.Csv](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.csv.Csv)
    for CSV and TSV'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.csv.Csv](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.csv.Csv)
    ç”¨äº CSV å’Œ TSV'
- en: '[datasets.packaged_modules.json.Json](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.json.Json)
    for JSON and JSONL'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.json.Json](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.json.Json)
    ç”¨äº JSON å’Œ JSONL'
- en: '[datasets.packaged_modules.parquet.Parquet](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.parquet.Parquet)
    for Parquet'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.parquet.Parquet](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.parquet.Parquet)
    ç”¨äº Parquet'
- en: '[datasets.packaged_modules.arrow.Arrow](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.arrow.Arrow)
    for Arrow (streaming file format)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.arrow.Arrow](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.arrow.Arrow)
    ç”¨äº Arrowï¼ˆæµæ–‡ä»¶æ ¼å¼ï¼‰'
- en: '[datasets.packaged_modules.sql.Sql](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.sql.Sql)
    for SQL databases'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.sql.Sql](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.sql.Sql)
    ç”¨äº SQL æ•°æ®åº“'
- en: '[datasets.packaged_modules.imagefolder.ImageFolder](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.imagefolder.ImageFolder)
    for image folders'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.imagefolder.ImageFolder](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.imagefolder.ImageFolder)
    ç”¨äºå›¾åƒæ–‡ä»¶å¤¹'
- en: '[datasets.packaged_modules.audiofolder.AudioFolder](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.audiofolder.AudioFolder)
    for audio folders'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[datasets.packaged_modules.audiofolder.AudioFolder](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.packaged_modules.audiofolder.AudioFolder)
    ç”¨äºéŸ³é¢‘æ–‡ä»¶å¤¹'
- en: If the dataset has a dataset script, then it downloads and imports it from the
    Hugging Face Hub. Code in the dataset script defines a custom [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    the dataset information (description, features, URL to the original files, etc.),
    and tells ğŸ¤— Datasets how to generate and display examples from it.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ•°æ®é›†æœ‰ä¸€ä¸ªæ•°æ®é›†è„šæœ¬ï¼Œé‚£ä¹ˆå®ƒä¼šä» Hugging Face Hub ä¸‹è½½å¹¶å¯¼å…¥ã€‚æ•°æ®é›†è„šæœ¬ä¸­çš„ä»£ç å®šä¹‰äº†ä¸€ä¸ªè‡ªå®šä¹‰[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)æ¥æè¿°æ•°æ®é›†ä¿¡æ¯ï¼ˆæè¿°ã€ç‰¹å¾ã€åŸå§‹æ–‡ä»¶çš„URLç­‰ï¼‰ï¼Œå¹¶å‘Šè¯‰ğŸ¤—
    æ•°æ®é›†å¦‚ä½•ç”Ÿæˆå’Œæ˜¾ç¤ºç¤ºä¾‹ã€‚
- en: Read the [Share](./upload_dataset) section to learn more about how to share
    a dataset. This section also provides a step-by-step guide on how to write your
    own dataset loading script!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: é˜…è¯»[åˆ†äº«](./upload_dataset)éƒ¨åˆ†ï¼Œäº†è§£å¦‚ä½•åˆ†äº«æ•°æ®é›†ã€‚è¯¥éƒ¨åˆ†è¿˜æä¾›äº†å…³äºå¦‚ä½•ç¼–å†™è‡ªå·±çš„æ•°æ®é›†åŠ è½½è„šæœ¬çš„é€æ­¥æŒ‡å—ï¼
- en: ğŸ¤— Datasets downloads the dataset files from the original URL, generates the
    dataset and caches it in an Arrow table on your drive. If youâ€™ve downloaded the
    dataset before, then ğŸ¤— Datasets will reload it from the cache to save you the
    trouble of downloading it again.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¤— æ•°æ®é›†ä¼šä»åŸå§‹URLä¸‹è½½æ•°æ®é›†æ–‡ä»¶ï¼Œç”Ÿæˆæ•°æ®é›†å¹¶å°†å…¶ç¼“å­˜åœ¨æ‚¨çš„é©±åŠ¨å™¨ä¸Šçš„ Arrow è¡¨ä¸­ã€‚å¦‚æœæ‚¨ä¹‹å‰å·²ç»ä¸‹è½½è¿‡æ•°æ®é›†ï¼Œåˆ™ğŸ¤— æ•°æ®é›†å°†ä»ç¼“å­˜ä¸­é‡æ–°åŠ è½½ï¼Œä»¥å…å†æ¬¡ä¸‹è½½ã€‚
- en: Now that you have a high-level understanding about how datasets are built, letâ€™s
    take a closer look at the nuts and bolts of how all this works.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ‚¨å·²ç»å¯¹æ•°æ®é›†æ˜¯å¦‚ä½•æ„å»ºæœ‰äº†é«˜å±‚æ¬¡çš„ç†è§£ï¼Œè®©æˆ‘ä»¬æ›´ä»”ç»†åœ°çœ‹çœ‹æ‰€æœ‰è¿™äº›æ˜¯å¦‚ä½•è¿ä½œçš„ã€‚
- en: Building a dataset
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ„å»ºæ•°æ®é›†
- en: 'When you load a dataset for the first time, ğŸ¤— Datasets takes the raw data file
    and builds it into a table of rows and typed columns. There are two main classes
    responsible for building a dataset: [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    and [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‚¨ç¬¬ä¸€æ¬¡åŠ è½½æ•°æ®é›†æ—¶ï¼ŒğŸ¤— æ•°æ®é›†ä¼šå°†åŸå§‹æ•°æ®æ–‡ä»¶æ„å»ºæˆä¸€å¼ è¡Œå’Œç±»å‹åˆ—çš„è¡¨æ ¼ã€‚è´Ÿè´£æ„å»ºæ•°æ®é›†çš„ä¸¤ä¸ªä¸»è¦ç±»æ˜¯ï¼š[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    å’Œ [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)ã€‚
- en: '![](../Images/bd493a651fa07ec8829a2c0ef2818f43.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd493a651fa07ec8829a2c0ef2818f43.png)'
- en: BuilderConfig
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BuilderConfig
- en: '[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    is the configuration class of [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder).
    The [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    contains the following basic attributes about a dataset:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    æ˜¯ [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    çš„é…ç½®ç±»ã€‚[BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    åŒ…å«æœ‰å…³æ•°æ®é›†çš„ä»¥ä¸‹åŸºæœ¬å±æ€§ï¼š'
- en: '| Attribute | Description |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| å±æ€§ | æè¿° |'
- en: '| --- | --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `name` | Short name of the dataset. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| `name` | æ•°æ®é›†çš„ç®€ç§°ã€‚ |'
- en: '| `version` | Dataset version identifier. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| `version` | æ•°æ®é›†ç‰ˆæœ¬æ ‡è¯†ç¬¦ã€‚ |'
- en: '| `data_dir` | Stores the path to a local folder containing the data files.
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `data_dir` | å­˜å‚¨åŒ…å«æ•°æ®æ–‡ä»¶çš„æœ¬åœ°æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚ |'
- en: '| `data_files` | Stores paths to local data files. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `data_files` | å­˜å‚¨æœ¬åœ°æ•°æ®æ–‡ä»¶çš„è·¯å¾„ã€‚ |'
- en: '| `description` | Description of the dataset. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `description` | æ•°æ®é›†æè¿°ã€‚ |'
- en: 'If you want to add additional attributes to your dataset such as the class
    labels, you can subclass the base [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class. There are two ways to populate the attributes of a [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class or subclass:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³å‘æ•°æ®é›†æ·»åŠ é¢å¤–çš„å±æ€§ï¼Œä¾‹å¦‚ç±»æ ‡ç­¾ï¼Œå¯ä»¥å¯¹åŸºç¡€ [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    ç±»è¿›è¡Œå­ç±»åŒ–ã€‚æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å¡«å…… [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    ç±»æˆ–å­ç±»çš„å±æ€§ï¼š
- en: Provide a list of predefined [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class (or subclass) instances in the datasets `DatasetBuilder.BUILDER_CONFIGS()`
    attribute.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®é›†çš„ `DatasetBuilder.BUILDER_CONFIGS()` å±æ€§ä¸­æä¾›é¢„å®šä¹‰çš„ [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    ç±»ï¼ˆæˆ–å­ç±»ï¼‰å®ä¾‹çš„åˆ—è¡¨ã€‚
- en: When you call [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset),
    any keyword arguments that are not specific to the method will be used to set
    the associated attributes of the [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    class. This will override the predefined attributes if a specific configuration
    was selected.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æ‚¨è°ƒç”¨ [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    æ—¶ï¼Œä»»ä½•ä¸ç‰¹å®šäºè¯¥æ–¹æ³•çš„å…³é”®å­—å‚æ•°å°†ç”¨äºè®¾ç½® [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    ç±»çš„ç›¸å…³å±æ€§ã€‚å¦‚æœé€‰æ‹©äº†ç‰¹å®šé…ç½®ï¼Œè¿™å°†è¦†ç›–é¢„å®šä¹‰çš„å±æ€§ã€‚
- en: You can also set the [DatasetBuilder.BUILDER_CONFIG_CLASS](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    to any custom subclass of [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨è¿˜å¯ä»¥å°† [DatasetBuilder.BUILDER_CONFIG_CLASS](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    è®¾ç½®ä¸º [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    çš„ä»»ä½•è‡ªå®šä¹‰å­ç±»ã€‚
- en: DatasetBuilder
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DatasetBuilder
- en: '[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    accesses all the attributes inside [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    to build the actual dataset.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    è®¿é—® [BuilderConfig](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.BuilderConfig)
    ä¸­çš„æ‰€æœ‰å±æ€§æ¥æ„å»ºå®é™…æ•°æ®é›†ã€‚'
- en: '![](../Images/bb7161ccc3fa095689cfa137b5590ded.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb7161ccc3fa095689cfa137b5590ded.png)'
- en: 'There are three main methods in [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    ä¸­æœ‰ä¸‰ä¸ªä¸»è¦æ–¹æ³•ï¼š'
- en: '`DatasetBuilder._info()` is in charge of defining the dataset attributes. When
    you call `dataset.info`, ğŸ¤— Datasets returns the information stored here. Likewise,
    the [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    are also specified here. Remember, the [Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    are like the skeleton of the dataset. It provides the names and types of each
    column.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetBuilder._info()` è´Ÿè´£å®šä¹‰æ•°æ®é›†å±æ€§ã€‚å½“æ‚¨è°ƒç”¨ `dataset.info` æ—¶ï¼ŒğŸ¤— æ•°æ®é›†ä¼šè¿”å›å­˜å‚¨åœ¨æ­¤å¤„çš„ä¿¡æ¯ã€‚åŒæ ·ï¼Œ[Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    ä¹Ÿåœ¨è¿™é‡ŒæŒ‡å®šã€‚è¯·è®°ä½ï¼Œ[Features](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Features)
    å°±åƒæ•°æ®é›†çš„éª¨æ¶ã€‚å®ƒæä¾›äº†æ¯åˆ—çš„åç§°å’Œç±»å‹ã€‚'
- en: '`DatasetBuilder._split_generator` downloads or retrieves the requested data
    files, organizes them into splits, and defines specific arguments for the generation
    process. This method has a [DownloadManager](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager)
    that downloads files or fetches them from your local filesystem. Within the [DownloadManager](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager),
    there is a [DownloadManager.download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)
    method that accepts a dictionary of URLs to the original data files, and downloads
    the requested files. Accepted inputs include: a single URL or path, or a list/dictionary
    of URLs or paths. Any compressed file types like TAR, GZIP and ZIP archives will
    be automatically extracted.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetBuilder._split_generator` ä¸‹è½½æˆ–æ£€ç´¢è¯·æ±‚çš„æ•°æ®æ–‡ä»¶ï¼Œå°†å…¶ç»„ç»‡æˆæ‹†åˆ†ï¼Œå¹¶ä¸ºç”Ÿæˆè¿‡ç¨‹å®šä¹‰ç‰¹å®šå‚æ•°ã€‚è¯¥æ–¹æ³•å…·æœ‰ä¸€ä¸ª
    [DownloadManager](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager)ï¼Œç”¨äºä¸‹è½½æ–‡ä»¶æˆ–ä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè·å–æ–‡ä»¶ã€‚åœ¨
    [DownloadManager](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager)
    ä¸­ï¼Œæœ‰ä¸€ä¸ª [DownloadManager.download_and_extract()](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract)
    æ–¹æ³•ï¼Œæ¥å—ä¸€ä¸ªåŒ…å«åŸå§‹æ•°æ®æ–‡ä»¶çš„ URL å­—å…¸ï¼Œå¹¶ä¸‹è½½è¯·æ±‚çš„æ–‡ä»¶ã€‚æ¥å—çš„è¾“å…¥åŒ…æ‹¬ï¼šå•ä¸ª URL æˆ–è·¯å¾„ï¼Œæˆ– URL æˆ–è·¯å¾„çš„åˆ—è¡¨/å­—å…¸ã€‚ä»»ä½•å‹ç¼©æ–‡ä»¶ç±»å‹ï¼Œå¦‚
    TARã€GZIP å’Œ ZIP å­˜æ¡£ï¼Œéƒ½å°†è¢«è‡ªåŠ¨æå–ã€‚'
- en: Once the files are downloaded, [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    organizes them into splits. The [SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    contains the name of the split, and any keyword arguments that are provided to
    the `DatasetBuilder._generate_examples` method. The keyword arguments can be specific
    to each split, and typically comprise at least the local path to the data files
    for each split.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ–‡ä»¶ä¸‹è½½å®Œæˆï¼Œ[SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    å°†å®ƒä»¬ç»„ç»‡æˆæ‹†åˆ†ã€‚[SplitGenerator](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.SplitGenerator)
    åŒ…å«æ‹†åˆ†çš„åç§°ï¼Œä»¥åŠæä¾›ç»™ `DatasetBuilder._generate_examples` æ–¹æ³•çš„ä»»ä½•å…³é”®å­—å‚æ•°ã€‚å…³é”®å­—å‚æ•°å¯ä»¥é’ˆå¯¹æ¯ä¸ªæ‹†åˆ†å…·ä½“è®¾ç½®ï¼Œé€šå¸¸è‡³å°‘åŒ…æ‹¬æ¯ä¸ªæ‹†åˆ†çš„æ•°æ®æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„ã€‚
- en: '`DatasetBuilder._generate_examples` reads and parses the data files for a split.
    Then it yields dataset examples according to the format specified in the `features`
    from `DatasetBuilder._info()`. The input of `DatasetBuilder._generate_examples`
    is actually the `filepath` provided in the keyword arguments of the last method.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DatasetBuilder._generate_examples` è¯»å–å¹¶è§£ææ‹†åˆ†çš„æ•°æ®æ–‡ä»¶ã€‚ç„¶åæ ¹æ® `DatasetBuilder._info()`
    ä¸­æŒ‡å®šçš„ `features` æ ¼å¼ç”Ÿæˆæ•°æ®é›†ç¤ºä¾‹ã€‚`DatasetBuilder._generate_examples` çš„è¾“å…¥å®é™…ä¸Šæ˜¯ä¸Šä¸€ä¸ªæ–¹æ³•çš„å…³é”®å­—å‚æ•°ä¸­æä¾›çš„
    `filepath`ã€‚'
- en: The dataset is generated with a Python generator, which doesnâ€™t load all the
    data in memory. As a result, the generator can handle large datasets. However,
    before the generated samples are flushed to the dataset file on disk, they are
    stored in an `ArrowWriter` buffer. This means the generated samples are written
    by batch. If your dataset samples consumes a lot of memory (images or videos),
    then make sure to specify a low value for the `DEFAULT_WRITER_BATCH_SIZE` attribute
    in [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder).
    We recommend not exceeding a size of 200 MB.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ•°æ®é›†æ˜¯ä½¿ç”¨ Python ç”Ÿæˆå™¨ç”Ÿæˆçš„ï¼Œä¸ä¼šå°†æ‰€æœ‰æ•°æ®åŠ è½½åˆ°å†…å­˜ä¸­ã€‚å› æ­¤ï¼Œç”Ÿæˆå™¨å¯ä»¥å¤„ç†å¤§å‹æ•°æ®é›†ã€‚ç„¶è€Œï¼Œåœ¨ç”Ÿæˆçš„æ ·æœ¬åˆ·æ–°åˆ°ç£ç›˜ä¸Šçš„æ•°æ®é›†æ–‡ä»¶ä¹‹å‰ï¼Œå®ƒä»¬ä¼šå­˜å‚¨åœ¨
    `ArrowWriter` ç¼“å†²åŒºä¸­ã€‚è¿™æ„å‘³ç€ç”Ÿæˆçš„æ ·æœ¬æ˜¯æŒ‰æ‰¹å†™å…¥çš„ã€‚å¦‚æœæ‚¨çš„æ•°æ®é›†æ ·æœ¬æ¶ˆè€—å¤§é‡å†…å­˜ï¼ˆå›¾åƒæˆ–è§†é¢‘ï¼‰ï¼Œè¯·ç¡®ä¿åœ¨ [DatasetBuilder](/docs/datasets/v2.17.0/en/package_reference/builder_classes#datasets.DatasetBuilder)
    ä¸­æŒ‡å®š `DEFAULT_WRITER_BATCH_SIZE` å±æ€§çš„ä½å€¼ã€‚æˆ‘ä»¬å»ºè®®ä¸è¦è¶…è¿‡ 200 MB çš„å¤§å°ã€‚
- en: Maintaining integrity
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¿æŒå®Œæ•´æ€§
- en: 'To ensure a dataset is complete, [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    will perform a series of tests on the downloaded files to make sure everything
    is there. This way, you donâ€™t encounter any surprises when your requested dataset
    doesnâ€™t get generated as expected. [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    verifies:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºç¡®ä¿æ•°æ®é›†å®Œæ•´ï¼Œ[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    å°†å¯¹ä¸‹è½½çš„æ–‡ä»¶æ‰§è¡Œä¸€ç³»åˆ—æµ‹è¯•ï¼Œä»¥ç¡®ä¿ä¸€åˆ‡å°±ç»ªã€‚è¿™æ ·ï¼Œå½“æ‚¨è¯·æ±‚çš„æ•°æ®é›†æœªæŒ‰é¢„æœŸç”Ÿæˆæ—¶ï¼Œæ‚¨å°±ä¸ä¼šé‡åˆ°ä»»ä½•æ„å¤–ã€‚[load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    éªŒè¯ï¼š
- en: The number of splits in the generated `DatasetDict`.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„ `DatasetDict` ä¸­çš„æ‹†åˆ†æ•°é‡ã€‚
- en: The number of samples in each split of the generated `DatasetDict`.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„ `DatasetDict` ä¸­æ¯ä¸ªæ‹†åˆ†ä¸­çš„æ ·æœ¬æ•°é‡ã€‚
- en: The list of downloaded files.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸‹è½½æ–‡ä»¶åˆ—è¡¨ã€‚
- en: The SHA256 checksums of the downloaded files (disabled by defaut).
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸‹è½½æ–‡ä»¶çš„ SHA256 æ ¡éªŒå’Œï¼ˆé»˜è®¤æƒ…å†µä¸‹å·²ç¦ç”¨ï¼‰ã€‚
- en: If the dataset doesnâ€™t pass the verifications, it is likely that the original
    host of the dataset made some changes in the data files.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ•°æ®é›†æœªé€šè¿‡éªŒè¯ï¼Œå¾ˆå¯èƒ½æ˜¯æ•°æ®é›†çš„åŸå§‹ä¸»æœºå¯¹æ•°æ®æ–‡ä»¶è¿›è¡Œäº†ä¸€äº›æ›´æ”¹ã€‚
- en: If it is your own dataset, youâ€™ll need to recompute the information above and
    update the `README.md` file in your dataset repository. Take a look at this [section](dataset_script#optional-generate-dataset-metadata)
    to learn how to generate and update this metadata.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ˜¯æ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œæ‚¨éœ€è¦é‡æ–°è®¡ç®—ä¸Šè¿°ä¿¡æ¯ï¼Œå¹¶æ›´æ–°æ•°æ®é›†å­˜å‚¨åº“ä¸­çš„ `README.md` æ–‡ä»¶ã€‚æŸ¥çœ‹è¿™ä¸ª [section](dataset_script#optional-generate-dataset-metadata)
    äº†è§£å¦‚ä½•ç”Ÿæˆå’Œæ›´æ–°è¿™äº›å…ƒæ•°æ®ã€‚
- en: In this case, an error is raised to alert that the dataset has changed. To ignore
    the error, one needs to specify `verification_mode="no_checks"` in [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset).
    Anytime you see a verification error, feel free to open a discussion or pull request
    in the corresponding dataset â€œCommunityâ€ tab, so that the integrity checks for
    that dataset are updated.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¼šå¼•å‘é”™è¯¯ä»¥è­¦ç¤ºæ•°æ®é›†å·²æ›´æ”¹ã€‚è¦å¿½ç•¥é”™è¯¯ï¼Œéœ€è¦åœ¨ [load_dataset()](/docs/datasets/v2.17.0/en/package_reference/loading_methods#datasets.load_dataset)
    ä¸­æŒ‡å®š `verification_mode="no_checks"`ã€‚æ¯å½“çœ‹åˆ°éªŒè¯é”™è¯¯æ—¶ï¼Œè¯·éšæ—¶åœ¨ç›¸åº”æ•°æ®é›†çš„â€œç¤¾åŒºâ€é€‰é¡¹å¡ä¸­å¼€å¯è®¨è®ºæˆ–æ‹‰å–è¯·æ±‚ï¼Œä»¥ä¾¿æ›´æ–°è¯¥æ•°æ®é›†çš„å®Œæ•´æ€§æ£€æŸ¥ã€‚
- en: Security
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®‰å…¨æ€§
- en: The dataset repositories on the Hub are scanned for malware, see more information
    [here](https://huggingface.co/docs/hub/security#malware-scanning).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Hubä¸Šçš„æ•°æ®é›†å­˜å‚¨åº“ä¼šè¿›è¡Œæ¶æ„è½¯ä»¶æ‰«æï¼Œæ›´å¤šä¿¡æ¯è¯·å‚è§[è¿™é‡Œ](https://huggingface.co/docs/hub/security#malware-scanning)ã€‚
- en: Moreover the datasets without a namespace (originally contributed on our GitHub
    repository) have all been reviewed by our maintainers. The code of these datasets
    is considered **safe**. It concerns datasets that are not under a namespace, e.g.
    â€œsquadâ€ or â€œglueâ€, unlike the other datasets that are named â€œusername/dataset_nameâ€
    or â€œorg/dataset_nameâ€.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæ²¡æœ‰å‘½åç©ºé—´çš„æ•°æ®é›†ï¼ˆæœ€åˆåœ¨æˆ‘ä»¬çš„GitHubå­˜å‚¨åº“ä¸Šè´¡çŒ®ï¼‰å·²ç»ç”±æˆ‘ä»¬çš„ç»´æŠ¤äººå‘˜è¿›è¡Œäº†å®¡æ ¸ã€‚è¿™äº›æ•°æ®é›†çš„ä»£ç è¢«è®¤ä¸ºæ˜¯**å®‰å…¨**çš„ã€‚è¿™æ¶‰åŠåˆ°æ²¡æœ‰å‘½åç©ºé—´çš„æ•°æ®é›†ï¼Œä¾‹å¦‚â€œsquadâ€æˆ–â€œglueâ€ï¼Œä¸åŒäºå…¶ä»–è¢«å‘½åä¸ºâ€œusername/dataset_nameâ€æˆ–â€œorg/dataset_nameâ€çš„æ•°æ®é›†ã€‚
