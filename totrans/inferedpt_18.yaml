- en: Create custom Inference Handler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://huggingface.co/docs/inference-endpoints/guides/custom_handler](https://huggingface.co/docs/inference-endpoints/guides/custom_handler)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/inference-endpoints/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/entry/start.efd013a9.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/scheduler.389d799c.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/singletons.eafbeb3b.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/paths.b3517460.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/entry/app.53dcf7ee.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/index.8f81d18f.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/nodes/0.474ae6bf.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/nodes/11.335bbf1c.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/CodeBlock.3845caa1.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/Heading.41733039.js">
  prefs: []
  type: TYPE_NORMAL
- en: Hugging Face Endpoints supports all of the Transformers and Sentence-Transformers
    tasks and can support custom tasks, including custom pre- & post-processing. The
    customization can be done through a [handler.py](https://huggingface.co/philschmid/distilbert-onnx-banking77/blob/main/handler.py)
    file in your model repository on the Hugging Face Hub.
  prefs: []
  type: TYPE_NORMAL
- en: The [handler.py](https://huggingface.co/philschmid/distilbert-onnx-banking77/blob/main/handler.py)
    needs to implement the [EndpointHandler](https://huggingface.co/philschmid/distilbert-onnx-banking77/blob/main/handler.py)
    class with a `__init__` and a `__call__` method.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to use custom dependencies, e.g. [optimum](https://raw.githubusercontent.com/huggingface/optimum),
    the dependencies must be listed in a `requirements.txt` as described above in
    ‚Äúadd custom dependencies.‚Äù
  prefs: []
  type: TYPE_NORMAL
- en: Custom Handler Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are already several public examples on the [Hugging Face Hub](https://huggingface.co/models?other=endpoints-template)
    where you can take insipiration or directly use them. The repositories are tagged
    with `endpoints-template` and can be found under this [link](https://huggingface.co/models?other=endpoints-template).
  prefs: []
  type: TYPE_NORMAL
- en: 'Included examples are for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Optimum and ONNX Runtime](https://huggingface.co/philschmid/distilbert-onnx-banking77)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Image Embeddings with BLIP](https://huggingface.co/florentgbelidji/blip_image_embeddings)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TrOCR for OCR Detection](https://huggingface.co/philschmid/trocr-base-printed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Optimized Sentence Transformers with Optimum](https://huggingface.co/philschmid/all-MiniLM-L6-v2-optimum-embeddings)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pyannote Speaker diarization](https://huggingface.co/philschmid/pyannote-speaker-diarization-endpoint)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LayoutLM](https://huggingface.co/philschmid/layoutlm-funsd)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Flair NER](https://huggingface.co/philschmid/flair-ner-english-ontonotes-large)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT-J 6B Single GPU](https://huggingface.co/philschmid/gpt-j-6B-fp16-sharded)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Donut Document understanding](https://huggingface.co/philschmid/donut-base-finetuned-cord-v2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SetFit classifier](https://huggingface.co/philschmid/setfit-ag-news-endpoint)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tutorial
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before creating a Custom Handler, you need a Hugging Face Model repository with
    your model weights and an Access Token with *WRITE* access to the repository.
    To find, create and manage Access Tokens, click [here](https://huggingface.co/settings/tokens).
  prefs: []
  type: TYPE_NORMAL
- en: If you want to write a Custom Handler for an existing model from the community,
    you can use the [repo_duplicator](https://huggingface.co/spaces/osanseviero/repo_duplicator)
    to create a repository fork.
  prefs: []
  type: TYPE_NORMAL
- en: The code can also be found in this [Notebook](https://colab.research.google.com/drive/1hANJeRa1PK1gZaUorobnQGu4bFj4_4Rf?usp=sharing).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also search for already existing Custom Handlers here: [https://huggingface.co/models?other=endpoints-template](https://huggingface.co/models?other=endpoints-template)'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Set up Development Environment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The easiest way to develop our custom handler is to set up a local development
    environment, to implement, test, and iterate there, and then deploy it as an Inference
    Endpoint. The first step is to install all required development dependencies.
    *needed to create the custom handler, not needed for inference*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: After we have installed our libraries we will clone our repository to our development
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: We will use [philschmid/distilbert-base-uncased-emotion](https://huggingface.co/philschmid/distilbert-base-uncased-emotion)
    during the tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To be able to push our CP later you need to login into our HF account. This
    can be done by using the `huggingface-cli`.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: Make sure to configure git config as well.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 2\. Create EndpointHandler (CP)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After we have set up our environment, we can start creating your custom handler.
    The custom handler is a Python class (`EndpointHandler`) inside a `handler.py`
    file in our repository. The `EndpointHandler` needs to implement an `__init__`
    and a `__call__` method.
  prefs: []
  type: TYPE_NORMAL
- en: The `__init__` method will be called when starting the Endpoint and will receive
    1 argument, a string with the path to your model weights. This allows you to load
    your model correctly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `__call__` method will be called on every request and receive a dictionary
    with your request body as a python dictionary. It will always contain the `inputs`
    key.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first step is to create our `handler.py` in the local clone of our repository.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In there, you define your `EndpointHandler` class with the `__init__` and `__call__`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 3\. Customize EndpointHandler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, you can add all of the custom logic you want to use during initialization
    or inference to your CP. You can already find multiple [Custom Handler on the
    Hub](https://huggingface.co/models?other=endpoints-template) if you need some
    inspiration. In our example, we will add a custom condition based on additional
    payload information.
  prefs: []
  type: TYPE_NORMAL
- en: '*The model we are using in the tutorial is fine-tuned to detect emotions. We
    will add an additional payload field for the date, and will use an external package
    to check if it is a holiday, to add a condition so that when the input date is
    a holiday, the model returns ‚Äúhappy‚Äù - since everyone is happy when there are
    holidays* üå¥üéâüòÜ'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to create a new `requirements.txt` and add our [holiday detection
    package](https://pypi.org/project/holidays/) and make sure we have it installed
    in our development environment as well.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Next, we have to adjust our `handler.py` and `EndpointHandler` to match our
    condition.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 4\. Test EndpointHandler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To test our EndpointHandler, we can simplify import, initialize and test it.
    Therefore we only need to prepare a sample payload.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It works!!!! üéâ
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: If you are using a notebook you might have to restart your kernel when
    you make changes to the handler.py since it is not automatically re-imported.*'
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Push the Custom Handler to your repository
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After you have successfully tested your handler locally, you can push it to
    your repository by simply using basic git commands.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now, you should see your `handler.py` and `requirements.txt` in your repository
    in the [‚ÄúFiles and version‚Äù](https://huggingface.co/philschmid/distilbert-base-uncased-emotion/tree/main)
    tab.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Deploy your Custom Handler as an Inference Endpoint
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The last step is to deploy your Custom Handler as an Inference Endpoint. You
    can deploy your Custom Handler like you would a regular Inference Endpoint. Add
    your repository, select your cloud and region, your instance and security setting,
    and deploy.
  prefs: []
  type: TYPE_NORMAL
- en: When creating your Endpoint, the Inference Endpoint Service will check for an
    available and valid `handler.py`, and will use it for serving requests no matter
    which ‚ÄúTask‚Äù you select.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: In your [Inference Endpoints dashboard](https://ui.endpoints.huggingface.co/),
    the Task for this Endpoint should now be set to Custom*'
  prefs: []
  type: TYPE_NORMAL
