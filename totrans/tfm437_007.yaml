- en: Load pretrained instances with an AutoClass
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial](https://huggingface.co/docs/transformers/v4.37.2/en/autoclass_tutorial)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: With so many different Transformer architectures, it can be challenging to create
    one for your checkpoint. As a part of ðŸ¤— Transformers core philosophy to make the
    library easy, simple and flexible to use, an `AutoClass` automatically infers
    and loads the correct architecture from a given checkpoint. The `from_pretrained()`
    method lets you quickly load a pretrained model for any architecture so you donâ€™t
    have to devote time and resources to train a model from scratch. Producing this
    type of checkpoint-agnostic code means if your code works for one checkpoint,
    it will work with another checkpoint - as long as it was trained for a similar
    task - even if the architecture is different.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, architecture refers to the skeleton of the model and checkpoints are
    the weights for a given architecture. For example, [BERT](https://huggingface.co/bert-base-uncased)
    is an architecture, while `bert-base-uncased` is a checkpoint. Model is a general
    term that can mean either architecture or checkpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this tutorial, learn to:'
  prefs: []
  type: TYPE_NORMAL
- en: Load a pretrained tokenizer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load a pretrained image processor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load a pretrained feature extractor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load a pretrained processor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load a pretrained model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load a model as a backbone.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AutoTokenizer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Nearly every NLP task begins with a tokenizer. A tokenizer converts your input
    into a format that can be processed by the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load a tokenizer with [AutoTokenizer.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then tokenize your input as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: AutoImageProcessor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For vision tasks, an image processor processes the image into the correct input
    format.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: AutoFeatureExtractor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For audio tasks, a feature extractor processes the audio signal the correct
    input format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load a feature extractor with [AutoFeatureExtractor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: AutoProcessor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multimodal tasks require a processor that combines two types of preprocessing
    tools. For example, the [LayoutLMV2](model_doc/layoutlmv2) model requires an image
    processor to handle images and a tokenizer to handle text; a processor combines
    both of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load a processor with [AutoProcessor.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoProcessor.from_pretrained):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: AutoModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PytorchHide Pytorch content
  prefs: []
  type: TYPE_NORMAL
- en: 'The `AutoModelFor` classes let you load a pretrained model for a given task
    (see [here](model_doc/auto) for a complete list of available tasks). For example,
    load a model for sequence classification with [AutoModelForSequenceClassification.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Easily reuse the same checkpoint to load an architecture for a different task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: For PyTorch models, the `from_pretrained()` method uses `torch.load()` which
    internally uses `pickle` and is known to be insecure. In general, never load a
    model that could have come from an untrusted source, or that could have been tampered
    with. This security risk is partially mitigated for public models hosted on the
    Hugging Face Hub, which are [scanned for malware](https://huggingface.co/docs/hub/security-malware)
    at each commit. See the [Hub documentation](https://huggingface.co/docs/hub/security)
    for best practices like [signed commit verification](https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg)
    with GPG.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow and Flax checkpoints are not affected, and can be loaded within PyTorch
    architectures using the `from_tf` and `from_flax` kwargs for the `from_pretrained`
    method to circumvent this issue.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, we recommend using the `AutoTokenizer` class and the `AutoModelFor`
    class to load pretrained instances of models. This will ensure you load the correct
    architecture every time. In the next [tutorial](preprocessing), learn how to use
    your newly loaded tokenizer, image processor, feature extractor and processor
    to preprocess a dataset for fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlowHide TensorFlow content
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the `TFAutoModelFor` classes let you load a pretrained model for a
    given task (see [here](model_doc/auto) for a complete list of available tasks).
    For example, load a model for sequence classification with [TFAutoModelForSequenceClassification.from_pretrained()](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Easily reuse the same checkpoint to load an architecture for a different task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Generally, we recommend using the `AutoTokenizer` class and the `TFAutoModelFor`
    class to load pretrained instances of models. This will ensure you load the correct
    architecture every time. In the next [tutorial](preprocessing), learn how to use
    your newly loaded tokenizer, image processor, feature extractor and processor
    to preprocess a dataset for fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: AutoBackbone
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`AutoBackbone` lets you use pretrained models as backbones and get feature
    maps as outputs from different stages of the models. Below you can see how to
    get feature maps from a [Swin](model_doc/swin) checkpoint.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
