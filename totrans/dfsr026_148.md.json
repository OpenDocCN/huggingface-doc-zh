["```py\n( tokenizer: T5Tokenizer text_encoder: T5EncoderModel unet: Kandinsky3UNet scheduler: DDPMScheduler movq: VQModel )\n```", "```py\n( prompt: Union = None num_inference_steps: int = 25 guidance_scale: float = 3.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 height: Optional = 1024 width: Optional = 1024 generator: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None attention_mask: Optional = None negative_attention_mask: Optional = None output_type: Optional = 'pil' return_dict: bool = True latents = None callback_on_step_end: Optional = None callback_on_step_end_tensor_inputs: List = ['latents'] **kwargs ) \u2192 export const metadata = 'undefined';ImagePipelineOutput or tuple\n```", "```py\n>>> from diffusers import AutoPipelineForText2Image\n>>> import torch\n\n>>> pipe = AutoPipelineForText2Image.from_pretrained(\"kandinsky-community/kandinsky-3\", variant=\"fp16\", torch_dtype=torch.float16)\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = \"A photograph of the inside of a subway train. There are raccoons sitting on the seats. One of them is reading a newspaper. The window shows the city in the background.\"\n\n>>> generator = torch.Generator(device=\"cpu\").manual_seed(0)\n>>> image = pipe(prompt, num_inference_steps=25, generator=generator).images[0]\n```", "```py\n( prompt do_classifier_free_guidance = True num_images_per_prompt = 1 device = None negative_prompt = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None _cut_context = False attention_mask: Optional = None negative_attention_mask: Optional = None )\n```", "```py\n( tokenizer: T5Tokenizer text_encoder: T5EncoderModel unet: Kandinsky3UNet scheduler: DDPMScheduler movq: VQModel )\n```", "```py\n( prompt: Union = None image: Union = None strength: float = 0.3 num_inference_steps: int = 25 guidance_scale: float = 3.0 negative_prompt: Union = None num_images_per_prompt: Optional = 1 generator: Union = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None attention_mask: Optional = None negative_attention_mask: Optional = None output_type: Optional = 'pil' return_dict: bool = True callback_on_step_end: Optional = None callback_on_step_end_tensor_inputs: List = ['latents'] **kwargs ) \u2192 export const metadata = 'undefined';ImagePipelineOutput or tuple\n```", "```py\n>>> from diffusers import AutoPipelineForImage2Image\n>>> from diffusers.utils import load_image\n>>> import torch\n\n>>> pipe = AutoPipelineForImage2Image.from_pretrained(\"kandinsky-community/kandinsky-3\", variant=\"fp16\", torch_dtype=torch.float16)\n>>> pipe.enable_model_cpu_offload()\n\n>>> prompt = \"A painting of the inside of a subway train with tiny raccoons.\"\n>>> image = load_image(\"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky3/t2i.png\")\n\n>>> generator = torch.Generator(device=\"cpu\").manual_seed(0)\n>>> image = pipe(prompt, image=image, strength=0.75, num_inference_steps=25, generator=generator).images[0]\n```", "```py\n( prompt do_classifier_free_guidance = True num_images_per_prompt = 1 device = None negative_prompt = None prompt_embeds: Optional = None negative_prompt_embeds: Optional = None _cut_context = False attention_mask: Optional = None negative_attention_mask: Optional = None )\n```"]