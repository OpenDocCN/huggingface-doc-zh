["```py\n>>> from transformers import Mask2FormerConfig, Mask2FormerModel\n\n>>> # Initializing a Mask2Former facebook/mask2former-swin-small-coco-instance configuration\n>>> configuration = Mask2FormerConfig()\n\n>>> # Initializing a model (with random weights) from the facebook/mask2former-swin-small-coco-instance style configuration\n>>> model = Mask2FormerModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n>>> from transformers import AutoImageProcessor, Mask2FormerModel\n\n>>> # load image\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n\n>>> # load image preprocessor and Mask2FormerModel trained on COCO instance segmentation dataset\n>>> image_processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-small-coco-instance\")\n>>> model = Mask2FormerModel.from_pretrained(\"facebook/mask2former-swin-small-coco-instance\")\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> # forward pass\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> # model outputs last hidden states of shape (batch_size, num_queries, hidden_size)\n>>> print(outputs.transformer_decoder_last_hidden_state.shape)\ntorch.Size([1, 100, 256])\n```", "```py\n>>> from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n>>> from PIL import Image\n>>> import requests\n>>> import torch\n\n>>> # Load Mask2Former trained on COCO instance segmentation dataset\n>>> image_processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-small-coco-instance\")\n>>> model = Mask2FormerForUniversalSegmentation.from_pretrained(\n...     \"facebook/mask2former-swin-small-coco-instance\"\n... )\n\n>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> # Model predicts class_queries_logits of shape `(batch_size, num_queries)`\n>>> # and masks_queries_logits of shape `(batch_size, num_queries, height, width)`\n>>> class_queries_logits = outputs.class_queries_logits\n>>> masks_queries_logits = outputs.masks_queries_logits\n\n>>> # Perform post-processing to get instance segmentation map\n>>> pred_instance_map = image_processor.post_process_semantic_segmentation(\n...     outputs, target_sizes=[image.size[::-1]]\n... )[0]\n>>> print(pred_instance_map.shape)\ntorch.Size([480, 640])\n```", "```py\n>>> from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n>>> from PIL import Image\n>>> import requests\n>>> import torch\n\n>>> # Load Mask2Former trained on ADE20k semantic segmentation dataset\n>>> image_processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-small-ade-semantic\")\n>>> model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-small-ade-semantic\")\n\n>>> url = (\n...     \"https://huggingface.co/datasets/hf-internal-testing/fixtures_ade20k/resolve/main/ADE_val_00000001.jpg\"\n... )\n>>> image = Image.open(requests.get(url, stream=True).raw)\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> # Model predicts class_queries_logits of shape `(batch_size, num_queries)`\n>>> # and masks_queries_logits of shape `(batch_size, num_queries, height, width)`\n>>> class_queries_logits = outputs.class_queries_logits\n>>> masks_queries_logits = outputs.masks_queries_logits\n\n>>> # Perform post-processing to get semantic segmentation map\n>>> pred_semantic_map = image_processor.post_process_semantic_segmentation(\n...     outputs, target_sizes=[image.size[::-1]]\n... )[0]\n>>> print(pred_semantic_map.shape)\ntorch.Size([512, 683])\n```", "```py\n>>> from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n>>> from PIL import Image\n>>> import requests\n>>> import torch\n\n>>> # Load Mask2Former trained on CityScapes panoptic segmentation dataset\n>>> image_processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-small-cityscapes-panoptic\")\n>>> model = Mask2FormerForUniversalSegmentation.from_pretrained(\n...     \"facebook/mask2former-swin-small-cityscapes-panoptic\"\n... )\n\n>>> url = \"https://cdn-media.huggingface.co/Inference-API/Sample-results-on-the-Cityscapes-dataset-The-above-images-show-how-our-method-can-handle.png\"\n>>> image = Image.open(requests.get(url, stream=True).raw)\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> # Model predicts class_queries_logits of shape `(batch_size, num_queries)`\n>>> # and masks_queries_logits of shape `(batch_size, num_queries, height, width)`\n>>> class_queries_logits = outputs.class_queries_logits\n>>> masks_queries_logits = outputs.masks_queries_logits\n\n>>> # Perform post-processing to get panoptic segmentation map\n>>> pred_panoptic_map = image_processor.post_process_panoptic_segmentation(\n...     outputs, target_sizes=[image.size[::-1]]\n... )[0][\"segmentation\"]\n>>> print(pred_panoptic_map.shape)\ntorch.Size([338, 676])\n```"]