["```py\n>>> import torch\n>>> from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n>>> from datasets import load_dataset\n\n>>> model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n\n>>> inputs = processor(ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\")\n>>> generated_ids = model.generate(inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n\n>>> transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> transcription\n['mister quilter is the apostle of the middle classes and we are glad to welcome his gospel']\n```", "```py\n>>> import torch\n>>> from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n>>> from datasets import load_dataset\n\n>>> model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-medium-mustc-multilingual-st\")\n>>> processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-medium-mustc-multilingual-st\")\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n\n>>> inputs = processor(ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\")\n>>> generated_ids = model.generate(\n...     inputs[\"input_features\"],\n...     attention_mask=inputs[\"attention_mask\"],\n...     forced_bos_token_id=processor.tokenizer.lang_code_to_id[\"fr\"],\n... )\n\n>>> translation = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> translation\n[\"(Vid\u00e9o) Si M. Kilder est l'apossible des classes moyennes, et nous sommes heureux d'\u00eatre accueillis dans son \u00e9vangile.\"]\n```", "```py\n>>> from transformers import Speech2TextConfig, Speech2TextModel\n\n>>> # Initializing a Speech2Text s2t_transformer_s style configuration\n>>> configuration = Speech2TextConfig()\n\n>>> # Initializing a model (with random weights) from the s2t_transformer_s style configuration\n>>> model = Speech2TextModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> import torch\n>>> from transformers import Speech2TextModel, AutoFeatureExtractor\n>>> from datasets import load_dataset\n\n>>> model = Speech2TextModel.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> inputs = feature_extractor(\n...     ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\"\n... )\n>>> input_features = inputs.input_features\n>>> decoder_input_ids = torch.tensor([[1, 1]]) * model.config.decoder_start_token_id\n>>> last_hidden_state = model(input_features, decoder_input_ids=decoder_input_ids).last_hidden_state\n>>> list(last_hidden_state.shape)\n[1, 2, 256]\n```", "```py\n>>> import torch\n>>> from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n>>> from datasets import load_dataset\n\n>>> model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n\n>>> inputs = processor(\n...     ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\"\n... )\n>>> input_features = inputs.input_features\n\n>>> generated_ids = model.generate(inputs=input_features)\n\n>>> transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n>>> transcription\n'mister quilter is the apostle of the middle classes and we are glad to welcome his gospel'\n```", "```py\n>>> from transformers import AutoTokenizer, TFSpeech2TextModel\n>>> import tensorflow as tf\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> model = TFSpeech2TextModel.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n>>> outputs = model(inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n>>> import tensorflow as tf\n>>> from transformers import Speech2TextProcessor, TFSpeech2TextForConditionalGeneration\n>>> from datasets import load_dataset\n>>> import soundfile as sf\n\n>>> model = TFSpeech2TextForConditionalGeneration.from_pretrained(\n...     \"facebook/s2t-small-librispeech-asr\", from_pt=True\n... )\n>>> processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n\n>>> def map_to_array(batch):\n...     speech, _ = sf.read(batch[\"file\"])\n...     batch[\"speech\"] = speech\n...     return batch\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> ds = ds.map(map_to_array)\n>>> ds.set_format(type=\"tf\")\n\n>>> input_features = processor(\n...     ds[\"speech\"][0], sampling_rate=16000, return_tensors=\"tf\"\n... ).input_features  # Batch size 1\n>>> generated_ids = model.generate(input_features)\n\n>>> transcription = processor.batch_decode(generated_ids)\n```"]