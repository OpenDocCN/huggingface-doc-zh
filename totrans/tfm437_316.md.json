["```py\n>>> import torch\n>>> from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n>>> from datasets import load_dataset\n\n>>> model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n\n>>> inputs = processor(ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\")\n>>> generated_ids = model.generate(inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n\n>>> transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> transcription\n['mister quilter is the apostle of the middle classes and we are glad to welcome his gospel']\n```", "```py\n>>> import torch\n>>> from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n>>> from datasets import load_dataset\n\n>>> model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-medium-mustc-multilingual-st\")\n>>> processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-medium-mustc-multilingual-st\")\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n\n>>> inputs = processor(ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\")\n>>> generated_ids = model.generate(\n...     inputs[\"input_features\"],\n...     attention_mask=inputs[\"attention_mask\"],\n...     forced_bos_token_id=processor.tokenizer.lang_code_to_id[\"fr\"],\n... )\n\n>>> translation = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> translation\n[\"(Vid\u00e9o) Si M. Kilder est l'apossible des classes moyennes, et nous sommes heureux d'\u00eatre accueillis dans son \u00e9vangile.\"]\n```", "```py\n( vocab_size = 10000 encoder_layers = 12 encoder_ffn_dim = 2048 encoder_attention_heads = 4 decoder_layers = 6 decoder_ffn_dim = 2048 decoder_attention_heads = 4 encoder_layerdrop = 0.0 decoder_layerdrop = 0.0 use_cache = True is_encoder_decoder = True activation_function = 'relu' d_model = 256 dropout = 0.1 attention_dropout = 0.0 activation_dropout = 0.0 init_std = 0.02 decoder_start_token_id = 2 scale_embedding = True pad_token_id = 1 bos_token_id = 0 eos_token_id = 2 max_source_positions = 6000 max_target_positions = 1024 num_conv_layers = 2 conv_kernel_sizes = (5, 5) conv_channels = 1024 input_feat_per_channel = 80 input_channels = 1 **kwargs )\n```", "```py\n>>> from transformers import Speech2TextConfig, Speech2TextModel\n\n>>> # Initializing a Speech2Text s2t_transformer_s style configuration\n>>> configuration = Speech2TextConfig()\n\n>>> # Initializing a model (with random weights) from the s2t_transformer_s style configuration\n>>> model = Speech2TextModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( vocab_file spm_file bos_token = '<s>' eos_token = '</s>' pad_token = '<pad>' unk_token = '<unk>' do_upper_case = False do_lower_case = False tgt_lang = None lang_codes = None additional_special_tokens = None sp_model_kwargs: Optional = None **kwargs )\n```", "```py\n( token_ids_0 token_ids_1 = None )\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( save_directory: str filename_prefix: Optional = None )\n```", "```py\n( feature_size = 80 sampling_rate = 16000 num_mel_bins = 80 padding_value = 0.0 do_ceptral_normalize = True normalize_means = True normalize_vars = True **kwargs )\n```", "```py\n( raw_speech: Union padding: Union = False max_length: Optional = None truncation: bool = False pad_to_multiple_of: Optional = None return_tensors: Union = None sampling_rate: Optional = None return_attention_mask: Optional = None **kwargs )\n```", "```py\n( feature_extractor tokenizer )\n```", "```py\n( *args **kwargs )\n```", "```py\n( pretrained_model_name_or_path: Union cache_dir: Union = None force_download: bool = False local_files_only: bool = False token: Union = None revision: str = 'main' **kwargs )\n```", "```py\n( save_directory push_to_hub: bool = False **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( config: Speech2TextConfig )\n```", "```py\n( input_features: Optional = None attention_mask: Optional = None decoder_input_ids: Optional = None decoder_attention_mask: Optional = None head_mask: Optional = None decoder_head_mask: Optional = None cross_attn_head_mask: Optional = None encoder_outputs: Optional = None past_key_values: Optional = None decoder_inputs_embeds: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.Seq2SeqLMOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> import torch\n>>> from transformers import Speech2TextModel, AutoFeatureExtractor\n>>> from datasets import load_dataset\n\n>>> model = Speech2TextModel.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> inputs = feature_extractor(\n...     ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\"\n... )\n>>> input_features = inputs.input_features\n>>> decoder_input_ids = torch.tensor([[1, 1]]) * model.config.decoder_start_token_id\n>>> last_hidden_state = model(input_features, decoder_input_ids=decoder_input_ids).last_hidden_state\n>>> list(last_hidden_state.shape)\n[1, 2, 256]\n```", "```py\n( config: Speech2TextConfig )\n```", "```py\n( input_features: Optional = None attention_mask: Optional = None decoder_input_ids: Optional = None decoder_attention_mask: Optional = None head_mask: Optional = None decoder_head_mask: Optional = None cross_attn_head_mask: Optional = None encoder_outputs: Optional = None past_key_values: Optional = None decoder_inputs_embeds: Optional = None labels: Optional = None use_cache: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.Seq2SeqLMOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> import torch\n>>> from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n>>> from datasets import load_dataset\n\n>>> model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n\n>>> inputs = processor(\n...     ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\"\n... )\n>>> input_features = inputs.input_features\n\n>>> generated_ids = model.generate(inputs=input_features)\n\n>>> transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n>>> transcription\n'mister quilter is the apostle of the middle classes and we are glad to welcome his gospel'\n```", "```py\n( config: Speech2TextConfig *inputs **kwargs )\n```", "```py\n( input_features: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None decoder_input_ids: np.ndarray | tf.Tensor | None = None decoder_attention_mask: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None decoder_head_mask: np.ndarray | tf.Tensor | None = None cross_attn_head_mask: np.ndarray | tf.Tensor | None = None encoder_outputs: np.ndarray | tf.Tensor | None = None past_key_values: Optional[Tuple[Tuple[Union[np.ndarray, tf.Tensor]]]] = None decoder_inputs_embeds: np.ndarray | tf.Tensor | None = None use_cache: Optional[bool] = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: bool = False **kwargs ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFSeq2SeqModelOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoTokenizer, TFSpeech2TextModel\n>>> import tensorflow as tf\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n>>> model = TFSpeech2TextModel.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n\n>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n>>> outputs = model(inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n```", "```py\n( config: Speech2TextConfig )\n```", "```py\n( input_features: TFModelInputType | None = None attention_mask: np.ndarray | tf.Tensor | None = None decoder_input_ids: np.ndarray | tf.Tensor | None = None decoder_attention_mask: np.ndarray | tf.Tensor | None = None head_mask: np.ndarray | tf.Tensor | None = None decoder_head_mask: np.ndarray | tf.Tensor | None = None cross_attn_head_mask: np.ndarray | tf.Tensor | None = None encoder_outputs: np.ndarray | tf.Tensor | None = None past_key_values: Optional[Tuple[Tuple[Union[np.ndarray, tf.Tensor]]]] = None decoder_inputs_embeds: np.ndarray | tf.Tensor | None = None labels: np.ndarray | tf.Tensor | None = None use_cache: Optional[bool] = None output_attentions: Optional[bool] = None output_hidden_states: Optional[bool] = None return_dict: Optional[bool] = None training: Optional[bool] = False **kwargs ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFSeq2SeqLMOutput or tuple(tf.Tensor)\n```", "```py\n>>> import tensorflow as tf\n>>> from transformers import Speech2TextProcessor, TFSpeech2TextForConditionalGeneration\n>>> from datasets import load_dataset\n>>> import soundfile as sf\n\n>>> model = TFSpeech2TextForConditionalGeneration.from_pretrained(\n...     \"facebook/s2t-small-librispeech-asr\", from_pt=True\n... )\n>>> processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n\n>>> def map_to_array(batch):\n...     speech, _ = sf.read(batch[\"file\"])\n...     batch[\"speech\"] = speech\n...     return batch\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> ds = ds.map(map_to_array)\n>>> ds.set_format(type=\"tf\")\n\n>>> input_features = processor(\n...     ds[\"speech\"][0], sampling_rate=16000, return_tensors=\"tf\"\n... ).input_features  # Batch size 1\n>>> generated_ids = model.generate(input_features)\n\n>>> transcription = processor.batch_decode(generated_ids)\n```"]