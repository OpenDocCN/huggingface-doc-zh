- en: models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: 'Original text: [https://huggingface.co/docs/transformers.js/api/models](https://huggingface.co/docs/transformers.js/api/models)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers.js/api/models](https://huggingface.co/docs/transformers.js/api/models)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Definitions of all models available in Transformers.js.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers.js 中所有可用模型的定义。
- en: '**Example:** Load and run an `AutoModel`.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 加载并运行一个 `AutoModel`。'
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We also provide other `AutoModel`s (listed below), which you can use in the
    same way as the Python library. For example:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供其他 `AutoModel`（如下所列），您可以像使用 Python 库一样使用它们。例如：
- en: '**Example:** Load and run an `AutoModelForSeq2SeqLM`.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 加载并运行一个 `AutoModelForSeq2SeqLM`。'
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[models](#module_models)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型
- en: '*static*'
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*static*'
- en: '[.PreTrainedModel](#module_models.PreTrainedModel)'
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.PreTrainedModel](#module_models.PreTrainedModel)'
- en: '[`new PreTrainedModel(config, session)`](#new_module_models.PreTrainedModel_new)'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new PreTrainedModel(config, session)`](#new_module_models.PreTrainedModel_new)'
- en: '*instance*'
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*instance*'
- en: '[`.dispose()`](#module_models.PreTrainedModel+dispose) ⇒ `Promise.<Array<unknown>>`'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.dispose()`](#module_models.PreTrainedModel+dispose) ⇒ `Promise.<Array<unknown>>`'
- en: '[`._call(model_inputs)`](#module_models.PreTrainedModel+_call) ⇒ `Promise.<Object>`'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.PreTrainedModel+_call) ⇒ `Promise.<Object>`'
- en: '[`.forward(model_inputs)`](#module_models.PreTrainedModel+forward) ⇒ `Promise.<Object>`'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.forward(model_inputs)`](#module_models.PreTrainedModel+forward) ⇒ `Promise.<Object>`'
- en: '[`._get_generation_config(generation_config)`](#module_models.PreTrainedModel+_get_generation_config)
    ⇒ `*`'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._get_generation_config(generation_config)`](#module_models.PreTrainedModel+_get_generation_config)
    ⇒ `*`'
- en: '[`.groupBeams(beams)`](#module_models.PreTrainedModel+groupBeams) ⇒ `Array`'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.groupBeams(beams)`](#module_models.PreTrainedModel+groupBeams) ⇒ `Array`'
- en: '[`.getPastKeyValues(decoderResults, pastKeyValues)`](#module_models.PreTrainedModel+getPastKeyValues)
    ⇒ `Object`'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.getPastKeyValues(decoderResults, pastKeyValues)`](#module_models.PreTrainedModel+getPastKeyValues)
    ⇒ `Object`'
- en: '[`.getAttentions(decoderResults)`](#module_models.PreTrainedModel+getAttentions)
    ⇒ `Object`'
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.getAttentions(decoderResults)`](#module_models.PreTrainedModel+getAttentions)
    ⇒ `Object`'
- en: '[`.addPastKeyValues(decoderFeeds, pastKeyValues)`](#module_models.PreTrainedModel+addPastKeyValues)'
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.addPastKeyValues(decoderFeeds, pastKeyValues)`](#module_models.PreTrainedModel+addPastKeyValues)'
- en: '*static*'
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*static*'
- en: '[`.from_pretrained(pretrained_model_name_or_path, options)`](#module_models.PreTrainedModel.from_pretrained)
    ⇒ `Promise.<PreTrainedModel>`'
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained(pretrained_model_name_or_path, options)`](#module_models.PreTrainedModel.from_pretrained)
    ⇒ `Promise.<PreTrainedModel>`'
- en: '[.BaseModelOutput](#module_models.BaseModelOutput)'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BaseModelOutput](#module_models.BaseModelOutput)'
- en: '[`new BaseModelOutput(output)`](#new_module_models.BaseModelOutput_new)'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new BaseModelOutput(output)`](#new_module_models.BaseModelOutput_new)'
- en: '[.BertForMaskedLM](#module_models.BertForMaskedLM)'
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BertForMaskedLM](#module_models.BertForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.BertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.BertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.BertForSequenceClassification](#module_models.BertForSequenceClassification)'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BertForSequenceClassification](#module_models.BertForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.BertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.BertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.BertForTokenClassification](#module_models.BertForTokenClassification)'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BertForTokenClassification](#module_models.BertForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.BertForTokenClassification+_call) ⇒
    `Promise.<TokenClassifierOutput>`'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.BertForTokenClassification+_call) ⇒
    `Promise.<TokenClassifierOutput>`'
- en: '[.BertForQuestionAnswering](#module_models.BertForQuestionAnswering)'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BertForQuestionAnswering](#module_models.BertForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.BertForQuestionAnswering+_call) ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.BertForQuestionAnswering+_call) ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.RoFormerModel](#module_models.RoFormerModel)'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.RoFormerModel](#module_models.RoFormerModel)'
- en: '[.RoFormerForMaskedLM](#module_models.RoFormerForMaskedLM)'
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.RoFormerForMaskedLM](#module_models.RoFormerForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.RoFormerForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.RoFormerForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.RoFormerForSequenceClassification](#module_models.RoFormerForSequenceClassification)'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.RoFormerForSequenceClassification](#module_models.RoFormerForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.RoFormerForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.RoFormerForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.RoFormerForTokenClassification](#module_models.RoFormerForTokenClassification)'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.RoFormerForTokenClassification](#module_models.RoFormerForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.RoFormerForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.RoFormerForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.RoFormerForQuestionAnswering](#module_models.RoFormerForQuestionAnswering)'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.RoFormerForQuestionAnswering](#module_models.RoFormerForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.RoFormerForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.RoFormerForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.ConvBertModel](#module_models.ConvBertModel)'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ConvBertModel](#module_models.ConvBertModel)'
- en: '[.ConvBertForMaskedLM](#module_models.ConvBertForMaskedLM)'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ConvBertForMaskedLM](#module_models.ConvBertForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.ConvBertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ConvBertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.ConvBertForSequenceClassification](#module_models.ConvBertForSequenceClassification)'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ConvBertForSequenceClassification](#module_models.ConvBertForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.ConvBertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ConvBertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.ConvBertForTokenClassification](#module_models.ConvBertForTokenClassification)'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ConvBertForTokenClassification](#module_models.ConvBertForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.ConvBertForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ConvBertForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.ConvBertForQuestionAnswering](#module_models.ConvBertForQuestionAnswering)'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ConvBertForQuestionAnswering](#module_models.ConvBertForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.ConvBertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ConvBertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.ElectraModel](#module_models.ElectraModel)'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ElectraModel](#module_models.ElectraModel)'
- en: '[.ElectraForMaskedLM](#module_models.ElectraForMaskedLM)'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ElectraForMaskedLM](#module_models.ElectraForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.ElectraForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ElectraForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.ElectraForSequenceClassification](#module_models.ElectraForSequenceClassification)'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ElectraForSequenceClassification](#module_models.ElectraForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.ElectraForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ElectraForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.ElectraForTokenClassification](#module_models.ElectraForTokenClassification)'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ElectraForTokenClassification](#module_models.ElectraForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.ElectraForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ElectraForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.ElectraForQuestionAnswering](#module_models.ElectraForQuestionAnswering)'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ElectraForQuestionAnswering](#module_models.ElectraForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.ElectraForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ElectraForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.CamembertModel](#module_models.CamembertModel)'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CamembertModel](#module_models.CamembertModel)'
- en: '[.CamembertForMaskedLM](#module_models.CamembertForMaskedLM)'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CamembertForMaskedLM](#module_models.CamembertForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.CamembertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.CamembertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.CamembertForSequenceClassification](#module_models.CamembertForSequenceClassification)'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CamembertForSequenceClassification](#module_models.CamembertForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.CamembertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.CamembertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.CamembertForTokenClassification](#module_models.CamembertForTokenClassification)'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CamembertForTokenClassification](#module_models.CamembertForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.CamembertForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.CamembertForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.CamembertForQuestionAnswering](#module_models.CamembertForQuestionAnswering)'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CamembertForQuestionAnswering](#module_models.CamembertForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.CamembertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.CamembertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.DebertaModel](#module_models.DebertaModel)'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaModel](#module_models.DebertaModel)'
- en: '[.DebertaForMaskedLM](#module_models.DebertaForMaskedLM)'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaForMaskedLM](#module_models.DebertaForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.DebertaForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DebertaForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.DebertaForSequenceClassification](#module_models.DebertaForSequenceClassification)'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaForSequenceClassification](#module_models.DebertaForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.DebertaForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DebertaForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.DebertaForTokenClassification](#module_models.DebertaForTokenClassification)'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaForTokenClassification](#module_models.DebertaForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.DebertaForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DebertaForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.DebertaForQuestionAnswering](#module_models.DebertaForQuestionAnswering)'
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaForQuestionAnswering](#module_models.DebertaForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.DebertaForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DebertaForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.DebertaV2Model](#module_models.DebertaV2Model)'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaV2Model](#module_models.DebertaV2Model)'
- en: '[.DebertaV2ForMaskedLM](#module_models.DebertaV2ForMaskedLM)'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaV2ForMaskedLM](#module_models.DebertaV2ForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.DebertaV2ForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DebertaV2ForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.DebertaV2ForSequenceClassification](#module_models.DebertaV2ForSequenceClassification)'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaV2ForSequenceClassification](#module_models.DebertaV2ForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.DebertaV2ForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DebertaV2ForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.DebertaV2ForTokenClassification](#module_models.DebertaV2ForTokenClassification)'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaV2ForTokenClassification](#module_models.DebertaV2ForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.DebertaV2ForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DebertaV2ForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.DebertaV2ForQuestionAnswering](#module_models.DebertaV2ForQuestionAnswering)'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DebertaV2ForQuestionAnswering](#module_models.DebertaV2ForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.DebertaV2ForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DebertaV2ForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.DistilBertForSequenceClassification](#module_models.DistilBertForSequenceClassification)'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DistilBertForSequenceClassification](#module_models.DistilBertForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.DistilBertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DistilBertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.DistilBertForTokenClassification](#module_models.DistilBertForTokenClassification)'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DistilBertForTokenClassification](#module_models.DistilBertForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.DistilBertForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DistilBertForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.DistilBertForQuestionAnswering](#module_models.DistilBertForQuestionAnswering)'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DistilBertForQuestionAnswering](#module_models.DistilBertForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.DistilBertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DistilBertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.DistilBertForMaskedLM](#module_models.DistilBertForMaskedLM)'
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DistilBertForMaskedLM](#module_models.DistilBertForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.DistilBertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.DistilBertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.EsmModel](#module_models.EsmModel)'
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.EsmModel](#module_models.EsmModel)'
- en: '[.EsmForMaskedLM](#module_models.EsmForMaskedLM)'
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.EsmForMaskedLM](#module_models.EsmForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.EsmForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.EsmForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.EsmForSequenceClassification](#module_models.EsmForSequenceClassification)'
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.EsmForSequenceClassification](#module_models.EsmForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.EsmForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.EsmForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.EsmForTokenClassification](#module_models.EsmForTokenClassification)'
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.EsmForTokenClassification](#module_models.EsmForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.EsmForTokenClassification+_call) ⇒
    `Promise.<TokenClassifierOutput>`'
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.EsmForTokenClassification+_call) ⇒
    `Promise.<TokenClassifierOutput>`'
- en: '[.MobileBertForMaskedLM](#module_models.MobileBertForMaskedLM)'
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MobileBertForMaskedLM](#module_models.MobileBertForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.MobileBertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.MobileBertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.MobileBertForSequenceClassification](#module_models.MobileBertForSequenceClassification)'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MobileBertForSequenceClassification](#module_models.MobileBertForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.MobileBertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.MobileBertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.MobileBertForQuestionAnswering](#module_models.MobileBertForQuestionAnswering)'
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MobileBertForQuestionAnswering](#module_models.MobileBertForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.MobileBertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.MobileBertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.MPNetModel](#module_models.MPNetModel)'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MPNetModel](#module_models.MPNetModel)'
- en: '[.MPNetForMaskedLM](#module_models.MPNetForMaskedLM)'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MPNetForMaskedLM](#module_models.MPNetForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.MPNetForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.MPNetForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.MPNetForSequenceClassification](#module_models.MPNetForSequenceClassification)'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MPNetForSequenceClassification](#module_models.MPNetForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.MPNetForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.MPNetForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.MPNetForTokenClassification](#module_models.MPNetForTokenClassification)'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MPNetForTokenClassification](#module_models.MPNetForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.MPNetForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.MPNetForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.MPNetForQuestionAnswering](#module_models.MPNetForQuestionAnswering)'
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MPNetForQuestionAnswering](#module_models.MPNetForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.MPNetForQuestionAnswering+_call) ⇒
    `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.MPNetForQuestionAnswering+_call) ⇒
    `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.T5ForConditionalGeneration](#module_models.T5ForConditionalGeneration)'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.T5ForConditionalGeneration](#module_models.T5ForConditionalGeneration)'
- en: '[`new T5ForConditionalGeneration(config, session, decoder_merged_session, generation_config)`](#new_module_models.T5ForConditionalGeneration_new)'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new T5ForConditionalGeneration(config, session, decoder_merged_session, generation_config)`](#new_module_models.T5ForConditionalGeneration_new)'
- en: '[.LongT5PreTrainedModel](#module_models.LongT5PreTrainedModel)'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.LongT5PreTrainedModel](#module_models.LongT5PreTrainedModel)'
- en: '[.LongT5Model](#module_models.LongT5Model)'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.LongT5Model](#module_models.LongT5Model)'
- en: '[.LongT5ForConditionalGeneration](#module_models.LongT5ForConditionalGeneration)'
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.LongT5ForConditionalGeneration](#module_models.LongT5ForConditionalGeneration)'
- en: '[`new LongT5ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.LongT5ForConditionalGeneration_new)'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new LongT5ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.LongT5ForConditionalGeneration_new)'
- en: '[.MT5ForConditionalGeneration](#module_models.MT5ForConditionalGeneration)'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MT5ForConditionalGeneration](#module_models.MT5ForConditionalGeneration)'
- en: '[`new MT5ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.MT5ForConditionalGeneration_new)'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new MT5ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.MT5ForConditionalGeneration_new)'
- en: '[.BartModel](#module_models.BartModel)'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BartModel](#module_models.BartModel)'
- en: '[.BartForConditionalGeneration](#module_models.BartForConditionalGeneration)'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BartForConditionalGeneration](#module_models.BartForConditionalGeneration)'
- en: '[`new BartForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.BartForConditionalGeneration_new)'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new BartForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.BartForConditionalGeneration_new)'
- en: '[.BartForSequenceClassification](#module_models.BartForSequenceClassification)'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BartForSequenceClassification](#module_models.BartForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.BartForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.BartForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.MBartModel](#module_models.MBartModel)'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MBartModel](#module_models.MBartModel)'
- en: '[.MBartForConditionalGeneration](#module_models.MBartForConditionalGeneration)'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MBartForConditionalGeneration](#module_models.MBartForConditionalGeneration)'
- en: '[`new MBartForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.MBartForConditionalGeneration_new)'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new MBartForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.MBartForConditionalGeneration_new)'
- en: '[.MBartForSequenceClassification](#module_models.MBartForSequenceClassification)'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MBartForSequenceClassification](#module_models.MBartForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.MBartForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.MBartForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.MBartForCausalLM](#module_models.MBartForCausalLM)'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MBartForCausalLM](#module_models.MBartForCausalLM)'
- en: '[`new MBartForCausalLM(config, decoder_merged_session, generation_config)`](#new_module_models.MBartForCausalLM_new)'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new MBartForCausalLM(config, decoder_merged_session, generation_config)`](#new_module_models.MBartForCausalLM_new)'
- en: '[.BlenderbotModel](#module_models.BlenderbotModel)'
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BlenderbotModel](#module_models.BlenderbotModel)'
- en: '[.BlenderbotForConditionalGeneration](#module_models.BlenderbotForConditionalGeneration)'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BlenderbotForConditionalGeneration](#module_models.BlenderbotForConditionalGeneration)'
- en: '[`new BlenderbotForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.BlenderbotForConditionalGeneration_new)'
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new BlenderbotForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.BlenderbotForConditionalGeneration_new)'
- en: '[.BlenderbotSmallModel](#module_models.BlenderbotSmallModel)'
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BlenderbotSmallModel](#module_models.BlenderbotSmallModel)'
- en: '[.BlenderbotSmallForConditionalGeneration](#module_models.BlenderbotSmallForConditionalGeneration)'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BlenderbotSmallForConditionalGeneration](#module_models.BlenderbotSmallForConditionalGeneration)'
- en: '[`new BlenderbotSmallForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.BlenderbotSmallForConditionalGeneration_new)'
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new BlenderbotSmallForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.BlenderbotSmallForConditionalGeneration_new)'
- en: '[.RobertaForMaskedLM](#module_models.RobertaForMaskedLM)'
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.RobertaForMaskedLM](#module_models.RobertaForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.RobertaForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.RobertaForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.RobertaForSequenceClassification](#module_models.RobertaForSequenceClassification)'
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.RobertaForSequenceClassification](#module_models.RobertaForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.RobertaForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.RobertaForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.RobertaForTokenClassification](#module_models.RobertaForTokenClassification)'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.RobertaForTokenClassification](#module_models.RobertaForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.RobertaForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.RobertaForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.RobertaForQuestionAnswering](#module_models.RobertaForQuestionAnswering)'
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.RobertaForQuestionAnswering](#module_models.RobertaForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.RobertaForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.RobertaForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.XLMPreTrainedModel](#module_models.XLMPreTrainedModel)'
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMPreTrainedModel](#module_models.XLMPreTrainedModel)'
- en: '[.XLMModel](#module_models.XLMModel)'
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMModel](#module_models.XLMModel)'
- en: '[.XLMWithLMHeadModel](#module_models.XLMWithLMHeadModel)'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMWithLMHeadModel](#module_models.XLMWithLMHeadModel)'
- en: '[`._call(model_inputs)`](#module_models.XLMWithLMHeadModel+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.XLMWithLMHeadModel+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.XLMForSequenceClassification](#module_models.XLMForSequenceClassification)'
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMForSequenceClassification](#module_models.XLMForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.XLMForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.XLMForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.XLMForTokenClassification](#module_models.XLMForTokenClassification)'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMForTokenClassification](#module_models.XLMForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.XLMForTokenClassification+_call) ⇒
    `Promise.<TokenClassifierOutput>`'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.XLMForTokenClassification+_call) ⇒
    `Promise.<TokenClassifierOutput>`'
- en: '[.XLMForQuestionAnswering](#module_models.XLMForQuestionAnswering)'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMForQuestionAnswering](#module_models.XLMForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.XLMForQuestionAnswering+_call) ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.XLMForQuestionAnswering+_call) ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.XLMRobertaForMaskedLM](#module_models.XLMRobertaForMaskedLM)'
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMRobertaForMaskedLM](#module_models.XLMRobertaForMaskedLM)'
- en: '[`._call(model_inputs)`](#module_models.XLMRobertaForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.XLMRobertaForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
- en: '[.XLMRobertaForSequenceClassification](#module_models.XLMRobertaForSequenceClassification)'
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMRobertaForSequenceClassification](#module_models.XLMRobertaForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.XLMRobertaForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.XLMRobertaForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.XLMRobertaForTokenClassification](#module_models.XLMRobertaForTokenClassification)'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMRobertaForTokenClassification](#module_models.XLMRobertaForTokenClassification)'
- en: '[`._call(model_inputs)`](#module_models.XLMRobertaForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.XLMRobertaForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
- en: '[.XLMRobertaForQuestionAnswering](#module_models.XLMRobertaForQuestionAnswering)'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.XLMRobertaForQuestionAnswering](#module_models.XLMRobertaForQuestionAnswering)'
- en: '[`._call(model_inputs)`](#module_models.XLMRobertaForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.XLMRobertaForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
- en: '[.ASTModel](#module_models.ASTModel)'
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ASTModel](#module_models.ASTModel)'
- en: '[.ASTForAudioClassification](#module_models.ASTForAudioClassification)'
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ASTForAudioClassification](#module_models.ASTForAudioClassification)'
- en: '[.WhisperModel](#module_models.WhisperModel)'
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.WhisperModel](#module_models.WhisperModel)'
- en: '[.WhisperForConditionalGeneration](#module_models.WhisperForConditionalGeneration)'
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.WhisperForConditionalGeneration](#module_models.WhisperForConditionalGeneration)'
- en: '[`new WhisperForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.WhisperForConditionalGeneration_new)'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new WhisperForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.WhisperForConditionalGeneration_new)'
- en: '[`.generate(inputs, generation_config, logits_processor)`](#module_models.WhisperForConditionalGeneration+generate)
    ⇒ `Promise.<Object>`'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.generate(inputs, generation_config, logits_processor)`](#module_models.WhisperForConditionalGeneration+generate)
    ⇒ `Promise.<Object>`'
- en: '[`._extract_token_timestamps(generate_outputs, alignment_heads, [num_frames],
    [time_precision])`](#module_models.WhisperForConditionalGeneration+_extract_token_timestamps)
    ⇒ `Tensor`'
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._extract_token_timestamps(generate_outputs, alignment_heads, [num_frames],
    [time_precision])`](#module_models.WhisperForConditionalGeneration+_extract_token_timestamps)
    ⇒ `Tensor`'
- en: '[.VisionEncoderDecoderModel](#module_models.VisionEncoderDecoderModel)'
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.VisionEncoderDecoderModel](#module_models.VisionEncoderDecoderModel)'
- en: '[`new VisionEncoderDecoderModel(config, session, decoder_merged_session, generation_config)`](#new_module_models.VisionEncoderDecoderModel_new)'
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new VisionEncoderDecoderModel(config, session, decoder_merged_session, generation_config)`](#new_module_models.VisionEncoderDecoderModel_new)'
- en: '[.CLIPModel](#module_models.CLIPModel)'
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CLIPModel](#module_models.CLIPModel)'
- en: '[.CLIPTextModelWithProjection](#module_models.CLIPTextModelWithProjection)'
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CLIPTextModelWithProjection](#module_models.CLIPTextModelWithProjection)'
- en: '[`.from_pretrained()`](#module_models.CLIPTextModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained()`](#module_models.CLIPTextModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
- en: '[.CLIPVisionModelWithProjection](#module_models.CLIPVisionModelWithProjection)'
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CLIPVisionModelWithProjection](#module_models.CLIPVisionModelWithProjection)'
- en: '[`.from_pretrained()`](#module_models.CLIPVisionModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained()`](#module_models.CLIPVisionModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
- en: '[.SiglipModel](#module_models.SiglipModel)'
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SiglipModel](#module_models.SiglipModel)'
- en: '[.SiglipTextModel](#module_models.SiglipTextModel)'
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SiglipTextModel](#module_models.SiglipTextModel)'
- en: '[`.from_pretrained()`](#module_models.SiglipTextModel.from_pretrained) : `PreTrainedModel.from_pretrained`'
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained()`](#module_models.SiglipTextModel.from_pretrained) : `PreTrainedModel.from_pretrained`'
- en: '[.SiglipVisionModel](#module_models.SiglipVisionModel)'
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SiglipVisionModel](#module_models.SiglipVisionModel)'
- en: '[`.from_pretrained()`](#module_models.SiglipVisionModel.from_pretrained) :
    `PreTrainedModel.from_pretrained`'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained()`](#module_models.SiglipVisionModel.from_pretrained) :
    `PreTrainedModel.from_pretrained`'
- en: '[.CLIPSegForImageSegmentation](#module_models.CLIPSegForImageSegmentation)'
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CLIPSegForImageSegmentation](#module_models.CLIPSegForImageSegmentation)'
- en: '[.GPT2PreTrainedModel](#module_models.GPT2PreTrainedModel)'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.GPT2PreTrainedModel](#module_models.GPT2PreTrainedModel)'
- en: '[`new GPT2PreTrainedModel(config, session, generation_config)`](#new_module_models.GPT2PreTrainedModel_new)'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new GPT2PreTrainedModel(config, session, generation_config)`](#new_module_models.GPT2PreTrainedModel_new)'
- en: '[.GPT2LMHeadModel](#module_models.GPT2LMHeadModel)'
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.GPT2LMHeadModel](#module_models.GPT2LMHeadModel)'
- en: '[.GPTNeoPreTrainedModel](#module_models.GPTNeoPreTrainedModel)'
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.GPTNeoPreTrainedModel](#module_models.GPTNeoPreTrainedModel)'
- en: '[`new GPTNeoPreTrainedModel(config, session, generation_config)`](#new_module_models.GPTNeoPreTrainedModel_new)'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new GPTNeoPreTrainedModel(config, session, generation_config)`](#new_module_models.GPTNeoPreTrainedModel_new)'
- en: '[.GPTNeoXPreTrainedModel](#module_models.GPTNeoXPreTrainedModel)'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.GPTNeoXPreTrainedModel](#module_models.GPTNeoXPreTrainedModel)'
- en: '[`new GPTNeoXPreTrainedModel(config, session, generation_config)`](#new_module_models.GPTNeoXPreTrainedModel_new)'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new GPTNeoXPreTrainedModel(config, session, generation_config)`](#new_module_models.GPTNeoXPreTrainedModel_new)'
- en: '[.GPTJPreTrainedModel](#module_models.GPTJPreTrainedModel)'
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.GPTJPreTrainedModel](#module_models.GPTJPreTrainedModel)'
- en: '[`new GPTJPreTrainedModel(config, session, generation_config)`](#new_module_models.GPTJPreTrainedModel_new)'
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new GPTJPreTrainedModel(config, session, generation_config)`](#new_module_models.GPTJPreTrainedModel_new)'
- en: '[.GPTBigCodePreTrainedModel](#module_models.GPTBigCodePreTrainedModel)'
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.GPTBigCodePreTrainedModel](#module_models.GPTBigCodePreTrainedModel)'
- en: '[`new GPTBigCodePreTrainedModel(config, session, generation_config)`](#new_module_models.GPTBigCodePreTrainedModel_new)'
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new GPTBigCodePreTrainedModel(config, session, generation_config)`](#new_module_models.GPTBigCodePreTrainedModel_new)'
- en: '[.CodeGenPreTrainedModel](#module_models.CodeGenPreTrainedModel)'
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CodeGenPreTrainedModel](#module_models.CodeGenPreTrainedModel)'
- en: '[`new CodeGenPreTrainedModel(config, session, generation_config)`](#new_module_models.CodeGenPreTrainedModel_new)'
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new CodeGenPreTrainedModel(config, session, generation_config)`](#new_module_models.CodeGenPreTrainedModel_new)'
- en: '[.CodeGenModel](#module_models.CodeGenModel)'
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CodeGenModel](#module_models.CodeGenModel)'
- en: '[.CodeGenForCausalLM](#module_models.CodeGenForCausalLM)'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CodeGenForCausalLM](#module_models.CodeGenForCausalLM)'
- en: '[.LlamaPreTrainedModel](#module_models.LlamaPreTrainedModel)'
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.LlamaPreTrainedModel](#module_models.LlamaPreTrainedModel)'
- en: '[`new LlamaPreTrainedModel(config, session, generation_config)`](#new_module_models.LlamaPreTrainedModel_new)'
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new LlamaPreTrainedModel(config, session, generation_config)`](#new_module_models.LlamaPreTrainedModel_new)'
- en: '[.LlamaModel](#module_models.LlamaModel)'
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.LlamaModel](#module_models.LlamaModel)'
- en: '[.Qwen2PreTrainedModel](#module_models.Qwen2PreTrainedModel)'
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Qwen2PreTrainedModel](#module_models.Qwen2PreTrainedModel)'
- en: '[`new Qwen2PreTrainedModel(config, session, generation_config)`](#new_module_models.Qwen2PreTrainedModel_new)'
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new Qwen2PreTrainedModel(config, session, generation_config)`](#new_module_models.Qwen2PreTrainedModel_new)'
- en: '[.Qwen2Model](#module_models.Qwen2Model)'
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Qwen2Model](#module_models.Qwen2Model)'
- en: '[.PhiPreTrainedModel](#module_models.PhiPreTrainedModel)'
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.PhiPreTrainedModel](#module_models.PhiPreTrainedModel)'
- en: '[`new PhiPreTrainedModel(config, session, generation_config)`](#new_module_models.PhiPreTrainedModel_new)'
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new PhiPreTrainedModel(config, session, generation_config)`](#new_module_models.PhiPreTrainedModel_new)'
- en: '[.PhiModel](#module_models.PhiModel)'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.PhiModel](#module_models.PhiModel)'
- en: '[.BloomPreTrainedModel](#module_models.BloomPreTrainedModel)'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BloomPreTrainedModel](#module_models.BloomPreTrainedModel)'
- en: '[`new BloomPreTrainedModel(config, session, generation_config)`](#new_module_models.BloomPreTrainedModel_new)'
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new BloomPreTrainedModel(config, session, generation_config)`](#new_module_models.BloomPreTrainedModel_new)'
- en: '[.BloomModel](#module_models.BloomModel)'
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BloomModel](#module_models.BloomModel)'
- en: '[.BloomForCausalLM](#module_models.BloomForCausalLM)'
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.BloomForCausalLM](#module_models.BloomForCausalLM)'
- en: '[.MptPreTrainedModel](#module_models.MptPreTrainedModel)'
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MptPreTrainedModel](#module_models.MptPreTrainedModel)'
- en: '[`new MptPreTrainedModel(config, session, generation_config)`](#new_module_models.MptPreTrainedModel_new)'
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new MptPreTrainedModel(config, session, generation_config)`](#new_module_models.MptPreTrainedModel_new)'
- en: '[.MptModel](#module_models.MptModel)'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MptModel](#module_models.MptModel)'
- en: '[.MptForCausalLM](#module_models.MptForCausalLM)'
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MptForCausalLM](#module_models.MptForCausalLM)'
- en: '[.OPTPreTrainedModel](#module_models.OPTPreTrainedModel)'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.OPTPreTrainedModel](#module_models.OPTPreTrainedModel)'
- en: '[`new OPTPreTrainedModel(config, session, generation_config)`](#new_module_models.OPTPreTrainedModel_new)'
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new OPTPreTrainedModel(config, session, generation_config)`](#new_module_models.OPTPreTrainedModel_new)'
- en: '[.OPTModel](#module_models.OPTModel)'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.OPTModel](#module_models.OPTModel)'
- en: '[.OPTForCausalLM](#module_models.OPTForCausalLM)'
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.OPTForCausalLM](#module_models.OPTForCausalLM)'
- en: '[.VitMatteForImageMatting](#module_models.VitMatteForImageMatting)'
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.VitMatteForImageMatting](#module_models.VitMatteForImageMatting)'
- en: '[`._call(model_inputs)`](#module_models.VitMatteForImageMatting+_call)'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.VitMatteForImageMatting+_call)'
- en: '[.DetrObjectDetectionOutput](#module_models.DetrObjectDetectionOutput)'
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DetrObjectDetectionOutput](#module_models.DetrObjectDetectionOutput)'
- en: '[`new DetrObjectDetectionOutput(output)`](#new_module_models.DetrObjectDetectionOutput_new)'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new DetrObjectDetectionOutput(output)`](#new_module_models.DetrObjectDetectionOutput_new)'
- en: '[.DetrSegmentationOutput](#module_models.DetrSegmentationOutput)'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DetrSegmentationOutput](#module_models.DetrSegmentationOutput)'
- en: '[`new DetrSegmentationOutput(output)`](#new_module_models.DetrSegmentationOutput_new)'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new DetrSegmentationOutput(output)`](#new_module_models.DetrSegmentationOutput_new)'
- en: '[.TableTransformerModel](#module_models.TableTransformerModel)'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.TableTransformerModel](#module_models.TableTransformerModel)'
- en: '[.TableTransformerForObjectDetection](#module_models.TableTransformerForObjectDetection)'
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.TableTransformerForObjectDetection](#module_models.TableTransformerForObjectDetection)'
- en: '[`._call(model_inputs)`](#module_models.TableTransformerForObjectDetection+_call)'
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.TableTransformerForObjectDetection+_call)'
- en: '[.ResNetPreTrainedModel](#module_models.ResNetPreTrainedModel)'
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ResNetPreTrainedModel](#module_models.ResNetPreTrainedModel)'
- en: '[.ResNetModel](#module_models.ResNetModel)'
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ResNetModel](#module_models.ResNetModel)'
- en: '[.ResNetForImageClassification](#module_models.ResNetForImageClassification)'
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ResNetForImageClassification](#module_models.ResNetForImageClassification)'
- en: '[`._call(model_inputs)`](#module_models.ResNetForImageClassification+_call)'
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ResNetForImageClassification+_call)'
- en: '[.Swin2SRModel](#module_models.Swin2SRModel)'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Swin2SRModel](#module_models.Swin2SRModel)'
- en: '[.Swin2SRForImageSuperResolution](#module_models.Swin2SRForImageSuperResolution)'
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Swin2SRForImageSuperResolution](#module_models.Swin2SRForImageSuperResolution)'
- en: '[.DPTModel](#module_models.DPTModel)'
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DPTModel](#module_models.DPTModel)'
- en: '[.DPTForDepthEstimation](#module_models.DPTForDepthEstimation)'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DPTForDepthEstimation](#module_models.DPTForDepthEstimation)'
- en: '[.DepthAnythingForDepthEstimation](#module_models.DepthAnythingForDepthEstimation)'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DepthAnythingForDepthEstimation](#module_models.DepthAnythingForDepthEstimation)'
- en: '[.GLPNModel](#module_models.GLPNModel)'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.GLPNModel](#module_models.GLPNModel)'
- en: '[.GLPNForDepthEstimation](#module_models.GLPNForDepthEstimation)'
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.GLPNForDepthEstimation](#module_models.GLPNForDepthEstimation)'
- en: '[.DonutSwinModel](#module_models.DonutSwinModel)'
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.DonutSwinModel](#module_models.DonutSwinModel)'
- en: '[.ConvNextModel](#module_models.ConvNextModel)'
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ConvNextModel](#module_models.ConvNextModel)'
- en: '[.ConvNextForImageClassification](#module_models.ConvNextForImageClassification)'
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ConvNextForImageClassification](#module_models.ConvNextForImageClassification)'
- en: '[`._call(model_inputs)`](#module_models.ConvNextForImageClassification+_call)'
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ConvNextForImageClassification+_call)'
- en: '[.ConvNextV2Model](#module_models.ConvNextV2Model)'
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ConvNextV2Model](#module_models.ConvNextV2Model)'
- en: '[.ConvNextV2ForImageClassification](#module_models.ConvNextV2ForImageClassification)'
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ConvNextV2ForImageClassification](#module_models.ConvNextV2ForImageClassification)'
- en: '[`._call(model_inputs)`](#module_models.ConvNextV2ForImageClassification+_call)'
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.ConvNextV2ForImageClassification+_call)'
- en: '[.Dinov2Model](#module_models.Dinov2Model)'
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Dinov2Model](#module_models.Dinov2Model)'
- en: '[.Dinov2ForImageClassification](#module_models.Dinov2ForImageClassification)'
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Dinov2ForImageClassification](#module_models.Dinov2ForImageClassification)'
- en: '[`._call(model_inputs)`](#module_models.Dinov2ForImageClassification+_call)'
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.Dinov2ForImageClassification+_call)'
- en: '[.YolosObjectDetectionOutput](#module_models.YolosObjectDetectionOutput)'
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.YolosObjectDetectionOutput](#module_models.YolosObjectDetectionOutput)'
- en: '[`new YolosObjectDetectionOutput(output)`](#new_module_models.YolosObjectDetectionOutput_new)'
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new YolosObjectDetectionOutput(output)`](#new_module_models.YolosObjectDetectionOutput_new)'
- en: '[.SamModel](#module_models.SamModel)'
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SamModel](#module_models.SamModel)'
- en: '[`new SamModel(config, vision_encoder, prompt_encoder_mask_decoder)`](#new_module_models.SamModel_new)'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new SamModel(config, vision_encoder, prompt_encoder_mask_decoder)`](#new_module_models.SamModel_new)'
- en: '[`.get_image_embeddings(model_inputs)`](#module_models.SamModel+get_image_embeddings)
    ⇒ `Promise.<{image_embeddings: Tensor, image_positional_embeddings: Tensor}>`'
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.get_image_embeddings(model_inputs)`](#module_models.SamModel+get_image_embeddings)
    ⇒ `Promise.<{image_embeddings: Tensor, image_positional_embeddings: Tensor}>`'
- en: '[`.forward(model_inputs)`](#module_models.SamModel+forward) ⇒ `Promise.<Object>`'
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.forward(model_inputs)`](#module_models.SamModel+forward) ⇒ `Promise.<Object>`'
- en: '[`._call(model_inputs)`](#module_models.SamModel+_call) ⇒ `Promise.<SamImageSegmentationOutput>`'
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.SamModel+_call) ⇒ `Promise.<SamImageSegmentationOutput>`'
- en: '[.SamImageSegmentationOutput](#module_models.SamImageSegmentationOutput)'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SamImageSegmentationOutput](#module_models.SamImageSegmentationOutput)'
- en: '[`new SamImageSegmentationOutput(output)`](#new_module_models.SamImageSegmentationOutput_new)'
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new SamImageSegmentationOutput(output)`](#new_module_models.SamImageSegmentationOutput_new)'
- en: '[.MarianMTModel](#module_models.MarianMTModel)'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MarianMTModel](#module_models.MarianMTModel)'
- en: '[`new MarianMTModel(config, session, decoder_merged_session, generation_config)`](#new_module_models.MarianMTModel_new)'
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new MarianMTModel(config, session, decoder_merged_session, generation_config)`](#new_module_models.MarianMTModel_new)'
- en: '[.M2M100ForConditionalGeneration](#module_models.M2M100ForConditionalGeneration)'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.M2M100ForConditionalGeneration](#module_models.M2M100ForConditionalGeneration)'
- en: '[`new M2M100ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.M2M100ForConditionalGeneration_new)'
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new M2M100ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.M2M100ForConditionalGeneration_new)'
- en: '[.Wav2Vec2Model](#module_models.Wav2Vec2Model)'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Wav2Vec2Model](#module_models.Wav2Vec2Model)'
- en: '[.Wav2Vec2BertModel](#module_models.Wav2Vec2BertModel)'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Wav2Vec2BertModel](#module_models.Wav2Vec2BertModel)'
- en: '[.Wav2Vec2BertForCTC](#module_models.Wav2Vec2BertForCTC)'
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Wav2Vec2BertForCTC](#module_models.Wav2Vec2BertForCTC)'
- en: '[`._call(model_inputs)`](#module_models.Wav2Vec2BertForCTC+_call)'
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.Wav2Vec2BertForCTC+_call)'
- en: '[.Wav2Vec2BertForSequenceClassification](#module_models.Wav2Vec2BertForSequenceClassification)'
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Wav2Vec2BertForSequenceClassification](#module_models.Wav2Vec2BertForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.Wav2Vec2BertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.Wav2Vec2BertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.HubertModel](#module_models.HubertModel)'
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.HubertModel](#module_models.HubertModel)'
- en: '[.HubertForCTC](#module_models.HubertForCTC)'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.HubertForCTC](#module_models.HubertForCTC)'
- en: '[`._call(model_inputs)`](#module_models.HubertForCTC+_call)'
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.HubertForCTC+_call)'
- en: '[.HubertForSequenceClassification](#module_models.HubertForSequenceClassification)'
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.HubertForSequenceClassification](#module_models.HubertForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.HubertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.HubertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.WavLMPreTrainedModel](#module_models.WavLMPreTrainedModel)'
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.WavLMPreTrainedModel](#module_models.WavLMPreTrainedModel)'
- en: '[.WavLMModel](#module_models.WavLMModel)'
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.WavLMModel](#module_models.WavLMModel)'
- en: '[.WavLMForCTC](#module_models.WavLMForCTC)'
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.WavLMForCTC](#module_models.WavLMForCTC)'
- en: '[`._call(model_inputs)`](#module_models.WavLMForCTC+_call)'
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.WavLMForCTC+_call)'
- en: '[.WavLMForSequenceClassification](#module_models.WavLMForSequenceClassification)'
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.WavLMForSequenceClassification](#module_models.WavLMForSequenceClassification)'
- en: '[`._call(model_inputs)`](#module_models.WavLMForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.WavLMForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
- en: '[.SpeechT5PreTrainedModel](#module_models.SpeechT5PreTrainedModel)'
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SpeechT5PreTrainedModel](#module_models.SpeechT5PreTrainedModel)'
- en: '[.SpeechT5Model](#module_models.SpeechT5Model)'
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SpeechT5Model](#module_models.SpeechT5Model)'
- en: '[.SpeechT5ForSpeechToText](#module_models.SpeechT5ForSpeechToText)'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SpeechT5ForSpeechToText](#module_models.SpeechT5ForSpeechToText)'
- en: '[.SpeechT5ForTextToSpeech](#module_models.SpeechT5ForTextToSpeech)'
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SpeechT5ForTextToSpeech](#module_models.SpeechT5ForTextToSpeech)'
- en: '[`new SpeechT5ForTextToSpeech(config, session, decoder_merged_session, generation_config)`](#new_module_models.SpeechT5ForTextToSpeech_new)'
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new SpeechT5ForTextToSpeech(config, session, decoder_merged_session, generation_config)`](#new_module_models.SpeechT5ForTextToSpeech_new)：新的SpeechT5文本转语音模型  '
- en: '[`.generate_speech(input_values, speaker_embeddings, options)`](#module_models.SpeechT5ForTextToSpeech+generate_speech)
    ⇒ `Promise.<SpeechOutput>`'
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.generate_speech(input_values, speaker_embeddings, options)`](#module_models.SpeechT5ForTextToSpeech+generate_speech)
    ⇒ `Promise.<SpeechOutput>`  '
- en: '[.SpeechT5HifiGan](#module_models.SpeechT5HifiGan)'
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SpeechT5HifiGan](#module_models.SpeechT5HifiGan)：SpeechT5HifiGan  '
- en: '[.TrOCRPreTrainedModel](#module_models.TrOCRPreTrainedModel)'
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.TrOCRPreTrainedModel](#module_models.TrOCRPreTrainedModel)：TrOCR预训练模型  '
- en: '[`new TrOCRPreTrainedModel(config, session, generation_config)`](#new_module_models.TrOCRPreTrainedModel_new)'
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new TrOCRPreTrainedModel(config, session, generation_config)`](#new_module_models.TrOCRPreTrainedModel_new)：新的TrOCR预训练模型  '
- en: '[.TrOCRForCausalLM](#module_models.TrOCRForCausalLM)'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.TrOCRForCausalLM](#module_models.TrOCRForCausalLM)：用于因果LM的TrOCR  '
- en: '[.MistralPreTrainedModel](#module_models.MistralPreTrainedModel)'
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MistralPreTrainedModel](#module_models.MistralPreTrainedModel)：Mistral预训练模型  '
- en: '[`new MistralPreTrainedModel(config, session, generation_config)`](#new_module_models.MistralPreTrainedModel_new)'
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new MistralPreTrainedModel(config, session, generation_config)`](#new_module_models.MistralPreTrainedModel_new)：新的Mistral预训练模型  '
- en: '[.FalconPreTrainedModel](#module_models.FalconPreTrainedModel)'
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.FalconPreTrainedModel](#module_models.FalconPreTrainedModel)：Falcon预训练模型  '
- en: '[`new FalconPreTrainedModel(config, session, generation_config)`](#new_module_models.FalconPreTrainedModel_new)'
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new FalconPreTrainedModel(config, session, generation_config)`](#new_module_models.FalconPreTrainedModel_new)：新的Falcon预训练模型  '
- en: '[.ClapTextModelWithProjection](#module_models.ClapTextModelWithProjection)'
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ClapTextModelWithProjection](#module_models.ClapTextModelWithProjection)：带投影的Clap文本模型  '
- en: '[`.from_pretrained()`](#module_models.ClapTextModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained()`](#module_models.ClapTextModelWithProjection.from_pretrained)：`PreTrainedModel.from_pretrained`  '
- en: '[.ClapAudioModelWithProjection](#module_models.ClapAudioModelWithProjection)'
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ClapAudioModelWithProjection](#module_models.ClapAudioModelWithProjection)：带投影的Clap音频模型  '
- en: '[`.from_pretrained()`](#module_models.ClapAudioModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained()`](#module_models.ClapAudioModelWithProjection.from_pretrained)：`PreTrainedModel.from_pretrained`  '
- en: '[.VitsModel](#module_models.VitsModel)'
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.VitsModel](#module_models.VitsModel)：Vits模型  '
- en: '[`._call(model_inputs)`](#module_models.VitsModel+_call) ⇒ `Promise.<VitsModelOutput>`'
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.VitsModel+_call) ⇒ `Promise.<VitsModelOutput>`  '
- en: '[.SegformerModel](#module_models.SegformerModel)'
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SegformerModel](#module_models.SegformerModel)：Segformer模型  '
- en: '[.SegformerForImageClassification](#module_models.SegformerForImageClassification)'
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SegformerForImageClassification](#module_models.SegformerForImageClassification)：用于图像分类的Segformer  '
- en: '[.SegformerForSemanticSegmentation](#module_models.SegformerForSemanticSegmentation)'
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SegformerForSemanticSegmentation](#module_models.SegformerForSemanticSegmentation)：用于语义分割的Segformer  '
- en: '[.PretrainedMixin](#module_models.PretrainedMixin)'
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.PretrainedMixin](#module_models.PretrainedMixin)：预训练混合模型  '
- en: '*instance*'
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*instance*  '
- en: '[`.MODEL_CLASS_MAPPINGS`](#module_models.PretrainedMixin+MODEL_CLASS_MAPPINGS)
    : `*`'
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.MODEL_CLASS_MAPPINGS`](#module_models.PretrainedMixin+MODEL_CLASS_MAPPINGS)：`*`  '
- en: '[`.BASE_IF_FAIL`](#module_models.PretrainedMixin+BASE_IF_FAIL)'
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.BASE_IF_FAIL`](#module_models.PretrainedMixin+BASE_IF_FAIL)：`*`  '
- en: '*static*'
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*static*  '
- en: '[`.from_pretrained()`](#module_models.PretrainedMixin.from_pretrained) : `PreTrainedModel.from_pretrained`'
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained()`](#module_models.PretrainedMixin.from_pretrained)：`PreTrainedModel.from_pretrained`  '
- en: '[.AutoModel](#module_models.AutoModel)'
  id: totrans-315
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModel](#module_models.AutoModel)：自动模型  '
- en: '[`.MODEL_CLASS_MAPPINGS`](#module_models.AutoModel+MODEL_CLASS_MAPPINGS) :
    `*`'
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.MODEL_CLASS_MAPPINGS`](#module_models.AutoModel+MODEL_CLASS_MAPPINGS)：`*`  '
- en: '[.AutoModelForSequenceClassification](#module_models.AutoModelForSequenceClassification)'
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForSequenceClassification](#module_models.AutoModelForSequenceClassification)：用于序列分类的自动模型  '
- en: '[.AutoModelForTokenClassification](#module_models.AutoModelForTokenClassification)'
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForTokenClassification](#module_models.AutoModelForTokenClassification)：用于标记分类的自动模型  '
- en: '[.AutoModelForSeq2SeqLM](#module_models.AutoModelForSeq2SeqLM)'
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForSeq2SeqLM](#module_models.AutoModelForSeq2SeqLM)：用于Seq2SeqLM的自动模型  '
- en: '[.AutoModelForSpeechSeq2Seq](#module_models.AutoModelForSpeechSeq2Seq)'
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForSpeechSeq2Seq](#module_models.AutoModelForSpeechSeq2Seq)：用于语音Seq2Seq的自动模型  '
- en: '[.AutoModelForTextToSpectrogram](#module_models.AutoModelForTextToSpectrogram)'
  id: totrans-321
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForTextToSpectrogram](#module_models.AutoModelForTextToSpectrogram)：用于文本到频谱图的自动模型  '
- en: '[.AutoModelForTextToWaveform](#module_models.AutoModelForTextToWaveform)'
  id: totrans-322
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForTextToWaveform](#module_models.AutoModelForTextToWaveform)：用于文本到波形的自动模型  '
- en: '[.AutoModelForCausalLM](#module_models.AutoModelForCausalLM)'
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForCausalLM](#module_models.AutoModelForCausalLM)：用于因果LM的自动模型  '
- en: '[.AutoModelForMaskedLM](#module_models.AutoModelForMaskedLM)'
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForMaskedLM](#module_models.AutoModelForMaskedLM)：用于MaskedLM的自动模型  '
- en: '[.AutoModelForQuestionAnswering](#module_models.AutoModelForQuestionAnswering)'
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForQuestionAnswering](#module_models.AutoModelForQuestionAnswering)：用于问答的自动模型  '
- en: '[.AutoModelForVision2Seq](#module_models.AutoModelForVision2Seq)'
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForVision2Seq](#module_models.AutoModelForVision2Seq)：用于Vision2Seq的自动模型  '
- en: '[.AutoModelForImageClassification](#module_models.AutoModelForImageClassification)'
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForImageClassification](#module_models.AutoModelForImageClassification)：用于图像分类的自动模型  '
- en: '[.AutoModelForImageSegmentation](#module_models.AutoModelForImageSegmentation)'
  id: totrans-328
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForImageSegmentation](#module_models.AutoModelForImageSegmentation)：用于图像分割的自动模型  '
- en: '[.AutoModelForSemanticSegmentation](#module_models.AutoModelForSemanticSegmentation)'
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForSemanticSegmentation](#module_models.AutoModelForSemanticSegmentation)：用于语义分割的自动模型  '
- en: '[.AutoModelForObjectDetection](#module_models.AutoModelForObjectDetection)'
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForObjectDetection](#module_models.AutoModelForObjectDetection)：用于目标检测的自动模型  '
- en: '[.AutoModelForMaskGeneration](#module_models.AutoModelForMaskGeneration)'
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.AutoModelForMaskGeneration](#module_models.AutoModelForMaskGeneration)：用于Mask生成的自动模型  '
- en: '[.Seq2SeqLMOutput](#module_models.Seq2SeqLMOutput)'
  id: totrans-332
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.Seq2SeqLMOutput](#module_models.Seq2SeqLMOutput)：Seq2SeqLM输出  '
- en: '[`new Seq2SeqLMOutput(output)`](#new_module_models.Seq2SeqLMOutput_new)'
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new Seq2SeqLMOutput(output)`](#new_module_models.Seq2SeqLMOutput_new)：新的Seq2SeqLM输出  '
- en: '[.SequenceClassifierOutput](#module_models.SequenceClassifierOutput)'
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SequenceClassifierOutput](#module_models.SequenceClassifierOutput)：序列分类器输出'
- en: '[`new SequenceClassifierOutput(output)`](#new_module_models.SequenceClassifierOutput_new)'
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new SequenceClassifierOutput(output)`](#new_module_models.SequenceClassifierOutput_new)：新的序列分类器输出  '
- en: '[.TokenClassifierOutput](#module_models.TokenClassifierOutput)'
  id: totrans-336
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.TokenClassifierOutput](#module_models.TokenClassifierOutput)：标记分类器输出  '
- en: '[`new TokenClassifierOutput(output)`](#new_module_models.TokenClassifierOutput_new)'
  id: totrans-337
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new TokenClassifierOutput(output)`](#new_module_models.TokenClassifierOutput_new)：新的标记分类器输出  '
- en: '[.MaskedLMOutput](#module_models.MaskedLMOutput)'
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.MaskedLMOutput](#module_models.MaskedLMOutput)：MaskedLM输出  '
- en: '[`new MaskedLMOutput(output)`](#new_module_models.MaskedLMOutput_new)'
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new MaskedLMOutput(output)`](#new_module_models.MaskedLMOutput_new)：新的MaskedLM输出  '
- en: '[.QuestionAnsweringModelOutput](#module_models.QuestionAnsweringModelOutput)'
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.QuestionAnsweringModelOutput](#module_models.QuestionAnsweringModelOutput)：问答模型输出  '
- en: '[`new QuestionAnsweringModelOutput(output)`](#new_module_models.QuestionAnsweringModelOutput_new)'
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new QuestionAnsweringModelOutput(output)`](#new_module_models.QuestionAnsweringModelOutput_new)：新的问答模型输出  '
- en: '[.CausalLMOutput](#module_models.CausalLMOutput)'
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CausalLMOutput](#module_models.CausalLMOutput)：因果LM输出  '
- en: '[`new CausalLMOutput(output)`](#new_module_models.CausalLMOutput_new)'
  id: totrans-343
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new CausalLMOutput(output)`](#new_module_models.CausalLMOutput_new)'
- en: '[.CausalLMOutputWithPast](#module_models.CausalLMOutputWithPast)'
  id: totrans-344
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.CausalLMOutputWithPast](#module_models.CausalLMOutputWithPast)'
- en: '[`new CausalLMOutputWithPast(output)`](#new_module_models.CausalLMOutputWithPast_new)'
  id: totrans-345
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new CausalLMOutputWithPast(output)`](#new_module_models.CausalLMOutputWithPast_new)'
- en: '[.ImageMattingOutput](#module_models.ImageMattingOutput)'
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.ImageMattingOutput](#module_models.ImageMattingOutput)'
- en: '[`new ImageMattingOutput(output)`](#new_module_models.ImageMattingOutput_new)'
  id: totrans-347
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new ImageMattingOutput(output)`](#new_module_models.ImageMattingOutput_new)'
- en: '[.VitsModelOutput](#module_models.VitsModelOutput)'
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.VitsModelOutput](#module_models.VitsModelOutput)'
- en: '[`new VitsModelOutput(output)`](#new_module_models.VitsModelOutput_new)'
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new VitsModelOutput(output)`](#new_module_models.VitsModelOutput_new)'
- en: '*inner*'
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*内部*'
- en: '[`~InferenceSession`](#module_models..InferenceSession) : `*`'
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`~InferenceSession`](#module_models..InferenceSession) : `*`'
- en: '[`~TypedArray`](#module_models..TypedArray) : `*`'
  id: totrans-352
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`~TypedArray`](#module_models..TypedArray) : `*`'
- en: '[`~DecoderOutput`](#module_models..DecoderOutput) ⇒ `Promise.<(Array<Array<number>>|EncoderDecoderOutput|DecoderOutput)>`'
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`~DecoderOutput`](#module_models..DecoderOutput) ⇒ `Promise.<(Array<Array<number>>|EncoderDecoderOutput|DecoderOutput)>`'
- en: '[`~WhisperGenerationConfig`](#module_models..WhisperGenerationConfig) : `Object`'
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`~WhisperGenerationConfig`](#module_models..WhisperGenerationConfig) : `Object`'
- en: '[`~SamModelInputs`](#module_models..SamModelInputs) : `Object`'
  id: totrans-355
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`~SamModelInputs`](#module_models..SamModelInputs) : `Object`'
- en: '[`~SpeechOutput`](#module_models..SpeechOutput) : `Object`'
  id: totrans-356
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`~SpeechOutput`](#module_models..SpeechOutput) : `Object`'
- en: '* * *'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.PreTrainedModel
  id: totrans-358
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.PreTrainedModel
- en: A base class for pre-trained models that provides the model configuration and
    an ONNX session.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 提供模型配置和ONNX会话的预训练模型的基类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '[.PreTrainedModel](#module_models.PreTrainedModel)'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.PreTrainedModel](#module_models.PreTrainedModel)'
- en: '[`new PreTrainedModel(config, session)`](#new_module_models.PreTrainedModel_new)'
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new PreTrainedModel(config, session)`](#new_module_models.PreTrainedModel_new)'
- en: '*instance*'
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实例*'
- en: '[`.dispose()`](#module_models.PreTrainedModel+dispose) ⇒ `Promise.<Array<unknown>>`'
  id: totrans-364
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.dispose()`](#module_models.PreTrainedModel+dispose) ⇒ `Promise.<Array<unknown>>`'
- en: '[`._call(model_inputs)`](#module_models.PreTrainedModel+_call) ⇒ `Promise.<Object>`'
  id: totrans-365
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.PreTrainedModel+_call) ⇒ `Promise.<Object>`'
- en: '[`.forward(model_inputs)`](#module_models.PreTrainedModel+forward) ⇒ `Promise.<Object>`'
  id: totrans-366
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.forward(model_inputs)`](#module_models.PreTrainedModel+forward) ⇒ `Promise.<Object>`'
- en: '[`._get_generation_config(generation_config)`](#module_models.PreTrainedModel+_get_generation_config)
    ⇒ `*`'
  id: totrans-367
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._get_generation_config(generation_config)`](#module_models.PreTrainedModel+_get_generation_config)
    ⇒ `*`'
- en: '[`.groupBeams(beams)`](#module_models.PreTrainedModel+groupBeams) ⇒ `Array`'
  id: totrans-368
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.groupBeams(beams)`](#module_models.PreTrainedModel+groupBeams) ⇒ `Array`'
- en: '[`.getPastKeyValues(decoderResults, pastKeyValues)`](#module_models.PreTrainedModel+getPastKeyValues)
    ⇒ `Object`'
  id: totrans-369
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.getPastKeyValues(decoderResults, pastKeyValues)`](#module_models.PreTrainedModel+getPastKeyValues)
    ⇒ `Object`'
- en: '[`.getAttentions(decoderResults)`](#module_models.PreTrainedModel+getAttentions)
    ⇒ `Object`'
  id: totrans-370
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.getAttentions(decoderResults)`](#module_models.PreTrainedModel+getAttentions)
    ⇒ `Object`'
- en: '[`.addPastKeyValues(decoderFeeds, pastKeyValues)`](#module_models.PreTrainedModel+addPastKeyValues)'
  id: totrans-371
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.addPastKeyValues(decoderFeeds, pastKeyValues)`](#module_models.PreTrainedModel+addPastKeyValues)'
- en: '*static*'
  id: totrans-372
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*静态*'
- en: '[`.from_pretrained(pretrained_model_name_or_path, options)`](#module_models.PreTrainedModel.from_pretrained)
    ⇒ `Promise.<PreTrainedModel>`'
  id: totrans-373
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained(pretrained_model_name_or_path, options)`](#module_models.PreTrainedModel.from_pretrained)
    ⇒ `Promise.<PreTrainedModel>`'
- en: '* * *'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new PreTrainedModel(config, session)
  id: totrans-375
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new PreTrainedModel(config, session)
- en: Creates a new instance of the `PreTrainedModel` class.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`PreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration. |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `Object` | 模型配置。 |'
- en: '| session | `any` | session for the model. |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 模型的会话。 |'
- en: '* * *'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: preTrainedModel.dispose() ⇒ <code> Promise. < Array < unknown > > </code>
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: preTrainedModel.dispose() ⇒ <code> Promise. < Array < unknown > > </code>
- en: Disposes of all the ONNX sessions that were created during inference.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 处理在推断期间创建的所有ONNX会话。
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`PreTrainedModel`](#module_models.PreTrainedModel)的实例方法'
- en: '**Returns**: `Promise.<Array<unknown>>` - An array of promises, one for each
    ONNX session that is being disposed.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回值**: `Promise.<Array<unknown>>` - 一个包含每个正在处理的ONNX会话的Promise数组。'
- en: '**Todo**'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '**待办事项**'
- en: Use [https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry)
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry)
- en: '* * *'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: preTrainedModel._call(model_inputs) ⇒ <code> Promise. < Object > </code>
  id: totrans-389
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: preTrainedModel._call(model_inputs) ⇒ <code> Promise. < Object > </code>
- en: Runs the model with the provided inputs
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 运行提供的输入的模型
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`PreTrainedModel`](#module_models.PreTrainedModel)的实例方法'
- en: '**Returns**: `Promise.<Object>` - Object containing output tensors'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回值**: `Promise.<Object>` - 包含输出张量的对象'
- en: '| Param | Type | Description |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | Object containing input tensors |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 包含输入张量的对象 |'
- en: '* * *'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: preTrainedModel.forward(model_inputs) ⇒ <code> Promise. < Object > </code>
  id: totrans-397
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: preTrainedModel.forward(model_inputs) ⇒ <code> Promise. < Object > </code>
- en: Forward method for a pretrained model. If not overridden by a subclass, the
    correct forward method will be chosen based on the model type.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型的前向方法。如果子类没有覆盖，将根据模型类型选择正确的前向方法。
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`PreTrainedModel`](#module_models.PreTrainedModel)的实例方法'
- en: '**Returns**: `Promise.<Object>` - The output data from the model in the format
    specified in the ONNX model.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回值**: `Promise.<Object>` - 模型中指定格式的输出数据。'
- en: '**Throws**:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '**抛出**:'
- en: '`Error` This method must be implemented in subclasses.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`错误` 这个方法必须在子类中实现。'
- en: '| Param | Type | Description |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The input data to the model in the format specified
    in the ONNX model. |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型中指定格式的输入数据。 |'
- en: '* * *'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: preTrainedModel._get_generation_config(generation_config) ⇒ <code> * </code>
  id: totrans-407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: preTrainedModel._get_generation_config(generation_config) ⇒ <code> * </code>
- en: This function merges multiple generation configs together to form a final generation
    config to be used by the model for text generation. It first creates an empty
    `GenerationConfig` object, then it applies the model’s own `generation_config`
    property to it. Finally, if a `generation_config` object was passed in the arguments,
    it overwrites the corresponding properties in the final config with those of the
    passed config object.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将多个生成配置合并在一起，形成最终的生成配置，供模型用于文本生成。首先创建一个空的`GenerationConfig`对象，然后将模型自己的`generation_config`属性应用于它。最后，如果在参数中传递了一个`generation_config`对象，则用传递的配置对象的属性覆盖最终配置中的相应属性。
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`PreTrainedModel`](#module_models.PreTrainedModel)的实例方法'
- en: '**Returns**: `*` - The final generation config object to be used by the model
    for text generation.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`*` - 用于文本生成的最终生成配置对象。'
- en: '| Param | Type | Description |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| generation_config | `*` | A `GenerationConfig` object containing generation
    parameters. |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `*` | 包含生成参数的`GenerationConfig`对象。|'
- en: '* * *'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: preTrainedModel.groupBeams(beams) ⇒ <code> Array </code>
  id: totrans-415
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: preTrainedModel.groupBeams(beams) ⇒ <code> Array </code>
- en: Groups an array of beam objects by their ids.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 按照它们的id将beam对象数组分组。
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`PreTrainedModel`](#module_models.PreTrainedModel)的实例方法'
- en: '**Returns**: `Array` - An array of arrays, where each inner array contains
    beam objects with the same id.'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Array` - 一个数组，其中每个内部数组包含具有相同id的beam对象。'
- en: '| Param | Type | Description |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| beams | `Array` | The array of beam objects to group. |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| beams | `Array` | 要分组的beam对象数组。|'
- en: '* * *'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: preTrainedModel.getPastKeyValues(decoderResults, pastKeyValues) ⇒ <code> Object
    </code>
  id: totrans-423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: preTrainedModel.getPastKeyValues(decoderResults, pastKeyValues) ⇒ <code> Object
    </code>
- en: Returns an object containing past key values from the given decoder results
    object.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定的解码器结果对象返回一个包含过去键值的对象。
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`PreTrainedModel`](#module_models.PreTrainedModel)的实例方法'
- en: '**Returns**: `Object` - An object containing past key values.'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Object` - 一个包含过去键值的对象。'
- en: '| Param | Type | Description |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| decoderResults | `Object` | The decoder results object. |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| decoderResults | `Object` | 解码器结果对象。|'
- en: '| pastKeyValues | `Object` | The previous past key values. |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| pastKeyValues | `Object` | 先前的过去键值。|'
- en: '* * *'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: preTrainedModel.getAttentions(decoderResults) ⇒ <code> Object </code>
  id: totrans-432
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: preTrainedModel.getAttentions(decoderResults) ⇒ <code> Object </code>
- en: Returns an object containing attentions from the given decoder results object.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定的解码器结果对象返回一个包含注意力的对象。
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`PreTrainedModel`](#module_models.PreTrainedModel)的实例方法'
- en: '**Returns**: `Object` - An object containing attentions.'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Object` - 一个包含注意力的对象。'
- en: '| Param | Type | Description |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| decoderResults | `Object` | The decoder results object. |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| decoderResults | `Object` | 解码器结果对象。|'
- en: '* * *'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: preTrainedModel.addPastKeyValues(decoderFeeds, pastKeyValues)
  id: totrans-440
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: preTrainedModel.addPastKeyValues(decoderFeeds, pastKeyValues)
- en: Adds past key values to the decoder feeds object. If pastKeyValues is null,
    creates new tensors for past key values.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 将过去键值添加到解码器feeds对象。如果pastKeyValues为null，则为过去键值创建新张量。
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`PreTrainedModel`](#module_models.PreTrainedModel)的实例方法'
- en: '| Param | Type | Description |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| decoderFeeds | `Object` | The decoder feeds object to add past key values
    to. |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| decoderFeeds | `Object` | 要添加过去键值的解码器feeds对象。|'
- en: '| pastKeyValues | `Object` | An object containing past key values. |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| pastKeyValues | `Object` | 包含过去键值的对象。|'
- en: '* * *'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: PreTrainedModel.from_pretrained(pretrained_model_name_or_path, options) ⇒ <code>
    Promise. < PreTrainedModel > </code>
  id: totrans-448
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PreTrainedModel.from_pretrained(pretrained_model_name_or_path, options) ⇒ <code>
    Promise. < PreTrainedModel > </code>
- en: Instantiate one of the model classes of the library from a pretrained model.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型实例化库中的一个模型类。
- en: The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible)
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置对象的`model_type`属性选择要实例化的模型类（如果可能，作为参数传递或从`pretrained_model_name_or_path`加载）
- en: '**Kind**: static method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`PreTrainedModel`](#module_models.PreTrainedModel)的静态方法'
- en: '**Returns**: `Promise.<PreTrainedModel>` - A new instance of the `PreTrainedModel`
    class.'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<PreTrainedModel>` - `PreTrainedModel`类的新实例。'
- en: '| Param | Type | Description |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| pretrained_model_name_or_path | `string` | The name or path of the pretrained
    model. Can be either:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: '| pretrained_model_name_or_path | `string` | 预训练模型的名称或路径。可以是：'
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，托管在huggingface.co模型存储库中的预训练模型的*模型id*。有效的模型id可以位于根级别，如`bert-base-uncased`，或者在用户或组织名称下命名空间化，如`dbmdz/bert-base-german-cased`。
- en: A path to a *directory* containing model weights, e.g., `./my_model_directory/`.
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含模型权重的*目录*的路径，例如`./my_model_directory/`。
- en: '|'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| options | `*` | Additional options for loading the model. |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| options | `*` | 加载模型的附加选项。|'
- en: '* * *'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BaseModelOutput
  id: totrans-461
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BaseModelOutput
- en: Base class for model’s outputs, with potential hidden states and attentions.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 模型输出的基类，具有潜在的隐藏状态和注意力。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new BaseModelOutput(output)
  id: totrans-465
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new BaseModelOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.last_hidden_state | `Tensor` | Sequence of hidden-states at the output
    of the last layer of the model. |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| output.last_hidden_state | `Tensor` | 模型最后一层输出的隐藏状态序列。 |'
- en: '| [output.hidden_states] | `Tensor` | Hidden-states of the model at the output
    of each layer plus the optional initial embedding outputs. |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| [output.hidden_states] | `Tensor` | 模型在每一层输出的隐藏状态加上可选的初始嵌入输出。 |'
- en: '| [output.attentions] | `Tensor` | Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads. |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| [output.attentions] | `Tensor` | 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。 |'
- en: '* * *'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BertForMaskedLM
  id: totrans-473
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BertForMaskedLM
- en: BertForMaskedLM is a class representing a BERT model for masked language modeling.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: BertForMaskedLM是表示用于掩码语言建模的BERT模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: bertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput > </code>
  id: totrans-477
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: bertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput > </code>
- en: Calls the model on new inputs.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`BertForMaskedLM`](#module_models.BertForMaskedLM)'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`BertForMaskedLM`](#module_models.BertForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<MaskedLMOutput>` - 包含模型对掩码语言建模的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BertForSequenceClassification
  id: totrans-485
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BertForSequenceClassification
- en: BertForSequenceClassification is a class representing a BERT model for sequence
    classification.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: BertForSequenceClassification是表示用于序列分类的BERT模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: bertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-489
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: bertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`BertForSequenceClassification`](#module_models.BertForSequenceClassification)'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`BertForSequenceClassification`](#module_models.BertForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<SequenceClassifierOutput>` - 包含模型对序列分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-493
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-494
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-495
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BertForTokenClassification
  id: totrans-497
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BertForTokenClassification
- en: BertForTokenClassification is a class representing a BERT model for token classification.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: BertForTokenClassification是表示用于标记分类的BERT模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: bertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-501
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: bertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`BertForTokenClassification`](#module_models.BertForTokenClassification)'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`BertForTokenClassification`](#module_models.BertForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<TokenClassifierOutput>` - 包含模型对标记分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-505
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-506
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-507
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BertForQuestionAnswering
  id: totrans-509
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BertForQuestionAnswering
- en: BertForQuestionAnswering is a class representing a BERT model for question answering.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: BertForQuestionAnswering是表示用于问题回答的BERT模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: bertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-513
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: bertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`BertForQuestionAnswering`](#module_models.BertForQuestionAnswering)'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`BertForQuestionAnswering`](#module_models.BertForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<QuestionAnsweringModelOutput>` - 包含模型对问题回答的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.RoFormerModel
  id: totrans-521
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.RoFormerModel
- en: The bare RoFormer Model transformer outputting raw hidden-states without any
    specific head on top.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 裸RoFormer模型变换器输出没有特定头部的原始隐藏状态。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.RoFormerForMaskedLM
  id: totrans-525
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.RoFormerForMaskedLM
- en: RoFormer Model with a `language modeling` head on top.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顶部`语言建模`头部的RoFormer模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: roFormerForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  id: totrans-529
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: roFormerForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
- en: Calls the model on new inputs.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`RoFormerForMaskedLM`](#module_models.RoFormerForMaskedLM)'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`RoFormerForMaskedLM`](#module_models.RoFormerForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<MaskedLMOutput>` - 包含模型对掩码语言建模的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-534
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-535
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.RoFormerForSequenceClassification
  id: totrans-537
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.RoFormerForSequenceClassification
- en: RoFormer Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output)
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顶部的序列分类/回归头部的RoFormer模型变换器（在汇总输出的顶部有一个线性层）
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: roFormerForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-541
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: roFormerForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`RoFormerForSequenceClassification`](#module_models.RoFormerForSequenceClassification)'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`RoFormerForSequenceClassification`](#module_models.RoFormerForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 包含序列分类模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.RoFormerForTokenClassification
  id: totrans-549
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.RoFormerForTokenClassification
- en: RoFormer Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 带有标记分类头部的RoFormer模型（隐藏状态输出的顶部线性层），例如用于命名实体识别（NER）任务。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: roFormerForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-553
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: roFormerForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`RoFormerForTokenClassification`](#module_models.RoFormerForTokenClassification)'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`RoFormerForTokenClassification`](#module_models.RoFormerForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<TokenClassifierOutput>` - 包含标记分类模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.RoFormerForQuestionAnswering
  id: totrans-561
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.RoFormerForQuestionAnswering
- en: RoFormer Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 带有用于提取式问答任务的跨度分类头部的RoFormer模型，例如SQuAD（隐藏状态输出的顶部线性层来计算`跨度开始logits`和`跨度结束logits`）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: roFormerForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-565
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: roFormerForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`RoFormerForQuestionAnswering`](#module_models.RoFormerForQuestionAnswering)'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`RoFormerForQuestionAnswering`](#module_models.RoFormerForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<QuestionAnsweringModelOutput>` - 包含问题回答模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-569
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-570
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-571
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ConvBertModel
  id: totrans-573
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ConvBertModel
- en: The bare ConvBERT Model transformer outputting raw hidden-states without any
    specific head on top.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的ConvBERT模型变换器，输出原始的隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ConvBertForMaskedLM
  id: totrans-577
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ConvBertForMaskedLM
- en: ConvBERT Model with a language modeling head on top.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头部的ConvBERT模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: convBertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  id: totrans-581
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: convBertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
- en: Calls the model on new inputs.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`ConvBertForMaskedLM`](#module_models.ConvBertForMaskedLM)'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ConvBertForMaskedLM`](#module_models.ConvBertForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<MaskedLMOutput>` - 包含遮蔽语言建模模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-585
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-586
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-587
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ConvBertForSequenceClassification
  id: totrans-589
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ConvBertForSequenceClassification
- en: ConvBERT Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output)
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 带有序列分类/回归头部的ConvBERT模型变换器（汇总输出的顶部线性层）
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: convBertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-593
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: convBertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`ConvBertForSequenceClassification`](#module_models.ConvBertForSequenceClassification)'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ConvBertForSequenceClassification`](#module_models.ConvBertForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 包含序列分类模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-597
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-598
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-599
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ConvBertForTokenClassification
  id: totrans-601
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ConvBertForTokenClassification
- en: ConvBERT Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 带有标记分类头部的ConvBERT模型（隐藏状态输出的顶部线性层），例如用于命名实体识别（NER）任务。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: convBertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-605
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: convBertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`ConvBertForTokenClassification`](#module_models.ConvBertForTokenClassification)'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ConvBertForTokenClassification`](#module_models.ConvBertForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<TokenClassifierOutput>` - 包含模型对标记分类的输出logits的对象。  '
- en: '| Param | Type | Description |'
  id: totrans-609
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |  '
- en: '| --- | --- | --- |'
  id: totrans-610
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |  '
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-611
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。  '
- en: '* * *'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: models.ConvBertForQuestionAnswering
  id: totrans-613
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'models.ConvBertForQuestionAnswering  '
- en: ConvBERT Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`)
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顶部用于提取式问答任务（如SQuAD）的跨度分类头的ConvBERT模型（在隐藏状态输出的顶部有线性层，用于计算`跨度开始logits`和`跨度结束logits`）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类  '
- en: '* * *'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: convBertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-617
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'convBertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>  '
- en: Calls the model on new inputs.
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: '对新输入调用模型。  '
- en: '**Kind**: instance method of [`ConvBertForQuestionAnswering`](#module_models.ConvBertForQuestionAnswering)'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ConvBertForQuestionAnswering`](#module_models.ConvBertForQuestionAnswering)的实例方法  '
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<QuestionAnsweringModelOutput>` - 包含模型对问题回答的输出logits的对象。  '
- en: '| Param | Type | Description |'
  id: totrans-621
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |  '
- en: '| --- | --- | --- |'
  id: totrans-622
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |  '
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-623
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。  '
- en: '* * *'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: models.ElectraModel
  id: totrans-625
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'models.ElectraModel  '
- en: The bare Electra Model transformer outputting raw hidden-states without any
    specific head on top. Identical to the BERT model except that it uses an additional
    linear layer between the embedding layer and the encoder if the hidden size and
    embedding size are different.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: '裸的ELECTRA模型变换器，输出原始隐藏状态，没有特定的顶部。与BERT模型相同，只是在嵌入层和编码器之间使用额外的线性层，如果隐藏大小和嵌入大小不同。  '
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类  '
- en: '* * *'
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: models.ElectraForMaskedLM
  id: totrans-629
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'models.ElectraForMaskedLM  '
- en: Electra model with a language modeling head on top.
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: '带有顶部语言建模头的ELECTRA模型。  '
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类  '
- en: '* * *'
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: electraForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  id: totrans-633
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'electraForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>  '
- en: Calls the model on new inputs.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: '对新输入调用模型。  '
- en: '**Kind**: instance method of [`ElectraForMaskedLM`](#module_models.ElectraForMaskedLM)'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ElectraForMaskedLM`](#module_models.ElectraForMaskedLM)的实例方法  '
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<MaskedLMOutput>` - 包含模型对掩码语言建模的输出logits的对象。  '
- en: '| Param | Type | Description |'
  id: totrans-637
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |  '
- en: '| --- | --- | --- |'
  id: totrans-638
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |  '
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-639
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。  '
- en: '* * *'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: models.ElectraForSequenceClassification
  id: totrans-641
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'models.ElectraForSequenceClassification  '
- en: ELECTRA Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output)
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: '带有顶部序列分类/回归头的ELECTRA模型变换器（在池化输出的顶部有一个线性层）  '
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类  '
- en: '* * *'
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: electraForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-645
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'electraForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>  '
- en: Calls the model on new inputs.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: '对新输入调用模型。  '
- en: '**Kind**: instance method of [`ElectraForSequenceClassification`](#module_models.ElectraForSequenceClassification)'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ElectraForSequenceClassification`](#module_models.ElectraForSequenceClassification)的实例方法  '
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 包含模型对序列分类的输出logits的对象。  '
- en: '| Param | Type | Description |'
  id: totrans-649
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |  '
- en: '| --- | --- | --- |'
  id: totrans-650
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |  '
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-651
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。  '
- en: '* * *'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: models.ElectraForTokenClassification
  id: totrans-653
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'models.ElectraForTokenClassification  '
- en: Electra model with a token classification head on top.
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: '带有顶部标记分类头的ELECTRA模型。  '
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类  '
- en: '* * *'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: electraForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-657
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'electraForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>  '
- en: Calls the model on new inputs.
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: '对新输入调用模型。  '
- en: '**Kind**: instance method of [`ElectraForTokenClassification`](#module_models.ElectraForTokenClassification)'
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ElectraForTokenClassification`](#module_models.ElectraForTokenClassification)的实例方法  '
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<TokenClassifierOutput>` - 包含模型对标记分类的输出logits的对象。  '
- en: '| Param | Type | Description |'
  id: totrans-661
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |  '
- en: '| --- | --- | --- |'
  id: totrans-662
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |  '
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-663
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。  '
- en: '* * *'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: models.ElectraForQuestionAnswering
  id: totrans-665
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'models.ElectraForQuestionAnswering  '
- en: LECTRA Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: '带有顶部用于提取式问答任务（如SQuAD）的跨度分类头的LECTRA模型（在隐藏状态输出的顶部有线性层，用于计算`跨度开始logits`和`跨度结束logits`）。  '
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类  '
- en: '* * *'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *  '
- en: electraForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-669
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'electraForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>  '
- en: Calls the model on new inputs.
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: '对新输入调用模型。  '
- en: '**Kind**: instance method of [`ElectraForQuestionAnswering`](#module_models.ElectraForQuestionAnswering)'
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ElectraForQuestionAnswering`](#module_models.ElectraForQuestionAnswering)的实例方法  '
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<QuestionAnsweringModelOutput>` - 包含模型对问题回答的输出logits的对象。  '
- en: '| Param | Type | Description |'
  id: totrans-673
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |  '
- en: '| --- | --- | --- |'
  id: totrans-674
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-675
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CamembertModel
  id: totrans-677
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CamembertModel
- en: The bare CamemBERT Model transformer outputting raw hidden-states without any
    specific head on top.
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: 裸CamemBERT模型变换器输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CamembertForMaskedLM
  id: totrans-681
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CamembertForMaskedLM
- en: CamemBERT Model with a `language modeling` head on top.
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 带有`语言建模`头部的CamemBERT模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: camembertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  id: totrans-685
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: camembertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`CamembertForMaskedLM`](#module_models.CamembertForMaskedLM)'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`CamembertForMaskedLM`](#module_models)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<MaskedLMOutput>` - 包含用于掩码语言建模的模型输出对数的对象。'
- en: '| Param | Type | Description |'
  id: totrans-689
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-690
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-691
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CamembertForSequenceClassification
  id: totrans-693
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CamembertForSequenceClassification
- en: CamemBERT Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output) e.g. for GLUE tasks.
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顺序分类/回归头部（池化输出顶部的线性层）的CamemBERT模型，例如用于GLUE任务。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: camembertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-697
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: camembertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`CamembertForSequenceClassification`](#module_models.CamembertForSequenceClassification)'
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`CamembertForSequenceClassification`](#module_models.CamembertForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 包含用于序列分类的模型输出对数的对象。'
- en: '| Param | Type | Description |'
  id: totrans-701
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-702
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-703
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CamembertForTokenClassification
  id: totrans-705
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CamembertForTokenClassification
- en: CamemBERT Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: 带有标记分类头部（隐藏状态输出顶部的线性层）的CamemBERT模型，例如用于命名实体识别（NER）任务。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: camembertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-709
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: camembertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`CamembertForTokenClassification`](#module_models.CamembertForTokenClassification)'
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`CamembertForTokenClassification`](#module_models.CamembertForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<TokenClassifierOutput>` - 包含用于标记分类的模型输出对数的对象。'
- en: '| Param | Type | Description |'
  id: totrans-713
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-714
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-715
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CamembertForQuestionAnswering
  id: totrans-717
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CamembertForQuestionAnswering
- en: CamemBERT Model with a span classification head on top for extractive question-answering
    tasks
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 带有抽取式问答任务的跨度分类头部的CamemBERT模型
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: camembertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-721
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: camembertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`CamembertForQuestionAnswering`](#module_models.CamembertForQuestionAnswering)'
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`CamembertForQuestionAnswering`](#module_models.CamembertForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<QuestionAnsweringModelOutput>` - 包含用于问题回答的模型输出对数的对象。'
- en: '| Param | Type | Description |'
  id: totrans-725
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-726
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-727
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaModel
  id: totrans-729
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DebertaModel
- en: The bare DeBERTa Model transformer outputting raw hidden-states without any
    specific head on top.
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: 裸DeBERTa模型变换器输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaForMaskedLM
  id: totrans-733
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DebertaForMaskedLM
- en: DeBERTa Model with a `language modeling` head on top.
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 带有`语言建模`头部的DeBERTa模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: debertaForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  id: totrans-737
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: debertaForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
- en: Calls the model on new inputs.
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DebertaForMaskedLM`](#module_models.DebertaForMaskedLM)'
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`DebertaForMaskedLM`](#module_models.DebertaForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<MaskedLMOutput>` - 包含用于掩码语言建模的模型输出对数的对象。'
- en: '| Param | Type | Description |'
  id: totrans-741
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-742
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-743
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaForSequenceClassification
  id: totrans-745
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DebertaForSequenceClassification
- en: DeBERTa Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output)
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顺序分类/回归头部（池化输出顶部的线性层）的DeBERTa模型变换器
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: debertaForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-749
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: debertaForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DebertaForSequenceClassification`](#module_models.DebertaForSequenceClassification)'
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DebertaForSequenceClassification`](#module_models.DebertaForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<SequenceClassifierOutput>` - 包含模型对序列分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-753
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-754
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-755
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaForTokenClassification
  id: totrans-757
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DebertaForTokenClassification
- en: DeBERTa Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部带有标记分类头的DeBERTa模型（隐藏状态输出顶部的线性层），例如用于命名实体识别（NER）任务。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: debertaForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-761
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: debertaForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DebertaForTokenClassification`](#module_models.DebertaForTokenClassification)'
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DebertaForTokenClassification`](#module_models.DebertaForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<TokenClassifierOutput>` - 包含模型对标记分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-765
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-766
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-767
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaForQuestionAnswering
  id: totrans-769
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DebertaForQuestionAnswering
- en: DeBERTa Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顶部的跨度分类头的DeBERTa模型，用于提取式问答任务，如SQuAD（在隐藏状态输出顶部的线性层上计算`跨度开始logits`和`跨度结束logits`）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: debertaForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-773
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: debertaForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DebertaForQuestionAnswering`](#module_models.DebertaForQuestionAnswering)'
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DebertaForQuestionAnswering`](#module_models.DebertaForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<QuestionAnsweringModelOutput>` - 包含模型对问题回答的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-777
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-778
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-779
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaV2Model
  id: totrans-781
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DebertaV2Model
- en: The bare DeBERTa-V2 Model transformer outputting raw hidden-states without any
    specific head on top.
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的DeBERTa-V2模型变换器，输出原始的隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaV2ForMaskedLM
  id: totrans-785
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DebertaV2ForMaskedLM
- en: DeBERTa-V2 Model with a `language modeling` head on top.
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部带有`语言建模`头的DeBERTa-V2模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: debertaV2ForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  id: totrans-789
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: debertaV2ForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DebertaV2ForMaskedLM`](#module_models.DebertaV2ForMaskedLM)'
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DebertaV2ForMaskedLM`](#module_models.DebertaV2ForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<MaskedLMOutput>` - 包含模型对掩码语言建模的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-793
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-794
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-795
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaV2ForSequenceClassification
  id: totrans-797
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DebertaV2ForSequenceClassification
- en: DeBERTa-V2 Model transformer with a sequence classification/regression head
    on top (a linear layer on top of the pooled output)
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顶部的序列分类/回归头的DeBERTa-V2模型变换器（在汇总输出的顶部的线性层）
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: debertaV2ForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-801
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: debertaV2ForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DebertaV2ForSequenceClassification`](#module_models.DebertaV2ForSequenceClassification)'
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DebertaV2ForSequenceClassification`](#module_models.DebertaV2ForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<SequenceClassifierOutput>` - 包含模型对序列分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-805
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-806
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-807
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaV2ForTokenClassification
  id: totrans-809
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DebertaV2ForTokenClassification
- en: DeBERTa-V2 Model with a token classification head on top (a linear layer on
    top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部带有标记分类头的DeBERTa-V2模型（隐藏状态输出顶部的线性层），例如用于命名实体识别（NER）任务。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: debertaV2ForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-813
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: debertaV2ForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DebertaV2ForTokenClassification`](#module_models.DebertaV2ForTokenClassification)'
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DebertaV2ForTokenClassification`](#module_models.DebertaV2ForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<TokenClassifierOutput>` - 包含模型用于标记分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-817
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-818
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-819
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-820
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DebertaV2ForQuestionAnswering
  id: totrans-821
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.DebertaV2ForQuestionAnswering
- en: DeBERTa-V2 Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: 带有用于提取式问答任务（如SQuAD）的跨度分类头部的DeBERTa-V2模型（在隐藏状态输出的顶部有线性层来计算`跨度起始logits`和`跨度结束logits`）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-824
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: debertaV2ForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-825
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: debertaV2ForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DebertaV2ForQuestionAnswering`](#module_models.DebertaV2ForQuestionAnswering)'
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DebertaV2ForQuestionAnswering`](#module_models.DebertaV2ForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<QuestionAnsweringModelOutput>` - 包含模型用于问答的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-829
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-830
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-831
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DistilBertForSequenceClassification
  id: totrans-833
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.DistilBertForSequenceClassification
- en: DistilBertForSequenceClassification is a class representing a DistilBERT model
    for sequence classification.
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
  zh: DistilBertForSequenceClassification是代表用于序列分类的DistilBERT模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: distilBertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. <
    SequenceClassifierOutput > </code>
  id: totrans-837
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: distilBertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. <
    SequenceClassifierOutput > </code>
- en: Calls the model on new inputs.
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DistilBertForSequenceClassification`](#module_models.DistilBertForSequenceClassification)'
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DistilBertForSequenceClassification`](#module_models.DistilBertForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<SequenceClassifierOutput>` - 包含模型用于序列分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-841
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-842
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-843
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DistilBertForTokenClassification
  id: totrans-845
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.DistilBertForTokenClassification
- en: DistilBertForTokenClassification is a class representing a DistilBERT model
    for token classification.
  id: totrans-846
  prefs: []
  type: TYPE_NORMAL
  zh: DistilBertForTokenClassification是代表用于标记分类的DistilBERT模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: distilBertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-849
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: distilBertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-850
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DistilBertForTokenClassification`](#module_models.DistilBertForTokenClassification)'
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DistilBertForTokenClassification`](#module_models.DistilBertForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<TokenClassifierOutput>` - 包含模型用于标记分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-853
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-854
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-855
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DistilBertForQuestionAnswering
  id: totrans-857
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.DistilBertForQuestionAnswering
- en: DistilBertForQuestionAnswering is a class representing a DistilBERT model for
    question answering.
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
  zh: DistilBertForQuestionAnswering是代表用于问答的DistilBERT模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-860
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: distilBertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-861
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: distilBertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DistilBertForQuestionAnswering`](#module_models.DistilBertForQuestionAnswering)'
  id: totrans-863
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DistilBertForQuestionAnswering`](#module_models.DistilBertForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<QuestionAnsweringModelOutput>` - 包含模型用于问答的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-865
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-866
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-867
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DistilBertForMaskedLM
  id: totrans-869
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.DistilBertForMaskedLM
- en: DistilBertForMaskedLM is a class representing a DistilBERT model for masking
    task.
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: DistilBertForMaskedLM是代表用于掩码任务的DistilBERT模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: distilBertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  id: totrans-873
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: distilBertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-874
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`DistilBertForMaskedLM`](#module_models.DistilBertForMaskedLM)'
  id: totrans-875
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`DistilBertForMaskedLM`](#module_models.DistilBertForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  id: totrans-876
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<MaskedLMOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-877
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-878
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-879
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-880
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.EsmModel
  id: totrans-881
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.EsmModel
- en: The bare ESM Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
  zh: ESM模型裸的变压器输出原始隐藏状态，没有特定头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-883
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-884
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.EsmForMaskedLM
  id: totrans-885
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.EsmForMaskedLM
- en: ESM Model with a `language modeling` head on top.
  id: totrans-886
  prefs: []
  type: TYPE_NORMAL
  zh: 带有`语言建模`头部的ESM模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-887
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: esmForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput > </code>
  id: totrans-889
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: esmForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput > </code>
- en: Calls the model on new inputs.
  id: totrans-890
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型对新输入进行操作。
- en: '**Kind**: instance method of [`EsmForMaskedLM`](#module_models.EsmForMaskedLM)'
  id: totrans-891
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`EsmForMaskedLM`](#module_models.EsmForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<MaskedLMOutput>` - 包含模型对掩码语言建模的输出对数的对象。'
- en: '| Param | Type | Description |'
  id: totrans-893
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-894
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-895
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.EsmForSequenceClassification
  id: totrans-897
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.EsmForSequenceClassification
- en: ESM Model transformer with a sequence classification/regression head on top
    (a linear layer on top of the pooled output)
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: ESM模型变换器，顶部带有一个序列分类/回归头（汇总输出顶部的线性层）
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-899
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: esmForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-901
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: esmForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-902
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型对新输入进行操作。
- en: '**Kind**: instance method of [`EsmForSequenceClassification`](#module_models.EsmForSequenceClassification)'
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`EsmForSequenceClassification`](#module_models.EsmForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 包含模型对序列分类的输出对数的对象。'
- en: '| Param | Type | Description |'
  id: totrans-905
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-906
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-907
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.EsmForTokenClassification
  id: totrans-909
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.EsmForTokenClassification
- en: ESM Model with a token classification head on top (a linear layer on top of
    the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
  zh: ESM模型，顶部带有一个标记分类头（隐藏状态输出顶部的线性层），例如用于命名实体识别（NER）任务。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: esmForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-913
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: esmForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-914
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型对新输入进行操作。
- en: '**Kind**: instance method of [`EsmForTokenClassification`](#module_models.EsmForTokenClassification)'
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`EsmForTokenClassification`](#module_models.EsmForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-916
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<TokenClassifierOutput>` - 包含模型对标记分类的输出对数的对象。'
- en: '| Param | Type | Description |'
  id: totrans-917
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-918
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-919
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MobileBertForMaskedLM
  id: totrans-921
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MobileBertForMaskedLM
- en: MobileBertForMaskedLM is a class representing a MobileBERT model for masking
    task.
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: MobileBertForMaskedLM是表示用于掩码任务的MobileBERT模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: mobileBertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  id: totrans-925
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: mobileBertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型对新输入进行操作。
- en: '**Kind**: instance method of [`MobileBertForMaskedLM`](#module_models.MobileBertForMaskedLM)'
  id: totrans-927
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`MobileBertForMaskedLM`](#module_models.MobileBertForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<MaskedLMOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-929
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-930
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-931
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-932
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MobileBertForSequenceClassification
  id: totrans-933
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MobileBertForSequenceClassification
- en: MobileBert Model transformer with a sequence classification/regression head
    on top (a linear layer on top of the pooled output)
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: MobileBert模型变换器，顶部带有一个序列分类/回归头（汇总输出顶部的线性层）
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-935
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-936
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: mobileBertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. <
    SequenceClassifierOutput > </code>
  id: totrans-937
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: mobileBertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. <
    SequenceClassifierOutput > </code>
- en: Calls the model on new inputs.
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型对新输入进行操作。
- en: '**Kind**: instance method of [`MobileBertForSequenceClassification`](#module_models.MobileBertForSequenceClassification)'
  id: totrans-939
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`MobileBertForSequenceClassification`](#module_models.MobileBertForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - returned object'
  id: totrans-940
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-941
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-942
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-943
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-944
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MobileBertForQuestionAnswering
  id: totrans-945
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MobileBertForQuestionAnswering
- en: MobileBert Model with a span classification head on top for extractive question-answering
    tasks
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
  zh: MobileBert模型，顶部带有一个用于提取性问答任务的跨度分类头
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-947
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: mobileBertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-949
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: mobileBertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-950
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型对新输入进行操作。
- en: '**Kind**: instance method of [`MobileBertForQuestionAnswering`](#module_models.MobileBertForQuestionAnswering)'
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`MobileBertForQuestionAnswering`](#module_models.MobileBertForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - returned object'
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<QuestionAnsweringModelOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-953
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-954
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-955
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MPNetModel
  id: totrans-957
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MPNetModel
- en: The bare MPNet Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
  zh: 裸MPNet模型变换器，输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-959
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MPNetForMaskedLM
  id: totrans-961
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MPNetForMaskedLM
- en: MPNetForMaskedLM is a class representing a MPNet model for masked language modeling.
  id: totrans-962
  prefs: []
  type: TYPE_NORMAL
  zh: MPNetForMaskedLM是表示用于掩码语言建模的MPNet模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models) 的静态类'
- en: '* * *'
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: mpNetForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput > </code>
  id: totrans-965
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: mpNetForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput > </code>
- en: Calls the model on new inputs.
  id: totrans-966
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型的新输入。
- en: '**Kind**: instance method of [`MPNetForMaskedLM`](#module_models.MPNetForMaskedLM)'
  id: totrans-967
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`MPNetForMaskedLM`](#module_models.MPNetForMaskedLM) 的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<MaskedLMOutput>` - 包含遮蔽语言建模模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-969
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-970
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-971
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-972
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MPNetForSequenceClassification
  id: totrans-973
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MPNetForSequenceClassification
- en: MPNetForSequenceClassification is a class representing a MPNet model for sequence
    classification.
  id: totrans-974
  prefs: []
  type: TYPE_NORMAL
  zh: MPNetForSequenceClassification 是表示用于序列分类的 MPNet 模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models) 的静态类'
- en: '* * *'
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: mpNetForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-977
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: mpNetForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-978
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型的新输入。
- en: '**Kind**: instance method of [`MPNetForSequenceClassification`](#module_models.MPNetForSequenceClassification)'
  id: totrans-979
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`MPNetForSequenceClassification`](#module_models.MPNetForSequenceClassification)
    的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 包含序列分类模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-981
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-982
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-983
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-984
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MPNetForTokenClassification
  id: totrans-985
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MPNetForTokenClassification
- en: MPNetForTokenClassification is a class representing a MPNet model for token
    classification.
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
  zh: MPNetForTokenClassification 是表示用于标记分类的 MPNet 模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-987
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models) 的静态类'
- en: '* * *'
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: mpNetForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-989
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: mpNetForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型的新输入。
- en: '**Kind**: instance method of [`MPNetForTokenClassification`](#module_models.MPNetForTokenClassification)'
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`MPNetForTokenClassification`](#module_models) 的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-992
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<TokenClassifierOutput>` - 包含标记分类模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-993
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-994
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-995
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MPNetForQuestionAnswering
  id: totrans-997
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MPNetForQuestionAnswering
- en: MPNetForQuestionAnswering is a class representing a MPNet model for question
    answering.
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: MPNetForQuestionAnswering 是表示用于问答的 MPNet 模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-999
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models) 的静态类'
- en: '* * *'
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: mpNetForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-1001
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: mpNetForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 调用模型的新输入。
- en: '**Kind**: instance method of [`MPNetForQuestionAnswering`](#module_models.MPNetForQuestionAnswering)'
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`MPNetForQuestionAnswering`](#module_models.MPNetForQuestionAnswering)
    的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<QuestionAnsweringModelOutput>` - 包含问答模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-1005
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1006
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1007
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.T5ForConditionalGeneration
  id: totrans-1009
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.T5ForConditionalGeneration
- en: T5Model is a class representing a T5 model for conditional generation.
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
  zh: T5Model 是表示用于条件生成的 T5 模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1011
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models) 的静态类'
- en: '* * *'
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new T5ForConditionalGeneration(config, session, decoder_merged_session, generation_config)
  id: totrans-1013
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new T5ForConditionalGeneration(config, session, decoder_merged_session, generation_config)
- en: Creates a new instance of the `T5ForConditionalGeneration` class.
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的 `T5ForConditionalGeneration` 类的实例。
- en: '| Param | Type | Description |'
  id: totrans-1015
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1016
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration. |'
  id: totrans-1017
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型配置。 |'
- en: '| session | `any` | session for the model. |'
  id: totrans-1018
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 模型的会话。 |'
- en: '| decoder_merged_session | `any` | session for the decoder. |'
  id: totrans-1019
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `any` | 解码器的会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1020
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1021
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.LongT5PreTrainedModel
  id: totrans-1022
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.LongT5PreTrainedModel
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
  zh: 一个抽象类，用于处理权重初始化和一个简单的接口，用于下载和加载预训练模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1024
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models) 的静态类'
- en: '* * *'
  id: totrans-1025
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.LongT5Model
  id: totrans-1026
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.LongT5Model
- en: The bare LONGT5 Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
  zh: 裸 LONGT5 模型变压器，输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models) 的静态类'
- en: '* * *'
  id: totrans-1029
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.LongT5ForConditionalGeneration
  id: totrans-1030
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.LongT5ForConditionalGeneration
- en: LONGT5 Model with a `language modeling` head on top.
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: 带有`语言建模`头部的 LONGT5 模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1032
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models) 的静态类'
- en: '* * *'
  id: totrans-1033
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new LongT5ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  id: totrans-1034
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new LongT5ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
- en: Creates a new instance of the `LongT5ForConditionalGeneration` class.
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的 `LongT5ForConditionalGeneration` 类的实例。
- en: '| Param | Type | Description |'
  id: totrans-1036
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1037
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration. |'
  id: totrans-1038
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型配置。 |'
- en: '| session | `any` | session for the model. |'
  id: totrans-1039
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 模型的会话。 |'
- en: '| decoder_merged_session | `any` | session for the decoder. |'
  id: totrans-1040
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `any` | 解码器的会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1041
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1042
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MT5ForConditionalGeneration
  id: totrans-1043
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MT5ForConditionalGeneration
- en: A class representing a conditional sequence-to-sequence model based on the MT5
    architecture.
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: 基于MT5架构的条件序列到序列模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1045
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new MT5ForConditionalGeneration(config, session, decoder_merged_session, generation_config)
  id: totrans-1047
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new MT5ForConditionalGeneration(config, session, decoder_merged_session, generation_config)
- en: Creates a new instance of the `MT5ForConditionalGeneration` class.
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`MT5ForConditionalGeneration`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1049
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1050
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `any` | The model configuration. |'
  id: totrans-1051
  prefs: []
  type: TYPE_TB
  zh: '| config | `any` | 模型配置。 |'
- en: '| session | `any` | The ONNX session containing the encoder weights. |'
  id: totrans-1052
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 包含编码器权重的ONNX会话。 |'
- en: '| decoder_merged_session | `any` | The ONNX session containing the merged decoder
    weights. |'
  id: totrans-1053
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `any` | 包含合并的解码器权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1054
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1055
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BartModel
  id: totrans-1056
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BartModel
- en: The bare BART Model outputting raw hidden-states without any specific head on
    top.
  id: totrans-1057
  prefs: []
  type: TYPE_NORMAL
  zh: 裸BART模型，输出原始隐藏状态，顶部没有特定的头。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1058
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BartForConditionalGeneration
  id: totrans-1060
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BartForConditionalGeneration
- en: The BART Model with a language modeling head. Can be used for summarization.
  id: totrans-1061
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头的BART模型。可用于摘要。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1063
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new BartForConditionalGeneration(config, session, decoder_merged_session, generation_config)
  id: totrans-1064
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new BartForConditionalGeneration(config, session, decoder_merged_session, generation_config)
- en: Creates a new instance of the `BartForConditionalGeneration` class.
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`BartForConditionalGeneration`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1066
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1067
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration object for the Bart model. |'
  id: totrans-1068
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | Bart模型的配置对象。 |'
- en: '| session | `Object` | The ONNX session used to execute the model. |'
  id: totrans-1069
  prefs: []
  type: TYPE_TB
  zh: '| session | `Object` | 用于执行模型的ONNX会话。 |'
- en: '| decoder_merged_session | `Object` | The ONNX session used to execute the
    decoder. |'
  id: totrans-1070
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `Object` | 用于执行解码器的ONNX会话。 |'
- en: '| generation_config | `Object` | The generation configuration object. |'
  id: totrans-1071
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `Object` | 生成配置对象。 |'
- en: '* * *'
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BartForSequenceClassification
  id: totrans-1073
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BartForSequenceClassification
- en: Bart model with a sequence classification/head on top (a linear layer on top
    of the pooled output)
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: 带有序列分类/头（汇总输出的顶部线性层）的Bart模型
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1075
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1076
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: bartForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-1077
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: bartForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1078
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`BartForSequenceClassification`](#module_models.BartForSequenceClassification)'
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`BartForSequenceClassification`](#module_models.BartForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-1080
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<SequenceClassifierOutput>` - 包含用于序列分类的模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-1081
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1082
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1083
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1084
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MBartModel
  id: totrans-1085
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MBartModel
- en: The bare MBART Model outputting raw hidden-states without any specific head
    on top.
  id: totrans-1086
  prefs: []
  type: TYPE_NORMAL
  zh: 裸MBART模型，顶部没有特定的头。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1087
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MBartForConditionalGeneration
  id: totrans-1089
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MBartForConditionalGeneration
- en: The MBART Model with a language modeling head. Can be used for summarization,
    after fine-tuning the pretrained models.
  id: totrans-1090
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头的MBART模型。在微调预训练模型后可用于摘要。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1091
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new MBartForConditionalGeneration(config, session, decoder_merged_session, generation_config)
  id: totrans-1093
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new MBartForConditionalGeneration(config, session, decoder_merged_session, generation_config)
- en: Creates a new instance of the `MBartForConditionalGeneration` class.
  id: totrans-1094
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`MBartForConditionalGeneration`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1095
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1096
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration object for the Bart model. |'
  id: totrans-1097
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | Bart模型的配置对象。 |'
- en: '| session | `Object` | The ONNX session used to execute the model. |'
  id: totrans-1098
  prefs: []
  type: TYPE_TB
  zh: '| session | `Object` | 用于执行模型的ONNX会话。 |'
- en: '| decoder_merged_session | `Object` | The ONNX session used to execute the
    decoder. |'
  id: totrans-1099
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `Object` | 用于执行解码器的ONNX会话。 |'
- en: '| generation_config | `Object` | The generation configuration object. |'
  id: totrans-1100
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `Object` | 生成配置对象。 |'
- en: '* * *'
  id: totrans-1101
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MBartForSequenceClassification
  id: totrans-1102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MBartForSequenceClassification
- en: MBart model with a sequence classification/head on top (a linear layer on top
    of the pooled output).
  id: totrans-1103
  prefs: []
  type: TYPE_NORMAL
  zh: MBart模型，顶部带有序列分类/头（汇总输出的顶部线性层）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1104
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: mBartForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-1106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: mBartForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`MBartForSequenceClassification`](#module_models.MBartForSequenceClassification)'
  id: totrans-1108
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`MBartForSequenceClassification`](#module_models.MBartForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-1109
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<SequenceClassifierOutput>` - 包含用于序列分类的模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-1110
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1111
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1112
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1113
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MBartForCausalLM
  id: totrans-1114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MBartForCausalLM
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1115
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1116
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new MBartForCausalLM(config, decoder_merged_session, generation_config)
  id: totrans-1117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new MBartForCausalLM(config, decoder_merged_session, generation_config)
- en: Creates a new instance of the `MBartForCausalLM` class.
  id: totrans-1118
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`MBartForCausalLM`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1119
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1120
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | Configuration object for the model. |'
  id: totrans-1121
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型的配置对象。 |'
- en: '| decoder_merged_session | `Object` | ONNX Session object for the decoder.
    |'
  id: totrans-1122
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `Object` | 用于解码器的ONNX会话对象。 |'
- en: '| generation_config | `Object` | Configuration object for the generation process.
    |'
  id: totrans-1123
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `Object` | 生成过程的配置对象。 |'
- en: '* * *'
  id: totrans-1124
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BlenderbotModel
  id: totrans-1125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BlenderbotModel
- en: The bare Blenderbot Model outputting raw hidden-states without any specific
    head on top.
  id: totrans-1126
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Blenderbot模型，输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1127
  prefs: []
  type: TYPE_NORMAL
  zh: 静态类[`models`](#module_models)的Kind：
- en: '* * *'
  id: totrans-1128
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BlenderbotForConditionalGeneration
  id: totrans-1129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BlenderbotForConditionalGeneration
- en: The Blenderbot Model with a language modeling head. Can be used for summarization.
  id: totrans-1130
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头部的Blenderbot模型。可用于摘要。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kind**: 静态类[`models`](#module_models)'
- en: '* * *'
  id: totrans-1132
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new BlenderbotForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  id: totrans-1133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new BlenderbotForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
- en: Creates a new instance of the `BlenderbotForConditionalGeneration` class.
  id: totrans-1134
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`BlenderbotForConditionalGeneration`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1135
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1136
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `any` | The model configuration. |'
  id: totrans-1137
  prefs: []
  type: TYPE_TB
  zh: '| config | `any` | 模型配置。 |'
- en: '| session | `any` | The ONNX session containing the encoder weights. |'
  id: totrans-1138
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 包含编码器权重的ONNX会话。 |'
- en: '| decoder_merged_session | `any` | The ONNX session containing the merged decoder
    weights. |'
  id: totrans-1139
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `any` | 包含合并的解码器权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1140
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1141
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BlenderbotSmallModel
  id: totrans-1142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BlenderbotSmallModel
- en: The bare BlenderbotSmall Model outputting raw hidden-states without any specific
    head on top.
  id: totrans-1143
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的BlenderbotSmall模型，输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1144
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kind**: 静态类[`models`](#module_models)'
- en: '* * *'
  id: totrans-1145
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BlenderbotSmallForConditionalGeneration
  id: totrans-1146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BlenderbotSmallForConditionalGeneration
- en: The BlenderbotSmall Model with a language modeling head. Can be used for summarization.
  id: totrans-1147
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头部的BlenderbotSmall模型。可用于摘要。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1148
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kind**: 静态类[`models`](#module_models)'
- en: '* * *'
  id: totrans-1149
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new BlenderbotSmallForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  id: totrans-1150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new BlenderbotSmallForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
- en: Creates a new instance of the `BlenderbotForConditionalGeneration` class.
  id: totrans-1151
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`BlenderbotForConditionalGeneration`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1152
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1153
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `any` | The model configuration. |'
  id: totrans-1154
  prefs: []
  type: TYPE_TB
  zh: '| config | `any` | 模型配置。 |'
- en: '| session | `any` | The ONNX session containing the encoder weights. |'
  id: totrans-1155
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 包含编码器权重的ONNX会话。 |'
- en: '| decoder_merged_session | `any` | The ONNX session containing the merged decoder
    weights. |'
  id: totrans-1156
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `any` | 包含合并的解码器权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1157
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1158
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.RobertaForMaskedLM
  id: totrans-1159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.RobertaForMaskedLM
- en: RobertaForMaskedLM class for performing masked language modeling on Roberta
    models.
  id: totrans-1160
  prefs: []
  type: TYPE_NORMAL
  zh: RobertaForMaskedLM类用于在Roberta模型上执行掩码语言建模。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1161
  prefs: []
  type: TYPE_NORMAL
  zh: 静态类[`models`](#module_models)的Kind：
- en: '* * *'
  id: totrans-1162
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: robertaForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  id: totrans-1163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: robertaForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
- en: Calls the model on new inputs.
  id: totrans-1164
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`RobertaForMaskedLM`](#module_models.RobertaForMaskedLM)'
  id: totrans-1165
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kind**: [`RobertaForMaskedLM`](#module_models.RobertaForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  id: totrans-1166
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<MaskedLMOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-1167
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1168
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1169
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1170
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.RobertaForSequenceClassification
  id: totrans-1171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.RobertaForSequenceClassification
- en: RobertaForSequenceClassification class for performing sequence classification
    on Roberta models.
  id: totrans-1172
  prefs: []
  type: TYPE_NORMAL
  zh: RobertaForSequenceClassification类用于在Roberta模型上执行序列分类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1173
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kind**: 静态类[`models`](#module_models)'
- en: '* * *'
  id: totrans-1174
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: robertaForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-1175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: robertaForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1176
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`RobertaForSequenceClassification`](#module_models.RobertaForSequenceClassification)'
  id: totrans-1177
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kind**: [`RobertaForSequenceClassification`](#module_models.RobertaForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - returned object'
  id: totrans-1178
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<SequenceClassifierOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-1179
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1180
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1181
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1182
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.RobertaForTokenClassification
  id: totrans-1183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.RobertaForTokenClassification
- en: RobertaForTokenClassification class for performing token classification on Roberta
    models.
  id: totrans-1184
  prefs: []
  type: TYPE_NORMAL
  zh: RobertaForTokenClassification类用于在Roberta模型上执行标记分类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1185
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kind**: 静态类[`models`](#module_models)'
- en: '* * *'
  id: totrans-1186
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: robertaForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-1187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: robertaForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1188
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`RobertaForTokenClassification`](#module_models.RobertaForTokenClassification)'
  id: totrans-1189
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kind**: [`RobertaForTokenClassification`](#module_models.RobertaForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-1190
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<TokenClassifierOutput>` - 包含用于标记分类的模型输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-1191
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1192
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1193
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1194
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.RobertaForQuestionAnswering
  id: totrans-1195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.RobertaForQuestionAnswering
- en: RobertaForQuestionAnswering class for performing question answering on Roberta
    models.
  id: totrans-1196
  prefs: []
  type: TYPE_NORMAL
  zh: 在Roberta模型上执行问答的RobertaForQuestionAnswering类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1197
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1198
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: robertaForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-1199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: robertaForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1200
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`RobertaForQuestionAnswering`](#module_models.RobertaForQuestionAnswering)'
  id: totrans-1201
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`RobertaForQuestionAnswering`](#module_models.RobertaForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - returned object'
  id: totrans-1202
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<QuestionAnsweringModelOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-1203
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1204
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1205
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1206
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMPreTrainedModel
  id: totrans-1207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMPreTrainedModel
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  id: totrans-1208
  prefs: []
  type: TYPE_NORMAL
  zh: 一个处理权重初始化和一个简单接口用于下载和加载预训练模型的抽象类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1209
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1210
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMModel
  id: totrans-1211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMModel
- en: The bare XLM Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-1212
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的XLM模型变换器输出原始隐藏状态，没有特定的头部在顶部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1213
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1214
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMWithLMHeadModel
  id: totrans-1215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMWithLMHeadModel
- en: The XLM Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  id: totrans-1216
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头部的XLM模型变换器（线性层，权重与输入嵌入相关联）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1217
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1218
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: xlmWithLMHeadModel._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  id: totrans-1219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: xlmWithLMHeadModel._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
- en: Calls the model on new inputs.
  id: totrans-1220
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`XLMWithLMHeadModel`](#module_models.XLMWithLMHeadModel)'
  id: totrans-1221
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`XLMWithLMHeadModel`](#module_models.XLMWithLMHeadModel)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  id: totrans-1222
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<MaskedLMOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-1223
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1224
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1225
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1226
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMForSequenceClassification
  id: totrans-1227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMForSequenceClassification
- en: XLM Model with a sequence classification/regression head on top (a linear layer
    on top of the pooled output)
  id: totrans-1228
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部有一个序列分类/回归头的XLM模型（在汇总输出的顶部有一个线性层）
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1229
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1230
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: xlmForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-1231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: xlmForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1232
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`XLMForSequenceClassification`](#module_models.XLMForSequenceClassification)'
  id: totrans-1233
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`XLMForSequenceClassification`](#module_models.XLMForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - returned object'
  id: totrans-1234
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-1235
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1236
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1237
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1238
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMForTokenClassification
  id: totrans-1239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMForTokenClassification
- en: XLM Model with a token classification head on top (a linear layer on top of
    the hidden-states output)
  id: totrans-1240
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部有一个标记分类头的XLM模型（在隐藏状态输出的顶部有一个线性层）
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1241
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1242
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: xlmForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-1243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: xlmForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1244
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`XLMForTokenClassification`](#module_models.XLMForTokenClassification)'
  id: totrans-1245
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`XLMForTokenClassification`](#module_models.XLMForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-1246
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<TokenClassifierOutput>` - 包含模型对标记分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-1247
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1248
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1249
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1250
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMForQuestionAnswering
  id: totrans-1251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMForQuestionAnswering
- en: XLM Model with a span classification head on top for extractive question-answering
    tasks
  id: totrans-1252
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部有一个用于提取问答任务的跨度分类头的XLM模型
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1253
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1254
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: xlmForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-1255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: xlmForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1256
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`XLMForQuestionAnswering`](#module_models.XLMForQuestionAnswering)'
  id: totrans-1257
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`XLMForQuestionAnswering`](#module_models.XLMForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - returned object'
  id: totrans-1258
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<QuestionAnsweringModelOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-1259
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1260
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1261
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1262
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMRobertaForMaskedLM
  id: totrans-1263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMRobertaForMaskedLM
- en: XLMRobertaForMaskedLM class for performing masked language modeling on XLMRoberta
    models.
  id: totrans-1264
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在XLMRoberta模型上执行掩码语言建模的XLMRobertaForMaskedLM类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1265
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1266
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: xlmRobertaForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  id: totrans-1267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: xlmRobertaForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1268
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`XLMRobertaForMaskedLM`](#module_models.XLMRobertaForMaskedLM)'
  id: totrans-1269
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`XLMRobertaForMaskedLM`](#module_models.XLMRobertaForMaskedLM)的实例方法'
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  id: totrans-1270
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<MaskedLMOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-1271
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1272
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1273
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1274
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMRobertaForSequenceClassification
  id: totrans-1275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMRobertaForSequenceClassification
- en: XLMRobertaForSequenceClassification class for performing sequence classification
    on XLMRoberta models.
  id: totrans-1276
  prefs: []
  type: TYPE_NORMAL
  zh: XLMRobertaForSequenceClassification类用于在XLMRoberta模型上执行序列分类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1277
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1278
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: xlmRobertaForSequenceClassification._call(model_inputs) ⇒ <code> Promise. <
    SequenceClassifierOutput > </code>
  id: totrans-1279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: xlmRobertaForSequenceClassification._call(model_inputs) ⇒ <code> Promise. <
    SequenceClassifierOutput > </code>
- en: Calls the model on new inputs.
  id: totrans-1280
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`XLMRobertaForSequenceClassification`](#module_models.XLMRobertaForSequenceClassification)'
  id: totrans-1281
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`XLMRobertaForSequenceClassification`](#module_models.XLMRobertaForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - returned object'
  id: totrans-1282
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回值**: `Promise.<SequenceClassifierOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-1283
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1284
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1285
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1286
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMRobertaForTokenClassification
  id: totrans-1287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMRobertaForTokenClassification
- en: XLMRobertaForTokenClassification class for performing token classification on
    XLMRoberta models.
  id: totrans-1288
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在XLMRoberta模型上执行标记分类的XLMRobertaForTokenClassification类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1289
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1290
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: xlmRobertaForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  id: totrans-1291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: xlmRobertaForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1292
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`XLMRobertaForTokenClassification`](#module_models.XLMRobertaForTokenClassification)'
  id: totrans-1293
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`XLMRobertaForTokenClassification`](#module_models.XLMRobertaForTokenClassification)的实例方法'
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  id: totrans-1294
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回值**: `Promise.<TokenClassifierOutput>` - 包含模型用于标记分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-1295
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1296
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1297
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1298
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.XLMRobertaForQuestionAnswering
  id: totrans-1299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.XLMRobertaForQuestionAnswering
- en: XLMRobertaForQuestionAnswering class for performing question answering on XLMRoberta
    models.
  id: totrans-1300
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在XLMRoberta模型上执行问题回答的XLMRobertaForQuestionAnswering类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1301
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1302
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: xlmRobertaForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  id: totrans-1303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: xlmRobertaForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1304
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`XLMRobertaForQuestionAnswering`](#module_models.XLMRobertaForQuestionAnswering)'
  id: totrans-1305
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`XLMRobertaForQuestionAnswering`](#module_models.XLMRobertaForQuestionAnswering)的实例方法'
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - returned object'
  id: totrans-1306
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回值**: `Promise.<QuestionAnsweringModelOutput>` - 返回的对象'
- en: '| Param | Type | Description |'
  id: totrans-1307
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1308
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1309
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1310
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ASTModel
  id: totrans-1311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ASTModel
- en: The bare AST Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-1312
  prefs: []
  type: TYPE_NORMAL
  zh: 输出原始隐藏状态而不在顶部具有特定头部的裸AST模型变换器。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1313
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1314
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ASTForAudioClassification
  id: totrans-1315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ASTForAudioClassification
- en: Audio Spectrogram Transformer model with an audio classification head on top
    (a linear layer on top of the pooled output) e.g. for datasets like AudioSet,
    Speech Commands v2.
  id: totrans-1316
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部具有音频分类头部的音频频谱变换器模型（在池化输出的顶部有一个线性层），例如用于AudioSet、Speech Commands v2等数据集。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1317
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1318
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.WhisperModel
  id: totrans-1319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.WhisperModel
- en: WhisperModel class for training Whisper models without a language model head.
  id: totrans-1320
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练没有语言模型头的Whisper模型的WhisperModel类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1321
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1322
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.WhisperForConditionalGeneration
  id: totrans-1323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.WhisperForConditionalGeneration
- en: WhisperForConditionalGeneration class for generating conditional outputs from
    Whisper models.
  id: totrans-1324
  prefs: []
  type: TYPE_NORMAL
  zh: 用于从Whisper模型生成条件输出的WhisperForConditionalGeneration类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1325
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '[.WhisperForConditionalGeneration](#module_models.WhisperForConditionalGeneration)'
  id: totrans-1326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.WhisperForConditionalGeneration](#module_models.WhisperForConditionalGeneration)'
- en: '[`new WhisperForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.WhisperForConditionalGeneration_new)'
  id: totrans-1327
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new WhisperForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.WhisperForConditionalGeneration_new)'
- en: '[`.generate(inputs, generation_config, logits_processor)`](#module_models.WhisperForConditionalGeneration+generate)
    ⇒ `Promise.<Object>`'
  id: totrans-1328
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.generate(inputs, generation_config, logits_processor)`](#module_models.WhisperForConditionalGeneration+generate)
    ⇒ `Promise.<Object>`'
- en: '[`._extract_token_timestamps(generate_outputs, alignment_heads, [num_frames],
    [time_precision])`](#module_models.WhisperForConditionalGeneration+_extract_token_timestamps)
    ⇒ `Tensor`'
  id: totrans-1329
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._extract_token_timestamps(generate_outputs, alignment_heads, [num_frames],
    [time_precision])`](#module_models.WhisperForConditionalGeneration+_extract_token_timestamps)
    ⇒ `Tensor`'
- en: '* * *'
  id: totrans-1330
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new WhisperForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  id: totrans-1331
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new WhisperForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
- en: Creates a new instance of the `WhisperForConditionalGeneration` class.
  id: totrans-1332
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`WhisperForConditionalGeneration`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1333
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1334
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | Configuration object for the model. |'
  id: totrans-1335
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型的配置对象。 |'
- en: '| session | `Object` | ONNX Session object for the model. |'
  id: totrans-1336
  prefs: []
  type: TYPE_TB
  zh: '| session | `Object` | 模型的ONNX会话对象。 |'
- en: '| decoder_merged_session | `Object` | ONNX Session object for the decoder.
    |'
  id: totrans-1337
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `Object` | 解码器的ONNX会话对象。 |'
- en: '| generation_config | `Object` | Configuration object for the generation process.
    |'
  id: totrans-1338
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `Object` | 生成过程的配置对象。 |'
- en: '* * *'
  id: totrans-1339
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: whisperForConditionalGeneration.generate(inputs, generation_config, logits_processor)
    ⇒ <code> Promise. < Object > </code>
  id: totrans-1340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: whisperForConditionalGeneration.generate(inputs, generation_config, logits_processor)
    ⇒ <code> Promise. < Object > </code>
- en: Generates outputs based on input and generation configuration.
  id: totrans-1341
  prefs: []
  type: TYPE_NORMAL
  zh: 根据输入和生成配置生成输出。
- en: '**Kind**: instance method of [`WhisperForConditionalGeneration`](#module_models.WhisperForConditionalGeneration)'
  id: totrans-1342
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`WhisperForConditionalGeneration`](#module_models)的实例方法'
- en: '**Returns**: `Promise.<Object>` - Promise object represents the generated outputs.'
  id: totrans-1343
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<Object>` - Promise对象表示生成的输出。'
- en: '| Param | Type | Default | Description |'
  id: totrans-1344
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 默认值 | 描述 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-1345
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| inputs | `Object` |  | Input data for the model. |'
  id: totrans-1346
  prefs: []
  type: TYPE_TB
  zh: '| 输入 | `Object` |  | 模型的输入数据。 |'
- en: '| generation_config | `WhisperGenerationConfig` |  | Configuration object for
    the generation process. |'
  id: totrans-1347
  prefs: []
  type: TYPE_TB
  zh: '| 生成配置 | `WhisperGenerationConfig` |  | 生成过程的配置对象。 |'
- en: '| logits_processor | `Object` |  | Optional logits processor object. |'
  id: totrans-1348
  prefs: []
  type: TYPE_TB
  zh: '| logits_processor | `Object` |  | 可选的logits处理器对象。 |'
- en: '* * *'
  id: totrans-1349
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: whisperForConditionalGeneration._extract_token_timestamps(generate_outputs,
    alignment_heads, [num_frames], [time_precision]) ⇒ <code> Tensor </code>
  id: totrans-1350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: whisperForConditionalGeneration._extract_token_timestamps(generate_outputs,
    alignment_heads, [num_frames], [time_precision]) ⇒ <code> Tensor </code>
- en: Calculates token-level timestamps using the encoder-decoder cross-attentions
    and dynamic time-warping (DTW) to map each output token to a position in the input
    audio.
  id: totrans-1351
  prefs: []
  type: TYPE_NORMAL
  zh: 使用编码器-解码器交叉注意力和动态时间规整（DTW）计算标记级时间戳，将每个输出标记映射到输入音频中的位置。
- en: '**Kind**: instance method of [`WhisperForConditionalGeneration`](#module_models.WhisperForConditionalGeneration)'
  id: totrans-1352
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`WhisperForConditionalGeneration`](#module_models)的实例方法'
- en: '**Returns**: `Tensor` - tensor containing the timestamps in seconds for each
    predicted token'
  id: totrans-1353
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Tensor` - 包含每个预测标记的秒数时间戳的张量'
- en: '| Param | Type | Default | Description |'
  id: totrans-1354
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 默认值 | 描述 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-1355
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| generate_outputs | `Object` |  | Outputs generated by the model |'
  id: totrans-1356
  prefs: []
  type: TYPE_TB
  zh: '| 生成输出 | `Object` |  | 模型生成的输出 |'
- en: '| generate_outputs.cross_attentions | `Array.<Array<Array<Tensor>>>` |  | The
    cross attentions output by the model |'
  id: totrans-1357
  prefs: []
  type: TYPE_TB
  zh: '| generate_outputs.cross_attentions | `Array.<Array<Array<Tensor>>>` |  | 模型输出的交叉注意力
    |'
- en: '| generate_outputs.decoder_attentions | `Array.<Array<Array<Tensor>>>` |  |
    The decoder attentions output by the model |'
  id: totrans-1358
  prefs: []
  type: TYPE_TB
  zh: '| generate_outputs.decoder_attentions | `Array.<Array<Array<Tensor>>>` |  |
    模型输出的解码器注意力 |'
- en: '| generate_outputs.sequences | `Array.<Array<number>>` |  | The sequences output
    by the model |'
  id: totrans-1359
  prefs: []
  type: TYPE_TB
  zh: '| generate_outputs.sequences | `Array.<Array<number>>` |  | 模型输出的序列 |'
- en: '| alignment_heads | `Array.<Array<number>>` |  | Alignment heads of the model
    |'
  id: totrans-1360
  prefs: []
  type: TYPE_TB
  zh: '| alignment_heads | `Array.<Array<number>>` |  | 模型的对齐头部 |'
- en: '| [num_frames] | `number` |  | Number of frames in the input audio. |'
  id: totrans-1361
  prefs: []
  type: TYPE_TB
  zh: '| [num_frames] | `number` |  | 输入音频中的帧数。 |'
- en: '| [time_precision] | `number` | `0.02` | Precision of the timestamps in seconds
    |'
  id: totrans-1362
  prefs: []
  type: TYPE_TB
  zh: '| [时间精度] | `number` | `0.02` | 秒数时间戳的精度 |'
- en: '* * *'
  id: totrans-1363
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.VisionEncoderDecoderModel
  id: totrans-1364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.VisionEncoderDecoderModel
- en: Vision Encoder-Decoder model based on OpenAI’s GPT architecture for image captioning
    and other vision tasks
  id: totrans-1365
  prefs: []
  type: TYPE_NORMAL
  zh: 基于OpenAI的GPT架构的视觉编码器-解码器模型，用于图像字幕和其他视觉任务
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1366
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1367
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new VisionEncoderDecoderModel(config, session, decoder_merged_session, generation_config)
  id: totrans-1368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new VisionEncoderDecoderModel(config, session, decoder_merged_session, generation_config)
- en: Creates a new instance of the `VisionEncoderDecoderModel` class.
  id: totrans-1369
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`VisionEncoderDecoderModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1370
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1371
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration object specifying the hyperparameters
    and other model settings. |'
  id: totrans-1372
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `Object` | 指定超参数和其他模型设置的配置对象。 |'
- en: '| session | `Object` | The ONNX session containing the encoder model. |'
  id: totrans-1373
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `Object` | 包含编码器模型的ONNX会话。 |'
- en: '| decoder_merged_session | `any` | The ONNX session containing the merged decoder
    model. |'
  id: totrans-1374
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `any` | 包含合并解码器模型的ONNX会话。 |'
- en: '| generation_config | `Object` | Configuration object for the generation process.
    |'
  id: totrans-1375
  prefs: []
  type: TYPE_TB
  zh: '| 生成配置 | `Object` | 生成过程的配置对象。 |'
- en: '* * *'
  id: totrans-1376
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CLIPModel
  id: totrans-1377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CLIPModel
- en: CLIP Text and Vision Model with a projection layers on top
  id: totrans-1378
  prefs: []
  type: TYPE_NORMAL
  zh: 带有投影层的CLIP文本和视觉模型
- en: '**Example:** Perform zero-shot image classification with a `CLIPModel`.'
  id: totrans-1379
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`CLIPModel`进行零样本图像分类。'
- en: '[PRE2]'
  id: totrans-1380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1381
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1382
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CLIPTextModelWithProjection
  id: totrans-1383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CLIPTextModelWithProjection
- en: CLIP Text Model with a projection layer on top (a linear layer on top of the
    pooled output)
  id: totrans-1384
  prefs: []
  type: TYPE_NORMAL
  zh: 带有投影层的CLIP文本模型（在池化输出的顶部有一个线性层）
- en: '**Example:** Compute text embeddings with `CLIPTextModelWithProjection`.'
  id: totrans-1385
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`CLIPTextModelWithProjection`计算文本嵌入。'
- en: '[PRE3]'
  id: totrans-1386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1387
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1388
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'CLIPTextModelWithProjection.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  id: totrans-1389
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CLIPTextModelWithProjection.from_pretrained()：`PreTrainedModel.from_pretrained`
- en: '**Kind**: static method of [`CLIPTextModelWithProjection`](#module_models.CLIPTextModelWithProjection)'
  id: totrans-1390
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`CLIPTextModelWithProjection`](#module_models.CLIPTextModelWithProjection)的静态方法'
- en: '* * *'
  id: totrans-1391
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CLIPVisionModelWithProjection
  id: totrans-1392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CLIPVisionModelWithProjection
- en: CLIP Vision Model with a projection layer on top (a linear layer on top of the
    pooled output)
  id: totrans-1393
  prefs: []
  type: TYPE_NORMAL
  zh: 带有投影层的CLIP视觉模型（在池化输出的顶部有一个线性层）
- en: '**Example:** Compute vision embeddings with `CLIPVisionModelWithProjection`.'
  id: totrans-1394
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`CLIPVisionModelWithProjection`计算视觉嵌入。'
- en: '[PRE4]'
  id: totrans-1395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1396
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1397
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'CLIPVisionModelWithProjection.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  id: totrans-1398
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CLIPVisionModelWithProjection.from_pretrained()：`PreTrainedModel.from_pretrained`
- en: '**Kind**: static method of [`CLIPVisionModelWithProjection`](#module_models.CLIPVisionModelWithProjection)'
  id: totrans-1399
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`CLIPVisionModelWithProjection`](#module_models.CLIPVisionModelWithProjection)的静态方法'
- en: '* * *'
  id: totrans-1400
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SiglipModel
  id: totrans-1401
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SiglipModel
- en: SigLIP Text and Vision Model with a projection layers on top
  id: totrans-1402
  prefs: []
  type: TYPE_NORMAL
  zh: 带有投影层的SigLIP文本和视觉模型
- en: '**Example:** Perform zero-shot image classification with a `SiglipModel`.'
  id: totrans-1403
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`SiglipModel`进行零样本图像分类。'
- en: '[PRE5]'
  id: totrans-1404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1405
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1406
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SiglipTextModel
  id: totrans-1407
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SiglipTextModel
- en: The text model from SigLIP without any head or projection on top.
  id: totrans-1408
  prefs: []
  type: TYPE_NORMAL
  zh: SigLIP文本模型，没有任何头部或投影层。
- en: '**Example:** Compute text embeddings with `SiglipTextModel`.'
  id: totrans-1409
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`SiglipTextModel`计算文本嵌入。'
- en: '[PRE6]'
  id: totrans-1410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1411
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1412
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'SiglipTextModel.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  id: totrans-1413
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'SiglipTextModel.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
- en: '**Kind**: static method of [`SiglipTextModel`](#module_models.SiglipTextModel)'
  id: totrans-1414
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`SiglipTextModel`](#module_models.SiglipTextModel)的静态方法'
- en: '* * *'
  id: totrans-1415
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SiglipVisionModel
  id: totrans-1416
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SiglipVisionModel
- en: The vision model from SigLIP without any head or projection on top.
  id: totrans-1417
  prefs: []
  type: TYPE_NORMAL
  zh: 来自SigLIP的视觉模型，没有头部或顶部投影。
- en: '**Example:** Compute vision embeddings with `SiglipVisionModel`.'
  id: totrans-1418
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`SiglipVisionModel`进行视觉嵌入计算。'
- en: '[PRE7]'
  id: totrans-1419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1420
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1421
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'SiglipVisionModel.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  id: totrans-1422
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'SiglipVisionModel.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
- en: '**Kind**: static method of [`SiglipVisionModel`](#module_models.SiglipVisionModel)'
  id: totrans-1423
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态方法'
- en: '* * *'
  id: totrans-1424
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CLIPSegForImageSegmentation
  id: totrans-1425
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CLIPSegForImageSegmentation
- en: CLIPSeg model with a Transformer-based decoder on top for zero-shot and one-shot
    image segmentation.
  id: totrans-1426
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于Transformer的解码器的CLIPSeg模型进行零样本和一次性图像分割。
- en: '**Example:** Perform zero-shot image segmentation with a `CLIPSegForImageSegmentation`
    model.'
  id: totrans-1427
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`CLIPSegForImageSegmentation`模型执行零样本图像分割。'
- en: '[PRE8]'
  id: totrans-1428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can visualize the predictions as follows:'
  id: totrans-1429
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按以下方式可视化预测：
- en: '[PRE9]'
  id: totrans-1430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1431
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1432
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.GPT2PreTrainedModel
  id: totrans-1433
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.GPT2PreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1434
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1435
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new GPT2PreTrainedModel(config, session, generation_config)
  id: totrans-1436
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个新的GPT2PreTrainedModel类的实例。
- en: Creates a new instance of the `GPT2PreTrainedModel` class.
  id: totrans-1437
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的GPT2PreTrainedModel类的实例。
- en: '| Param | Type | Description |'
  id: totrans-1438
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1439
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration of the model. |'
  id: totrans-1440
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型的配置。 |'
- en: '| session | `any` | The ONNX session containing the model weights. |'
  id: totrans-1441
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 包含模型权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1442
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1443
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.GPT2LMHeadModel
  id: totrans-1444
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.GPT2LMHeadModel
- en: GPT-2 language model head on top of the GPT-2 base model. This model is suitable
    for text generation tasks.
  id: totrans-1445
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2语言模型头部在GPT-2基础模型之上。该模型适用于文本生成任务。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1446
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1447
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.GPTNeoPreTrainedModel
  id: totrans-1448
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.GPTNeoPreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1449
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1450
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new GPTNeoPreTrainedModel(config, session, generation_config)
  id: totrans-1451
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个新的GPTNeoPreTrainedModel实例。
- en: Creates a new instance of the `GPTNeoPreTrainedModel` class.
  id: totrans-1452
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的GPTNeoPreTrainedModel类的实例。
- en: '| Param | Type | Description |'
  id: totrans-1453
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1454
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration of the model. |'
  id: totrans-1455
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型的配置。 |'
- en: '| session | `any` | The ONNX session containing the model weights. |'
  id: totrans-1456
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 包含模型权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1457
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1458
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.GPTNeoXPreTrainedModel
  id: totrans-1459
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.GPTNeoXPreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1460
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1461
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new GPTNeoXPreTrainedModel(config, session, generation_config)
  id: totrans-1462
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个新的GPTNeoXPreTrainedModel实例。
- en: Creates a new instance of the `GPTNeoXPreTrainedModel` class.
  id: totrans-1463
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的GPTNeoXPreTrainedModel类的实例。
- en: '| Param | Type | Description |'
  id: totrans-1464
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1465
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration of the model. |'
  id: totrans-1466
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型的配置。 |'
- en: '| session | `any` | The ONNX session containing the model weights. |'
  id: totrans-1467
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 包含模型权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1468
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1469
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.GPTJPreTrainedModel
  id: totrans-1470
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.GPTJPreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1471
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1472
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new GPTJPreTrainedModel(config, session, generation_config)
  id: totrans-1473
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个新的GPTJPreTrainedModel实例。
- en: Creates a new instance of the `GPTJPreTrainedModel` class.
  id: totrans-1474
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的GPTJPreTrainedModel类的实例。
- en: '| Param | Type | Description |'
  id: totrans-1475
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1476
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration of the model. |'
  id: totrans-1477
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型的配置。 |'
- en: '| session | `any` | The ONNX session containing the model weights. |'
  id: totrans-1478
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 包含模型权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1479
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1480
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.GPTBigCodePreTrainedModel
  id: totrans-1481
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.GPTBigCodePreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1482
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1483
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new GPTBigCodePreTrainedModel(config, session, generation_config)
  id: totrans-1484
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个新的GPTBigCodePreTrainedModel实例。
- en: Creates a new instance of the `GPTBigCodePreTrainedModel` class.
  id: totrans-1485
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的GPTBigCodePreTrainedModel类的实例。
- en: '| Param | Type | Description |'
  id: totrans-1486
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1487
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration of the model. |'
  id: totrans-1488
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型的配置。 |'
- en: '| session | `any` | The ONNX session containing the model weights. |'
  id: totrans-1489
  prefs: []
  type: TYPE_TB
  zh: '| session | `any` | 包含模型权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1490
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1491
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CodeGenPreTrainedModel
  id: totrans-1492
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CodeGenPreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1493
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1494
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new CodeGenPreTrainedModel(config, session, generation_config)
  id: totrans-1495
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个新的CodeGenPreTrainedModel实例。
- en: Creates a new instance of the `CodeGenPreTrainedModel` class.
  id: totrans-1496
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的CodeGenPreTrainedModel类的实例。
- en: '| Param | Type | Description |'
  id: totrans-1497
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1498
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration object. |'
  id: totrans-1499
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型配置对象。 |'
- en: '| session | `Object` | The ONNX session object. |'
  id: totrans-1500
  prefs: []
  type: TYPE_TB
  zh: '| session | `Object` | ONNX会话对象。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1501
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1502
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CodeGenModel
  id: totrans-1503
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CodeGenModel
- en: CodeGenModel is a class representing a code generation model without a language
    model head.
  id: totrans-1504
  prefs: []
  type: TYPE_NORMAL
  zh: CodeGenModel是一个代表没有语言模型头部的代码生成模型的类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1505
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1506
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CodeGenForCausalLM
  id: totrans-1507
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CodeGenForCausalLM
- en: CodeGenForCausalLM is a class that represents a code generation model based
    on the GPT-2 architecture. It extends the `CodeGenPreTrainedModel` class.
  id: totrans-1508
  prefs: []
  type: TYPE_NORMAL
  zh: CodeGenForCausalLM是基于GPT-2架构的代码生成模型的类。它扩展了`CodeGenPreTrainedModel`类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1509
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1510
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.LlamaPreTrainedModel
  id: totrans-1511
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.LlamaPreTrainedModel
- en: The bare LLama Model outputting raw hidden-states without any specific head
    on top.
  id: totrans-1512
  prefs: []
  type: TYPE_NORMAL
  zh: 裸LLama模型输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1513
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1514
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new LlamaPreTrainedModel(config, session, generation_config)
  id: totrans-1515
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的LlamaPreTrainedModel(config, session, generation_config)
- en: Creates a new instance of the `LlamaPreTrainedModel` class.
  id: totrans-1516
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`LlamaPreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1517
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1518
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration object. |'
  id: totrans-1519
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `Object` | 模型配置对象。 |'
- en: '| session | `Object` | The ONNX session object. |'
  id: totrans-1520
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `Object` | ONNX会话对象。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1521
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1522
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.LlamaModel
  id: totrans-1523
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.LlamaModel
- en: The bare LLaMA Model outputting raw hidden-states without any specific head
    on top.
  id: totrans-1524
  prefs: []
  type: TYPE_NORMAL
  zh: 裸LLaMA模型输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1525
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1526
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Qwen2PreTrainedModel
  id: totrans-1527
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Qwen2PreTrainedModel
- en: The bare Qwen2 Model outputting raw hidden-states without any specific head
    on top.
  id: totrans-1528
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Qwen2模型输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1529
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1530
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new Qwen2PreTrainedModel(config, session, generation_config)
  id: totrans-1531
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的Qwen2PreTrainedModel(config, session, generation_config)
- en: Creates a new instance of the `Qwen2PreTrainedModel` class.
  id: totrans-1532
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`Qwen2PreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1533
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1534
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration object. |'
  id: totrans-1535
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `Object` | 模型配置对象。 |'
- en: '| session | `Object` | The ONNX session object. |'
  id: totrans-1536
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `Object` | ONNX会话对象。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1537
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1538
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Qwen2Model
  id: totrans-1539
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Qwen2Model
- en: The bare Qwen2 Model outputting raw hidden-states without any specific head
    on top.
  id: totrans-1540
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Qwen2模型输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1541
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1542
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.PhiPreTrainedModel
  id: totrans-1543
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.PhiPreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1544
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1545
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new PhiPreTrainedModel(config, session, generation_config)
  id: totrans-1546
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的PhiPreTrainedModel(config, session, generation_config)
- en: Creates a new instance of the `PhiPreTrainedModel` class.
  id: totrans-1547
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`PhiPreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1548
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1549
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration object. |'
  id: totrans-1550
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `Object` | 模型配置对象。 |'
- en: '| session | `Object` | The ONNX session object. |'
  id: totrans-1551
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `Object` | ONNX会话对象。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1552
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1553
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.PhiModel
  id: totrans-1554
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.PhiModel
- en: The bare Phi Model outputting raw hidden-states without any specific head on
    top.
  id: totrans-1555
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Phi模型输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1556
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1557
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BloomPreTrainedModel
  id: totrans-1558
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BloomPreTrainedModel
- en: The Bloom Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  id: totrans-1559
  prefs: []
  type: TYPE_NORMAL
  zh: 具有语言建模头部的Bloom模型变换器（线性层，其权重与输入嵌入相关联）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1560
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1561
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new BloomPreTrainedModel(config, session, generation_config)
  id: totrans-1562
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的BloomPreTrainedModel(config, session, generation_config)
- en: Creates a new instance of the `BloomPreTrainedModel` class.
  id: totrans-1563
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`BloomPreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1564
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1565
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration of the model. |'
  id: totrans-1566
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `Object` | 模型配置。 |'
- en: '| session | `any` | The ONNX session containing the model weights. |'
  id: totrans-1567
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `any` | 包含模型权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1568
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1569
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BloomModel
  id: totrans-1570
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BloomModel
- en: The bare Bloom Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-1571
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Bloom模型变换器输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1572
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1573
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.BloomForCausalLM
  id: totrans-1574
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.BloomForCausalLM
- en: The Bloom Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  id: totrans-1575
  prefs: []
  type: TYPE_NORMAL
  zh: 具有语言建模头部的Bloom模型变换器（线性层，其权重与输入嵌入相关联）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1576
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1577
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MptPreTrainedModel
  id: totrans-1578
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MptPreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1579
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1580
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new MptPreTrainedModel(config, session, generation_config)
  id: totrans-1581
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的MptPreTrainedModel(config, session, generation_config)
- en: Creates a new instance of the `MptPreTrainedModel` class.
  id: totrans-1582
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`MptPreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1583
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1584
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration object. |'
  id: totrans-1585
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `Object` | 模型配置对象。 |'
- en: '| session | `Object` | The ONNX session object. |'
  id: totrans-1586
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `Object` | ONNX会话对象。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1587
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1588
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MptModel
  id: totrans-1589
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MptModel
- en: The bare Mpt Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-1590
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Mpt模型变换器输出原始隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1591
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1592
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MptForCausalLM
  id: totrans-1593
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MptForCausalLM
- en: The MPT Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  id: totrans-1594
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头部的MPT模型变换器（线性层，权重与输入嵌入绑定）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1595
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1596
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.OPTPreTrainedModel
  id: totrans-1597
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.OPTPreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1598
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1599
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new OPTPreTrainedModel(config, session, generation_config)
  id: totrans-1600
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new OPTPreTrainedModel(config, session, generation_config)
- en: Creates a new instance of the `OPTPreTrainedModel` class.
  id: totrans-1601
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`OPTPreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1602
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1603
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration object. |'
  id: totrans-1604
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `Object` | 模型配置对象。 |'
- en: '| session | `Object` | The ONNX session object. |'
  id: totrans-1605
  prefs: []
  type: TYPE_TB
  zh: '| session | `Object` | ONNX会话对象。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1606
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1607
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.OPTModel
  id: totrans-1608
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.OPTModel
- en: The bare OPT Model outputting raw hidden-states without any specific head on
    top.
  id: totrans-1609
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的OPT模型输出原始隐藏状态，顶部没有任何特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1610
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1611
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.OPTForCausalLM
  id: totrans-1612
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.OPTForCausalLM
- en: The OPT Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  id: totrans-1613
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头部的OPT模型变换器（线性层，权重与输入嵌入绑定）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1614
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1615
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.VitMatteForImageMatting
  id: totrans-1616
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.VitMatteForImageMatting
- en: ViTMatte framework leveraging any vision backbone e.g. for ADE20k, CityScapes.
  id: totrans-1617
  prefs: []
  type: TYPE_NORMAL
  zh: 利用任何视觉骨干（例如ADE20k，CityScapes）的ViTMatte框架。
- en: '**Example:** Perform image matting with a `VitMatteForImageMatting` model.'
  id: totrans-1618
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例:** 使用`VitMatteForImageMatting`模型执行图像抠图。'
- en: '[PRE10]'
  id: totrans-1619
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can visualize the alpha matte as follows:'
  id: totrans-1620
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按以下方式可视化alpha遮罩：
- en: '[PRE11]'
  id: totrans-1621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1622
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1623
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: vitMatteForImageMatting._call(model_inputs)
  id: totrans-1624
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: vitMatteForImageMatting._call(model_inputs)
- en: '**Kind**: instance method of [`VitMatteForImageMatting`](#module_models.VitMatteForImageMatting)'
  id: totrans-1625
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`VitMatteForImageMatting`](#module_models.VitMatteForImageMatting)的实例方法'
- en: '| Param | Type |'
  id: totrans-1626
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 |'
- en: '| --- | --- |'
  id: totrans-1627
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| model_inputs | `any` |'
  id: totrans-1628
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `any` |'
- en: '* * *'
  id: totrans-1629
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DetrObjectDetectionOutput
  id: totrans-1630
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DetrObjectDetectionOutput
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1631
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1632
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new DetrObjectDetectionOutput(output)
  id: totrans-1633
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new DetrObjectDetectionOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-1634
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1635
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-1636
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.logits | `Tensor` | Classification logits (including no-object) for
    all queries. |'
  id: totrans-1637
  prefs: []
  type: TYPE_TB
  zh: '| output.logits | `Tensor` | 所有查询的分类logits（包括无对象）。 |'
- en: '| output.pred_boxes | `Tensor` | Normalized boxes coordinates for all queries,
    represented as (center_x, center_y, width, height). These values are normalized
    in [0, 1], relative to the size of each individual image in the batch (disregarding
    possible padding). |'
  id: totrans-1638
  prefs: []
  type: TYPE_TB
  zh: '| output.pred_boxes | `Tensor` | 所有查询的标准化框坐标，表示为（中心_x，中心_y，宽度，高度）。这些值在[0, 1]范围内标准化，相对于批处理中每个单独图像的大小（忽略可能的填充）。
    |'
- en: '* * *'
  id: totrans-1639
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DetrSegmentationOutput
  id: totrans-1640
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DetrSegmentationOutput
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1641
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1642
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new DetrSegmentationOutput(output)
  id: totrans-1643
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new DetrSegmentationOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-1644
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1645
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-1646
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.logits | `Tensor` | The output logits of the model. |'
  id: totrans-1647
  prefs: []
  type: TYPE_TB
  zh: '| output.logits | `Tensor` | 模型的输出logits。 |'
- en: '| output.pred_boxes | `Tensor` | Predicted boxes. |'
  id: totrans-1648
  prefs: []
  type: TYPE_TB
  zh: '| output.pred_boxes | `Tensor` | 预测的框。 |'
- en: '| output.pred_masks | `Tensor` | Predicted masks. |'
  id: totrans-1649
  prefs: []
  type: TYPE_TB
  zh: '| output.pred_masks | `Tensor` | 预测的掩模。 |'
- en: '* * *'
  id: totrans-1650
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.TableTransformerModel
  id: totrans-1651
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.TableTransformerModel
- en: The bare Table Transformer Model (consisting of a backbone and encoder-decoder
    Transformer) outputting raw hidden-states without any specific head on top.
  id: totrans-1652
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Table Transformer模型（由骨干和编码器-解码器Transformer组成），输出顶部没有任何特定头部的原始隐藏状态。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1653
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1654
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.TableTransformerForObjectDetection
  id: totrans-1655
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.TableTransformerForObjectDetection
- en: Table Transformer Model (consisting of a backbone and encoder-decoder Transformer)
    with object detection heads on top, for tasks such as COCO detection.
  id: totrans-1656
  prefs: []
  type: TYPE_NORMAL
  zh: 带有对象检测头部的Table Transformer模型（由骨干和编码器-解码器Transformer组成），用于诸如COCO检测之类的任务。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1657
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1658
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: tableTransformerForObjectDetection._call(model_inputs)
  id: totrans-1659
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: tableTransformerForObjectDetection._call(model_inputs)
- en: '**Kind**: instance method of [`TableTransformerForObjectDetection`](#module_models.TableTransformerForObjectDetection)'
  id: totrans-1660
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`TableTransformerForObjectDetection`](#module_models.TableTransformerForObjectDetection)的实例方法'
- en: '| Param | Type |'
  id: totrans-1661
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 |'
- en: '| --- | --- |'
  id: totrans-1662
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| model_inputs | `any` |'
  id: totrans-1663
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `any` |'
- en: '* * *'
  id: totrans-1664
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ResNetPreTrainedModel
  id: totrans-1665
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ResNetPreTrainedModel
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  id: totrans-1666
  prefs: []
  type: TYPE_NORMAL
  zh: 一个处理权重初始化和简单接口以下载和加载预训练模型的抽象类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1667
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1668
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ResNetModel
  id: totrans-1669
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ResNetModel
- en: The bare ResNet model outputting raw features without any specific head on top.
  id: totrans-1670
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的ResNet模型输出原始特征，顶部没有任何特定的头。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1671
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1672
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ResNetForImageClassification
  id: totrans-1673
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ResNetForImageClassification
- en: ResNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-1674
  prefs: []
  type: TYPE_NORMAL
  zh: 带有图像分类头部（在池化特征的顶部有一个线性层），例如用于ImageNet的ResNet模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1675
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1676
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: resNetForImageClassification._call(model_inputs)
  id: totrans-1677
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: resNetForImageClassification._call(model_inputs)
- en: '**Kind**: instance method of [`ResNetForImageClassification`](#module_models.ResNetForImageClassification)'
  id: totrans-1678
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**: [`models`](#module_models.ResNetForImageClassification)的实例方法'
- en: '| Param | Type |'
  id: totrans-1679
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 |'
- en: '| --- | --- |'
  id: totrans-1680
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| model_inputs | `any` |'
  id: totrans-1681
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `any` |'
- en: '* * *'
  id: totrans-1682
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Swin2SRModel
  id: totrans-1683
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Swin2SRModel
- en: The bare Swin2SR Model transformer outputting raw hidden-states without any
    specific head on top.
  id: totrans-1684
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Swin2SR模型转换器，输出原始的隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1685
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1686
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Swin2SRForImageSuperResolution
  id: totrans-1687
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Swin2SRForImageSuperResolution
- en: Swin2SR Model transformer with an upsampler head on top for image super resolution
    and restoration.
  id: totrans-1688
  prefs: []
  type: TYPE_NORMAL
  zh: 带有上采样头部的Swin2SR模型转换器，用于图像超分辨率和恢复。
- en: '**Example:** Super-resolution w/ `Xenova/swin2SR-classical-sr-x2-64`.'
  id: totrans-1689
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：使用`Xenova/swin2SR-classical-sr-x2-64`进行超分辨率。'
- en: '[PRE12]'
  id: totrans-1690
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1691
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1692
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DPTModel
  id: totrans-1693
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DPTModel
- en: The bare DPT Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-1694
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的DPT模型转换器，输出原始的隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1695
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1696
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DPTForDepthEstimation
  id: totrans-1697
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DPTForDepthEstimation
- en: DPT Model with a depth estimation head on top (consisting of 3 convolutional
    layers) e.g. for KITTI, NYUv2.
  id: totrans-1698
  prefs: []
  type: TYPE_NORMAL
  zh: 带有深度估计头部的DPT模型（由3个卷积层组成），例如用于KITTI、NYUv2。
- en: '**Example:** Depth estimation w/ `Xenova/dpt-hybrid-midas`.'
  id: totrans-1699
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：使用`Xenova/dpt-hybrid-midas`进行深度估计。'
- en: '[PRE13]'
  id: totrans-1700
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1701
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1702
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DepthAnythingForDepthEstimation
  id: totrans-1703
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DepthAnythingForDepthEstimation
- en: Depth Anything Model with a depth estimation head on top (consisting of 3 convolutional
    layers) e.g. for KITTI, NYUv2.
  id: totrans-1704
  prefs: []
  type: TYPE_NORMAL
  zh: 带有深度估计头部的深度任意模型（由3个卷积层组成），例如用于KITTI、NYUv2。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1705
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1706
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.GLPNModel
  id: totrans-1707
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.GLPNModel
- en: The bare GLPN encoder (Mix-Transformer) outputting raw hidden-states without
    any specific head on top.
  id: totrans-1708
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的GLPN编码器（Mix-Transformer），输出原始的隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1709
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1710
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.GLPNForDepthEstimation
  id: totrans-1711
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.GLPNForDepthEstimation
- en: GLPN Model transformer with a lightweight depth estimation head on top e.g.
    for KITTI, NYUv2.
  id: totrans-1712
  prefs: []
  type: TYPE_NORMAL
  zh: 带有轻量级深度估计头部的GLPN模型转换器，例如用于KITTI、NYUv2。
- en: '**Example:** Depth estimation w/ `Xenova/glpn-kitti`.'
  id: totrans-1713
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：使用`Xenova/glpn-kitti`进行深度估计。'
- en: '[PRE14]'
  id: totrans-1714
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1715
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1716
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.DonutSwinModel
  id: totrans-1717
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.DonutSwinModel
- en: The bare Donut Swin Model transformer outputting raw hidden-states without any
    specific head on top.
  id: totrans-1718
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Donut Swin模型转换器，输出原始的隐藏状态，没有特定的头部。
- en: '**Example:** Step-by-step Document Parsing.'
  id: totrans-1719
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：逐步文档解析。'
- en: '[PRE15]'
  id: totrans-1720
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Example:** Step-by-step Document Visual Question Answering (DocVQA)'
  id: totrans-1721
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：逐步文档视觉问答（DocVQA）'
- en: '[PRE16]'
  id: totrans-1722
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1723
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1724
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ConvNextModel
  id: totrans-1725
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ConvNextModel
- en: The bare ConvNext model outputting raw features without any specific head on
    top.
  id: totrans-1726
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的ConvNext模型，输出原始特征，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1727
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1728
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ConvNextForImageClassification
  id: totrans-1729
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ConvNextForImageClassification
- en: ConvNext Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  id: totrans-1730
  prefs: []
  type: TYPE_NORMAL
  zh: 带有图像分类头部的ConvNext模型（在池化特征的顶部有一个线性层），例如用于ImageNet。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1731
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1732
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: convNextForImageClassification._call(model_inputs)
  id: totrans-1733
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: convNextForImageClassification._call(model_inputs)
- en: '**Kind**: instance method of [`ConvNextForImageClassification`](#module_models.ConvNextForImageClassification)'
  id: totrans-1734
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的实例方法'
- en: '| Param | Type |'
  id: totrans-1735
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 |'
- en: '| --- | --- |'
  id: totrans-1736
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| model_inputs | `any` |'
  id: totrans-1737
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `any` |'
- en: '* * *'
  id: totrans-1738
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ConvNextV2Model
  id: totrans-1739
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ConvNextV2Model
- en: The bare ConvNextV2 model outputting raw features without any specific head
    on top.
  id: totrans-1740
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的ConvNextV2模型，输出原始特征，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1741
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1742
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ConvNextV2ForImageClassification
  id: totrans-1743
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ConvNextV2ForImageClassification
- en: ConvNextV2 Model with an image classification head on top (a linear layer on
    top of the pooled features), e.g. for ImageNet.
  id: totrans-1744
  prefs: []
  type: TYPE_NORMAL
  zh: 带有图像分类头部的ConvNextV2模型（在池化特征的顶部有一个线性层），例如用于ImageNet。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1745
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1746
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: convNextV2ForImageClassification._call(model_inputs)
  id: totrans-1747
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: convNextV2ForImageClassification._call(model_inputs)
- en: '**Kind**: instance method of [`ConvNextV2ForImageClassification`](#module_models.ConvNextV2ForImageClassification)'
  id: totrans-1748
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的`ConvNextV2ForImageClassification`实例方法'
- en: '| Param | Type |'
  id: totrans-1749
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 |'
- en: '| --- | --- |'
  id: totrans-1750
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| model_inputs | `any` |'
  id: totrans-1751
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `any` |'
- en: '* * *'
  id: totrans-1752
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Dinov2Model
  id: totrans-1753
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Dinov2Model
- en: The bare DINOv2 Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-1754
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的DINOv2模型转换器，输出原始的隐藏状态，没有特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1755
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1756
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Dinov2ForImageClassification
  id: totrans-1757
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Dinov2ForImageClassification
- en: Dinov2 Model transformer with an image classification head on top (a linear
    layer on top of the final hidden state of the [CLS] token) e.g. for ImageNet.
  id: totrans-1758
  prefs: []
  type: TYPE_NORMAL
  zh: 带有图像分类头部的Dinov2模型转换器（在[CLS]标记的最终隐藏状态的顶部有一个线性层），例如用于ImageNet。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1759
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1760
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: dinov2ForImageClassification._call(model_inputs)
  id: totrans-1761
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: dinov2ForImageClassification._call(model_inputs)
- en: '**Kind**: instance method of [`Dinov2ForImageClassification`](#module_models.Dinov2ForImageClassification)'
  id: totrans-1762
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的`Dinov2ForImageClassification`实例方法'
- en: '| Param | Type |'
  id: totrans-1763
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 |'
- en: '| --- | --- |'
  id: totrans-1764
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| model_inputs | `any` |'
  id: totrans-1765
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `any` |'
- en: '* * *'
  id: totrans-1766
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.YolosObjectDetectionOutput
  id: totrans-1767
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.YolosObjectDetectionOutput
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1768
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1769
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new YolosObjectDetectionOutput(output)
  id: totrans-1770
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的YolosObjectDetectionOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-1771
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1772
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-1773
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.logits | `Tensor` | Classification logits (including no-object) for
    all queries. |'
  id: totrans-1774
  prefs: []
  type: TYPE_TB
  zh: '| output.logits | `Tensor` | 所有查询的分类logits（包括无对象）。'
- en: '| output.pred_boxes | `Tensor` | Normalized boxes coordinates for all queries,
    represented as (center_x, center_y, width, height). These values are normalized
    in [0, 1], relative to the size of each individual image in the batch (disregarding
    possible padding). |'
  id: totrans-1775
  prefs: []
  type: TYPE_TB
  zh: '| output.pred_boxes | `Tensor` | 所有查询的标准化框坐标，表示为（中心_x，中心_y，宽度，高度）。这些值在[0, 1]范围内标准化，相对于批处理中每个单独图像的大小（忽略可能的填充）。
    |'
- en: '* * *'
  id: totrans-1776
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SamModel
  id: totrans-1777
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SamModel
- en: Segment Anything Model (SAM) for generating segmentation masks, given an input
    image and optional 2D location and bounding boxes.
  id: totrans-1778
  prefs: []
  type: TYPE_NORMAL
  zh: Segment Anything Model (SAM)用于生成分割蒙版，给定输入图像和可选的2D位置和边界框。
- en: '**Example:** Perform mask generation w/ `Xenova/sam-vit-base`.'
  id: totrans-1779
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例:** 使用`Xenova/sam-vit-base`执行蒙版生成。'
- en: '[PRE17]'
  id: totrans-1780
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1781
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '[.SamModel](#module_models.SamModel)'
  id: totrans-1782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SamModel](#module_models.SamModel)'
- en: '[`new SamModel(config, vision_encoder, prompt_encoder_mask_decoder)`](#new_module_models.SamModel_new)'
  id: totrans-1783
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new SamModel(config, vision_encoder, prompt_encoder_mask_decoder)`](#new_module_models.SamModel_new)'
- en: '[`.get_image_embeddings(model_inputs)`](#module_models.SamModel+get_image_embeddings)
    ⇒ `Promise.<{image_embeddings: Tensor, image_positional_embeddings: Tensor}>`'
  id: totrans-1784
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.get_image_embeddings(model_inputs)`](#module_models.SamModel+get_image_embeddings)
    ⇒ `Promise.<{image_embeddings: Tensor, image_positional_embeddings: Tensor}>`'
- en: '[`.forward(model_inputs)`](#module_models.SamModel+forward) ⇒ `Promise.<Object>`'
  id: totrans-1785
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.forward(model_inputs)`](#module_models.SamModel+forward) ⇒ `Promise.<Object>`'
- en: '[`._call(model_inputs)`](#module_models.SamModel+_call) ⇒ `Promise.<SamImageSegmentationOutput>`'
  id: totrans-1786
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`._call(model_inputs)`](#module_models.SamModel+_call) ⇒ `Promise.<SamImageSegmentationOutput>`'
- en: '* * *'
  id: totrans-1787
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new SamModel(config, vision_encoder, prompt_encoder_mask_decoder)
  id: totrans-1788
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new SamModel(config, vision_encoder, prompt_encoder_mask_decoder)
- en: Creates a new instance of the `SamModel` class.
  id: totrans-1789
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`SamModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1790
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1791
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration object specifying the hyperparameters
    and other model settings. |'
  id: totrans-1792
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 指定超参数和其他模型设置的配置对象。 |'
- en: '| vision_encoder | `Object` | The ONNX session containing the vision encoder
    model. |'
  id: totrans-1793
  prefs: []
  type: TYPE_TB
  zh: '| vision_encoder | `Object` | 包含视觉编码器模型的ONNX会话。 |'
- en: '| prompt_encoder_mask_decoder | `any` | The ONNX session containing the prompt
    encoder and mask decoder model. |'
  id: totrans-1794
  prefs: []
  type: TYPE_TB
  zh: '| prompt_encoder_mask_decoder | `any` | 包含提示编码器和蒙版解码器模型的ONNX会话。 |'
- en: '* * *'
  id: totrans-1795
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'samModel.get_image_embeddings(model_inputs) ⇒ <code> Promise. < {image_embeddings:
    Tensor, image_positional_embeddings: Tensor} > </code>'
  id: totrans-1796
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'samModel.get_image_embeddings(model_inputs) ⇒ <code> Promise. < {image_embeddings:
    Tensor, image_positional_embeddings: Tensor} > </code>'
- en: Compute image embeddings and positional image embeddings, given the pixel values
    of an image.
  id: totrans-1797
  prefs: []
  type: TYPE_NORMAL
  zh: 计算图像嵌入和位置图像嵌入，给定图像的像素值。
- en: '**Kind**: instance method of [`SamModel`](#module_models.SamModel)'
  id: totrans-1798
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`SamModel`](#module_models)的实例方法'
- en: '**Returns**: `Promise.<{image_embeddings: Tensor, image_positional_embeddings:
    Tensor}>` - The image embeddings and positional image embeddings.'
  id: totrans-1799
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<{image_embeddings: Tensor, image_positional_embeddings: Tensor}>`
    - 图像嵌入和位置图像嵌入。'
- en: '| Param | Type | Description |'
  id: totrans-1800
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1801
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | Object containing the model inputs. |'
  id: totrans-1802
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 包含模型输入的对象。 |'
- en: '| model_inputs.pixel_values | `Tensor` | Pixel values obtained using a `SamProcessor`.
    |'
  id: totrans-1803
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs.pixel_values | `Tensor` | 使用`SamProcessor`获取的像素值。 |'
- en: '* * *'
  id: totrans-1804
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: samModel.forward(model_inputs) ⇒ <code> Promise. < Object > </code>
  id: totrans-1805
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: samModel.forward(model_inputs) ⇒ <code> Promise. < Object > </code>
- en: '**Kind**: instance method of [`SamModel`](#module_models.SamModel)'
  id: totrans-1806
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`SamModel`](#module_models.SamModel)的实例方法'
- en: '**Returns**: `Promise.<Object>` - The output of the model.'
  id: totrans-1807
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<Object>` - 模型的输出。'
- en: '| Param | Type | Description |'
  id: totrans-1808
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1809
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `SamModelInputs` | Object containing the model inputs. |'
  id: totrans-1810
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `SamModelInputs` | 包含模型输入的对象。 |'
- en: '* * *'
  id: totrans-1811
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: samModel._call(model_inputs) ⇒ <code> Promise. < SamImageSegmentationOutput
    > </code>
  id: totrans-1812
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: samModel._call(model_inputs) ⇒ <code> Promise. < SamImageSegmentationOutput
    > </code>
- en: Runs the model with the provided inputs
  id: totrans-1813
  prefs: []
  type: TYPE_NORMAL
  zh: 运行提供的输入的模型
- en: '**Kind**: instance method of [`SamModel`](#module_models.SamModel)'
  id: totrans-1814
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`SamModel`](#module_models.SamModel)的实例方法'
- en: '**Returns**: `Promise.<SamImageSegmentationOutput>` - Object containing segmentation
    outputs'
  id: totrans-1815
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**: `Promise.<SamImageSegmentationOutput>` - 包含分割输出的对象'
- en: '| Param | Type | Description |'
  id: totrans-1816
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1817
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | Model inputs |'
  id: totrans-1818
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型输入 |'
- en: '* * *'
  id: totrans-1819
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SamImageSegmentationOutput
  id: totrans-1820
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SamImageSegmentationOutput
- en: Base class for Segment-Anything model’s output.
  id: totrans-1821
  prefs: []
  type: TYPE_NORMAL
  zh: Segment-Anything模型输出的基类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1822
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1823
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new SamImageSegmentationOutput(output)
  id: totrans-1824
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new SamImageSegmentationOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-1825
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1826
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-1827
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.iou_scores | `Tensor` | The output logits of the model. |'
  id: totrans-1828
  prefs: []
  type: TYPE_TB
  zh: '| output.iou_scores | `Tensor` | 模型的输出对数。 |'
- en: '| output.pred_masks | `Tensor` | Predicted boxes. |'
  id: totrans-1829
  prefs: []
  type: TYPE_TB
  zh: '| output.pred_masks | `Tensor` | 预测的框。 |'
- en: '* * *'
  id: totrans-1830
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MarianMTModel
  id: totrans-1831
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MarianMTModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1832
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1833
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new MarianMTModel(config, session, decoder_merged_session, generation_config)
  id: totrans-1834
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new MarianMTModel(config, session, decoder_merged_session, generation_config)
- en: Creates a new instance of the `MarianMTModel` class.
  id: totrans-1835
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`MarianMTModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1836
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1837
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration object. |'
  id: totrans-1838
  prefs: []
  type: TYPE_TB
  zh: '| config | `Object` | 模型配置对象。 |'
- en: '| session | `Object` | The ONNX session object. |'
  id: totrans-1839
  prefs: []
  type: TYPE_TB
  zh: '| session | `Object` | ONNX会话对象。 |'
- en: '| decoder_merged_session | `any` |  |'
  id: totrans-1840
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `any` |  |'
- en: '| generation_config | `any` |  |'
  id: totrans-1841
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `any` |  |'
- en: '* * *'
  id: totrans-1842
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.M2M100ForConditionalGeneration
  id: totrans-1843
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.M2M100ForConditionalGeneration
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1844
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**: [`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1845
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new M2M100ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  id: totrans-1846
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new M2M100ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
- en: Creates a new instance of the `M2M100ForConditionalGeneration` class.
  id: totrans-1847
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`M2M100ForConditionalGeneration`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1848
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1849
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration object. |'
  id: totrans-1850
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `Object` | 模型配置对象。 |'
- en: '| session | `Object` | The ONNX session object. |'
  id: totrans-1851
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `Object` | ONNX会话对象。 |'
- en: '| decoder_merged_session | `any` |  |'
  id: totrans-1852
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `any` |  |'
- en: '| generation_config | `any` |  |'
  id: totrans-1853
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `any` |  |'
- en: '* * *'
  id: totrans-1854
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Wav2Vec2Model
  id: totrans-1855
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Wav2Vec2Model
- en: The bare Wav2Vec2 Model transformer outputting raw hidden-states without any
    specific head on top.
  id: totrans-1856
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Wav2Vec2模型变压器输出原始隐藏状态，没有特定的头部。
- en: '**Example:** Load and run a `Wav2Vec2Model` for feature extraction.'
  id: totrans-1857
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**加载并运行`Wav2Vec2Model`进行特征提取。'
- en: '[PRE18]'
  id: totrans-1858
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1859
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1860
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Wav2Vec2BertModel
  id: totrans-1861
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Wav2Vec2BertModel
- en: The bare Wav2Vec2Bert Model transformer outputting raw hidden-states without
    any specific head on top.
  id: totrans-1862
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Wav2Vec2Bert模型变压器输出原始隐藏状态，没有任何特定的头部。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1863
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1864
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Wav2Vec2BertForCTC
  id: totrans-1865
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Wav2Vec2BertForCTC
- en: Wav2Vec2Bert Model with a `language modeling` head on top for Connectionist
    Temporal Classification (CTC).
  id: totrans-1866
  prefs: []
  type: TYPE_NORMAL
  zh: Wav2Vec2Bert模型，顶部带有用于连接主义时间分类（CTC）的`语言建模`头。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1867
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1868
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: wav2Vec2BertForCTC._call(model_inputs)
  id: totrans-1869
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: wav2Vec2BertForCTC._call(model_inputs)
- en: '**Kind**: instance method of [`Wav2Vec2BertForCTC`](#module_models.Wav2Vec2BertForCTC)'
  id: totrans-1870
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`Wav2Vec2BertForCTC`](#module_models.Wav2Vec2BertForCTC)的实例方法'
- en: '| Param | Type | Description |'
  id: totrans-1871
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1872
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` |  |'
  id: totrans-1873
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` |  |'
- en: '| model_inputs.input_features | `Tensor` | Float values of input mel-spectrogram.
    |'
  id: totrans-1874
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs.input_features | `Tensor` | 输入梅尔频谱的浮点值。 |'
- en: '| model_inputs.attention_mask | `Tensor` | Mask to avoid performing convolution
    and attention on padding token indices. Mask values selected in [0, 1] |'
  id: totrans-1875
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs.attention_mask | `Tensor` | 避免在填充标记索引上执行卷积和注意力的掩码。掩码值选择在[0,
    1]中 |'
- en: '* * *'
  id: totrans-1876
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Wav2Vec2BertForSequenceClassification
  id: totrans-1877
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Wav2Vec2BertForSequenceClassification
- en: Wav2Vec2Bert Model with a sequence classification head on top (a linear layer
    over the pooled output).
  id: totrans-1878
  prefs: []
  type: TYPE_NORMAL
  zh: Wav2Vec2Bert模型，顶部带有序列分类头（在汇总输出上的线性层）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1879
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1880
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: wav2Vec2BertForSequenceClassification._call(model_inputs) ⇒ <code> Promise.
    < SequenceClassifierOutput > </code>
  id: totrans-1881
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: wav2Vec2BertForSequenceClassification._call(model_inputs) ⇒ <code> Promise.
    < SequenceClassifierOutput > </code>
- en: Calls the model on new inputs.
  id: totrans-1882
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`Wav2Vec2BertForSequenceClassification`](#module_models.Wav2Vec2BertForSequenceClassification)'
  id: totrans-1883
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`Wav2Vec2BertForSequenceClassification`](#module_models.Wav2Vec2BertForSequenceClassification)'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-1884
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 包含模型用于序列分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-1885
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1886
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1887
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1888
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.HubertModel
  id: totrans-1889
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.HubertModel
- en: The bare Hubert Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-1890
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Hubert模型变压器输出原始隐藏状态，没有特定的头部。
- en: '**Example:** Load and run a `HubertModel` for feature extraction.'
  id: totrans-1891
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**加载并运行`HubertModel`进行特征提取。'
- en: '[PRE19]'
  id: totrans-1892
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1893
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1894
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.HubertForCTC
  id: totrans-1895
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.HubertForCTC
- en: Hubert Model with a `language modeling` head on top for Connectionist Temporal
    Classification (CTC).
  id: totrans-1896
  prefs: []
  type: TYPE_NORMAL
  zh: Hubert模型，顶部带有用于连接主义时间分类（CTC）的`语言建模`头。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1897
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1898
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: hubertForCTC._call(model_inputs)
  id: totrans-1899
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: hubertForCTC._call(model_inputs)
- en: '**Kind**: instance method of [`HubertForCTC`](#module_models.HubertForCTC)'
  id: totrans-1900
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`HubertForCTC`](#module_models.HubertForCTC)的实例方法'
- en: '| Param | Type | Description |'
  id: totrans-1901
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1902
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` |  |'
  id: totrans-1903
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` |  |'
- en: '| model_inputs.input_values | `Tensor` | Float values of input raw speech waveform.
    |'
  id: totrans-1904
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs.input_values | `Tensor` | 输入原始语音波形的浮点值。 |'
- en: '| model_inputs.attention_mask | `Tensor` | Mask to avoid performing convolution
    and attention on padding token indices. Mask values selected in [0, 1] |'
  id: totrans-1905
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs.attention_mask | `Tensor` | 避免在填充标记索引上执行卷积和注意力的掩码。掩码值选择在[0,
    1]中 |'
- en: '* * *'
  id: totrans-1906
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.HubertForSequenceClassification
  id: totrans-1907
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.HubertForSequenceClassification
- en: Hubert Model with a sequence classification head on top (a linear layer over
    the pooled output) for tasks like SUPERB Keyword Spotting.
  id: totrans-1908
  prefs: []
  type: TYPE_NORMAL
  zh: Hubert模型，顶部带有序列分类头（在汇总输出上的线性层），用于任务如SUPERB关键词检测。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1909
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1910
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: hubertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-1911
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: hubertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1912
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`HubertForSequenceClassification`](#module_models.HubertForSequenceClassification)'
  id: totrans-1913
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`HubertForSequenceClassification`](#module_models.HubertForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-1914
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 包含模型用于序列分类的输出logits的对象。'
- en: '| Param | Type | Description |'
  id: totrans-1915
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1916
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1917
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `Object` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1918
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.WavLMPreTrainedModel
  id: totrans-1919
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.WavLMPreTrainedModel
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  id: totrans-1920
  prefs: []
  type: TYPE_NORMAL
  zh: 一个抽象类，用于处理权重初始化和一个简单的接口来下载和加载预训练模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1921
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)'
- en: '* * *'
  id: totrans-1922
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.WavLMModel
  id: totrans-1923
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.WavLMModel
- en: The bare WavLM Model transformer outputting raw hidden-states without any specific
    head on top.
  id: totrans-1924
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的WavLM模型变压器输出原始隐藏状态，没有特定的头部。
- en: '**Example:** Load and run a `WavLMModel` for feature extraction.'
  id: totrans-1925
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**加载并运行`WavLMModel`进行特征提取。'
- en: '[PRE20]'
  id: totrans-1926
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1927
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1928
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.WavLMForCTC
  id: totrans-1929
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.WavLMForCTC
- en: WavLM Model with a `language modeling` head on top for Connectionist Temporal
    Classification (CTC).
  id: totrans-1930
  prefs: []
  type: TYPE_NORMAL
  zh: 带有`语言建模`头部的WavLM模型，用于连接主义时间分类（CTC）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1931
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1932
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: wavLMForCTC._call(model_inputs)
  id: totrans-1933
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: wavLMForCTC._call(model_inputs)
- en: '**Kind**: instance method of [`WavLMForCTC`](#module_models.WavLMForCTC)'
  id: totrans-1934
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`WavLMForCTC`](#module_models.WavLMForCTC)的实例方法'
- en: '| Param | Type | Description |'
  id: totrans-1935
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1936
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` |  |'
  id: totrans-1937
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `对象` |  |'
- en: '| model_inputs.input_values | `Tensor` | Float values of input raw speech waveform.
    |'
  id: totrans-1938
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs.input_values | `张量` | 输入原始语音波形的浮点值。 |'
- en: '| model_inputs.attention_mask | `Tensor` | Mask to avoid performing convolution
    and attention on padding token indices. Mask values selected in [0, 1] |'
  id: totrans-1939
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs.attention_mask | `张量` | 避免在填充标记索引上执行卷积和注意力的掩码。掩码值选择在[0, 1]中
    |'
- en: '* * *'
  id: totrans-1940
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.WavLMForSequenceClassification
  id: totrans-1941
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.WavLMForSequenceClassification
- en: WavLM Model with a sequence classification head on top (a linear layer over
    the pooled output).
  id: totrans-1942
  prefs: []
  type: TYPE_NORMAL
  zh: WavLM模型，顶部带有序列分类头（池化输出上的线性层）。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1943
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1944
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: wavLMForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  id: totrans-1945
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: wavLMForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
- en: Calls the model on new inputs.
  id: totrans-1946
  prefs: []
  type: TYPE_NORMAL
  zh: 对新输入调用模型。
- en: '**Kind**: instance method of [`WavLMForSequenceClassification`](#module_models.WavLMForSequenceClassification)'
  id: totrans-1947
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`WavLMForSequenceClassification`](#module_models.WavLMForSequenceClassification)的实例方法'
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  id: totrans-1948
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SequenceClassifierOutput>` - 包含模型输出logits的对象，用于序列分类。'
- en: '| Param | Type | Description |'
  id: totrans-1949
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1950
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-1951
  prefs: []
  type: TYPE_TB
  zh: '| model_inputs | `对象` | 模型的输入。 |'
- en: '* * *'
  id: totrans-1952
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SpeechT5PreTrainedModel
  id: totrans-1953
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SpeechT5PreTrainedModel
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  id: totrans-1954
  prefs: []
  type: TYPE_NORMAL
  zh: 一个抽象类，用于处理权重初始化和下载和加载预训练模型的简单接口。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1955
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1956
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SpeechT5Model
  id: totrans-1957
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SpeechT5Model
- en: The bare SpeechT5 Encoder-Decoder Model outputting raw hidden-states without
    any specific pre- or post-nets.
  id: totrans-1958
  prefs: []
  type: TYPE_NORMAL
  zh: SpeechT5编码器-解码器模型裸输出原始隐藏状态，没有任何特定的前置或后置网络。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1959
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1960
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SpeechT5ForSpeechToText
  id: totrans-1961
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SpeechT5ForSpeechToText
- en: SpeechT5 Model with a speech encoder and a text decoder.
  id: totrans-1962
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语音编码器和文本解码器的SpeechT5模型。
- en: '**Example:** Generate speech from text with `SpeechT5ForSpeechToText`.'
  id: totrans-1963
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**使用`SpeechT5ForSpeechToText`从文本生成语音。'
- en: '[PRE21]'
  id: totrans-1964
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1965
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-1966
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SpeechT5ForTextToSpeech
  id: totrans-1967
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SpeechT5ForTextToSpeech
- en: SpeechT5 Model with a text encoder and a speech decoder.
  id: totrans-1968
  prefs: []
  type: TYPE_NORMAL
  zh: 带有文本编码器和语音解码器的SpeechT5模型。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-1969
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '[.SpeechT5ForTextToSpeech](#module_models.SpeechT5ForTextToSpeech)'
  id: totrans-1970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.SpeechT5ForTextToSpeech](#module_models.SpeechT5ForTextToSpeech)'
- en: '[`new SpeechT5ForTextToSpeech(config, session, decoder_merged_session, generation_config)`](#new_module_models.SpeechT5ForTextToSpeech_new)'
  id: totrans-1971
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`new SpeechT5ForTextToSpeech(config, session, decoder_merged_session, generation_config)`](#new_module_models.SpeechT5ForTextToSpeech_new)'
- en: '[`.generate_speech(input_values, speaker_embeddings, options)`](#module_models.SpeechT5ForTextToSpeech+generate_speech)
    ⇒ `Promise.<SpeechOutput>`'
  id: totrans-1972
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.generate_speech(input_values, speaker_embeddings, options)`](#module_models.SpeechT5ForTextToSpeech+generate_speech)
    ⇒ `Promise.<SpeechOutput>`'
- en: '* * *'
  id: totrans-1973
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new SpeechT5ForTextToSpeech(config, session, decoder_merged_session, generation_config)
  id: totrans-1974
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new SpeechT5ForTextToSpeech(config, session, decoder_merged_session, generation_config)
- en: Creates a new instance of the `SpeechT5ForTextToSpeech` class.
  id: totrans-1975
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`SpeechT5ForTextToSpeech`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-1976
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-1977
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The model configuration. |'
  id: totrans-1978
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `对象` | 模型配置。 |'
- en: '| session | `any` | session for the model. |'
  id: totrans-1979
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `任意` | 模型的会话。 |'
- en: '| decoder_merged_session | `any` | session for the decoder. |'
  id: totrans-1980
  prefs: []
  type: TYPE_TB
  zh: '| decoder_merged_session | `任意` | 解码器的会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-1981
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-1982
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: speechT5ForTextToSpeech.generate_speech(input_values, speaker_embeddings, options)
    ⇒ <code> Promise. < SpeechOutput > </code>
  id: totrans-1983
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: speechT5ForTextToSpeech.generate_speech(input_values, speaker_embeddings, options)
    ⇒ <code> Promise. < SpeechOutput > </code>
- en: Converts a sequence of input tokens into a sequence of mel spectrograms, which
    are subsequently turned into a speech waveform using a vocoder.
  id: totrans-1984
  prefs: []
  type: TYPE_NORMAL
  zh: 将一系列输入标记转换为一系列梅尔频谱图，随后使用声码器将其转换为语音波形。
- en: '**Kind**: instance method of [`SpeechT5ForTextToSpeech`](#module_models.SpeechT5ForTextToSpeech)'
  id: totrans-1985
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`SpeechT5ForTextToSpeech`](#module_models.SpeechT5ForTextToSpeech)的实例方法'
- en: '**Returns**: `Promise.<SpeechOutput>` - A promise which resolves to an object
    containing the spectrogram, waveform, and cross-attention tensors.'
  id: totrans-1986
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<SpeechOutput>` - 一个包含频谱图、波形和交叉注意张量的对象的Promise。'
- en: '| Param | Type | Default | Description |'
  id: totrans-1987
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 默认值 | 描述 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-1988
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| input_values | `Tensor` |  | Indices of input sequence tokens in the vocabulary.
    |'
  id: totrans-1989
  prefs: []
  type: TYPE_TB
  zh: '| input_values | `张量` |  | 词汇表中输入序列标记的索引。 |'
- en: '| speaker_embeddings | `Tensor` |  | Tensor containing the speaker embeddings.
    |'
  id: totrans-1990
  prefs: []
  type: TYPE_TB
  zh: '| speaker_embeddings | `张量` |  | 包含说话者嵌入的张量。 |'
- en: '| options | `Object` |  | Optional parameters for generating speech. |'
  id: totrans-1991
  prefs: []
  type: TYPE_TB
  zh: '| 选项 | `对象` |  | 生成语音的可选参数。 |'
- en: '| [options.threshold] | `number` | `0.5` | The generated sequence ends when
    the predicted stop token probability exceeds this value. |'
  id: totrans-1992
  prefs: []
  type: TYPE_TB
  zh: '| [选项.threshold] | `数字` | `0.5` | 当预测的停止标记概率超过此值时，生成的序列结束。 |'
- en: '| [options.minlenratio] | `number` | `0.0` | Used to calculate the minimum
    required length for the output sequence. |'
  id: totrans-1993
  prefs: []
  type: TYPE_TB
  zh: '| [选项.minlenratio] | `数字` | `0.0` | 用于计算输出序列所需的最小长度。 |'
- en: '| [options.maxlenratio] | `number` | `20.0` | Used to calculate the maximum
    allowed length for the output sequence. |'
  id: totrans-1994
  prefs: []
  type: TYPE_TB
  zh: '| [选项.maxlenratio] | `数字` | `20.0` | 用于计算输出序列的最大允许长度。 |'
- en: '| [options.vocoder] | `Object` |  | The vocoder that converts the mel spectrogram
    into a speech waveform. If `null`, the output is the mel spectrogram. |'
  id: totrans-1995
  prefs: []
  type: TYPE_TB
  zh: '| [选项.声码器] | `对象` | 将梅尔频谱图转换为语音波形的声码器。如果为`null`，则输出为梅尔频谱图。 |'
- en: '| [options.output_cross_attentions] | `boolean` | `false` | Whether or not
    to return the attentions tensors of the decoder''s cross-attention layers. |'
  id: totrans-1996
  prefs: []
  type: TYPE_TB
  zh: '| [选项.输出交叉注意力] | `布尔` | `false` | 是否返回解码器的交叉注意力层的注意力张量。 |'
- en: '* * *'
  id: totrans-1997
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SpeechT5HifiGan
  id: totrans-1998
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.SpeechT5HifiGan
- en: HiFi-GAN vocoder.
  id: totrans-1999
  prefs: []
  type: TYPE_NORMAL
  zh: HiFi-GAN声码器。
- en: See [SpeechT5ForSpeechToText](./models#module_models.SpeechT5ForSpeechToText)
    for example usage.
  id: totrans-2000
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[SpeechT5ForSpeechToText](./models#module_models.SpeechT5ForSpeechToText)以获取示例用法。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2001
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2002
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.TrOCRPreTrainedModel
  id: totrans-2003
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.TrOCRPreTrainedModel
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2004
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2005
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new TrOCRPreTrainedModel(config, session, generation_config)
  id: totrans-2006
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的TrOCRPreTrainedModel(config, session, generation_config)
- en: Creates a new instance of the `TrOCRPreTrainedModel` class.
  id: totrans-2007
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`TrOCRPreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-2008
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2009
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration of the model. |'
  id: totrans-2010
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `对象` | 模型的配置。 |'
- en: '| session | `any` | The ONNX session containing the model weights. |'
  id: totrans-2011
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `任意` | 包含模型权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-2012
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-2013
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.TrOCRForCausalLM
  id: totrans-2014
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.TrOCRForCausalLM
- en: The TrOCR Decoder with a language modeling head.
  id: totrans-2015
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头的TrOCR解码器。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2016
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2017
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MistralPreTrainedModel
  id: totrans-2018
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.MistralPreTrainedModel
- en: The bare Mistral Model outputting raw hidden-states without any specific head
    on top.
  id: totrans-2019
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Mistral模型输出原始隐藏状态，没有特定的顶部头。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2020
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2021
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new MistralPreTrainedModel(config, session, generation_config)
  id: totrans-2022
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的MistralPreTrainedModel(config, session, generation_config)
- en: Creates a new instance of the `MistralPreTrainedModel` class.
  id: totrans-2023
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`MistralPreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-2024
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2025
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration of the model. |'
  id: totrans-2026
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `对象` | 模型的配置。 |'
- en: '| session | `any` | The ONNX session containing the model weights. |'
  id: totrans-2027
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `任意` | 包含模型权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-2028
  prefs: []
  type: TYPE_TB
  zh: '| 生成配置 | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-2029
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.FalconPreTrainedModel
  id: totrans-2030
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.FalconPreTrainedModel
- en: The bare Falcon Model outputting raw hidden-states without any specific head
    on top.
  id: totrans-2031
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Falcon模型输出原始隐藏状态，没有特定的顶部头。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2032
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2033
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new FalconPreTrainedModel(config, session, generation_config)
  id: totrans-2034
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的FalconPreTrainedModel(config, session, generation_config)
- en: Creates a new instance of the `FalconPreTrainedModel` class.
  id: totrans-2035
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`FalconPreTrainedModel`类的新实例。
- en: '| Param | Type | Description |'
  id: totrans-2036
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2037
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| config | `Object` | The configuration of the model. |'
  id: totrans-2038
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | `对象` | 模型的配置。 |'
- en: '| session | `any` | The ONNX session containing the model weights. |'
  id: totrans-2039
  prefs: []
  type: TYPE_TB
  zh: '| 会话 | `任意` | 包含模型权重的ONNX会话。 |'
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  id: totrans-2040
  prefs: []
  type: TYPE_TB
  zh: '| 生成配置 | `GenerationConfig` | 生成配置。 |'
- en: '* * *'
  id: totrans-2041
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ClapTextModelWithProjection
  id: totrans-2042
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.ClapTextModelWithProjection
- en: CLAP Text Model with a projection layer on top (a linear layer on top of the
    pooled output).
  id: totrans-2043
  prefs: []
  type: TYPE_NORMAL
  zh: CLAP文本模型，顶部带有投影层（在池化输出的顶部有一个线性层）。
- en: '**Example:** Compute text embeddings with `ClapTextModelWithProjection`.'
  id: totrans-2044
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`ClapTextModelWithProjection`计算文本嵌入。'
- en: '[PRE22]'
  id: totrans-2045
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2046
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2047
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'ClapTextModelWithProjection.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  id: totrans-2048
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ClapTextModelWithProjection.from_pretrained()：`PreTrainedModel.from_pretrained`
- en: '**Kind**: static method of [`ClapTextModelWithProjection`](#module_models.ClapTextModelWithProjection)'
  id: totrans-2049
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ClapTextModelWithProjection`](#module_models.ClapTextModelWithProjection)的静态方法'
- en: '* * *'
  id: totrans-2050
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ClapAudioModelWithProjection
  id: totrans-2051
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.ClapAudioModelWithProjection
- en: CLAP Audio Model with a projection layer on top (a linear layer on top of the
    pooled output).
  id: totrans-2052
  prefs: []
  type: TYPE_NORMAL
  zh: 带有投影层的CLAP音频模型（在池化输出的顶部有一个线性层）。
- en: '**Example:** Compute audio embeddings with `ClapAudioModelWithProjection`.'
  id: totrans-2053
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`ClapAudioModelWithProjection`计算音频嵌入。'
- en: '[PRE23]'
  id: totrans-2054
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2055
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2056
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'ClapAudioModelWithProjection.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  id: totrans-2057
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ClapAudioModelWithProjection.from_pretrained()：`PreTrainedModel.from_pretrained`
- en: '**Kind**: static method of [`ClapAudioModelWithProjection`](#module_models.ClapAudioModelWithProjection)'
  id: totrans-2058
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`ClapAudioModelWithProjection`](#module_models.ClapAudioModelWithProjection)的静态方法'
- en: '* * *'
  id: totrans-2059
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.VitsModel
  id: totrans-2060
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.VitsModel
- en: The complete VITS model, for text-to-speech synthesis.
  id: totrans-2061
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的VITS模型，用于文本到语音合成。
- en: '**Example:** Generate speech from text with `VitsModel`.'
  id: totrans-2062
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 使用`VitsModel`从文本生成语音。'
- en: '[PRE24]'
  id: totrans-2063
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2064
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2065
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: vitsModel._call(model_inputs) ⇒ <code> Promise. < VitsModelOutput > </code>
  id: totrans-2066
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: vitsModel._call(model_inputs) ⇒ `Promise.<VitsModelOutput>`
- en: Calls the model on new inputs.
  id: totrans-2067
  prefs: []
  type: TYPE_NORMAL
  zh: 在新输入上调用模型。
- en: '**Kind**: instance method of [`VitsModel`](#module_models.VitsModel)'
  id: totrans-2068
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`VitsModel`](#module_models.VitsModel)的实例方法'
- en: '**Returns**: `Promise.<VitsModelOutput>` - The outputs for the VITS model.'
  id: totrans-2069
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<VitsModelOutput>` - VITS模型的输出。'
- en: '| Param | Type | Description |'
  id: totrans-2070
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2071
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| model_inputs | `Object` | The inputs to the model. |'
  id: totrans-2072
  prefs: []
  type: TYPE_TB
  zh: '| 模型输入 | `对象` | 模型的输入。 |'
- en: '* * *'
  id: totrans-2073
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SegformerModel
  id: totrans-2074
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型.SegformerModel
- en: The bare SegFormer encoder (Mix-Transformer) outputting raw hidden-states without
    any specific head on top.
  id: totrans-2075
  prefs: []
  type: TYPE_NORMAL
  zh: 裸SegFormer编码器（Mix-Transformer）输出原始隐藏状态，没有特定的顶部头。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2076
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2077
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SegformerForImageClassification
  id: totrans-2078
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SegformerForImageClassification
- en: SegFormer Model transformer with an image classification head on top (a linear
    layer on top of the final hidden states) e.g. for ImageNet.
  id: totrans-2079
  prefs: []
  type: TYPE_NORMAL
  zh: SegFormer模型变压器，顶部带有图像分类头（最终隐藏状态顶部的线性层），例如用于ImageNet。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2080
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2081
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SegformerForSemanticSegmentation
  id: totrans-2082
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SegformerForSemanticSegmentation
- en: SegFormer Model transformer with an all-MLP decode head on top e.g. for ADE20k,
    CityScapes.
  id: totrans-2083
  prefs: []
  type: TYPE_NORMAL
  zh: SegFormer模型变压器，顶部带有全MLP解码头，例如用于ADE20k，CityScapes。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2084
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2085
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.PretrainedMixin
  id: totrans-2086
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.PretrainedMixin
- en: Base class of all AutoModels. Contains the `from_pretrained` function which
    is used to instantiate pretrained models.
  id: totrans-2087
  prefs: []
  type: TYPE_NORMAL
  zh: 所有AutoModels的基类。包含用于实例化预训练模型的`from_pretrained`函数。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2088
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '[.PretrainedMixin](#module_models.PretrainedMixin)'
  id: totrans-2089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[.PretrainedMixin](#module_models.PretrainedMixin)'
- en: '*instance*'
  id: totrans-2090
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实例*'
- en: '[`.MODEL_CLASS_MAPPINGS`](#module_models.PretrainedMixin+MODEL_CLASS_MAPPINGS)
    : `*`'
  id: totrans-2091
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.MODEL_CLASS_MAPPINGS`](#module_models.PretrainedMixin+MODEL_CLASS_MAPPINGS)：`*`'
- en: '[`.BASE_IF_FAIL`](#module_models.PretrainedMixin+BASE_IF_FAIL)'
  id: totrans-2092
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.BASE_IF_FAIL`](#module_models.PretrainedMixin+BASE_IF_FAIL)'
- en: '*static*'
  id: totrans-2093
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*静态*'
- en: '[`.from_pretrained()`](#module_models.PretrainedMixin.from_pretrained) : `PreTrainedModel.from_pretrained`'
  id: totrans-2094
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`.from_pretrained()`](#module_models.PretrainedMixin.from_pretrained)：`PreTrainedModel.from_pretrained`'
- en: '* * *'
  id: totrans-2095
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'pretrainedMixin.MODEL_CLASS_MAPPINGS : <code> * </code>'
  id: totrans-2096
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pretrainedMixin.MODEL_CLASS_MAPPINGS：`*`
- en: Mapping from model type to model class.
  id: totrans-2097
  prefs: []
  type: TYPE_NORMAL
  zh: 从模型类型到模型类的映射。
- en: '**Kind**: instance property of [`PretrainedMixin`](#module_models.PretrainedMixin)'
  id: totrans-2098
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`PretrainedMixin`](#module_models.PretrainedMixin)的实例属性'
- en: '* * *'
  id: totrans-2099
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: pretrainedMixin.BASE_IF_FAIL
  id: totrans-2100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pretrainedMixin.BASE_IF_FAIL
- en: Whether to attempt to instantiate the base class (`PretrainedModel`) if the
    model type is not found in the mapping.
  id: totrans-2101
  prefs: []
  type: TYPE_NORMAL
  zh: 是否尝试实例化基类（`PretrainedModel`）如果在映射中找不到模型类型。
- en: '**Kind**: instance property of [`PretrainedMixin`](#module_models.PretrainedMixin)'
  id: totrans-2102
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`PretrainedMixin`](#module_models.PretrainedMixin)的实例属性'
- en: '* * *'
  id: totrans-2103
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'PretrainedMixin.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  id: totrans-2104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PretrainedMixin.from_pretrained()：`PreTrainedModel.from_pretrained`
- en: '**Kind**: static method of [`PretrainedMixin`](#module_models.PretrainedMixin)'
  id: totrans-2105
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`PretrainedMixin`](#module_models.PretrainedMixin)的静态方法'
- en: '* * *'
  id: totrans-2106
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModel
  id: totrans-2107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModel
- en: Helper class which is used to instantiate pretrained models with the `from_pretrained`
    function. The chosen model class is determined by the type specified in the model
    config.
  id: totrans-2108
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练模型的辅助类。所选的模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2109
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2110
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'autoModel.MODEL_CLASS_MAPPINGS : <code> * </code>'
  id: totrans-2111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: autoModel.MODEL_CLASS_MAPPINGS：`*`
- en: '**Kind**: instance property of [`AutoModel`](#module_models.AutoModel)'
  id: totrans-2112
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`AutoModel`](#module_models.AutoModel)的实例属性'
- en: '* * *'
  id: totrans-2113
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForSequenceClassification
  id: totrans-2114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForSequenceClassification
- en: Helper class which is used to instantiate pretrained sequence classification
    models with the `from_pretrained` function. The chosen model class is determined
    by the type specified in the model config.
  id: totrans-2115
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练序列分类模型的辅助类。所选的模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2116
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2117
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForTokenClassification
  id: totrans-2118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForTokenClassification
- en: Helper class which is used to instantiate pretrained token classification models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2119
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练标记分类模型的辅助类。所选的模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2120
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2121
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForSeq2SeqLM
  id: totrans-2122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForSeq2SeqLM
- en: Helper class which is used to instantiate pretrained sequence-to-sequence models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2123
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练序列到序列模型的辅助类。所选的模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2124
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2125
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForSpeechSeq2Seq
  id: totrans-2126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForSpeechSeq2Seq
- en: Helper class which is used to instantiate pretrained sequence-to-sequence speech-to-text
    models with the `from_pretrained` function. The chosen model class is determined
    by the type specified in the model config.
  id: totrans-2127
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练序列到序列语音到文本模型的辅助类。所选的模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2128
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2129
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForTextToSpectrogram
  id: totrans-2130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForTextToSpectrogram
- en: Helper class which is used to instantiate pretrained sequence-to-sequence text-to-spectrogram
    models with the `from_pretrained` function. The chosen model class is determined
    by the type specified in the model config.
  id: totrans-2131
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练序列到序列文本到频谱图模型的辅助类。所选的模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2132
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2133
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForTextToWaveform
  id: totrans-2134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForTextToWaveform
- en: Helper class which is used to instantiate pretrained text-to-waveform models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2135
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练文本到波形模型的辅助类。所选的模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2136
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2137
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForCausalLM
  id: totrans-2138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForCausalLM
- en: Helper class which is used to instantiate pretrained causal language models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2139
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练因果语言模型的辅助类。所选的模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2140
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2141
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForMaskedLM
  id: totrans-2142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForMaskedLM
- en: Helper class which is used to instantiate pretrained masked language models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2143
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练掩蔽语言模型的辅助类。所选模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2144
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2145
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForQuestionAnswering
  id: totrans-2146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForQuestionAnswering
- en: Helper class which is used to instantiate pretrained question answering models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2147
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练问答模型的辅助类。所选模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2148
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2149
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForVision2Seq
  id: totrans-2150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForVision2Seq
- en: Helper class which is used to instantiate pretrained vision-to-sequence models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2151
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练视觉到序列模型的辅助类。所选模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2152
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2153
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForImageClassification
  id: totrans-2154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForImageClassification
- en: Helper class which is used to instantiate pretrained image classification models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2155
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练图像分类模型的辅助类。所选模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2156
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2157
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForImageSegmentation
  id: totrans-2158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForImageSegmentation
- en: Helper class which is used to instantiate pretrained image segmentation models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2159
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练图像分割模型的辅助类。所选模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2160
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2161
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForSemanticSegmentation
  id: totrans-2162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForSemanticSegmentation
- en: Helper class which is used to instantiate pretrained image segmentation models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2163
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练图像分割模型的辅助类。所选模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2164
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2165
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForObjectDetection
  id: totrans-2166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForObjectDetection
- en: Helper class which is used to instantiate pretrained object detection models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2167
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练目标检测模型的辅助类。所选模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2168
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2169
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.AutoModelForMaskGeneration
  id: totrans-2170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.AutoModelForMaskGeneration
- en: Helper class which is used to instantiate pretrained mask generation models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  id: totrans-2171
  prefs: []
  type: TYPE_NORMAL
  zh: 用于使用`from_pretrained`函数实例化预训练掩蔽生成模型的辅助类。所选模型类由模型配置中指定的类型确定。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2172
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2173
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.Seq2SeqLMOutput
  id: totrans-2174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.Seq2SeqLMOutput
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2175
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2176
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new Seq2SeqLMOutput(output)
  id: totrans-2177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的Seq2SeqLMOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-2178
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2179
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-2180
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.logits | `Tensor` | The output logits of the model. |'
  id: totrans-2181
  prefs: []
  type: TYPE_TB
  zh: '| output.logits | `Tensor` | 模型的输出logits。 |'
- en: '| output.past_key_values | `Tensor` | An tensor of key/value pairs that represent
    the previous state of the model. |'
  id: totrans-2182
  prefs: []
  type: TYPE_TB
  zh: '| output.past_key_values | `Tensor` | 代表模型先前状态的键/值对张量。 |'
- en: '| output.encoder_outputs | `Tensor` | The output of the encoder in a sequence-to-sequence
    model. |'
  id: totrans-2183
  prefs: []
  type: TYPE_TB
  zh: '| output.encoder_outputs | `Tensor` | 序列到序列模型中编码器的输出。 |'
- en: '| [output.decoder_attentions] | `Tensor` | Attentions weights of the decoder,
    after the attention softmax, used to compute the weighted average in the self-attention
    heads. |'
  id: totrans-2184
  prefs: []
  type: TYPE_TB
  zh: '| [output.decoder_attentions] | `Tensor` | 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均。
    |'
- en: '| [output.cross_attentions] | `Tensor` | Attentions weights of the decoder''s
    cross-attention layer, after the attention softmax, used to compute the weighted
    average in the cross-attention heads. |'
  id: totrans-2185
  prefs: []
  type: TYPE_TB
  zh: '| [output.cross_attentions] | `Tensor` | 解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均。
    |'
- en: '* * *'
  id: totrans-2186
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.SequenceClassifierOutput
  id: totrans-2187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.SequenceClassifierOutput
- en: Base class for outputs of sentence classification models.
  id: totrans-2188
  prefs: []
  type: TYPE_NORMAL
  zh: 用于句子分类模型输出的基类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2189
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2190
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new SequenceClassifierOutput(output)
  id: totrans-2191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的SequenceClassifierOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-2192
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2193
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-2194
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.logits | `Tensor` | classification (or regression if config.num_labels==1)
    scores (before SoftMax). |'
  id: totrans-2195
  prefs: []
  type: TYPE_TB
  zh: '| output.logits | `Tensor` | 分类（如果config.num_labels==1则为回归）得分（SoftMax之前）。 |'
- en: '* * *'
  id: totrans-2196
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.TokenClassifierOutput
  id: totrans-2197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.TokenClassifierOutput
- en: Base class for outputs of token classification models.
  id: totrans-2198
  prefs: []
  type: TYPE_NORMAL
  zh: 用于标记分类模型输出的基类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2199
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2200
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new TokenClassifierOutput(output)
  id: totrans-2201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新的TokenClassifierOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-2202
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2203
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-2204
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.logits | `Tensor` | Classification scores (before SoftMax). |'
  id: totrans-2205
  prefs: []
  type: TYPE_TB
  zh: '| output.logits | `Tensor` | 分类得分（SoftMax之前）。 |'
- en: '* * *'
  id: totrans-2206
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.MaskedLMOutput
  id: totrans-2207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.MaskedLMOutput
- en: Base class for masked language models outputs.
  id: totrans-2208
  prefs: []
  type: TYPE_NORMAL
  zh: 用于掩蔽语言模型输出的基类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2209
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2210
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new MaskedLMOutput(output)
  id: totrans-2211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new MaskedLMOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-2212
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2213
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-2214
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.logits | `Tensor` | Prediction scores of the language modeling head
    (scores for each vocabulary token before SoftMax). |'
  id: totrans-2215
  prefs: []
  type: TYPE_TB
  zh: '| output.logits | `Tensor` | 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。 |'
- en: '* * *'
  id: totrans-2216
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.QuestionAnsweringModelOutput
  id: totrans-2217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.QuestionAnsweringModelOutput
- en: Base class for outputs of question answering models.
  id: totrans-2218
  prefs: []
  type: TYPE_NORMAL
  zh: 用于问答模型输出的基类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2219
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2220
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new QuestionAnsweringModelOutput(output)
  id: totrans-2221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new QuestionAnsweringModelOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-2222
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2223
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-2224
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.start_logits | `Tensor` | Span-start scores (before SoftMax). |'
  id: totrans-2225
  prefs: []
  type: TYPE_TB
  zh: '| output.start_logits | `Tensor` | 跨度开始分数（SoftMax之前）。 |'
- en: '| output.end_logits | `Tensor` | Span-end scores (before SoftMax). |'
  id: totrans-2226
  prefs: []
  type: TYPE_TB
  zh: '| output.end_logits | `Tensor` | 跨度结束分数（SoftMax之前）。 |'
- en: '* * *'
  id: totrans-2227
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CausalLMOutput
  id: totrans-2228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CausalLMOutput
- en: Base class for causal language model (or autoregressive) outputs.
  id: totrans-2229
  prefs: []
  type: TYPE_NORMAL
  zh: 用于因果语言模型（或自回归）输出的基类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2230
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2231
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new CausalLMOutput(output)
  id: totrans-2232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new CausalLMOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-2233
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2234
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-2235
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.logits | `Tensor` | Prediction scores of the language modeling head
    (scores for each vocabulary token before softmax). |'
  id: totrans-2236
  prefs: []
  type: TYPE_TB
  zh: '| output.logits | `Tensor` | 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。 |'
- en: '* * *'
  id: totrans-2237
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.CausalLMOutputWithPast
  id: totrans-2238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.CausalLMOutputWithPast
- en: Base class for causal language model (or autoregressive) outputs.
  id: totrans-2239
  prefs: []
  type: TYPE_NORMAL
  zh: 用于因果语言模型（或自回归）输出的基类。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2240
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2241
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new CausalLMOutputWithPast(output)
  id: totrans-2242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new CausalLMOutputWithPast(output)
- en: '| Param | Type | Description |'
  id: totrans-2243
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2244
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-2245
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.logits | `Tensor` | Prediction scores of the language modeling head
    (scores for each vocabulary token before softmax). |'
  id: totrans-2246
  prefs: []
  type: TYPE_TB
  zh: '| output.logits | `Tensor` | 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。 |'
- en: '| output.past_key_values | `Tensor` | Contains pre-computed hidden-states (key
    and values in the self-attention blocks) that can be used (see `past_key_values`
    input) to speed up sequential decoding. |'
  id: totrans-2247
  prefs: []
  type: TYPE_TB
  zh: '| output.past_key_values | `Tensor` | 包含预先计算的隐藏状态（自注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
    |'
- en: '* * *'
  id: totrans-2248
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.ImageMattingOutput
  id: totrans-2249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.ImageMattingOutput
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2250
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2251
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new ImageMattingOutput(output)
  id: totrans-2252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new ImageMattingOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-2253
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2254
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-2255
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.alphas | `Tensor` | Estimated alpha values, of shape `(batch_size,
    num_channels, height, width)`. |'
  id: totrans-2256
  prefs: []
  type: TYPE_TB
  zh: '| output.alphas | `Tensor` | 估计的alpha值，形状为`(batch_size, num_channels, height,
    width)`。 |'
- en: '* * *'
  id: totrans-2257
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models.VitsModelOutput
  id: totrans-2258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models.VitsModelOutput
- en: Describes the outputs for the VITS model.
  id: totrans-2259
  prefs: []
  type: TYPE_NORMAL
  zh: 描述VITS模型的输出。
- en: '**Kind**: static class of [`models`](#module_models)'
  id: totrans-2260
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的静态类'
- en: '* * *'
  id: totrans-2261
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: new VitsModelOutput(output)
  id: totrans-2262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new VitsModelOutput(output)
- en: '| Param | Type | Description |'
  id: totrans-2263
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2264
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| output | `Object` | The output of the model. |'
  id: totrans-2265
  prefs: []
  type: TYPE_TB
  zh: '| output | `Object` | 模型的输出。 |'
- en: '| output.waveform | `Tensor` | The final audio waveform predicted by the model,
    of shape `(batch_size, sequence_length)`. |'
  id: totrans-2266
  prefs: []
  type: TYPE_TB
  zh: '| output.waveform | `Tensor` | 模型预测的最终音频波形，形状为`(batch_size, sequence_length)`。
    |'
- en: '| output.spectrogram | `Tensor` | The log-mel spectrogram predicted at the
    output of the flow model. This spectrogram is passed to the Hi-Fi GAN decoder
    model to obtain the final audio waveform. |'
  id: totrans-2267
  prefs: []
  type: TYPE_TB
  zh: '| output.spectrogram | `Tensor` | 在流模型输出处预测的对数梅尔频谱图。将此频谱图传递给Hi-Fi GAN解码器模型以获得最终音频波形。
    |'
- en: '* * *'
  id: totrans-2268
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'models~InferenceSession : <code> * </code>'
  id: totrans-2269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models~InferenceSession： <code> * </code>
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  id: totrans-2270
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的内部类型定义'
- en: '* * *'
  id: totrans-2271
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'models~TypedArray : <code> * </code>'
  id: totrans-2272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models~TypedArray： <code> * </code>
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  id: totrans-2273
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的内部类型定义'
- en: '* * *'
  id: totrans-2274
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: models~DecoderOutput ⇒ <code> Promise. < (Array < Array < number > > |EncoderDecoderOutput|DecoderOutput)
    > </code>
  id: totrans-2275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models~DecoderOutput ⇒ <code> Promise. < (Array < Array < number > > |EncoderDecoderOutput|DecoderOutput)
    > </code>
- en: Generates text based on the given inputs and generation configuration using
    the model.
  id: totrans-2276
  prefs: []
  type: TYPE_NORMAL
  zh: 根据给定的输入和生成配置使用模型生成文本。
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  id: totrans-2277
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的内部类型定义'
- en: '**Returns**: `Promise.<(Array<Array<number>>|EncoderDecoderOutput|DecoderOutput)>`
    - An array of generated output sequences, where each sequence is an array of token
    IDs.'
  id: totrans-2278
  prefs: []
  type: TYPE_NORMAL
  zh: '**返回**：`Promise.<(Array<Array<number>>|EncoderDecoderOutput|DecoderOutput)>`
    - 生成的输出序列的数组，其中每个序列都是一个标记ID数组。'
- en: '**Throws**:'
  id: totrans-2279
  prefs: []
  type: TYPE_NORMAL
  zh: '**抛出**：'
- en: '`Error` Throws an error if the inputs array is empty.'
  id: totrans-2280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Error` 如果输入数组为空，则抛出错误。'
- en: '| Param | Type | Default | Description |'
  id: totrans-2281
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 默认值 | 描述 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-2282
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| inputs | `Tensor` &#124; `Array` &#124; `TypedArray` |  | An array of input
    token IDs. |'
  id: totrans-2283
  prefs: []
  type: TYPE_TB
  zh: '| 输入 | `Tensor` &#124; `Array` &#124; `TypedArray` |  | 输入标记ID的数组。 |'
- en: '| generation_config | `Object` &#124; `GenerationConfig` &#124; `null` |  |
    The generation configuration to use. If null, default configuration will be used.
    |'
  id: totrans-2284
  prefs: []
  type: TYPE_TB
  zh: '| generation_config | `Object` &#124; `GenerationConfig` &#124; `null` |  |
    要使用的生成配置。如果为null，将使用默认配置。 |'
- en: '| logits_processor | `Object` &#124; `null` |  | An optional logits processor
    to use. If null, a new LogitsProcessorList instance will be created. |'
  id: totrans-2285
  prefs: []
  type: TYPE_TB
  zh: '| logits_processor | `Object` &#124; `null` |  | 要使用的可选logits处理器。如果为null，将创建一个新的LogitsProcessorList实例。
    |'
- en: '| options | `Object` |  | options |'
  id: totrans-2286
  prefs: []
  type: TYPE_TB
  zh: '| 选项 | `Object` |  | 选项 |'
- en: '| [options.inputs_attention_mask] | `Object` |  | An optional attention mask
    for the inputs. |'
  id: totrans-2287
  prefs: []
  type: TYPE_TB
  zh: '| [options.inputs_attention_mask] | `对象` |  | 输入的可选注意力掩码。 |'
- en: '* * *'
  id: totrans-2288
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'models~WhisperGenerationConfig : <code> Object </code>'
  id: totrans-2289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models~WhisperGenerationConfig： <code>对象</code>
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  id: totrans-2290
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的内部类型定义'
- en: '**Extends**: `GenerationConfig`'
  id: totrans-2291
  prefs: []
  type: TYPE_NORMAL
  zh: '**扩展**：`GenerationConfig`'
- en: '**Properties**'
  id: totrans-2292
  prefs: []
  type: TYPE_NORMAL
  zh: '**属性**'
- en: '| Name | Type | Default | Description |'
  id: totrans-2293
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 类型 | 默认值 | 描述 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-2294
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| [return_timestamps] | `boolean` |  | Whether to return the timestamps with
    the text. This enables the `WhisperTimestampsLogitsProcessor`. |'
  id: totrans-2295
  prefs: []
  type: TYPE_TB
  zh: '| [return_timestamps] | `boolean` |  | 是否返回时间戳与文本。这使得`WhisperTimestampsLogitsProcessor`生效。
    |'
- en: '| [return_token_timestamps] | `boolean` |  | Whether to return token-level
    timestamps with the text. This can be used with or without the `return_timestamps`
    option. To get word-level timestamps, use the tokenizer to group the tokens into
    words. |'
  id: totrans-2296
  prefs: []
  type: TYPE_TB
  zh: '| [return_token_timestamps] | `boolean` |  | 是否返回标记级时间戳与文本。这可以与`return_timestamps`选项一起使用。要获得单词级时间戳，请使用分词器将标记分组成单词。
    |'
- en: '| [num_frames] | `number` |  | The number of audio frames available in this
    chunk. This is only used generating word-level timestamps. |'
  id: totrans-2297
  prefs: []
  type: TYPE_TB
  zh: '| [num_frames] | `number` |  | 此块中可用的音频帧数。这仅用于生成单词级时间戳。 |'
- en: '* * *'
  id: totrans-2298
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'models~SamModelInputs : <code> Object </code>'
  id: totrans-2299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models~SamModelInputs： <code>对象</code>
- en: Object containing the model inputs.
  id: totrans-2300
  prefs: []
  type: TYPE_NORMAL
  zh: 包含模型输入的对象。
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  id: totrans-2301
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的内部类型定义'
- en: '**Properties**'
  id: totrans-2302
  prefs: []
  type: TYPE_NORMAL
  zh: '**属性**'
- en: '| Name | Type | Description |'
  id: totrans-2303
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2304
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| pixel_values | `Tensor` | Pixel values as a Tensor with shape `(batch_size,
    num_channels, height, width)`. These can be obtained using a `SamProcessor`. |'
  id: totrans-2305
  prefs: []
  type: TYPE_TB
  zh: '| pixel_values | `Tensor` | 像素值作为形状为`(batch_size, num_channels, height, width)`的张量。这些可以使用`SamProcessor`获得。
    |'
- en: '| input_points | `Tensor` | Input 2D spatial points with shape `(batch_size,
    num_points, 2)`. This is used by the prompt encoder to encode the prompt. |'
  id: totrans-2306
  prefs: []
  type: TYPE_TB
  zh: '| input_points | `Tensor` | 具有形状`(batch_size, num_points, 2)`的输入2D空间点。这由提示编码器用于编码提示。
    |'
- en: '| [input_labels] | `Tensor` | Input labels for the points, as a Tensor of shape
    `(batch_size, point_batch_size, num_points)`. This is used by the prompt encoder
    to encode the prompt. There are 4 types of labels:'
  id: totrans-2307
  prefs: []
  type: TYPE_NORMAL
  zh: '| [input_labels] | `Tensor` | 点的输入标签，作为形状为`(batch_size, point_batch_size, num_points)`的张量。这由提示编码器用于编码提示。有4种类型的标签：'
- en: '`1`: the point is a point that contains the object of interest'
  id: totrans-2308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1`：该点是包含感兴趣对象的点'
- en: '`0`: the point is a point that does not contain the object of interest'
  id: totrans-2309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0`：该点是不包含感兴趣对象的点'
- en: '`-1`: the point corresponds to the background'
  id: totrans-2310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-1`：该点对应于背景'
- en: '`-10`: the point is a padding point, thus should be ignored by the prompt encoder'
  id: totrans-2311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-10`：该点是填充点，因此应该被提示编码器忽略'
- en: '|'
  id: totrans-2312
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [image_embeddings] | `Tensor` | Image embeddings used by the mask decoder.
    |'
  id: totrans-2313
  prefs: []
  type: TYPE_TB
  zh: '| [image_embeddings] | `Tensor` | 被掩码解码器使用的图像嵌入。 |'
- en: '| [image_positional_embeddings] | `Tensor` | Image positional embeddings used
    by the mask decoder. |'
  id: totrans-2314
  prefs: []
  type: TYPE_TB
  zh: '| [image_positional_embeddings] | `Tensor` | 被掩码解码器使用的图像位置嵌入。 |'
- en: '* * *'
  id: totrans-2315
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'models~SpeechOutput : <code> Object </code>'
  id: totrans-2316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: models~SpeechOutput： <code>对象</code>
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  id: totrans-2317
  prefs: []
  type: TYPE_NORMAL
  zh: '**种类**：[`models`](#module_models)的内部类型定义'
- en: '**Properties**'
  id: totrans-2318
  prefs: []
  type: TYPE_NORMAL
  zh: '**属性**'
- en: '| Name | Type | Description |'
  id: totrans-2319
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-2320
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| [spectrogram] | `Tensor` | The predicted log-mel spectrogram of shape `(output_sequence_length,
    config.num_mel_bins)`. Returned when no `vocoder` is provided |'
  id: totrans-2321
  prefs: []
  type: TYPE_TB
  zh: '| [spectrogram] | `Tensor` | 形状为`(output_sequence_length, config.num_mel_bins)`的预测对数梅尔频谱图。在没有提供`vocoder`时返回
    |'
- en: '| [waveform] | `Tensor` | The predicted waveform of shape `(num_frames,)`.
    Returned when a `vocoder` is provided. |'
  id: totrans-2322
  prefs: []
  type: TYPE_TB
  zh: '| [waveform] | `Tensor` | 形状为`(num_frames,)`的预测波形。在提供`vocoder`时返回。 |'
- en: '| [cross_attentions] | `Tensor` | The outputs of the decoder''s cross-attention
    layers of shape `(config.decoder_layers, config.decoder_attention_heads, output_sequence_length,
    input_sequence_length)`. returned when `output_cross_attentions` is `true`. |'
  id: totrans-2323
  prefs: []
  type: TYPE_TB
  zh: '| [cross_attentions] | `Tensor` | 形状为`(config.decoder_layers, config.decoder_attention_heads,
    output_sequence_length, input_sequence_length)`的解码器交叉注意力层的输出。当`output_cross_attentions`为`true`时返回。
    |'
- en: '* * *'
  id: totrans-2324
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
