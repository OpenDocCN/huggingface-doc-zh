- en: models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/transformers.js/api/models](https://huggingface.co/docs/transformers.js/api/models)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Definitions of all models available in Transformers.js.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Load and run an `AutoModel`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We also provide other `AutoModel`s (listed below), which you can use in the
    same way as the Python library. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Load and run an `AutoModelForSeq2SeqLM`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[models](#module_models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*static*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.PreTrainedModel](#module_models.PreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new PreTrainedModel(config, session)`](#new_module_models.PreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*instance*'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.dispose()`](#module_models.PreTrainedModel+dispose) ⇒ `Promise.<Array<unknown>>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.PreTrainedModel+_call) ⇒ `Promise.<Object>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.forward(model_inputs)`](#module_models.PreTrainedModel+forward) ⇒ `Promise.<Object>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._get_generation_config(generation_config)`](#module_models.PreTrainedModel+_get_generation_config)
    ⇒ `*`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.groupBeams(beams)`](#module_models.PreTrainedModel+groupBeams) ⇒ `Array`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.getPastKeyValues(decoderResults, pastKeyValues)`](#module_models.PreTrainedModel+getPastKeyValues)
    ⇒ `Object`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.getAttentions(decoderResults)`](#module_models.PreTrainedModel+getAttentions)
    ⇒ `Object`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.addPastKeyValues(decoderFeeds, pastKeyValues)`](#module_models.PreTrainedModel+addPastKeyValues)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*static*'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained(pretrained_model_name_or_path, options)`](#module_models.PreTrainedModel.from_pretrained)
    ⇒ `Promise.<PreTrainedModel>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BaseModelOutput](#module_models.BaseModelOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new BaseModelOutput(output)`](#new_module_models.BaseModelOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BertForMaskedLM](#module_models.BertForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.BertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BertForSequenceClassification](#module_models.BertForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.BertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BertForTokenClassification](#module_models.BertForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.BertForTokenClassification+_call) ⇒
    `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BertForQuestionAnswering](#module_models.BertForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.BertForQuestionAnswering+_call) ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.RoFormerModel](#module_models.RoFormerModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.RoFormerForMaskedLM](#module_models.RoFormerForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.RoFormerForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.RoFormerForSequenceClassification](#module_models.RoFormerForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.RoFormerForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.RoFormerForTokenClassification](#module_models.RoFormerForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.RoFormerForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.RoFormerForQuestionAnswering](#module_models.RoFormerForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.RoFormerForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ConvBertModel](#module_models.ConvBertModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ConvBertForMaskedLM](#module_models.ConvBertForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ConvBertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ConvBertForSequenceClassification](#module_models.ConvBertForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ConvBertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ConvBertForTokenClassification](#module_models.ConvBertForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ConvBertForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ConvBertForQuestionAnswering](#module_models.ConvBertForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ConvBertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ElectraModel](#module_models.ElectraModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ElectraForMaskedLM](#module_models.ElectraForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ElectraForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ElectraForSequenceClassification](#module_models.ElectraForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ElectraForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ElectraForTokenClassification](#module_models.ElectraForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ElectraForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ElectraForQuestionAnswering](#module_models.ElectraForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ElectraForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CamembertModel](#module_models.CamembertModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CamembertForMaskedLM](#module_models.CamembertForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.CamembertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CamembertForSequenceClassification](#module_models.CamembertForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.CamembertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CamembertForTokenClassification](#module_models.CamembertForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.CamembertForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CamembertForQuestionAnswering](#module_models.CamembertForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.CamembertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaModel](#module_models.DebertaModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaForMaskedLM](#module_models.DebertaForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DebertaForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaForSequenceClassification](#module_models.DebertaForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DebertaForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaForTokenClassification](#module_models.DebertaForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DebertaForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaForQuestionAnswering](#module_models.DebertaForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DebertaForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaV2Model](#module_models.DebertaV2Model)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaV2ForMaskedLM](#module_models.DebertaV2ForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DebertaV2ForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaV2ForSequenceClassification](#module_models.DebertaV2ForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DebertaV2ForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaV2ForTokenClassification](#module_models.DebertaV2ForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DebertaV2ForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DebertaV2ForQuestionAnswering](#module_models.DebertaV2ForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DebertaV2ForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DistilBertForSequenceClassification](#module_models.DistilBertForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DistilBertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DistilBertForTokenClassification](#module_models.DistilBertForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DistilBertForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DistilBertForQuestionAnswering](#module_models.DistilBertForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DistilBertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DistilBertForMaskedLM](#module_models.DistilBertForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.DistilBertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.EsmModel](#module_models.EsmModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.EsmForMaskedLM](#module_models.EsmForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.EsmForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.EsmForSequenceClassification](#module_models.EsmForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.EsmForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.EsmForTokenClassification](#module_models.EsmForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.EsmForTokenClassification+_call) ⇒
    `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MobileBertForMaskedLM](#module_models.MobileBertForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.MobileBertForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MobileBertForSequenceClassification](#module_models.MobileBertForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.MobileBertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MobileBertForQuestionAnswering](#module_models.MobileBertForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.MobileBertForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MPNetModel](#module_models.MPNetModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MPNetForMaskedLM](#module_models.MPNetForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.MPNetForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MPNetForSequenceClassification](#module_models.MPNetForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.MPNetForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MPNetForTokenClassification](#module_models.MPNetForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.MPNetForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MPNetForQuestionAnswering](#module_models.MPNetForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.MPNetForQuestionAnswering+_call) ⇒
    `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.T5ForConditionalGeneration](#module_models.T5ForConditionalGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new T5ForConditionalGeneration(config, session, decoder_merged_session, generation_config)`](#new_module_models.T5ForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.LongT5PreTrainedModel](#module_models.LongT5PreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.LongT5Model](#module_models.LongT5Model)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.LongT5ForConditionalGeneration](#module_models.LongT5ForConditionalGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new LongT5ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.LongT5ForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MT5ForConditionalGeneration](#module_models.MT5ForConditionalGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new MT5ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.MT5ForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BartModel](#module_models.BartModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BartForConditionalGeneration](#module_models.BartForConditionalGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new BartForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.BartForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BartForSequenceClassification](#module_models.BartForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.BartForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MBartModel](#module_models.MBartModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MBartForConditionalGeneration](#module_models.MBartForConditionalGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new MBartForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.MBartForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MBartForSequenceClassification](#module_models.MBartForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.MBartForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MBartForCausalLM](#module_models.MBartForCausalLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new MBartForCausalLM(config, decoder_merged_session, generation_config)`](#new_module_models.MBartForCausalLM_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BlenderbotModel](#module_models.BlenderbotModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BlenderbotForConditionalGeneration](#module_models.BlenderbotForConditionalGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new BlenderbotForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.BlenderbotForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BlenderbotSmallModel](#module_models.BlenderbotSmallModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BlenderbotSmallForConditionalGeneration](#module_models.BlenderbotSmallForConditionalGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new BlenderbotSmallForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.BlenderbotSmallForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.RobertaForMaskedLM](#module_models.RobertaForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.RobertaForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.RobertaForSequenceClassification](#module_models.RobertaForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.RobertaForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.RobertaForTokenClassification](#module_models.RobertaForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.RobertaForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.RobertaForQuestionAnswering](#module_models.RobertaForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.RobertaForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMPreTrainedModel](#module_models.XLMPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMModel](#module_models.XLMModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMWithLMHeadModel](#module_models.XLMWithLMHeadModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.XLMWithLMHeadModel+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMForSequenceClassification](#module_models.XLMForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.XLMForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMForTokenClassification](#module_models.XLMForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.XLMForTokenClassification+_call) ⇒
    `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMForQuestionAnswering](#module_models.XLMForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.XLMForQuestionAnswering+_call) ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMRobertaForMaskedLM](#module_models.XLMRobertaForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.XLMRobertaForMaskedLM+_call) ⇒ `Promise.<MaskedLMOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMRobertaForSequenceClassification](#module_models.XLMRobertaForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.XLMRobertaForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMRobertaForTokenClassification](#module_models.XLMRobertaForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.XLMRobertaForTokenClassification+_call)
    ⇒ `Promise.<TokenClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.XLMRobertaForQuestionAnswering](#module_models.XLMRobertaForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.XLMRobertaForQuestionAnswering+_call)
    ⇒ `Promise.<QuestionAnsweringModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ASTModel](#module_models.ASTModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ASTForAudioClassification](#module_models.ASTForAudioClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.WhisperModel](#module_models.WhisperModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.WhisperForConditionalGeneration](#module_models.WhisperForConditionalGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new WhisperForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.WhisperForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.generate(inputs, generation_config, logits_processor)`](#module_models.WhisperForConditionalGeneration+generate)
    ⇒ `Promise.<Object>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._extract_token_timestamps(generate_outputs, alignment_heads, [num_frames],
    [time_precision])`](#module_models.WhisperForConditionalGeneration+_extract_token_timestamps)
    ⇒ `Tensor`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.VisionEncoderDecoderModel](#module_models.VisionEncoderDecoderModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new VisionEncoderDecoderModel(config, session, decoder_merged_session, generation_config)`](#new_module_models.VisionEncoderDecoderModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CLIPModel](#module_models.CLIPModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CLIPTextModelWithProjection](#module_models.CLIPTextModelWithProjection)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained()`](#module_models.CLIPTextModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CLIPVisionModelWithProjection](#module_models.CLIPVisionModelWithProjection)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained()`](#module_models.CLIPVisionModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SiglipModel](#module_models.SiglipModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SiglipTextModel](#module_models.SiglipTextModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained()`](#module_models.SiglipTextModel.from_pretrained) : `PreTrainedModel.from_pretrained`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SiglipVisionModel](#module_models.SiglipVisionModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained()`](#module_models.SiglipVisionModel.from_pretrained) :
    `PreTrainedModel.from_pretrained`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CLIPSegForImageSegmentation](#module_models.CLIPSegForImageSegmentation)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.GPT2PreTrainedModel](#module_models.GPT2PreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new GPT2PreTrainedModel(config, session, generation_config)`](#new_module_models.GPT2PreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.GPT2LMHeadModel](#module_models.GPT2LMHeadModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.GPTNeoPreTrainedModel](#module_models.GPTNeoPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new GPTNeoPreTrainedModel(config, session, generation_config)`](#new_module_models.GPTNeoPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.GPTNeoXPreTrainedModel](#module_models.GPTNeoXPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new GPTNeoXPreTrainedModel(config, session, generation_config)`](#new_module_models.GPTNeoXPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.GPTJPreTrainedModel](#module_models.GPTJPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new GPTJPreTrainedModel(config, session, generation_config)`](#new_module_models.GPTJPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.GPTBigCodePreTrainedModel](#module_models.GPTBigCodePreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new GPTBigCodePreTrainedModel(config, session, generation_config)`](#new_module_models.GPTBigCodePreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CodeGenPreTrainedModel](#module_models.CodeGenPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new CodeGenPreTrainedModel(config, session, generation_config)`](#new_module_models.CodeGenPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CodeGenModel](#module_models.CodeGenModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CodeGenForCausalLM](#module_models.CodeGenForCausalLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.LlamaPreTrainedModel](#module_models.LlamaPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new LlamaPreTrainedModel(config, session, generation_config)`](#new_module_models.LlamaPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.LlamaModel](#module_models.LlamaModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Qwen2PreTrainedModel](#module_models.Qwen2PreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new Qwen2PreTrainedModel(config, session, generation_config)`](#new_module_models.Qwen2PreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Qwen2Model](#module_models.Qwen2Model)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.PhiPreTrainedModel](#module_models.PhiPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new PhiPreTrainedModel(config, session, generation_config)`](#new_module_models.PhiPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.PhiModel](#module_models.PhiModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BloomPreTrainedModel](#module_models.BloomPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new BloomPreTrainedModel(config, session, generation_config)`](#new_module_models.BloomPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BloomModel](#module_models.BloomModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.BloomForCausalLM](#module_models.BloomForCausalLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MptPreTrainedModel](#module_models.MptPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new MptPreTrainedModel(config, session, generation_config)`](#new_module_models.MptPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MptModel](#module_models.MptModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MptForCausalLM](#module_models.MptForCausalLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.OPTPreTrainedModel](#module_models.OPTPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new OPTPreTrainedModel(config, session, generation_config)`](#new_module_models.OPTPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.OPTModel](#module_models.OPTModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.OPTForCausalLM](#module_models.OPTForCausalLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.VitMatteForImageMatting](#module_models.VitMatteForImageMatting)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.VitMatteForImageMatting+_call)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DetrObjectDetectionOutput](#module_models.DetrObjectDetectionOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new DetrObjectDetectionOutput(output)`](#new_module_models.DetrObjectDetectionOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DetrSegmentationOutput](#module_models.DetrSegmentationOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new DetrSegmentationOutput(output)`](#new_module_models.DetrSegmentationOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.TableTransformerModel](#module_models.TableTransformerModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.TableTransformerForObjectDetection](#module_models.TableTransformerForObjectDetection)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.TableTransformerForObjectDetection+_call)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ResNetPreTrainedModel](#module_models.ResNetPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ResNetModel](#module_models.ResNetModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ResNetForImageClassification](#module_models.ResNetForImageClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ResNetForImageClassification+_call)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Swin2SRModel](#module_models.Swin2SRModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Swin2SRForImageSuperResolution](#module_models.Swin2SRForImageSuperResolution)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DPTModel](#module_models.DPTModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DPTForDepthEstimation](#module_models.DPTForDepthEstimation)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DepthAnythingForDepthEstimation](#module_models.DepthAnythingForDepthEstimation)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.GLPNModel](#module_models.GLPNModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.GLPNForDepthEstimation](#module_models.GLPNForDepthEstimation)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.DonutSwinModel](#module_models.DonutSwinModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ConvNextModel](#module_models.ConvNextModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ConvNextForImageClassification](#module_models.ConvNextForImageClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ConvNextForImageClassification+_call)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ConvNextV2Model](#module_models.ConvNextV2Model)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ConvNextV2ForImageClassification](#module_models.ConvNextV2ForImageClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.ConvNextV2ForImageClassification+_call)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Dinov2Model](#module_models.Dinov2Model)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Dinov2ForImageClassification](#module_models.Dinov2ForImageClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.Dinov2ForImageClassification+_call)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.YolosObjectDetectionOutput](#module_models.YolosObjectDetectionOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new YolosObjectDetectionOutput(output)`](#new_module_models.YolosObjectDetectionOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SamModel](#module_models.SamModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new SamModel(config, vision_encoder, prompt_encoder_mask_decoder)`](#new_module_models.SamModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.get_image_embeddings(model_inputs)`](#module_models.SamModel+get_image_embeddings)
    ⇒ `Promise.<{image_embeddings: Tensor, image_positional_embeddings: Tensor}>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.forward(model_inputs)`](#module_models.SamModel+forward) ⇒ `Promise.<Object>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.SamModel+_call) ⇒ `Promise.<SamImageSegmentationOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SamImageSegmentationOutput](#module_models.SamImageSegmentationOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new SamImageSegmentationOutput(output)`](#new_module_models.SamImageSegmentationOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MarianMTModel](#module_models.MarianMTModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new MarianMTModel(config, session, decoder_merged_session, generation_config)`](#new_module_models.MarianMTModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.M2M100ForConditionalGeneration](#module_models.M2M100ForConditionalGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new M2M100ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.M2M100ForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Wav2Vec2Model](#module_models.Wav2Vec2Model)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Wav2Vec2BertModel](#module_models.Wav2Vec2BertModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Wav2Vec2BertForCTC](#module_models.Wav2Vec2BertForCTC)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.Wav2Vec2BertForCTC+_call)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Wav2Vec2BertForSequenceClassification](#module_models.Wav2Vec2BertForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.Wav2Vec2BertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.HubertModel](#module_models.HubertModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.HubertForCTC](#module_models.HubertForCTC)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.HubertForCTC+_call)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.HubertForSequenceClassification](#module_models.HubertForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.HubertForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.WavLMPreTrainedModel](#module_models.WavLMPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.WavLMModel](#module_models.WavLMModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.WavLMForCTC](#module_models.WavLMForCTC)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.WavLMForCTC+_call)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.WavLMForSequenceClassification](#module_models.WavLMForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.WavLMForSequenceClassification+_call)
    ⇒ `Promise.<SequenceClassifierOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SpeechT5PreTrainedModel](#module_models.SpeechT5PreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SpeechT5Model](#module_models.SpeechT5Model)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SpeechT5ForSpeechToText](#module_models.SpeechT5ForSpeechToText)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SpeechT5ForTextToSpeech](#module_models.SpeechT5ForTextToSpeech)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new SpeechT5ForTextToSpeech(config, session, decoder_merged_session, generation_config)`](#new_module_models.SpeechT5ForTextToSpeech_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.generate_speech(input_values, speaker_embeddings, options)`](#module_models.SpeechT5ForTextToSpeech+generate_speech)
    ⇒ `Promise.<SpeechOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SpeechT5HifiGan](#module_models.SpeechT5HifiGan)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.TrOCRPreTrainedModel](#module_models.TrOCRPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new TrOCRPreTrainedModel(config, session, generation_config)`](#new_module_models.TrOCRPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.TrOCRForCausalLM](#module_models.TrOCRForCausalLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MistralPreTrainedModel](#module_models.MistralPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new MistralPreTrainedModel(config, session, generation_config)`](#new_module_models.MistralPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.FalconPreTrainedModel](#module_models.FalconPreTrainedModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new FalconPreTrainedModel(config, session, generation_config)`](#new_module_models.FalconPreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ClapTextModelWithProjection](#module_models.ClapTextModelWithProjection)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained()`](#module_models.ClapTextModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ClapAudioModelWithProjection](#module_models.ClapAudioModelWithProjection)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained()`](#module_models.ClapAudioModelWithProjection.from_pretrained)
    : `PreTrainedModel.from_pretrained`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.VitsModel](#module_models.VitsModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.VitsModel+_call) ⇒ `Promise.<VitsModelOutput>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SegformerModel](#module_models.SegformerModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SegformerForImageClassification](#module_models.SegformerForImageClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SegformerForSemanticSegmentation](#module_models.SegformerForSemanticSegmentation)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.PretrainedMixin](#module_models.PretrainedMixin)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*instance*'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.MODEL_CLASS_MAPPINGS`](#module_models.PretrainedMixin+MODEL_CLASS_MAPPINGS)
    : `*`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.BASE_IF_FAIL`](#module_models.PretrainedMixin+BASE_IF_FAIL)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*static*'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained()`](#module_models.PretrainedMixin.from_pretrained) : `PreTrainedModel.from_pretrained`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModel](#module_models.AutoModel)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.MODEL_CLASS_MAPPINGS`](#module_models.AutoModel+MODEL_CLASS_MAPPINGS) :
    `*`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForSequenceClassification](#module_models.AutoModelForSequenceClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForTokenClassification](#module_models.AutoModelForTokenClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForSeq2SeqLM](#module_models.AutoModelForSeq2SeqLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForSpeechSeq2Seq](#module_models.AutoModelForSpeechSeq2Seq)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForTextToSpectrogram](#module_models.AutoModelForTextToSpectrogram)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForTextToWaveform](#module_models.AutoModelForTextToWaveform)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForCausalLM](#module_models.AutoModelForCausalLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForMaskedLM](#module_models.AutoModelForMaskedLM)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForQuestionAnswering](#module_models.AutoModelForQuestionAnswering)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForVision2Seq](#module_models.AutoModelForVision2Seq)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForImageClassification](#module_models.AutoModelForImageClassification)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForImageSegmentation](#module_models.AutoModelForImageSegmentation)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForSemanticSegmentation](#module_models.AutoModelForSemanticSegmentation)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForObjectDetection](#module_models.AutoModelForObjectDetection)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.AutoModelForMaskGeneration](#module_models.AutoModelForMaskGeneration)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.Seq2SeqLMOutput](#module_models.Seq2SeqLMOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new Seq2SeqLMOutput(output)`](#new_module_models.Seq2SeqLMOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.SequenceClassifierOutput](#module_models.SequenceClassifierOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new SequenceClassifierOutput(output)`](#new_module_models.SequenceClassifierOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.TokenClassifierOutput](#module_models.TokenClassifierOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new TokenClassifierOutput(output)`](#new_module_models.TokenClassifierOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.MaskedLMOutput](#module_models.MaskedLMOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new MaskedLMOutput(output)`](#new_module_models.MaskedLMOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.QuestionAnsweringModelOutput](#module_models.QuestionAnsweringModelOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new QuestionAnsweringModelOutput(output)`](#new_module_models.QuestionAnsweringModelOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CausalLMOutput](#module_models.CausalLMOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new CausalLMOutput(output)`](#new_module_models.CausalLMOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.CausalLMOutputWithPast](#module_models.CausalLMOutputWithPast)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new CausalLMOutputWithPast(output)`](#new_module_models.CausalLMOutputWithPast_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.ImageMattingOutput](#module_models.ImageMattingOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new ImageMattingOutput(output)`](#new_module_models.ImageMattingOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[.VitsModelOutput](#module_models.VitsModelOutput)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new VitsModelOutput(output)`](#new_module_models.VitsModelOutput_new)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*inner*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`~InferenceSession`](#module_models..InferenceSession) : `*`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`~TypedArray`](#module_models..TypedArray) : `*`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`~DecoderOutput`](#module_models..DecoderOutput) ⇒ `Promise.<(Array<Array<number>>|EncoderDecoderOutput|DecoderOutput)>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`~WhisperGenerationConfig`](#module_models..WhisperGenerationConfig) : `Object`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`~SamModelInputs`](#module_models..SamModelInputs) : `Object`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`~SpeechOutput`](#module_models..SpeechOutput) : `Object`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.PreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A base class for pre-trained models that provides the model configuration and
    an ONNX session.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '[.PreTrainedModel](#module_models.PreTrainedModel)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new PreTrainedModel(config, session)`](#new_module_models.PreTrainedModel_new)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*instance*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.dispose()`](#module_models.PreTrainedModel+dispose) ⇒ `Promise.<Array<unknown>>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.PreTrainedModel+_call) ⇒ `Promise.<Object>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.forward(model_inputs)`](#module_models.PreTrainedModel+forward) ⇒ `Promise.<Object>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._get_generation_config(generation_config)`](#module_models.PreTrainedModel+_get_generation_config)
    ⇒ `*`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.groupBeams(beams)`](#module_models.PreTrainedModel+groupBeams) ⇒ `Array`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.getPastKeyValues(decoderResults, pastKeyValues)`](#module_models.PreTrainedModel+getPastKeyValues)
    ⇒ `Object`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.getAttentions(decoderResults)`](#module_models.PreTrainedModel+getAttentions)
    ⇒ `Object`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.addPastKeyValues(decoderFeeds, pastKeyValues)`](#module_models.PreTrainedModel+addPastKeyValues)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*static*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained(pretrained_model_name_or_path, options)`](#module_models.PreTrainedModel.from_pretrained)
    ⇒ `Promise.<PreTrainedModel>`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new PreTrainedModel(config, session)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `PreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | session for the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: preTrainedModel.dispose() ⇒ <code> Promise. < Array < unknown > > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Disposes of all the ONNX sessions that were created during inference.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<Array<unknown>>` - An array of promises, one for each
    ONNX session that is being disposed.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Todo**'
  prefs: []
  type: TYPE_NORMAL
- en: Use [https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: preTrainedModel._call(model_inputs) ⇒ <code> Promise. < Object > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Runs the model with the provided inputs
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<Object>` - Object containing output tensors'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | Object containing input tensors |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: preTrainedModel.forward(model_inputs) ⇒ <code> Promise. < Object > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Forward method for a pretrained model. If not overridden by a subclass, the
    correct forward method will be chosen based on the model type.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<Object>` - The output data from the model in the format
    specified in the ONNX model.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Throws**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Error` This method must be implemented in subclasses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The input data to the model in the format specified
    in the ONNX model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: preTrainedModel._get_generation_config(generation_config) ⇒ <code> * </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This function merges multiple generation configs together to form a final generation
    config to be used by the model for text generation. It first creates an empty
    `GenerationConfig` object, then it applies the model’s own `generation_config`
    property to it. Finally, if a `generation_config` object was passed in the arguments,
    it overwrites the corresponding properties in the final config with those of the
    passed config object.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `*` - The final generation config object to be used by the model
    for text generation.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `*` | A `GenerationConfig` object containing generation
    parameters. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: preTrainedModel.groupBeams(beams) ⇒ <code> Array </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Groups an array of beam objects by their ids.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Array` - An array of arrays, where each inner array contains
    beam objects with the same id.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| beams | `Array` | The array of beam objects to group. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: preTrainedModel.getPastKeyValues(decoderResults, pastKeyValues) ⇒ <code> Object
    </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Returns an object containing past key values from the given decoder results
    object.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Object` - An object containing past key values.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| decoderResults | `Object` | The decoder results object. |'
  prefs: []
  type: TYPE_TB
- en: '| pastKeyValues | `Object` | The previous past key values. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: preTrainedModel.getAttentions(decoderResults) ⇒ <code> Object </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Returns an object containing attentions from the given decoder results object.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Object` - An object containing attentions.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| decoderResults | `Object` | The decoder results object. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: preTrainedModel.addPastKeyValues(decoderFeeds, pastKeyValues)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Adds past key values to the decoder feeds object. If pastKeyValues is null,
    creates new tensors for past key values.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| decoderFeeds | `Object` | The decoder feeds object to add past key values
    to. |'
  prefs: []
  type: TYPE_TB
- en: '| pastKeyValues | `Object` | An object containing past key values. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: PreTrainedModel.from_pretrained(pretrained_model_name_or_path, options) ⇒ <code>
    Promise. < PreTrainedModel > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Instantiate one of the model classes of the library from a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: The model class to instantiate is selected based on the `model_type` property
    of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path`
    if possible)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static method of [`PreTrainedModel`](#module_models.PreTrainedModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<PreTrainedModel>` - A new instance of the `PreTrainedModel`
    class.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| pretrained_model_name_or_path | `string` | The name or path of the pretrained
    model. Can be either:'
  prefs: []
  type: TYPE_NORMAL
- en: A string, the *model id* of a pretrained model hosted inside a model repo on
    huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`,
    or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a *directory* containing model weights, e.g., `./my_model_directory/`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| options | `*` | Additional options for loading the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BaseModelOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base class for model’s outputs, with potential hidden states and attentions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new BaseModelOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.last_hidden_state | `Tensor` | Sequence of hidden-states at the output
    of the last layer of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| [output.hidden_states] | `Tensor` | Hidden-states of the model at the output
    of each layer plus the optional initial embedding outputs. |'
  prefs: []
  type: TYPE_TB
- en: '| [output.attentions] | `Tensor` | Attentions weights after the attention softmax,
    used to compute the weighted average in the self-attention heads. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BertForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BertForMaskedLM is a class representing a BERT model for masked language modeling.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: bertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`BertForMaskedLM`](#module_models.BertForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BertForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BertForSequenceClassification is a class representing a BERT model for sequence
    classification.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: bertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`BertForSequenceClassification`](#module_models.BertForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BertForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BertForTokenClassification is a class representing a BERT model for token classification.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: bertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`BertForTokenClassification`](#module_models.BertForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BertForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BertForQuestionAnswering is a class representing a BERT model for question answering.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: bertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`BertForQuestionAnswering`](#module_models.BertForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.RoFormerModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare RoFormer Model transformer outputting raw hidden-states without any
    specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.RoFormerForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RoFormer Model with a `language modeling` head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: roFormerForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`RoFormerForMaskedLM`](#module_models.RoFormerForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.RoFormerForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RoFormer Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: roFormerForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`RoFormerForSequenceClassification`](#module_models.RoFormerForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.RoFormerForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RoFormer Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: roFormerForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`RoFormerForTokenClassification`](#module_models.RoFormerForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.RoFormerForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RoFormer Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: roFormerForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`RoFormerForQuestionAnswering`](#module_models.RoFormerForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ConvBertModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare ConvBERT Model transformer outputting raw hidden-states without any
    specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ConvBertForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ConvBERT Model with a language modeling head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: convBertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ConvBertForMaskedLM`](#module_models.ConvBertForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ConvBertForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ConvBERT Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: convBertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ConvBertForSequenceClassification`](#module_models.ConvBertForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ConvBertForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ConvBERT Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: convBertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ConvBertForTokenClassification`](#module_models.ConvBertForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ConvBertForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ConvBERT Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: convBertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ConvBertForQuestionAnswering`](#module_models.ConvBertForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ElectraModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Electra Model transformer outputting raw hidden-states without any
    specific head on top. Identical to the BERT model except that it uses an additional
    linear layer between the embedding layer and the encoder if the hidden size and
    embedding size are different.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ElectraForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Electra model with a language modeling head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: electraForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ElectraForMaskedLM`](#module_models.ElectraForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ElectraForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ELECTRA Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: electraForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ElectraForSequenceClassification`](#module_models.ElectraForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ElectraForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Electra model with a token classification head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: electraForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ElectraForTokenClassification`](#module_models.ElectraForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ElectraForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LECTRA Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: electraForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ElectraForQuestionAnswering`](#module_models.ElectraForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CamembertModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare CamemBERT Model transformer outputting raw hidden-states without any
    specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CamembertForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CamemBERT Model with a `language modeling` head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: camembertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`CamembertForMaskedLM`](#module_models.CamembertForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CamembertForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CamemBERT Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output) e.g. for GLUE tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: camembertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`CamembertForSequenceClassification`](#module_models.CamembertForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CamembertForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CamemBERT Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: camembertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`CamembertForTokenClassification`](#module_models.CamembertForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CamembertForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CamemBERT Model with a span classification head on top for extractive question-answering
    tasks
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: camembertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`CamembertForQuestionAnswering`](#module_models.CamembertForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare DeBERTa Model transformer outputting raw hidden-states without any
    specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DeBERTa Model with a `language modeling` head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: debertaForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DebertaForMaskedLM`](#module_models.DebertaForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DeBERTa Model transformer with a sequence classification/regression head on
    top (a linear layer on top of the pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: debertaForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DebertaForSequenceClassification`](#module_models.DebertaForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DeBERTa Model with a token classification head on top (a linear layer on top
    of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: debertaForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DebertaForTokenClassification`](#module_models.DebertaForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DeBERTa Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: debertaForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DebertaForQuestionAnswering`](#module_models.DebertaForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaV2Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare DeBERTa-V2 Model transformer outputting raw hidden-states without any
    specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaV2ForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DeBERTa-V2 Model with a `language modeling` head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: debertaV2ForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DebertaV2ForMaskedLM`](#module_models.DebertaV2ForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaV2ForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DeBERTa-V2 Model transformer with a sequence classification/regression head
    on top (a linear layer on top of the pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: debertaV2ForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DebertaV2ForSequenceClassification`](#module_models.DebertaV2ForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaV2ForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DeBERTa-V2 Model with a token classification head on top (a linear layer on
    top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: debertaV2ForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DebertaV2ForTokenClassification`](#module_models.DebertaV2ForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DebertaV2ForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DeBERTa-V2 Model with a span classification head on top for extractive question-answering
    tasks like SQuAD (a linear layers on top of the hidden-states output to compute
    `span start logits` and `span end logits`).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: debertaV2ForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DebertaV2ForQuestionAnswering`](#module_models.DebertaV2ForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DistilBertForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DistilBertForSequenceClassification is a class representing a DistilBERT model
    for sequence classification.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: distilBertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. <
    SequenceClassifierOutput > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DistilBertForSequenceClassification`](#module_models.DistilBertForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DistilBertForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DistilBertForTokenClassification is a class representing a DistilBERT model
    for token classification.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: distilBertForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DistilBertForTokenClassification`](#module_models.DistilBertForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DistilBertForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DistilBertForQuestionAnswering is a class representing a DistilBERT model for
    question answering.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: distilBertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DistilBertForQuestionAnswering`](#module_models.DistilBertForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DistilBertForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DistilBertForMaskedLM is a class representing a DistilBERT model for masking
    task.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: distilBertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`DistilBertForMaskedLM`](#module_models.DistilBertForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.EsmModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare ESM Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.EsmForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ESM Model with a `language modeling` head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: esmForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`EsmForMaskedLM`](#module_models.EsmForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.EsmForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ESM Model transformer with a sequence classification/regression head on top
    (a linear layer on top of the pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: esmForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`EsmForSequenceClassification`](#module_models.EsmForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.EsmForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ESM Model with a token classification head on top (a linear layer on top of
    the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: esmForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`EsmForTokenClassification`](#module_models.EsmForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MobileBertForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MobileBertForMaskedLM is a class representing a MobileBERT model for masking
    task.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: mobileBertForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`MobileBertForMaskedLM`](#module_models.MobileBertForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MobileBertForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MobileBert Model transformer with a sequence classification/regression head
    on top (a linear layer on top of the pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: mobileBertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. <
    SequenceClassifierOutput > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`MobileBertForSequenceClassification`](#module_models.MobileBertForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MobileBertForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MobileBert Model with a span classification head on top for extractive question-answering
    tasks
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: mobileBertForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`MobileBertForQuestionAnswering`](#module_models.MobileBertForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MPNetModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare MPNet Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MPNetForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MPNetForMaskedLM is a class representing a MPNet model for masked language modeling.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: mpNetForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`MPNetForMaskedLM`](#module_models.MPNetForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - An object containing the model’s
    output logits for masked language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MPNetForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MPNetForSequenceClassification is a class representing a MPNet model for sequence
    classification.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: mpNetForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`MPNetForSequenceClassification`](#module_models.MPNetForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MPNetForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MPNetForTokenClassification is a class representing a MPNet model for token
    classification.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: mpNetForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`MPNetForTokenClassification`](#module_models.MPNetForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MPNetForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MPNetForQuestionAnswering is a class representing a MPNet model for question
    answering.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: mpNetForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`MPNetForQuestionAnswering`](#module_models.MPNetForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - An object containing
    the model’s output logits for question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.T5ForConditionalGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: T5Model is a class representing a T5 model for conditional generation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new T5ForConditionalGeneration(config, session, decoder_merged_session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `T5ForConditionalGeneration` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | session for the model. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `any` | session for the decoder. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.LongT5PreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.LongT5Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare LONGT5 Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.LongT5ForConditionalGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LONGT5 Model with a `language modeling` head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new LongT5ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `LongT5ForConditionalGeneration` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | session for the model. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `any` | session for the decoder. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MT5ForConditionalGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A class representing a conditional sequence-to-sequence model based on the MT5
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new MT5ForConditionalGeneration(config, session, decoder_merged_session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `MT5ForConditionalGeneration` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `any` | The model configuration. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the encoder weights. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `any` | The ONNX session containing the merged decoder
    weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BartModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare BART Model outputting raw hidden-states without any specific head on
    top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BartForConditionalGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The BART Model with a language modeling head. Can be used for summarization.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new BartForConditionalGeneration(config, session, decoder_merged_session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `BartForConditionalGeneration` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration object for the Bart model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session used to execute the model. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `Object` | The ONNX session used to execute the
    decoder. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `Object` | The generation configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BartForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bart model with a sequence classification/head on top (a linear layer on top
    of the pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: bartForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`BartForSequenceClassification`](#module_models.BartForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MBartModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare MBART Model outputting raw hidden-states without any specific head
    on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MBartForConditionalGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The MBART Model with a language modeling head. Can be used for summarization,
    after fine-tuning the pretrained models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new MBartForConditionalGeneration(config, session, decoder_merged_session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `MBartForConditionalGeneration` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration object for the Bart model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session used to execute the model. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `Object` | The ONNX session used to execute the
    decoder. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `Object` | The generation configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MBartForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MBart model with a sequence classification/head on top (a linear layer on top
    of the pooled output).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: mBartForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`MBartForSequenceClassification`](#module_models.MBartForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MBartForCausalLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new MBartForCausalLM(config, decoder_merged_session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `MBartForCausalLM` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | Configuration object for the model. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `Object` | ONNX Session object for the decoder.
    |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `Object` | Configuration object for the generation process.
    |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BlenderbotModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Blenderbot Model outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BlenderbotForConditionalGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Blenderbot Model with a language modeling head. Can be used for summarization.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new BlenderbotForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `BlenderbotForConditionalGeneration` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `any` | The model configuration. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the encoder weights. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `any` | The ONNX session containing the merged decoder
    weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BlenderbotSmallModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare BlenderbotSmall Model outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BlenderbotSmallForConditionalGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The BlenderbotSmall Model with a language modeling head. Can be used for summarization.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new BlenderbotSmallForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `BlenderbotForConditionalGeneration` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `any` | The model configuration. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the encoder weights. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `any` | The ONNX session containing the merged decoder
    weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.RobertaForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RobertaForMaskedLM class for performing masked language modeling on Roberta
    models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: robertaForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`RobertaForMaskedLM`](#module_models.RobertaForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.RobertaForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RobertaForSequenceClassification class for performing sequence classification
    on Roberta models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: robertaForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`RobertaForSequenceClassification`](#module_models.RobertaForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.RobertaForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RobertaForTokenClassification class for performing token classification on Roberta
    models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: robertaForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`RobertaForTokenClassification`](#module_models.RobertaForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.RobertaForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RobertaForQuestionAnswering class for performing question answering on Roberta
    models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: robertaForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`RobertaForQuestionAnswering`](#module_models.RobertaForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare XLM Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMWithLMHeadModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The XLM Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: xlmWithLMHeadModel._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput >
    </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`XLMWithLMHeadModel`](#module_models.XLMWithLMHeadModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: XLM Model with a sequence classification/regression head on top (a linear layer
    on top of the pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: xlmForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`XLMForSequenceClassification`](#module_models.XLMForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: XLM Model with a token classification head on top (a linear layer on top of
    the hidden-states output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: xlmForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`XLMForTokenClassification`](#module_models.XLMForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: XLM Model with a span classification head on top for extractive question-answering
    tasks
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: xlmForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`XLMForQuestionAnswering`](#module_models.XLMForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMRobertaForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: XLMRobertaForMaskedLM class for performing masked language modeling on XLMRoberta
    models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: xlmRobertaForMaskedLM._call(model_inputs) ⇒ <code> Promise. < MaskedLMOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`XLMRobertaForMaskedLM`](#module_models.XLMRobertaForMaskedLM)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<MaskedLMOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMRobertaForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: XLMRobertaForSequenceClassification class for performing sequence classification
    on XLMRoberta models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: xlmRobertaForSequenceClassification._call(model_inputs) ⇒ <code> Promise. <
    SequenceClassifierOutput > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`XLMRobertaForSequenceClassification`](#module_models.XLMRobertaForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMRobertaForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: XLMRobertaForTokenClassification class for performing token classification on
    XLMRoberta models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: xlmRobertaForTokenClassification._call(model_inputs) ⇒ <code> Promise. < TokenClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`XLMRobertaForTokenClassification`](#module_models.XLMRobertaForTokenClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<TokenClassifierOutput>` - An object containing the model’s
    output logits for token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.XLMRobertaForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: XLMRobertaForQuestionAnswering class for performing question answering on XLMRoberta
    models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: xlmRobertaForQuestionAnswering._call(model_inputs) ⇒ <code> Promise. < QuestionAnsweringModelOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`XLMRobertaForQuestionAnswering`](#module_models.XLMRobertaForQuestionAnswering)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<QuestionAnsweringModelOutput>` - returned object'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ASTModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare AST Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ASTForAudioClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Audio Spectrogram Transformer model with an audio classification head on top
    (a linear layer on top of the pooled output) e.g. for datasets like AudioSet,
    Speech Commands v2.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.WhisperModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: WhisperModel class for training Whisper models without a language model head.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.WhisperForConditionalGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: WhisperForConditionalGeneration class for generating conditional outputs from
    Whisper models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '[.WhisperForConditionalGeneration](#module_models.WhisperForConditionalGeneration)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new WhisperForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)`](#new_module_models.WhisperForConditionalGeneration_new)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.generate(inputs, generation_config, logits_processor)`](#module_models.WhisperForConditionalGeneration+generate)
    ⇒ `Promise.<Object>`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._extract_token_timestamps(generate_outputs, alignment_heads, [num_frames],
    [time_precision])`](#module_models.WhisperForConditionalGeneration+_extract_token_timestamps)
    ⇒ `Tensor`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new WhisperForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `WhisperForConditionalGeneration` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | Configuration object for the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | ONNX Session object for the model. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `Object` | ONNX Session object for the decoder.
    |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `Object` | Configuration object for the generation process.
    |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: whisperForConditionalGeneration.generate(inputs, generation_config, logits_processor)
    ⇒ <code> Promise. < Object > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generates outputs based on input and generation configuration.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`WhisperForConditionalGeneration`](#module_models.WhisperForConditionalGeneration)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<Object>` - Promise object represents the generated outputs.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Default | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| inputs | `Object` |  | Input data for the model. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `WhisperGenerationConfig` |  | Configuration object for
    the generation process. |'
  prefs: []
  type: TYPE_TB
- en: '| logits_processor | `Object` |  | Optional logits processor object. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: whisperForConditionalGeneration._extract_token_timestamps(generate_outputs,
    alignment_heads, [num_frames], [time_precision]) ⇒ <code> Tensor </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calculates token-level timestamps using the encoder-decoder cross-attentions
    and dynamic time-warping (DTW) to map each output token to a position in the input
    audio.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`WhisperForConditionalGeneration`](#module_models.WhisperForConditionalGeneration)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Tensor` - tensor containing the timestamps in seconds for each
    predicted token'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Default | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| generate_outputs | `Object` |  | Outputs generated by the model |'
  prefs: []
  type: TYPE_TB
- en: '| generate_outputs.cross_attentions | `Array.<Array<Array<Tensor>>>` |  | The
    cross attentions output by the model |'
  prefs: []
  type: TYPE_TB
- en: '| generate_outputs.decoder_attentions | `Array.<Array<Array<Tensor>>>` |  |
    The decoder attentions output by the model |'
  prefs: []
  type: TYPE_TB
- en: '| generate_outputs.sequences | `Array.<Array<number>>` |  | The sequences output
    by the model |'
  prefs: []
  type: TYPE_TB
- en: '| alignment_heads | `Array.<Array<number>>` |  | Alignment heads of the model
    |'
  prefs: []
  type: TYPE_TB
- en: '| [num_frames] | `number` |  | Number of frames in the input audio. |'
  prefs: []
  type: TYPE_TB
- en: '| [time_precision] | `number` | `0.02` | Precision of the timestamps in seconds
    |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.VisionEncoderDecoderModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Vision Encoder-Decoder model based on OpenAI’s GPT architecture for image captioning
    and other vision tasks
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new VisionEncoderDecoderModel(config, session, decoder_merged_session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `VisionEncoderDecoderModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration object specifying the hyperparameters
    and other model settings. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session containing the encoder model. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `any` | The ONNX session containing the merged decoder
    model. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `Object` | Configuration object for the generation process.
    |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CLIPModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CLIP Text and Vision Model with a projection layers on top
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Perform zero-shot image classification with a `CLIPModel`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CLIPTextModelWithProjection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CLIP Text Model with a projection layer on top (a linear layer on top of the
    pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Compute text embeddings with `CLIPTextModelWithProjection`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'CLIPTextModelWithProjection.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: static method of [`CLIPTextModelWithProjection`](#module_models.CLIPTextModelWithProjection)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CLIPVisionModelWithProjection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CLIP Vision Model with a projection layer on top (a linear layer on top of the
    pooled output)
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Compute vision embeddings with `CLIPVisionModelWithProjection`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'CLIPVisionModelWithProjection.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: static method of [`CLIPVisionModelWithProjection`](#module_models.CLIPVisionModelWithProjection)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SiglipModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SigLIP Text and Vision Model with a projection layers on top
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Perform zero-shot image classification with a `SiglipModel`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SiglipTextModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The text model from SigLIP without any head or projection on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Compute text embeddings with `SiglipTextModel`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'SiglipTextModel.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: static method of [`SiglipTextModel`](#module_models.SiglipTextModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SiglipVisionModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The vision model from SigLIP without any head or projection on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Compute vision embeddings with `SiglipVisionModel`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'SiglipVisionModel.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: static method of [`SiglipVisionModel`](#module_models.SiglipVisionModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CLIPSegForImageSegmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CLIPSeg model with a Transformer-based decoder on top for zero-shot and one-shot
    image segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Perform zero-shot image segmentation with a `CLIPSegForImageSegmentation`
    model.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You can visualize the predictions as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.GPT2PreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new GPT2PreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `GPT2PreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the model weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.GPT2LMHeadModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GPT-2 language model head on top of the GPT-2 base model. This model is suitable
    for text generation tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.GPTNeoPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new GPTNeoPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `GPTNeoPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the model weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.GPTNeoXPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new GPTNeoXPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `GPTNeoXPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the model weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.GPTJPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new GPTJPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `GPTJPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the model weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.GPTBigCodePreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new GPTBigCodePreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `GPTBigCodePreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the model weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CodeGenPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new CodeGenPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `CodeGenPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session object. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CodeGenModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CodeGenModel is a class representing a code generation model without a language
    model head.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CodeGenForCausalLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CodeGenForCausalLM is a class that represents a code generation model based
    on the GPT-2 architecture. It extends the `CodeGenPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.LlamaPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare LLama Model outputting raw hidden-states without any specific head
    on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new LlamaPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `LlamaPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session object. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.LlamaModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare LLaMA Model outputting raw hidden-states without any specific head
    on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Qwen2PreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Qwen2 Model outputting raw hidden-states without any specific head
    on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new Qwen2PreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `Qwen2PreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session object. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Qwen2Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Qwen2 Model outputting raw hidden-states without any specific head
    on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.PhiPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new PhiPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `PhiPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session object. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.PhiModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Phi Model outputting raw hidden-states without any specific head on
    top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BloomPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Bloom Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new BloomPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `BloomPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the model weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BloomModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Bloom Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.BloomForCausalLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Bloom Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MptPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new MptPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `MptPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session object. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MptModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Mpt Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MptForCausalLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The MPT Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.OPTPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new OPTPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `OPTPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session object. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.OPTModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare OPT Model outputting raw hidden-states without any specific head on
    top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.OPTForCausalLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The OPT Model transformer with a language modeling head on top (linear layer
    with weights tied to the input embeddings).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.VitMatteForImageMatting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ViTMatte framework leveraging any vision backbone e.g. for ADE20k, CityScapes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Perform image matting with a `VitMatteForImageMatting` model.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You can visualize the alpha matte as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: vitMatteForImageMatting._call(model_inputs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`VitMatteForImageMatting`](#module_models.VitMatteForImageMatting)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `any` |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DetrObjectDetectionOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new DetrObjectDetectionOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.logits | `Tensor` | Classification logits (including no-object) for
    all queries. |'
  prefs: []
  type: TYPE_TB
- en: '| output.pred_boxes | `Tensor` | Normalized boxes coordinates for all queries,
    represented as (center_x, center_y, width, height). These values are normalized
    in [0, 1], relative to the size of each individual image in the batch (disregarding
    possible padding). |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DetrSegmentationOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new DetrSegmentationOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.logits | `Tensor` | The output logits of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.pred_boxes | `Tensor` | Predicted boxes. |'
  prefs: []
  type: TYPE_TB
- en: '| output.pred_masks | `Tensor` | Predicted masks. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.TableTransformerModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Table Transformer Model (consisting of a backbone and encoder-decoder
    Transformer) outputting raw hidden-states without any specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.TableTransformerForObjectDetection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Table Transformer Model (consisting of a backbone and encoder-decoder Transformer)
    with object detection heads on top, for tasks such as COCO detection.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: tableTransformerForObjectDetection._call(model_inputs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`TableTransformerForObjectDetection`](#module_models.TableTransformerForObjectDetection)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `any` |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ResNetPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ResNetModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare ResNet model outputting raw features without any specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ResNetForImageClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ResNet Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: resNetForImageClassification._call(model_inputs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ResNetForImageClassification`](#module_models.ResNetForImageClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `any` |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Swin2SRModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Swin2SR Model transformer outputting raw hidden-states without any
    specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Swin2SRForImageSuperResolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Swin2SR Model transformer with an upsampler head on top for image super resolution
    and restoration.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Super-resolution w/ `Xenova/swin2SR-classical-sr-x2-64`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DPTModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare DPT Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DPTForDepthEstimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DPT Model with a depth estimation head on top (consisting of 3 convolutional
    layers) e.g. for KITTI, NYUv2.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Depth estimation w/ `Xenova/dpt-hybrid-midas`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DepthAnythingForDepthEstimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depth Anything Model with a depth estimation head on top (consisting of 3 convolutional
    layers) e.g. for KITTI, NYUv2.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.GLPNModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare GLPN encoder (Mix-Transformer) outputting raw hidden-states without
    any specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.GLPNForDepthEstimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GLPN Model transformer with a lightweight depth estimation head on top e.g.
    for KITTI, NYUv2.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Depth estimation w/ `Xenova/glpn-kitti`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.DonutSwinModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Donut Swin Model transformer outputting raw hidden-states without any
    specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Step-by-step Document Parsing.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**Example:** Step-by-step Document Visual Question Answering (DocVQA)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ConvNextModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare ConvNext model outputting raw features without any specific head on
    top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ConvNextForImageClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ConvNext Model with an image classification head on top (a linear layer on top
    of the pooled features), e.g. for ImageNet.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: convNextForImageClassification._call(model_inputs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ConvNextForImageClassification`](#module_models.ConvNextForImageClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `any` |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ConvNextV2Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare ConvNextV2 model outputting raw features without any specific head
    on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ConvNextV2ForImageClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ConvNextV2 Model with an image classification head on top (a linear layer on
    top of the pooled features), e.g. for ImageNet.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: convNextV2ForImageClassification._call(model_inputs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`ConvNextV2ForImageClassification`](#module_models.ConvNextV2ForImageClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `any` |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Dinov2Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare DINOv2 Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Dinov2ForImageClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Dinov2 Model transformer with an image classification head on top (a linear
    layer on top of the final hidden state of the [CLS] token) e.g. for ImageNet.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: dinov2ForImageClassification._call(model_inputs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`Dinov2ForImageClassification`](#module_models.Dinov2ForImageClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `any` |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.YolosObjectDetectionOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new YolosObjectDetectionOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.logits | `Tensor` | Classification logits (including no-object) for
    all queries. |'
  prefs: []
  type: TYPE_TB
- en: '| output.pred_boxes | `Tensor` | Normalized boxes coordinates for all queries,
    represented as (center_x, center_y, width, height). These values are normalized
    in [0, 1], relative to the size of each individual image in the batch (disregarding
    possible padding). |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SamModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Segment Anything Model (SAM) for generating segmentation masks, given an input
    image and optional 2D location and bounding boxes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Perform mask generation w/ `Xenova/sam-vit-base`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '[.SamModel](#module_models.SamModel)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new SamModel(config, vision_encoder, prompt_encoder_mask_decoder)`](#new_module_models.SamModel_new)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.get_image_embeddings(model_inputs)`](#module_models.SamModel+get_image_embeddings)
    ⇒ `Promise.<{image_embeddings: Tensor, image_positional_embeddings: Tensor}>`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.forward(model_inputs)`](#module_models.SamModel+forward) ⇒ `Promise.<Object>`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`._call(model_inputs)`](#module_models.SamModel+_call) ⇒ `Promise.<SamImageSegmentationOutput>`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new SamModel(config, vision_encoder, prompt_encoder_mask_decoder)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `SamModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration object specifying the hyperparameters
    and other model settings. |'
  prefs: []
  type: TYPE_TB
- en: '| vision_encoder | `Object` | The ONNX session containing the vision encoder
    model. |'
  prefs: []
  type: TYPE_TB
- en: '| prompt_encoder_mask_decoder | `any` | The ONNX session containing the prompt
    encoder and mask decoder model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'samModel.get_image_embeddings(model_inputs) ⇒ <code> Promise. < {image_embeddings:
    Tensor, image_positional_embeddings: Tensor} > </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compute image embeddings and positional image embeddings, given the pixel values
    of an image.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`SamModel`](#module_models.SamModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<{image_embeddings: Tensor, image_positional_embeddings:
    Tensor}>` - The image embeddings and positional image embeddings.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | Object containing the model inputs. |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs.pixel_values | `Tensor` | Pixel values obtained using a `SamProcessor`.
    |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: samModel.forward(model_inputs) ⇒ <code> Promise. < Object > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`SamModel`](#module_models.SamModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<Object>` - The output of the model.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `SamModelInputs` | Object containing the model inputs. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: samModel._call(model_inputs) ⇒ <code> Promise. < SamImageSegmentationOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Runs the model with the provided inputs
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`SamModel`](#module_models.SamModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SamImageSegmentationOutput>` - Object containing segmentation
    outputs'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | Model inputs |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SamImageSegmentationOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base class for Segment-Anything model’s output.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new SamImageSegmentationOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.iou_scores | `Tensor` | The output logits of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.pred_masks | `Tensor` | Predicted boxes. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MarianMTModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new MarianMTModel(config, session, decoder_merged_session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `MarianMTModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session object. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `any` |  |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `any` |  |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.M2M100ForConditionalGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new M2M100ForConditionalGeneration(config, session, decoder_merged_session,
    generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `M2M100ForConditionalGeneration` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration object. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `Object` | The ONNX session object. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `any` |  |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `any` |  |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Wav2Vec2Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Wav2Vec2 Model transformer outputting raw hidden-states without any
    specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Load and run a `Wav2Vec2Model` for feature extraction.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Wav2Vec2BertModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Wav2Vec2Bert Model transformer outputting raw hidden-states without
    any specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Wav2Vec2BertForCTC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Wav2Vec2Bert Model with a `language modeling` head on top for Connectionist
    Temporal Classification (CTC).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: wav2Vec2BertForCTC._call(model_inputs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`Wav2Vec2BertForCTC`](#module_models.Wav2Vec2BertForCTC)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` |  |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs.input_features | `Tensor` | Float values of input mel-spectrogram.
    |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs.attention_mask | `Tensor` | Mask to avoid performing convolution
    and attention on padding token indices. Mask values selected in [0, 1] |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Wav2Vec2BertForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Wav2Vec2Bert Model with a sequence classification head on top (a linear layer
    over the pooled output).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: wav2Vec2BertForSequenceClassification._call(model_inputs) ⇒ <code> Promise.
    < SequenceClassifierOutput > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`Wav2Vec2BertForSequenceClassification`](#module_models.Wav2Vec2BertForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.HubertModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Hubert Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Load and run a `HubertModel` for feature extraction.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.HubertForCTC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hubert Model with a `language modeling` head on top for Connectionist Temporal
    Classification (CTC).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: hubertForCTC._call(model_inputs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`HubertForCTC`](#module_models.HubertForCTC)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` |  |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs.input_values | `Tensor` | Float values of input raw speech waveform.
    |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs.attention_mask | `Tensor` | Mask to avoid performing convolution
    and attention on padding token indices. Mask values selected in [0, 1] |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.HubertForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hubert Model with a sequence classification head on top (a linear layer over
    the pooled output) for tasks like SUPERB Keyword Spotting.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: hubertForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`HubertForSequenceClassification`](#module_models.HubertForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.WavLMPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.WavLMModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare WavLM Model transformer outputting raw hidden-states without any specific
    head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Load and run a `WavLMModel` for feature extraction.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.WavLMForCTC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: WavLM Model with a `language modeling` head on top for Connectionist Temporal
    Classification (CTC).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: wavLMForCTC._call(model_inputs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`WavLMForCTC`](#module_models.WavLMForCTC)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` |  |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs.input_values | `Tensor` | Float values of input raw speech waveform.
    |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs.attention_mask | `Tensor` | Mask to avoid performing convolution
    and attention on padding token indices. Mask values selected in [0, 1] |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.WavLMForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: WavLM Model with a sequence classification head on top (a linear layer over
    the pooled output).
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: wavLMForSequenceClassification._call(model_inputs) ⇒ <code> Promise. < SequenceClassifierOutput
    > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`WavLMForSequenceClassification`](#module_models.WavLMForSequenceClassification)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SequenceClassifierOutput>` - An object containing the
    model’s output logits for sequence classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SpeechT5PreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An abstract class to handle weights initialization and a simple interface for
    downloading and loading pretrained models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SpeechT5Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare SpeechT5 Encoder-Decoder Model outputting raw hidden-states without
    any specific pre- or post-nets.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SpeechT5ForSpeechToText
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SpeechT5 Model with a speech encoder and a text decoder.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Generate speech from text with `SpeechT5ForSpeechToText`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SpeechT5ForTextToSpeech
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SpeechT5 Model with a text encoder and a speech decoder.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '[.SpeechT5ForTextToSpeech](#module_models.SpeechT5ForTextToSpeech)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`new SpeechT5ForTextToSpeech(config, session, decoder_merged_session, generation_config)`](#new_module_models.SpeechT5ForTextToSpeech_new)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.generate_speech(input_values, speaker_embeddings, options)`](#module_models.SpeechT5ForTextToSpeech+generate_speech)
    ⇒ `Promise.<SpeechOutput>`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new SpeechT5ForTextToSpeech(config, session, decoder_merged_session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `SpeechT5ForTextToSpeech` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The model configuration. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | session for the model. |'
  prefs: []
  type: TYPE_TB
- en: '| decoder_merged_session | `any` | session for the decoder. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: speechT5ForTextToSpeech.generate_speech(input_values, speaker_embeddings, options)
    ⇒ <code> Promise. < SpeechOutput > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Converts a sequence of input tokens into a sequence of mel spectrograms, which
    are subsequently turned into a speech waveform using a vocoder.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`SpeechT5ForTextToSpeech`](#module_models.SpeechT5ForTextToSpeech)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<SpeechOutput>` - A promise which resolves to an object
    containing the spectrogram, waveform, and cross-attention tensors.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Default | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| input_values | `Tensor` |  | Indices of input sequence tokens in the vocabulary.
    |'
  prefs: []
  type: TYPE_TB
- en: '| speaker_embeddings | `Tensor` |  | Tensor containing the speaker embeddings.
    |'
  prefs: []
  type: TYPE_TB
- en: '| options | `Object` |  | Optional parameters for generating speech. |'
  prefs: []
  type: TYPE_TB
- en: '| [options.threshold] | `number` | `0.5` | The generated sequence ends when
    the predicted stop token probability exceeds this value. |'
  prefs: []
  type: TYPE_TB
- en: '| [options.minlenratio] | `number` | `0.0` | Used to calculate the minimum
    required length for the output sequence. |'
  prefs: []
  type: TYPE_TB
- en: '| [options.maxlenratio] | `number` | `20.0` | Used to calculate the maximum
    allowed length for the output sequence. |'
  prefs: []
  type: TYPE_TB
- en: '| [options.vocoder] | `Object` |  | The vocoder that converts the mel spectrogram
    into a speech waveform. If `null`, the output is the mel spectrogram. |'
  prefs: []
  type: TYPE_TB
- en: '| [options.output_cross_attentions] | `boolean` | `false` | Whether or not
    to return the attentions tensors of the decoder''s cross-attention layers. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SpeechT5HifiGan
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: HiFi-GAN vocoder.
  prefs: []
  type: TYPE_NORMAL
- en: See [SpeechT5ForSpeechToText](./models#module_models.SpeechT5ForSpeechToText)
    for example usage.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.TrOCRPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new TrOCRPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `TrOCRPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the model weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.TrOCRForCausalLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The TrOCR Decoder with a language modeling head.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MistralPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Mistral Model outputting raw hidden-states without any specific head
    on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new MistralPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `MistralPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the model weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.FalconPreTrainedModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare Falcon Model outputting raw hidden-states without any specific head
    on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new FalconPreTrainedModel(config, session, generation_config)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creates a new instance of the `FalconPreTrainedModel` class.
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| config | `Object` | The configuration of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| session | `any` | The ONNX session containing the model weights. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `GenerationConfig` | The generation configuration. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ClapTextModelWithProjection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CLAP Text Model with a projection layer on top (a linear layer on top of the
    pooled output).
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Compute text embeddings with `ClapTextModelWithProjection`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'ClapTextModelWithProjection.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: static method of [`ClapTextModelWithProjection`](#module_models.ClapTextModelWithProjection)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ClapAudioModelWithProjection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CLAP Audio Model with a projection layer on top (a linear layer on top of the
    pooled output).
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Compute audio embeddings with `ClapAudioModelWithProjection`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'ClapAudioModelWithProjection.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: static method of [`ClapAudioModelWithProjection`](#module_models.ClapAudioModelWithProjection)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.VitsModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The complete VITS model, for text-to-speech synthesis.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example:** Generate speech from text with `VitsModel`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: vitsModel._call(model_inputs) ⇒ <code> Promise. < VitsModelOutput > </code>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calls the model on new inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance method of [`VitsModel`](#module_models.VitsModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<VitsModelOutput>` - The outputs for the VITS model.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| model_inputs | `Object` | The inputs to the model. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SegformerModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bare SegFormer encoder (Mix-Transformer) outputting raw hidden-states without
    any specific head on top.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SegformerForImageClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SegFormer Model transformer with an image classification head on top (a linear
    layer on top of the final hidden states) e.g. for ImageNet.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SegformerForSemanticSegmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SegFormer Model transformer with an all-MLP decode head on top e.g. for ADE20k,
    CityScapes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.PretrainedMixin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base class of all AutoModels. Contains the `from_pretrained` function which
    is used to instantiate pretrained models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '[.PretrainedMixin](#module_models.PretrainedMixin)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*instance*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.MODEL_CLASS_MAPPINGS`](#module_models.PretrainedMixin+MODEL_CLASS_MAPPINGS)
    : `*`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.BASE_IF_FAIL`](#module_models.PretrainedMixin+BASE_IF_FAIL)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*static*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`.from_pretrained()`](#module_models.PretrainedMixin.from_pretrained) : `PreTrainedModel.from_pretrained`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'pretrainedMixin.MODEL_CLASS_MAPPINGS : <code> * </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mapping from model type to model class.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance property of [`PretrainedMixin`](#module_models.PretrainedMixin)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: pretrainedMixin.BASE_IF_FAIL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Whether to attempt to instantiate the base class (`PretrainedModel`) if the
    model type is not found in the mapping.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: instance property of [`PretrainedMixin`](#module_models.PretrainedMixin)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'PretrainedMixin.from_pretrained() : <code> PreTrainedModel.from_pretrained
    </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: static method of [`PretrainedMixin`](#module_models.PretrainedMixin)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained models with the `from_pretrained`
    function. The chosen model class is determined by the type specified in the model
    config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'autoModel.MODEL_CLASS_MAPPINGS : <code> * </code>'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kind**: instance property of [`AutoModel`](#module_models.AutoModel)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForSequenceClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained sequence classification
    models with the `from_pretrained` function. The chosen model class is determined
    by the type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForTokenClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained token classification models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForSeq2SeqLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained sequence-to-sequence models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForSpeechSeq2Seq
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained sequence-to-sequence speech-to-text
    models with the `from_pretrained` function. The chosen model class is determined
    by the type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForTextToSpectrogram
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained sequence-to-sequence text-to-spectrogram
    models with the `from_pretrained` function. The chosen model class is determined
    by the type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForTextToWaveform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained text-to-waveform models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForCausalLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained causal language models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForMaskedLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained masked language models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForQuestionAnswering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained question answering models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForVision2Seq
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained vision-to-sequence models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForImageClassification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained image classification models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForImageSegmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained image segmentation models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForSemanticSegmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained image segmentation models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForObjectDetection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained object detection models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.AutoModelForMaskGeneration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Helper class which is used to instantiate pretrained mask generation models
    with the `from_pretrained` function. The chosen model class is determined by the
    type specified in the model config.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.Seq2SeqLMOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new Seq2SeqLMOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.logits | `Tensor` | The output logits of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.past_key_values | `Tensor` | An tensor of key/value pairs that represent
    the previous state of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.encoder_outputs | `Tensor` | The output of the encoder in a sequence-to-sequence
    model. |'
  prefs: []
  type: TYPE_TB
- en: '| [output.decoder_attentions] | `Tensor` | Attentions weights of the decoder,
    after the attention softmax, used to compute the weighted average in the self-attention
    heads. |'
  prefs: []
  type: TYPE_TB
- en: '| [output.cross_attentions] | `Tensor` | Attentions weights of the decoder''s
    cross-attention layer, after the attention softmax, used to compute the weighted
    average in the cross-attention heads. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.SequenceClassifierOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base class for outputs of sentence classification models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new SequenceClassifierOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.logits | `Tensor` | classification (or regression if config.num_labels==1)
    scores (before SoftMax). |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.TokenClassifierOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base class for outputs of token classification models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new TokenClassifierOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.logits | `Tensor` | Classification scores (before SoftMax). |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.MaskedLMOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base class for masked language models outputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new MaskedLMOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.logits | `Tensor` | Prediction scores of the language modeling head
    (scores for each vocabulary token before SoftMax). |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.QuestionAnsweringModelOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base class for outputs of question answering models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new QuestionAnsweringModelOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.start_logits | `Tensor` | Span-start scores (before SoftMax). |'
  prefs: []
  type: TYPE_TB
- en: '| output.end_logits | `Tensor` | Span-end scores (before SoftMax). |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CausalLMOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base class for causal language model (or autoregressive) outputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new CausalLMOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.logits | `Tensor` | Prediction scores of the language modeling head
    (scores for each vocabulary token before softmax). |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.CausalLMOutputWithPast
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Base class for causal language model (or autoregressive) outputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new CausalLMOutputWithPast(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.logits | `Tensor` | Prediction scores of the language modeling head
    (scores for each vocabulary token before softmax). |'
  prefs: []
  type: TYPE_TB
- en: '| output.past_key_values | `Tensor` | Contains pre-computed hidden-states (key
    and values in the self-attention blocks) that can be used (see `past_key_values`
    input) to speed up sequential decoding. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.ImageMattingOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new ImageMattingOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.alphas | `Tensor` | Estimated alpha values, of shape `(batch_size,
    num_channels, height, width)`. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models.VitsModelOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Describes the outputs for the VITS model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: static class of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: new VitsModelOutput(output)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Param | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| output | `Object` | The output of the model. |'
  prefs: []
  type: TYPE_TB
- en: '| output.waveform | `Tensor` | The final audio waveform predicted by the model,
    of shape `(batch_size, sequence_length)`. |'
  prefs: []
  type: TYPE_TB
- en: '| output.spectrogram | `Tensor` | The log-mel spectrogram predicted at the
    output of the flow model. This spectrogram is passed to the Hi-Fi GAN decoder
    model to obtain the final audio waveform. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'models~InferenceSession : <code> * </code>'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'models~TypedArray : <code> * </code>'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: models~DecoderOutput ⇒ <code> Promise. < (Array < Array < number > > |EncoderDecoderOutput|DecoderOutput)
    > </code>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generates text based on the given inputs and generation configuration using
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Returns**: `Promise.<(Array<Array<number>>|EncoderDecoderOutput|DecoderOutput)>`
    - An array of generated output sequences, where each sequence is an array of token
    IDs.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Throws**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Error` Throws an error if the inputs array is empty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Param | Type | Default | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| inputs | `Tensor` &#124; `Array` &#124; `TypedArray` |  | An array of input
    token IDs. |'
  prefs: []
  type: TYPE_TB
- en: '| generation_config | `Object` &#124; `GenerationConfig` &#124; `null` |  |
    The generation configuration to use. If null, default configuration will be used.
    |'
  prefs: []
  type: TYPE_TB
- en: '| logits_processor | `Object` &#124; `null` |  | An optional logits processor
    to use. If null, a new LogitsProcessorList instance will be created. |'
  prefs: []
  type: TYPE_TB
- en: '| options | `Object` |  | options |'
  prefs: []
  type: TYPE_TB
- en: '| [options.inputs_attention_mask] | `Object` |  | An optional attention mask
    for the inputs. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'models~WhisperGenerationConfig : <code> Object </code>'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Extends**: `GenerationConfig`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Properties**'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Type | Default | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [return_timestamps] | `boolean` |  | Whether to return the timestamps with
    the text. This enables the `WhisperTimestampsLogitsProcessor`. |'
  prefs: []
  type: TYPE_TB
- en: '| [return_token_timestamps] | `boolean` |  | Whether to return token-level
    timestamps with the text. This can be used with or without the `return_timestamps`
    option. To get word-level timestamps, use the tokenizer to group the tokens into
    words. |'
  prefs: []
  type: TYPE_TB
- en: '| [num_frames] | `number` |  | The number of audio frames available in this
    chunk. This is only used generating word-level timestamps. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'models~SamModelInputs : <code> Object </code>'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Object containing the model inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Properties**'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| pixel_values | `Tensor` | Pixel values as a Tensor with shape `(batch_size,
    num_channels, height, width)`. These can be obtained using a `SamProcessor`. |'
  prefs: []
  type: TYPE_TB
- en: '| input_points | `Tensor` | Input 2D spatial points with shape `(batch_size,
    num_points, 2)`. This is used by the prompt encoder to encode the prompt. |'
  prefs: []
  type: TYPE_TB
- en: '| [input_labels] | `Tensor` | Input labels for the points, as a Tensor of shape
    `(batch_size, point_batch_size, num_points)`. This is used by the prompt encoder
    to encode the prompt. There are 4 types of labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '`1`: the point is a point that contains the object of interest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`0`: the point is a point that does not contain the object of interest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-1`: the point corresponds to the background'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-10`: the point is a padding point, thus should be ignored by the prompt encoder'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [image_embeddings] | `Tensor` | Image embeddings used by the mask decoder.
    |'
  prefs: []
  type: TYPE_TB
- en: '| [image_positional_embeddings] | `Tensor` | Image positional embeddings used
    by the mask decoder. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'models~SpeechOutput : <code> Object </code>'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Kind**: inner typedef of [`models`](#module_models)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Properties**'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [spectrogram] | `Tensor` | The predicted log-mel spectrogram of shape `(output_sequence_length,
    config.num_mel_bins)`. Returned when no `vocoder` is provided |'
  prefs: []
  type: TYPE_TB
- en: '| [waveform] | `Tensor` | The predicted waveform of shape `(num_frames,)`.
    Returned when a `vocoder` is provided. |'
  prefs: []
  type: TYPE_TB
- en: '| [cross_attentions] | `Tensor` | The outputs of the decoder''s cross-attention
    layers of shape `(config.decoder_layers, config.decoder_attention_heads, output_sequence_length,
    input_sequence_length)`. returned when `output_cross_attentions` is `true`. |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
