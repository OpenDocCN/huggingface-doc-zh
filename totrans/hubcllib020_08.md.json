["```py\n>>> from huggingface_hub import HfApi\n>>> api = HfApi()\n>>> api.upload_file(\n...     path_or_fileobj=\"/path/to/local/folder/README.md\",\n...     path_in_repo=\"README.md\",\n...     repo_id=\"username/test-dataset\",\n...     repo_type=\"dataset\",\n... )\n```", "```py\n>>> from huggingface_hub import HfApi\n>>> api = HfApi()\n\n# Upload all the content from the local folder to your remote Space.\n# By default, files are uploaded at the root of the repo\n>>> api.upload_folder(\n...     folder_path=\"/path/to/local/space\",\n...     repo_id=\"username/my-cool-space\",\n...     repo_type=\"space\",\n... )\n```", "```py\n>>> api.upload_folder(\n...     folder_path=\"/path/to/local/folder\",\n...     path_in_repo=\"my-dataset/train\", # Upload to a specific folder\n...     repo_id=\"username/test-dataset\",\n...     repo_type=\"dataset\",\n...     ignore_patterns=\"**/logs/*.txt\", # Ignore all text logs\n... )\n```", "```py\n>>> api.upload_folder(\n...     folder_path=\"/path/to/local/folder/logs\",\n...     repo_id=\"username/trained-model\",\n...     path_in_repo=\"experiment/logs/\",\n...     allow_patterns=\"*.txt\", # Upload all local text files\n...     delete_patterns=\"*.txt\", # Delete all remote text files before\n... )\n```", "```py\n# Usage:  huggingface-cli upload [repo_id] [local_path] [path_in_repo]\n>>> huggingface-cli upload Wauplin/my-cool-model ./models/model.safetensors model.safetensors\nhttps://huggingface.co/Wauplin/my-cool-model/blob/main/model.safetensors\n\n>>> huggingface-cli upload Wauplin/my-cool-model ./models .\nhttps://huggingface.co/Wauplin/my-cool-model/tree/main\n```", "```py\n>>> from huggingface_hub import HfApi\n>>> api = HfApi()\n>>> future = api.upload_folder( # Upload in the background (non-blocking action)\n...     repo_id=\"username/my-model\",\n...     folder_path=\"checkpoints-001\",\n...     run_as_future=True,\n... )\n>>> future\nFuture(...)\n>>> future.done()\nFalse\n>>> future.result() # Wait for the upload to complete (blocking action)\n...\n```", "```py\n>>> from huggingface_hub import HfApi\n>>> api = HfApi()\n>>> api.run_as_future(api.create_repo, \"username/my-model\", exists_ok=True)\nFuture(...)\n>>> api.upload_file(\n...     repo_id=\"username/my-model\",\n...     path_in_repo=\"file.txt\",\n...     path_or_fileobj=b\"file content\",\n...     run_as_future=True,\n... )\nFuture(...)\n```", "```py\n>>> upload_folder(\n...     folder_path=\"local/checkpoints\",\n...     repo_id=\"username/my-dataset\",\n...     repo_type=\"dataset\",\n...     multi_commits=True,\n...     multi_commits_verbose=True,\n... )\n```", "```py\n>>> import json\n>>> import uuid\n>>> from pathlib import Path\n>>> import gradio as gr\n>>> from huggingface_hub import CommitScheduler\n\n# Define the file where to save the data. Use UUID to make sure not to overwrite existing data from a previous run.\n>>> feedback_file = Path(\"user_feedback/\") / f\"data_{uuid.uuid4()}.json\"\n>>> feedback_folder = feedback_file.parent\n\n# Schedule regular uploads. Remote repo and local folder are created if they don't already exist.\n>>> scheduler = CommitScheduler(\n...     repo_id=\"report-translation-feedback\",\n...     repo_type=\"dataset\",\n...     folder_path=feedback_folder,\n...     path_in_repo=\"data\",\n...     every=10,\n... )\n\n# Define the function that will be called when the user submits its feedback (to be called in Gradio)\n>>> def save_feedback(input_text:str, output_1: str, output_2:str, user_choice: int) -> None:\n...     \"\"\"\n...     Append input/outputs and user feedback to a JSON Lines file using a thread lock to avoid concurrent writes from different users.\n...     \"\"\"\n...     with scheduler.lock:\n...         with feedback_file.open(\"a\") as f:\n...             f.write(json.dumps({\"input\": input_text, \"output_1\": output_1, \"output_2\": output_2, \"user_choice\": user_choice}))\n...             f.write(\"\\n\")\n\n# Start Gradio\n>>> with gr.Blocks() as demo:\n>>>     ... # define Gradio demo + use `save_feedback`\n>>> demo.launch()\n```", "```py\nclass ZipScheduler(CommitScheduler):\n    def push_to_hub(self):\n        # 1\\. List PNG files\n          png_files = list(self.folder_path.glob(\"*.png\"))\n          if len(png_files) == 0:\n              return None  # return early if nothing to commit\n\n        # 2\\. Zip png files in a single archive\n        with tempfile.TemporaryDirectory() as tmpdir:\n            archive_path = Path(tmpdir) / \"train.zip\"\n            with zipfile.ZipFile(archive_path, \"w\", zipfile.ZIP_DEFLATED) as zip:\n                for png_file in png_files:\n                    zip.write(filename=png_file, arcname=png_file.name)\n\n            # 3\\. Upload archive\n            self.api.upload_file(..., path_or_fileobj=archive_path)\n\n        # 4\\. Delete local png files to avoid re-uploading them later\n        for png_file in png_files:\n            png_file.unlink()\n```", "```py\n>>> from huggingface_hub import HfApi, CommitOperationAdd, CommitOperationDelete\n>>> api = HfApi()\n>>> operations = [\n...     CommitOperationAdd(path_in_repo=\"LICENSE.md\", path_or_fileobj=\"~/repo/LICENSE.md\"),\n...     CommitOperationAdd(path_in_repo=\"weights.h5\", path_or_fileobj=\"~/repo/weights-final.h5\"),\n...     CommitOperationDelete(path_in_repo=\"old-weights.h5\"),\n...     CommitOperationDelete(path_in_repo=\"logs/\"),\n...     CommitOperationCopy(src_path_in_repo=\"image.png\", path_in_repo=\"duplicate_image.png\"),\n... ]\n```", "```py\n>>> api.create_commit(\n...     repo_id=\"lysandre/test-model\",\n...     operations=operations,\n...     commit_message=\"Upload my model weights and license\",\n... )\n```", "```py\n>>> from huggingface_hub import CommitOperationAdd, preupload_lfs_files, create_commit, create_repo\n\n>>> repo_id = create_repo(\"test_preupload\").repo_id\n\n>>> operations = [] # List of all `CommitOperationAdd` objects that will be generated\n>>> for i in range(5):\n...     content = ... # generate binary content\n...     addition = CommitOperationAdd(path_in_repo=f\"shard_{i}_of_5.bin\", path_or_fileobj=content)\n...     preupload_lfs_files(repo_id, additions=[addition])\n...     operations.append(addition)\n\n>>> # Create commit\n>>> create_commit(repo_id, operations=operations, commit_message=\"Commit all shards\")\n```", "```py\nhuggingface-cli lfs-enable-largefiles\n```", "```py\n>>> from huggingface_hub import Repository\n>>> with Repository(local_dir=\"text-files\", clone_from=\"<user>/text-files\").commit(commit_message=\"My first file :)\"):\n...     with open(\"file.txt\", \"w+\") as f:\n...         f.write(json.dumps({\"hey\": 8}))\n```", "```py\n>>> import torch\n>>> model = torch.nn.Transformer()\n>>> with Repository(\"torch-model\", clone_from=\"<user>/torch-model\", token=True).commit(commit_message=\"My cool model :)\"):\n...     torch.save(model.state_dict(), \"model.pt\")\n```", "```py\n>>> with repo.commit(commit_message=\"My cool model :)\", blocking=False)\n```", "```py\n>>> last_command = repo.command_queue[-1]\n>>> last_command.status\n```", "```py\n# Inspect an error.\n>>> last_command.stderr\n\n# Check whether a push is completed or ongoing.\n>>> last_command.is_done\n\n# Check whether a push command has errored.\n>>> last_command.failed\n```", "```py\n>>> from huggingface_hub import Repository\n>>> repo = Repository(local_dir=\"path/to/local/repo\")\n```", "```py\n>>> repo.git_pull()\n>>> repo.push_to_hub(commit_message=\"Commit my-awesome-file to the Hub\")\n```", "```py\n>>> repo.git_add(\"path/to/file\")\n>>> repo.git_commit(commit_message=\"add my first model config file :)\")\n```", "```py\n>>> repo.git_push()\n```"]