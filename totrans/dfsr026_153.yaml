- en: Paint by Example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://huggingface.co/docs/diffusers/api/pipelines/paint_by_example](https://huggingface.co/docs/diffusers/api/pipelines/paint_by_example)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/56.c2b7c96f.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Tip.230e2334.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Docstring.93f6f462.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/globals.7f7f1b26.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/ExampleCodeBlock.658f5cd6.js">
  prefs: []
  type: TYPE_NORMAL
- en: '[Paint by Example: Exemplar-based Image Editing with Diffusion Models](https://huggingface.co/papers/2211.13227)
    is by Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun,
    Dong Chen, Fang Wen.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Language-guided image editing has achieved great success recently. In this
    paper, for the first time, we investigate exemplar-guided image editing for more
    precise control. We achieve this goal by leveraging self-supervised training to
    disentangle and re-organize the source image and the exemplar. However, the naive
    approach will cause obvious fusing artifacts. We carefully analyze it and propose
    an information bottleneck and strong augmentations to avoid the trivial solution
    of directly copying and pasting the exemplar image. Meanwhile, to ensure the controllability
    of the editing process, we design an arbitrary shape mask for the exemplar image
    and leverage the classifier-free guidance to increase the similarity to the exemplar
    image. The whole framework involves a single forward of the diffusion model without
    any iterative optimization. We demonstrate that our method achieves an impressive
    performance and enables controllable editing on in-the-wild images with high fidelity.*'
  prefs: []
  type: TYPE_NORMAL
- en: The original codebase can be found at [Fantasy-Studio/Paint-by-Example](https://github.com/Fantasy-Studio/Paint-by-Example),
    and you can try it out in a [demo](https://huggingface.co/spaces/Fantasy-Studio/Paint-by-Example).
  prefs: []
  type: TYPE_NORMAL
- en: Tips
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Paint by Example is supported by the official [Fantasy-Studio/Paint-by-Example](https://huggingface.co/Fantasy-Studio/Paint-by-Example)
    checkpoint. The checkpoint is warm-started from [CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)
    to inpaint partly masked images conditioned on example and reference images.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to check out the Schedulers [guide](../../using-diffusers/schedulers)
    to learn how to explore the tradeoff between scheduler speed and quality, and
    see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines)
    section to learn how to efficiently load the same components into multiple pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: PaintByExamplePipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.PaintByExamplePipeline`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/paint_by_example/pipeline_paint_by_example.py#L151)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`vae` ([AutoencoderKL](/docs/diffusers/v0.26.3/en/api/models/autoencoderkl#diffusers.AutoencoderKL))
    ‚Äî Variational Auto-Encoder (VAE) model to encode and decode images to and from
    latent representations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image_encoder` (`PaintByExampleImageEncoder`) ‚Äî Encodes the example input
    image. The `unet` is conditioned on the example image instead of a text prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer` ([CLIPTokenizer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPTokenizer))
    ‚Äî A `CLIPTokenizer` to tokenize text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unet` ([UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel))
    ‚Äî A `UNet2DConditionModel` to denoise the encoded image latents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scheduler` ([SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin))
    ‚Äî A scheduler to be used in combination with `unet` to denoise the encoded image
    latents. Can be one of [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    [LMSDiscreteScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler),
    or [PNDMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/pndm#diffusers.PNDMScheduler).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safety_checker` (`StableDiffusionSafetyChecker`) ‚Äî Classification module that
    estimates whether generated images could be considered offensive or harmful. Please
    refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    for more details about a model‚Äôs potential harms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`feature_extractor` ([CLIPImageProcessor](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/clip#transformers.CLIPImageProcessor))
    ‚Äî A `CLIPImageProcessor` to extract features from generated images; used as inputs
    to the `safety_checker`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: üß™ This is an experimental feature!
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline for image-guided image inpainting using Stable Diffusion.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [DiffusionPipeline](/docs/diffusers/v0.26.3/en/api/pipelines/overview#diffusers.DiffusionPipeline).
    Check the superclass documentation for the generic methods implemented for all
    pipelines (downloading, saving, running on a particular device, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/paint_by_example/pipeline_paint_by_example.py#L388)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`example_image` (`torch.FloatTensor` or `PIL.Image.Image` or `List[PIL.Image.Image]`)
    ‚Äî An example image to guide image generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image` (`torch.FloatTensor` or `PIL.Image.Image` or `List[PIL.Image.Image]`)
    ‚Äî `Image` or tensor representing an image batch to be inpainted (parts of the
    image are masked out with `mask_image` and repainted according to `prompt`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask_image` (`torch.FloatTensor` or `PIL.Image.Image` or `List[PIL.Image.Image]`)
    ‚Äî `Image` or tensor representing an image batch to mask `image`. White pixels
    in the mask are repainted, while black pixels are preserved. If `mask_image` is
    a PIL image, it is converted to a single channel (luminance) before use. If it‚Äôs
    a tensor, it should contain one color channel (L) instead of 3, so the expected
    shape would be `(B, H, W, 1)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    ‚Äî The height in pixels of the generated image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width` (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`)
    ‚Äî The width in pixels of the generated image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, *optional*, defaults to 50) ‚Äî The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, *optional*, defaults to 7.5) ‚Äî A higher guidance
    scale value encourages the model to generate images closely linked to the text
    `prompt` at the expense of lower image quality. Guidance scale is enabled when
    `guidance_scale > 1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str` or `List[str]`, *optional*) ‚Äî The prompt or prompts
    to guide what to not include in image generation. If not defined, you need to
    pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale
    < 1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_images_per_prompt` (`int`, *optional*, defaults to 1) ‚Äî The number of
    images to generate per prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eta` (`float`, *optional*, defaults to 0.0) ‚Äî Corresponds to parameter eta
    (Œ∑) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies to the
    [DDIMScheduler](/docs/diffusers/v0.26.3/en/api/schedulers/ddim#diffusers.DDIMScheduler),
    and is ignored in other schedulers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator` or `List[torch.Generator]`, *optional*) ‚Äî A
    [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html)
    to make generation deterministic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`latents` (`torch.FloatTensor`, *optional*) ‚Äî Pre-generated noisy latents sampled
    from a Gaussian distribution, to be used as inputs for image generation. Can be
    used to tweak the same generation with different prompts. If not provided, a latents
    tensor is generated by sampling using the supplied random `generator`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type` (`str`, *optional*, defaults to `"pil"`) ‚Äî The output format
    of the generated image. Choose between `PIL.Image` or `np.array`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) ‚Äî Whether or not to
    return a [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback` (`Callable`, *optional*) ‚Äî A function that calls every `callback_steps`
    steps during inference. The function is called with the following arguments: `callback(step:
    int, timestep: int, latents: torch.FloatTensor)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`callback_steps` (`int`, *optional*, defaults to 1) ‚Äî The frequency at which
    the `callback` function is called. If not specified, the callback is called at
    every step.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: If `return_dict` is `True`, [StableDiffusionPipelineOutput](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput)
    is returned, otherwise a `tuple` is returned where the first element is a list
    with the generated images and the second element is a list of `bool`s indicating
    whether the corresponding generated image contains ‚Äúnot-safe-for-work‚Äù (nsfw)
    content.
  prefs: []
  type: TYPE_NORMAL
- en: The call function to the pipeline for generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: StableDiffusionPipelineOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/stable_diffusion/pipeline_output.py#L10)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`images` (`List[PIL.Image.Image]` or `np.ndarray`) ‚Äî List of denoised PIL images
    of length `batch_size` or NumPy array of shape `(batch_size, height, width, num_channels)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nsfw_content_detected` (`List[bool]`) ‚Äî List indicating whether the corresponding
    generated image contains ‚Äúnot-safe-for-work‚Äù (nsfw) content or `None` if safety
    checking could not be performed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output class for Stable Diffusion pipelines.
  prefs: []
  type: TYPE_NORMAL
