["```py\nimport torch\nfrom diffusers import AutoPipelineForText2Image\nfrom diffusers.pipelines.wuerstchen import DEFAULT_STAGE_C_TIMESTEPS\n\npipe = AutoPipelineForText2Image.from_pretrained(\"warp-ai/wuerstchen\", torch_dtype=torch.float16).to(\"cuda\")\n\ncaption = \"Anthropomorphic cat dressed as a fire fighter\"\nimages = pipe(\n    caption,\n    width=1024,\n    height=1536,\n    prior_timesteps=DEFAULT_STAGE_C_TIMESTEPS,\n    prior_guidance_scale=4.0,\n    num_images_per_prompt=2,\n).images\n```", "```py\nimport torch\nfrom diffusers import WuerstchenDecoderPipeline, WuerstchenPriorPipeline\nfrom diffusers.pipelines.wuerstchen import DEFAULT_STAGE_C_TIMESTEPS\n\ndevice = \"cuda\"\ndtype = torch.float16\nnum_images_per_prompt = 2\n\nprior_pipeline = WuerstchenPriorPipeline.from_pretrained(\n    \"warp-ai/wuerstchen-prior\", torch_dtype=dtype\n).to(device)\ndecoder_pipeline = WuerstchenDecoderPipeline.from_pretrained(\n    \"warp-ai/wuerstchen\", torch_dtype=dtype\n).to(device)\n\ncaption = \"Anthropomorphic cat dressed as a fire fighter\"\nnegative_prompt = \"\"\n\nprior_output = prior_pipeline(\n    prompt=caption,\n    height=1024,\n    width=1536,\n    timesteps=DEFAULT_STAGE_C_TIMESTEPS,\n    negative_prompt=negative_prompt,\n    guidance_scale=4.0,\n    num_images_per_prompt=num_images_per_prompt,\n)\ndecoder_output = decoder_pipeline(\n    image_embeddings=prior_output.image_embeddings,\n    prompt=caption,\n    negative_prompt=negative_prompt,\n    guidance_scale=0.0,\n    output_type=\"pil\",\n).images[0]\ndecoder_output\n```", "```py\nprior_pipeline.prior = torch.compile(prior_pipeline.prior, mode=\"reduce-overhead\", fullgraph=True)\ndecoder_pipeline.decoder = torch.compile(decoder_pipeline.decoder, mode=\"reduce-overhead\", fullgraph=True)\n```", "```py\n>>> from diffusions import WuerstchenCombinedPipeline\n\n>>> pipe = WuerstchenCombinedPipeline.from_pretrained(\"warp-ai/Wuerstchen\", torch_dtype=torch.float16).to(\n...     \"cuda\"\n... )\n>>> prompt = \"an image of a shiba inu, donning a spacesuit and helmet\"\n>>> images = pipe(prompt=prompt)\n```", "```py\n>>> import torch\n>>> from diffusers import WuerstchenPriorPipeline\n\n>>> prior_pipe = WuerstchenPriorPipeline.from_pretrained(\n...     \"warp-ai/wuerstchen-prior\", torch_dtype=torch.float16\n... ).to(\"cuda\")\n\n>>> prompt = \"an image of a shiba inu, donning a spacesuit and helmet\"\n>>> prior_output = pipe(prompt)\n```", "```py\n>>> import torch\n>>> from diffusers import WuerstchenPriorPipeline, WuerstchenDecoderPipeline\n\n>>> prior_pipe = WuerstchenPriorPipeline.from_pretrained(\n...     \"warp-ai/wuerstchen-prior\", torch_dtype=torch.float16\n... ).to(\"cuda\")\n>>> gen_pipe = WuerstchenDecoderPipeline.from_pretrain(\"warp-ai/wuerstchen\", torch_dtype=torch.float16).to(\n...     \"cuda\"\n... )\n\n>>> prompt = \"an image of a shiba inu, donning a spacesuit and helmet\"\n>>> prior_output = pipe(prompt)\n>>> images = gen_pipe(prior_output.image_embeddings, prompt=prompt)\n```", "```py\n      @misc{pernias2023wuerstchen,\n            title={Wuerstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models},\n            author={Pablo Pernias and Dominic Rampas and Mats L. Richter and Christopher J. Pal and Marc Aubreville},\n            year={2023},\n            eprint={2306.00637},\n            archivePrefix={arXiv},\n            primaryClass={cs.CV}\n      }\n```"]