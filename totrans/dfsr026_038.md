# ç¨³å®šæ‰©æ•£ XL

> åŽŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/diffusers/using-diffusers/sdxl`](https://huggingface.co/docs/diffusers/using-diffusers/sdxl)

[ç¨³å®šæ‰©æ•£ XL](https://huggingface.co/papers/2307.01952)ï¼ˆSDXLï¼‰æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡åž‹ï¼Œé€šè¿‡ä¸‰ç§å…³é”®æ–¹å¼æ”¹è¿›äº†å…ˆå‰çš„ç¨³å®šæ‰©æ•£æ¨¡åž‹ï¼š

1.  UNet æ˜¯ 3 å€å¤§ï¼ŒSDXL å°†ç¬¬äºŒä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼ˆOpenCLIP ViT-bigG/14ï¼‰ä¸ŽåŽŸå§‹æ–‡æœ¬ç¼–ç å™¨ç»“åˆèµ·æ¥ï¼Œæ˜¾è‘—å¢žåŠ å‚æ•°æ•°é‡

1.  å¼•å…¥å°ºå¯¸å’Œè£å‰ªæ¡ä»¶ï¼Œä»¥ä¿ç•™è®­ç»ƒæ•°æ®ä¸è¢«ä¸¢å¼ƒï¼Œå¹¶æ›´å¥½åœ°æŽ§åˆ¶ç”Ÿæˆå›¾åƒçš„è£å‰ªæ–¹å¼

1.  å¼•å…¥äº†ä¸€ä¸ªä¸¤é˜¶æ®µæ¨¡åž‹è¿‡ç¨‹ï¼›*åŸºç¡€*æ¨¡åž‹ï¼ˆä¹Ÿå¯ä»¥ä½œä¸ºç‹¬ç«‹æ¨¡åž‹è¿è¡Œï¼‰ç”Ÿæˆä¸€ä¸ªå›¾åƒä½œä¸º*ç²¾ç‚¼å™¨*æ¨¡åž‹çš„è¾“å…¥ï¼ŒåŽè€…æ·»åŠ é¢å¤–çš„é«˜è´¨é‡ç»†èŠ‚

æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ SDXL è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒåˆ°å›¾åƒå’Œä¿®è¡¥ã€‚

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹åº“ï¼š

```py
# uncomment to install the necessary libraries in Colab
#!pip install -q diffusers transformers accelerate invisible-watermark>=0.2.0
```

æˆ‘ä»¬å»ºè®®å®‰è£…[invisible-watermark](https://pypi.org/project/invisible-watermark/)åº“æ¥å¸®åŠ©è¯†åˆ«ç”Ÿæˆçš„å›¾åƒã€‚å¦‚æžœå®‰è£…äº† invisible-watermark åº“ï¼Œé»˜è®¤æƒ…å†µä¸‹ä¼šä½¿ç”¨å®ƒã€‚è¦ç¦ç”¨æ°´å°ï¼š

```py
pipeline = StableDiffusionXLPipeline.from_pretrained(..., add_watermarker=False)
```

## åŠ è½½æ¨¡åž‹æ£€æŸ¥ç‚¹

æ¨¡åž‹æƒé‡å¯èƒ½å­˜å‚¨åœ¨ Hub æˆ–æœ¬åœ°çš„å•ç‹¬å­æ–‡ä»¶å¤¹ä¸­ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨ from_pretrained()æ–¹æ³•ï¼š

```py
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, use_safetensors=True, variant="fp16"
).to("cuda")
```

æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ from_single_file()æ–¹æ³•æ¥åŠ è½½å­˜å‚¨åœ¨å•ä¸ªæ–‡ä»¶æ ¼å¼ï¼ˆ`.ckpt`æˆ–`.safetensors`ï¼‰ä¸­çš„æ¨¡åž‹æ£€æŸ¥ç‚¹ï¼Œä»Ž Hub æˆ–æœ¬åœ°ï¼š

```py
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_single_file(
    "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/sd_xl_base_1.0.safetensors", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = StableDiffusionXLImg2ImgPipeline.from_single_file(
    "https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/blob/main/sd_xl_refiner_1.0.safetensors", torch_dtype=torch.float16, use_safetensors=True, variant="fp16"
).to("cuda")
```

## æ–‡æœ¬åˆ°å›¾åƒ

å¯¹äºŽæ–‡æœ¬åˆ°å›¾åƒï¼Œä¼ é€’ä¸€ä¸ªæ–‡æœ¬æç¤ºã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒSDXL ç”Ÿæˆ 1024x1024 å›¾åƒä»¥èŽ·å¾—æœ€ä½³ç»“æžœã€‚æ‚¨å¯ä»¥å°è¯•å°†`height`å’Œ`width`å‚æ•°è®¾ç½®ä¸º 768x768 æˆ– 512x512ï¼Œä½†ä½ŽäºŽ 512x512 çš„å°ºå¯¸ä¸å¤ªå¯èƒ½æœ‰æ•ˆã€‚

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline_text2image = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image = pipeline_text2image(prompt=prompt).images[0]
image
```

![ç”Ÿæˆçš„å›¾åƒï¼Œä¸€ä¸ªå®‡èˆªå‘˜åœ¨ä¸›æž—ä¸­](img/47eb848e4e09fd8ca2c920b1f98d089d.png)

## å›¾åƒåˆ°å›¾åƒ

å¯¹äºŽå›¾åƒåˆ°å›¾åƒï¼ŒSDXL åœ¨ 768x768 å’Œ 1024x1024 ä¹‹é—´çš„å›¾åƒå°ºå¯¸ä¸Šè¡¨çŽ°ç‰¹åˆ«å¥½ã€‚ä¼ é€’ä¸€ä¸ªåˆå§‹å›¾åƒå’Œä¸€ä¸ªæ–‡æœ¬æç¤ºæ¥è°ƒæ•´å›¾åƒï¼š

```py
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import load_image, make_image_grid

# use from_pipe to avoid consuming additional memory when loading a checkpoint
pipeline = AutoPipelineForImage2Image.from_pipe(pipeline_text2image).to("cuda")

url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png"
init_image = load_image(url)
prompt = "a dog catching a frisbee in the jungle"
image = pipeline(prompt, image=init_image, strength=0.8, guidance_scale=10.5).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

![ç”Ÿæˆçš„å›¾åƒï¼Œä¸€åªç‹—åœ¨ä¸›æž—ä¸­æŽ¥ä½é£žç›˜](img/55a0d39eaf8bd9f5f77b3d034b991391.png)

## ä¿®è¡¥

å¯¹äºŽä¿®è¡¥ï¼Œæ‚¨å°†éœ€è¦åŽŸå§‹å›¾åƒå’Œè¦æ›¿æ¢åŽŸå§‹å›¾åƒä¸­å†…å®¹çš„è’™ç‰ˆã€‚åˆ›å»ºä¸€ä¸ªæç¤ºæ¥æè¿°æ‚¨æƒ³ç”¨è’™ç‰ˆåŒºåŸŸæ›¿æ¢çš„å†…å®¹ã€‚

```py
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

# use from_pipe to avoid consuming additional memory when loading a checkpoint
pipeline = AutoPipelineForInpainting.from_pipe(pipeline_text2image).to("cuda")

img_url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png"
mask_url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-inpaint-mask.png"

init_image = load_image(img_url)
mask_image = load_image(mask_url)

prompt = "A deep sea diver floating"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.85, guidance_scale=12.5).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

![ç”Ÿæˆçš„å›¾åƒï¼Œä¸€ä¸ªæ·±æµ·æ½œæ°´å‘˜åœ¨ä¸›æž—ä¸­](img/1f8afc98a8a746ad39b81d94dcd646d0.png)

## æé«˜å›¾åƒè´¨é‡

SDXL åŒ…æ‹¬ä¸€ä¸ª[ç²¾ç‚¼å™¨æ¨¡åž‹](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0)ï¼Œä¸“é—¨ç”¨äºŽåŽ»å™ªä½Žå™ªå£°é˜¶æ®µå›¾åƒï¼Œä»¥ä»ŽåŸºç¡€æ¨¡åž‹ç”Ÿæˆæ›´é«˜è´¨é‡çš„å›¾åƒã€‚æœ‰ä¸¤ç§ä½¿ç”¨ç²¾ç‚¼å™¨çš„æ–¹æ³•ï¼š

1.  ä½¿ç”¨åŸºç¡€å’Œç²¾ç‚¼å™¨æ¨¡åž‹ä¸€èµ·ç”Ÿæˆä¸€ä¸ªç²¾ç‚¼å›¾åƒ

1.  ä½¿ç”¨åŸºç¡€æ¨¡åž‹ç”Ÿæˆä¸€ä¸ªå›¾åƒï¼Œç„¶åŽä½¿ç”¨ç²¾ç‚¼å™¨æ¨¡åž‹ä¸ºå›¾åƒæ·»åŠ æ›´å¤šç»†èŠ‚ï¼ˆè¿™æ˜¯ SDXL æœ€åˆè®­ç»ƒçš„æ–¹å¼ï¼‰

### åŸºç¡€+ç²¾ç‚¼å™¨æ¨¡åž‹

å½“æ‚¨å°†åŸºç¡€æ¨¡åž‹å’Œç²¾ç‚¼å™¨æ¨¡åž‹ä¸€èµ·ä½¿ç”¨ç”Ÿæˆå›¾åƒæ—¶ï¼Œè¿™è¢«ç§°ä¸º[*ä¸“å®¶åŽ»å™ªå™¨é›†åˆ*](https://research.nvidia.com/labs/dir/eDiff-I/)ã€‚ä¸“å®¶åŽ»å™ªå™¨é›†åˆæ–¹æ³•éœ€è¦è¾ƒå°‘çš„æ•´ä½“åŽ»å™ªæ­¥éª¤ï¼Œä¸Žå°†åŸºç¡€æ¨¡åž‹çš„è¾“å‡ºä¼ é€’ç»™ç²¾ç‚¼å™¨æ¨¡åž‹ç›¸æ¯”ï¼Œè¿è¡Œé€Ÿåº¦åº”è¯¥æ›´å¿«ã€‚ä½†æ˜¯ï¼Œæ‚¨å°†æ— æ³•æ£€æŸ¥åŸºç¡€æ¨¡åž‹çš„è¾“å‡ºï¼Œå› ä¸ºå®ƒä»ç„¶åŒ…å«å¤§é‡å™ªéŸ³ã€‚

ä½œä¸ºä¸“å®¶åŽ»å™ªå™¨çš„é›†åˆï¼ŒåŸºç¡€æ¨¡åž‹åœ¨é«˜å™ªå£°æ‰©æ•£é˜¶æ®µå……å½“ä¸“å®¶ï¼Œç²¾ç‚¼å™¨æ¨¡åž‹åœ¨ä½Žå™ªå£°æ‰©æ•£é˜¶æ®µå……å½“ä¸“å®¶ã€‚åŠ è½½åŸºç¡€å’Œç²¾ç‚¼å™¨æ¨¡åž‹ï¼š

```py
from diffusers import DiffusionPipeline
import torch

base = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    text_encoder_2=base.text_encoder_2,
    vae=base.vae,
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16",
).to("cuda")
```

è¦ä½¿ç”¨è¿™ç§æ–¹æ³•ï¼Œæ‚¨éœ€è¦ä¸ºæ¯ä¸ªæ¨¡åž‹å®šä¹‰é€šè¿‡å„è‡ªé˜¶æ®µè¿è¡Œçš„æ—¶é—´æ­¥æ•°ã€‚å¯¹äºŽåŸºç¡€æ¨¡åž‹ï¼Œè¿™ç”±[`denoising_end`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline.__call__.denoising_end)å‚æ•°æŽ§åˆ¶ï¼Œå¯¹äºŽç²¾ç‚¼æ¨¡åž‹ï¼Œç”±[`denoising_start`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLImg2ImgPipeline.__call__.denoising_start)å‚æ•°æŽ§åˆ¶ã€‚

`denoising_end`å’Œ`denoising_start`å‚æ•°åº”è¯¥æ˜¯ 0 åˆ° 1 ä¹‹é—´çš„æµ®ç‚¹æ•°ã€‚è¿™äº›å‚æ•°è¡¨ç¤ºä¸ºç¦»æ•£æ—¶é—´æ­¥æ•°çš„æ¯”ä¾‹ï¼Œç”±è°ƒåº¦å™¨å®šä¹‰ã€‚å¦‚æžœæ‚¨è¿˜ä½¿ç”¨`strength`å‚æ•°ï¼Œå®ƒå°†è¢«å¿½ç•¥ï¼Œå› ä¸ºåŽ»å™ªæ­¥æ•°ç”±æ¨¡åž‹è®­ç»ƒçš„ç¦»æ•£æ—¶é—´æ­¥æ•°å’Œå£°æ˜Žçš„åˆ†æ•°æˆªæ­¢ç¡®å®šã€‚

è®©æˆ‘ä»¬è®¾ç½®`denoising_end=0.8`ï¼Œè¿™æ ·åŸºç¡€æ¨¡åž‹å°†æ‰§è¡Œå‰ 80%çš„åŽ»å™ª**é«˜å™ªå£°**æ—¶é—´æ­¥ï¼Œå¹¶è®¾ç½®`denoising_start=0.8`ï¼Œè¿™æ ·ç²¾ç‚¼æ¨¡åž‹å°†æ‰§è¡Œæœ€åŽ 20%çš„åŽ»å™ª**ä½Žå™ªå£°**æ—¶é—´æ­¥ã€‚åŸºç¡€æ¨¡åž‹çš„è¾“å‡ºåº”è¯¥æ˜¯**æ½œåœ¨**ç©ºé—´è€Œä¸æ˜¯ PIL å›¾åƒã€‚

```py
prompt = "A majestic lion jumping from a big stone at night"

image = base(
    prompt=prompt,
    num_inference_steps=40,
    denoising_end=0.8,
    output_type="latent",
).images
image = refiner(
    prompt=prompt,
    num_inference_steps=40,
    denoising_start=0.8,
    image=image,
).images[0]
image
```

![å¤œæ™šå²©çŸ³ä¸Šç‹®å­çš„ç”Ÿæˆå›¾åƒ](img/ef6f87a67e4302925ad70cad452060f0.png)

é»˜è®¤åŸºç¡€æ¨¡åž‹

![å¤œæ™šå²©çŸ³ä¸Šç‹®å­çš„é«˜è´¨é‡ç”Ÿæˆå›¾åƒ](img/33eab9fdb93d52d1ea5ac9c0abb385b9.png)

ä¸“å®¶åŽ»å™ªçš„é›†åˆ

ç²¾ç‚¼æ¨¡åž‹ä¹Ÿå¯ä»¥ç”¨äºŽ StableDiffusionXLInpaintPipeline ä¸­çš„ä¿®è¡¥ï¼š

```py
from diffusers import StableDiffusionXLInpaintPipeline
from diffusers.utils import load_image, make_image_grid
import torch

base = StableDiffusionXLInpaintPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = StableDiffusionXLInpaintPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    text_encoder_2=base.text_encoder_2,
    vae=base.vae,
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16",
).to("cuda")

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = load_image(img_url)
mask_image = load_image(mask_url)

prompt = "A majestic tiger sitting on a bench"
num_inference_steps = 75
high_noise_frac = 0.7

image = base(
    prompt=prompt,
    image=init_image,
    mask_image=mask_image,
    num_inference_steps=num_inference_steps,
    denoising_end=high_noise_frac,
    output_type="latent",
).images
image = refiner(
    prompt=prompt,
    image=image,
    mask_image=mask_image,
    num_inference_steps=num_inference_steps,
    denoising_start=high_noise_frac,
).images[0]
make_image_grid([init_image, mask_image, image.resize((512, 512))], rows=1, cols=3)
```

è¿™ä¸ªä¸“å®¶åŽ»å™ªæ–¹æ³•çš„é›†åˆå¯¹æ‰€æœ‰å¯ç”¨çš„è°ƒåº¦å™¨éƒ½æœ‰æ•ˆï¼

### åŸºç¡€åˆ°ç²¾ç‚¼æ¨¡åž‹

é€šè¿‡åœ¨å›¾åƒåˆ°å›¾åƒè®¾ç½®ä¸­ä½¿ç”¨ç²¾ç‚¼æ¨¡åž‹å‘åŸºç¡€æ¨¡åž‹çš„å®Œå…¨åŽ»å™ªå›¾åƒæ·»åŠ é¢å¤–çš„é«˜è´¨é‡ç»†èŠ‚ï¼ŒSDXL åœ¨å›¾åƒè´¨é‡ä¸Šå¾—åˆ°æå‡ã€‚

åŠ è½½åŸºç¡€å’Œç²¾ç‚¼æ¨¡åž‹ï¼š

```py
from diffusers import DiffusionPipeline
import torch

base = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    text_encoder_2=base.text_encoder_2,
    vae=base.vae,
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16",
).to("cuda")
```

ä»ŽåŸºç¡€æ¨¡åž‹ç”Ÿæˆå›¾åƒï¼Œå¹¶å°†æ¨¡åž‹è¾“å‡ºè®¾ç½®ä¸º**æ½œåœ¨**ç©ºé—´ï¼š

```py
prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

image = base(prompt=prompt, output_type="latent").images[0]
```

å°†ç”Ÿæˆçš„å›¾åƒä¼ é€’ç»™ç²¾ç‚¼æ¨¡åž‹ï¼š

```py
image = refiner(prompt=prompt, image=image[None, :]).images[0]
```

![ç”Ÿæˆçš„ç«æ˜Ÿä¸Šéª‘ç»¿é©¬çš„å®‡èˆªå‘˜å›¾åƒ](img/80df2aefcda4915968249be118157434.png)

åŸºç¡€æ¨¡åž‹

![ç«æ˜Ÿä¸Šéª‘ç»¿é©¬çš„å®‡èˆªå‘˜çš„é«˜è´¨é‡ç”Ÿæˆå›¾åƒ](img/e69b90229b2f9360e7773d6580ae6cf1.png)

åŸºç¡€æ¨¡åž‹ + ç²¾ç‚¼æ¨¡åž‹

å¯¹äºŽä¿®è¡¥ï¼ŒåŠ è½½åŸºç¡€å’Œç²¾ç‚¼æ¨¡åž‹åœ¨ StableDiffusionXLInpaintPipeline ä¸­ï¼Œåˆ é™¤`denoising_end`å’Œ`denoising_start`å‚æ•°ï¼Œå¹¶ä¸ºç²¾ç‚¼å™¨é€‰æ‹©è¾ƒå°‘çš„æŽ¨ç†æ­¥éª¤ã€‚

## å¾®è°ƒèŠ‚

SDXL è®­ç»ƒæ¶‰åŠå‡ ç§é¢å¤–çš„è°ƒèŠ‚æŠ€æœ¯ï¼Œè¢«ç§°ä¸º*å¾®è°ƒèŠ‚*ã€‚è¿™äº›åŒ…æ‹¬åŽŸå§‹å›¾åƒå°ºå¯¸ã€ç›®æ ‡å›¾åƒå°ºå¯¸å’Œè£å‰ªå‚æ•°ã€‚è¿™äº›å¾®è°ƒèŠ‚å¯ä»¥åœ¨æŽ¨ç†æ—¶ç”¨äºŽåˆ›å»ºé«˜è´¨é‡ã€å±…ä¸­çš„å›¾åƒã€‚

ç”±äºŽæ— éœ€åˆ†ç±»å™¨çš„æŒ‡å¯¼ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å¾®è°ƒèŠ‚å’Œè´Ÿå¾®è°ƒèŠ‚å‚æ•°ã€‚å®ƒä»¬åœ¨ StableDiffusionXLPipelineã€StableDiffusionXLImg2ImgPipelineã€StableDiffusionXLInpaintPipeline å’Œ StableDiffusionXLControlNetPipeline ä¸­éƒ½å¯ç”¨ã€‚

### å°ºå¯¸è°ƒèŠ‚

æœ‰ä¸¤ç§ç±»åž‹çš„å°ºå¯¸è°ƒèŠ‚ï¼š

+   [`original_size`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline.__call__.original_size) æ¡ä»¶æ¥è‡ªè®­ç»ƒæ‰¹æ¬¡ä¸­çš„æ”¾å¤§å›¾åƒï¼ˆå› ä¸ºä¸¢å¼ƒæž„æˆæ€»è®­ç»ƒæ•°æ®è¿‘ 40%çš„è¾ƒå°å›¾åƒå°†æ˜¯æµªè´¹çš„ï¼‰ã€‚è¿™æ ·ï¼ŒSDXL å­¦ä¹ åˆ°æ”¾å¤§ä¼ªå½±ä¸åº”å‡ºçŽ°åœ¨é«˜åˆ†è¾¨çŽ‡å›¾åƒä¸­ã€‚åœ¨æŽ¨ç†è¿‡ç¨‹ä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`original_size`æŒ‡ç¤ºåŽŸå§‹å›¾åƒåˆ†è¾¨çŽ‡ã€‚ä½¿ç”¨é»˜è®¤å€¼`(1024, 1024)`ä¼šç”Ÿæˆç±»ä¼¼æ•°æ®é›†ä¸­ 1024x1024 å›¾åƒçš„é«˜è´¨é‡å›¾åƒã€‚å¦‚æžœé€‰æ‹©ä½¿ç”¨è¾ƒä½Žåˆ†è¾¨çŽ‡ï¼Œå¦‚`(256, 256)`ï¼Œæ¨¡åž‹ä»ä¼šç”Ÿæˆ 1024x1024 å›¾åƒï¼Œä½†å®ƒä»¬çœ‹èµ·æ¥åƒæ•°æ®é›†ä¸­çš„ä½Žåˆ†è¾¨çŽ‡å›¾åƒï¼ˆç®€å•å›¾æ¡ˆï¼Œæ¨¡ç³Šï¼‰ã€‚

+   [`target_size`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline.__call__.target_size) æ¡ä»¶æ¥è‡ªå¯¹ SDXL è¿›è¡Œå¾®è°ƒä»¥æ”¯æŒä¸åŒçš„å›¾åƒçºµæ¨ªæ¯”ã€‚åœ¨æŽ¨ç†è¿‡ç¨‹ä¸­ï¼Œå¦‚æžœæ‚¨ä½¿ç”¨é»˜è®¤å€¼`(1024, 1024)`ï¼Œæ‚¨å°†èŽ·å¾—ä¸€ä¸ªç±»ä¼¼äºŽæ•°æ®é›†ä¸­æ–¹å½¢å›¾åƒç»„åˆçš„å›¾åƒã€‚æˆ‘ä»¬å»ºè®®å¯¹`target_size`å’Œ`original_size`ä½¿ç”¨ç›¸åŒçš„å€¼ï¼Œä½†è¯·éšæ—¶å°è¯•å…¶ä»–é€‰é¡¹ï¼

ðŸ¤— Diffusers è¿˜å…è®¸æ‚¨æŒ‡å®šå…³äºŽå›¾åƒå¤§å°çš„è´Ÿé¢æ¡ä»¶ï¼Œä»¥ä½¿ç”Ÿæˆè¿œç¦»æŸäº›å›¾åƒåˆ†è¾¨çŽ‡ï¼š

```py
from diffusers import StableDiffusionXLPipeline
import torch

pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image = pipe(
    prompt=prompt,
    negative_original_size=(512, 512),
    negative_target_size=(1024, 1024),
).images[0]
```

![](img/eb8daaf025f019bf5475af302cf825d4.png)

å›¾åƒè´Ÿé¢æ¡ä»¶æ˜¯(128, 128)ã€(256, 256)å’Œ(512, 512)çš„å›¾åƒåˆ†è¾¨çŽ‡ã€‚

### è£å‰ªæ¡ä»¶

ä»¥å‰çš„ç¨³å®šæ‰©æ•£æ¨¡åž‹ç”Ÿæˆçš„å›¾åƒæœ‰æ—¶å¯èƒ½çœ‹èµ·æ¥è¢«è£å‰ªäº†ã€‚è¿™æ˜¯å› ä¸ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®žé™…ä¸Šå¯¹å›¾åƒè¿›è¡Œäº†è£å‰ªï¼Œä»¥ä½¿æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰å›¾åƒå…·æœ‰ç›¸åŒçš„å¤§å°ã€‚é€šè¿‡åœ¨è£å‰ªåæ ‡ä¸Šè¿›è¡Œæ¡ä»¶åŒ–ï¼ŒSDXL *å­¦ä¹ *åˆ°æ²¡æœ‰è£å‰ª - åæ ‡`(0, 0)` - é€šå¸¸ä¸Žä¸­å¿ƒä¸»é¢˜å’Œå®Œæ•´é¢å­”ç›¸å…³è”ï¼ˆè¿™æ˜¯ðŸ¤— Diffusers ä¸­çš„é»˜è®¤å€¼ï¼‰ã€‚å¦‚æžœè¦ç”Ÿæˆåç¦»ä¸­å¿ƒçš„æž„å›¾ï¼Œå¯ä»¥å°è¯•ä¸åŒçš„åæ ‡ï¼

```py
from diffusers import StableDiffusionXLPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image = pipeline(prompt=prompt, crops_coords_top_left=(256, 0)).images[0]
image
```

![åœ¨ä¸›æž—ä¸­çš„å®‡èˆªå‘˜ï¼Œç•¥æœ‰è£å‰ªçš„ç”Ÿæˆå›¾åƒ](img/f09d2bde8c0bb94924d692c1760dfca3.png)

æ‚¨è¿˜å¯ä»¥æŒ‡å®šè´Ÿé¢è£å‰ªåæ ‡ï¼Œä»¥ä½¿ç”Ÿæˆè¿œç¦»æŸäº›è£å‰ªå‚æ•°ï¼š

```py
from diffusers import StableDiffusionXLPipeline
import torch

pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image = pipe(
    prompt=prompt,
    negative_original_size=(512, 512),
    negative_crops_coords_top_left=(0, 0),
    negative_target_size=(1024, 1024),
).images[0]
image
```

## ä¸ºæ¯ä¸ªæ–‡æœ¬ç¼–ç å™¨ä½¿ç”¨ä¸åŒçš„æç¤º

SDXL ä½¿ç”¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼Œå› æ­¤å¯ä»¥å‘æ¯ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¼ é€’ä¸åŒçš„æç¤ºï¼Œè¿™å¯ä»¥[æé«˜è´¨é‡](https://github.com/huggingface/diffusers/issues/4004#issuecomment-1627764201)ã€‚å°†æ‚¨çš„åŽŸå§‹æç¤ºä¼ é€’ç»™`prompt`ï¼Œå°†ç¬¬äºŒä¸ªæç¤ºä¼ é€’ç»™`prompt_2`ï¼ˆå¦‚æžœæ‚¨ä½¿ç”¨è´Ÿé¢æç¤ºï¼Œè¯·ä½¿ç”¨`negative_prompt`å’Œ`negative_prompt_2`ï¼‰ï¼š

```py
from diffusers import StableDiffusionXLPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

# prompt is passed to OAI CLIP-ViT/L-14
prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
# prompt_2 is passed to OpenCLIP-ViT/bigG-14
prompt_2 = "Van Gogh painting"
image = pipeline(prompt=prompt, prompt_2=prompt_2).images[0]
image
```

![åœ¨ä¸›æž—ä¸­çš„å®‡èˆªå‘˜é£Žæ ¼çš„æ¢µé«˜ç”»ä½œç”Ÿæˆçš„å›¾åƒ](img/3bd090b79f879a79477c88a713c15375.png)

åŒæ–‡æœ¬ç¼–ç å™¨è¿˜æ”¯æŒéœ€è¦å•ç‹¬åŠ è½½çš„æ–‡æœ¬åè½¬åµŒå…¥ï¼Œå¦‚ SDXL æ–‡æœ¬åè½¬éƒ¨åˆ†æ‰€è¿°ã€‚

## ä¼˜åŒ–

SDXL æ˜¯ä¸€ä¸ªåºžå¤§çš„æ¨¡åž‹ï¼Œæ‚¨å¯èƒ½éœ€è¦ä¼˜åŒ–å†…å­˜æ‰èƒ½ä½¿å…¶åœ¨æ‚¨çš„ç¡¬ä»¶ä¸Šè¿è¡Œã€‚ä»¥ä¸‹æ˜¯ä¸€äº›èŠ‚çœå†…å­˜å¹¶åŠ å¿«æŽ¨ç†é€Ÿåº¦çš„æç¤ºã€‚

1.  é€šè¿‡ enable_model_cpu_offload()å°†æ¨¡åž‹å¸è½½åˆ° CPU ä»¥é¿å…å†…å­˜é”™è¯¯ï¼š

```py
- base.to("cuda")
- refiner.to("cuda")
+ base.enable_model_cpu_offload()
+ refiner.enable_model_cpu_offload()
```

1.  ä½¿ç”¨`torch.compile`å¯ä»¥æé«˜çº¦ 20%çš„é€Ÿåº¦ï¼ˆæ‚¨éœ€è¦`torch>=2.0`ï¼‰ï¼š

```py
+ base.unet = torch.compile(base.unet, mode="reduce-overhead", fullgraph=True)
+ refiner.unet = torch.compile(refiner.unet, mode="reduce-overhead", fullgraph=True)
```

1.  å¦‚æžœ`torch<2.0`ï¼Œè¯·å¯ç”¨ xFormers æ¥è¿è¡Œ SDXLï¼š

```py
+ base.enable_xformers_memory_efficient_attention()
+ refiner.enable_xformers_memory_efficient_attention()
```

## å…¶ä»–èµ„æº

å¦‚æžœæ‚¨å¯¹åœ¨ SDXL ä¸­ä½¿ç”¨çš„ UNet2DConditionModel çš„æœ€å°ç‰ˆæœ¬è¿›è¡Œå®žéªŒæ„Ÿå…´è¶£ï¼Œè¯·æŸ¥çœ‹åœ¨ PyTorch ä¸­ç¼–å†™çš„å¹¶ä¸ŽðŸ¤— Diffusers ç›´æŽ¥å…¼å®¹çš„[minSDXL](https://github.com/cloneofsimo/minSDXL)å®žçŽ°ã€‚
