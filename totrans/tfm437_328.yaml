- en: Whisper
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Whisper
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/whisper](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/whisper)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/whisper](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/whisper)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The Whisper model was proposed in [Robust Speech Recognition via Large-Scale
    Weak Supervision](https://cdn.openai.com/papers/whisper.pdf) by Alec Radford,
    Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Whisper模型由Alec Radford、Jong Wook Kim、Tao Xu、Greg Brockman、Christine McLeavey、Ilya
    Sutskever在[通过大规模弱监督实现稳健语音识别](https://cdn.openai.com/papers/whisper.pdf)中提出。
- en: 'The abstract from the paper is the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要如下：
- en: '*We study the capabilities of speech processing systems trained simply to predict
    large amounts of transcripts of audio on the internet. When scaled to 680,000
    hours of multilingual and multitask supervision, the resulting models generalize
    well to standard benchmarks and are often competitive with prior fully supervised
    results but in a zeroshot transfer setting without the need for any finetuning.
    When compared to humans, the models approach their accuracy and robustness. We
    are releasing models and inference code to serve as a foundation for further work
    on robust speech processing.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们研究了简单训练以预测互联网上大量音频转录的语音处理系统的能力。当扩展到680,000小时的多语言和多任务监督时，得到的模型在标准基准上表现良好，并且通常与先前的完全监督结果竞争，但在零次迁移设置中无需任何微调。与人类相比，模型接近其准确性和稳健性。我们发布了模型和推理代码，以作为进一步研究稳健语音处理的基础。*'
- en: This model was contributed by [Arthur Zucker](https://huggingface.co/ArthurZ).
    The Tensorflow version of this model was contributed by [amyeroberts](https://huggingface.co/amyeroberts).
    The original code can be found [here](https://github.com/openai/whisper).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型由[Arthur Zucker](https://huggingface.co/ArthurZ)贡献。此模型的Tensorflow版本由[amyeroberts](https://huggingface.co/amyeroberts)贡献。原始代码可在[此处](https://github.com/openai/whisper)找到。
- en: Usage tips
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示
- en: The model usually performs well without requiring any finetuning.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型通常无需任何微调即可表现良好。
- en: The architecture follows a classic encoder-decoder architecture, which means
    that it relies on the [generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)
    function for inference.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该架构遵循经典的编码器-解码器架构，这意味着它依赖于[generate()](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationMixin.generate)函数进行推理。
- en: Inference is currently only implemented for short-form i.e. audio is pre-segmented
    into <=30s segments. Long-form (including timestamps) will be implemented in a
    future release.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前仅实现了短形式的推理，即音频被预分段为<=30秒的片段。长形式（包括时间戳）将在未来的版本中实现。
- en: One can use [WhisperProcessor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor)
    to prepare audio for the model, and decode the predicted ID’s back into text.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用[WhisperProcessor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor)来准备音频以供模型使用，并将预测的ID解码回文本。
- en: 'To convert the model and the processor, we recommend using the following:'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要转换模型和处理器，我们建议使用以下方法：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The script will automatically determine all necessary parameters from the OpenAI
    checkpoint. A `tiktoken` library needs to be installed to perform the conversion
    of the OpenAI tokenizer to the `tokenizers` version.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本将自动从OpenAI检查点确定所有必要的参数。需要安装`tiktoken`库以执行将OpenAI分词器转换为`tokenizers`版本的转换。
- en: Inference
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: 'Here is a step-by-step guide to transcribing an audio sample using a pre-trained
    Whisper model:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用预训练的Whisper模型转录音频样本的逐步指南：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Resources
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: A list of official Hugging Face and community (indicated by 🌎) resources to
    help you get started with Whisper. If you’re interested in submitting a resource
    to be included here, please feel free to open a Pull Request and we’ll review
    it! The resource should ideally demonstrate something new instead of duplicating
    an existing resource.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 官方Hugging Face和社区（由🌎表示）资源列表，可帮助您开始使用Whisper。如果您有兴趣提交资源以包含在此处，请随时提交拉取请求，我们将进行审核！资源应该展示一些新东西，而不是重复现有资源。
- en: 'A fork with a script to [convert a Whisper model in Hugging Face format to
    OpenAI format](https://github.com/zuazo-forks/transformers/blob/convert_hf_to_openai/src/transformers/models/whisper/convert_hf_to_openai.py).
    🌎 Usage example:'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含脚本的分支，用于[将Hugging Face格式的Whisper模型转换为OpenAI格式](https://github.com/zuazo-forks/transformers/blob/convert_hf_to_openai/src/transformers/models/whisper/convert_hf_to_openai.py)。🌎
    使用示例：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: WhisperConfig
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WhisperConfig
- en: '### `class transformers.WhisperConfig`'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.WhisperConfig`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/configuration_whisper.py#L62)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/configuration_whisper.py#L62)'
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_size` (`int`, *optional*, defaults to 51865) — Vocabulary size of the
    Whisper model. Defines the number of different tokens that can be represented
    by the `decoder_input_ids` passed when calling [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_size`（`int`，*可选*，默认为51865）— Whisper模型的词汇量。定义了在调用[WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)时可以由`decoder_input_ids`表示的不同标记数量。'
- en: '`num_mel_bins` (`int`, *optional*, defaults to 80) — Number of mel features
    used per input features. Should correspond to the value used in the `WhisperProcessor`
    class.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_mel_bins`（`int`，*可选*，默认为80）— 每个输入特征中使用的mel特征数量。应与`WhisperProcessor`类中使用的值对应。'
- en: '`encoder_layers` (`int`, *optional*, defaults to 4) — Number of encoder layers.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layers`（`int`，*可选*，默认为4）— 编码器层数。'
- en: '`decoder_layers` (`int`, *optional*, defaults to 4) — Number of decoder layers.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layers`（`int`，*可选*，默认为4）— 解码器层数。'
- en: '`encoder_attention_heads` (`int`, *optional*, defaults to 6) — Number of attention
    heads for each attention layer in the Transformer encoder.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attention_heads`（`int`，*可选*，默认为6）— Transformer编码器中每个注意力层的注意力头数。'
- en: '`decoder_attention_heads` (`int`, *optional*, defaults to 6) — Number of attention
    heads for each attention layer in the Transformer decoder.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_heads` (`int`, *optional*, 默认为6) — Transformer解码器中每个注意力层的注意力头数。'
- en: '`encoder_ffn_dim` (`int`, *optional*, defaults to 1536) — Dimensionality of
    the “intermediate” (often named feed-forward) layer in encoder.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_ffn_dim` (`int`, *optional*, 默认为1536) — 编码器中“中间”（通常称为前馈）层的维度。'
- en: '`decoder_ffn_dim` (`int`, *optional*, defaults to 1536) — Dimensionality of
    the “intermediate” (often named feed-forward) layer in decoder.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_ffn_dim` (`int`, *optional*, 默认为1536) — 解码器中“中间”（通常称为前馈）层的维度。'
- en: '`encoder_layerdrop` (`float`, *optional*, defaults to 0.0) — The LayerDrop
    probability for the encoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_layerdrop` (`float`, *optional*, 默认为0.0) — 编码器的LayerDrop概率。有关更多详细信息，请参阅[LayerDrop
    paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`decoder_layerdrop` (`float`, *optional*, defaults to 0.0) — The LayerDrop
    probability for the decoder. See the [LayerDrop paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))
    for more details.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_layerdrop` (`float`, *optional*, 默认为0.0) — 解码器的LayerDrop概率。有关更多详细信息，请参阅[LayerDrop
    paper](see [https://arxiv.org/abs/1909.11556](https://arxiv.org/abs/1909.11556))。'
- en: '`decoder_start_token_id` (`int`, *optional*, defaults to 50257) — Corresponds
    to the ”<|startoftranscript|>” token, which is automatically used when no `decoder_input_ids`
    are provided to the `generate` function. It is used to guide the model`s generation
    process depending on the task.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_start_token_id`（`int`，*optional*，默认为50257）--对应于`“<|startoftranscript|>”`标记，当没有向`generate`函数提供`decoder_input_ids`时，会自动使用该标记。它用于根据任务指导模型的生成过程。'
- en: '`use_cache` (`bool`, *optional*, defaults to `True`) — Whether or not the model
    should return the last key/values attentions (not used by all models).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*, 默认为`True`) — 模型是否应返回最后的键/值注意力（并非所有模型都使用）。'
- en: '`is_encoder_decoder` (`bool`, *optional*, defaults to `True`) — Whether the
    model is used as an encoder/decoder or not.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_encoder_decoder` (`bool`, *optional*, 默认为`True`) — 模型是否用作编码器/解码器。'
- en: '`activation_function` (`str`, *optional*, defaults to `"gelu"`) — The non-linear
    activation function (function or string) in the encoder and pooler. If string,
    `"gelu"`, `"relu"`, `"silu"` and `"gelu_new"` are supported.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_function` (`str`, *optional*, 默认为`"gelu"`) — 编码器和池化器中的非线性激活函数（函数或字符串）。如果是字符串，支持`"gelu"`、`"relu"`、`"silu"`和`"gelu_new"`。'
- en: '`d_model` (`int`, *optional*, defaults to 384) — Dimensionality of the layers.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d_model` (`int`, *optional*, 默认为384) — 层的维度。'
- en: '`dropout` (`float`, *optional*, defaults to 0.1) — The dropout probability
    for all fully connected layers in the embeddings, encoder, and pooler.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout` (`float`, *optional*, 默认为0.1) — 嵌入层、编码器和池化层中所有全连接层的丢弃概率。'
- en: '`attention_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for the attention probabilities.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_dropout` (`float`, *optional*, 默认为0.0) — 注意力概率的丢弃比率。'
- en: '`activation_dropout` (`float`, *optional*, defaults to 0.0) — The dropout ratio
    for activations inside the fully connected layer.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation_dropout` (`float`, *optional*, 默认为0.0) — 全连接层内部激活的丢弃比率。'
- en: '`init_std` (`float`, *optional*, defaults to 0.02) — The standard deviation
    of the truncated_normal_initializer for initializing all weight matrices.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_std` (`float`, *optional*, 默认为0.02) — 用于初始化所有权重矩阵的截断正态初始化器的标准差。'
- en: '`scale_embedding` (`bool`, *optional*, defaults to False) — Scale embeddings
    by diving by sqrt(d_model).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale_embedding` (`bool`, *optional*, 默认为False) — 通过除以sqrt(d_model)来缩放嵌入。'
- en: '`max_source_positions` (`int`, *optional*, defaults to 1500) — The maximum
    sequence length of log-mel filter-bank features that this model might ever be
    used with.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_source_positions` (`int`, *optional*, 默认为1500) — 该模型可能用于的对数梅尔滤波器组特征的最大序列长度。'
- en: '`max_target_positions` (`int`, *optional*, defaults to 448) — The maximum sequence
    length that this model might ever be used with. Typically set this to something
    large just in case (e.g., 512 or 1024 or 2048).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_target_positions` (`int`, *optional*, 默认为448) — 该模型可能用于的最大序列长度。通常将其设置为较大的值以防万一（例如512、1024或2048）。'
- en: '`pad_token_id` (`int`, *optional*, defaults to 50256) — Padding token id.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token_id` (`int`, *optional*, 默认为50256) — 填充标记id。'
- en: '`bos_token_id` (`int`, *optional*, defaults to 50256) — Begin of stream token
    id.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token_id` (`int`, *optional*, 默认为50256) — 流的开始标记id。'
- en: '`eos_token_id` (`int`, *optional*, defaults to 50256) — End of stream token
    id.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token_id` (`int`, *optional*, 默认为50256) — 流的结束标记id。'
- en: '`suppress_tokens` (`List[int]`, *optional*) — A list containing the non-speech
    tokens that will be used by the logit processor in the `generate` function. NON_SPEECH_TOKENS
    and NON_SPEECH_TOKENS_MULTI each correspond to the `english-only` and the `multilingual`
    model.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`suppress_tokens` (`List[int]`, *optional*) — 包含将在`generate`函数中由对数处理器使用的非语音标记的列表。NON_SPEECH_TOKENS和NON_SPEECH_TOKENS_MULTI分别对应于`english-only`和`multilingual`模型。'
- en: '`begin_suppress_tokens` (`List[int]`, *optional*, defaults to `[220,50256]`)
    — A list containing tokens that will be supressed at the beginning of the sampling
    process. Initialized as the token for `" "` (`blank_token_id`) and the `eos_token_id`'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`begin_suppress_tokens` (`List[int]`, *optional*, 默认为`[220,50256]`) — 包含在采样过程开始时将被抑制的标记的列表。初始化为`"
    "`（`blank_token_id`）和`eos_token_id`的标记。'
- en: '`use_weighted_layer_sum` (`bool`, *optional*, defaults to `False`) — Whether
    to use a weighted average of layer outputs with learned weights. Only relevant
    when using an instance of [WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_weighted_layer_sum` (`bool`, *optional*, 默认为`False`) — 是否使用带有学习权重的层输出的加权平均值。仅在使用[WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)的实例时相关。'
- en: '`classifier_proj_size` (`int`, *optional*, defaults to 256) — Dimensionality
    of the projection before token mean-pooling for classification. Only relevant
    when using an instance of [WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`classifier_proj_size` (`int`, *optional*, 默认为256) — 分类前的投影维度，用于标记均值池化。仅在使用[WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)的实例时相关。'
- en: '`apply_spec_augment` (`bool`, *optional*, defaults to `False`) — Whether to
    apply *SpecAugment* data augmentation to the outputs of the feature encoder. For
    reference see [SpecAugment: A Simple Data Augmentation Method for Automatic Speech
    Recognition](https://arxiv.org/abs/1904.08779).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apply_spec_augment` (`bool`, *optional*, defaults to `False`) — 是否将*SpecAugment*数据增强应用于特征编码器的输出。有关详细信息，请参阅[SpecAugment:
    A Simple Data Augmentation Method for Automatic Speech Recognition](https://arxiv.org/abs/1904.08779)。'
- en: '`mask_time_prob` (`float`, *optional*, defaults to 0.05) — Percentage (between
    0 and 1) of all feature vectors along the time axis which will be masked. The
    masking procecure generates `mask_time_prob*len(time_axis)/mask_time_length` independent
    masks over the axis. If reasoning from the propability of each feature vector
    to be chosen as the start of the vector span to be masked, *mask_time_prob* should
    be `prob_vector_start*mask_time_length`. Note that overlap may decrease the actual
    percentage of masked vectors. This is only relevant if `apply_spec_augment ==
    True`.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_time_prob` (`float`, *optional*, defaults to 0.05) — 沿时间轴的所有特征向量的百分比（介于0和1之间）将被掩盖。掩盖过程在轴上生成`mask_time_prob*len(time_axis)/mask_time_length`个独立的掩码。如果从每个特征向量被选择为要掩盖的向量跨度的起始的概率推理，*mask_time_prob*应为`prob_vector_start*mask_time_length`。请注意，重叠可能会降低掩盖向量的实际百分比。只有在`apply_spec_augment
    == True`时才相关。'
- en: '`mask_time_length` (`int`, *optional*, defaults to 10) — Length of vector span
    along the time axis.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_time_length` (`int`, *optional*, defaults to 10) — 沿时间轴的向量跨度长度。'
- en: '`mask_time_min_masks` (`int`, *optional*, defaults to 2), — The minimum number
    of masks of length `mask_feature_length` generated along the time axis, each time
    step, irrespectively of `mask_feature_prob`. Only relevant if ”mask_time_prob*len(time_axis)/mask_time_length
    < mask_time_min_masks”'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_time_min_masks` (`int`, *optional*, defaults to 2), — 沿时间轴生成的长度为`mask_feature_length`的掩码的最小数量，每个时间步，与`mask_feature_prob`无关。只有在”mask_time_prob*len(time_axis)/mask_time_length
    < mask_time_min_masks”时才相关。'
- en: '`mask_feature_prob` (`float`, *optional*, defaults to 0.0) — Percentage (between
    0 and 1) of all feature vectors along the feature axis which will be masked. The
    masking procecure generates `mask_feature_prob*len(feature_axis)/mask_time_length`
    independent masks over the axis. If reasoning from the propability of each feature
    vector to be chosen as the start of the vector span to be masked, *mask_feature_prob*
    should be `prob_vector_start*mask_feature_length`. Note that overlap may decrease
    the actual percentage of masked vectors. This is only relevant if `apply_spec_augment
    is True`.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_feature_prob` (`float`, *optional*, defaults to 0.0) — 沿特征轴的所有特征向量的百分比（介于0和1之间）将被掩盖。掩盖过程在轴上生成`mask_feature_prob*len(feature_axis)/mask_time_length`个独立的掩码。如果从每个特征向量被选择为要掩盖的向量跨度的起始的概率推理，*mask_feature_prob*应为`prob_vector_start*mask_feature_length`。请注意，重叠可能会降低掩盖向量的实际百分比。只有在`apply_spec_augment`为True时才相关。'
- en: '`mask_feature_length` (`int`, *optional*, defaults to 10) — Length of vector
    span along the feature axis.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_feature_length` (`int`, *optional*, defaults to 10) — 沿特征轴的向量跨度长度。'
- en: '`mask_feature_min_masks` (`int`, *optional*, defaults to 0), — The minimum
    number of masks of length `mask_feature_length` generated along the feature axis,
    each time step, irrespectively of `mask_feature_prob`. Only relevant if `mask_feature_prob*len(feature_axis)/mask_feature_length
    < mask_feature_min_masks`.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask_feature_min_masks` (`int`, *optional*, defaults to 0), — 沿特征轴生成的长度为`mask_feature_length`的掩码的最小数量，每个时间步，与`mask_feature_prob`无关。只有在`mask_feature_prob*len(feature_axis)/mask_feature_length
    < mask_feature_min_masks`时才相关。'
- en: '`median_filter_width` (`int`, *optional*, defaults to 7) — Width of the median
    filter used to smoothen to cross-attention outputs when computing token timestamps.
    Should be an odd number.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`median_filter_width` (`int`, *optional*, defaults to 7) — 用于在计算标记时间戳时平滑交叉注意力输出的中值滤波器的宽度。应为奇数。'
- en: This is the configuration class to store the configuration of a [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel).
    It is used to instantiate a Whisper model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the Whisper [openai/whisper-tiny](https://huggingface.co/openai/whisper-tiny)
    architecture.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于存储[WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)配置的配置类。它用于根据指定的参数实例化Whisper模型，定义模型架构。使用默认值实例化配置将产生类似于Whisper
    [openai/whisper-tiny](https://huggingface.co/openai/whisper-tiny)架构的配置。
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    and can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象继承自[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)，可用于控制模型输出。阅读[PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)的文档以获取更多信息。
- en: 'Example:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: WhisperTokenizer
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WhisperTokenizer
- en: '### `class transformers.WhisperTokenizer`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.WhisperTokenizer`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L217)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L217)'
- en: '[PRE5]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`vocab_file` (`str`) — Path to the vocabulary file.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vocab_file` (`str`) — 词汇文件的路径。'
- en: '`merges_file` (`str`) — Path to the merges file.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`merges_file` (`str`) — 合并文件的路径。'
- en: '`normalizer_file` (`str`, *optional*) — Path to the normalizer_file file.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalizer_file` (`str`, *optional*) — 正则化器文件的路径。'
- en: '`errors` (`str`, *optional*, defaults to `"replace"`) — Paradigm to follow
    when decoding bytes to UTF-8\. See [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode)
    for more information.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`errors`（`str`，*optional*，默认为`“replace”`）--将字节解码为UTF-8时要遵循的示例。请参阅[bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode)了解更多信息。'
- en: '`unk_token` (`str`, *optional*, defaults to `"<|endoftext|>"`) — The unknown
    token. A token that is not in the vocabulary cannot be converted to an ID and
    is set to be this token instead.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token`（`str`，*optional*，默认为`“<|endoftext|>”`）--未知令牌。词汇表中没有的令牌无法转换为ID，而是设置为该令牌。'
- en: '`bos_token` (`str`, *optional*, defaults to `"<|endoftext|>"`) — The beginning
    of sequence token. The `decoder_start_token_id` is used to set the first token
    as `"<|startoftranscript|>"` when generating.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token`（`str`，*optional*，默认为`“<|endoftext|>”`）--序列标记的开头。`decoder_start_token_id`用于在生成时将第一个令牌设置为`“<|startoftranscript|>”`。'
- en: '`eos_token` (`str`, *optional*, defaults to `"<|endoftext|>"`) — The end of
    sequence token.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token`（`str`，*optional*，默认为`“<|endoftext|>”`）--序列结束标记。'
- en: '`pad_token` (`str`, *optional*) — The token used for padding, for example when
    batching sequences of different lengths.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_token` (`str`, *optional*) — 用于填充的标记，例如在批处理不同长度的序列时。'
- en: '`add_prefix_space` (`bool`, *optional*, defaults to `False`) — Whether or not
    to add an initial space to the input. This allows to treat the leading word just
    as any other word.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_prefix_space` (`bool`, *optional*, defaults to `False`) — 是否在输入前添加一个初始空格。这允许将前导单词视为任何其他单词。'
- en: '`language` (`str`, *optional*) — The language of the transcription text. The
    corresponding language id token is appended to the start of the sequence for multilingual
    speech recognition and speech translation tasks, e.g. for Spanish the token `"<|es|>"`
    is appended to the start of sequence. This should be used for multilingual fine-tuning
    only.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language`（`str`，*可选*）--转录文本的语言。对于多语言语音识别和语音翻译任务，相应的语言id标记被附加到序列的开头，例如对于西班牙语，标记`“<|es|>”`被附加到顺序的开头。这只能用于多语言微调。'
- en: '`task` (`str`, *optional*) — Task identifier to append at the start of sequence
    (if any). This should be used for mulitlingual fine-tuning, with `"transcribe"`
    for speech recognition and `"translate"` for speech translation.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task`（`str`，*可选*）--要附加在序列开头的任务标识符（如果有）。这应用于多语言微调，`"transcribe"`用于语音识别，`"translate"`用于语音翻译。'
- en: '`predict_timestamps` (`bool`, *optional*, defaults to `False`) — Whether to
    omit the `<|notimestamps|>` token at the start of the sequence.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: predict_timestamps`（`bool`，*optional*，默认为`False`）--是否省略序列开头的`<|notimestamps|>`标记。
- en: Construct a Whisper tokenizer.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个Whisper tokenizer。
- en: This tokenizer inherits from [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)
    which contains some of the main methods. Users should refer to the superclass
    for more information regarding such methods.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分词器继承自 [PreTrainedTokenizer](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)，其中包含一些主要方法。用户应参考超类以获取有关这些方法的更多信息。
- en: '#### `set_prefix_tokens`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_prefix_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L389)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L389)'
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`language` (`str`, *optional*, defaults to `None`) — The language of the transcription
    text.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language`（`str`，*可选*，默认为 `None`）— 转录文本的语言。'
- en: '`task` (`str`, *optional*, defaults to `None`) — Task identifier to append
    at the start of sequence (if any).'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task`（`str`，*可选*，默认为 `None`）— 任务标识符，附加在序列开头（如果有）。'
- en: '`predict_timestamps` (`bool`, *optional*, defaults to `None`) — Whether to
    omit the `<|notimestamps|>` token at the start of the sequence.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict_timestamps`（`bool`，*optional*，默认为`None`）--是否省略序列开头的`<|notimestamps|>`标记。'
- en: Override the prefix tokens appended to the start of the label sequence. This
    method can be used standalone to
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖附加到标签序列开头的前缀标记。此方法可以独立使用以
- en: 'update the prefix tokens as required when fine-tuning. Example:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调时根据需要更新前缀标记。示例：
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `build_inputs_with_special_tokens`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L448)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L448)'
- en: '[PRE8]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Build model inputs from a sequence by appending eos_token_id.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 通过附加 eos_token_id 从序列构建模型输入。
- en: '#### `get_special_tokens_mask`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_special_tokens_mask`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L456)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L456)'
- en: '[PRE9]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）— ID 列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）— 序列对的可选第二个 ID 列表。'
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`already_has_special_tokens`（`bool`，*可选*，默认为 `False`）— 标记列表是否已经格式化为模型的特殊标记。'
- en: Returns
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一个整数列表，范围为 [0, 1]：1 表示特殊标记，0 表示序列标记。
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 从没有添加特殊标记的标记列表中检索序列 ID。在使用分词器的 `prepare_for_model` 方法添加特殊标记时调用此方法。
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3302)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3302)'
- en: '[PRE10]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Parameters
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — The first tokenized sequence.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）— 第一个标记化序列。'
- en: '`token_ids_1` (`List[int]`, *optional*) — The second tokenized sequence.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）— 第二个标记化序列。'
- en: Returns
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: The token type ids.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 标记类型 ID。
- en: Create the token type IDs corresponding to the sequences passed. [What are token
    type IDs?](../glossary#token-type-ids)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 创建与传递的序列对应的标记类型 ID。[什么是标记类型 ID？](../glossary#token-type-ids)
- en: Should be overridden in a subclass if the model has a special way of building
    those.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型有一种特殊的构建方式，则应在子类中重写它。
- en: '#### `save_vocabulary`'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_vocabulary`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L763)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L763)'
- en: '[PRE11]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#### `batch_decode`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3692)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3692)'
- en: '[PRE12]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Parameters
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sequences` (`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`)
    — List of tokenized input ids. Can be obtained using the `__call__` method.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequences`（`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`）—
    标记化输入 ID 的列表。可以使用 `__call__` 方法获取。'
- en: '`skip_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove special tokens in the decoding.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens`（`bool`，*可选*，默认为 `False`）— 是否在解码时删除特殊标记。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*) — Whether or not to clean
    up the tokenization spaces. If `None`, will default to `self.clean_up_tokenization_spaces`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces`（`bool`，*可选*）— 是否清理分词空格。如果为 `None`，将默认为 `self.clean_up_tokenization_spaces`。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    underlying model specific decode method.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）— 将传递给底层模型特定的解码方法。'
- en: Returns
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[str]`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[str]`'
- en: The list of decoded sentences.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 解码的句子列表。
- en: Convert a list of lists of token ids into a list of strings by calling decode.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用解码将标记 ID 的列表列表转换为字符串列表。
- en: '#### `decode`'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L639)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper.py#L639)'
- en: '[PRE13]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids` (`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`)
    — List of tokenized input ids. Can be obtained using the `__call__` method.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids`（`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`）—
    标记化输入 ID 的列表。可以使用 `__call__` 方法获取。'
- en: '`skip_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove special tokens in the decoding.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens`（`bool`，*可选*，默认为 `False`）— 是否在解码时删除特殊标记。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*) — Whether or not to clean
    up the tokenization spaces. If `None`, will default to `self.clean_up_tokenization_spaces`
    (available in the `tokenizer_config`).'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces`（`bool`，*可选*）— 是否清理分词空格。如果为 `None`，将默认为 `self.clean_up_tokenization_spaces`（在
    `tokenizer_config` 中可用）。'
- en: '`output_offsets` (`bool`, *optional*, defaults to `False`) — Whether or not
    to output the offsets of the tokens. This should only be set if the model predicted
    timestamps.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`time_precision` (`float`, `optional`, defaults to 0.02) — The time ratio to
    convert from token to time.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decode_with_timestamps` (`bool`, *optional*, defaults to `False`) — Whether
    or not to decode with timestamps included in the raw text.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`normalize` (`bool`, *optional*, defaults to `False`) — Whether or not to apply
    the English text normalizer to the decoded text. Only applicable when the target
    text is in English. Otherwise, the basic text normalizer should be applied.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`basic_normalize` (`bool`, *optional*, defaults to `False`) — Whether or not
    to apply the Basic text normalizer to the decoded text. Applicable to multilingual
    target text.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`remove_diacritics` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove diacritics when applying the Basic text normalizer. Removing diacritics
    may destroy information in the decoded text, hence it should be used with caution.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    underlying model specific decode method.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '`str`'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: The decoded sentence.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Converts a sequence of ids in a string, using the tokenizer and vocabulary with
    options to remove special tokens and clean up tokenization spaces.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Similar to doing `self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: WhisperTokenizerFast
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class transformers.WhisperTokenizerFast`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper_fast.py#L90)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '`vocab_file` (`str`, *optional*) — Path to the vocabulary file.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`merges_file` (`str`, *optional*) — Path to the merges file.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`normalizer_file` (`str`, *optional*) — Path to the normalizer_file file.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer_file` (`str`, *optional*) — Path to [tokenizers](https://github.com/huggingface/tokenizers)
    file (generally has a .json extension) that contains everything needed to load
    the tokenizer.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unk_token` (`str`, *optional*, defaults to `"<|endoftext|>"`) — The unknown
    token. A token that is not in the vocabulary cannot be converted to an ID and
    is set to be this token instead.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unk_token`（`str`，*optional*，默认为`“<|endoftext|>”`）--未知令牌。词汇表中没有的令牌无法转换为ID，而是设置为该令牌。'
- en: '`bos_token` (`str`, *optional*, defaults to `"<|endoftext|>"`) — The beginning
    of sequence token. The `decoder_start_token_id` is used to set the first token
    as `"<|startoftranscript|>"` when generating.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bos_token`（`str`，*optional*，默认为`“<|endoftext|>”`）--序列标记的开头。`decoder_start_token_id`用于在生成时将第一个令牌设置为`“<|startoftranscript|>”`。'
- en: '`eos_token` (`str`, *optional*, defaults to `"<|endoftext|>"`) — The end of
    sequence token.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token`（`str`，*optional*，默认为`“<|endoftext|>”`）--序列结束标记。'
- en: '`add_prefix_space` (`bool`, *optional*, defaults to `False`) — Whether or not
    to add an initial space to the input. This allows to treat the leading word just
    as any other word. (Whisper tokenizer detect beginning of words by the preceding
    space).'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`language` (`str`, *optional*) — The language of the transcription text. The
    corresponding language id token is appended to the start of the sequence for multilingual
    speech recognition and speech translation tasks, e.g. for Spanish the token `"<|es|>"`
    is appended to the start of sequence. This should be used for multilingual fine-tuning
    only.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language`（`str`，*可选*）--转录文本的语言。对于多语言语音识别和语音翻译任务，相应的语言id标记被附加到序列的开头，例如对于西班牙语，标记`"<|es|>"`被附加到顺序的开头。这只能用于多语言微调。'
- en: '`task` (`str`, *optional*) — Task identifier to append at the start of sequence
    (if any). This should be used for mulitlingual fine-tuning, with `"transcribe"`
    for speech recognition and `"translate"` for speech translation.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task`（`str`，*可选*）--要附加在序列开头的任务标识符（如果有）。这应用于多语言微调，“转录”用于语音识别，“翻译”用于语音翻译。'
- en: '`predict_timestamps` (`bool`, *optional*, defaults to `False`) — Whether to
    omit the `<|notimestamps|>` token at the start of the sequence.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict_timestamps`（`bool`，*optional*，默认为`False`）--是否省略序列开头的`<|notimestamps|>`标记。'
- en: Construct a “fast” Whisper tokenizer (backed by HuggingFace’s *tokenizers* library).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: This tokenizer inherits from [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '#### `set_prefix_tokens`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper_fast.py#L462)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '`language` (`str`, *optional*, defaults to `None`) — The language of the transcription
    text.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`task` (`str`, *optional*, defaults to `None`) — Task identifier to append
    at the start of sequence (if any).'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predict_timestamps` (`bool`, *optional*, defaults to `None`) — Whether to
    omit the `<|notimestamps|>` token at the start of the sequence.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict_timestamps`（`bool`，*optional*，默认为`None`）--是否省略序列开头的`<|notimestamps|>`标记。'
- en: Override the prefix tokens appended to the start of the label sequence. This
    method can be used standalone to
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'update the prefix tokens as required when fine-tuning. Example:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#### `build_inputs_with_special_tokens`'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper_fast.py#L536)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Build model inputs from a sequence by appending eos_token_id.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_special_tokens_mask`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper_fast.py#L544)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper_fast.py#L544)'
- en: '[PRE18]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — List of IDs.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）— ID列表。'
- en: '`token_ids_1` (`List[int]`, *optional*) — Optional second list of IDs for sequence
    pairs.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）— 序列对的第二个ID列表。'
- en: '`already_has_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether
    or not the token list is already formatted with special tokens for the model.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`already_has_special_tokens`（`bool`，*可选*，默认为`False`）— 标记列表是否已经使用特殊标记格式化为模型。'
- en: Returns
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: 'A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence
    token.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 整数列表在范围[0, 1]内：1表示特殊标记，0表示序列标记。
- en: Retrieve sequence ids from a token list that has no special tokens added. This
    method is called when adding special tokens using the tokenizer `prepare_for_model`
    method.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 从没有添加特殊标记的标记列表中检索序列ID。当使用tokenizer的`prepare_for_model`方法添加特殊标记时，将调用此方法。
- en: '#### `create_token_type_ids_from_sequences`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_token_type_ids_from_sequences`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3302)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3302)'
- en: '[PRE19]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parameters
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids_0` (`List[int]`) — The first tokenized sequence.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_0`（`List[int]`）— 第一个标记化序列。'
- en: '`token_ids_1` (`List[int]`, *optional*) — The second tokenized sequence.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids_1`（`List[int]`，*可选*）— 第二个标记化序列。'
- en: Returns
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[int]`'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[int]`'
- en: The token type ids.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 标记类型ID。
- en: Create the token type IDs corresponding to the sequences passed. [What are token
    type IDs?](../glossary#token-type-ids)
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 创建与传递的序列对应的标记类型ID。[什么是标记类型ID？](../glossary#token-type-ids)
- en: Should be overridden in a subclass if the model has a special way of building
    those.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型有特殊构建方式，则应在子类中重写。
- en: '#### `save_vocabulary`'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_vocabulary`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper_fast.py#L447)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper_fast.py#L447)'
- en: '[PRE20]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#### `batch_decode`'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3692)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/tokenization_utils_base.py#L3692)'
- en: '[PRE21]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Parameters
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sequences` (`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`)
    — List of tokenized input ids. Can be obtained using the `__call__` method.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sequences`（`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`）—
    标记化输入ID的列表。可以使用`__call__`方法获得。'
- en: '`skip_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove special tokens in the decoding.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens`（`bool`，*可选*，默认为`False`）— 是否在解码中删除特殊标记。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*) — Whether or not to clean
    up the tokenization spaces. If `None`, will default to `self.clean_up_tokenization_spaces`.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces`（`bool`，*可选*）— 是否清除标记空格。如果为`None`，将默认为`self.clean_up_tokenization_spaces`。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    underlying model specific decode method.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（其他关键字参数，*可选*）— 将传递给底层模型特定解码方法。'
- en: Returns
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[str]`'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[str]`'
- en: The list of decoded sentences.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 解码句子的列表。
- en: Convert a list of lists of token ids into a list of strings by calling decode.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用解码将标记ID列表的列表转换为字符串列表。
- en: '#### `decode`'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper_fast.py#L338)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/tokenization_whisper_fast.py#L338)'
- en: '[PRE22]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`token_ids` (`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`)
    — List of tokenized input ids. Can be obtained using the `__call__` method.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_ids`（`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`）—
    标记化输入ID的列表。可以使用`__call__`方法获得。'
- en: '`skip_special_tokens` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove special tokens in the decoding.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip_special_tokens`（`bool`，*可选*，默认为`False`）— 是否在解码中删除特殊标记。'
- en: '`clean_up_tokenization_spaces` (`bool`, *optional*) — Whether or not to clean
    up the tokenization spaces. If `None`, will default to `self.clean_up_tokenization_spaces`
    (available in the `tokenizer_config`).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_up_tokenization_spaces`（`bool`，*可选*）— 是否清除标记空格。如果为`None`，将默认为`self.clean_up_tokenization_spaces`（在`tokenizer_config`中可用）。'
- en: '`output_offsets` (`bool`, *optional*, defaults to `False`) — Whether or not
    to output the offsets of the tokens. This should only be set if the model predicted
    timestamps.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_offsets`（`bool`，*可选*，默认为`False`）— 是否输出标记的偏移量。只有在模型预测时间戳时才应设置此选项。'
- en: '`time_precision` (`float`, `optional`, defaults to 0.02) — The time ratio to
    convert from token to time.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_precision`（`float`，`可选`，默认为0.02）— 从标记到时间的转换时间比率。'
- en: '`decode_with_timestamps` (`bool`, *optional*, defaults to `False`) — Whether
    or not to decode with timestamps included in the raw text.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decode_with_timestamps`（`bool`，*可选*，默认为`False`）— 是否在原始文本中包含时间戳进行解码。'
- en: '`normalize` (`bool`, *optional*, defaults to `False`) — Whether or not to apply
    the English text normalizer to the decoded text. Only applicable when the target
    text is in English. Otherwise, the basic text normalizer should be applied.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`normalize`（`bool`，*可选*，默认为`False`）— 是否对解码文本应用英文文本规范化。仅在目标文本为英文时适用。否则，应应用基本文本规范化。'
- en: '`basic_normalize` (`bool`, *optional*, defaults to `False`) — Whether or not
    to apply the Basic text normalizer to the decoded text. Applicable to multilingual
    target text.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`basic_normalize`（`bool`，*可选*，默认为`False`）— 是否对解码文本应用基本文本规范化。适用于多语言目标文本。'
- en: '`remove_diacritics` (`bool`, *optional*, defaults to `False`) — Whether or
    not to remove diacritics when applying the Basic text normalizer. Removing diacritics
    may destroy information in the decoded text, hence it should be used with caution.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`remove_diacritics`（`bool`，*可选*，默认为`False`）— 是否在应用基本文本规范化时删除变音符号。删除变音符号可能会破坏解码文本中的信息，因此应谨慎使用。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Will be passed to the
    underlying model specific decode method.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*）- 将传递给底层模型特定的解码方法。'
- en: Returns
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The decoded sentence.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 解码后的句子。
- en: Converts a sequence of ids in a string, using the tokenizer and vocabulary with
    options to remove special tokens and clean up tokenization spaces.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 将字符串中的ids序列转换为字符串，使用tokenizer和词汇表，可选择删除特殊标记并清理标记化空格。
- en: Similar to doing `self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于执行`self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`。
- en: WhisperFeatureExtractor
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WhisperFeatureExtractor
- en: '### `class transformers.WhisperFeatureExtractor`'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.WhisperFeatureExtractor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/feature_extraction_whisper.py#L35)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/feature_extraction_whisper.py#L35)'
- en: '[PRE23]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Parameters
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`feature_size` (`int`, defaults to 80) — The feature dimension of the extracted
    features.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_size`（`int`，默认为80）- 提取特征的特征维度。'
- en: '`sampling_rate` (`int`, defaults to 16000) — The sampling rate at which the
    audio files should be digitalized expressed in hertz (Hz).'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate`（`int`，默认为16000）- 音频文件应数字化的采样率，以赫兹（Hz）表示。'
- en: '`hop_length` (`int`, defaults to 160) — Length of the overlaping windows for
    the STFT used to obtain the Mel Frequency coefficients.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hop_length`（`int`，默认为160）- 用于获取梅尔频率系数的STFT的重叠窗口的长度。'
- en: '`chunk_length` (`int`, defaults to 30) — The maximum number of chuncks of `sampling_rate`
    samples used to trim and pad longer or shorter audio sequences.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunk_length`（`int`，默认为30）- 用于修剪和填充较长或较短音频序列的`sampling_rate`样本的最大块数。'
- en: '`n_fft` (`int`, defaults to 400) — Size of the Fourier transform.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_fft`（`int`，默认为400）- 傅立叶变换的大小。'
- en: '`padding_value` (`float`, *optional*, defaults to 0.0) — Padding value used
    to pad the audio. Should correspond to silences.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_value`（`float`，*可选*，默认为0.0）- 用于填充音频的填充值。应对应于静音。'
- en: Constructs a Whisper feature extractor.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个Whisper特征提取器。
- en: This feature extractor inherits from [SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)
    which contains most of the main methods. Users should refer to this superclass
    for more information regarding those methods.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 该特征提取器继承自[SequenceFeatureExtractor](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor)，其中包含大部分主要方法。用户应参考此超类以获取有关这些方法的更多信息。
- en: This class extracts mel-filter bank features from raw speech using a custom
    numpy implementation of the `Short Time Fourier Transform` which should match
    pytorch’s `torch.stft` equivalent.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 该类使用自定义的numpy实现从原始语音中提取mel滤波器组特征，该实现应与pytorch的`torch.stft`等效。
- en: '#### `__call__`'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/feature_extraction_whisper.py#L157)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/feature_extraction_whisper.py#L157)'
- en: '[PRE24]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`raw_speech` (`np.ndarray`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`)
    — The sequence or batch of sequences to be padded. Each sequence can be a numpy
    array, a list of float values, a list of numpy arrays or a list of list of float
    values. Must be mono channel audio, not stereo, i.e. single float per timestep.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`raw_speech`（`np.ndarray`，`List[float]`，`List[np.ndarray]`，`List[List[float]]`）-
    要填充的序列或序列批次。每个序列可以是numpy数组，浮点值列表，numpy数组列表或浮点值列表的列表。必须是单声道音频，不是立体声，即每个时间步长一个浮点数。'
- en: '`truncation` (`bool`, *optional*, default to `True`) — Activates truncation
    to cut input sequences longer than *max_length* to *max_length*.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`（`bool`，*可选*，默认为`True`）- 激活截断以将输入序列截断为*max_length*以上的长度为*max_length*。'
- en: '`pad_to_multiple_of` (`int`, *optional*, defaults to None) — If set will pad
    the sequence to a multiple of the provided value.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad_to_multiple_of`（`int`，*可选*，默认为None）- 如果设置，将填充序列到提供的值的倍数。'
- en: This is especially useful to enable the use of Tensor Cores on NVIDIA hardware
    with compute capability `>= 7.5` (Volta), or on TPUs which benefit from having
    sequence lengths be a multiple of 128.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这对于启用NVIDIA硬件上的Tensor Cores特别有用，其计算能力为`>= 7.5`（Volta），或者对于受益于序列长度为128的TPUs。
- en: '`return_attention_mask` (`bool`, *optional*) — Whether to return the attention
    mask. If left to the default, will return the attention mask according to the
    specific feature_extractor’s default.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_attention_mask`（`bool`，*可选*）- 是否返回注意力掩码。如果保持默认设置，将根据特定feature_extractor的默认设置返回注意力掩码。'
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: For Whisper models, `attention_mask` should always be passed for batched inference,
    to avoid subtle bugs.
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于Whisper模型，批量推理时应始终传递`attention_mask`，以避免细微的错误。
- en: '`return_tensors` (`str` or [TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType),
    *optional*) — If set, will return tensors instead of list of python integers.
    Acceptable values are:'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_tensors`（`str`或[TensorType](/docs/transformers/v4.37.2/en/internal/file_utils#transformers.TensorType)，*可选*）-
    如果设置，将返回张量而不是Python整数列表。可接受的值为：'
- en: '`''tf''`: Return TensorFlow `tf.constant` objects.'
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''tf''`：返回TensorFlow `tf.constant`对象。'
- en: '`''pt''`: Return PyTorch `torch.Tensor` objects.'
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pt''`：返回PyTorch `torch.Tensor`对象。'
- en: '`''np''`: Return Numpy `np.ndarray` objects.'
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''np''`：返回Numpy `np.ndarray`对象。'
- en: '`sampling_rate` (`int`, *optional*) — The sampling rate at which the `raw_speech`
    input was sampled. It is strongly recommended to pass `sampling_rate` at the forward
    call to prevent silent errors and allow automatic speech recognition pipeline.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sampling_rate`（`int`，*可选*）- `raw_speech`输入采样的采样率。强烈建议在前向调用时传递`sampling_rate`，以防止静默错误并允许自动语音识别流水线。'
- en: '`padding_value` (`float`, defaults to 0.0) — The value that is used to fill
    the padding values / vectors.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding_value`（`float`，默认为0.0）- 用于填充填充值/向量的值。'
- en: '`do_normalize` (`bool`, *optional*, defaults to `False`) — Whether or not to
    zero-mean unit-variance normalize the input. Normalizing can help to significantly
    improve the performance of the model.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_normalize`（`bool`，*可选*，默认为`False`）— 是否对输入进行零均值单位方差归一化。归一化可以帮助显著提高模型的性能。'
- en: Main method to featurize and prepare for the model one or several sequence(s).
    Implementation uses PyTorch for the STFT computation if available, otherwise a
    slower NumPy based one.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 用于对一个或多个序列进行特征化和准备模型的主要方法。如果可用，实现使用PyTorch进行STFT计算，否则使用较慢的基于NumPy的方法。
- en: WhisperProcessor
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WhisperProcessor
- en: '### `class transformers.WhisperProcessor`'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.WhisperProcessor`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/processing_whisper.py#L23)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/processing_whisper.py#L23)'
- en: '[PRE25]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Parameters
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`feature_extractor` (`WhisperFeatureExtractor`) — An instance of [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor).
    The feature extractor is a required input.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_extractor`（`WhisperFeatureExtractor`）— [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)的一个实例。特征提取器是必需的输入。'
- en: '`tokenizer` (`WhisperTokenizer`) — An instance of [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer).
    The tokenizer is a required input.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`（`WhisperTokenizer`）— [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)的一个实例。分词器是必需的输入。'
- en: Constructs a Whisper processor which wraps a Whisper feature extractor and a
    Whisper tokenizer into a single processor.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个Whisper处理器，将Whisper特征提取器和Whisper分词器包装成一个单一处理器。
- en: '[WhisperProcessor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor)
    offers all the functionalities of [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)
    and [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer).
    See the [**call**()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor.__call__)
    and [decode()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor.decode)
    for more information.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '[WhisperProcessor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor)提供了[WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)和[WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)的所有功能。有关更多信息，请参阅[**call**()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor.__call__)和[decode()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperProcessor.decode)。'
- en: '#### `__call__`'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/processing_whisper.py#L49)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/processing_whisper.py#L49)'
- en: '[PRE26]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Forwards the `audio` argument to WhisperFeatureExtractor’s [**call**()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)
    and the `text` argument to [**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__).
    Please refer to the doctsring of the above two methods for more information.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 将`audio`参数转发到WhisperFeatureExtractor的[**call**()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)，将`text`参数转发到[**call**()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。请参阅上述两种方法的文档字符串以获取更多信息。
- en: '#### `from_pretrained`'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L406)'
- en: '[PRE27]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parameters
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`pretrained_model_name_or_path` (`str` or `os.PathLike`) — This can be either:'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`（`str`或`os.PathLike`）— 这可以是：'
- en: a string, the *model id* of a pretrained feature_extractor hosted inside a model
    repo on huggingface.co. Valid model ids can be located at the root-level, like
    `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，预训练特征提取器的*模型ID*，托管在huggingface.co上的模型存储库内。有效的模型ID可以位于根级别，如`bert-base-uncased`，或者命名空间下的用户或组织名称，如`dbmdz/bert-base-german-cased`。
- en: a path to a *directory* containing a feature extractor file saved using the
    [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    method, e.g., `./my_model_directory/`.
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含使用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)方法保存的特征提取器文件的*目录*路径，例如，`./my_model_directory/`。
- en: a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
    **kwargs — Additional keyword arguments passed along to both [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)
    and `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`.
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存的特征提取器JSON *文件*的路径或URL，例如，`./my_model_directory/preprocessor_config.json`。**kwargs
    — 传递给[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)和`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`的其他关键字参数。
- en: Instantiate a processor associated with a pretrained model.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化与预训练模型相关联的处理器。
- en: This class method is simply calling the feature extractor [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained),
    image processor [ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)
    and the tokenizer `~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`
    methods. Please refer to the docstrings of the methods above for more information.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类方法只是调用特征提取器的[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained)、图像处理器[ImageProcessingMixin](/docs/transformers/v4.37.2/en/internal/image_processing_utils#transformers.ImageProcessingMixin)和分词器`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`方法。有关更多信息，请参阅上述方法的文档字符串。
- en: '#### `save_pretrained`'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `save_pretrained`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/processing_utils.py#L167)'
- en: '[PRE28]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`save_directory` (`str` or `os.PathLike`) — Directory where the feature extractor
    JSON file and the tokenizer files will be saved (directory will be created if
    it does not exist).'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_directory`（`str`或`os.PathLike`）—要保存特征提取器JSON文件和分词器文件的目录（如果目录不存在，则将创建该目录）。'
- en: '`push_to_hub` (`bool`, *optional*, defaults to `False`) — Whether or not to
    push your model to the Hugging Face model hub after saving it. You can specify
    the repository you want to push to with `repo_id` (will default to the name of
    `save_directory` in your namespace).'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push_to_hub`（`bool`，*可选*，默认为`False`）—保存模型后是否将其推送到Hugging Face模型中心。您可以使用`repo_id`指定要推送到的存储库（将默认为您的命名空间中的`save_directory`名称）。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Additional key word arguments passed
    along to the [push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)
    method.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（`Dict[str, Any]`，*可选*）—传递给[push_to_hub()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.push_to_hub)方法的额外关键字参数。'
- en: Saves the attributes of this processor (feature extractor, tokenizer…) in the
    specified directory so that it can be reloaded using the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)
    method.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 将此处理器的属性（特征提取器、分词器等）保存在指定目录中，以便可以使用[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained)方法重新加载它。
- en: This class method is simply calling [save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)
    and [save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained).
    Please refer to the docstrings of the methods above for more information.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 此类方法只是调用[save_pretrained()](/docs/transformers/v4.37.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained)和[save_pretrained()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained)。请参考上述方法的文档字符串以获取更多信息。
- en: '#### `batch_decode`'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `batch_decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/processing_whisper.py#L83)'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/processing_whisper.py#L83)'
- en: '[PRE29]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This method forwards all its arguments to WhisperTokenizer’s [batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode).
    Please refer to the docstring of this method for more information.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法将其所有参数转发到WhisperTokenizer的[batch_decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)。请参考此方法的文档字符串以获取更多信息。
- en: '#### `decode`'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `decode`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/processing_whisper.py#L90)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/processing_whisper.py#L90)'
- en: '[PRE30]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This method forwards all its arguments to WhisperTokenizer’s [decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode).
    Please refer to the docstring of this method for more information.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法将其所有参数转发到WhisperTokenizer的[decode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.decode)。请参考此方法的文档字符串以获取更多信息。
- en: PytorchHide Pytorch content
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: PytorchHide Pytorch内容
- en: WhisperModel
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WhisperModel
- en: '### `class transformers.WhisperModel`'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.WhisperModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1488)'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1488)'
- en: '[PRE31]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）—具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The bare Whisper Model outputting raw hidden-states without any specific head
    on top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的Whisper模型输出原始隐藏状态，没有特定的头部。此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型也是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取所有与一般用法和行为相关的事项。
- en: '#### `forward`'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1563)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1563)'
- en: '[PRE32]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, feature_size,
    sequence_length)`) — Float values mel features extracted from the raw speech waveform.
    Raw speech waveform can be obtained by loading a `.flac` or `.wav` audio file
    into an array of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile
    library (`pip install soundfile`). To prepare the array into `input_features`,
    the [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)
    should be used for extracting the mel features, padding and conversion into a
    tensor of type `torch.FloatTensor`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（形状为`(batch_size, feature_size, sequence_length)`的`torch.FloatTensor`）-
    从原始语音波形中提取的浮点值mel特征。原始语音波形可以通过将`.flac`或`.wav`音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中获得，例如通过soundfile库（`pip
    install soundfile`）。要准备好数组为`input_features`，应使用[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)来提取mel特征，填充并转换为`torch.FloatTensor`类型的张量。请参阅[`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
- en: '`attention_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing *SpecAugment* data augmentation on padding
    token indices. Mask values selected in `[0, 1]`:'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）-
    用于避免在填充标记索引上执行*SpecAugment*数据增强的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 for tokens that are `not masked`,
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示标记未被`掩码`，
- en: 0 for tokens that are `masked`.
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示标记被`掩码`。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[注意力掩码是什么？](../glossary#attention-mask)'
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）-
    解码器输入序列标记在词汇表中的索引。'
- en: Indices can be obtained using [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)来获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[解码器输入ID是什么？](../glossary#decoder-input-ids)'
- en: Whisper uses the `decoder_start_token_id` as the starting token for `decoder_input_ids`
    generation. If `past_key_values` is used, optionally only the last `decoder_input_ids`
    have to be input (see `past_key_values`).
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Whisper使用`decoder_start_token_id`作为`decoder_input_ids`生成的起始标记。如果使用`past_key_values`，则可以选择仅输入最后的`decoder_input_ids`（请参阅`past_key_values`）。
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）-
    默认行为：生成一个忽略`decoder_input_ids`中填充标记的张量。因果掩码也将默认使用。'
- en: If you want to change padding behavior, you should read `modeling_whisper._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the BART paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您想要更改填充行为，您应该阅读`modeling_whisper._prepare_decoder_attention_mask`并根据您的需求进行修改。有关默认策略的更多信息，请参阅[BART论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(encoder_layers, encoder_attention_heads)`的`torch.Tensor`，*可选*）-
    用于将编码器中注意力模块的选定头部置零的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-344
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`掩码`，
- en: 0 indicates the head is `masked`.
  id: totrans-345
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`掩码`。
- en: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）-
    用于将解码器中注意力模块的选定头部置零的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-347
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`掩码`，
- en: 0 indicates the head is `masked`.
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`掩码`。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）-
    用于将交叉注意力模块的选定头部置零的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被`掩码`，
- en: 0 indicates the head is `masked`.
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被`掩码`。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs`（`tuple(tuple(torch.FloatTensor)`，*可选*）- 元组包括(`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`)
    `last_hidden_state`的形状为`(batch_size, sequence_length, hidden_size)`，*可选*）是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *可选*，当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，用户可以选择仅输入最后一个形状为`(batch_size, 1)`的`decoder_input_ids`（那些没有将其过去的键值状态提供给此模型的输入）而不是形状为`(batch_size,
    sequence_length)`的所有`decoder_input_ids`。
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`torch.FloatTensor`，形状为`(batch_size, target_sequence_length,
    hidden_size)`，*可选*) — 可选地，可以直接传递嵌入表示，而不是传递`decoder_input_ids`。如果使用了`past_key_values`，可以选择仅输入最后一个`decoder_inputs_embeds`（参见`past_key_values`）。如果您希望更多地控制如何将`decoder_input_ids`索引转换为相关向量，而不是模型的内部嵌入查找矩阵，则这很有用。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *可选*) — 如果设置为`True`，将返回`past_key_values`键值状态，并可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量中的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: Returns
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    and inputs.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.Seq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）和输入的不同元素。
- en: '`last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`) — 模型解码器最后一层的隐藏状态序列输出。'
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，则输出形状为`(batch_size, 1, hidden_size)`的序列的最后一个隐藏状态。
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *可选*，当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型具有嵌入层，则为嵌入的输出+每层的输出）。'
- en: Hidden-states of the decoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`，*optional*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the encoder at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)
    forward method, overrides the `__call__` special method.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '[WhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperModel)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的方法需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行前处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE33]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '#### `_mask_input_features`'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `_mask_input_features`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1520)'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1520)'
- en: '[PRE34]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Masks extracted features along time axis and/or along feature axis according
    to [SpecAugment](https://arxiv.org/abs/1904.08779).
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[SpecAugment](https://arxiv.org/abs/1904.08779)沿时间轴和/或特征轴掩盖提取的特征。
- en: WhisperForConditionalGeneration
  id: totrans-387
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WhisperForConditionalGeneration
- en: '### `class transformers.WhisperForConditionalGeneration`'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.WhisperForConditionalGeneration`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1658)'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1658)'
- en: '[PRE35]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The Whisper Model with a language modeling head. Can be used for automatic speech
    recognition. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头的Whisper模型。可用于自动语音识别。此模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型还是PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1696)'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1696)'
- en: '[PRE36]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Parameters
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, feature_size,
    sequence_length)`) — Float values mel features extracted from the raw speech waveform.
    Raw speech waveform can be obtained by loading a `.flac` or `.wav` audio file
    into an array of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile
    library (`pip install soundfile`). To prepare the array into `input_features`,
    the [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)
    should be used for extracting the mel features, padding and conversion into a
    tensor of type `torch.FloatTensor`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（形状为`(batch_size, feature_size, sequence_length)`的`torch.FloatTensor`）-
    从原始语音波形中提取的浮点值mel特征。原始语音波形可以通过将`.flac`或`.wav`音频文件加载到类型为`List[float]`或`numpy.ndarray`的数组中获得，例如通过soundfile库（`pip
    install soundfile`）。要将数组准备成`input_features`，应使用[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)来提取mel特征，填充并转换为`torch.FloatTensor`类型的张量。参见[`call()`](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
- en: '`attention_mask` (`torch.LongTensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing *SpecAugment* data augmentation on padding
    token indices. Mask values selected in `[0, 1]`:'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）-
    用于避免在填充标记索引上执行*SpecAugment*数据增强的掩码。掩码值选定在`[0, 1]`范围内：'
- en: 1 for tokens that are `not masked`,
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部`未被掩盖`,
- en: 0 for tokens that are `masked`.
  id: totrans-402
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示`被掩盖`的标记。
- en: '[What are attention masks?](../glossary#attention-mask)'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是注意力掩码？](../glossary#attention-mask)'
- en: '`decoder_input_ids` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）-
    词汇表中解码器输入序列标记的索引。'
- en: Indices can be obtained using [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用[WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)获取索引。有关详细信息，请参见[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是解码器输入ID？](../glossary#decoder-input-ids)'
- en: Whisper uses the `decoder_start_token_id` as the starting token for `decoder_input_ids`
    generation. If `past_key_values` is used, optionally only the last `decoder_input_ids`
    have to be input (see `past_key_values`).
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Whisper使用`decoder_start_token_id`作为`decoder_input_ids`生成的起始标记。如果使用`past_key_values`，则可能只需输入最后的`decoder_input_ids`（请参见`past_key_values`）。
- en: '`decoder_attention_mask` (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（形状为`(batch_size, target_sequence_length)`的`torch.LongTensor`，*可选*）-
    默认行为：生成一个忽略`decoder_input_ids`中填充标记的张量。因果掩码也将默认使用。'
- en: If you want to change padding behavior, you should read `modeling_whisper._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the BART paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，应阅读`modeling_whisper._prepare_decoder_attention_mask`并根据需要进行修改。有关默认策略的更多信息，请参见[BART论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(encoder_layers, encoder_attention_heads)`的`torch.Tensor`，*可选*）-
    用于在编码器中使注意力模块的选定头部失效的掩码。掩码值选定在`[0, 1]`范围内：'
- en: 1 indicates the head is `not masked`,
  id: totrans-411
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部`未被掩盖`,
- en: 0 indicates the head is `masked`.
  id: totrans-412
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部`被掩盖`。
- en: '`decoder_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）-
    用于在解码器中使注意力模块的选定头部失效的掩码。掩码值选定在`[0, 1]`范围内：'
- en: 1 indicates the head is `not masked`,
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部`未被掩盖`,
- en: 0 indicates the head is `masked`.
  id: totrans-415
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部`被掩盖`。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`torch.Tensor`，*可选*）-
    用于使交叉注意力模块的选定头部失效的掩码。掩码值选定在`[0, 1]`范围内：'
- en: 1 indicates the head is `not masked`,
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部`未被掩盖`,
- en: 0 indicates the head is `masked`.
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部`被掩盖`。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.
    Used in the cross-attention of the decoder.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs`（`tuple(tuple(torch.FloatTensor)`，*可选*）— 元组包含（`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`）`last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*可选*是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）—
    元组由长度为`config.n_layers`的`tuple(torch.FloatTensor)`组成，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量，以及2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择只输入最后一个形状为`(batch_size, 1)`的`decoder_input_ids`（那些没有将它们的过去键值状态提供给此模型的输入），而不是形状为`(batch_size,
    sequence_length)`的所有`decoder_input_ids`。
- en: '`decoder_inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds`（形状为`(batch_size, target_sequence_length, hidden_size)`的`torch.FloatTensor`，*可选*）—
    可选地，可以直接传递嵌入表示，而不是传递`decoder_input_ids`。如果使用`past_key_values`，可以选择仅输入最后一个`decoder_inputs_embeds`（参见`past_key_values`）。如果您想要更多控制如何将`decoder_input_ids`索引转换为相关向量，而不是模型内部的嵌入查找矩阵，则这很有用。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*）— 如果设置为`True`，将返回`past_key_values`键值状态，并可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the language modeling loss. Indices should either be in
    `[0, ..., config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with
    indices set to `-100` are ignored (masked), the loss is only computed for the
    tokens with labels in `[0, ..., config.vocab_size]`.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, sequence_length)`的`torch.LongTensor`，*可选*）— 用于计算语言建模损失的标签。索引应该在`[0,
    ..., config.vocab_size]`范围内，或者为-100（参见`input_ids`文档字符串）。索引设置为`-100`的标记将被忽略（掩盖），损失仅计算具有`[0,
    ..., config.vocab_size]`标签的标记。'
- en: Returns
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    and inputs.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.Seq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）和输入的不同元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(1,)`的`torch.FloatTensor`，*可选*，在提供`labels`时返回）— 语言建模损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`torch.FloatTensor`）—
    语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(torch.FloatTensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可以用于加速顺序解码（参见`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出和每一层的输出）。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器在每一层输出的隐藏状态加上初始嵌入输出。
- en: '`decoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`torch.FloatTensor`，形状为`(batch_size, sequence_length,
    hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    — Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组（如果模型有嵌入层，则为嵌入输出和每一层的输出）。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层输出的隐藏状态加上初始嵌入输出。
- en: '`encoder_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) —
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组（每层一个）。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration)
    forward method, overrides the `__call__` special method.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '[WhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传播的步骤需要在此函数内定义，但应该在之后调用`Module`实例，而不是这个，因为前者会处理运行前后的预处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE37]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '#### `generate`'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/generation_whisper.py#L250)'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/generation_whisper.py#L250)'
- en: '[PRE38]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Parameters
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.Tensor` of shape `(batch_size, feature_size, sequence_length)`,
    *optional*) — Float values of log-mel features extracted from the raw speech waveform.
    The raw speech waveform can be obtained by loading a `.flac` or `.wav` audio file
    into an array of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile
    library (`pip install soundfile`). To prepare the array into `input_features`,
    the [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)
    should be used for extracting the mel features, padding and conversion into a
    tensor of type `torch.FloatTensor`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)
    for details.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（`torch.Tensor`，形状为`(batch_size, feature_size, sequence_length)`，*可选*）—
    浮点值的对数梅尔特征，从原始语音波形中提取。原始语音波形可以通过将`.flac`或`.wav`音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中获得，*例如*通过soundfile库（`pip
    install soundfile`）。要将数组准备成`input_features`，应使用[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)来提取梅尔特征，填充并转换为`torch.FloatTensor`类型的张量。详细信息请参见[`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)。'
- en: '`generation_config` (`~generation.GenerationConfig`, *optional*) — The generation
    configuration to be used as base parametrization for the generation call. `**kwargs`
    passed to generate matching the attributes of `generation_config` will override
    them. If `generation_config` is not provided, the default will be used, which
    had the following loading priority: 1) from the `generation_config.json` model
    file, if it exists; 2) from the model configuration. Please note that unspecified
    parameters will inherit [GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)’s
    default values, whose documentation should be checked to parameterize generation.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generation_config`（`~generation.GenerationConfig`，*可选*）— 用作生成调用的基本参数化的生成配置。传递给生成的`**kwargs`与`generation_config`的属性匹配将覆盖它们。如果未提供`generation_config`，将使用默认值，其加载优先级如下：1）从`generation_config.json`模型文件中，如果存在；2）从模型配置中。请注意，未指定的参数将继承[GenerationConfig](/docs/transformers/v4.37.2/en/main_classes/text_generation#transformers.GenerationConfig)的默认值，应检查其文档以参数化生成。'
- en: '`logits_processor` (`LogitsProcessorList`, *optional*) — Custom logits processors
    that complement the default logits processors built from arguments and generation
    config. If a logit processor is passed that is already created with the arguments
    or a generation config an error is thrown. This feature is intended for advanced
    users.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits_processor`（`LogitsProcessorList`，*可选*）— 自定义对数处理器，补充由参数和生成配置构建的默认对数处理器。如果传递的对数处理器已经使用参数或生成配置创建，则会引发错误。此功能适用于高级用户。'
- en: '`stopping_criteria` (`StoppingCriteriaList`, *optional*) — Custom stopping
    criteria that complement the default stopping criteria built from arguments and
    a generation config. If a stopping criteria is passed that is already created
    with the arguments or a generation config an error is thrown. This feature is
    intended for advanced users.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stopping_criteria`（`StoppingCriteriaList`，*可选*）— 自定义停止标准，补充由参数和生成配置构建的默认停止标准。如果传递的停止标准已经使用参数或生成配置创建，则会引发错误。此功能适用于高级用户。'
- en: '`prefix_allowed_tokens_fn` (`Callable[[int, torch.Tensor], List[int]]`, *optional*)
    — If provided, this function constraints the beam search to allowed tokens only
    at each step. If not provided no constraint is applied. This function takes 2
    arguments: the batch ID `batch_id` and `input_ids`. It has to return a list with
    the allowed tokens for the next generation step conditioned on the batch ID `batch_id`
    and the previously generated tokens `inputs_ids`. This argument is useful for
    constrained generation conditioned on the prefix, as described in [Autoregressive
    Entity Retrieval](https://arxiv.org/abs/2010.00904).'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prefix_allowed_tokens_fn`（`Callable[[int, torch.Tensor], List[int]]`，*可选*）—
    如果提供，此函数将在每个步骤将束搜索限制为仅允许的标记。如果未提供，则不应用约束。此函数接受2个参数：批次ID`batch_id`和`input_ids`。它必须返回一个列表，其中包含下一代步骤的允许标记，条件是批次ID`batch_id`和先前生成的标记`inputs_ids`。此参数对于受前缀约束的生成很有用，如[自回归实体检索](https://arxiv.org/abs/2010.00904)中所述。'
- en: '`synced_gpus` (`bool`, *optional*, defaults to `False`) — Whether to continue
    running the while loop until max_length (needed for ZeRO stage 3)'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`synced_gpus`（`bool`，*可选*，默认为`False`）— 是否继续运行while循环直到max_length（对于ZeRO阶段3是必需的）'
- en: '`return_timestamps` (`bool`, *optional*) — Whether to return the timestamps
    with the text. This enables the `WhisperTimestampsLogitsProcessor`.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_timestamps`（`bool`，*可选*）— 是否返回文本的时间戳。这将启用`WhisperTimestampsLogitsProcessor`。'
- en: '`task` (`str`, *optional*) — Task to use for generation, either “translate”
    or “transcribe”. The `model.config.forced_decoder_ids` will be updated accordingly.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task`（`str`，*可选*）— 用于生成的任务，可以是“translate”或“transcribe”。`model.config.forced_decoder_ids`将相应更新。'
- en: '`language` (`str`, *optional*) — Language token to use for generation, can
    be either in the form of `<|en|>`, `en` or `english`. You can find all the possible
    language tokens in the `model.generation_config.lang_to_id` dictionary.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language`（`str`，*optional*）--用于生成的语言标记，可以是`<|en|>`、`en`或`english`形式。您可以在`model.generation_config.lang_to_id`字典中找到所有可能的语言标记。'
- en: '`is_multilingual` (`bool`, *optional*) — Whether or not the model is multilingual.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_multilingual`（`bool`，*可选*）— 模型是否是多语言的。'
- en: '`prompt_ids` (`torch.Tensor`, *optional*) — Rank-1 tensor of token IDs created
    by passing text to `get_prompt_ids()` that is provided as a prompt to each chunk.
    This can be used to provide or “prompt-engineer” a context for transcription,
    e.g. custom vocabularies or proper nouns to make it more likely to predict those
    words correctly. It cannot be used in conjunction with `decoder_start_token_id`
    as it overwrites this value.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_ids`（`torch.Tensor`，*可选*）— 通过将文本传递给`get_prompt_ids()`创建的令牌ID的秩-1张量，作为每个块的提示提供。这可用于为转录提供或“提示工程”上下文，例如自定义词汇或专有名词，以使其更有可能正确预测这些单词。它不能与`decoder_start_token_id`结合使用，因为它会覆盖此值。'
- en: '`condition_on_prev_tokens` (`bool`, *optional*) — Only relevant for long-form
    transcription. Whether to condition each segment on the previous segment. As shown
    in the [the Whisper paper](https://cdn.openai.com/papers/whisper.pdf), this can
    help to improve performance.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`condition_on_prev_tokens`（`bool`，*可选*）— 仅适用于长篇转录。是否将每个片段的生成条件设置为前一个片段。如[Whisper论文](https://cdn.openai.com/papers/whisper.pdf)所示，这可以帮助提高性能。'
- en: '`temperature` (`float` or list of `float`, *optional*) — The temperature to
    be used for generation. Passing a single `float` value and `do_sample=True` activates
    generation using sampling. For long-form transcription, temperature fallback can
    be activated by passing a list of float values such as (0.0, 0.2, 0.4, 0.6, 0.8,
    1.0). As shown in the [the Whisper paper](https://cdn.openai.com/papers/whisper.pdf),
    this can help to improve performance.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature` (`float` 或 `float` 列表，*可选*) — 用于生成的温度。传递单个 `float` 值并且 `do_sample=True`
    会激活使用采样进行生成。对于长篇转录，可以通过传递一组浮点值（例如 (0.0, 0.2, 0.4, 0.6, 0.8, 1.0)）来激活温度回退。正如[Whisper论文](https://cdn.openai.com/papers/whisper.pdf)所示，这可以帮助提高性能。'
- en: '`compression_ratio_threshold` (`float`, *optional*) — Only relevant for long-form
    transcription. If defined, the zlib compression rate of each segment will be computed.
    If the compression rate of a segment is higher than `compression_ratio_threshold`,
    temperature fallback is activated: the generated segment is discarded and the
    generation is repeated using a higher temperature. The intuition behind this feature
    is that segments with very high compression rates suffer from a lot of repetition.
    The unwanted repetition can be reduced by injecting more randomness by increasing
    the temperature. If `compression_ratio_threshold` is defined make sure that `temperature`
    is a list of values. A common value for `compression_ratio_threshold` is 1.35.
    As shown in the [the Whisper paper](https://cdn.openai.com/papers/whisper.pdf),
    this can help to improve performance.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compression_ratio_threshold` (`float`, *可选*) — 仅适用于长篇转录。如果定义了，将计算每个片段的 zlib
    压缩率。如果一个片段的压缩率高于 `compression_ratio_threshold`，则激活温度回退：生成的片段被丢弃，使用更高的温度重复生成。这个特性背后的直觉是，具有非常高压缩率的片段存在大量重复。通过增加温度注入更多随机性可以减少不需要的重复。如果定义了
    `compression_ratio_threshold`，请确保 `temperature` 是一个值列表。`compression_ratio_threshold`
    的常见值为 1.35。正如[Whisper论文](https://cdn.openai.com/papers/whisper.pdf)所示，这可以帮助提高性能。'
- en: '`logprob_threshold` (`float`, *optional*) — Only relevant for long-form transcription.
    If defined, the average log-probability of each segment will be computed. If the
    log-probability of a given segment is lower than `logprob_threshold`, temperature
    fallback is activated: the generated segment is discarded and the generation is
    repeated using a higher temperature. The intuition behind this feature is that
    segments of low log-probability can be improved by injecting more randomness by
    increasing the temperature. If `logprob_threshold` is defined make sure that `temperature`
    is a list of values. A common value for `logprob_threshold` is -1.0. As shown
    in the [the Whisper paper](https://cdn.openai.com/papers/whisper.pdf), this can
    help to improve performance.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logprob_threshold` (`float`, *可选*) — 仅适用于长篇转录。如果定义了，将计算每个片段的平均对数概率。如果给定片段的对数概率低于
    `logprob_threshold`，则激活温度回退：生成的片段被丢弃，使用更高的温度重复生成。这个特性背后的直觉是，低对数概率的片段可以通过增加温度注入更多随机性来改善。如果定义了
    `logprob_threshold`，请确保 `temperature` 是一个值列表。`logprob_threshold` 的常见值为 -1.0。正如[Whisper论文](https://cdn.openai.com/papers/whisper.pdf)所示，这可以帮助提高性能。'
- en: '`no_speech_threshold` (`float`, *optional*) — Only relevant for long-form transcription.
    If defined, the “no-speech” token combined with the `logprob_threshold` is used
    to determine whether a segment contains only silence. In this case, the transcription
    for this segment is skipped. As shown in the [the Whisper paper](https://cdn.openai.com/papers/whisper.pdf),
    this can help to improve performance.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`no_speech_threshold` (`float`, *可选*) — 仅适用于长篇转录。如果定义了，“无语音”标记与 `logprob_threshold`
    结合使用来确定一个片段是否只包含静音。在这种情况下，将跳过该片段的转录。正如[Whisper论文](https://cdn.openai.com/papers/whisper.pdf)所示，这可以帮助提高性能。'
- en: '`num_segment_frames` (`int`, *optional*) — The number of frames a single segment
    is made of. If not defined, `num_segment_frames` defaults to the model’s stride
    times the maximum input length.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_segment_frames` (`int`, *可选*) — 单个片段包含的帧数。如果未定义，`num_segment_frames` 默认为模型的步幅乘以最大输入长度。'
- en: '`attention_mask` (`torch.Tensor`, *optional*) — `attention_mask` needs to be
    passed when doing long-form transcription using a batch size > 1.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor`, *可选*) — 在使用批量大小 > 1 进行长篇转录时需要传递 `attention_mask`。'
- en: '`time_precision` (`int`, *optional*, defaults to 0.02) — The duration of output
    token in seconds. *E.g.* 0.02 means that a generated token on average accounts
    for 20 ms.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_precision` (`int`, *可选*, 默认为 0.02) — 输出标记的持续时间（秒）。*例如*，0.02 表示生成的标记平均占据
    20 毫秒。'
- en: '`return_token_timestamps` (`bool`, *optional*) — Whether to return token-level
    timestamps with the text. This can be used with or without the `return_timestamps`
    option. To get word-level timestamps, use the tokenizer to group the tokens into
    words.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_token_timestamps` (`bool`, *可选*) — 是否返回文本的标记级时间戳。可以与 `return_timestamps`
    选项一起使用。要获得单词级时间戳，请使用分词器将标记分组成单词。'
- en: '`return_segments` (`bool`, *optional*, defaults to `False`) — Whether to additionally
    return a list of all segments. Note that this option can only be enabled when
    doing long-form transcription.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_segments` (`bool`, *可选*, 默认为 `False`) — 是否额外返回所有片段的列表。请注意，只有在进行长篇转录时才能启用此选项。'
- en: '`return_dict_in_generate` (`bool`, *optional*, defaults to `False`) — Whether
    or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of just returning the generated tokens. Note that when doing long-form
    transcription, `return_dict_in_generate` can only be enabled when `return_segments`
    is set True. In this case the generation outputs of each segment is added to each
    segment.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict_in_generate` (`bool`, *可选*, 默认为 `False`) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不仅仅返回生成的标记。请注意，在进行长篇转录时，只有在设置 `return_segments` 为 True 时才能启用 `return_dict_in_generate`。在这种情况下，每个片段的生成输出将添加到每个片段中。'
- en: '`kwargs` (`Dict[str, Any]`, *optional*) — Ad hoc parametrization of `generate_config`
    and/or additional model-specific kwargs that will be forwarded to the `forward`
    function of the model. If the model is an encoder-decoder model, encoder specific
    kwargs should not be prefixed and decoder specific kwargs should be prefixed with
    *decoder_*.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（`Dict[str, Any]`，*可选*）-`generate_config`的特定于特定模型的参数化和/或其他模型特定kwargs，将转发到模型的`forward`函数。如果模型是编码器-解码器模型，则不应以前缀形式指定编码器特定kwargs，而应以*decoder_*为前缀指定解码器特定kwargs。'
- en: Returns
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    or `torch.LongTensor` or `Dict[str, Any]`'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)或`torch.LongTensor`或`Dict[str,
    Any]`'
- en: A [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    (if `return_dict_in_generate=True` or when `config.return_dict_in_generate=True`)
    or a `torch.FloatTensor` or a dict of segments when `return_segments=True`.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)（如果`return_dict_in_generate=True`或当`config.return_dict_in_generate=True`时）或一个`torch.FloatTensor`或一个段的字典，当`return_segments=True`时。
- en: If the passed input is > 30 seconds / > 3000 mel input features and `return_segments=True`
    then a dictionary of generated sequence ids, called `sequences` and a list of
    each generated segment is returned.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 如果传入的输入> 30秒/ > 3000 mel输入特征，并且`return_segments=True`，则返回一个生成的序列id字典，称为`sequences`，以及每个生成段的列表。
- en: 'else if the passed input is <= 30 seconds / >= 3000 mel input features, the
    possible [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    types are:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，如果传入的输入<= 30秒/ >= 3000 mel输入特征，则可能的[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)类型为：
- en: '[GenerateEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateEncoderDecoderOutput),'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GenerateEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateEncoderDecoderOutput)，'
- en: '[GenerateBeamEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateBeamEncoderDecoderOutput)'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GenerateBeamEncoderDecoderOutput](/docs/transformers/v4.37.2/en/internal/generation_utils#transformers.generation.GenerateBeamEncoderDecoderOutput)'
- en: else only the generated output sequence ids are returned.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，仅返回生成的输出序列id。
- en: Transcribes or translates log-mel input features to a sequence of auto-regressively
    generated token ids.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 将对数mel输入特征转录或翻译为自回归生成的令牌id序列。
- en: Most generation-controlling parameters are set in `generation_config` which,
    if not passed, will be set to the model’s default generation configuration. You
    can override any `generation_config` by passing the corresponding parameters to
    generate(), e.g. `.generate(inputs, num_beams=4, do_sample=True)`.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数生成控制参数都在`generation_config`中设置，如果未传递，则将设置为模型的默认生成配置。您可以通过将相应的参数传递给generate()来覆盖任何`generation_config`，例如`.generate(inputs,
    num_beams=4, do_sample=True)`。
- en: For an overview of generation strategies and code examples, check out the [following
    guide](./generation_strategies).
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 有关生成策略和代码示例的概述，请查看[以下指南](./generation_strategies)。
- en: 'Example:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '*Longform transcription*: To transcribe or translate audios longer than 30
    seconds, process the audio files without truncation and pass all mel features
    at once to generate.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*详细转录*：要转录或翻译超过30秒的音频，请处理音频文件而不截断，并一次传递所有mel特征以生成。'
- en: '[PRE39]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '*Shortform transcription*: If passed mel input features are < 30 seconds, the
    whole audio will be transcribed with a single call to generate.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*简化转录*：如果传入的mel输入特征< 30秒，则整个音频将通过一次调用生成进行转录。'
- en: '[PRE40]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: WhisperForCausalLM
  id: totrans-494
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WhisperForCausalLM
- en: '### `class transformers.WhisperForCausalLM`'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.WhisperForCausalLM`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1865)'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1865)'
- en: '[PRE41]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Parameters
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）-模型配置类，具有模型的所有参数。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: Whisper decoder with with a language modeling head on top (linear layer with
    weights tied to the input embeddings).
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: Whisper解码器，顶部带有语言建模头（线性层，其权重与输入嵌入绑定）。
- en: This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型继承自[PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel)。检查超类文档以获取库为所有模型实现的通用方法（例如下载或保存，调整输入嵌入大小，修剪头等）。
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型也是一个PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)子类。将其用作常规PyTorch模块，并参考PyTorch文档以获取有关一般用法和行为的所有相关信息。
- en: '#### `forward`'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1903)'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L1903)'
- en: '[PRE42]'
  id: totrans-505
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Parameters
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    Indices of input sequence tokens in the vocabulary. Padding will be ignored by
    default should you provide it. Indices can be obtained using [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are input IDs?](../glossary#input-ids)'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids` (`torch.LongTensor` of shape `(batch_size, sequence_length)`) —
    词汇表中输入序列标记的索引。默认情况下将忽略填充。可以使用 [AutoTokenizer](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoTokenizer)
    获取索引。有关详细信息，请参见 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是输入
    ID？](../glossary#input-ids)'
- en: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — Mask to avoid performing attention on padding token indices. Mask
    values selected in `[0, 1]`:'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) — 用于避免在填充标记索引上执行注意力的掩码。掩码值选在 `[0, 1]` 中：'
- en: 1 for tokens that are `not masked`,
  id: totrans-509
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示标记是 `not masked`，
- en: 0 for tokens that are `masked`. [What are attention masks?](../glossary#attention-mask)
  id: totrans-510
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示标记是 `masked`。[什么是注意力掩码？](../glossary#attention-mask)
- en: '`encoder_outputs` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder. Used in the cross-attention if the model is configured as
    a decoder.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 编码器最后一层的隐藏状态序列。如果模型配置为解码器，则在交叉注意力中使用。'
- en: '`head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules. Mask values
    selected in `[0, 1]`:'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — 用于使注意力模块中选择的头部失效的掩码。掩码值选在 `[0, 1]` 中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-513
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被 `masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-514
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被 `masked`。
- en: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — 用于使交叉注意力模块中选择的头部失效的掩码。掩码值选在 `[0, 1]` 中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-516
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示头部未被 `masked`，
- en: 0 indicates the head is `masked`.
  id: totrans-517
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示头部被 `masked`。
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.
    The two additional tensors are only required when the model is used as a decoder
    in a Sequence to Sequence model. Contains pre-computed hidden-states (key and
    values in the self-attention blocks and in the cross-attention blocks) that can
    be used (see `past_key_values` input) to speed up sequential decoding. If `past_key_values`
    are used, the user can optionally input only the last `decoder_input_ids` (those
    that don’t have their past key value states given to this model) of shape `(batch_size,
    1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, 当传递 `use_cache=True`
    或 `config.use_cache=True` 时返回) — 长度为 `config.n_layers` 的 `tuple(torch.FloatTensor)`
    的元组，每个元组有 2 个形状为 `(batch_size, num_heads, sequence_length, embed_size_per_head)`
    的张量和 2 个额外的形状为 `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`
    的张量。当模型用作序列到序列模型中的解码器时，只有这两个额外的张量是必需的。包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见
    `past_key_values` 输入）。如果使用了 `past_key_values`，用户可以选择只输入最后一个形状为 `(batch_size, 1)`
    的 `decoder_input_ids`（这些没有将其过去的键值状态提供给该模型的标记）而不是所有形状为 `(batch_size, sequence_length)`
    的 `decoder_input_ids`。'
- en: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model’s internal embedding lookup matrix.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs_embeds` (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — 可选地，可以直接传递嵌入表示，而不是传递 `input_ids`。如果您想要更多控制如何将 `input_ids`
    索引转换为相关向量，这将非常有用，而不是使用模型的内部嵌入查找矩阵。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the masked language modeling loss. Indices should either
    be in `[0, ..., config.vocab_size]` or -100 (see `input_ids` docstring). Tokens
    with indices set to `-100` are ignored (masked), the loss is only computed for
    the tokens with labels in `[0, ..., config.vocab_size]`.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*)
    — 用于计算掩码语言建模损失的标签。索引应该在 `[0, ..., config.vocab_size]` 或 -100（参见 `input_ids` 文档字符串）。索引设置为
    `-100` 的标记将被忽略（掩码），损失仅计算具有标签在 `[0, ..., config.vocab_size]` 中的标记。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) — 如果设置为 `True`，则会返回 `past_key_values` 键值状态，可用于加速解码（参见
    `past_key_values`）。'
- en: 1 for tokens that are `not masked`,
  id: totrans-522
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示标记是 `not masked`，
- en: 0 for tokens that are `masked`.
  id: totrans-523
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示标记是 `masked`。
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的
    `attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.CausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithCrossAttentions)
    or `tuple(torch.FloatTensor)`'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.CausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithCrossAttentions)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.CausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithCrossAttentions)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    and inputs.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_outputs.CausalLMOutputWithCrossAttentions](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithCrossAttentions)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`时）包含根据配置（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）和输入的各种元素。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Language modeling loss (for next-token prediction).'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`损失` (`torch.FloatTensor`，形状为`(1,)`，*可选*，当提供`labels`时返回) — 语言建模损失（用于下一个标记预测）。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor`，形状为`(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）
    — 形状为`(batch_size, sequence_length, hidden_size)`的`torch.FloatTensor`元组。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每个层的输出的隐藏状态加上可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的自注意力头中的注意力权重，用于计算加权平均值。
- en: '`cross_attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(torch.FloatTensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`torch.FloatTensor`元组。'
- en: Cross attentions weights after the attention softmax, used to compute the weighted
    average in the cross-attention heads.
  id: totrans-537
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的交叉注意力权重，用于计算交叉注意力头中的加权平均值。
- en: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) — Tuple of `torch.FloatTensor`
    tuples of length `config.n_layers`, with each tuple containing the cached key,
    value states of the self-attention and the cross-attention layers if model is
    used in encoder-decoder setting. Only relevant if `config.is_decoder = True`.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(torch.FloatTensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）
    — 长度为`config.n_layers`的`torch.FloatTensor`元组的元组，每个元组包含自注意力和交叉注意力层的缓存键、值状态，如果模型用于编码器-解码器设置，则相关。仅在`config.is_decoder
    = True`时相关。'
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    that can be used (see `past_key_values` input) to speed up sequential decoding.
  id: totrans-539
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（注意力块中的键和值），可用于加速顺序解码（查看`past_key_values`输入）。
- en: 'Example:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE43]'
  id: totrans-541
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: WhisperForAudioClassification
  id: totrans-542
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WhisperForAudioClassification
- en: '### `class transformers.WhisperForAudioClassification`'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.WhisperForAudioClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L2085)'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L2085)'
- en: '[PRE44]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Parameters
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, feature_size,
    sequence_length)`) — Float values mel features extracted from the raw speech waveform.
    Raw speech waveform can be obtained by loading a `.flac` or `.wav` audio file
    into an array of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile
    library (`pip install soundfile`). To prepare the array into `input_features`,
    the [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)
    should be used for extracting the mel features, padding and conversion into a
    tensor of type `torch.FloatTensor`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`torch.FloatTensor`，形状为`(batch_size, feature_size, sequence_length)`)
    — 从原始语音波形中提取的浮点值mel特征。原始语音波形可以通过将`.flac`或`.wav`音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中获得，例如通过soundfile库（`pip
    install soundfile`）。要将数组准备成`input_features`，应使用[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)来提取mel特征，填充并转换为`torch.FloatTensor`类型的张量。请参见[`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor`，形状为`(encoder_layers, encoder_attention_heads)`，*optional*)
    — 用于使编码器中注意力模块的选定头部失效的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-549
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-550
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — 元组包括(`last_hidden_state`，*optional*:
    `hidden_states`，*optional*: `attentions`) `last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*optional*)是编码器最后一层输出的隐藏状态序列。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Whisper Encoder Model with a sequence classification head on top (a linear layer
    over the pooled output) for tasks like SUPERB Keyword Spotting.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顶部序列分类头部（在汇聚输出上的线性层）的Whisper编码器模型，用于类似SUPERB关键词识别的任务。
- en: '#### `forward`'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L2119)'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_whisper.py#L2119)'
- en: '[PRE45]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Parameters
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`torch.FloatTensor` of shape `(batch_size, feature_size,
    sequence_length)`) — Float values mel features extracted from the raw speech waveform.
    Raw speech waveform can be obtained by loading a `.flac` or `.wav` audio file
    into an array of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile
    library (`pip install soundfile`). To prepare the array into `input_features`,
    the [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)
    should be used for extracting the mel features, padding and conversion into a
    tensor of type `torch.FloatTensor`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`torch.FloatTensor`，形状为`(batch_size, feature_size, sequence_length)`)
    — 从原始语音波形中提取的浮点值mel特征。原始语音波形可以通过将`.flac`或`.wav`音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中获得，例如通过soundfile库（`pip
    install soundfile`）。要将数组准备成`input_features`，应使用[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)来提取mel特征，填充并转换为`torch.FloatTensor`类型的张量。请参见[`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
- en: '`head_mask` (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`torch.Tensor`，形状为`(encoder_layers, encoder_attention_heads)`，*optional*)
    — 用于使编码器中注意力模块的选定头部失效的掩码。掩码值选定在`[0, 1]`之间：'
- en: 1 indicates the head is `not masked`,
  id: totrans-562
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-563
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — Tuple consists
    of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)
    `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*)
    is a sequence of hidden-states at the output of the last layer of the encoder.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(torch.FloatTensor)`, *optional*) — 元组包括(`last_hidden_state`，*optional*:
    `hidden_states`，*optional*: `attentions`) `last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*optional*)是编码器最后一层输出的隐藏状态序列。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回 [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    而不是普通元组。'
- en: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — Labels
    for computing the sequence classification/regression loss. Indices should be in
    `[0, ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression loss
    is computed (Mean-Square loss), If `config.num_labels > 1` a classification loss
    is computed (Cross-Entropy).'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`torch.LongTensor` of shape `(batch_size,)`, *optional*) — 用于计算序列分类/回归损失的标签。索引应在
    `[0, ..., config.num_labels - 1]` 中。如果 `config.num_labels == 1`，则计算回归损失（均方损失），如果
    `config.num_labels > 1`，则计算分类损失（交叉熵）。'
- en: Returns
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    或 `tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    and inputs.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [transformers.modeling_outputs.SequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput)
    或一个 `torch.FloatTensor` 元组（如果传递了 `return_dict=False` 或当 `config.return_dict=False`
    时）包含各种元素，取决于配置（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）和输入。
- en: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels`
    is provided) — Classification (or regression if config.num_labels==1) loss.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss` (`torch.FloatTensor` of shape `(1,)`, *optional*, 当提供 `labels` 时返回)
    — 分类（或回归，如果 config.num_labels==1）损失。'
- en: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    Classification (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) —
    分类（或回归，如果 config.num_labels==1）得分（SoftMax 之前）。'
- en: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `torch.FloatTensor`
    (one for the output of the embeddings, if the model has an embedding layer, +
    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(torch.FloatTensor)`, *optional*, 当传递 `output_hidden_states=True`
    或当 `config.output_hidden_states=True` 时返回) — 形状为 `(batch_size, sequence_length,
    hidden_size)` 的 `torch.FloatTensor` 元组。'
- en: Hidden-states of the model at the output of each layer plus the optional initial
    embedding outputs.
  id: totrans-575
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及可选的初始嵌入输出。
- en: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `torch.FloatTensor`
    (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(torch.FloatTensor)`, *optional*, 当传递 `output_attentions=True`
    或当 `config.output_attentions=True` 时返回) — 形状为 `(batch_size, num_heads, sequence_length,
    sequence_length)` 的 `torch.FloatTensor` 元组。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-577
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力权重在注意力 SoftMax 之后，用于计算自注意力头中的加权平均值。
- en: The [WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: '[WhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperForAudioClassification)
    的前向方法，覆盖了 `__call__` 特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用 `Module` 实例，而不是在此处调用，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE46]'
  id: totrans-581
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: TensorFlowHide TensorFlow content
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlowHide TensorFlow 内容
- en: TFWhisperModel
  id: totrans-583
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFWhisperModel
- en: '### `class transformers.TFWhisperModel`'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFWhisperModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_tf_whisper.py#L1230)'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_tf_whisper.py#L1230)'
- en: '[PRE47]'
  id: totrans-586
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Parameters
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — 包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只会加载配置。查看 [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    方法以加载模型权重。'
- en: The bare Whisper Model outputting raw hidden-states without any specific head
    on top. This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 裸的 Whisper 模型输出原始隐藏状态，没有特定的头部。此模型继承自 [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型也是一个[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)子类。将其用作常规的TF
    2.0 Keras模型，并参考TF 2.0文档以获取与一般用法和行为相关的所有事项。
- en: '#### `call`'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_tf_whisper.py#L1258)'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_tf_whisper.py#L1258)'
- en: '[PRE48]'
  id: totrans-593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Parameters
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`tf.Tensor` of shape `(batch_size, feature_size, sequence_length)`)
    — Float values of fbank features extracted from the raw speech waveform. Raw speech
    waveform can be obtained by loading a `.flac` or `.wav` audio file into an array
    of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile library (`pip
    install soundfile`). To prepare the array into `input_features`, the [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)
    should be used for extracting the fbank features, padding and conversion into
    a tensor of type `tf.Tensor`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（形状为`(batch_size, feature_size, sequence_length)`的`tf.Tensor`）-
    从原始语音波形中提取的fbank特征的浮点值。原始语音波形可以通过将`.flac`或`.wav`音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中获得，例如通过soundfile库（`pip
    install soundfile`）。要将数组准备成`input_features`，应使用[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)来提取fbank特征，填充并转换为`tf.Tensor`类型的张量。请参见[`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
- en: '`decoder_input_ids` (`tf.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`（形状为`(batch_size, target_sequence_length)`的`tf.Tensor`，*可选*）-
    词汇表中解码器输入序列标记的索引。'
- en: Indices can be obtained using `SpeechToTextTokenizer`. See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-597
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用`SpeechToTextTokenizer`获取索引。有关详细信息，请参见[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-598
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是decoder input IDs？](../glossary#decoder-input-ids)'
- en: SpeechToText uses the `eos_token_id` as the starting token for `decoder_input_ids`
    generation. If `past_key_values` is used, optionally only the last `decoder_input_ids`
    have to be input (see `past_key_values`).
  id: totrans-599
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SpeechToText使用`eos_token_id`作为`decoder_input_ids`生成的起始标记。如果使用`past_key_values`，可选择只输入最后的`decoder_input_ids`（参见`past_key_values`）。
- en: '`decoder_attention_mask` (`tf.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（形状为`(batch_size, target_sequence_length)`的`tf.Tensor`，*可选*）-
    默认行为：生成一个忽略`decoder_input_ids`中填充标记的张量。因果蒙版也将默认使用。'
- en: If you want to change padding behavior, you should read `modeling_whisper._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-601
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，请阅读`modeling_whisper._prepare_decoder_attention_mask`并根据需要进行修改。有关默认策略的更多信息，请参见[论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`head_mask` (`tf.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask`（形状为`(encoder_layers, encoder_attention_heads)`的`tf.Tensor`，*可选*）-
    用于在编码器中使选定注意力模块的头部失效的蒙版。蒙版值选定在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-603
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-604
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`decoder_head_mask` (`tf.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`tf.Tensor`，*可选*）-
    用于在解码器中使选定注意力模块的头部失效的蒙版。蒙版值选定在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-606
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-607
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`cross_attn_head_mask` (`tf.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask`（形状为`(decoder_layers, decoder_attention_heads)`的`tf.Tensor`，*可选*）-
    用于使交叉注意力模块的选定头部失效的蒙版。蒙版值选定在`[0, 1]`中：'
- en: 1 indicates the head is `not masked`,
  id: totrans-609
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被遮蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-610
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被遮蔽。
- en: '`encoder_outputs` (`tuple(tuple(tf.Tensor)`, *optional*) — Tuple consists of
    (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`) `last_hidden_state`
    of shape `(batch_size, sequence_length, hidden_size)`, *optional*) is a sequence
    of hidden-states at the output of the last layer of the encoder. Used in the cross-attention
    of the decoder.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs`（`tuple(tuple(tf.Tensor)`，*可选*）- 元组包含(`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`)
    `last_hidden_state`的形状为`(batch_size, sequence_length, hidden_size)`，*可选*）是编码器最后一层输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(tf.Tensor))`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — Tuple of `tuple(tf.Tensor)` of length
    `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size, num_heads,
    sequence_length, embed_size_per_head)`) and 2 additional tensors of shape `(batch_size,
    num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`tuple(tuple(tf.Tensor))`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）-
    长度为`config.n_layers`的`tuple(tf.Tensor)`的元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-613
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-614
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，用户可以选择仅输入最后的`decoder_input_ids`（那些没有将其过去的键值状态提供给此模型的）的形状为`(batch_size,
    1)`的张量，而不是形状为`(batch_size, sequence_length)`的所有`decoder_input_ids`。
- en: '`decoder_inputs_embeds` (`tf.Tensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds`（形状为`(batch_size, target_sequence_length, hidden_size)`的`tf.Tensor`，*可选*）—
    可选地，您可以选择直接传递嵌入表示而不是传递`decoder_input_ids`。如果使用`past_key_values`，则可以选择仅输入最后的`decoder_inputs_embeds`（参见`past_key_values`）。如果您想要更多控制如何将`decoder_input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache`（`bool`，*可选*）— 如果设置为`True`，则返回`past_key_values`键值状态，并可用于加速解码（参见`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）— 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回的张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）— 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回的张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）— 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_tf_outputs.TFSeq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqModelOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '`transformers.modeling_tf_outputs.TFSeq2SeqModelOutput`或`tuple(tf.Tensor)`'
- en: A [transformers.modeling_tf_outputs.TFSeq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqModelOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    and inputs.
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_tf_outputs.TFSeq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqModelOutput)或一个`tf.Tensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）和输入而异的各种元素。
- en: '`last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`)
    — Sequence of hidden-states at the output of the last layer of the decoder of
    the model.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`）—
    模型解码器最后一层的隐藏状态序列。'
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-624
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，则仅输出形状为`(batch_size, 1, hidden_size)`序列的最后一个隐藏状态。
- en: '`past_key_values` (`List[tf.Tensor]`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — List of `tf.Tensor` of length `config.n_layers`,
    with each tensor of shape `(2, batch_size, num_heads, sequence_length, embed_size_per_head)`).'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`List[tf.Tensor]`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）—
    长度为`config.n_layers`的`tf.Tensor`列表，每个张量的形状为`(2, batch_size, num_heads, sequence_length,
    embed_size_per_head)`。'
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    of the decoder that can be used (see `past_key_values` input) to speed up sequential
    decoding.
  id: totrans-626
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含解码器的预计算隐藏状态（注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出，一个用于每层的输出）。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-628
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器在每一层输出的隐藏状态加上初始嵌入输出。
- en: '`decoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-630
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-632
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`，*可选*）—
    模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）—
    形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每层的输出）。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-635
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层的隐藏状态加上初始嵌入输出。
- en: '`encoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）—
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-637
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel)
    forward method, overrides the `__call__` special method.
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFWhisperModel](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperModel)的前向方法覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者会负责运行预处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE49]'
  id: totrans-641
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: TFWhisperForConditionalGeneration
  id: totrans-642
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TFWhisperForConditionalGeneration
- en: '### `class transformers.TFWhisperForConditionalGeneration`'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.TFWhisperForConditionalGeneration`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_tf_whisper.py#L1346)'
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_tf_whisper.py#L1346)'
- en: '[PRE50]'
  id: totrans-645
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Parameters
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）—
    包含模型所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: The Whisper Model with a language modeling head. Can be used for automatic speech
    recognition. This model inherits from [TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头的Whisper模型。可用于自动语音识别。该模型继承自[TFPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.TFPreTrainedModel)。查看超类文档以获取库为所有模型实现的通用方法（如下载或保存、调整输入嵌入、修剪头等）。
- en: This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
    subclass. Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation
    for all matter related to general usage and behavior.
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型也是一个[tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)子类。将其用作常规的TF
    2.0 Keras模型，并参考TF 2.0文档以获取与一般用法和行为相关的所有内容。
- en: '#### `call`'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `call`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_tf_whisper.py#L1381)'
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_tf_whisper.py#L1381)'
- en: '[PRE51]'
  id: totrans-652
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Parameters
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`tf.Tensor` of shape `(batch_size, feature_size, sequence_length)`)
    — Float values of fbank features extracted from the raw speech waveform. Raw speech
    waveform can be obtained by loading a `.flac` or `.wav` audio file into an array
    of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile library (`pip
    install soundfile`). To prepare the array into `input_features`, the [AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)
    should be used for extracting the fbank features, padding and conversion into
    a tensor of type `tf.Tensor`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（形状为`(batch_size, feature_size, sequence_length)`的`tf.Tensor`）—
    从原始语音波形中提取的fbank特征的浮点值。原始语音波形可以通过将`.flac`或`.wav`音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中获得，*例如*通过soundfile库（`pip
    install soundfile`）。要准备好数组为`input_features`，应使用[AutoFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/auto#transformers.AutoFeatureExtractor)来提取fbank特征，填充并转换为`tf.Tensor`类型的张量。参见[`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
- en: '`decoder_input_ids` (`tf.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary.'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`（形状为`(batch_size, target_sequence_length)`的`tf.Tensor`，*可选*）—
    解码器输入序列标记在词汇表中的索引。'
- en: Indices can be obtained using `SpeechToTextTokenizer`. See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details.
  id: totrans-656
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用`SpeechToTextTokenizer`获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。
- en: '[What are decoder input IDs?](../glossary#decoder-input-ids)'
  id: totrans-657
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[什么是解码器输入ID？](../glossary#decoder-input-ids)'
- en: SpeechToText uses the `eos_token_id` as the starting token for `decoder_input_ids`
    generation. If `past_key_values` is used, optionally only the last `decoder_input_ids`
    have to be input (see `past_key_values`).
  id: totrans-658
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SpeechToText使用`eos_token_id`作为`decoder_input_ids`生成的起始标记。如果使用了`past_key_values`，则可能只需输入最后的`decoder_input_ids`（请参阅`past_key_values`）。
- en: '`decoder_attention_mask` (`tf.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`tf.Tensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) — 默认行为：生成一个忽略`decoder_input_ids`中填充标记的张量。因果掩码也将默认使用。'
- en: If you want to change padding behavior, you should read `modeling_whisper._prepare_decoder_attention_mask`
    and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.
  id: totrans-660
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果要更改填充行为，应阅读`modeling_whisper._prepare_decoder_attention_mask`并根据需要进行修改。有关默认策略的更多信息，请参阅[论文](https://arxiv.org/abs/1910.13461)中的图表1。
- en: '`head_mask` (`tf.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head_mask` (`tf.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) — 用于使编码器中注意力模块的选择头部失效的掩码。掩码值选在`[0, 1]`：'
- en: 1 indicates the head is `not masked`,
  id: totrans-662
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被屏蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-663
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被屏蔽。
- en: '`decoder_head_mask` (`tf.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_head_mask` (`tf.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — 用于在解码器中使选择的注意力模块的头部失效的掩码。掩码值选在`[0, 1]`范围内：'
- en: 1 indicates the head is `not masked`,
  id: totrans-665
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被屏蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-666
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被屏蔽。
- en: '`cross_attn_head_mask` (`tf.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attn_head_mask` (`tf.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) — 用于使交叉注意力模块的选择头部失效的掩码。掩码值选在`[0, 1]`范围内：'
- en: 1 indicates the head is `not masked`,
  id: totrans-668
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1表示头部未被屏蔽，
- en: 0 indicates the head is `masked`.
  id: totrans-669
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0表示头部被屏蔽。
- en: '`encoder_outputs` (`tuple(tuple(tf.Tensor)`, *optional*) — Tuple consists of
    (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`) `last_hidden_state`
    of shape `(batch_size, sequence_length, hidden_size)`, *optional*) is a sequence
    of hidden-states at the output of the last layer of the encoder. Used in the cross-attention
    of the decoder.'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_outputs` (`tuple(tuple(tf.Tensor)`, *optional*) — 元组包括（`last_hidden_state`，*可选*：`hidden_states`，*可选*：`attentions`）`last_hidden_state`的形状为`(batch_size,
    sequence_length, hidden_size)`，*可选*）是编码器最后一层的输出的隐藏状态序列。用于解码器的交叉注意力。'
- en: '`past_key_values` (`tuple(tuple(tf.Tensor))`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — Tuple of `tuple(tf.Tensor)` of length
    `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size, num_heads,
    sequence_length, embed_size_per_head)`) and 2 additional tensors of shape `(batch_size,
    num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(tf.Tensor))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(tf.Tensor)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-672
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码。
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don’t have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  id: totrans-673
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用了`past_key_values`，用户可以选择仅输入最后的`decoder_input_ids`（这些未将其过去的键值状态提供给此模型）的形状为`(batch_size,
    1)`的张量，而不是所有形状为`(batch_size, sequence_length)`的`decoder_input_ids`。
- en: '`decoder_inputs_embeds` (`tf.Tensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — Optionally, instead of passing `decoder_input_ids`
    you can choose to directly pass an embedded representation. If `past_key_values`
    is used, optionally only the last `decoder_inputs_embeds` have to be input (see
    `past_key_values`). This is useful if you want more control over how to convert
    `decoder_input_ids` indices into associated vectors than the model’s internal
    embedding lookup matrix.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_inputs_embeds` (`tf.Tensor` of shape `(batch_size, target_sequence_length,
    hidden_size)`, *optional*) — 可选地，您可以选择直接传递嵌入表示，而不是传递`decoder_input_ids`。如果使用了`past_key_values`，则可能只需输入最后的`decoder_inputs_embeds`（请参阅`past_key_values`）。如果您想要更多控制权，以便将`decoder_input_ids`索引转换为相关向量，而不是使用模型的内部嵌入查找矩阵，则这很有用。'
- en: '`use_cache` (`bool`, *optional*) — If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cache` (`bool`, *optional*) — 如果设置为`True`，则返回`past_key_values`键值状态，并可用于加速解码（请参阅`past_key_values`）。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量中的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）- 是否返回所有层的隐藏状态。有关更多详细信息，请查看返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）- 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: '`labels` (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*)
    — Labels for computing the language modeling loss. Indices should either be in
    `[0, ..., config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with
    indices set to `-100` are ignored (masked), the loss is only computed for the
    tokens with labels in `[0, ..., config.vocab_size]`.'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`（形状为`(batch_size, sequence_length)`的`tf.Tensor`，*可选*）- 用于计算语言建模损失的标签。索引应该在`[0,
    ..., config.vocab_size]`范围内，或者为-100（参见`input_ids`文档字符串）。索引设置为`-100`的标记将被忽略（掩码），损失仅计算具有`[0,
    ..., config.vocab_size]`标签的标记。'
- en: Returns
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_tf_outputs.TFSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqLMOutput)
    or `tuple(tf.Tensor)`'
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_tf_outputs.TFSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqLMOutput)或`tuple(tf.Tensor)`'
- en: A [transformers.modeling_tf_outputs.TFSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqLMOutput)
    or a tuple of `tf.Tensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    and inputs.
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_tf_outputs.TFSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_tf_outputs.TFSeq2SeqLMOutput)或一个`tf.Tensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含根据配置（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）和输入的不同元素。
- en: '`loss` (`tf.Tensor` of shape `(n,)`, *optional*, where n is the number of non-masked
    labels, returned when `labels` is provided) — Language modeling loss.'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss`（形状为`(n,)`的`tf.Tensor`，*可选*，当提供`labels`时返回，其中n是未屏蔽标签的数量）- 语言建模损失。'
- en: '`logits` (`tf.Tensor` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits`（形状为`(batch_size, sequence_length, config.vocab_size)`的`tf.Tensor`）-
    语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`past_key_values` (`List[tf.Tensor]`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — List of `tf.Tensor` of length `config.n_layers`,
    with each tensor of shape `(2, batch_size, num_heads, sequence_length, embed_size_per_head)`).'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values`（`List[tf.Tensor]`，*可选*，当传递`use_cache=True`或`config.use_cache=True`时返回）-
    长度为`config.n_layers`的`tf.Tensor`列表，每个张量形状为`(2, batch_size, num_heads, sequence_length,
    embed_size_per_head)`。'
- en: Contains pre-computed hidden-states (key and values in the attention blocks)
    of the decoder that can be used (see `past_key_values` input) to speed up sequential
    decoding.
  id: totrans-686
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含解码器的预先计算隐藏状态（注意力块中的键和值），可用于加速顺序解码。
- en: '`decoder_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-688
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器每层输出的隐藏状态加上初始嵌入输出。
- en: '`decoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-690
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均。
- en: '`cross_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions`（`tuple(tf.Tensor)`，*可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回）-
    形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每个层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-692
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均。
- en: '`encoder_last_hidden_state` (`tf.Tensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state`（形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`，*可选*）-
    模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `tf.Tensor` (one
    for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states`（`tuple(tf.Tensor)`，*可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回）-
    形状为`(batch_size, sequence_length, hidden_size)`的`tf.Tensor`元组（一个用于嵌入的输出 + 一个用于每个层的输出）。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-695
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器每层输出的隐藏状态加上初始嵌入输出。
- en: '`encoder_attentions` (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `tf.Tensor` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(tf.Tensor)`, *optional*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`tf.Tensor`元组（每层一个）。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-697
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The [TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)
    forward method, overrides the `__call__` special method.
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: '[TFWhisperForConditionalGeneration](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是在此处调用，因为前者负责运行预处理和后处理步骤，而后者则会默默地忽略它们。
- en: 'Example:'
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE52]'
  id: totrans-701
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: JAXHide JAX content
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: JAXHide JAX content
- en: FlaxWhisperModel
  id: totrans-703
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxWhisperModel
- en: '### `class transformers.FlaxWhisperModel`'
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxWhisperModel`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1185)'
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1185)'
- en: '[PRE53]'
  id: totrans-706
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Parameters
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs). This can be used to enable mixed-precision
    training or half-precision inference on GPUs or TPUs. If specified all the computation
    will be performed with the given `dtype`. **Note that this only specifies the
    dtype of the computation and does not influence the dtype of model parameters.**
    If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    计算的数据类型。可以是`jax.numpy.float32`、`jax.numpy.float16`（在GPU上）和`jax.numpy.bfloat16`（在TPU上）之一。这可以用于在GPU或TPU上启用混合精度训练或半精度推断。如果指定了`dtype`，则所有计算将使用给定的`dtype`执行。**请注意，这仅指定计算的dtype，不影响模型参数的dtype。**如果您希望更改模型参数的dtype，请参阅[to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)和[to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)。'
- en: 'The bare Whisper Model transformer outputting raw hidden-states without any
    specific head on top. This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its models (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.) This model is also a Flax Linen [flax.nn.Module](https://flax.readthedocs.io/en/latest/_autosummary/flax.nn.module.html)
    subclass. Use it as a regular Flax Module and refer to the Flax documentation
    for all matter related to general usage and behavior. Finally, this model supports
    inherent JAX features such as:'
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 裸Whisper模型变压器输出原始隐藏状态，没有特定的头部。此模型继承自[FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)。检查超类文档以了解库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。此模型还是Flax
    Linen [flax.nn.Module](https://flax.readthedocs.io/en/latest/_autosummary/flax.nn.module.html)子类。将其用作常规Flax模块，并参考Flax文档以了解所有与一般用法和行为相关的事项。最后，此模型支持固有的JAX功能，例如：
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[即时（JIT）编译](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动微分](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[矢量化](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[并行化](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1134)'
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1134)'
- en: '[PRE54]'
  id: totrans-717
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Parameters
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`numpy.ndarray` of shape `(batch_size, feature_size, sequence_length)`)
    — Float values mel features extracted from the raw speech waveform. Raw speech
    waveform can be obtained by loading a `.flac` or `.wav` audio file into an array
    of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile library (`pip
    install soundfile`). To prepare the array into `input_features`, the [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)
    should be used for extracting the features, padding and conversion into a tensor
    of type `numpy.ndarray`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features`（形状为`(batch_size, feature_size, sequence_length)`的`numpy.ndarray`）-
    从原始语音波形中提取的浮点值mel特征。原始语音波形可以通过将`.flac`或`.wav`音频文件加载到类型为`List[float]`或`numpy.ndarray`的数组中获得，例如通过soundfile库（`pip
    install soundfile`）。要将数组准备成`input_features`，应使用[WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)来提取特征，填充并转换为类型为`numpy.ndarray`的张量。参见[`call()`](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
- en: '`attention_mask` (`numpy.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) — Whisper does not support masking of the `input_features`, this argument
    is preserved for compatibility, but is not used. By default the silence in the
    input log mel spectrogram are ignored.'
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`（形状为`(batch_size, sequence_length)`的`numpy.ndarray`，*可选*）-
    Whisper不支持对`input_features`进行掩码，此参数保留以确保兼容性，但不会使用。默认情况下，输入对数mel频谱图中的静音将被忽略。'
- en: '`decoder_input_ids` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary. Indices
    can be obtained using [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are decoder input IDs?](../glossary#decoder-input-ids) Whisper
    uses the `decoder_start_token_id` as the starting token for `decoder_input_ids`
    generation.'
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids`（形状为`(batch_size, target_sequence_length)`的`numpy.ndarray`，*可选*）-
    词汇表中解码器输入序列标记的索引。可以使用[WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)获取索引。有关详细信息，请参见[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call()`](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是解码器输入ID？](../glossary#decoder-input-ids)
    Whisper使用`decoder_start_token_id`作为`decoder_input_ids`生成的起始标记。'
- en: '`decoder_attention_mask` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default. If you want to change padding behavior,
    you should modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask`（形状为`(batch_size, target_sequence_length)`的`numpy.ndarray`，*可选*）-
    默认行为：生成一个张量，忽略`decoder_input_ids`中的填充标记。因果掩码也将默认使用。如果要更改填充行为，应根据需要进行修改。有关默认策略的更多信息，请参见[论文](https://arxiv.org/abs/1910.13461)中的图表1。'
- en: '`position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`, *optional*)
    — Whisper does not use `position_ids` in the encoder as `input_features` is always
    the same size and doesn’t use masking, but this argument is preserved for compatibility.
    By default the silence in the input log mel spectrogram are ignored.'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids`（形状为`(batch_size, sequence_length)`的`numpy.ndarray`，*可选*）- Whisper在编码器中不使用`position_ids`，因为`input_features`始终具有相同的大小且不使用掩码，但此参数保留以确保兼容性。默认情况下，输入对数mel频谱图中的静音将被忽略。'
- en: '`decoder_position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each decoder input sequence tokens in the
    position embeddings. Selected in the range `[0, config.max_position_embeddings
    - 1]`.'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_position_ids`（形状为`(batch_size, sequence_length)`的`numpy.ndarray`，*可选*）-
    每个解码器输入序列标记的位置索引。选择范围为`[0, config.max_position_embeddings - 1]`。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions`（`bool`，*可选*）- 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回的张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states`（`bool`，*可选*）- 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回的张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict`（`bool`，*可选*）- 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: Returns
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    and inputs.
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput)或一个`torch.FloatTensor`元组（如果传递了`return_dict=False`或`config.return_dict=False`时）包含各种元素，取决于配置（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）和输入。'
- en: '`last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`) — Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_hidden_state` (`形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`)
    — 模型解码器最后一层的隐藏状态序列。'
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  id: totrans-732
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用`past_key_values`，则只输出形状为`(batch_size, 1, hidden_size)`的序列的最后隐藏状态。
- en: '`past_key_values` (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — Tuple of `tuple(jnp.ndarray)` of
    length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(jnp.ndarray))`, *可选的*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(jnp.ndarray)`元组，每个元组有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-734
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码（参见`past_key_values`输入）。
- en: '`decoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-736
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器在每一层输出时的隐藏状态加上初始嵌入输出。
- en: '`decoder_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-738
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-740
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`,
    *可选的*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出，一个用于每一层的输出）。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-743
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层输出时的隐藏状态加上初始嵌入输出。
- en: '`encoder_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(jnp.ndarray)`, *可选的*, 当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-745
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The `FlaxWhisperPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: '`FlaxWhisperPreTrainedModel`的前向方法覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者会处理运行前后处理步骤，而后者会默默地忽略它们。
- en: 'Example:'
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE55]'
  id: totrans-749
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: FlaxWhisperForConditionalGeneration
  id: totrans-750
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxWhisperForConditionalGeneration
- en: '### `class transformers.FlaxWhisperForConditionalGeneration`'
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxWhisperForConditionalGeneration`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1267)'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1267)'
- en: '[PRE56]'
  id: totrans-753
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Parameters
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — 模型的所有参数的模型配置类。使用配置文件初始化不会加载与模型相关的权重，只会加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs). This can be used to enable mixed-precision
    training or half-precision inference on GPUs or TPUs. If specified all the computation
    will be performed with the given `dtype`. **Note that this only specifies the
    dtype of the computation and does not influence the dtype of model parameters.**
    If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).'
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jax.numpy.dtype`, *可选*, 默认为 `jax.numpy.float32`) — 计算的数据类型。可以是`jax.numpy.float32`、`jax.numpy.float16`（在GPU上）和`jax.numpy.bfloat16`（在TPU上）之一。这可以用于在GPU或TPU上启用混合精度训练或半精度推断。如果指定了`dtype`，则所有计算将使用给定的`dtype`执行。**请注意，这仅指定计算的数据类型，不影响模型参数的数据类型。**如果要更改模型参数的数据类型，请参阅[to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)和[to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)。'
- en: 'The Whisper Model with a language modeling head. This model inherits from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its models (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.) This model is also a Flax Linen [flax.nn.Module](https://flax.readthedocs.io/en/latest/_autosummary/flax.nn.module.html)
    subclass. Use it as a regular Flax Module and refer to the Flax documentation
    for all matter related to general usage and behavior. Finally, this model supports
    inherent JAX features such as:'
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: 带有语言建模头的Whisper模型。此模型继承自[FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)。查看超类文档以了解库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。此模型还是Flax
    Linen [flax.nn.Module](https://flax.readthedocs.io/en/latest/_autosummary/flax.nn.module.html)子类。将其用作常规Flax模块，并参考Flax文档以了解与一般用法和行为相关的所有事项。最后，此模型支持内在的JAX功能，例如：
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[即时（JIT）编译](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动微分](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[矢量化](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[并行化](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1134)'
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1134)'
- en: '[PRE57]'
  id: totrans-764
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Parameters
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`numpy.ndarray` of shape `(batch_size, feature_size, sequence_length)`)
    — Float values mel features extracted from the raw speech waveform. Raw speech
    waveform can be obtained by loading a `.flac` or `.wav` audio file into an array
    of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile library (`pip
    install soundfile`). To prepare the array into `input_features`, the [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)
    should be used for extracting the features, padding and conversion into a tensor
    of type `numpy.ndarray`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`numpy.ndarray`，形状为`(batch_size, feature_size, sequence_length)`)
    — 从原始语音波形中提取的浮点值梅尔特征。原始语音波形可以通过将`.flac`或`.wav`音频文件加载到`List[float]`类型的数组或`numpy.ndarray`中获得，例如通过soundfile库（`pip
    install soundfile`）。要准备数组为`input_features`，应使用[WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)来提取特征、填充和转换为`numpy.ndarray`类型的张量。参见[`call()`](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)。'
- en: '`attention_mask` (`numpy.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) — Whisper does not support masking of the `input_features`, this argument
    is preserved for compatibility, but is not used. By default the silence in the
    input log mel spectrogram are ignored.'
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`numpy.ndarray`，形状为`(batch_size, sequence_length)`，*可选*)
    — Whisper不支持`input_features`的掩码，此参数保留以确保兼容性，但不会使用。默认情况下，输入对数梅尔频谱中的静音将被忽略。'
- en: '`decoder_input_ids` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary. Indices
    can be obtained using [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are decoder input IDs?](../glossary#decoder-input-ids) Whisper
    uses the `decoder_start_token_id` as the starting token for `decoder_input_ids`
    generation.'
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) — 词汇表中解码器输入序列标记的索引。可以使用[WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)获取索引。有关详细信息，请参阅[PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)和[PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。Whisper使用`decoder_start_token_id`作为`decoder_input_ids`生成的起始标记。'
- en: '`decoder_attention_mask` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default. If you want to change padding behavior,
    you should modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.'
  id: totrans-769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) — 默认行为：生成一个张量，忽略`decoder_input_ids`中的填充标记。因果掩码也将默认使用。如果要更改填充行为，应根据需要进行修改。有关默认策略的更多信息，请参见[论文](https://arxiv.org/abs/1910.13461)中的图表1。'
- en: '`position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`, *optional*)
    — Whisper does not use `position_ids` in the encoder as `input_features` is always
    the same size and doesn’t use masking, but this argument is preserved for compatibility.
    By default the silence in the input log mel spectrogram are ignored.'
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`, *optional*)
    — Whisper在编码器中不使用`position_ids`，因为`input_features`始终具有相同的大小并且不使用掩码，但为了兼容性保留了这个参数。默认情况下，输入对数梅尔频谱中的静音将被忽略。'
- en: '`decoder_position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each decoder input sequence tokens in the
    position embeddings. Selected in the range `[0, config.max_position_embeddings
    - 1]`.'
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) — 解码器输入序列标记在位置嵌入中的位置索引。选择范围为`[0, config.max_position_embeddings -
    1]`。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *optional*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参见返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *optional*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参见返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *optional*) — 是否返回[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是普通元组。'
- en: Returns
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    and inputs.
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: 包含根据配置（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）和输入而组成的各种元素的[transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）。
- en: '`logits` (`jnp.ndarray` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — Prediction scores of the language modeling head (scores for each vocabulary
    token before SoftMax).'
  id: totrans-778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`jnp.ndarray` of shape `(batch_size, sequence_length, config.vocab_size)`)
    — 语言建模头的预测分数（SoftMax之前每个词汇标记的分数）。'
- en: '`past_key_values` (`tuple(tuple(jnp.ndarray))`, *optional*, returned when `use_cache=True`
    is passed or when `config.use_cache=True`) — Tuple of `tuple(jnp.ndarray)` of
    length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  id: totrans-779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_key_values` (`tuple(tuple(jnp.ndarray))`, *optional*, 当传递`use_cache=True`或`config.use_cache=True`时返回)
    — 长度为`config.n_layers`的`tuple(jnp.ndarray)`元组，每个元组具有2个形状为`(batch_size, num_heads,
    sequence_length, embed_size_per_head)`的张量和2个额外的形状为`(batch_size, num_heads, encoder_sequence_length,
    embed_size_per_head)`的张量。'
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  id: totrans-780
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含预先计算的隐藏状态（自注意力块和交叉注意力块中的键和值），可用于加速顺序解码。
- en: '`decoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, 当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入的输出 +
    一个用于每个层的输出）。'
- en: Hidden-states of the decoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-782
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器在每一层输出的隐藏状态加上初始嵌入输出。
- en: '`decoder_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attentions` (`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。'
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-784
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: '`cross_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cross_attentions` (`tuple(jnp.ndarray)`，*可选*，当传递`output_attentions=True`或当`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。'
- en: Attentions weights of the decoder’s cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  id: totrans-786
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解码器的交叉注意力层的注意力权重，在注意力softmax之后，用于计算交叉注意力头中的加权平均值。
- en: '`encoder_last_hidden_state` (`jnp.ndarray` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) — Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_last_hidden_state` (`jnp.ndarray`，形状为`(batch_size, sequence_length,
    hidden_size)`，*可选*) — 模型编码器最后一层的隐藏状态序列。'
- en: '`encoder_hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_hidden_states` (`tuple(jnp.ndarray)`，*可选*，当传递`output_hidden_states=True`或当`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入输出 + 一个用于每一层的输出）。'
- en: Hidden-states of the encoder at the output of each layer plus the initial embedding
    outputs.
  id: totrans-789
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器在每一层输出的隐藏状态加上初始嵌入输出。
- en: '`encoder_attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_attentions` (`tuple(jnp.ndarray)`, *可选*, 当传递`output_attentions=True`或当`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。'
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  id: totrans-791
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码器的注意力权重，在注意力softmax之后，用于计算自注意力头中的加权平均值。
- en: The `FlaxWhisperPreTrainedModel` forward method, overrides the `__call__` special
    method.
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: '`FlaxWhisperPreTrainedModel`的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然前向传递的步骤需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行前处理和后处理步骤，而后者会默默地忽略它们。
- en: 'Transcription example:'
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
  zh: 转录示例：
- en: '[PRE58]'
  id: totrans-795
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: FlaxWhisperForAudioClassification
  id: totrans-796
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlaxWhisperForAudioClassification
- en: '### `class transformers.FlaxWhisperForAudioClassification`'
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class transformers.FlaxWhisperForAudioClassification`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1597)'
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1597)'
- en: '[PRE59]'
  id: totrans-799
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Parameters
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`config` ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    — Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)
    method to load the model weights.'
  id: totrans-801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）
    — 具有模型所有参数的模型配置类。使用配置文件初始化不会加载与模型关联的权重，只加载配置。查看[from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.from_pretrained)方法以加载模型权重。'
- en: '`dtype` (`jax.numpy.dtype`, *optional*, defaults to `jax.numpy.float32`) —
    The data type of the computation. Can be one of `jax.numpy.float32`, `jax.numpy.float16`
    (on GPUs) and `jax.numpy.bfloat16` (on TPUs). This can be used to enable mixed-precision
    training or half-precision inference on GPUs or TPUs. If specified all the computation
    will be performed with the given `dtype`. **Note that this only specifies the
    dtype of the computation and does not influence the dtype of model parameters.**
    If you wish to change the dtype of the model parameters, see [to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)
    and [to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16).'
  id: totrans-802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`jax.numpy.dtype`，*可选*，默认为`jax.numpy.float32`) — 计算的数据类型。可以是`jax.numpy.float32`、`jax.numpy.float16`（在GPU上）和`jax.numpy.bfloat16`（在TPU上）中的一种。这可以用于在GPU或TPU上启用混合精度训练或半精度推断。如果指定了`dtype`，则所有计算将使用给定的`dtype`执行。**请注意，这仅指定计算的数据类型，不影响模型参数的数据类型。**如果您希望更改模型参数的数据类型，请参阅[to_fp16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_fp16)和[to_bf16()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel.to_bf16)。'
- en: 'The Whisper Model with an audio classification head on top. This model inherits
    from [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its models (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.) This model is also a Flax Linen [flax.nn.Module](https://flax.readthedocs.io/en/latest/_autosummary/flax.nn.module.html)
    subclass. Use it as a regular Flax Module and refer to the Flax documentation
    for all matter related to general usage and behavior. Finally, this model supports
    inherent JAX features such as:'
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: 带有顶部音频分类头的 Whisper 模型。此模型继承自 [FlaxPreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.FlaxPreTrainedModel)。检查超类文档以了解库为所有模型实现的通用方法（例如下载或保存、调整输入嵌入、修剪头等）。此模型还是
    Flax Linen [flax.nn.Module](https://flax.readthedocs.io/en/latest/_autosummary/flax.nn.module.html)
    子类。将其用作常规 Flax 模块，并参考 Flax 文档以获取有关一般用法和行为的所有相关信息。最后，此模型支持内在的 JAX 功能，例如：
- en: '[Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[即时 (JIT) 编译](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)'
- en: '[Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动微分](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)'
- en: '[Vectorization](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[矢量化](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)'
- en: '[Parallelization](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
  id: totrans-807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[并行化](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)'
- en: '#### `__call__`'
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `__call__`'
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1625)'
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/whisper/modeling_flax_whisper.py#L1625)'
- en: '[PRE60]'
  id: totrans-810
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Parameters
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`input_features` (`numpy.ndarray` of shape `(batch_size, feature_size, sequence_length)`)
    — Float values mel features extracted from the raw speech waveform. Raw speech
    waveform can be obtained by loading a `.flac` or `.wav` audio file into an array
    of type `List[float]` or a `numpy.ndarray`, *e.g.* via the soundfile library (`pip
    install soundfile`). To prepare the array into `input_features`, the [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)
    should be used for extracting the features, padding and conversion into a tensor
    of type `numpy.ndarray`. See [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
  id: totrans-812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_features` (`numpy.ndarray` of shape `(batch_size, feature_size, sequence_length)`)
    — 从原始语音波形中提取的浮点值 mel 特征。原始语音波形可以通过将 `.flac` 或 `.wav` 音频文件加载到类型为 `List[float]`
    或 `numpy.ndarray` 的数组中获得，例如通过 soundfile 库 (`pip install soundfile`)。要将数组准备成 `input_features`，应使用
    [WhisperFeatureExtractor](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor)
    来提取特征，填充并转换为类型为 `numpy.ndarray` 的张量。参见 [`call`()](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperFeatureExtractor.__call__)'
- en: '`attention_mask` (`numpy.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) — Whisper does not support masking of the `input_features`, this argument
    is preserved for compatibility, but is not used. By default the silence in the
    input log mel spectrogram are ignored.'
  id: totrans-813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask` (`numpy.ndarray` of shape `(batch_size, sequence_length)`,
    *可选*) — Whisper 不支持对 `input_features` 进行掩码，此参数保留了兼容性，但不会使用。默认情况下，输入对数 mel 频谱图中的静音会被忽略。'
- en: '`decoder_input_ids` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Indices of decoder input sequence tokens in the vocabulary. Indices
    can be obtained using [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer).
    See [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    and [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)
    for details. [What are decoder input IDs?](../glossary#decoder-input-ids) Whisper
    uses the `decoder_start_token_id` as the starting token for `decoder_input_ids`
    generation.'
  id: totrans-814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_ids` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *可选*) — 词汇表中解码器输入序列标记的索引。可以使用 [WhisperTokenizer](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperTokenizer)
    获取索引。有关详细信息，请参阅 [PreTrainedTokenizer.encode()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode)
    和 [PreTrainedTokenizer.`call`()](/docs/transformers/v4.37.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__)。[什么是解码器输入
    ID？](../glossary#decoder-input-ids) Whisper 使用 `decoder_start_token_id` 作为 `decoder_input_ids`
    生成的起始标记。'
- en: '`decoder_attention_mask` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *optional*) — Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`.
    Causal mask will also be used by default. If you want to change padding behavior,
    you should modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461)
    for more information on the default strategy.'
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_attention_mask` (`numpy.ndarray` of shape `(batch_size, target_sequence_length)`,
    *可选*) — 默认行为：生成一个忽略 `decoder_input_ids` 中填充标记的张量。默认情况下还将使用因果掩码。如果要更改填充行为，应根据需要进行修改。有关默认策略的更多信息，请参见
    [论文](https://arxiv.org/abs/1910.13461) 中的图表 1。'
- en: '`position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`, *optional*)
    — Whisper does not use `position_ids` in the encoder as `input_features` is always
    the same size and doesn’t use masking, but this argument is preserved for compatibility.
    By default the silence in the input log mel spectrogram are ignored.'
  id: totrans-816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`, *可选*)
    — Whisper 在编码器中不使用 `position_ids`，因为 `input_features` 总是相同大小且不使用掩码，但为了兼容性保留了此参数。默认情况下，输入对数
    mel 频谱图中的静音会被忽略。'
- en: '`decoder_position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`,
    *optional*) — Indices of positions of each decoder input sequence tokens in the
    position embeddings. Selected in the range `[0, config.max_position_embeddings
    - 1]`.'
  id: totrans-817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_position_ids` (`numpy.ndarray` of shape `(batch_size, sequence_length)`,
    *可选*) — 每个解码器输入序列标记在位置嵌入中的位置索引。选择范围为 `[0, config.max_position_embeddings - 1]`。'
- en: '`output_attentions` (`bool`, *optional*) — Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  id: totrans-818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_attentions` (`bool`, *可选*) — 是否返回所有注意力层的注意力张量。有关更多详细信息，请参阅返回张量下的`attentions`。'
- en: '`output_hidden_states` (`bool`, *optional*) — Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_hidden_states` (`bool`, *可选*) — 是否返回所有层的隐藏状态。有关更多详细信息，请参阅返回张量下的`hidden_states`。'
- en: '`return_dict` (`bool`, *optional*) — Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*) — 是否返回一个[ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)而不是一个普通元组。'
- en: Returns
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput)
    or `tuple(torch.FloatTensor)`'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: '[transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput)或`tuple(torch.FloatTensor)`'
- en: A [transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig))
    and inputs.
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput)或一个`torch.FloatTensor`元组（如果传递`return_dict=False`或`config.return_dict=False`）包含各种元素，取决于配置（[WhisperConfig](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.WhisperConfig)）和输入。
- en: '`logits` (`jnp.ndarray` of shape `(batch_size, config.num_labels)`) — Classification
    (or regression if config.num_labels==1) scores (before SoftMax).'
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logits` (`jnp.ndarray`，形状为`(batch_size, config.num_labels)`) — 分类（如果`config.num_labels==1`则为回归）得分（SoftMax之前）。'
- en: '`hidden_states` (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True`
    is passed or when `config.output_hidden_states=True`) — Tuple of `jnp.ndarray`
    (one for the output of the embeddings + one for the output of each layer) of shape
    `(batch_size, sequence_length, hidden_size)`.'
  id: totrans-825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_states` (`tuple(jnp.ndarray)`, *可选*，当传递`output_hidden_states=True`或`config.output_hidden_states=True`时返回)
    — 形状为`(batch_size, sequence_length, hidden_size)`的`jnp.ndarray`元组（一个用于嵌入的输出 +
    一个用于每层的输出）。'
- en: Hidden-states of the model at the output of each layer plus the initial embedding
    outputs.
  id: totrans-826
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型在每一层输出的隐藏状态以及初始嵌入输出。
- en: '`attentions` (`tuple(jnp.ndarray)`, *optional*, returned when `output_attentions=True`
    is passed or when `config.output_attentions=True`) — Tuple of `jnp.ndarray` (one
    for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.'
  id: totrans-827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attentions` (`tuple(jnp.ndarray)`, *可选*，当传递`output_attentions=True`或`config.output_attentions=True`时返回)
    — 形状为`(batch_size, num_heads, sequence_length, sequence_length)`的`jnp.ndarray`元组（每层一个）。'
- en: Attentions weights after the attention softmax, used to compute the weighted
    average in the self-attention heads.
  id: totrans-828
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力softmax后的注意力权重，用于计算自注意力头中的加权平均值。
- en: The [FlaxWhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForAudioClassification)
    forward method, overrides the `__call__` special method.
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
  zh: '[FlaxWhisperForAudioClassification](/docs/transformers/v4.37.2/en/model_doc/whisper#transformers.FlaxWhisperForAudioClassification)的前向方法，覆盖了`__call__`特殊方法。'
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前向传递的配方需要在此函数内定义，但应该在此之后调用`Module`实例，而不是这个，因为前者负责运行预处理和后处理步骤，而后者则默默地忽略它们。
- en: 'Transcription example:'
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
  zh: 转录示例：
- en: '[PRE61]'
  id: totrans-832
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
