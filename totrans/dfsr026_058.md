# æ–‡æœ¬åˆ°å›¾åƒ

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/diffusers/training/text2image`](https://huggingface.co/docs/diffusers/training/text2image)

æ–‡æœ¬åˆ°å›¾åƒè„šæœ¬æ˜¯å®éªŒæ€§çš„ï¼Œå¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆå¹¶é‡åˆ°ç¾éš¾æ€§é—å¿˜ç­‰é—®é¢˜ã€‚å°è¯•æ¢ç´¢ä¸åŒçš„è¶…å‚æ•°ï¼Œä»¥è·å¾—æ•°æ®é›†çš„æœ€ä½³ç»“æœã€‚

æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å¦‚ Stable Diffusion æ˜¯æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒçš„ã€‚

è®­ç»ƒæ¨¡å‹å¯èƒ½ä¼šå¯¹æ‚¨çš„ç¡¬ä»¶é€ æˆè´Ÿæ‹…ï¼Œä½†å¦‚æœå¯ç”¨`gradient_checkpointing`å’Œ`mixed_precision`ï¼Œå¯ä»¥åœ¨å•ä¸ª 24GB GPU ä¸Šè®­ç»ƒæ¨¡å‹ã€‚å¦‚æœæ‚¨ä½¿ç”¨æ›´å¤§çš„æ‰¹é‡å¤§å°è¿›è¡Œè®­ç»ƒæˆ–å¸Œæœ›è®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œæœ€å¥½ä½¿ç”¨å…·æœ‰è¶…è¿‡ 30GB å†…å­˜çš„ GPUã€‚æ‚¨å¯ä»¥é€šè¿‡å¯ç”¨ xFormers çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›æ¥å‡å°‘å†…å­˜å ç”¨ã€‚JAX/Flax è®­ç»ƒä¹Ÿæ”¯æŒåœ¨ TPU å’Œ GPU ä¸Šè¿›è¡Œé«˜æ•ˆè®­ç»ƒï¼Œä½†ä¸æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹ã€æ¢¯åº¦ç´¯ç§¯æˆ– xFormersã€‚å»ºè®®ä½¿ç”¨è‡³å°‘ 30GB å†…å­˜çš„ GPU æˆ– TPU v3 è¿›è¡Œ Flax è®­ç»ƒã€‚

æœ¬æŒ‡å—å°†æ¢ç´¢[train_text_to_image.py](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)è®­ç»ƒè„šæœ¬ï¼Œä»¥å¸®åŠ©æ‚¨ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•ä¸ºè‡ªå·±çš„ç”¨ä¾‹è¿›è¡Œè°ƒæ•´ã€‚

åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨ä»æºä»£ç å®‰è£…åº“ï¼š

```py
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```

ç„¶åè½¬åˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶å®‰è£…æ‚¨æ­£åœ¨ä½¿ç”¨çš„è„šæœ¬æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š

PyTorchFlax

```py
cd examples/text_to_image
pip install -r requirements.txt
```

ğŸ¤— Accelerate æ˜¯ä¸€ä¸ªå¸®åŠ©æ‚¨åœ¨å¤šä¸ª GPU/TPU ä¸Šè®­ç»ƒæˆ–ä½¿ç”¨æ··åˆç²¾åº¦çš„åº“ã€‚å®ƒå°†æ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚æŸ¥çœ‹ğŸ¤— Accelerate [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour)ä»¥äº†è§£æ›´å¤šã€‚

åˆå§‹åŒ–ğŸ¤— Accelerate ç¯å¢ƒï¼š

```py
accelerate config
```

è¦è®¾ç½®é»˜è®¤çš„ğŸ¤— Accelerate ç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š

```py
accelerate config default
```

æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼ shellï¼Œæ¯”å¦‚ç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š

```py
from accelerate.utils import write_basic_config

write_basic_config()
```

æœ€åï¼Œå¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚

## è„šæœ¬å‚æ•°

ä»¥ä¸‹éƒ¨åˆ†çªå‡ºæ˜¾ç¤ºäº†è®­ç»ƒè„šæœ¬çš„ä¸€äº›é‡è¦éƒ¨åˆ†ï¼Œä»¥å¸®åŠ©æ‚¨äº†è§£å¦‚ä½•ä¿®æ”¹å®ƒï¼Œä½†å¹¶æœªè¯¦ç»†æ¶µç›–è„šæœ¬çš„æ¯ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·éšæ—¶é˜…è¯»[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)ï¼Œå¹¶å‘Šè¯‰æˆ‘ä»¬æ‚¨æ˜¯å¦æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ã€‚

è®­ç»ƒè„šæœ¬æä¾›äº†è®¸å¤šå‚æ•°ï¼Œå¸®åŠ©æ‚¨è‡ªå®šä¹‰è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°éƒ½å¯ä»¥åœ¨[`parse_args()`](https://github.com/huggingface/diffusers/blob/8959c5b9dec1c94d6ba482c94a58d2215c5fd026/examples/text_to_image/train_text_to_image.py#L193)å‡½æ•°ä¸­æ‰¾åˆ°ã€‚è¯¥å‡½æ•°ä¸ºæ¯ä¸ªå‚æ•°æä¾›é»˜è®¤å€¼ï¼Œä¾‹å¦‚è®­ç»ƒæ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œä½†å¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚

ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨ fp16 æ ¼å¼åŠ å¿«æ··åˆç²¾åº¦è®­ç»ƒï¼Œè¯·åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ `--mixed_precision`å‚æ•°ï¼š

```py
accelerate launch train_text_to_image.py \
  --mixed_precision="fp16"
```

ä¸€äº›åŸºæœ¬ä¸”é‡è¦çš„å‚æ•°åŒ…æ‹¬ï¼š

+   `--pretrained_model_name_or_path`ï¼šHub ä¸Šæ¨¡å‹çš„åç§°æˆ–æœ¬åœ°é¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„

+   `--dataset_name`ï¼šHub ä¸Šæ•°æ®é›†çš„åç§°æˆ–è¦è®­ç»ƒçš„æ•°æ®é›†çš„æœ¬åœ°è·¯å¾„

+   `--image_column`ï¼šæ•°æ®é›†ä¸­è¦è®­ç»ƒçš„å›¾åƒåˆ—çš„åç§°

+   `--caption_column`ï¼šæ•°æ®é›†ä¸­è¦è®­ç»ƒçš„æ–‡æœ¬åˆ—çš„åç§°

+   `--output_dir`ï¼šä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹çš„ä½ç½®

+   `--push_to_hub`ï¼šæ˜¯å¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ° Hub

+   `--checkpointing_steps`ï¼šä¿å­˜æ£€æŸ¥ç‚¹çš„é¢‘ç‡ï¼Œå½“è®­ç»ƒä¸­æ–­æ—¶ï¼Œå¯ä»¥é€šè¿‡åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ  `--resume_from_checkpoint` ä»è¯¥æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ

### æœ€å°-SNR åŠ æƒ

[æœ€å°-SNR](https://huggingface.co/papers/2303.09556) åŠ æƒç­–ç•¥å¯ä»¥é€šè¿‡é‡æ–°å¹³è¡¡æŸå¤±æ¥å¸®åŠ©è®­ç»ƒï¼Œä»¥å®ç°æ›´å¿«çš„æ”¶æ•›ã€‚è®­ç»ƒè„šæœ¬æ”¯æŒé¢„æµ‹ `epsilon`ï¼ˆå™ªå£°ï¼‰æˆ– `v_prediction`ï¼Œä½†æœ€å°-SNR ä¸ä¸¤ç§é¢„æµ‹ç±»å‹å…¼å®¹ã€‚è¿™ç§åŠ æƒç­–ç•¥ä»…å— PyTorch æ”¯æŒï¼Œåœ¨ Flax è®­ç»ƒè„šæœ¬ä¸­ä¸å¯ç”¨ã€‚

æ·»åŠ  `--snr_gamma` å‚æ•°ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºæ¨èå€¼ 5.0ï¼š

```py
accelerate launch train_text_to_image.py \
  --snr_gamma=5.0
```

æ‚¨å¯ä»¥åœ¨è¿™ä¸ª [Weights and Biases](https://wandb.ai/sayakpaul/text2image-finetune-minsnr) æŠ¥å‘Šä¸­æ¯”è¾ƒä¸åŒ `snr_gamma` å€¼çš„æŸå¤±æ›²é¢ã€‚å¯¹äºè¾ƒå°çš„æ•°æ®é›†ï¼Œä¸è¾ƒå¤§æ•°æ®é›†ç›¸æ¯”ï¼Œæœ€å°-SNR çš„å½±å“å¯èƒ½ä¸é‚£ä¹ˆæ˜æ˜¾ã€‚

## è®­ç»ƒè„šæœ¬

æ•°æ®é›†é¢„å¤„ç†ä»£ç å’Œè®­ç»ƒå¾ªç¯åœ¨ [`main()`](https://github.com/huggingface/diffusers/blob/8959c5b9dec1c94d6ba482c94a58d2215c5fd026/examples/text_to_image/train_text_to_image.py#L490) å‡½æ•°ä¸­ã€‚å¦‚æœéœ€è¦è°ƒæ•´è®­ç»ƒè„šæœ¬ï¼Œè¿™å°±æ˜¯æ‚¨éœ€è¦è¿›è¡Œæ›´æ”¹çš„åœ°æ–¹ã€‚

`train_text_to_image` è„šæœ¬é¦–å…ˆ[åŠ è½½è°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/8959c5b9dec1c94d6ba482c94a58d2215c5fd026/examples/text_to_image/train_text_to_image.py#L543)å’Œåˆ†è¯å™¨ã€‚å¦‚æœéœ€è¦ï¼Œæ‚¨å¯ä»¥é€‰æ‹©åœ¨è¿™é‡Œä½¿ç”¨ä¸åŒçš„è°ƒåº¦å™¨ï¼š

```py
noise_scheduler = DDPMScheduler.from_pretrained(args.pretrained_model_name_or_path, subfolder="scheduler")
tokenizer = CLIPTokenizer.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="tokenizer", revision=args.revision
)
```

ç„¶åè„šæœ¬[åŠ è½½ UNet](https://github.com/huggingface/diffusers/blob/8959c5b9dec1c94d6ba482c94a58d2215c5fd026/examples/text_to_image/train_text_to_image.py#L619) æ¨¡å‹ï¼š

```py
load_model = UNet2DConditionModel.from_pretrained(input_dir, subfolder="unet")
model.register_to_config(**load_model.config)

model.load_state_dict(load_model.state_dict())
```

æ¥ä¸‹æ¥ï¼Œéœ€è¦å¯¹æ•°æ®é›†çš„æ–‡æœ¬å’Œå›¾åƒåˆ—è¿›è¡Œé¢„å¤„ç†ã€‚[`tokenize_captions`](https://github.com/huggingface/diffusers/blob/8959c5b9dec1c94d6ba482c94a58d2215c5fd026/examples/text_to_image/train_text_to_image.py#L724) å‡½æ•°å¤„ç†è¾“å…¥çš„åˆ†è¯ï¼Œ[`train_transforms`](https://github.com/huggingface/diffusers/blob/8959c5b9dec1c94d6ba482c94a58d2215c5fd026/examples/text_to_image/train_text_to_image.py#L742) å‡½æ•°æŒ‡å®šè¦åº”ç”¨äºå›¾åƒçš„è½¬æ¢ç±»å‹ã€‚è¿™ä¸¤ä¸ªå‡½æ•°éƒ½æ‰“åŒ…åˆ° `preprocess_train` ä¸­ï¼š

```py
def preprocess_train(examples):
    images = [image.convert("RGB") for image in examples[image_column]]
    examples["pixel_values"] = [train_transforms(image) for image in images]
    examples["input_ids"] = tokenize_captions(examples)
    return examples
```

æœ€åï¼Œ[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/8959c5b9dec1c94d6ba482c94a58d2215c5fd026/examples/text_to_image/train_text_to_image.py#L878) å¤„ç†å…¶ä»–æ‰€æœ‰äº‹åŠ¡ã€‚å®ƒå°†å›¾åƒç¼–ç ä¸ºæ½œåœ¨ç©ºé—´ï¼Œå‘æ½œåœ¨ç©ºé—´æ·»åŠ å™ªå£°ï¼Œè®¡ç®—æ–‡æœ¬åµŒå…¥ä»¥è¿›è¡Œæ¡ä»¶åŒ–ï¼Œæ›´æ–°æ¨¡å‹å‚æ•°ï¼Œå¹¶å°†æ¨¡å‹ä¿å­˜å¹¶æ¨é€åˆ° Hubã€‚å¦‚æœæ‚¨æƒ³äº†è§£è®­ç»ƒå¾ªç¯çš„å·¥ä½œåŸç†ï¼Œè¯·æŸ¥çœ‹ äº†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦å™¨ æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹è¯¦ç»†ä»‹ç»äº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚

## å¯åŠ¨è„šæœ¬

ä¸€æ—¦æ‚¨å®Œæˆæ‰€æœ‰æ›´æ”¹æˆ–å¯¹é»˜è®¤é…ç½®æ»¡æ„ï¼Œæ‚¨å°±å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€

PyTorchFlax

è®©æˆ‘ä»¬åœ¨ [PokÃ©mon BLIP æ ‡é¢˜](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions) æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œç”Ÿæˆæ‚¨è‡ªå·±çš„ PokÃ©monã€‚å°†ç¯å¢ƒå˜é‡ `MODEL_NAME` å’Œ `dataset_name` è®¾ç½®ä¸ºæ¨¡å‹å’Œæ•°æ®é›†ï¼ˆæ¥è‡ª Hub æˆ–æœ¬åœ°è·¯å¾„ï¼‰ã€‚å¦‚æœæ‚¨è¦åœ¨å¤šä¸ª GPU ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¯·åœ¨ `accelerate launch` å‘½ä»¤ä¸­æ·»åŠ  `--multi_gpu` å‚æ•°ã€‚

è¦åœ¨æœ¬åœ°æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œè¯·å°† `TRAIN_DIR` å’Œ `OUTPUT_DIR` ç¯å¢ƒå˜é‡è®¾ç½®ä¸ºæ•°æ®é›†çš„è·¯å¾„å’Œè¦ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚

```py
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export dataset_name="lambdalabs/pokemon-blip-captions"

accelerate launch --mixed_precision="fp16"  train_text_to_image.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$dataset_name \
  --use_ema \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --gradient_checkpointing \
  --max_train_steps=15000 \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --enable_xformers_memory_efficient_attention
  --lr_scheduler="constant" --lr_warmup_steps=0 \
  --output_dir="sd-pokemon-model" \
  --push_to_hub
```

è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ–°è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼š

PyTorchFlax

```py
from diffusers import StableDiffusionPipeline
import torch

pipeline = StableDiffusionPipeline.from_pretrained("path/to/saved_model", torch_dtype=torch.float16, use_safetensors=True).to("cuda")

image = pipeline(prompt="yoda").images[0]
image.save("yoda-pokemon.png")
```

## ä¸‹ä¸€æ­¥

ç¥è´ºæ‚¨è®­ç»ƒæˆåŠŸè‡ªå·±çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼è¦äº†è§£å¦‚ä½•ä½¿ç”¨æ‚¨çš„æ–°æ¨¡å‹ï¼Œä»¥ä¸‹æŒ‡å—å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼š

+   å­¦ä¹ å¦‚ä½•åœ¨æ¨ç†æ—¶åŠ è½½ LoRA æƒé‡ï¼Œå¦‚æœæ‚¨ä½¿ç”¨ LoRA è®­ç»ƒäº†æ‚¨çš„æ¨¡å‹ã€‚

+   äº†è§£æ›´å¤šå…³äºå¦‚ä½•é€šè¿‡æŒ‡å¯¼å°ºåº¦ç­‰å‚æ•°æˆ–æŠ€æœ¯ï¼Œå¦‚æç¤ºåŠ æƒï¼Œæ¥å¸®åŠ©æ‚¨æ§åˆ¶åœ¨æ–‡æœ¬åˆ°å›¾åƒä»»åŠ¡æŒ‡å—ä¸­çš„æ¨ç†ã€‚
