- en: Checks on a Pull Request
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://huggingface.co/docs/transformers/v4.37.2/en/pr_checks](https://huggingface.co/docs/transformers/v4.37.2/en/pr_checks)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/transformers/v4.37.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/start.1af50ed5.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/scheduler.9bc65507.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/singletons.a2d7fdf1.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.3b203c72.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/paths.b8f1dad4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/app.59e74a31.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.707bf1b6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/0.dbd8cc12.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/332.3c7b943d.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Tip.c2ecdbf4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/CodeBlock.54a9f38d.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Heading.342b1fa6.js">
  prefs: []
  type: TYPE_NORMAL
- en: 'When you open a pull request on ü§ó Transformers, a fair number of checks will
    be run to make sure the patch you are adding is not breaking anything existing.
    Those checks are of four types:'
  prefs: []
  type: TYPE_NORMAL
- en: regular tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: documentation build
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: code and documentation style
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: general repository consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this document, we will take a stab at explaining what those various checks
    are and the reason behind them, as well as how to debug them locally if one of
    them fails on your PR.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that, ideally, they require you to have a dev install:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'or for an editable install:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: inside the Transformers repo. Since the number of optional dependencies of Transformers
    has grown a lot, it‚Äôs possible you don‚Äôt manage to get all of them. If the dev
    install fails, make sure to install the Deep Learning framework you are working
    with (PyTorch, TensorFlow and/or Flax) then do
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'or for an editable install:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All the jobs that begin with `ci/circleci: run_tests_` run parts of the Transformers
    testing suite. Each of those jobs focuses on a part of the library in a certain
    environment: for instance `ci/circleci: run_tests_pipelines_tf` runs the pipelines
    test in an environment where TensorFlow only is installed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that to avoid running tests when there is no real change in the modules
    they are testing, only part of the test suite is run each time: a utility is run
    to determine the differences in the library between before and after the PR (what
    GitHub shows you in the ‚ÄúFiles changes‚Äù tab) and picks the tests impacted by that
    diff. That utility can be run locally with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'from the root of the Transformers repo. It will:'
  prefs: []
  type: TYPE_NORMAL
- en: Check for each file in the diff if the changes are in the code or only in comments
    or docstrings. Only the files with real code changes are kept.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build an internal map that gives for each file of the source code of the library
    all the files it recursively impacts. Module A is said to impact module B if module
    B imports module A. For the recursive impact, we need a chain of modules going
    from module A to module B in which each module imports the previous one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply this map on the files gathered in step 1, which gives us the list of model
    files impacted by the PR.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Map each of those files to their corresponding test file(s) and get the list
    of tests to run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When executing the script locally, you should get the results of step 1, 3
    and 4 printed and thus know which tests are run. The script will also create a
    file named `test_list.txt` which contains the list of tests to run, and you can
    run them locally with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Just in case anything slipped through the cracks, the full test suite is also
    run daily.
  prefs: []
  type: TYPE_NORMAL
- en: Documentation build
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `build_pr_documentation` job builds and generates a preview of the documentation
    to make sure everything looks okay once your PR is merged. A bot will add a link
    to preview the documentation in your PR. Any changes you make to the PR are automatically
    updated in the preview. If the documentation fails to build, click on **Details**
    next to the failed job to see where things went wrong. Often, the error is as
    simple as a missing file in the `toctree`.
  prefs: []
  type: TYPE_NORMAL
- en: If you‚Äôre interested in building or previewing the documentation locally, take
    a look at the [`README.md`](https://github.com/huggingface/transformers/tree/main/docs)
    in the docs folder.
  prefs: []
  type: TYPE_NORMAL
- en: Code and documentation style
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Code formatting is applied to all the source files, the examples and the tests
    using `black` and `ruff`. We also have a custom tool taking care of the formatting
    of docstrings and `rst` files (`utils/style_doc.py`), as well as the order of
    the lazy imports performed in the Transformers `__init__.py` files (`utils/custom_init_isort.py`).
    All of this can be launched by executing
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The CI checks those have been applied inside the `ci/circleci: check_code_quality`
    check. It also runs `ruff`, that will have a basic look at your code and will
    complain if it finds an undefined variable, or one that is not used. To run that
    check locally, use'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This can take a lot of time, so to run the same thing on only the files you
    modified in the current branch, run
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This last command will also run all the additional checks for the repository
    consistency. Let‚Äôs have a look at them.
  prefs: []
  type: TYPE_NORMAL
- en: Repository consistency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This regroups all the tests to make sure your PR leaves the repository in a
    good state, and is performed by the `ci/circleci: check_repository_consistency`
    check. You can locally run that check by executing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This checks that:'
  prefs: []
  type: TYPE_NORMAL
- en: All objects added to the init are documented (performed by `utils/check_repo.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All `__init__.py` files have the same content in their two sections (performed
    by `utils/check_inits.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All code identified as a copy from another module is consistent with the original
    (performed by `utils/check_copies.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All configuration classes have at least one valid checkpoint mentioned in their
    docstrings (performed by `utils/check_config_docstrings.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All configuration classes only contain attributes that are used in corresponding
    modeling files (performed by `utils/check_config_attributes.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The translations of the READMEs and the index of the doc have the same model
    list as the main README (performed by `utils/check_copies.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The auto-generated tables in the documentation are up to date (performed by
    `utils/check_table.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The library has all objects available even if not all optional dependencies
    are installed (performed by `utils/check_dummies.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All docstrings properly document the arguments in the signature of the object
    (performed by `utils/check_docstrings.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Should this check fail, the first two items require manual fixing, the last
    four can be fixed automatically for you by running the command
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Additional checks concern PRs that add new models, mainly that:'
  prefs: []
  type: TYPE_NORMAL
- en: All models added are in an Auto-mapping (performed by `utils/check_repo.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All models are properly tested (performed by `utils/check_repo.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check copies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since the Transformers library is very opinionated with respect to model code,
    and each model should fully be implemented in a single file without relying on
    other models, we have added a mechanism that checks whether a copy of the code
    of a layer of a given model stays consistent with the original. This way, when
    there is a bug fix, we can see all other impacted models and choose to trickle
    down the modification or break the copy.
  prefs: []
  type: TYPE_NORMAL
- en: If a file is a full copy of another file, you should register it in the constant
    `FULL_COPIES` of `utils/check_copies.py`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This mechanism relies on comments of the form `# Copied from xxx`. The `xxx`
    should contain the whole path to the class of function which is being copied below.
    For instance, `RobertaSelfOutput` is a direct copy of the `BertSelfOutput` class,
    so you can see [here](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L289)
    it has a comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that instead of applying this to a whole class, you can apply it to the
    relevant methods that are copied from. For instance [here](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L598)
    you can see how `RobertaPreTrainedModel._init_weights` is copied from the same
    method in `BertPreTrainedModel` with the comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes the copy is exactly the same except for names: for instance in `RobertaAttention`,
    we use `RobertaSelfAttention` insted of `BertSelfAttention` but other than that,
    the code is exactly the same. This is why `# Copied from` supports simple string
    replacements with the follwoing syntax: `Copied from xxx with foo->bar`. This
    means the code is copied with all instances of `foo` being replaced by `bar`.
    You can see how it used [here](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L304C1-L304C86)
    in `RobertaAttention` with the comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that there shouldn‚Äôt be any spaces around the arrow (unless that space
    is part of the pattern to replace of course).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can add several patterns separated by a comma. For instance here `CamemberForMaskedLM`
    is a direct copy of `RobertaForMaskedLM` with two replacements: `Roberta` to `Camembert`
    and `ROBERTA` to `CAMEMBERT`. You can see [here](https://github.com/huggingface/transformers/blob/15082a9dc6950ecae63a0d3e5060b2fc7f15050a/src/transformers/models/camembert/modeling_camembert.py#L929)
    this is done with the comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: If the order matters (because one of the replacements might conflict with a
    previous one), the replacements are executed from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: If the replacements change the formatting (if you replace a short name by a
    very long name for instance), the copy is checked after applying the auto-formatter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way when the patterns are just different casings of the same replacement
    (with an uppercased and a lowercased variants) is just to add the option `all-casing`.
    [Here](https://github.com/huggingface/transformers/blob/15082a9dc6950ecae63a0d3e5060b2fc7f15050a/src/transformers/models/mobilebert/modeling_mobilebert.py#L1237)
    is an example in `MobileBertForSequenceClassification` with the comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the code is copied from `BertForSequenceClassification` by replacing:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Bert` by `MobileBert` (for instance when using `MobileBertModel` in the init)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bert` by `mobilebert` (for instance when defining `self.mobilebert`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BERT` by `MOBILEBERT` (in the constant `MOBILEBERT_INPUTS_DOCSTRING`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
