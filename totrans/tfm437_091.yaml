- en: Checks on a Pull Request
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/transformers/v4.37.2/en/pr_checks](https://huggingface.co/docs/transformers/v4.37.2/en/pr_checks)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/transformers/v4.37.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/start.1af50ed5.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/scheduler.9bc65507.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/singletons.a2d7fdf1.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.3b203c72.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/paths.b8f1dad4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/app.59e74a31.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.707bf1b6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/0.dbd8cc12.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/332.3c7b943d.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Tip.c2ecdbf4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/CodeBlock.54a9f38d.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Heading.342b1fa6.js">
  prefs: []
  type: TYPE_NORMAL
- en: 'When you open a pull request on ðŸ¤— Transformers, a fair number of checks will
    be run to make sure the patch you are adding is not breaking anything existing.
    Those checks are of four types:'
  prefs: []
  type: TYPE_NORMAL
- en: regular tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: documentation build
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: code and documentation style
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: general repository consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this document, we will take a stab at explaining what those various checks
    are and the reason behind them, as well as how to debug them locally if one of
    them fails on your PR.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that, ideally, they require you to have a dev install:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'or for an editable install:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: inside the Transformers repo. Since the number of optional dependencies of Transformers
    has grown a lot, itâ€™s possible you donâ€™t manage to get all of them. If the dev
    install fails, make sure to install the Deep Learning framework you are working
    with (PyTorch, TensorFlow and/or Flax) then do
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'or for an editable install:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All the jobs that begin with `ci/circleci: run_tests_` run parts of the Transformers
    testing suite. Each of those jobs focuses on a part of the library in a certain
    environment: for instance `ci/circleci: run_tests_pipelines_tf` runs the pipelines
    test in an environment where TensorFlow only is installed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that to avoid running tests when there is no real change in the modules
    they are testing, only part of the test suite is run each time: a utility is run
    to determine the differences in the library between before and after the PR (what
    GitHub shows you in the â€œFiles changesâ€ tab) and picks the tests impacted by that
    diff. That utility can be run locally with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'from the root of the Transformers repo. It will:'
  prefs: []
  type: TYPE_NORMAL
- en: Check for each file in the diff if the changes are in the code or only in comments
    or docstrings. Only the files with real code changes are kept.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build an internal map that gives for each file of the source code of the library
    all the files it recursively impacts. Module A is said to impact module B if module
    B imports module A. For the recursive impact, we need a chain of modules going
    from module A to module B in which each module imports the previous one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply this map on the files gathered in step 1, which gives us the list of model
    files impacted by the PR.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Map each of those files to their corresponding test file(s) and get the list
    of tests to run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When executing the script locally, you should get the results of step 1, 3
    and 4 printed and thus know which tests are run. The script will also create a
    file named `test_list.txt` which contains the list of tests to run, and you can
    run them locally with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Just in case anything slipped through the cracks, the full test suite is also
    run daily.
  prefs: []
  type: TYPE_NORMAL
- en: Documentation build
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `build_pr_documentation` job builds and generates a preview of the documentation
    to make sure everything looks okay once your PR is merged. A bot will add a link
    to preview the documentation in your PR. Any changes you make to the PR are automatically
    updated in the preview. If the documentation fails to build, click on **Details**
    next to the failed job to see where things went wrong. Often, the error is as
    simple as a missing file in the `toctree`.
  prefs: []
  type: TYPE_NORMAL
- en: If youâ€™re interested in building or previewing the documentation locally, take
    a look at the [`README.md`](https://github.com/huggingface/transformers/tree/main/docs)
    in the docs folder.
  prefs: []
  type: TYPE_NORMAL
- en: Code and documentation style
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Code formatting is applied to all the source files, the examples and the tests
    using `black` and `ruff`. We also have a custom tool taking care of the formatting
    of docstrings and `rst` files (`utils/style_doc.py`), as well as the order of
    the lazy imports performed in the Transformers `__init__.py` files (`utils/custom_init_isort.py`).
    All of this can be launched by executing
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The CI checks those have been applied inside the `ci/circleci: check_code_quality`
    check. It also runs `ruff`, that will have a basic look at your code and will
    complain if it finds an undefined variable, or one that is not used. To run that
    check locally, use'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This can take a lot of time, so to run the same thing on only the files you
    modified in the current branch, run
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This last command will also run all the additional checks for the repository
    consistency. Letâ€™s have a look at them.
  prefs: []
  type: TYPE_NORMAL
- en: Repository consistency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This regroups all the tests to make sure your PR leaves the repository in a
    good state, and is performed by the `ci/circleci: check_repository_consistency`
    check. You can locally run that check by executing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This checks that:'
  prefs: []
  type: TYPE_NORMAL
- en: All objects added to the init are documented (performed by `utils/check_repo.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All `__init__.py` files have the same content in their two sections (performed
    by `utils/check_inits.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All code identified as a copy from another module is consistent with the original
    (performed by `utils/check_copies.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All configuration classes have at least one valid checkpoint mentioned in their
    docstrings (performed by `utils/check_config_docstrings.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All configuration classes only contain attributes that are used in corresponding
    modeling files (performed by `utils/check_config_attributes.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The translations of the READMEs and the index of the doc have the same model
    list as the main README (performed by `utils/check_copies.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The auto-generated tables in the documentation are up to date (performed by
    `utils/check_table.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The library has all objects available even if not all optional dependencies
    are installed (performed by `utils/check_dummies.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All docstrings properly document the arguments in the signature of the object
    (performed by `utils/check_docstrings.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Should this check fail, the first two items require manual fixing, the last
    four can be fixed automatically for you by running the command
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Additional checks concern PRs that add new models, mainly that:'
  prefs: []
  type: TYPE_NORMAL
- en: All models added are in an Auto-mapping (performed by `utils/check_repo.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All models are properly tested (performed by `utils/check_repo.py`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check copies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since the Transformers library is very opinionated with respect to model code,
    and each model should fully be implemented in a single file without relying on
    other models, we have added a mechanism that checks whether a copy of the code
    of a layer of a given model stays consistent with the original. This way, when
    there is a bug fix, we can see all other impacted models and choose to trickle
    down the modification or break the copy.
  prefs: []
  type: TYPE_NORMAL
- en: If a file is a full copy of another file, you should register it in the constant
    `FULL_COPIES` of `utils/check_copies.py`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This mechanism relies on comments of the form `# Copied from xxx`. The `xxx`
    should contain the whole path to the class of function which is being copied below.
    For instance, `RobertaSelfOutput` is a direct copy of the `BertSelfOutput` class,
    so you can see [here](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L289)
    it has a comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that instead of applying this to a whole class, you can apply it to the
    relevant methods that are copied from. For instance [here](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L598)
    you can see how `RobertaPreTrainedModel._init_weights` is copied from the same
    method in `BertPreTrainedModel` with the comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes the copy is exactly the same except for names: for instance in `RobertaAttention`,
    we use `RobertaSelfAttention` insted of `BertSelfAttention` but other than that,
    the code is exactly the same. This is why `# Copied from` supports simple string
    replacements with the follwoing syntax: `Copied from xxx with foo->bar`. This
    means the code is copied with all instances of `foo` being replaced by `bar`.
    You can see how it used [here](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L304C1-L304C86)
    in `RobertaAttention` with the comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that there shouldnâ€™t be any spaces around the arrow (unless that space
    is part of the pattern to replace of course).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can add several patterns separated by a comma. For instance here `CamemberForMaskedLM`
    is a direct copy of `RobertaForMaskedLM` with two replacements: `Roberta` to `Camembert`
    and `ROBERTA` to `CAMEMBERT`. You can see [here](https://github.com/huggingface/transformers/blob/15082a9dc6950ecae63a0d3e5060b2fc7f15050a/src/transformers/models/camembert/modeling_camembert.py#L929)
    this is done with the comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: If the order matters (because one of the replacements might conflict with a
    previous one), the replacements are executed from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: If the replacements change the formatting (if you replace a short name by a
    very long name for instance), the copy is checked after applying the auto-formatter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way when the patterns are just different casings of the same replacement
    (with an uppercased and a lowercased variants) is just to add the option `all-casing`.
    [Here](https://github.com/huggingface/transformers/blob/15082a9dc6950ecae63a0d3e5060b2fc7f15050a/src/transformers/models/mobilebert/modeling_mobilebert.py#L1237)
    is an example in `MobileBertForSequenceClassification` with the comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the code is copied from `BertForSequenceClassification` by replacing:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Bert` by `MobileBert` (for instance when using `MobileBertModel` in the init)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bert` by `mobilebert` (for instance when defining `self.mobilebert`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BERT` by `MOBILEBERT` (in the constant `MOBILEBERT_INPUTS_DOCSTRING`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
