["```py\nexport HUGGING_FACE_HUB_TOKEN=<YOUR READ TOKEN>\n```", "```py\nmodel=meta-llama/Llama-2-7b-chat-hf\nvolume=$PWD/data\ntoken=<your READ token>\n\ndocker run --gpus all \\\n    --shm-size 1g \\\n    -e HUGGING_FACE_HUB_TOKEN=$token \\\n    -p 8080:80 \\\n    -v $volume:/data ghcr.io/huggingface/text-generation-inference:1.4 \\\n    --model-id $model\n```"]