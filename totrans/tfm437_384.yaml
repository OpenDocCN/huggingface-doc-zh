- en: Informer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/informer](https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/informer)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/transformers/v4.37.2/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/start.1af50ed5.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/scheduler.9bc65507.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/singletons.a2d7fdf1.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.3b203c72.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/paths.b8f1dad4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/entry/app.59e74a31.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/index.707bf1b6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/0.dbd8cc12.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/nodes/154.b0359b10.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Tip.c2ecdbf4.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Docstring.17db21ae.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/globals.7f7f1b26.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/Heading.342b1fa6.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/CodeBlock.54a9f38d.js">
    <link rel="modulepreload" href="/docs/transformers/v4.37.2/en/_app/immutable/chunks/ExampleCodeBlock.4f515aa9.js">
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Informer model was proposed in [Informer: Beyond Efficient Transformer
    for Long Sequence Time-Series Forecasting](https://arxiv.org/abs/2012.07436) by
    Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and
    Wancai Zhang.'
  prefs: []
  type: TYPE_NORMAL
- en: This method introduces a Probabilistic Attention mechanism to select the ‚Äúactive‚Äù
    queries rather than the ‚Äúlazy‚Äù queries and provides a sparse Transformer thus
    mitigating the quadratic compute and memory requirements of vanilla attention.
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Many real-world applications require the prediction of long sequence time-series,
    such as electricity consumption planning. Long sequence time-series forecasting
    (LSTF) demands a high prediction capacity of the model, which is the ability to
    capture precise long-range dependency coupling between output and input efficiently.
    Recent studies have shown the potential of Transformer to increase the prediction
    capacity. However, there are several severe issues with Transformer that prevent
    it from being directly applicable to LSTF, including quadratic time complexity,
    high memory usage, and inherent limitation of the encoder-decoder architecture.
    To address these issues, we design an efficient transformer-based model for LSTF,
    named Informer, with three distinctive characteristics: (i) a ProbSparse self-attention
    mechanism, which achieves O(L logL) in time complexity and memory usage, and has
    comparable performance on sequences‚Äô dependency alignment. (ii) the self-attention
    distilling highlights dominating attention by halving cascading layer input, and
    efficiently handles extreme long input sequences. (iii) the generative style decoder,
    while conceptually simple, predicts the long time-series sequences at one forward
    operation rather than a step-by-step way, which drastically improves the inference
    speed of long-sequence predictions. Extensive experiments on four large-scale
    datasets demonstrate that Informer significantly outperforms existing methods
    and provides a new solution to the LSTF problem.*'
  prefs: []
  type: TYPE_NORMAL
- en: This model was contributed by [elisim](https://huggingface.co/elisim) and [kashif](https://huggingface.co/kashif).
    The original code can be found [here](https://github.com/zhouhaoyi/Informer2020).
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A list of official Hugging Face and community (indicated by üåé) resources to
    help you get started. If you‚Äôre interested in submitting a resource to be included
    here, please feel free to open a Pull Request and we‚Äôll review it! The resource
    should ideally demonstrate something new instead of duplicating an existing resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the Informer blog-post in HuggingFace blog: [Multivariate Probabilistic
    Time Series Forecasting with Informer](https://huggingface.co/blog/informer)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: InformerConfig
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class transformers.InformerConfig'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/informer/configuration_informer.py#L33)'
  prefs: []
  type: TYPE_NORMAL
- en: '( prediction_length: Optional = None context_length: Optional = None distribution_output:
    str = ''student_t'' loss: str = ''nll'' input_size: int = 1 lags_sequence: List
    = None scaling: Union = ''mean'' num_dynamic_real_features: int = 0 num_static_real_features:
    int = 0 num_static_categorical_features: int = 0 num_time_features: int = 0 cardinality:
    Optional = None embedding_dimension: Optional = None d_model: int = 64 encoder_ffn_dim:
    int = 32 decoder_ffn_dim: int = 32 encoder_attention_heads: int = 2 decoder_attention_heads:
    int = 2 encoder_layers: int = 2 decoder_layers: int = 2 is_encoder_decoder: bool
    = True activation_function: str = ''gelu'' dropout: float = 0.05 encoder_layerdrop:
    float = 0.1 decoder_layerdrop: float = 0.1 attention_dropout: float = 0.1 activation_dropout:
    float = 0.1 num_parallel_samples: int = 100 init_std: float = 0.02 use_cache =
    True attention_type: str = ''prob'' sampling_factor: int = 5 distil: bool = True
    **kwargs )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**prediction_length** (`int`) ‚Äî The prediction length for the decoder. In other
    words, the prediction horizon of the model. This value is typically dictated by
    the dataset and we recommend to set it appropriately.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**context_length** (`int`, *optional*, defaults to `prediction_length`) ‚Äî The
    context length for the encoder. If `None`, the context length will be the same
    as the `prediction_length`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distribution_output** (`string`, *optional*, defaults to `"student_t"`) ‚Äî
    The distribution emission head for the model. Could be either ‚Äústudent_t‚Äù, ‚Äúnormal‚Äù
    or ‚Äúnegative_binomial‚Äù.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**loss** (`string`, *optional*, defaults to `"nll"`) ‚Äî The loss function for
    the model corresponding to the `distribution_output` head. For parametric distributions
    it is the negative log likelihood (nll) - which currently is the only supported
    one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**input_size** (`int`, *optional*, defaults to 1) ‚Äî The size of the target
    variable which by default is 1 for univariate targets. Would be > 1 in case of
    multivariate targets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**scaling** (`string` or `bool`, *optional* defaults to `"mean"`) ‚Äî Whether
    to scale the input targets via ‚Äúmean‚Äù scaler, ‚Äústd‚Äù scaler or no scaler if `None`.
    If `True`, the scaler is set to ‚Äúmean‚Äù.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**lags_sequence** (`list[int]`, *optional*, defaults to `[1, 2, 3, 4, 5, 6,
    7]`) ‚Äî The lags of the input time series as covariates often dictated by the frequency
    of the data. Default is `[1, 2, 3, 4, 5, 6, 7]` but we recommend to change it
    based on the dataset appropriately.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**num_time_features** (`int`, *optional*, defaults to 0) ‚Äî The number of time
    features in the input time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**num_dynamic_real_features** (`int`, *optional*, defaults to 0) ‚Äî The number
    of dynamic real valued features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**num_static_categorical_features** (`int`, *optional*, defaults to 0) ‚Äî The
    number of static categorical features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**num_static_real_features** (`int`, *optional*, defaults to 0) ‚Äî The number
    of static real valued features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cardinality** (`list[int]`, *optional*) ‚Äî The cardinality (number of different
    values) for each of the static categorical features. Should be a list of integers,
    having the same length as `num_static_categorical_features`. Cannot be `None`
    if `num_static_categorical_features` is > 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**embedding_dimension** (`list[int]`, *optional*) ‚Äî The dimension of the embedding
    for each of the static categorical features. Should be a list of integers, having
    the same length as `num_static_categorical_features`. Cannot be `None` if `num_static_categorical_features`
    is > 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**d_model** (`int`, *optional*, defaults to 64) ‚Äî Dimensionality of the transformer
    layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder_layers** (`int`, *optional*, defaults to 2) ‚Äî Number of encoder layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**decoder_layers** (`int`, *optional*, defaults to 2) ‚Äî Number of decoder layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder_attention_heads** (`int`, *optional*, defaults to 2) ‚Äî Number of
    attention heads for each attention layer in the Transformer encoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**decoder_attention_heads** (`int`, *optional*, defaults to 2) ‚Äî Number of
    attention heads for each attention layer in the Transformer decoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder_ffn_dim** (`int`, *optional*, defaults to 32) ‚Äî Dimension of the
    ‚Äúintermediate‚Äù (often named feed-forward) layer in encoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**decoder_ffn_dim** (`int`, *optional*, defaults to 32) ‚Äî Dimension of the
    ‚Äúintermediate‚Äù (often named feed-forward) layer in decoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**activation_function** (`str` or `function`, *optional*, defaults to `"gelu"`)
    ‚Äî The non-linear activation function (function or string) in the encoder and decoder.
    If string, `"gelu"` and `"relu"` are supported.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**dropout** (`float`, *optional*, defaults to 0.1) ‚Äî The dropout probability
    for all fully connected layers in the encoder, and decoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder_layerdrop** (`float`, *optional*, defaults to 0.1) ‚Äî The dropout
    probability for the attention and fully connected layers for each encoder layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**decoder_layerdrop** (`float`, *optional*, defaults to 0.1) ‚Äî The dropout
    probability for the attention and fully connected layers for each decoder layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**attention_dropout** (`float`, *optional*, defaults to 0.1) ‚Äî The dropout
    probability for the attention probabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**activation_dropout** (`float`, *optional*, defaults to 0.1) ‚Äî The dropout
    probability used between the two layers of the feed-forward networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**num_parallel_samples** (`int`, *optional*, defaults to 100) ‚Äî The number
    of samples to generate in parallel for each time step of inference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**init_std** (`float`, *optional*, defaults to 0.02) ‚Äî The standard deviation
    of the truncated normal weight initialization distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**use_cache** (`bool`, *optional*, defaults to `True`) ‚Äî Whether to use the
    past key/values attentions (if applicable to the model) to speed up decoding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**attention_type** (`str`, *optional*, defaults to ‚Äúprob‚Äù) ‚Äî Attention used
    in encoder. This can be set to ‚Äúprob‚Äù (Informer‚Äôs ProbAttention) or ‚Äúfull‚Äù (vanilla
    transformer‚Äôs canonical self-attention).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sampling_factor** (`int`, *optional*, defaults to 5) ‚Äî ProbSparse sampling
    factor (only makes affect when `attention_type`=‚Äúprob‚Äù). It is used to control
    the reduced query matrix (Q_reduce) input length.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**distil** (`bool`, *optional*, defaults to `True`) ‚Äî Whether to use distilling
    in encoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the configuration class to store the configuration of an [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel).
    It is used to instantiate an Informer model according to the specified arguments,
    defining the model architecture. Instantiating a configuration with the defaults
    will yield a similar configuration to that of the Informer [huggingface/informer-tourism-monthly](https://huggingface.co/huggingface/informer-tourism-monthly)
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration objects inherit from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    can be used to control the model outputs. Read the documentation from [PretrainedConfig](/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: InformerModel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class transformers.InformerModel'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/informer/modeling_informer.py#L1442)'
  prefs: []
  type: TYPE_NORMAL
- en: '( config: InformerConfig )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig))
    ‚Äî Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bare Informer Model outputting raw hidden-states without any specific head
    on top. This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  prefs: []
  type: TYPE_NORMAL
- en: '#### forward'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/informer/modeling_informer.py#L1585)'
  prefs: []
  type: TYPE_NORMAL
- en: '( past_values: Tensor past_time_features: Tensor past_observed_mask: Tensor
    static_categorical_features: Optional = None static_real_features: Optional =
    None future_values: Optional = None future_time_features: Optional = None decoder_attention_mask:
    Optional = None head_mask: Optional = None decoder_head_mask: Optional = None
    cross_attn_head_mask: Optional = None encoder_outputs: Optional = None past_key_values:
    Optional = None output_hidden_states: Optional = None output_attentions: Optional
    = None use_cache: Optional = None return_dict: Optional = None ) ‚Üí [transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or `tuple(torch.FloatTensor)`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**past_values** (`torch.FloatTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`) ‚Äî Past values of the time series,
    that serve as context in order to predict the future. The sequence size of this
    tensor must be larger than the `context_length` of the model, since the model
    will use the larger size to construct lag features, i.e. additional values from
    the past which are added in order to serve as ‚Äúextra context‚Äù.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `sequence_length` here is equal to `config.context_length` + `max(config.lags_sequence)`,
    which if no `lags_sequence` is configured, is equal to `config.context_length`
    + 7 (as by default, the largest look-back index in `config.lags_sequence` is 7).
    The property `_past_length` returns the actual length of the past.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `past_values` is what the Transformer encoder gets as input (with optional
    additional features, such as `static_categorical_features`, `static_real_features`,
    `past_time_features` and lags).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Optionally, missing values need to be replaced with zeros and indicated via
    the `past_observed_mask`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For multivariate time series, the `input_size` > 1 dimension is required and
    corresponds to the number of variates in the time series per time step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**past_time_features** (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_features)`) ‚Äî Required time features, which the model internally will add
    to `past_values`. These could be things like ‚Äúmonth of year‚Äù, ‚Äúday of the month‚Äù,
    etc. encoded as vectors (for instance as Fourier features). These could also be
    so-called ‚Äúage‚Äù features, which basically help the model know ‚Äúat which point
    in life‚Äù a time-series is. Age features have small values for distant past time
    steps and increase monotonically the more we approach the current time step. Holiday
    features are also a good example of time features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These features serve as the ‚Äúpositional encodings‚Äù of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features. The Time Series Transformer only learns additional embeddings for
    `static_categorical_features`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Additional dynamic real covariates can be concatenated to this tensor, with
    the caveat that these features must but known at prediction time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `num_features` here is equal to `config.`num_time_features`+`config.num_dynamic_real_features`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**past_observed_mask** (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) ‚Äî Boolean mask to
    indicate which `past_values` were observed and which were missing. Mask values
    selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for values that are **observed**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for values that are **missing** (i.e. NaNs that were replaced by zeros).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**static_categorical_features** (`torch.LongTensor` of shape `(batch_size,
    number of static categorical features)`, *optional*) ‚Äî Optional static categorical
    features for which the model will learn an embedding, which it will add to the
    values of the time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static categorical features are features which have the same value for all time
    steps (static over time).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A typical example of a static categorical feature is a time series ID.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**static_real_features** (`torch.FloatTensor` of shape `(batch_size, number
    of static real features)`, *optional*) ‚Äî Optional static real features which the
    model will add to the values of the time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static real features are features which have the same value for all time steps
    (static over time).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A typical example of a static real feature is promotion information.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**future_values** (`torch.FloatTensor` of shape `(batch_size, prediction_length)`
    or `(batch_size, prediction_length, input_size)`, *optional*) ‚Äî Future values
    of the time series, that serve as labels for the model. The `future_values` is
    what the Transformer needs during training to learn to output, given the `past_values`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence length here is equal to `prediction_length`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: See the demo notebook and code snippets for details.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Optionally, during training any missing values need to be replaced with zeros
    and indicated via the `future_observed_mask`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For multivariate time series, the `input_size` > 1 dimension is required and
    corresponds to the number of variates in the time series per time step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**future_time_features** (`torch.FloatTensor` of shape `(batch_size, prediction_length,
    num_features)`) ‚Äî Required time features for the prediction window, which the
    model internally will add to `future_values`. These could be things like ‚Äúmonth
    of year‚Äù, ‚Äúday of the month‚Äù, etc. encoded as vectors (for instance as Fourier
    features). These could also be so-called ‚Äúage‚Äù features, which basically help
    the model know ‚Äúat which point in life‚Äù a time-series is. Age features have small
    values for distant past time steps and increase monotonically the more we approach
    the current time step. Holiday features are also a good example of time features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These features serve as the ‚Äúpositional encodings‚Äù of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features. The Time Series Transformer only learns additional embeddings for
    `static_categorical_features`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Additional dynamic real covariates can be concatenated to this tensor, with
    the caveat that these features must but known at prediction time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `num_features` here is equal to `config.`num_time_features`+`config.num_dynamic_real_features`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**future_observed_mask** (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) ‚Äî Boolean mask to
    indicate which `future_values` were observed and which were missing. Mask values
    selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for values that are **observed**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for values that are **missing** (i.e. NaNs that were replaced by zeros).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This mask is used to filter out missing values for the final loss calculation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**attention_mask** (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) ‚Äî Mask to avoid performing attention on certain token indices. Mask
    values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are **not masked**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are **masked**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**decoder_attention_mask** (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) ‚Äî Mask to avoid performing attention on certain token indices. By
    default, a causal mask will be used, to make sure the model can only look at previous
    inputs in order to predict the future.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**head_mask** (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) ‚Äî Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is **not masked**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is **masked**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**decoder_head_mask** (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) ‚Äî Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is **not masked**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is **masked**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cross_attn_head_mask** (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) ‚Äî Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is **not masked**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is **masked**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder_outputs** (`tuple(tuple(torch.FloatTensor)`, *optional*) ‚Äî Tuple
    consists of `last_hidden_state`, `hidden_states` (*optional*) and `attentions`
    (*optional*) `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`
    (*optional*) is a sequence of hidden-states at the output of the last layer of
    the encoder. Used in the cross-attention of the decoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**past_key_values** (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) ‚Äî Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don‚Äôt have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**inputs_embeds** (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) ‚Äî Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model‚Äôs internal embedding lookup matrix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**use_cache** (`bool`, *optional*) ‚Äî If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_attentions** (`bool`, *optional*) ‚Äî Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_hidden_states** (`bool`, *optional*) ‚Äî Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_dict** (`bool`, *optional*) ‚Äî Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or `tuple(torch.FloatTensor)`'
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig))
    and inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**last_hidden_state** (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) ‚Äî Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**past_key_values** (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) ‚Äî Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**decoder_hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    ‚Äî Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the decoder at the output of each layer plus the optional initial
    embedding outputs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**decoder_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) ‚Äî
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cross_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) ‚Äî
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder‚Äôs cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**encoder_last_hidden_state** (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) ‚Äî Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder_hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    ‚Äî Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the optional initial
    embedding outputs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**encoder_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) ‚Äî
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**loc** (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) ‚Äî Shift values of each time series‚Äô context window which is used to
    give the model inputs of the same magnitude and then used to shift back to the
    original magnitude.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**scale** (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) ‚Äî Scaling values of each time series‚Äô context window which is used
    to give the model inputs of the same magnitude and then used to rescale back to
    the original magnitude.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**static_features** (`torch.FloatTensor` of shape `(batch_size, feature size)`,
    *optional*) ‚Äî Static features of each time series‚Äô in a batch which are copied
    to the covariates at inference time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [InformerModel](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerModel)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: InformerForPrediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### class transformers.InformerForPrediction'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/informer/modeling_informer.py#L1704)'
  prefs: []
  type: TYPE_NORMAL
- en: '( config: InformerConfig )'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**config** ([TimeSeriesTransformerConfig](/docs/transformers/v4.37.2/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig))
    ‚Äî Model configuration class with all the parameters of the model. Initializing
    with a config file does not load the weights associated with the model, only the
    configuration. Check out the [from_pretrained()](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)
    method to load the model weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Informer Model with a distribution head on top for time-series forecasting.
    This model inherits from [PreTrainedModel](/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel).
    Check the superclass documentation for the generic methods the library implements
    for all its model (such as downloading or saving, resizing the input embeddings,
    pruning heads etc.)
  prefs: []
  type: TYPE_NORMAL
- en: This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)
    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation
    for all matter related to general usage and behavior.
  prefs: []
  type: TYPE_NORMAL
- en: '#### forward'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/transformers/blob/v4.37.2/src/transformers/models/informer/modeling_informer.py#L1749)'
  prefs: []
  type: TYPE_NORMAL
- en: '( past_values: Tensor past_time_features: Tensor past_observed_mask: Tensor
    static_categorical_features: Optional = None static_real_features: Optional =
    None future_values: Optional = None future_time_features: Optional = None future_observed_mask:
    Optional = None decoder_attention_mask: Optional = None head_mask: Optional =
    None decoder_head_mask: Optional = None cross_attn_head_mask: Optional = None
    encoder_outputs: Optional = None past_key_values: Optional = None output_hidden_states:
    Optional = None output_attentions: Optional = None use_cache: Optional = None
    return_dict: Optional = None ) ‚Üí [transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or `tuple(torch.FloatTensor)`'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**past_values** (`torch.FloatTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`) ‚Äî Past values of the time series,
    that serve as context in order to predict the future. The sequence size of this
    tensor must be larger than the `context_length` of the model, since the model
    will use the larger size to construct lag features, i.e. additional values from
    the past which are added in order to serve as ‚Äúextra context‚Äù.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `sequence_length` here is equal to `config.context_length` + `max(config.lags_sequence)`,
    which if no `lags_sequence` is configured, is equal to `config.context_length`
    + 7 (as by default, the largest look-back index in `config.lags_sequence` is 7).
    The property `_past_length` returns the actual length of the past.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `past_values` is what the Transformer encoder gets as input (with optional
    additional features, such as `static_categorical_features`, `static_real_features`,
    `past_time_features` and lags).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Optionally, missing values need to be replaced with zeros and indicated via
    the `past_observed_mask`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For multivariate time series, the `input_size` > 1 dimension is required and
    corresponds to the number of variates in the time series per time step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**past_time_features** (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    num_features)`) ‚Äî Required time features, which the model internally will add
    to `past_values`. These could be things like ‚Äúmonth of year‚Äù, ‚Äúday of the month‚Äù,
    etc. encoded as vectors (for instance as Fourier features). These could also be
    so-called ‚Äúage‚Äù features, which basically help the model know ‚Äúat which point
    in life‚Äù a time-series is. Age features have small values for distant past time
    steps and increase monotonically the more we approach the current time step. Holiday
    features are also a good example of time features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These features serve as the ‚Äúpositional encodings‚Äù of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features. The Time Series Transformer only learns additional embeddings for
    `static_categorical_features`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Additional dynamic real covariates can be concatenated to this tensor, with
    the caveat that these features must but known at prediction time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `num_features` here is equal to `config.`num_time_features`+`config.num_dynamic_real_features`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**past_observed_mask** (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) ‚Äî Boolean mask to
    indicate which `past_values` were observed and which were missing. Mask values
    selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for values that are **observed**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for values that are **missing** (i.e. NaNs that were replaced by zeros).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**static_categorical_features** (`torch.LongTensor` of shape `(batch_size,
    number of static categorical features)`, *optional*) ‚Äî Optional static categorical
    features for which the model will learn an embedding, which it will add to the
    values of the time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static categorical features are features which have the same value for all time
    steps (static over time).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A typical example of a static categorical feature is a time series ID.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**static_real_features** (`torch.FloatTensor` of shape `(batch_size, number
    of static real features)`, *optional*) ‚Äî Optional static real features which the
    model will add to the values of the time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static real features are features which have the same value for all time steps
    (static over time).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A typical example of a static real feature is promotion information.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**future_values** (`torch.FloatTensor` of shape `(batch_size, prediction_length)`
    or `(batch_size, prediction_length, input_size)`, *optional*) ‚Äî Future values
    of the time series, that serve as labels for the model. The `future_values` is
    what the Transformer needs during training to learn to output, given the `past_values`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence length here is equal to `prediction_length`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: See the demo notebook and code snippets for details.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Optionally, during training any missing values need to be replaced with zeros
    and indicated via the `future_observed_mask`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For multivariate time series, the `input_size` > 1 dimension is required and
    corresponds to the number of variates in the time series per time step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**future_time_features** (`torch.FloatTensor` of shape `(batch_size, prediction_length,
    num_features)`) ‚Äî Required time features for the prediction window, which the
    model internally will add to `future_values`. These could be things like ‚Äúmonth
    of year‚Äù, ‚Äúday of the month‚Äù, etc. encoded as vectors (for instance as Fourier
    features). These could also be so-called ‚Äúage‚Äù features, which basically help
    the model know ‚Äúat which point in life‚Äù a time-series is. Age features have small
    values for distant past time steps and increase monotonically the more we approach
    the current time step. Holiday features are also a good example of time features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These features serve as the ‚Äúpositional encodings‚Äù of the inputs. So contrary
    to a model like BERT, where the position encodings are learned from scratch internally
    as parameters of the model, the Time Series Transformer requires to provide additional
    time features. The Time Series Transformer only learns additional embeddings for
    `static_categorical_features`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Additional dynamic real covariates can be concatenated to this tensor, with
    the caveat that these features must but known at prediction time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `num_features` here is equal to `config.`num_time_features`+`config.num_dynamic_real_features`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**future_observed_mask** (`torch.BoolTensor` of shape `(batch_size, sequence_length)`
    or `(batch_size, sequence_length, input_size)`, *optional*) ‚Äî Boolean mask to
    indicate which `future_values` were observed and which were missing. Mask values
    selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for values that are **observed**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for values that are **missing** (i.e. NaNs that were replaced by zeros).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This mask is used to filter out missing values for the final loss calculation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**attention_mask** (`torch.Tensor` of shape `(batch_size, sequence_length)`,
    *optional*) ‚Äî Mask to avoid performing attention on certain token indices. Mask
    values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 for tokens that are **not masked**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 for tokens that are **masked**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are attention masks?](../glossary#attention-mask)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**decoder_attention_mask** (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`,
    *optional*) ‚Äî Mask to avoid performing attention on certain token indices. By
    default, a causal mask will be used, to make sure the model can only look at previous
    inputs in order to predict the future.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**head_mask** (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`,
    *optional*) ‚Äî Mask to nullify selected heads of the attention modules in the encoder.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is **not masked**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is **masked**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**decoder_head_mask** (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) ‚Äî Mask to nullify selected heads of the attention modules in the decoder.
    Mask values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is **not masked**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is **masked**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cross_attn_head_mask** (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`,
    *optional*) ‚Äî Mask to nullify selected heads of the cross-attention modules. Mask
    values selected in `[0, 1]`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 indicates the head is **not masked**,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 indicates the head is **masked**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder_outputs** (`tuple(tuple(torch.FloatTensor)`, *optional*) ‚Äî Tuple
    consists of `last_hidden_state`, `hidden_states` (*optional*) and `attentions`
    (*optional*) `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`
    (*optional*) is a sequence of hidden-states at the output of the last layer of
    the encoder. Used in the cross-attention of the decoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**past_key_values** (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) ‚Äî Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids`
    (those that don‚Äôt have their past key value states given to this model) of shape
    `(batch_size, 1)` instead of all `decoder_input_ids` of shape `(batch_size, sequence_length)`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**inputs_embeds** (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) ‚Äî Optionally, instead of passing `input_ids` you can
    choose to directly pass an embedded representation. This is useful if you want
    more control over how to convert `input_ids` indices into associated vectors than
    the model‚Äôs internal embedding lookup matrix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**use_cache** (`bool`, *optional*) ‚Äî If set to `True`, `past_key_values` key
    value states are returned and can be used to speed up decoding (see `past_key_values`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_attentions** (`bool`, *optional*) ‚Äî Whether or not to return the attentions
    tensors of all attention layers. See `attentions` under returned tensors for more
    detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**output_hidden_states** (`bool`, *optional*) ‚Äî Whether or not to return the
    hidden states of all layers. See `hidden_states` under returned tensors for more
    detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_dict** (`bool`, *optional*) ‚Äî Whether or not to return a [ModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.utils.ModelOutput)
    instead of a plain tuple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or `tuple(torch.FloatTensor)`'
  prefs: []
  type: TYPE_NORMAL
- en: A [transformers.modeling_outputs.Seq2SeqTSModelOutput](/docs/transformers/v4.37.2/en/main_classes/output#transformers.modeling_outputs.Seq2SeqTSModelOutput)
    or a tuple of `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`)
    comprising various elements depending on the configuration ([InformerConfig](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerConfig))
    and inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '**last_hidden_state** (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`) ‚Äî Sequence of hidden-states at the output of the last layer of
    the decoder of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If `past_key_values` is used only the last hidden-state of the sequences of
    shape `(batch_size, 1, hidden_size)` is output.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**past_key_values** (`tuple(tuple(torch.FloatTensor))`, *optional*, returned
    when `use_cache=True` is passed or when `config.use_cache=True`) ‚Äî Tuple of `tuple(torch.FloatTensor)`
    of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size,
    num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
    shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contains pre-computed hidden-states (key and values in the self-attention blocks
    and in the cross-attention blocks) that can be used (see `past_key_values` input)
    to speed up sequential decoding.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**decoder_hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    ‚Äî Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the decoder at the output of each layer plus the optional initial
    embedding outputs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**decoder_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) ‚Äî
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**cross_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) ‚Äî
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the decoder‚Äôs cross-attention layer, after the attention
    softmax, used to compute the weighted average in the cross-attention heads.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**encoder_last_hidden_state** (`torch.FloatTensor` of shape `(batch_size, sequence_length,
    hidden_size)`, *optional*) ‚Äî Sequence of hidden-states at the output of the last
    layer of the encoder of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoder_hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned
    when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`)
    ‚Äî Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model
    has an embedding layer, + one for the output of each layer) of shape `(batch_size,
    sequence_length, hidden_size)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden-states of the encoder at the output of each layer plus the optional initial
    embedding outputs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**encoder_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when
    `output_attentions=True` is passed or when `config.output_attentions=True`) ‚Äî
    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads,
    sequence_length, sequence_length)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attentions weights of the encoder, after the attention softmax, used to compute
    the weighted average in the self-attention heads.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**loc** (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) ‚Äî Shift values of each time series‚Äô context window which is used to
    give the model inputs of the same magnitude and then used to shift back to the
    original magnitude.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**scale** (`torch.FloatTensor` of shape `(batch_size,)` or `(batch_size, input_size)`,
    *optional*) ‚Äî Scaling values of each time series‚Äô context window which is used
    to give the model inputs of the same magnitude and then used to rescale back to
    the original magnitude.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**static_features** (`torch.FloatTensor` of shape `(batch_size, feature size)`,
    *optional*) ‚Äî Static features of each time series‚Äô in a batch which are copied
    to the covariates at inference time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [InformerForPrediction](/docs/transformers/v4.37.2/en/model_doc/informer#transformers.InformerForPrediction)
    forward method, overrides the `__call__` special method.
  prefs: []
  type: TYPE_NORMAL
- en: Although the recipe for forward pass needs to be defined within this function,
    one should call the `Module` instance afterwards instead of this since the former
    takes care of running the pre and post processing steps while the latter silently
    ignores them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
