- en: Use a custom Container Image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/inference-endpoints/guides/custom_container](https://huggingface.co/docs/inference-endpoints/guides/custom_container)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/inference-endpoints/main/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/entry/start.efd013a9.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/scheduler.389d799c.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/singletons.eafbeb3b.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/paths.b3517460.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/entry/app.53dcf7ee.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/index.8f81d18f.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/nodes/0.474ae6bf.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/nodes/9.610bf712.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/CodeBlock.3845caa1.js">
    <link rel="modulepreload" href="/docs/inference-endpoints/main/en/_app/immutable/chunks/Heading.41733039.js">
  prefs: []
  type: TYPE_NORMAL
- en: Inference Endpoints not only allows you to [customize your inference handler](/docs/inference-endpoints/guides/custom_handler),
    but it also allows you to provide a custom container image. Those can be public
    images like `tensorflow/serving:2.7.3` or private Images hosted on [Docker Hub](https://hub.docker.com/),
    [AWS ECR](https://aws.amazon.com/ecr/?nc1=h_ls), [Azure ACR](https://azure.microsoft.com/de-de/services/container-registry/),
    or [Google GCR](https://cloud.google.com/container-registry?hl=de).
  prefs: []
  type: TYPE_NORMAL
- en: '![custom container config](../Images/2edd4889d6faa4c5faa3ba08780c78a9.png)'
  prefs: []
  type: TYPE_IMG
- en: The [creation flow](/docs/inference-endpoints/guides/create_endpoint) of your
    Image artifacts from a custom image is the same as the base image. This means
    Inference Endpoints will create a unique image artifact derived from your provided
    image, including all Model Artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Model Artifacts (weights) are stored under `/repository`. For example,
    if you use`tensorflow/serving` as your custom image, then you have to set `model_base_path=“/repository”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
