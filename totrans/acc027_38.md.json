["```py\n- print(\"My thing I want to print!\")\n+ accelerator.print(\"My thing I want to print!\")\n```", "```py\nif accelerator.is_local_main_process:\n    do_thing_once_per_server()\n```", "```py\n@accelerator.on_local_main_process\ndef do_my_thing():\n    \"Something done once per server\"\n    do_thing_once_per_server()\n```", "```py\nif accelerator.is_main_process:\n    do_thing_once()\n```", "```py\n@accelerator.on_main_process\ndef do_my_thing():\n    \"Something done once per server\"\n    do_thing_once()\n```", "```py\n@accelerator.on_local_process(local_process_idx=0)\ndef do_my_thing():\n    \"Something done on process index 0 on each server\"\n    do_thing_on_index_zero_on_each_server()\n```", "```py\n@accelerator.on_process(process_index=0)\ndef do_my_thing():\n    \"Something done on process index 0\"\n    do_thing_on_index_zero()\n```", "```py\nmodel = MyModel()\nmodel = accelerator.prepare(model)\n```", "```py\n- torch.save(state_dict, \"my_state.pkl\")\n+ accelerator.save_model(model, save_directory)\n```", "```py\naccelerator.save_model(model, save_directory, max_shard_size=\"1GB\", safe_serialization=True)\n```", "```py\nfrom transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"bert-base-cased\")\nmodel = accelerator.prepare(model)\n\n# ...fine-tune with PyTorch...\n\nunwrapped_model = accelerator.unwrap_model(model)\nunwrapped_model.save_pretrained(\n    \"path/to/my_model_directory\",\n    is_main_process=accelerator.is_main_process,\n    save_function=accelerator.save,\n)\n```", "```py\nfrom transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"path/to/my_model_directory\")\n```", "```py\n- accelerator = Accelerator()\n+ accelerator = Accelerator(gradient_accumulation_steps=2)\n\n  for (input, label) in training_dataloader:\n+     with accelerator.accumulate(model):\n          predictions = model(input)\n          loss = loss_function(predictions, labels)\n          accelerator.backward(loss)\n          optimizer.step()\n          scheduler.step()\n          optimizer.zero_grad()\n```", "```py\n( num_steps: int = None adjust_scheduler: bool = True sync_with_dataloader: bool = True )\n```", "```py\nfrom accelerate.utils import GradientAccumulationPlugin\n\ngradient_accumulation_plugin = GradientAccumulationPlugin(num_steps=2)\n- accelerator = Accelerator()\n+ accelerator = Accelerator(gradient_accumulation_plugin=gradient_accumulation_plugin)\n```", "```py\n( device_placement: bool = True split_batches: bool = False mixed_precision: PrecisionType | str | None = None gradient_accumulation_steps: int = 1 cpu: bool = False deepspeed_plugin: DeepSpeedPlugin | None = None fsdp_plugin: FullyShardedDataParallelPlugin | None = None megatron_lm_plugin: MegatronLMPlugin | None = None rng_types: list[str | RNGType] | None = None log_with: str | LoggerType | GeneralTracker | list[str | LoggerType | GeneralTracker] | None = None project_dir: str | os.PathLike | None = None project_config: ProjectConfiguration | None = None gradient_accumulation_plugin: GradientAccumulationPlugin | None = None dispatch_batches: bool | None = None even_batches: bool = True use_seedable_sampler: bool = False step_scheduler_with_optimizer: bool = True kwargs_handlers: list[KwargsHandler] | None = None dynamo_backend: DynamoBackend | str | None = None )\n```", "```py\n( *models )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator(gradient_accumulation_steps=1)\n>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)\n\n>>> for input, output in dataloader:\n...     with accelerator.accumulate(model):\n...         outputs = model(input)\n...         loss = loss_func(outputs)\n...         loss.backward()\n...         optimizer.step()\n...         scheduler.step()\n...         optimizer.zero_grad()\n```", "```py\n( cache_enabled: bool = False autocast_handler: AutocastKwargs = None )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator(mixed_precision=\"fp16\")\n>>> with accelerator.autocast():\n...     train()\n```", "```py\n( loss **kwargs )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator(gradient_accumulation_steps=2)\n>>> outputs = model(inputs)\n>>> loss = loss_fn(outputs, labels)\n>>> accelerator.backward(loss)\n```", "```py\n( )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> # Assume later in the training script\n>>> # `should_do_breakpoint` is a custom function to monitor when to break,\n>>> # e.g. when the loss is NaN\n>>> if should_do_breakpoint(loss):\n...     accelerator.set_trigger()\n>>> # Assume later in the training script\n>>> if accelerator.check_trigger():\n...     break\n```", "```py\n( )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> model, optimizer, scheduler = ...\n>>> model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)\n>>> accelerator.free_memory()\n>>> del model, optimizer, scheduler\n```", "```py\n( parameters max_norm norm_type = 2 ) \u2192 export const metadata = 'undefined';torch.Tensor\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator(gradient_accumulation_steps=2)\n>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)\n\n>>> for input, target in dataloader:\n...     optimizer.zero_grad()\n...     output = model(input)\n...     loss = loss_func(output, target)\n...     accelerator.backward(loss)\n...     if accelerator.sync_gradients:\n...         accelerator.clip_grad_norm_(model.parameters(), max_grad_norm)\n...     optimizer.step()\n```", "```py\n( parameters clip_value )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator(gradient_accumulation_steps=2)\n>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)\n\n>>> for input, target in dataloader:\n...     optimizer.zero_grad()\n...     output = model(input)\n...     loss = loss_func(output, target)\n...     accelerator.backward(loss)\n...     if accelerator.sync_gradients:\n...         accelerator.clip_grad_value_(model.parameters(), clip_value)\n...     optimizer.step()\n```", "```py\n( )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> model, optimizer, scheduler = ...\n>>> model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)\n>>> accelerator.free_memory()\n>>> del model, optimizer, scheduler\n```", "```py\n( tensor ) \u2192 export const metadata = 'undefined';torch.Tensor, or a nested tuple/list/dictionary of torch.Tensor\n```", "```py\n>>> # Assuming four processes\n>>> import torch\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> process_tensor = torch.tensor([accelerator.process_index])\n>>> gathered_tensor = accelerator.gather(process_tensor)\n>>> gathered_tensor\ntensor([0, 1, 2, 3])\n```", "```py\n( input_data )\n```", "```py\n>>> # Assuming two processes, with a batch size of 5 on a dataset with 9 samples\n>>> import torch\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> dataloader = torch.utils.data.DataLoader(range(9), batch_size=5)\n>>> dataloader = accelerator.prepare(dataloader)\n>>> batch = next(iter(dataloader))\n>>> gathered_items = accelerator.gather_for_metrics(batch)\n>>> len(gathered_items)\n9\n```", "```py\n( model unwrap = True ) \u2192 export const metadata = 'undefined';dict\n```", "```py\n>>> import torch\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> net = torch.nn.Linear(2, 2)\n>>> net = accelerator.prepare(net)\n>>> state_dict = accelerator.get_state_dict(net)\n```", "```py\n( name: str unwrap: bool = False ) \u2192 export const metadata = 'undefined';GeneralTracker\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator(log_with=\"tensorboard\")\n>>> accelerator.init_trackers(\"my_project\")\n>>> tensorboard_tracker = accelerator.get_tracker(\"tensorboard\")\n```", "```py\n( joinables even_batches = None )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator(even_batches=True)\n>>> ddp_model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)\n\n>>> with accelerator.join_uneven_inputs([ddp_model], even_batches=False):\n...     for input, output in dataloader:\n...         outputs = model(input)\n...         loss = loss_func(outputs)\n...         loss.backward()\n...         optimizer.step()\n...         optimizer.zero_grad()\n```", "```py\n( input_dir: str = None **load_model_func_kwargs )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> model, optimizer, lr_scheduler = ...\n>>> model, optimizer, lr_scheduler = accelerator.prepare(model, optimizer, lr_scheduler)\n>>> accelerator.load_state(\"my_checkpoint\")\n```", "```py\n( )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> with accelerator.local_main_process_first():\n...     # This will be printed first by local process 0 then in a seemingly\n...     # random order by the other processes.\n...     print(f\"This will be printed by process {accelerator.local_process_index}\")\n```", "```py\n( )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> with accelerator.main_process_first():\n...     # This will be printed first by process 0 then in a seemingly\n...     # random order by the other processes.\n...     print(f\"This will be printed by process {accelerator.process_index}\")\n```", "```py\n( model )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> dataloader, model, optimizer = accelerator.prepare(dataloader, model, optimizer)\n>>> input_a = next(iter(dataloader))\n>>> input_b = next(iter(dataloader))\n\n>>> with accelerator.no_sync():\n...     outputs = model(input_a)\n...     loss = loss_func(outputs)\n...     accelerator.backward(loss)\n...     # No synchronization across processes, only accumulate gradients\n>>> outputs = model(input_b)\n>>> accelerator.backward(loss)\n>>> # Synchronization across all processes\n>>> optimizer.step()\n>>> optimizer.zero_grad()\n```", "```py\n( function: Callable[..., Any] )\n```", "```py\n# Assume we have 4 processes.\nfrom accelerate import Accelerator\n\naccelerator = Accelerator()\n\n@accelerator.on_last_process\ndef print_something():\n    print(f\"Printed on process {accelerator.process_index}\")\n\nprint_something()\n\"Printed on process 3\"\n```", "```py\n( function: Callable[..., Any] = None )\n```", "```py\n# Assume we have 2 servers with 4 processes each.\nfrom accelerate import Accelerator\n\naccelerator = Accelerator()\n\n@accelerator.on_local_main_process\ndef print_something():\n    print(\"This will be printed by process 0 only on each server.\")\n\nprint_something()\n# On server 1:\n\"This will be printed by process 0 only\"\n# On server 2:\n\"This will be printed by process 0 only\"\n```", "```py\n( function: Callable[..., Any] = None local_process_index: int = None )\n```", "```py\n# Assume we have 2 servers with 4 processes each.\nfrom accelerate import Accelerator\n\naccelerator = Accelerator()\n\n@accelerator.on_local_process(local_process_index=2)\ndef print_something():\n    print(f\"Printed on process {accelerator.local_process_index}\")\n\nprint_something()\n# On server 1:\n\"Printed on process 2\"\n# On server 2:\n\"Printed on process 2\"\n```", "```py\n( function: Callable[..., Any] = None )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n\n>>> @accelerator.on_main_process\n... def print_something():\n...     print(\"This will be printed by process 0 only.\")\n\n>>> print_something()\n\"This will be printed by process 0 only\"\n```", "```py\n( function: Callable[..., Any] = None process_index: int = None )\n```", "```py\n# Assume we have 4 processes.\nfrom accelerate import Accelerator\n\naccelerator = Accelerator()\n\n@accelerator.on_process(process_index=2)\ndef print_something():\n    print(f\"Printed on process {accelerator.process_index}\")\n\nprint_something()\n\"Printed on process 2\"\n```", "```py\n( tensor dim = 0 pad_index = 0 pad_first = False ) \u2192 export const metadata = 'undefined';torch.Tensor, or a nested tuple/list/dictionary of torch.Tensor\n```", "```py\n>>> # Assuming two processes, with the first processes having a tensor of size 1 and the second of size 2\n>>> import torch\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> process_tensor = torch.arange(accelerator.process_index + 1).to(accelerator.device)\n>>> padded_tensor = accelerator.pad_across_processes(process_tensor)\n>>> padded_tensor.shape\ntorch.Size([2])\n```", "```py\n( *args device_placement = None )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> # Assume a model, optimizer, data_loader and scheduler are defined\n>>> model, optimizer, data_loader, scheduler = accelerator.prepare(model, optimizer, data_loader, scheduler)\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> # Assume a model, optimizer, data_loader and scheduler are defined\n>>> device_placement = [True, True, False, False]\n>>> # Will place the first to items passed in automatically to the right device but not the last two.\n>>> model, optimizer, data_loader, scheduler = accelerator.prepare(\n...     model, optimizer, data_loader, scheduler, device_placement=device_placement\n... )\n```", "```py\n( data_loader: torch.utils.data.DataLoader device_placement = None slice_fn_for_dispatch = None )\n```", "```py\n>>> import torch\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> data_loader = torch.utils.data.DataLoader(...)\n>>> data_loader = accelerator.prepare_data_loader(data_loader, device_placement=True)\n```", "```py\n( model: torch.nn.Module device_placement: bool = None evaluation_mode: bool = False )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> # Assume a model is defined\n>>> model = accelerator.prepare_model(model)\n```", "```py\n( optimizer: torch.optim.Optimizer device_placement = None )\n```", "```py\n>>> import torch\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> optimizer = torch.optim.Adam(...)\n>>> optimizer = accelerator.prepare_optimizer(optimizer, device_placement=True)\n```", "```py\n( scheduler: LRScheduler )\n```", "```py\n>>> import torch\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> optimizer = torch.optim.Adam(...)\n>>> scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, ...)\n>>> scheduler = accelerator.prepare_scheduler(scheduler)\n```", "```py\n( *args **kwargs )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> accelerator.print(\"Hello world!\")\n```", "```py\n( tensor reduction = 'sum' scale = 1.0 ) \u2192 export const metadata = 'undefined';torch.Tensor, or a nested tuple/list/dictionary of torch.Tensor\n```", "```py\n>>> # Assuming two processes\n>>> import torch\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> process_tensor = torch.arange(accelerator.num_processes) + 1 + (2 * accelerator.process_index)\n>>> process_tensor = process_tensor.to(accelerator.device)\n>>> reduced_tensor = accelerator.reduce(process_tensor, reduction=\"sum\")\n>>> reduced_tensor\ntensor([4, 6])\n```", "```py\n( *objects )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> # Assume `CustomObject` has a `state_dict` and `load_state_dict` function.\n>>> obj = CustomObject()\n>>> accelerator.register_for_checkpointing(obj)\n>>> accelerator.save_state(\"checkpoint.pt\")\n```", "```py\n( hook: Callable[..., None] ) \u2192 export const metadata = 'undefined';torch.utils.hooks.RemovableHandle\n```", "```py\n( hook: Callable[..., None] ) \u2192 export const metadata = 'undefined';torch.utils.hooks.RemovableHandle\n```", "```py\n( obj f safe_serialization = False )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> arr = [0, 1, 2, 3]\n>>> accelerator.save(arr, \"array.pkl\")\n```", "```py\n( model: torch.nn.Module save_directory: Union[str, os.PathLike] max_shard_size: Union[int, str] = '10GB' safe_serialization: bool = True )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> model = ...\n>>> accelerator.save_model(model, save_directory)\n```", "```py\n( output_dir: str = None safe_serialization: bool = True **save_model_func_kwargs )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> model, optimizer, lr_scheduler = ...\n>>> model, optimizer, lr_scheduler = accelerator.prepare(model, optimizer, lr_scheduler)\n>>> accelerator.save_state(output_dir=\"my_checkpoint\")\n```", "```py\n( )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> # Assume later in the training script\n>>> # `should_do_breakpoint` is a custom function to monitor when to break,\n>>> # e.g. when the loss is NaN\n>>> if should_do_breakpoint(loss):\n...     accelerator.set_trigger()\n>>> # Assume later in the training script\n>>> if accelerator.check_breakpoint():\n...     break\n```", "```py\n( dataloader num_batches: int = 0 )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)\n>>> skipped_dataloader = accelerator.skip_first_batches(dataloader, num_batches=2)\n>>> # for the first epoch only\n>>> for input, target in skipped_dataloader:\n...     optimizer.zero_grad()\n...     output = model(input)\n...     loss = loss_func(output, target)\n...     accelerator.backward(loss)\n...     optimizer.step()\n\n>>> # subsequent epochs\n>>> for input, target in dataloader:\n...     optimizer.zero_grad()\n...     ...\n```", "```py\n( inputs: list | tuple | dict | torch.Tensor apply_padding: bool = False )\n```", "```py\n# Assume there are two processes\nfrom accelerate import Accelerator\n\naccelerator = Accelerator()\nwith accelerator.split_between_processes([\"A\", \"B\", \"C\"]) as inputs:\n    print(inputs)\n# Process 0\n[\"A\", \"B\"]\n# Process 1\n[\"C\"]\n\nwith accelerator.split_between_processes([\"A\", \"B\", \"C\"], apply_padding=True) as inputs:\n    print(inputs)\n# Process 0\n[\"A\", \"B\"]\n# Process 1\n[\"C\", \"C\"]\n```", "```py\n( model )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> dataloader, model, optimizer = accelerator.prepare(dataloader, model, optimizer)\n\n>>> with accelerator.no_sync():\n...     loss_a = loss_func(model(input_a))  # first forward pass\n...     loss_b = loss_func(model(input_b))  # second forward pass\n>>> accelerator.backward(loss_a)  # No synchronization across processes, only accumulate gradients\n>>> with accelerator.trigger_sync_in_backward(model):\n...     accelerator.backward(loss_b)  # Synchronization across all processes\n>>> optimizer.step()\n>>> optimizer.zero_grad()\n```", "```py\n( optimizer = None )\n```", "```py\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> model, optimizer = accelerator.prepare(model, optimizer)\n>>> outputs = model(inputs)\n>>> loss = loss_fn(outputs, labels)\n>>> accelerator.backward(loss)\n>>> accelerator.unscale_gradients(optimizer=optimizer)\n```", "```py\n( model keep_fp32_wrapper: bool = True ) \u2192 export const metadata = 'undefined';torch.nn.Module\n```", "```py\n>>> # Assuming two GPU processes\n>>> from torch.nn.parallel import DistributedDataParallel\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> model = accelerator.prepare(MyModel())\n>>> print(model.__class__.__name__)\nDistributedDataParallel\n\n>>> model = accelerator.unwrap_model(model)\n>>> print(model.__class__.__name__)\nMyModel\n```", "```py\n( model: torch.nn.Module )\n```", "```py\n( )\n```", "```py\n>>> # Assuming two GPU processes\n>>> import time\n>>> from accelerate import Accelerator\n\n>>> accelerator = Accelerator()\n>>> if accelerator.is_main_process:\n...     time.sleep(2)\n>>> else:\n...     print(\"I'm waiting for the main process to finish its sleep...\")\n>>> accelerator.wait_for_everyone()\n>>> # Should print on every process at the same time\n>>> print(\"Everyone is here\")\n```"]