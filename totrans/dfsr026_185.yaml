- en: CMStochasticIterativeScheduler
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CMStochasticIterativeScheduler
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/schedulers/cm_stochastic_iterative](https://huggingface.co/docs/diffusers/api/schedulers/cm_stochastic_iterative)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/diffusers/api/schedulers/cm_stochastic_iterative](https://huggingface.co/docs/diffusers/api/schedulers/cm_stochastic_iterative)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[Consistency Models](https://huggingface.co/papers/2303.01469) by Yang Song,
    Prafulla Dhariwal, Mark Chen, and Ilya Sutskever introduced a multistep and onestep
    scheduler (Algorithm 1) that is capable of generating good samples in one or a
    small number of steps.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[一致性模型](https://huggingface.co/papers/2303.01469) 由杨松、Prafulla Dhariwal、Mark
    Chen 和 Ilya Sutskever 提出了一种多步和单步调度器（算法 1），能够在一步或少量步骤中生成良好的样本。'
- en: 'The abstract from the paper is:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 论文摘要为：
- en: '*Diffusion models have significantly advanced the fields of image, audio, and
    video generation, but they depend on an iterative sampling process that causes
    slow generation. To overcome this limitation, we propose consistency models, a
    new family of models that generate high quality samples by directly mapping noise
    to data. They support fast one-step generation by design, while still allowing
    multistep sampling to trade compute for sample quality. They also support zero-shot
    data editing, such as image inpainting, colorization, and super-resolution, without
    requiring explicit training on these tasks. Consistency models can be trained
    either by distilling pre-trained diffusion models, or as standalone generative
    models altogether. Through extensive experiments, we demonstrate that they outperform
    existing distillation techniques for diffusion models in one- and few-step sampling,
    achieving the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on ImageNet
    64x64 for one-step generation. When trained in isolation, consistency models become
    a new family of generative models that can outperform existing one-step, non-adversarial
    generative models on standard benchmarks such as CIFAR-10, ImageNet 64x64 and
    LSUN 256x256.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*扩散模型显著推进了图像、音频和视频生成领域，但它们依赖于导致生成速度缓慢的迭代采样过程。为了克服这一限制，我们提出了一致性模型，这是一种通过直接将噪声映射到数据来生成高质量样本的新型模型系列。它们通过设计支持快速一步生成，同时仍允许多步采样以在计算和样本质量之间进行交换。它们还支持零样本数据编辑，如图像修补、着色和超分辨率，而无需在这些任务上进行显式训练。一致性模型可以通过蒸馏预训练的扩散模型或作为独立的生成模型进行训练。通过大量实验，我们证明它们在一步和少步采样中优于现有的扩散模型蒸馏技术，实现了CIFAR-10上新的FID最佳值为3.55，ImageNet
    64x64为6.20的一步生成。当单独训练时，一致性模型成为一种新的生成模型系列，可以在标准基准测试中优于现有的一步、非对抗性生成模型，如CIFAR-10、ImageNet
    64x64 和 LSUN 256x256。*'
- en: The original codebase can be found at [openai/consistency_models](https://github.com/openai/consistency_models).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 原始代码库可在 [openai/consistency_models](https://github.com/openai/consistency_models)
    找到。
- en: CMStochasticIterativeScheduler
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CMStochasticIterativeScheduler
- en: '### `class diffusers.CMStochasticIterativeScheduler`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.CMStochasticIterativeScheduler`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L44)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L44)'
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_train_timesteps` (`int`, defaults to 40) — The number of diffusion steps
    to train the model.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_train_timesteps` (`int`, 默认为 40) — 训练模型的扩散步数。'
- en: '`sigma_min` (`float`, defaults to 0.002) — Minimum noise magnitude in the sigma
    schedule. Defaults to 0.002 from the original implementation.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sigma_min` (`float`, 默认为 0.002) — sigma调度中的最小噪声幅度。默认值为原始实现中的 0.002。'
- en: '`sigma_max` (`float`, defaults to 80.0) — Maximum noise magnitude in the sigma
    schedule. Defaults to 80.0 from the original implementation.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sigma_max` (`float`, 默认为 80.0) — sigma调度中的最大噪声幅度。默认值为原始实现中的 80.0。'
- en: '`sigma_data` (`float`, defaults to 0.5) — The standard deviation of the data
    distribution from the EDM [paper](https://huggingface.co/papers/2206.00364). Defaults
    to 0.5 from the original implementation.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sigma_data` (`float`, 默认为 0.5) — 来自EDM [论文](https://huggingface.co/papers/2206.00364)
    的数据分布的标准差。默认值为原始实现中的 0.5。'
- en: '`s_noise` (`float`, defaults to 1.0) — The amount of additional noise to counteract
    loss of detail during sampling. A reasonable range is [1.000, 1.011]. Defaults
    to 1.0 from the original implementation.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s_noise` (`float`, 默认为 1.0) — 用于抵消采样过程中细节丢失的额外噪声量。合理范围为 [1.000, 1.011]。默认值为原始实现中的
    1.0。'
- en: '`rho` (`float`, defaults to 7.0) — The parameter for calculating the Karras
    sigma schedule from the EDM [paper](https://huggingface.co/papers/2206.00364).
    Defaults to 7.0 from the original implementation.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rho` (`float`, 默认为 7.0) — 用于从EDM [论文](https://huggingface.co/papers/2206.00364)
    计算Karras sigma调度的参数。默认值为原始实现中的 7.0。'
- en: '`clip_denoised` (`bool`, defaults to `True`) — Whether to clip the denoised
    outputs to `(-1, 1)`.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clip_denoised` (`bool`, 默认为 `True`) — 是否将去噪输出剪裁到 `(-1, 1)`。'
- en: '`timesteps` (`List` or `np.ndarray` or `torch.Tensor`, *optional*) — An explicit
    timestep schedule that can be optionally specified. The timesteps are expected
    to be in increasing order.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`List` 或 `np.ndarray` 或 `torch.Tensor`, *可选*) — 可选指定的显式时间步骤表。预期时间步骤按递增顺序排列。'
- en: Multistep and onestep sampling for consistency models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性模型的多步和单步采样。
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型继承自 [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    和 [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin)。查看超类文档以了解库实现的所有调度器通用方法，如加载和保存。
- en: '#### `get_scalings_for_boundary_condition`'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_scalings_for_boundary_condition`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L256)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L256)'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sigma` (`torch.FloatTensor`) — The current sigma in the Karras sigma schedule.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sigma` (`torch.FloatTensor`) — Karras sigma计划中的当前sigma。'
- en: Returns
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`tuple`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`tuple`'
- en: A two-element tuple where `c_skip` (which weights the current sample) is the
    first element and `c_out` (which weights the consistency model output) is the
    second element.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含两个元素的元组，其中`c_skip`（加权当前样本）是第一个元素，`c_out`（加权一致性模型输出）是第二个元素。
- en: Gets the scalings used in the consistency model parameterization (from Appendix
    C of the [paper](https://huggingface.co/papers/2303.01469)) to enforce boundary
    condition.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 获取用于强制边界条件的一致性模型参数化中使用的缩放（来自[论文](https://huggingface.co/papers/2303.01469)的附录C）。
- en: '`epsilon` in the equations for `c_skip` and `c_out` is set to `sigma_min`.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 方程中的`epsilon`用于将`c_skip`和`c_out`设置为`sigma_min`。
- en: '#### `scale_model_input`'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `scale_model_input`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L117)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L117)'
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Parameters
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sample` (`torch.FloatTensor`) — The input sample.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample` (`torch.FloatTensor`) — 输入样本。'
- en: '`timestep` (`float` or `torch.FloatTensor`) — The current timestep in the diffusion
    chain.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep` (`float`或`torch.FloatTensor`) — 扩散链中的当前时间步长。'
- en: Returns
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`torch.FloatTensor`'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.FloatTensor`'
- en: A scaled input sample.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放后的输入样本。
- en: Scales the consistency model input by `(sigma**2 + sigma_data**2) ** 0.5`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`(sigma**2 + sigma_data**2) ** 0.5`缩放一致性模型输入。
- en: '#### `set_timesteps`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_timesteps`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L163)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L163)'
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`num_inference_steps` (`int`) — The number of diffusion steps used when generating
    samples with a pre-trained model.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`) — 在使用预训练模型生成样本时使用的扩散步骤数。'
- en: '`device` (`str` or `torch.device`, *optional*) — The device to which the timesteps
    should be moved to. If `None`, the timesteps are not moved.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` (`str`或`torch.device`, *可选*) — 应将时间步长移动到的设备。如果为`None`，则不移动时间步长。'
- en: '`timesteps` (`List[int]`, *optional*) — Custom timesteps used to support arbitrary
    spacing between timesteps. If `None`, then the default timestep spacing strategy
    of equal spacing between timesteps is used. If `timesteps` is passed, `num_inference_steps`
    must be `None`.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timesteps` (`List[int]`, *可选*) — 用于支持时间步长之间任意间距的自定义时间步长。如果为`None`，则使用等间距时间步长策略。如果传递了`timesteps`，则`num_inference_steps`必须为`None`。'
- en: Sets the timesteps used for the diffusion chain (to be run before inference).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 设置用于扩散链的时间步长（在推断之前运行）。
- en: '#### `sigma_to_t`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `sigma_to_t`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L144)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L144)'
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Parameters
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`sigmas` (`float` or `np.ndarray`) — A single Karras sigma or an array of Karras
    sigmas.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sigmas` (`float`或`np.ndarray`) — 单个Karras sigma或Karras sigmas数组。'
- en: Returns
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`float` or `np.ndarray`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`float`或`np.ndarray`'
- en: A scaled input timestep or scaled input timestep array.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放后的输入时间步长或缩放后的输入时间步长数组。
- en: Gets scaled timesteps from the Karras sigmas for input to the consistency model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 从Karras sigmas获取缩放的时间步长，以输入一致性模型。
- en: '#### `step`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `step`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L301)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L301)'
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model_output` (`torch.FloatTensor`) — The direct output from the learned diffusion
    model.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_output` (`torch.FloatTensor`) — 从学习扩散模型直接输出的结果。'
- en: '`timestep` (`float`) — The current timestep in the diffusion chain.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestep` (`float`) — 扩散链中的当前时间步长。'
- en: '`sample` (`torch.FloatTensor`) — A current instance of a sample created by
    the diffusion process.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`样本` (`torch.FloatTensor`) — 由扩散过程创建的样本的当前实例。'
- en: '`generator` (`torch.Generator`, *optional*) — A random number generator.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator` (`torch.Generator`, *可选*) — 随机数生成器。'
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)
    or `tuple`.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_dict` (`bool`, *可选*, 默认为`True`) — 是否返回[CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)或`tuple`。'
- en: Returns
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)
    or `tuple`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)或`tuple`'
- en: If return_dict is `True`, [CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)
    is returned, otherwise a tuple is returned where the first element is the sample
    tensor.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`return_dict`为`True`，则返回[CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)，否则返回一个元组，其中第一个元素是样本张量。
- en: Predict the sample from the previous timestep by reversing the SDE. This function
    propagates the diffusion process from the learned model outputs (most often the
    predicted noise).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通过反转SDE从先前时间步长预测样本。此函数从学习模型输出（通常是预测的噪声）传播扩散过程。
- en: CMStochasticIterativeSchedulerOutput
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CMStochasticIterativeSchedulerOutput
- en: '### `class diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput`'
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L30)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L30)'
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prev_sample` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)` for images) — Computed sample `(x_{t-1})` of previous timestep. `prev_sample`
    should be used as next model input in the denoising loop.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prev_sample`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`，用于图像）-
    上一个时间步的计算样本`(x_{t-1})`。`prev_sample`应该在去噪循环中作为下一个模型输入使用。'
- en: Output class for the scheduler’s `step` function.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 调度程序的`step`函数的输出类。
