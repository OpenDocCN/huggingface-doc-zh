- en: CMStochasticIterativeScheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/diffusers/api/schedulers/cm_stochastic_iterative](https://huggingface.co/docs/diffusers/api/schedulers/cm_stochastic_iterative)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: '[Consistency Models](https://huggingface.co/papers/2303.01469) by Yang Song,
    Prafulla Dhariwal, Mark Chen, and Ilya Sutskever introduced a multistep and onestep
    scheduler (Algorithm 1) that is capable of generating good samples in one or a
    small number of steps.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The abstract from the paper is:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Diffusion models have significantly advanced the fields of image, audio, and
    video generation, but they depend on an iterative sampling process that causes
    slow generation. To overcome this limitation, we propose consistency models, a
    new family of models that generate high quality samples by directly mapping noise
    to data. They support fast one-step generation by design, while still allowing
    multistep sampling to trade compute for sample quality. They also support zero-shot
    data editing, such as image inpainting, colorization, and super-resolution, without
    requiring explicit training on these tasks. Consistency models can be trained
    either by distilling pre-trained diffusion models, or as standalone generative
    models altogether. Through extensive experiments, we demonstrate that they outperform
    existing distillation techniques for diffusion models in one- and few-step sampling,
    achieving the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on ImageNet
    64x64 for one-step generation. When trained in isolation, consistency models become
    a new family of generative models that can outperform existing one-step, non-adversarial
    generative models on standard benchmarks such as CIFAR-10, ImageNet 64x64 and
    LSUN 256x256.*'
  prefs: []
  type: TYPE_NORMAL
- en: The original codebase can be found at [openai/consistency_models](https://github.com/openai/consistency_models).
  prefs: []
  type: TYPE_NORMAL
- en: CMStochasticIterativeScheduler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.CMStochasticIterativeScheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L44)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`num_train_timesteps` (`int`, defaults to 40) — The number of diffusion steps
    to train the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sigma_min` (`float`, defaults to 0.002) — Minimum noise magnitude in the sigma
    schedule. Defaults to 0.002 from the original implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sigma_max` (`float`, defaults to 80.0) — Maximum noise magnitude in the sigma
    schedule. Defaults to 80.0 from the original implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sigma_data` (`float`, defaults to 0.5) — The standard deviation of the data
    distribution from the EDM [paper](https://huggingface.co/papers/2206.00364). Defaults
    to 0.5 from the original implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s_noise` (`float`, defaults to 1.0) — The amount of additional noise to counteract
    loss of detail during sampling. A reasonable range is [1.000, 1.011]. Defaults
    to 1.0 from the original implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rho` (`float`, defaults to 7.0) — The parameter for calculating the Karras
    sigma schedule from the EDM [paper](https://huggingface.co/papers/2206.00364).
    Defaults to 7.0 from the original implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clip_denoised` (`bool`, defaults to `True`) — Whether to clip the denoised
    outputs to `(-1, 1)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timesteps` (`List` or `np.ndarray` or `torch.Tensor`, *optional*) — An explicit
    timestep schedule that can be optionally specified. The timesteps are expected
    to be in increasing order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multistep and onestep sampling for consistency models.
  prefs: []
  type: TYPE_NORMAL
- en: This model inherits from [SchedulerMixin](/docs/diffusers/v0.26.3/en/api/schedulers/overview#diffusers.SchedulerMixin)
    and [ConfigMixin](/docs/diffusers/v0.26.3/en/api/configuration#diffusers.ConfigMixin).
    Check the superclass documentation for the generic methods the library implements
    for all schedulers such as loading and saving.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_scalings_for_boundary_condition`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L256)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`sigma` (`torch.FloatTensor`) — The current sigma in the Karras sigma schedule.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: A two-element tuple where `c_skip` (which weights the current sample) is the
    first element and `c_out` (which weights the consistency model output) is the
    second element.
  prefs: []
  type: TYPE_NORMAL
- en: Gets the scalings used in the consistency model parameterization (from Appendix
    C of the [paper](https://huggingface.co/papers/2303.01469)) to enforce boundary
    condition.
  prefs: []
  type: TYPE_NORMAL
- en: '`epsilon` in the equations for `c_skip` and `c_out` is set to `sigma_min`.'
  prefs: []
  type: TYPE_NORMAL
- en: '#### `scale_model_input`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L117)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`sample` (`torch.FloatTensor`) — The input sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timestep` (`float` or `torch.FloatTensor`) — The current timestep in the diffusion
    chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`torch.FloatTensor`'
  prefs: []
  type: TYPE_NORMAL
- en: A scaled input sample.
  prefs: []
  type: TYPE_NORMAL
- en: Scales the consistency model input by `(sigma**2 + sigma_data**2) ** 0.5`.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `set_timesteps`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L163)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`) — The number of diffusion steps used when generating
    samples with a pre-trained model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device` (`str` or `torch.device`, *optional*) — The device to which the timesteps
    should be moved to. If `None`, the timesteps are not moved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timesteps` (`List[int]`, *optional*) — Custom timesteps used to support arbitrary
    spacing between timesteps. If `None`, then the default timestep spacing strategy
    of equal spacing between timesteps is used. If `timesteps` is passed, `num_inference_steps`
    must be `None`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sets the timesteps used for the diffusion chain (to be run before inference).
  prefs: []
  type: TYPE_NORMAL
- en: '#### `sigma_to_t`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L144)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`sigmas` (`float` or `np.ndarray`) — A single Karras sigma or an array of Karras
    sigmas.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '`float` or `np.ndarray`'
  prefs: []
  type: TYPE_NORMAL
- en: A scaled input timestep or scaled input timestep array.
  prefs: []
  type: TYPE_NORMAL
- en: Gets scaled timesteps from the Karras sigmas for input to the consistency model.
  prefs: []
  type: TYPE_NORMAL
- en: '#### `step`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L301)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`model_output` (`torch.FloatTensor`) — The direct output from the learned diffusion
    model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timestep` (`float`) — The current timestep in the diffusion chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sample` (`torch.FloatTensor`) — A current instance of a sample created by
    the diffusion process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generator` (`torch.Generator`, *optional*) — A random number generator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_dict` (`bool`, *optional*, defaults to `True`) — Whether or not to
    return a [CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)
    or `tuple`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  prefs: []
  type: TYPE_NORMAL
- en: '[CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)
    or `tuple`'
  prefs: []
  type: TYPE_NORMAL
- en: If return_dict is `True`, [CMStochasticIterativeSchedulerOutput](/docs/diffusers/v0.26.3/en/api/schedulers/cm_stochastic_iterative#diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput)
    is returned, otherwise a tuple is returned where the first element is the sample
    tensor.
  prefs: []
  type: TYPE_NORMAL
- en: Predict the sample from the previous timestep by reversing the SDE. This function
    propagates the diffusion process from the learned model outputs (most often the
    predicted noise).
  prefs: []
  type: TYPE_NORMAL
- en: CMStochasticIterativeSchedulerOutput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class diffusers.schedulers.scheduling_consistency_models.CMStochasticIterativeSchedulerOutput`'
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/schedulers/scheduling_consistency_models.py#L30)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: '`prev_sample` (`torch.FloatTensor` of shape `(batch_size, num_channels, height,
    width)` for images) — Computed sample `(x_{t-1})` of previous timestep. `prev_sample`
    should be used as next model input in the denoising loop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output class for the scheduler’s `step` function.
  prefs: []
  type: TYPE_NORMAL
