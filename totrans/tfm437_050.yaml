- en: Use tokenizers from 🤗 Tokenizers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用🤗 Tokenizers中的分词器
- en: 'Original text: [https://huggingface.co/docs/transformers/v4.37.2/en/fast_tokenizers](https://huggingface.co/docs/transformers/v4.37.2/en/fast_tokenizers)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/transformers/v4.37.2/en/fast_tokenizers](https://huggingface.co/docs/transformers/v4.37.2/en/fast_tokenizers)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    depends on the [🤗 Tokenizers](https://huggingface.co/docs/tokenizers) library.
    The tokenizers obtained from the 🤗 Tokenizers library can be loaded very simply
    into 🤗 Transformers.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    依赖于 [🤗 Tokenizers](https://huggingface.co/docs/tokenizers) 库。从🤗 Tokenizers库获得的分词器可以非常简单地加载到🤗
    Transformers中。'
- en: 'Before getting in the specifics, let’s first start by creating a dummy tokenizer
    in a few lines:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入具体内容之前，让我们首先通过几行代码创建一个虚拟的分词器：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We now have a tokenizer trained on the files we defined. We can either continue
    using it in that runtime, or save it to a JSON file for future re-use.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个在我们定义的文件上训练过的分词器。我们可以继续在该运行时中使用它，或者将其保存到一个JSON文件中以供将来重复使用。
- en: Loading directly from the tokenizer object
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直接从分词器对象加载
- en: 'Let’s see how to leverage this tokenizer object in the 🤗 Transformers library.
    The [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    class allows for easy instantiation, by accepting the instantiated *tokenizer*
    object as an argument:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在🤗 Transformers库中利用这个分词器对象。[PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    类允许通过接受实例化的 *tokenizer* 对象作为参数来轻松实例化：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This object can now be used with all the methods shared by the 🤗 Transformers
    tokenizers! Head to [the tokenizer page](main_classes/tokenizer) for more information.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个对象现在可以与🤗 Transformers分词器共享的所有方法一起使用！请前往[分词器页面](main_classes/tokenizer)获取更多信息。
- en: Loading from a JSON file
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从一个JSON文件加载
- en: 'In order to load a tokenizer from a JSON file, let’s first start by saving
    our tokenizer:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从一个JSON文件中加载一个分词器，让我们首先保存我们的分词器：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The path to which we saved this file can be passed to the [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    initialization method using the `tokenizer_file` parameter:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们保存这个文件的路径可以通过 `tokenizer_file` 参数传递给 [PreTrainedTokenizerFast](/docs/transformers/v4.37.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)
    初始化方法：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This object can now be used with all the methods shared by the 🤗 Transformers
    tokenizers! Head to [the tokenizer page](main_classes/tokenizer) for more information.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这个对象现在可以与🤗 Transformers分词器共享的所有方法一起使用！请前往[分词器页面](main_classes/tokenizer)获取更多信息。
