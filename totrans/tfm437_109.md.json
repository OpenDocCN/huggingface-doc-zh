["```py\nmodel = AutoModel.from_pretrained(\"bert-base-cased\")\n```", "```py\nfrom transformers import AutoConfig, AutoModel\n\nAutoConfig.register(\"new-model\", NewModelConfig)\nAutoModel.register(NewModelConfig, NewModel)\n```", "```py\n( )\n```", "```py\n( pretrained_model_name_or_path **kwargs )\n```", "```py\n>>> from transformers import AutoConfig\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-uncased\")\n\n>>> # Download configuration from huggingface.co (user-uploaded) and cache.\n>>> config = AutoConfig.from_pretrained(\"dbmdz/bert-base-german-cased\")\n\n>>> # If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).\n>>> config = AutoConfig.from_pretrained(\"./test/bert_saved_model/\")\n\n>>> # Load a specific configuration file.\n>>> config = AutoConfig.from_pretrained(\"./test/bert_saved_model/my_configuration.json\")\n\n>>> # Change some config attributes when loading a pretrained config.\n>>> config = AutoConfig.from_pretrained(\"bert-base-uncased\", output_attentions=True, foo=False)\n>>> config.output_attentions\nTrue\n\n>>> config, unused_kwargs = AutoConfig.from_pretrained(\n...     \"bert-base-uncased\", output_attentions=True, foo=False, return_unused_kwargs=True\n... )\n>>> config.output_attentions\nTrue\n\n>>> unused_kwargs\n{'foo': False}\n```", "```py\n( model_type config exist_ok = False )\n```", "```py\n( )\n```", "```py\n( pretrained_model_name_or_path *inputs **kwargs )\n```", "```py\n>>> from transformers import AutoTokenizer\n\n>>> # Download vocabulary from huggingface.co and cache.\n>>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n>>> # Download vocabulary from huggingface.co (user-uploaded) and cache.\n>>> tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-cased\")\n\n>>> # If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)\n>>> # tokenizer = AutoTokenizer.from_pretrained(\"./test/bert_saved_model/\")\n\n>>> # Download vocabulary from huggingface.co and define model-specific arguments\n>>> tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", add_prefix_space=True)\n```", "```py\n( config_class slow_tokenizer_class = None fast_tokenizer_class = None exist_ok = False )\n```", "```py\n( )\n```", "```py\n( pretrained_model_name_or_path **kwargs )\n```", "```py\n>>> from transformers import AutoFeatureExtractor\n\n>>> # Download feature extractor from huggingface.co and cache.\n>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n\n>>> # If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)\n>>> # feature_extractor = AutoFeatureExtractor.from_pretrained(\"./test/saved_model/\")\n```", "```py\n( config_class feature_extractor_class exist_ok = False )\n```", "```py\n( )\n```", "```py\n( pretrained_model_name_or_path **kwargs )\n```", "```py\n>>> from transformers import AutoImageProcessor\n\n>>> # Download image processor from huggingface.co and cache.\n>>> image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n\n>>> # If image processor files are in a directory (e.g. image processor was saved using *save_pretrained('./test/saved_model/')*)\n>>> # image_processor = AutoImageProcessor.from_pretrained(\"./test/saved_model/\")\n```", "```py\n( config_class image_processor_class exist_ok = False )\n```", "```py\n( )\n```", "```py\n( pretrained_model_name_or_path **kwargs )\n```", "```py\n>>> from transformers import AutoProcessor\n\n>>> # Download processor from huggingface.co and cache.\n>>> processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n\n>>> # If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)\n>>> # processor = AutoProcessor.from_pretrained(\"./test/saved_model/\")\n```", "```py\n( config_class processor_class exist_ok = False )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModel\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModel.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModel\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModel.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModel.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModel.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModel\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModel.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModel\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModel.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModel.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModel.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModel\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModel.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModel\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModel.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModel.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModel.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForPreTraining\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForPreTraining.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForPreTraining\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForPreTraining.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForPreTraining.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForPreTraining.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForPreTraining\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForPreTraining.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForPreTraining\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForPreTraining.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForPreTraining.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForPreTraining.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForPreTraining\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForPreTraining.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForPreTraining\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForPreTraining.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForPreTraining.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForPreTraining.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForCausalLM\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForCausalLM.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForCausalLM\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForCausalLM.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForCausalLM.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForCausalLM.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForCausalLM\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForCausalLM.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForCausalLM\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForCausalLM.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForCausalLM.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForCausalLM.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForCausalLM\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForCausalLM.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForCausalLM\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForCausalLM.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForCausalLM.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForCausalLM.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForMaskedLM\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForMaskedLM.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForMaskedLM\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForMaskedLM.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForMaskedLM.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForMaskedLM.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForMaskedLM\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForMaskedLM.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForMaskedLM\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForMaskedLM.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForMaskedLM.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForMaskedLM.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForMaskedLM\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForMaskedLM.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForMaskedLM\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForMaskedLM.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForMaskedLM.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForMaskedLM.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForSeq2SeqLM\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"t5-base\")\n>>> model = AutoModelForSeq2SeqLM.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForSeq2SeqLM\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/t5_tf_model_config.json\")\n>>> model = AutoModelForSeq2SeqLM.from_pretrained(\n...     \"./tf_model/t5_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForSeq2SeqLM\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"t5-base\")\n>>> model = TFAutoModelForSeq2SeqLM.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForSeq2SeqLM\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-base\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/t5_pt_model_config.json\")\n>>> model = TFAutoModelForSeq2SeqLM.from_pretrained(\n...     \"./pt_model/t5_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"t5-base\")\n>>> model = FlaxAutoModelForSeq2SeqLM.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForSeq2SeqLM.from_pretrained(\"t5-base\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/t5_pt_model_config.json\")\n>>> model = FlaxAutoModelForSeq2SeqLM.from_pretrained(\n...     \"./pt_model/t5_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForSequenceClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForSequenceClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForSequenceClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForSequenceClassification.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForSequenceClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForSequenceClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForSequenceClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForSequenceClassification.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForSequenceClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForSequenceClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForSequenceClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForSequenceClassification.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForMultipleChoice\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForMultipleChoice.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForMultipleChoice\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForMultipleChoice.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForMultipleChoice.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForMultipleChoice.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForMultipleChoice\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForMultipleChoice.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForMultipleChoice\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForMultipleChoice.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForMultipleChoice.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForMultipleChoice.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForMultipleChoice\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForMultipleChoice.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForMultipleChoice\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForMultipleChoice.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForMultipleChoice.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForMultipleChoice.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForNextSentencePrediction\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForNextSentencePrediction.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForNextSentencePrediction\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForNextSentencePrediction.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForNextSentencePrediction.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForNextSentencePrediction.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForNextSentencePrediction\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForNextSentencePrediction.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForNextSentencePrediction\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForNextSentencePrediction.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForNextSentencePrediction.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForNextSentencePrediction.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForNextSentencePrediction.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForNextSentencePrediction.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForNextSentencePrediction.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForNextSentencePrediction.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForTokenClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForTokenClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForTokenClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForTokenClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForTokenClassification.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForTokenClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForTokenClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForTokenClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForTokenClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForTokenClassification.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForTokenClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForTokenClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForTokenClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForTokenClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForTokenClassification.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForQuestionAnswering\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForQuestionAnswering.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForQuestionAnswering\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForQuestionAnswering.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForQuestionAnswering\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForQuestionAnswering.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForQuestionAnswering\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForQuestionAnswering.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForQuestionAnswering.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForQuestionAnswering.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForQuestionAnswering.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForQuestionAnswering.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForQuestionAnswering.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForQuestionAnswering.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForDepthEstimation\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForDepthEstimation.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForDepthEstimation\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForDepthEstimation.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForDepthEstimation.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForDepthEstimation.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForImageClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForImageClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForImageClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForImageClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForImageClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForImageClassification.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForImageClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForImageClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForImageClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForImageClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForImageClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForImageClassification.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForImageClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForImageClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForImageClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForImageClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForImageClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForImageClassification.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForVideoClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForVideoClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForVideoClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForVideoClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForVideoClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForVideoClassification.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForMaskedImageModeling\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForMaskedImageModeling.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForMaskedImageModeling\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForMaskedImageModeling.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForMaskedImageModeling.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForMaskedImageModeling.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForMaskedImageModeling\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForMaskedImageModeling.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForMaskedImageModeling\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForMaskedImageModeling.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForMaskedImageModeling.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForMaskedImageModeling.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForObjectDetection\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForObjectDetection.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForObjectDetection\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForObjectDetection.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForObjectDetection.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForObjectDetection.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForImageSegmentation\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForImageSegmentation.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForImageSegmentation\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForImageSegmentation.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForImageSegmentation.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForImageSegmentation.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForSemanticSegmentation\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForSemanticSegmentation.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForSemanticSegmentation\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForSemanticSegmentation.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForSemanticSegmentation.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForSemanticSegmentation.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForSemanticSegmentation\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForSemanticSegmentation.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForSemanticSegmentation\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForSemanticSegmentation.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForSemanticSegmentation.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForSemanticSegmentation.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForInstanceSegmentation\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForInstanceSegmentation.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForInstanceSegmentation\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForInstanceSegmentation.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForInstanceSegmentation.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForInstanceSegmentation.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForUniversalSegmentation\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForUniversalSegmentation.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForUniversalSegmentation\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForUniversalSegmentation.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForUniversalSegmentation.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForUniversalSegmentation.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForZeroShotImageClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForZeroShotImageClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForZeroShotImageClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForZeroShotImageClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForZeroShotImageClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForZeroShotImageClassification.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForZeroShotImageClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForZeroShotImageClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForZeroShotImageClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForZeroShotImageClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForZeroShotImageClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForZeroShotImageClassification.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForZeroShotObjectDetection\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForZeroShotObjectDetection.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForZeroShotObjectDetection\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForZeroShotObjectDetection.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForZeroShotObjectDetection.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForZeroShotObjectDetection.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForAudioClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForAudioClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForAudioClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForAudioClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForAudioClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForAudioClassification.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForAudioClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForAudioClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForAudioClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForAudioClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForAudioClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForAudioClassification.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForAudioFrameClassification\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForAudioFrameClassification.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForAudioFrameClassification\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForAudioFrameClassification.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForAudioFrameClassification.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForAudioFrameClassification.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForCTC\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForCTC.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForCTC\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForCTC.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForCTC.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForCTC.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForSpeechSeq2Seq\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForSpeechSeq2Seq.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForSpeechSeq2Seq\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForSpeechSeq2Seq.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForSpeechSeq2Seq.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForSpeechSeq2Seq.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForSpeechSeq2Seq.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForSpeechSeq2Seq.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForSpeechSeq2Seq.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForSpeechSeq2Seq.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForSpeechSeq2Seq\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForSpeechSeq2Seq.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForSpeechSeq2Seq\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForAudioXVector\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForAudioXVector.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForAudioXVector\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForAudioXVector.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForAudioXVector.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForAudioXVector.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForTableQuestionAnswering\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = AutoModelForTableQuestionAnswering.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForTableQuestionAnswering\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForTableQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForTableQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/tapas_tf_model_config.json\")\n>>> model = AutoModelForTableQuestionAnswering.from_pretrained(\n...     \"./tf_model/tapas_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n>>> model = TFAutoModelForTableQuestionAnswering.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForTableQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForTableQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/tapas_pt_model_config.json\")\n>>> model = TFAutoModelForTableQuestionAnswering.from_pretrained(\n...     \"./pt_model/tapas_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"impira/layoutlm-document-qa\", revision=\"52e01b3\")\n>>> model = AutoModelForDocumentQuestionAnswering.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained(\"impira/layoutlm-document-qa\", revision=\"52e01b3\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained(\"impira/layoutlm-document-qa\", revision=\"52e01b3\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/layoutlm_tf_model_config.json\")\n>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained(\n...     \"./tf_model/layoutlm_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"impira/layoutlm-document-qa\", revision=\"52e01b3\")\n>>> model = TFAutoModelForDocumentQuestionAnswering.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(\"impira/layoutlm-document-qa\", revision=\"52e01b3\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(\"impira/layoutlm-document-qa\", revision=\"52e01b3\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/layoutlm_pt_model_config.json\")\n>>> model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(\n...     \"./pt_model/layoutlm_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForVisualQuestionAnswering\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n>>> model = AutoModelForVisualQuestionAnswering.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForVisualQuestionAnswering\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForVisualQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForVisualQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/vilt_tf_model_config.json\")\n>>> model = AutoModelForVisualQuestionAnswering.from_pretrained(\n...     \"./tf_model/vilt_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForVision2Seq\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = AutoModelForVision2Seq.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, AutoModelForVision2Seq\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = AutoModelForVision2Seq.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = AutoModelForVision2Seq.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n>>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n>>> model = AutoModelForVision2Seq.from_pretrained(\n...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForVision2Seq\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = TFAutoModelForVision2Seq.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, TFAutoModelForVision2Seq\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = TFAutoModelForVision2Seq.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = TFAutoModelForVision2Seq.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = TFAutoModelForVision2Seq.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```", "```py\n( *args **kwargs )\n```", "```py\n( **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForVision2Seq\n\n>>> # Download configuration from huggingface.co and cache.\n>>> config = AutoConfig.from_pretrained(\"bert-base-cased\")\n>>> model = FlaxAutoModelForVision2Seq.from_config(config)\n```", "```py\n( *model_args **kwargs )\n```", "```py\n>>> from transformers import AutoConfig, FlaxAutoModelForVision2Seq\n\n>>> # Download model and configuration from huggingface.co and cache.\n>>> model = FlaxAutoModelForVision2Seq.from_pretrained(\"bert-base-cased\")\n\n>>> # Update configuration during loading\n>>> model = FlaxAutoModelForVision2Seq.from_pretrained(\"bert-base-cased\", output_attentions=True)\n>>> model.config.output_attentions\nTrue\n\n>>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)\n>>> config = AutoConfig.from_pretrained(\"./pt_model/bert_pt_model_config.json\")\n>>> model = FlaxAutoModelForVision2Seq.from_pretrained(\n...     \"./pt_model/bert_pytorch_model.bin\", from_pt=True, config=config\n... )\n```"]