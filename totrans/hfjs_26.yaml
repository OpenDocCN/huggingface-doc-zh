- en: 'Interface: TextGenerationStreamDetails'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/huggingface.js/inference/interfaces/TextGenerationStreamDetails](https://huggingface.co/docs/huggingface.js/inference/interfaces/TextGenerationStreamDetails)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: best _ of _ sequences
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `Optional` `best_of_sequences`: [`TextGenerationStreamBestOfSequence`](TextGenerationStreamBestOfSequence)[]'
  prefs: []
  type: TYPE_NORMAL
- en: Additional sequences when using the `best_of` parameter
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:66](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L66)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: finish _ reason
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `finish_reason`: [`TextGenerationStreamFinishReason`](../modules#textgenerationstreamfinishreason)'
  prefs: []
  type: TYPE_NORMAL
- en: Generation finish reason
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:56](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L56)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: generated _ tokens
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `generated_tokens`: `number`'
  prefs: []
  type: TYPE_NORMAL
- en: Number of generated tokens
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:58](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L58)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: prefill
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `prefill`: [`TextGenerationStreamPrefillToken`](TextGenerationStreamPrefillToken)[]'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt tokens
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:62](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L62)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: seed
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `Optional` `seed`: `number`'
  prefs: []
  type: TYPE_NORMAL
- en: Sampling seed if sampling was activated
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:60](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L60)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: tokens
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `tokens`: [`TextGenerationStreamToken`](TextGenerationStreamToken)[]'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:64](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L64)'
  prefs: []
  type: TYPE_NORMAL
