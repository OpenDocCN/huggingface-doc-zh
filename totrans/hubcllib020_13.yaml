- en: Run Inference on servers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在服务器上运行推理
- en: 'Original text: [https://huggingface.co/docs/huggingface_hub/guides/inference](https://huggingface.co/docs/huggingface_hub/guides/inference)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/huggingface_hub/guides/inference](https://huggingface.co/docs/huggingface_hub/guides/inference)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Inference is the process of using a trained model to make predictions on new
    data. As this process can be compute-intensive, running on a dedicated server
    can be an interesting option. The `huggingface_hub` library provides an easy way
    to call a service that runs inference for hosted models. There are several services
    you can connect to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 推理是使用训练好的模型对新数据进行预测的过程。由于这个过程可能需要大量计算资源，运行在专用服务器上可能是一个有趣的选择。`huggingface_hub`库提供了一种简单的方式来调用一个运行托管模型推理的服务。您可以连接到几种服务：
- en: '[Inference API](https://huggingface.co/docs/api-inference/index): a service
    that allows you to run accelerated inference on Hugging Face’s infrastructure
    for free. This service is a fast way to get started, test different models, and
    prototype AI products.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Inference API](https://huggingface.co/docs/api-inference/index)：一个服务，允许您在Hugging
    Face的基础设施上免费运行加速推理。这项服务是快速开始、测试不同模型和原型化AI产品的快速方式。'
- en: '[Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index):
    a product to easily deploy models to production. Inference is run by Hugging Face
    in a dedicated, fully managed infrastructure on a cloud provider of your choice.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index)：一个产品，可以轻松部署模型到生产环境。推理由Hugging
    Face在您选择的云提供商上的专用完全托管基础设施上运行。'
- en: These services can be called with the [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    object. It acts as a replacement for the legacy [InferenceApi](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceApi)
    client, adding specific support for tasks and handling inference on both [Inference
    API](https://huggingface.co/docs/api-inference/index) and [Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index).
    Learn how to migrate to the new client in the [Legacy InferenceAPI client](#legacy-inferenceapi-client)
    section.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这些服务可以通过[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)对象调用。它作为传统[InferenceApi](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceApi)客户端的替代品，为任务添加了特定支持，并处理了[Inference
    API](https://huggingface.co/docs/api-inference/index)和[Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index)上的推理。在[Legacy
    InferenceAPI client](#legacy-inferenceapi-client)部分了解如何迁移到新客户端。
- en: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    is a Python client making HTTP calls to our APIs. If you want to make the HTTP
    calls directly using your preferred tool (curl, postman,…), please refer to the
    [Inference API](https://huggingface.co/docs/api-inference/index) or to the [Inference
    Endpoints](https://huggingface.co/docs/inference-endpoints/index) documentation
    pages.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)是一个Python客户端，通过HTTP调用我们的API。如果您想使用您喜欢的工具（curl、postman等）直接进行HTTP调用，请参考[Inference
    API](https://huggingface.co/docs/api-inference/index)或[Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index)文档页面。'
- en: For web development, a [JS client](https://huggingface.co/docs/huggingface.js/inference/README)
    has been released. If you are interested in game development, you might have a
    look at our [C# project](https://github.com/huggingface/unity-api).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Web开发，已发布了[JS客户端](https://huggingface.co/docs/huggingface.js/inference/README)。如果您对游戏开发感兴趣，可以查看我们的[C#项目](https://github.com/huggingface/unity-api)。
- en: Getting started
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 入门
- en: 'Let’s get started with a text-to-image task:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始一个文本到图像的任务：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We initialized an [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    with the default parameters. The only thing you need to know is the [task](#supported-tasks)
    you want to perform. By default, the client will connect to the Inference API
    and select a model to complete the task. In our example, we generated an image
    from a text prompt. The returned value is a `PIL.Image` object that can be saved
    to a file.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用默认参数初始化了一个[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)。您唯一需要知道的是您想要执行的[任务](#supported-tasks)。默认情况下，客户端将连接到推理API并选择一个模型来完成任务。在我们的示例中，我们从文本提示生成了一张图片。返回的值是一个`PIL.Image`对象，可以保存到文件中。
- en: The API is designed to be simple. Not all parameters and options are available
    or described for the end user. Check out [this page](https://huggingface.co/docs/api-inference/detailed_parameters)
    if you are interested in learning more about all the parameters available for
    each task.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: API设计简单。并非所有参数和选项都适用或描述给最终用户。如果您想了解每个任务可用的所有参数，请查看[此页面](https://huggingface.co/docs/api-inference/detailed_parameters)。
- en: Using a specific model
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用特定模型
- en: 'What if you want to use a specific model? You can specify it either as a parameter
    or directly at an instance level:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想使用特定模型怎么办？您可以将其指定为参数或直接在实例级别指定：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: There are more than 200k models on the Hugging Face Hub! Each task in the [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    comes with a recommended model. Be aware that the HF recommendation can change
    over time without prior notice. Therefore it is best to explicitly set a model
    once you are decided. Also, in most cases you’ll be interested in finding a model
    specific to *your* needs. Visit the [Models](https://huggingface.co/models) page
    on the Hub to explore your possibilities.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在Hugging Face Hub上有超过200k个模型！[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)中的每个任务都附带一个推荐模型。请注意，HF的推荐可能会随时间而变化，没有事先通知。因此，最好在决定后明确设置一个模型。此外，在大多数情况下，您可能会对找到一个符合*您*需求的模型感兴趣。访问Hub上的[Models](https://huggingface.co/models)页面来探索您的可能性。
- en: Using a specific URL
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用特定URL
- en: 'The examples we saw above use the free-hosted Inference API. This proves to
    be very useful for prototyping and testing things quickly. Once you’re ready to
    deploy your model to production, you’ll need to use a dedicated infrastructure.
    That’s where [Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index)
    comes into play. It allows you to deploy any model and expose it as a private
    API. Once deployed, you’ll get a URL that you can connect to using exactly the
    same code as before, changing only the `model` parameter:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们上面看到的示例使用了免费托管的推理API。这对于快速原型设计和测试非常有用。一旦您准备将模型部署到生产环境中，您将需要使用专用基础设施。这就是[推理端点](https://huggingface.co/docs/inference-endpoints/index)的作用所在。它允许您部署任何模型并将其公开为私有API。一旦部署，您将获得一个URL，您可以使用与之前完全相同的代码连接到该URL，只需更改`model`参数即可：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Authentication
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 身份验证
- en: 'Calls made with the [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    can be authenticated using a [User Access Token](https://huggingface.co/docs/hub/security-tokens).
    By default, it will use the token saved on your machine if you are logged in (check
    out [how to authenticate](https://huggingface.co/docs/huggingface_hub/quick-start#authentication)).
    If you are not logged in, you can pass your token as an instance parameter:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)进行的调用可以使用[用户访问令牌](https://huggingface.co/docs/hub/security-tokens)进行身份验证。默认情况下，如果您已登录，则它将使用保存在您的计算机上的令牌（查看[如何进行身份验证](https://huggingface.co/docs/huggingface_hub/quick-start#authentication)）。如果您未登录，您可以将您的令牌作为实例参数传递：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Authentication is NOT mandatory when using the Inference API. However, authenticated
    users get a higher free-tier to play with the service. Token is also mandatory
    if you want to run inference on your private models or on private endpoints.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用推理API时，身份验证并不是强制性的。但是，经过身份验证的用户可以获得更高的免费使用额度。如果您想在私有模型或私有端点上运行推理，则令牌也是必需的。
- en: Supported tasks
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持的任务
- en: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)’s
    goal is to provide the easiest interface to run inference on Hugging Face models.
    It has a simple API that supports the most common tasks. Here is a list of the
    currently supported tasks:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)的目标是提供在Hugging
    Face模型上运行推理的最简单接口。它具有一个简单的API，支持最常见的任务。以下是当前支持的任务列表：'
- en: '| Domain | Task | Supported | Documentation |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: 领域 | 任务 | 支持 | 文档 |
- en: '| --- | --- | --- | --- |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Audio | [Audio Classification](https://huggingface.co/tasks/audio-classification)
    | ✅ | [audio_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.audio_classification)
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 音频 | [音频分类](https://huggingface.co/tasks/audio-classification) | ✅ | [audio_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.audio_classification)
    |'
- en: '|  | [Automatic Speech Recognition](https://huggingface.co/tasks/automatic-speech-recognition)
    | ✅ | [automatic_speech_recognition()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.automatic_speech_recognition)
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  | [自动语音识别](https://huggingface.co/tasks/automatic-speech-recognition) |
    ✅ | [automatic_speech_recognition()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.automatic_speech_recognition)
    |'
- en: '|  | [Text-to-Speech](https://huggingface.co/tasks/text-to-speech) | ✅ | [text_to_speech()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.text_to_speech)
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '|  | [文本转语音](https://huggingface.co/tasks/text-to-speech) | ✅ | [text_to_speech()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.text_to_speech)
    |'
- en: '| Computer Vision | [Image Classification](https://huggingface.co/tasks/image-classification)
    | ✅ | [image_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_classification)
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 计算机视觉 | [图像分类](https://huggingface.co/tasks/image-classification) | ✅ | [image_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_classification)
    |'
- en: '|  | [Image Segmentation](https://huggingface.co/tasks/image-segmentation)
    | ✅ | [image_segmentation()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_segmentation)
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|  | [图像分割](https://huggingface.co/tasks/image-segmentation) | ✅ | [image_segmentation()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_segmentation)
    |'
- en: '|  | [Image-to-Image](https://huggingface.co/tasks/image-to-image) | ✅ | [image_to_image()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_to_image)
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | [图像到图像](https://huggingface.co/tasks/image-to-image) | ✅ | [image_to_image()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_to_image)
    |'
- en: '|  | [Image-to-Text](https://huggingface.co/tasks/image-to-text) | ✅ | [image_to_text()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_to_text)
    |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | [图像到文本](https://huggingface.co/tasks/image-to-text) | ✅ | [image_to_text()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_to_text)
    |'
- en: '|  | [Object Detection](https://huggingface.co/tasks/object-detection) | ✅
    | [object_detection()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.object_detection)
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '|  | [目标检测](https://huggingface.co/tasks/object-detection) | ✅ | [object_detection()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.object_detection)
    |'
- en: '|  | [Text-to-Image](https://huggingface.co/tasks/text-to-image) | ✅ | [text_to_image()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.text_to_image)
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | [文本到图像](https://huggingface.co/tasks/text-to-image) | ✅ | [text_to_image()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.text_to_image)
    |'
- en: '|  | [Zero-Shot-Image-Classification](https://huggingface.co/tasks/zero-shot-image-classification)
    | ✅ | [zero_shot_image_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.zero_shot_image_classification)
    |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | [零样本图像分类](https://huggingface.co/tasks/zero-shot-image-classification)
    | ✅ | [zero_shot_image_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.zero_shot_image_classification)
    |'
- en: '| Multimodal | [Documentation Question Answering](https://huggingface.co/tasks/document-question-answering)
    | ✅ | [document_question_answering()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.document_question_answering)
    |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 多模态 | [文档问答](https://huggingface.co/tasks/document-question-answering) |
    ✅ | [document_question_answering()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.document_question_answering)
    |'
- en: '|  | [Visual Question Answering](https://huggingface.co/tasks/visual-question-answering)
    | ✅ | [visual_question_answering()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.visual_question_answering)
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|  | [视觉问答](https://huggingface.co/tasks/visual-question-answering) | ✅ | [visual_question_answering()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.visual_question_answering)
    |'
- en: '| NLP | [Conversational](https://huggingface.co/tasks/conversational) | ✅ |
    [conversational()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.conversational)
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| NLP | [对话](https://huggingface.co/tasks/conversational) | ✅ | [conversational()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.conversational)
    |'
- en: '|  | [Feature Extraction](https://huggingface.co/tasks/feature-extraction)
    | ✅ | [feature_extraction()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.feature_extraction)
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '|  | [特征提取](https://huggingface.co/tasks/feature-extraction) | ✅ | [feature_extraction()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.feature_extraction)
    |'
- en: '|  | [Fill Mask](https://huggingface.co/tasks/fill-mask) | ✅ | [fill_mask()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.fill_mask)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | [填充掩码](https://huggingface.co/tasks/fill-mask) | ✅ | [fill_mask()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.fill_mask)
    |'
- en: '|  | [Question Answering](https://huggingface.co/tasks/question-answering)
    | ✅ | [question_answering()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.question_answering)
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|  | [问答](https://huggingface.co/tasks/question-answering) | ✅ | [question_answering()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.question_answering)
    |'
- en: '|  | [Sentence Similarity](https://huggingface.co/tasks/sentence-similarity)
    | ✅ | [sentence_similarity()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.sentence_similarity)
    |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|  | [句子相似度](https://huggingface.co/tasks/sentence-similarity) | ✅ | [sentence_similarity()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.sentence_similarity)
    |'
- en: '|  | [Summarization](https://huggingface.co/tasks/summarization) | ✅ | [summarization()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.summarization)
    |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|  | [摘要](https://huggingface.co/tasks/summarization) | ✅ | [summarization()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.summarization)
    |'
- en: '|  | [Table Question Answering](https://huggingface.co/tasks/table-question-answering)
    | ✅ | [table_question_answering()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.table_question_answering)
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|  | [表格问答](https://huggingface.co/tasks/table-question-answering) | ✅ | [table_question_answering()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.table_question_answering)
    |'
- en: '|  | [Text Classification](https://huggingface.co/tasks/text-classification)
    | ✅ | [text_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.text_classification)
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | [文本分类](https://huggingface.co/tasks/text-classification) | ✅ | [text_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.text_classification)
    |'
- en: '|  | [Text Generation](https://huggingface.co/tasks/text-generation) | ✅ |
    [text_generation()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.text_generation)
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | [文本生成](https://huggingface.co/tasks/text-generation) | ✅ | [text_generation()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.text_generation)
    |'
- en: '|  | [Token Classification](https://huggingface.co/tasks/token-classification)
    | ✅ | [token_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.token_classification)
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | [标记分类](https://huggingface.co/tasks/token-classification) | ✅ | [token_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.token_classification)
    |'
- en: '|  | [Translation](https://huggingface.co/tasks/translation) | ✅ | [translation()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.translation)
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | [翻译](https://huggingface.co/tasks/translation) | ✅ | [translation()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.translation)
    |'
- en: '|  | [Zero Shot Classification](https://huggingface.co/tasks/zero-shot-classification)
    | ✅ | [zero_shot_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.zero_shot_classification)
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | [零样本分类](https://huggingface.co/tasks/zero-shot-classification) | ✅ | [zero_shot_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.zero_shot_classification)
    |'
- en: '| Tabular | [Tabular Classification](https://huggingface.co/tasks/tabular-classification)
    | ✅ | [tabular_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.tabular_classification)
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 表格 | [表格分类](https://huggingface.co/tasks/tabular-classification) | ✅ | [tabular_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.tabular_classification)
    |'
- en: '|  | [Tabular Regression](https://huggingface.co/tasks/tabular-regression)
    | ✅ | [tabular_regression()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.tabular_regression)
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | [表格回归](https://huggingface.co/tasks/tabular-regression) | ✅ | [tabular_regression()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.tabular_regression)
    |'
- en: Check out the [Tasks](https://huggingface.co/tasks) page to learn more about
    each task, how to use them, and the most popular models for each task.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[Tasks](https://huggingface.co/tasks)页面，了解更多关于每个任务的信息，如何使用它们以及每个任务的最受欢迎的模型。
- en: Custom requests
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义请求
- en: However, it is not always possible to cover all use cases. For custom requests,
    the [InferenceClient.post()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.post)
    method gives you the flexibility to send any request to the Inference API. For
    example, you can specify how to parse the inputs and outputs. In the example below,
    the generated image is returned as raw bytes instead of parsing it as a `PIL Image`.
    This can be helpful if you don’t have `Pillow` installed in your setup and just
    care about the binary content of the image. [InferenceClient.post()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.post)
    is also useful to handle tasks that are not yet officially supported.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非总是可能覆盖所有用例。对于自定义请求，[InferenceClient.post()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.post)方法为您提供了灵活性，以向推断API发送任何请求。例如，您可以指定如何解析输入和输出。在下面的示例中，生成的图像以原始字节返回，而不是将其解析为`PIL
    Image`。如果您的设置中没有安装`Pillow`，并且只关心图像的二进制内容，则这可能会有所帮助。[InferenceClient.post()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.post)还可用于处理尚未正式支持的任务。
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Async client
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异步客户端
- en: 'An async version of the client is also provided, based on `asyncio` and `aiohttp`.
    You can either install `aiohttp` directly or use the `[inference]` extra:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 还提供了一个基于`asyncio`和`aiohttp`的异步版本的客户端。您可以直接安装`aiohttp`，也可以使用`[inference]`额外功能：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After installation all async API endpoints are available via [AsyncInferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.AsyncInferenceClient).
    Its initialization and APIs are strictly the same as the sync-only version.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 安装后，所有异步API端点都可以通过[AsyncInferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.AsyncInferenceClient)访问。它的初始化和API与仅同步版本严格相同。
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For more information about the `asyncio` module, please refer to the [official
    documentation](https://docs.python.org/3/library/asyncio.html).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`asyncio`模块的更多信息，请参考[官方文档](https://docs.python.org/3/library/asyncio.html)。
- en: Advanced tips
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级技巧
- en: In the above section, we saw the main aspects of [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient).
    Let’s dive into some more advanced tips.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的部分中，我们看到了[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)的主要方面。让我们深入一些更高级的技巧。
- en: Timeout
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 超时
- en: 'When doing inference, there are two main causes for a timeout:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行推断时，有两个主要原因会导致超时：
- en: The inference process takes a long time to complete.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推断过程需要很长时间才能完成。
- en: The model is not available, for example when Inference API is loading it for
    the first time.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，当推断API首次加载模型时，模型不可用。
- en: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    has a global `timeout` parameter to handle those two aspects. By default, it is
    set to `None`, meaning that the client will wait indefinitely for the inference
    to complete. If you want more control in your workflow, you can set it to a specific
    value in seconds. If the timeout delay expires, an [InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    is raised. You can catch it and handle it in your code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)有一个全局的`timeout`参数来处理这两个方面。默认情况下，它设置为`None`，这意味着客户端将无限期地等待推断完成。如果您希望在工作流程中有更多控制，可以将其设置为特定的秒数值。如果超时延迟到期，将引发一个[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)。您可以捕获它并在您的代码中处理它：'
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Binary inputs
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二进制输入
- en: 'Some tasks require binary inputs, for example, when dealing with images or
    audio files. In this case, [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    tries to be as permissive as possible and accept different types:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 有些任务需要二进制输入，例如处理图像或音频文件时。在这种情况下，[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)尝试尽可能宽松，并接受不同类型：
- en: raw `bytes`
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始的`bytes`
- en: 'a file-like object, opened as binary (`with open("audio.flac", "rb") as f:
    ...`)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '一个类似文件的对象，以二进制形式打开（`with open("audio.flac", "rb") as f: ...`）'
- en: a path (`str` or `Path`) pointing to a local file
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向本地文件的路径（`str`或`Path`）
- en: a URL (`str`) pointing to a remote file (e.g. `https://...`). In this case,
    the file will be downloaded locally before sending it to the Inference API.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向远程文件的URL（例如`https://...`）。在这种情况下，文件将在发送到推断API之前被下载到本地。
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Legacy InferenceAPI client
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统的InferenceAPI客户端
- en: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    acts as a replacement for the legacy [InferenceApi](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceApi)
    client. It adds specific support for tasks and handles inference on both [Inference
    API](https://huggingface.co/docs/api-inference/index) and [Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)充当传统[InferenceApi](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceApi)客户端的替代品。它为任务添加了特定支持，并处理了[Inference
    API](https://huggingface.co/docs/api-inference/index)和[Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index)上的推断。'
- en: Here is a short guide to help you migrate from [InferenceApi](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceApi)
    to [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个简短的指南，帮助您从[InferenceApi](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceApi)迁移到[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)。
- en: Initialization
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初始化
- en: Change from
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 更改自
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: to
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 至
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Run on a specific task
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在特定任务上运行
- en: Change from
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 更改自
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: to
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 至
- en: '[PRE12]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This is the recommended way to adapt your code to [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient).
    It lets you benefit from the task-specific methods like `feature_extraction`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是将您的代码适应[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)的推荐方式。它让您可以从诸如`feature_extraction`之类的特定任务方法中受益。
- en: Run custom request
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行自定义请求
- en: Change from
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 从
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: to
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 到
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Run with parameters
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带参数运行
- en: Change from
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: to
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 到
- en: '[PRE16]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
