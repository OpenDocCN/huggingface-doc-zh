- en: ğŸ¤— Transformers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ¤— Transformers
- en: 'Original text: [https://huggingface.co/docs/evaluate/transformers_integrations](https://huggingface.co/docs/evaluate/transformers_integrations)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/evaluate/transformers_integrations](https://huggingface.co/docs/evaluate/transformers_integrations)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the ğŸ¤— Transformers examples make sure you have installed the following
    libraries:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è¿è¡ŒğŸ¤— Transformersç¤ºä¾‹ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹åº“ï¼š
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Trainer
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Trainer
- en: The metrics in `evaluate` can be easily integrated with the [Trainer](https://huggingface.co/docs/transformers/v4.25.1/en/main_classes/trainer#transformers.Trainer).
    The `Trainer` accepts a `compute_metrics` keyword argument that passes a function
    to compute metrics. One can specify the evaluation interval with `evaluation_strategy`
    in the `TrainerArguments`, and based on that, the model is evaluated accordingly,
    and the predictions and labels passed to `compute_metrics`.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '`evaluate`ä¸­çš„æŒ‡æ ‡å¯ä»¥è½»æ¾ä¸[Trainer](https://huggingface.co/docs/transformers/v4.25.1/en/main_classes/trainer#transformers.Trainer)é›†æˆã€‚`Trainer`æ¥å—ä¸€ä¸ª`compute_metrics`å…³é”®å­—å‚æ•°ï¼Œä¼ é€’ä¸€ä¸ªè®¡ç®—æŒ‡æ ‡çš„å‡½æ•°ã€‚å¯ä»¥åœ¨`TrainerArguments`ä¸­ä½¿ç”¨`evaluation_strategy`æŒ‡å®šè¯„ä¼°é—´éš”ï¼Œæ ¹æ®æ­¤é—´éš”ï¼Œç›¸åº”åœ°è¯„ä¼°æ¨¡å‹ï¼Œå¹¶å°†é¢„æµ‹å’Œæ ‡ç­¾ä¼ é€’ç»™`compute_metrics`ã€‚'
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Seq2SeqTrainer
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Seq2SeqTrainer
- en: We can use the [Seq2SeqTrainer](https://huggingface.co/docs/transformers/v4.25.1/en/main_classes/trainer#transformers.Seq2SeqTrainer)
    for sequence-to-sequence tasks such as translation or summarization. For such
    generative tasks usually metrics such as ROUGE or BLEU are evaluated. However,
    these metrics require that we generate some text with the model rather than a
    single forward pass as with e.g. classification. The `Seq2SeqTrainer` allows for
    the use of the generate method when setting `predict_with_generate=True` which
    will generate text for each sample in the evaluation set. That means we evaluate
    generated text within the `compute_metric` function. We just need to decode the
    predictions and labels first.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨åºåˆ—åˆ°åºåˆ—ä»»åŠ¡ï¼ˆå¦‚ç¿»è¯‘æˆ–æ‘˜è¦ï¼‰ä¸­ä½¿ç”¨[Seq2SeqTrainer](https://huggingface.co/docs/transformers/v4.25.1/en/main_classes/trainer#transformers.Seq2SeqTrainer)ã€‚å¯¹äºè¿™ç§ç”Ÿæˆå¼ä»»åŠ¡ï¼Œé€šå¸¸ä¼šè¯„ä¼°ROUGEæˆ–BLEUç­‰æŒ‡æ ‡ã€‚ç„¶è€Œï¼Œè¿™äº›æŒ‡æ ‡è¦æ±‚æˆ‘ä»¬ä½¿ç”¨æ¨¡å‹ç”Ÿæˆä¸€äº›æ–‡æœ¬ï¼Œè€Œä¸æ˜¯åƒåˆ†ç±»é‚£æ ·è¿›è¡Œå•æ¬¡å‰å‘ä¼ é€’ã€‚å½“è®¾ç½®`predict_with_generate=True`æ—¶ï¼Œ`Seq2SeqTrainer`å…è®¸ä½¿ç”¨ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†ä¸ºè¯„ä¼°é›†ä¸­çš„æ¯ä¸ªæ ·æœ¬ç”Ÿæˆæ–‡æœ¬ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬åœ¨`compute_metric`å‡½æ•°ä¸­è¯„ä¼°ç”Ÿæˆçš„æ–‡æœ¬ã€‚æˆ‘ä»¬åªéœ€è¦é¦–å…ˆè§£ç é¢„æµ‹å’Œæ ‡ç­¾ã€‚
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can use any `evaluate` metric with the `Trainer` and `Seq2SeqTrainer` as
    long as they are compatible with the task and predictions. In case you donâ€™t want
    to train a model but just evaluate an existing model you can replace `trainer.train()`
    with `trainer.evaluate()` in the above scripts.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨`Trainer`å’Œ`Seq2SeqTrainer`ä¸­ä½¿ç”¨ä»»ä½•ä¸ä»»åŠ¡å’Œé¢„æµ‹å…¼å®¹çš„`evaluate`æŒ‡æ ‡ã€‚å¦‚æœæ‚¨ä¸æƒ³è®­ç»ƒæ¨¡å‹ï¼Œè€Œåªæ˜¯è¯„ä¼°ç°æœ‰æ¨¡å‹ï¼Œå¯ä»¥åœ¨ä¸Šè¿°è„šæœ¬ä¸­ç”¨`trainer.evaluate()`æ›¿æ¢`trainer.train()`ã€‚
