["```py\n>>> import torch\n>>> from transformers import AutoModel, AutoTokenizer\n\n>>> bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n\n>>> # For transformers v4.x+:\n>>> tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n\n>>> # For transformers v3.x:\n>>> # tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n\n>>> # INPUT TWEET IS ALREADY NORMALIZED!\n>>> line = \"SC has first two presumptive cases of coronavirus , DHEC confirms HTTPURL via @USER :cry:\"\n\n>>> input_ids = torch.tensor([tokenizer.encode(line)])\n\n>>> with torch.no_grad():\n...     features = bertweet(input_ids)  # Models outputs are now tuples\n\n>>> # With TensorFlow 2.0+:\n>>> # from transformers import TFAutoModel\n>>> # bertweet = TFAutoModel.from_pretrained(\"vinai/bertweet-base\")\n```", "```py\n( vocab_file merges_file normalization = False bos_token = '<s>' eos_token = '</s>' sep_token = '</s>' cls_token = '<s>' unk_token = '<unk>' pad_token = '<pad>' mask_token = '<mask>' **kwargs )\n```", "```py\n( f )\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( tokens )\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( token_ids_0: List token_ids_1: Optional = None already_has_special_tokens: bool = False ) \u2192 export const metadata = 'undefined';List[int]\n```", "```py\n( token )\n```", "```py\n( tweet )\n```"]