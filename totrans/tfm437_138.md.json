["```py\n>>> import torch\n>>> from transformers import AutoModel, AutoTokenizer\n\n>>> bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n\n>>> # For transformers v4.x+:\n>>> tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n\n>>> # For transformers v3.x:\n>>> # tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n\n>>> # INPUT TWEET IS ALREADY NORMALIZED!\n>>> line = \"SC has first two presumptive cases of coronavirus , DHEC confirms HTTPURL via @USER :cry:\"\n\n>>> input_ids = torch.tensor([tokenizer.encode(line)])\n\n>>> with torch.no_grad():\n...     features = bertweet(input_ids)  # Models outputs are now tuples\n\n>>> # With TensorFlow 2.0+:\n>>> # from transformers import TFAutoModel\n>>> # bertweet = TFAutoModel.from_pretrained(\"vinai/bertweet-base\")\n```"]