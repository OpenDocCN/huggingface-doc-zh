- en: Adapt a model to a new task
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huggingface.co/docs/diffusers/training/adapt_a_model](https://huggingface.co/docs/diffusers/training/adapt_a_model)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/diffusers/v0.26.3/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/start.99629b4a.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/scheduler.182ea377.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/singletons.fade7992.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.1f6d62f6.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/paths.108a236d.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/entry/app.2b3eaeb0.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/index.abf12888.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/0.3862a335.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/nodes/134.936c33eb.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/CodeBlock.57fe6e13.js">
    <link rel="modulepreload" href="/docs/diffusers/v0.26.3/en/_app/immutable/chunks/Heading.16916d63.js">
  prefs: []
  type: TYPE_NORMAL
- en: Many diffusion systems share the same components, allowing you to adapt a pretrained
    model for one task to an entirely different task.
  prefs: []
  type: TYPE_NORMAL
- en: This guide will show you how to adapt a pretrained text-to-image model for inpainting
    by initializing and modifying the architecture of a pretrained [UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel).
  prefs: []
  type: TYPE_NORMAL
- en: Configure UNet2DConditionModel parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A [UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)
    by default accepts 4 channels in the [input sample](https://huggingface.co/docs/diffusers/v0.16.0/en/api/models#diffusers.UNet2DConditionModel.in_channels).
    For example, load a pretrained text-to-image model like [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5)
    and take a look at the number of `in_channels`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Inpainting requires 9 channels in the input sample. You can check this value
    in a pretrained inpainting model like [`runwayml/stable-diffusion-inpainting`](https://huggingface.co/runwayml/stable-diffusion-inpainting):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To adapt your text-to-image model for inpainting, you’ll need to change the
    number of `in_channels` from 4 to 9.
  prefs: []
  type: TYPE_NORMAL
- en: Initialize a [UNet2DConditionModel](/docs/diffusers/v0.26.3/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)
    with the pretrained text-to-image model weights, and change `in_channels` to 9\.
    Changing the number of `in_channels` means you need to set `ignore_mismatched_sizes=True`
    and `low_cpu_mem_usage=False` to avoid a size mismatch error because the shape
    is different now.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The pretrained weights of the other components from the text-to-image model
    are initialized from their checkpoints, but the input channel weights (`conv_in.weight`)
    of the `unet` are randomly initialized. It is important to finetune the model
    for inpainting because otherwise the model returns noise.
  prefs: []
  type: TYPE_NORMAL
