["```py\n( depths: List = [3, 2, 6, 4] hidden_sizes: List = [48, 96, 224, 448] downsamples: List = [True, True, True, True] dim: int = 448 key_dim: int = 32 attention_ratio: int = 4 resolution: int = 7 num_hidden_layers: int = 5 num_attention_heads: int = 8 mlp_expansion_ratio: int = 4 hidden_dropout_prob: float = 0.0 patch_size: int = 16 num_channels: int = 3 pool_size: int = 3 downsample_patch_size: int = 3 downsample_stride: int = 2 downsample_pad: int = 1 drop_path_rate: float = 0.0 num_meta3d_blocks: int = 1 distillation: bool = True use_layer_scale: bool = True layer_scale_init_value: float = 1e-05 hidden_act: str = 'gelu' initializer_range: float = 0.02 layer_norm_eps: float = 1e-12 image_size: int = 224 batch_norm_eps: float = 1e-05 **kwargs )\n```", "```py\n>>> from transformers import EfficientFormerConfig, EfficientFormerModel\n\n>>> # Initializing a EfficientFormer efficientformer-l1 style configuration\n>>> configuration = EfficientFormerConfig()\n\n>>> # Initializing a EfficientFormerModel (with random weights) from the efficientformer-l3 style configuration\n>>> model = EfficientFormerModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n( do_resize: bool = True size: Optional = None resample: Resampling = <Resampling.BICUBIC: 3> do_center_crop: bool = True do_rescale: bool = True rescale_factor: Union = 0.00392156862745098 crop_size: Dict = None do_normalize: bool = True image_mean: Union = None image_std: Union = None **kwargs )\n```", "```py\n( images: Union do_resize: Optional = None size: Dict = None resample: Resampling = None do_center_crop: bool = None crop_size: int = None do_rescale: Optional = None rescale_factor: Optional = None do_normalize: Optional = None image_mean: Union = None image_std: Union = None return_tensors: Union = None data_format: Union = <ChannelDimension.FIRST: 'channels_first'> input_data_format: Union = None **kwargs )\n```", "```py\n( config: EfficientFormerConfig )\n```", "```py\n( pixel_values: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.BaseModelOutputWithPooling or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, EfficientFormerModel\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"snap-research/efficientformer-l1-300\")\n>>> model = EfficientFormerModel.from_pretrained(\"snap-research/efficientformer-l1-300\")\n\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 49, 448]\n```", "```py\n( config: EfficientFormerConfig )\n```", "```py\n( pixel_values: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.modeling_outputs.ImageClassifierOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, EfficientFormerForImageClassification\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"snap-research/efficientformer-l1-300\")\n>>> model = EfficientFormerForImageClassification.from_pretrained(\"snap-research/efficientformer-l1-300\")\n\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> # model predicts one of the 1000 ImageNet classes\n>>> predicted_label = logits.argmax(-1).item()\n>>> print(model.config.id2label[predicted_label])\nEgyptian cat\n```", "```py\n( config: EfficientFormerConfig )\n```", "```py\n( pixel_values: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None ) \u2192 export const metadata = 'undefined';transformers.models.efficientformer.modeling_efficientformer.EfficientFormerForImageClassificationWithTeacherOutput or tuple(torch.FloatTensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, EfficientFormerForImageClassificationWithTeacher\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"snap-research/efficientformer-l1-300\")\n>>> model = EfficientFormerForImageClassificationWithTeacher.from_pretrained(\"snap-research/efficientformer-l1-300\")\n\n>>> inputs = image_processor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> # model predicts one of the 1000 ImageNet classes\n>>> predicted_label = logits.argmax(-1).item()\n>>> print(model.config.id2label[predicted_label])\nEgyptian cat\n```", "```py\n( config: EfficientFormerConfig **kwargs )\n```", "```py\n( pixel_values: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None training: bool = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, TFEfficientFormerModel\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"snap-research/efficientformer-l1-300\")\n>>> model = TFEfficientFormerModel.from_pretrained(\"snap-research/efficientformer-l1-300\")\n\n>>> inputs = image_processor(image, return_tensors=\"tf\")\n>>> outputs = model(**inputs)\n\n>>> last_hidden_states = outputs.last_hidden_state\n>>> list(last_hidden_states.shape)\n[1, 49, 448]\n```", "```py\n( config: EfficientFormerConfig )\n```", "```py\n( pixel_values: Optional = None labels: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None training: bool = False ) \u2192 export const metadata = 'undefined';transformers.modeling_tf_outputs.TFImageClassifierOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, TFEfficientFormerForImageClassification\n>>> import tensorflow as tf\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"snap-research/efficientformer-l1-300\")\n>>> model = TFEfficientFormerForImageClassification.from_pretrained(\"snap-research/efficientformer-l1-300\")\n\n>>> inputs = image_processor(image, return_tensors=\"tf\")\n>>> logits = model(**inputs).logits\n\n>>> # model predicts one of the 1000 ImageNet classes\n>>> predicted_label = int(tf.math.argmax(logits, axis=-1))\n>>> print(model.config.id2label[predicted_label])\nLABEL_281\n```", "```py\n( config: EfficientFormerConfig )\n```", "```py\n( pixel_values: Optional = None output_attentions: Optional = None output_hidden_states: Optional = None return_dict: Optional = None training: bool = False ) \u2192 export const metadata = 'undefined';transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerForImageClassificationWithTeacherOutput or tuple(tf.Tensor)\n```", "```py\n>>> from transformers import AutoImageProcessor, TFEfficientFormerForImageClassificationWithTeacher\n>>> import tensorflow as tf\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> image_processor = AutoImageProcessor.from_pretrained(\"snap-research/efficientformer-l1-300\")\n>>> model = TFEfficientFormerForImageClassificationWithTeacher.from_pretrained(\"snap-research/efficientformer-l1-300\")\n\n>>> inputs = image_processor(image, return_tensors=\"tf\")\n>>> logits = model(**inputs).logits\n\n>>> # model predicts one of the 1000 ImageNet classes\n>>> predicted_label = int(tf.math.argmax(logits, axis=-1))\n>>> print(model.config.id2label[predicted_label])\nLABEL_281\n```"]