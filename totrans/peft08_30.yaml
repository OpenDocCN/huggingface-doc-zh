- en: Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¨¡å‹
- en: 'Original text: [https://huggingface.co/docs/peft/package_reference/peft_model](https://huggingface.co/docs/peft/package_reference/peft_model)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/peft/package_reference/peft_model](https://huggingface.co/docs/peft/package_reference/peft_model)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel)
    is the base model class for specifying the base Transformer model and configuration
    to apply a PEFT method to. The base `PeftModel` contains methods for loading and
    saving models from the Hub.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel)æ˜¯æŒ‡å®šåŸºç¡€å˜æ¢å™¨æ¨¡å‹å’Œé…ç½®ä»¥åº”ç”¨PEFTæ–¹æ³•çš„åŸºç¡€æ¨¡å‹ç±»ã€‚åŸºç¡€`PeftModel`åŒ…å«ä»HubåŠ è½½å’Œä¿å­˜æ¨¡å‹çš„æ–¹æ³•ã€‚'
- en: PeftModel
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModel
- en: '### `class peft.PeftModel`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModel`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L88)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L88)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” The base transformer model used for Peft.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” ç”¨äºPeftçš„åŸºç¡€å˜æ¢å™¨æ¨¡å‹ã€‚'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” The configuration of the Peft model.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peftæ¨¡å‹çš„é…ç½®ã€‚'
- en: '`adapter_name` (`str`, *optional*) â€” The name of the adapter, defaults to `"default"`.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, *å¯é€‰*) â€” é€‚é…å™¨çš„åç§°ï¼Œé»˜è®¤ä¸º`"default"`ã€‚'
- en: Base model encompassing various Peft methods.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åŒ…å«å„ç§Peftæ–¹æ³•çš„åŸºç¡€æ¨¡å‹ã€‚
- en: '**Attributes**:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**å±æ€§**ï¼š'
- en: '`base_model` (`torch.nn.Module`) â€” The base transformer model used for Peft.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base_model` (`torch.nn.Module`) â€” ç”¨äºPeftçš„åŸºç¡€å˜æ¢å™¨æ¨¡å‹ã€‚'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” The configuration of the Peft model.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peftæ¨¡å‹çš„é…ç½®ã€‚'
- en: '`modules_to_save` (`list` of `str`) â€” The list of sub-module names to save
    when saving the model.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modules_to_save` (`list` of `str`) â€” ä¿å­˜æ¨¡å‹æ—¶è¦ä¿å­˜çš„å­æ¨¡å—åç§°çš„åˆ—è¡¨ã€‚'
- en: '`prompt_encoder` ([PromptEncoder](/docs/peft/v0.8.2/en/package_reference/p_tuning#peft.PromptEncoder))
    â€” The prompt encoder used for Peft if using [PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_encoder` ([PromptEncoder](/docs/peft/v0.8.2/en/package_reference/p_tuning#peft.PromptEncoder))
    â€” å¦‚æœä½¿ç”¨[PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)ï¼Œåˆ™ç”¨äºPeftçš„æç¤ºç¼–ç å™¨ã€‚'
- en: '`prompt_tokens` (`torch.Tensor`) â€” The virtual prompt tokens used for Peft
    if using [PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_tokens` (`torch.Tensor`) â€” å¦‚æœä½¿ç”¨[PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)ï¼Œåˆ™ç”¨äºPeftçš„è™šæ‹Ÿæç¤ºæ ‡è®°ã€‚'
- en: '`transformer_backbone_name` (`str`) â€” The name of the transformer backbone
    in the base model if using [PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_backbone_name` (`str`) â€” å¦‚æœä½¿ç”¨[PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)ï¼Œåˆ™æ˜¯åŸºç¡€æ¨¡å‹ä¸­å˜æ¢å™¨ä¸»å¹²çš„åç§°ã€‚'
- en: '`word_embeddings` (`torch.nn.Embedding`) â€” The word embeddings of the transformer
    backbone in the base model if using [PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`word_embeddings` (`torch.nn.Embedding`) â€” å¦‚æœä½¿ç”¨[PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)ï¼Œåˆ™æ˜¯åŸºç¡€æ¨¡å‹ä¸­å˜æ¢å™¨ä¸»å¹²çš„è¯åµŒå…¥ã€‚'
- en: '#### `add_adapter`'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L587)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L587)'
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`adapter_name` (`str`) â€” The name of the adapter to be added.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`) â€” è¦æ·»åŠ çš„é€‚é…å™¨çš„åç§°ã€‚'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” The configuration of the adapter to be added.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” è¦æ·»åŠ çš„é€‚é…å™¨çš„é…ç½®ã€‚'
- en: Add an adapter to the model based on the passed configuration.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ä¼ é€’çš„é…ç½®å‘æ¨¡å‹æ·»åŠ é€‚é…å™¨ã€‚
- en: The name for the new adapter should be unique.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ–°é€‚é…å™¨çš„åç§°åº”è¯¥æ˜¯å”¯ä¸€çš„ã€‚
- en: The new adapter is not automatically set as the active adapter. Use [PeftModel.set_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.set_adapter)
    to set the active adapter.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ–°é€‚é…å™¨ä¸ä¼šè‡ªåŠ¨è®¾ç½®ä¸ºæ´»åŠ¨é€‚é…å™¨ã€‚ä½¿ç”¨[PeftModel.set_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.set_adapter)æ¥è®¾ç½®æ´»åŠ¨é€‚é…å™¨ã€‚
- en: '#### `create_or_update_model_card`'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_or_update_model_card`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L777)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L777)'
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Updates or create model card to include information about peft:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´æ–°æˆ–åˆ›å»ºæ¨¡å‹å¡ä»¥åŒ…å«æœ‰å…³peftçš„ä¿¡æ¯ï¼š
- en: Adds `peft` library tag
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ·»åŠ `peft`åº“æ ‡ç­¾
- en: Adds peft version
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ·»åŠ peftç‰ˆæœ¬
- en: Adds base model info
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ·»åŠ åŸºç¡€æ¨¡å‹ä¿¡æ¯
- en: Adds quantization information if it was used
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœä½¿ç”¨äº†é‡åŒ–ä¿¡æ¯ï¼Œåˆ™æ·»åŠ é‡åŒ–ä¿¡æ¯
- en: '#### `disable_adapter`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L547)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L547)'
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Context manager that disables the adapter module. Use this to run inference
    on the base model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨é€‚é…å™¨æ¨¡å—çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚ä½¿ç”¨æ­¤åŠŸèƒ½åœ¨åŸºç¡€æ¨¡å‹ä¸Šè¿è¡Œæ¨ç†ã€‚
- en: 'Example:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `forward`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L533)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L533)'
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Forward pass of the model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„å‰å‘ä¼ é€’ã€‚
- en: '#### `from_pretrained`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L283)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L283)'
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` (`torch.nn.Module`) â€” The model to be adapted. For ğŸ¤— Transformers models,
    the model should be initialized with the [from_pretrained](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained).'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) â€” è¦é€‚é…çš„æ¨¡å‹ã€‚å¯¹äºğŸ¤—å˜æ¢å™¨æ¨¡å‹ï¼Œæ¨¡å‹åº”è¯¥ä½¿ç”¨[from_pretrained](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)è¿›è¡Œåˆå§‹åŒ–ã€‚'
- en: '`model_id` (`str` or `os.PathLike`) â€” The name of the PEFT configuration to
    use. Can be either:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_id` (`str`æˆ–`os.PathLike`) â€” è¦ä½¿ç”¨çš„PEFTé…ç½®çš„åç§°ã€‚å¯ä»¥æ˜¯ï¼š'
- en: A string, the `model id` of a PEFT configuration hosted inside a model repo
    on the Hugging Face Hub.
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a directory containing a PEFT configuration file saved using the `save_pretrained`
    method (`./my_peft_config_directory/`).
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`adapter_name` (`str`, *optional*, defaults to `"default"`) â€” The name of the
    adapter to be loaded. This is useful for loading multiple adapters.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_trainable` (`bool`, *optional*, defaults to `False`) â€” Whether the adapter
    should be trainable or not. If `False`, the adapter will be frozen and can only
    be used for inference.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig),
    *optional*) â€” The configuration object to use instead of an automatically loaded
    configuration. This configuration object is mutually exclusive with `model_id`
    and `kwargs`. This is useful when configuration is already loaded before calling
    `from_pretrained`. kwargs â€” (`optional`): Additional keyword arguments passed
    along to the specific PEFT configuration class.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate a PEFT model from a pretrained model and loaded PEFT weights.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Note that the passed `model` may be modified inplace.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_base_model`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L577)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Returns the base model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_nb_trainable_parameters`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L492)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Returns the number of trainable parameters and the number of all parameters
    in the model.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_prompt`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L446)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Returns the virtual prompts to use for Peft. Only applicable when using a prompt
    learning method.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_prompt_embedding_to_save`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L427)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Returns the prompt embedding to save when saving the model. Only applicable
    when using a prompt learning method.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '#### `load_adapter`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L652)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '`adapter_name` (`str`) â€” The name of the adapter to be added.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” The configuration of the adapter to be added.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_trainable` (`bool`, *optional*, defaults to `False`) â€” Whether the adapter
    should be trainable or not. If `False`, the adapter will be frozen and can only
    be used for inference. kwargs â€” (`optional`): Additional arguments to modify the
    way the adapter is loaded, e.g. the token for Hugging Face Hub.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load a trained adapter into the model.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: The name for the new adapter should be unique.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: The new adapter is not automatically set as the active adapter. Use [PeftModel.set_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.set_adapter)
    to set the active adapter.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '#### `print_trainable_parameters`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L516)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Prints the number of trainable parameters in the model.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '#### `save_pretrained`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L161)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '`save_directory` (`str`) â€” Directory where the adapter model and configuration
    files will be saved (will be created if it does not exist).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safe_serialization` (`bool`, *optional*) â€” Whether to save the adapter files
    in safetensors format, defaults to `True`.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`selected_adapters` (`List[str]`, *optional*) â€” A list of adapters to be saved.
    If `None`, will default to all adapters.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save_embedding_layers` (`Union[bool, str]`, *optional*, defaults to `"auto"`)
    â€” If `True`, save the embedding layers in addition to adapter weights. If `auto`,
    checks the common embedding layers `peft.utils.other.EMBEDDING_LAYER_NAMES` in
    configâ€™s `target_modules` when available. and automatically sets the boolean flag.
    This only works for ğŸ¤— transformers models.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_main_process` (`bool`, *optional*) â€” Whether the process calling this is
    the main process or not. Will default to `True`. Will not save the checkpoint
    if not on the main process, which is important for multi device setups (e.g. DDP).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process` (`bool`, *å¯é€‰*) â€” è°ƒç”¨æ­¤å‡½æ•°çš„è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ã€‚é»˜è®¤ä¸º `True`ã€‚å¦‚æœä¸æ˜¯ä¸»è¿›ç¨‹ï¼Œåˆ™ä¸ä¼šä¿å­˜æ£€æŸ¥ç‚¹ï¼Œè¿™å¯¹äºå¤šè®¾å¤‡è®¾ç½®ï¼ˆä¾‹å¦‚
    DDPï¼‰å¾ˆé‡è¦ã€‚'
- en: '`kwargs` (additional keyword arguments, *optional*) â€” Additional keyword arguments
    passed along to the `push_to_hub` method.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`ï¼ˆé¢å¤–çš„å…³é”®å­—å‚æ•°ï¼Œ*å¯é€‰*ï¼‰ â€” ä¼ é€’ç»™ `push_to_hub` æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚'
- en: This function saves the adapter model and the adapter configuration files to
    a directory, so that it can be reloaded using the [PeftModel.from_pretrained()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.from_pretrained)
    class method, and also used by the `PeftModel.push_to_hub()` method.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å‡½æ•°å°†é€‚é…å™¨æ¨¡å‹å’Œé€‚é…å™¨é…ç½®æ–‡ä»¶ä¿å­˜åˆ°ä¸€ä¸ªç›®å½•ä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä½¿ç”¨ [PeftModel.from_pretrained()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.from_pretrained)
    ç±»æ–¹æ³•é‡æ–°åŠ è½½ï¼Œå¹¶ä¸”ä¹Ÿå¯ä»¥è¢« `PeftModel.push_to_hub()` æ–¹æ³•ä½¿ç”¨ã€‚
- en: '#### `set_adapter`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L743)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L743)'
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`adapter_name` (`str`) â€” The name of the adapter to be set as active. The adapter
    must be loaded first.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`) â€” è¦è®¾ç½®ä¸ºæ´»åŠ¨çš„é€‚é…å™¨çš„åç§°ã€‚å¿…é¡»å…ˆåŠ è½½é€‚é…å™¨ã€‚'
- en: Sets the active adapter.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ç½®æ´»åŠ¨é€‚é…å™¨ã€‚
- en: Only one adapter can be active at a time.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ¬¡åªèƒ½æœ‰ä¸€ä¸ªé€‚é…å™¨å¤„äºæ´»åŠ¨çŠ¶æ€ã€‚
- en: Additionally, this function will set the specified adapter to trainable (i.e.,
    requires_grad=True). If this is not desired, use the following code.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæ­¤å‡½æ•°å°†è®¾ç½®æŒ‡å®šçš„é€‚é…å™¨ä¸ºå¯è®­ç»ƒçš„ï¼ˆå³ï¼Œrequires_grad=Trueï¼‰ã€‚å¦‚æœä¸éœ€è¦æ­¤åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹ä»£ç ã€‚
- en: '[PRE15]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: PeftModelForSequenceClassification
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForSequenceClassification
- en: A `PeftModel` for sequence classification tasks.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºåºåˆ—åˆ†ç±»ä»»åŠ¡çš„ `PeftModel`ã€‚
- en: '### `class peft.PeftModelForSequenceClassification`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L830)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L830)'
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” Base transformer model.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” åŸºç¡€å˜æ¢å™¨æ¨¡å‹ã€‚'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft config.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft é…ç½®ã€‚'
- en: Peft model for sequence classification tasks.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºåºåˆ—åˆ†ç±»ä»»åŠ¡çš„ Peft æ¨¡å‹ã€‚
- en: '**Attributes**:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**å±æ€§**:'
- en: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    â€” The configuration object of the base model.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    â€” åŸºç¡€æ¨¡å‹çš„é…ç½®å¯¹è±¡ã€‚'
- en: '`cls_layer_name` (`str`) â€” The name of the classification layer.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_layer_name` (`str`) â€” åˆ†ç±»å±‚çš„åç§°ã€‚'
- en: 'Example:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç¤ºä¾‹:'
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: PeftModelForTokenClassification
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForTokenClassification
- en: A `PeftModel` for token classification tasks.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºæ ‡è®°åˆ†ç±»ä»»åŠ¡çš„ `PeftModel`ã€‚
- en: '### `class peft.PeftModelForTokenClassification`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForTokenClassification`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1460)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1460)'
- en: '[PRE18]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” Base transformer model.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” åŸºç¡€å˜æ¢å™¨æ¨¡å‹ã€‚'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft config.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft é…ç½®ã€‚'
- en: Peft model for token classification tasks.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºæ ‡è®°åˆ†ç±»ä»»åŠ¡çš„ Peft æ¨¡å‹ã€‚
- en: '**Attributes**:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**å±æ€§**:'
- en: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    â€” The configuration object of the base model.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    â€” åŸºç¡€æ¨¡å‹çš„é…ç½®å¯¹è±¡ã€‚'
- en: '`cls_layer_name` (`str`) â€” The name of the classification layer.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_layer_name` (`str`) â€” åˆ†ç±»å±‚çš„åç§°ã€‚'
- en: 'Example:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç¤ºä¾‹:'
- en: '[PRE19]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: PeftModelForCausalLM
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForCausalLM
- en: A `PeftModel` for causal language modeling.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºå› æœè¯­è¨€å»ºæ¨¡çš„ `PeftModel`ã€‚
- en: '### `class peft.PeftModelForCausalLM`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForCausalLM`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1021)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1021)'
- en: '[PRE20]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” Base transformer model.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” åŸºç¡€å˜æ¢å™¨æ¨¡å‹ã€‚'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft config.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft é…ç½®ã€‚'
- en: Peft model for causal language modeling.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºå› æœè¯­è¨€å»ºæ¨¡çš„ Peft æ¨¡å‹ã€‚
- en: 'Example:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç¤ºä¾‹:'
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: PeftModelForSeq2SeqLM
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForSeq2SeqLM
- en: A `PeftModel` for sequence-to-sequence language modeling.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºåºåˆ—åˆ°åºåˆ—è¯­è¨€å»ºæ¨¡çš„ `PeftModel`ã€‚
- en: '### `class peft.PeftModelForSeq2SeqLM`'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForSeq2SeqLM`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1211)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1211)'
- en: '[PRE22]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” Base transformer model.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” åŸºç¡€å˜æ¢å™¨æ¨¡å‹ã€‚'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft config.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft é…ç½®ã€‚'
- en: Peft model for sequence-to-sequence language modeling.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºåºåˆ—åˆ°åºåˆ—è¯­è¨€å»ºæ¨¡çš„ Peft æ¨¡å‹ã€‚
- en: 'Example:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç¤ºä¾‹:'
- en: '[PRE23]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: PeftModelForQuestionAnswering
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForQuestionAnswering
- en: A `PeftModel` for question answering.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºé—®ç­”çš„ `PeftModel`ã€‚
- en: '### `class peft.PeftModelForQuestionAnswering`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1635)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1635)'
- en: '[PRE24]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” Base transformer model.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” åŸºç¡€å˜æ¢å™¨æ¨¡å‹ã€‚'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft config.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Pefté…ç½®ã€‚'
- en: Peft model for extractive question answering.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºæŠ½å–å¼é—®ç­”çš„Peftæ¨¡å‹ã€‚
- en: '**Attributes**:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**å±æ€§**ï¼š'
- en: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    â€” The configuration object of the base model.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    â€” åŸºç¡€æ¨¡å‹çš„é…ç½®å¯¹è±¡ã€‚'
- en: '`cls_layer_name` (`str`) â€” The name of the classification layer.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_layer_name` (`str`) â€” åˆ†ç±»å±‚çš„åç§°ã€‚'
- en: 'Example:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE25]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: PeftModelForFeatureExtraction
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForFeatureExtraction
- en: A `PeftModel` for getting extracting features/embeddings from transformer models.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºä»å˜æ¢å™¨æ¨¡å‹ä¸­æå–ç‰¹å¾/åµŒå…¥çš„`PeftModel`ã€‚
- en: '### `class peft.PeftModelForFeatureExtraction`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForFeatureExtraction`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1830)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1830)'
- en: '[PRE26]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” Base transformer model.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” åŸºç¡€å˜æ¢å™¨æ¨¡å‹ã€‚'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Peft config.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Pefté…ç½®ã€‚'
- en: Peft model for extracting features/embeddings from transformer models
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºä»å˜æ¢å™¨æ¨¡å‹ä¸­æå–ç‰¹å¾/åµŒå…¥çš„Peftæ¨¡å‹ã€‚
- en: '**Attributes**:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**å±æ€§**ï¼š'
- en: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    â€” The configuration object of the base model.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    â€” åŸºç¡€æ¨¡å‹çš„é…ç½®å¯¹è±¡ã€‚'
- en: 'Example:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE27]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: PeftMixedModel
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftMixedModel
- en: A `PeftModel` for mixing different adapter types (e.g. LoRA and LoHa).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºæ··åˆä¸åŒé€‚é…å™¨ç±»å‹ï¼ˆä¾‹å¦‚LoRAå’ŒLoHaï¼‰çš„`PeftModel`ã€‚
- en: '### `class peft.PeftMixedModel`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftMixedModel`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L83)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L83)'
- en: '[PRE28]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` (`torch.nn.Module`) â€” The model to be tuned.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) â€” è¦è°ƒæ•´çš„æ¨¡å‹ã€‚'
- en: '`config` (`PeftConfig`) â€” The config of the model to be tuned. The adapter
    type must be compatible.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` (`PeftConfig`) â€” è¦è°ƒæ•´çš„æ¨¡å‹çš„é…ç½®ã€‚é€‚é…å™¨ç±»å‹å¿…é¡»å…¼å®¹ã€‚'
- en: '`adapter_name` (`str`, `optional`, defaults to `"default"`) â€” The name of the
    first adapter.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, `å¯é€‰`, é»˜è®¤ä¸º`"default"`) â€” ç¬¬ä¸€ä¸ªé€‚é…å™¨çš„åç§°ã€‚'
- en: PeftMixedModel for loading mixing different types of adapters for inference.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºåŠ è½½ä¸åŒç±»å‹é€‚é…å™¨è¿›è¡Œæ¨æ–­çš„PeftMixedModelã€‚
- en: This class does not support loading/saving, and it shouldnâ€™t usually be initialized
    directly. Instead, use `get_peft_model` with the argument `mixed=True`.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤ç±»ä¸æ”¯æŒåŠ è½½/ä¿å­˜ï¼Œé€šå¸¸ä¸åº”ç›´æ¥åˆå§‹åŒ–ã€‚è€Œæ˜¯ä½¿ç”¨`get_peft_model`å¹¶ä½¿ç”¨å‚æ•°`mixed=True`ã€‚
- en: Read the [Mixed adapter types](https://huggingface.co/docs/peft/en/developer_guides/mixed_models)
    guide to learn more about using different adapter types.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: é˜…è¯»[Mixed adapter types](https://huggingface.co/docs/peft/en/developer_guides/mixed_models)æŒ‡å—ï¼Œäº†è§£æ›´å¤šå…³äºä½¿ç”¨ä¸åŒé€‚é…å™¨ç±»å‹çš„ä¿¡æ¯ã€‚
- en: 'Example:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ï¼š
- en: '[PRE29]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '#### `disable_adapter`'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L203)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L203)'
- en: '[PRE30]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Disables the adapter module.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦ç”¨é€‚é…å™¨æ¨¡å—ã€‚
- en: '#### `forward`'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L191)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L191)'
- en: '[PRE31]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Forward pass of the model.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„å‰å‘ä¼ é€’ã€‚
- en: '#### `from_pretrained`'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L329)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L329)'
- en: '[PRE32]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` (`nn.Module`) â€” The model to be adapted.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`nn.Module`) â€” è¦é€‚åº”çš„æ¨¡å‹ã€‚'
- en: '`model_id` (`str` or `os.PathLike`) â€” The name of the PEFT configuration to
    use. Can be either:'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_id` (`str`æˆ–`os.PathLike`) â€” è¦ä½¿ç”¨çš„PEFTé…ç½®çš„åç§°ã€‚å¯ä»¥æ˜¯ï¼š'
- en: A string, the `model id` of a PEFT configuration hosted inside a model repo
    on the Hugging Face Hub.
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒPEFTé…ç½®çš„`æ¨¡å‹id`ï¼Œæ‰˜ç®¡åœ¨Hugging Face Hubä¸Šçš„æ¨¡å‹å­˜å‚¨åº“ä¸­ã€‚
- en: A path to a directory containing a PEFT configuration file saved using the `save_pretrained`
    method (`./my_peft_config_directory/`).
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŒ…å«ä½¿ç”¨`save_pretrained`æ–¹æ³•ä¿å­˜çš„PEFTé…ç½®æ–‡ä»¶çš„ç›®å½•è·¯å¾„ï¼ˆ`./my_peft_config_directory/`ï¼‰ã€‚
- en: '`adapter_name` (`str`, *optional*, defaults to `"default"`) â€” The name of the
    adapter to be loaded. This is useful for loading multiple adapters.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, *å¯é€‰*, é»˜è®¤ä¸º`"default"`) â€” è¦åŠ è½½çš„é€‚é…å™¨çš„åç§°ã€‚è¿™å¯¹äºåŠ è½½å¤šä¸ªé€‚é…å™¨å¾ˆæœ‰ç”¨ã€‚'
- en: '`is_trainable` (`bool`, *optional*, defaults to `False`) â€” Whether the adapter
    should be trainable or not. If `False`, the adapter will be frozen and use for
    inference'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_trainable` (`bool`, *å¯é€‰*, é»˜è®¤ä¸º`False`) â€” é€‚é…å™¨æ˜¯å¦å¯è®­ç»ƒã€‚å¦‚æœä¸º`False`ï¼Œé€‚é…å™¨å°†è¢«å†»ç»“å¹¶ç”¨äºæ¨æ–­ã€‚'
- en: '`config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig),
    *optional*) â€” The configuration object to use instead of an automatically loaded
    configuration. This configuration object is mutually exclusive with `model_id`
    and `kwargs`. This is useful when configuration is already loaded before calling
    `from_pretrained`. kwargs â€” (`optional`): Additional keyword arguments passed
    along to the specific PEFT configuration class.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig),
    *å¯é€‰*) â€” è¦ä½¿ç”¨çš„é…ç½®å¯¹è±¡ï¼Œè€Œä¸æ˜¯è‡ªåŠ¨åŠ è½½çš„é…ç½®ã€‚æ­¤é…ç½®å¯¹è±¡ä¸`model_id`å’Œ`kwargs`äº’æ–¥ã€‚åœ¨è°ƒç”¨`from_pretrained`ä¹‹å‰å·²åŠ è½½é…ç½®æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚kwargs
    â€” (`å¯é€‰`): ä¼ é€’ç»™ç‰¹å®šPEFTé…ç½®ç±»çš„å…¶ä»–å…³é”®å­—å‚æ•°ã€‚'
- en: Instantiate a PEFT mixed model from a pretrained model and loaded PEFT weights.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é¢„è®­ç»ƒæ¨¡å‹å’ŒåŠ è½½çš„PEFTæƒé‡å®ä¾‹åŒ–ä¸€ä¸ªPEFTæ··åˆæ¨¡å‹ã€‚
- en: Note that the passed `model` may be modified inplace.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œä¼ é€’çš„ `model` å¯èƒ½ä¼šè¢«åŸåœ°ä¿®æ”¹ã€‚
- en: '#### `generate`'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L197)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L197)'
- en: '[PRE33]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Generate output.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆè¾“å‡ºã€‚
- en: '#### `get_nb_trainable_parameters`'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_nb_trainable_parameters`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L146)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L146)'
- en: '[PRE34]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Returns the number of trainable parameters and number of all parameters in the
    model.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: è¿”å›æ¨¡å‹ä¸­å¯è®­ç»ƒå‚æ•°çš„æ•°é‡å’Œæ‰€æœ‰å‚æ•°çš„æ•°é‡ã€‚
- en: '#### `merge_and_unload`'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `merge_and_unload`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L283)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L283)'
- en: '[PRE35]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`progressbar` (`bool`) â€” whether to show a progressbar indicating the unload
    and merge process'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`progressbar` (`bool`) â€” æ˜¯å¦æ˜¾ç¤ºæŒ‡ç¤ºå¸è½½å’Œåˆå¹¶è¿‡ç¨‹çš„è¿›åº¦æ¡'
- en: '`safe_merge` (`bool`) â€” whether to activate the safe merging check to check
    if there is any potential Nan in the adapter weights'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_merge` (`bool`) â€” æ˜¯å¦æ¿€æ´»å®‰å…¨åˆå¹¶æ£€æŸ¥ä»¥æ£€æŸ¥é€‚é…å™¨æƒé‡ä¸­æ˜¯å¦å­˜åœ¨æ½œåœ¨çš„ NaN'
- en: '`adapter_names` (`List[str]`, *optional*) â€” The list of adapter names that
    should be merged. If None, all active adapters will be merged. Defaults to `None`.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_names` (`List[str]`, *optional*) â€” åº”åˆå¹¶çš„é€‚é…å™¨åç§°åˆ—è¡¨ã€‚å¦‚æœä¸º Noneï¼Œåˆ™å°†åˆå¹¶æ‰€æœ‰æ´»åŠ¨é€‚é…å™¨ã€‚é»˜è®¤ä¸º
    `None`ã€‚'
- en: This method merges the adapter layers into the base model. This is needed if
    someone wants to use the base model as a standalone model.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ–¹æ³•å°†é€‚é…å™¨å±‚åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹ä¸­ã€‚å¦‚æœæœ‰äººæƒ³è¦å°†åŸºç¡€æ¨¡å‹ç”¨ä½œç‹¬ç«‹æ¨¡å‹ï¼Œåˆ™éœ€è¦è¿™æ ·åšã€‚
- en: '#### `print_trainable_parameters`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `print_trainable_parameters`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L171)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L171)'
- en: '[PRE36]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Prints the number of trainable parameters in the model.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰“å°æ¨¡å‹ä¸­å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚
- en: '#### `set_adapter`'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L237)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L237)'
- en: '[PRE37]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Parameters
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`adapter_name` (`str` or `List[str]`) â€” The name of the adapter(s) to be activated.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str` æˆ– `List[str]`) â€” è¦æ¿€æ´»çš„é€‚é…å™¨çš„åç§°ã€‚'
- en: Sets the active adapter(s) for the model.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ç½®æ¨¡å‹çš„æ´»åŠ¨é€‚é…å™¨ã€‚
- en: Note that the order in which the adapters are applied during the forward pass
    may not be the same as the order in which they are passed to this function. Instead,
    the order during the forward pass is determined by the order in which the adapters
    were loaded into the model. The active adapters only determine which adapters
    are active during the forward pass, but not the order in which they are applied.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œåœ¨å‰å‘ä¼ é€’æœŸé—´åº”ç”¨é€‚é…å™¨çš„é¡ºåºå¯èƒ½ä¸å°†é€‚é…å™¨ä¼ é€’ç»™æ­¤å‡½æ•°çš„é¡ºåºä¸åŒã€‚ç›¸åï¼Œåœ¨å‰å‘ä¼ é€’æœŸé—´çš„é¡ºåºç”±é€‚é…å™¨åŠ è½½åˆ°æ¨¡å‹ä¸­çš„é¡ºåºç¡®å®šã€‚æ´»åŠ¨é€‚é…å™¨ä»…ç¡®å®šåœ¨å‰å‘ä¼ é€’æœŸé—´å“ªäº›é€‚é…å™¨å¤„äºæ´»åŠ¨çŠ¶æ€ï¼Œä½†ä¸ç¡®å®šå®ƒä»¬è¢«åº”ç”¨çš„é¡ºåºã€‚
- en: Additionally, this function will set the specified adapters to trainable (i.e.,
    requires_grad=True). If this is not desired, use the following code.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæ­¤å‡½æ•°å°†æŒ‡å®šçš„é€‚é…å™¨è®¾ç½®ä¸ºå¯è®­ç»ƒï¼ˆå³ï¼Œrequires_grad=Trueï¼‰ã€‚å¦‚æœä¸éœ€è¦è¿™æ ·åšï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹ä»£ç ã€‚
- en: '[PRE38]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '#### `unload`'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `unload`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L300)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L300)'
- en: '[PRE39]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Gets back the base model by removing all the adapter modules without merging.
    This gives back the original base model.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åˆ é™¤æ‰€æœ‰é€‚é…å™¨æ¨¡å—è€Œä¸è¿›è¡Œåˆå¹¶æ¥è·å–åŸºç¡€æ¨¡å‹ã€‚è¿™å°†è¿˜åŸåŸå§‹åŸºç¡€æ¨¡å‹ã€‚
- en: Utilities
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®ç”¨å·¥å…·
- en: '#### `peft.cast_mixed_precision_params`'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.cast_mixed_precision_params`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/other.py#L523)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/other.py#L523)'
- en: '[PRE40]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Parameters
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` (`torch.nn.Module`) â€” The model to cast the non-trainable parameters
    of.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) â€” è¦è½¬æ¢ä¸å¯è®­ç»ƒå‚æ•°çš„æ¨¡å‹ã€‚'
- en: '`dtype` (`torch.dtype`) â€” The dtype to cast the non-trainable parameters to.
    The `dtype` can be `torch.float16` or'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`torch.dtype`) â€” è¦å°†ä¸å¯è®­ç»ƒå‚æ•°è½¬æ¢ä¸ºçš„ dtypeã€‚`dtype` å¯ä»¥æ˜¯ `torch.float16` æˆ–'
- en: Cast all non-trainable parameters of the model to the given `dtype`. The `dtype`
    can be `torch.float16` or `torch.bfloat16` as per the mixed-precision training
    you are performing. The trainable parameters are cast to full precision. This
    is meant to reduce the GPU memory usage when using PEFT methods by using half-precision
    dtype for non-trainable parameters. Having the trainable parameters in full-precision
    preserves training stability when using automatic mixed-precision training.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¨¡å‹çš„æ‰€æœ‰ä¸å¯è®­ç»ƒå‚æ•°è½¬æ¢ä¸ºç»™å®šçš„ `dtype`ã€‚`dtype` å¯ä»¥æ˜¯ `torch.float16` æˆ– `torch.bfloat16`ï¼Œæ ¹æ®æ‚¨æ­£åœ¨æ‰§è¡Œçš„æ··åˆç²¾åº¦è®­ç»ƒè€Œå®šã€‚å¯è®­ç»ƒå‚æ•°è½¬æ¢ä¸ºå…¨ç²¾åº¦ã€‚è¿™æ—¨åœ¨é€šè¿‡ä½¿ç”¨åŠç²¾åº¦
    dtype å‡å°‘ä½¿ç”¨ PEFT æ–¹æ³•æ—¶çš„ GPU å†…å­˜ä½¿ç”¨é‡ã€‚å°†å¯è®­ç»ƒå‚æ•°ä¿ç•™ä¸ºå…¨ç²¾åº¦å¯åœ¨ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒæ—¶ä¿æŒè®­ç»ƒç¨³å®šæ€§ã€‚
- en: '`torch.bfloat16` as per the mixed-precision training you are performing.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.bfloat16` æ ¹æ®æ‚¨æ­£åœ¨æ‰§è¡Œçš„æ··åˆç²¾åº¦è®­ç»ƒã€‚'
- en: '#### `peft.get_peft_model`'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.get_peft_model`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mapping.py#L106)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mapping.py#L106)'
- en: '[PRE41]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Parameters
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` ([transformers.PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” Model to be wrapped.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([transformers.PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    â€” Model to be wrapped.'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” Configuration object containing the parameters of the Peft model.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    â€” åŒ…å« Peft æ¨¡å‹å‚æ•°çš„é…ç½®å¯¹è±¡ã€‚'
- en: '`adapter_name` (`str`, `optional`, defaults to `"default"`) â€” The name of the
    adapter to be injected, if not provided, the default adapter name is used (â€œdefaultâ€).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, `optional`, é»˜è®¤ä¸º `"default"`) â€” è¦æ³¨å…¥çš„é€‚é…å™¨çš„åç§°ï¼Œå¦‚æœæœªæä¾›ï¼Œåˆ™ä½¿ç”¨é»˜è®¤é€‚é…å™¨åç§°ï¼ˆâ€œdefaultâ€ï¼‰ã€‚'
- en: '`mixed` (`bool`, `optional`, defaults to `False`) â€” Whether to allow mixing
    different (compatible) adapter types.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mixed` (`bool`, `optional`, é»˜è®¤ä¸º `False`) â€” æ˜¯å¦å…è®¸æ··åˆä¸åŒï¼ˆå…¼å®¹çš„ï¼‰é€‚é…å™¨ç±»å‹ã€‚'
- en: Returns a Peft model object from a model and a config.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ¨¡å‹å’Œé…ç½®è¿”å›ä¸€ä¸ª Peft æ¨¡å‹å¯¹è±¡ã€‚
- en: '#### `peft.inject_adapter_in_model`'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.inject_adapter_in_model`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mapping.py#L139)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mapping.py#L139)'
- en: '[PRE42]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Parameters
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`peft_config` (`PeftConfig`) â€” Configuration object containing the parameters
    of the Peft model.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config`ï¼ˆ`PeftConfig`ï¼‰- åŒ…å«Peftæ¨¡å‹å‚æ•°çš„é…ç½®å¯¹è±¡ã€‚'
- en: '`model` (`torch.nn.Module`) â€” The input model where the adapter will be injected.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`ï¼ˆ`torch.nn.Module`ï¼‰- è¦æ³¨å…¥é€‚é…å™¨çš„è¾“å…¥æ¨¡å‹ã€‚'
- en: '`adapter_name` (`str`, `optional`, defaults to `"default"`) â€” The name of the
    adapter to be injected, if not provided, the default adapter name is used (â€œdefaultâ€).'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name`ï¼ˆ`str`ï¼Œ`å¯é€‰`ï¼Œé»˜è®¤ä¸º`"default"`ï¼‰- è¦æ³¨å…¥çš„é€‚é…å™¨çš„åç§°ï¼Œå¦‚æœæœªæä¾›ï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„é€‚é…å™¨åç§°ï¼ˆâ€œdefaultâ€ï¼‰ã€‚'
- en: A simple API to create and inject adapter in-place into a model. Currently the
    API does not support prompt learning methods and adaption prompt. Make sure to
    have the correct `target_names` set in the `peft_config` object. The API calls
    `get_peft_model` under the hood but would be restricted only to non-prompt learning
    methods.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç®€å•çš„APIï¼Œç”¨äºåœ¨æ¨¡å‹ä¸­åˆ›å»ºå¹¶å°±åœ°æ³¨å…¥é€‚é…å™¨ã€‚ç›®å‰ï¼Œè¯¥APIä¸æ”¯æŒæç¤ºå­¦ä¹ æ–¹æ³•å’Œé€‚åº”æç¤ºã€‚è¯·ç¡®ä¿åœ¨`peft_config`å¯¹è±¡ä¸­è®¾ç½®äº†æ­£ç¡®çš„`target_names`ã€‚APIåœ¨åº•å±‚è°ƒç”¨`get_peft_model`ï¼Œä½†ä»…é™äºéæç¤ºå­¦ä¹ æ–¹æ³•ã€‚
- en: '#### `peft.get_peft_model_state_dict`'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.get_peft_model_state_dict`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/save_and_load.py#L46)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/save_and_load.py#L46)'
- en: '[PRE43]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Parameters
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` ([PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel))
    â€” The Peft model. When using torch.nn.DistributedDataParallel, DeepSpeed or FSDP,
    the model should be the underlying model/unwrapped model (i.e. model.module).'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`ï¼ˆ[PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel)ï¼‰-
    Peftæ¨¡å‹ã€‚åœ¨ä½¿ç”¨torch.nn.DistributedDataParallelã€DeepSpeedæˆ–FSDPæ—¶ï¼Œæ¨¡å‹åº”ä¸ºåŸºç¡€æ¨¡å‹/å–æ¶ˆåŒ…è£…æ¨¡å‹ï¼ˆå³model.moduleï¼‰ã€‚'
- en: '`state_dict` (`dict`, *optional*, defaults to `None`) â€” The state dict of the
    model. If not provided, the state dict of the passed model will be used.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`None`ï¼‰- æ¨¡å‹çš„çŠ¶æ€å­—å…¸ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™å°†ä½¿ç”¨ä¼ é€’æ¨¡å‹çš„çŠ¶æ€å­—å…¸ã€‚'
- en: '`adapter_name` (`str`, *optional*, defaults to `"default"`) â€” The name of the
    adapter whose state dict should be returned.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name`ï¼ˆ`str`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`"default"`ï¼‰- åº”è¿”å›å…¶çŠ¶æ€å­—å…¸çš„é€‚é…å™¨çš„åç§°ã€‚'
- en: '`unwrap_compiled` (`bool`, *optional*, defaults to `False`) â€” Whether to unwrap
    the model if torch.compile was used.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unwrap_compiled`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`False`ï¼‰- æ˜¯å¦åœ¨ä½¿ç”¨torch.compileæ—¶å–æ¶ˆåŒ…è£…æ¨¡å‹ã€‚'
- en: '`save_embedding_layers` (`Union[bool, str]`, , *optional*, defaults to `auto`)
    â€” If `True`, save the embedding layers in addition to adapter weights. If `auto`,
    checks the common embedding layers `peft.utils.other.EMBEDDING_LAYER_NAMES` in
    configâ€™s `target_modules` when available. Based on it sets the boolean flag. This
    only works for ğŸ¤— transformers models.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_embedding_layers`ï¼ˆ`Union[bool, str]`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`auto`ï¼‰- å¦‚æœä¸º`True`ï¼Œåˆ™ä¿å­˜åµŒå…¥å±‚ä»¥åŠé€‚é…å™¨æƒé‡ã€‚å¦‚æœä¸º`auto`ï¼Œåˆ™åœ¨é…ç½®çš„`target_modules`ä¸­æ£€æŸ¥å¸¸è§çš„åµŒå…¥å±‚`peft.utils.other.EMBEDDING_LAYER_NAMES`ï¼Œå¹¶æ ¹æ®å…¶è®¾ç½®å¸ƒå°”æ ‡å¿—ã€‚è¿™ä»…é€‚ç”¨äºğŸ¤—
    transformersæ¨¡å‹ã€‚'
- en: Get the state dict of the Peft model.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: è·å–Peftæ¨¡å‹çš„çŠ¶æ€å­—å…¸ã€‚
- en: '#### `peft.prepare_model_for_kbit_training`'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.prepare_model_for_kbit_training`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/other.py#L77)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '[<æ¥æº>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/other.py#L77)'
- en: '[PRE44]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Parameters
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°
- en: '`model` (`transformers.PreTrainedModel`) â€” The loaded model from `transformers`'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`ï¼ˆ`transformers.PreTrainedModel`ï¼‰- ä»`transformers`åŠ è½½çš„æ¨¡å‹'
- en: '`use_gradient_checkpointing` (`bool`, *optional*, defaults to `True`) â€” If
    True, use gradient checkpointing to save memory at the expense of slower backward
    pass.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_gradient_checkpointing`ï¼ˆ`bool`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`True`ï¼‰- å¦‚æœä¸ºTrueï¼Œåˆ™ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜ï¼Œä½†ä¼šå¯¼è‡´åå‘ä¼ æ’­é€Ÿåº¦å˜æ…¢ã€‚'
- en: '`gradient_checkpointing_kwargs` (`dict`, *optional*, defaults to `None`) â€”
    Keyword arguments to pass to the gradient checkpointing function, please refer
    to the documentation of `torch.utils.checkpoint.checkpoint` for more details about
    the arguments that you can pass to that method. Note this is only available in
    the latest transformers versions (> 4.34.1).'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gradient_checkpointing_kwargs`ï¼ˆ`dict`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º`None`ï¼‰- ä¼ é€’ç»™æ¢¯åº¦æ£€æŸ¥ç‚¹å‡½æ•°çš„å…³é”®å­—å‚æ•°ï¼Œè¯·å‚è€ƒ`torch.utils.checkpoint.checkpoint`çš„æ–‡æ¡£ï¼Œäº†è§£å¯ä»¥ä¼ é€’ç»™è¯¥æ–¹æ³•çš„å‚æ•°çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚è¯·æ³¨æ„ï¼Œè¿™ä»…é€‚ç”¨äºæœ€æ–°çš„transformersç‰ˆæœ¬ï¼ˆ>
    4.34.1ï¼‰ã€‚'
- en: Note this method only works for `transformers` models.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæ­¤æ–¹æ³•ä»…é€‚ç”¨äº`transformers`æ¨¡å‹ã€‚
- en: 'This method wraps the entire protocol for preparing a model before running
    a training. This includes: 1- Cast the layernorm in fp32 2- making output embedding
    layer require grads 3- Add the upcasting of the lm head to fp32'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ–¹æ³•åŒ…è£…äº†å‡†å¤‡æ¨¡å‹åœ¨è¿è¡Œè®­ç»ƒä¹‹å‰çš„æ•´ä¸ªåè®®ã€‚è¿™åŒ…æ‹¬ï¼š1- å°†layernormè½¬æ¢ä¸ºfp32 2- ä½¿è¾“å‡ºåµŒå…¥å±‚éœ€è¦æ¢¯åº¦ 3- å°†lmå¤´çš„å‡çº§è½¬æ¢ä¸ºfp32
