- en: Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: 'Original text: [https://huggingface.co/docs/peft/package_reference/peft_model](https://huggingface.co/docs/peft/package_reference/peft_model)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/peft/package_reference/peft_model](https://huggingface.co/docs/peft/package_reference/peft_model)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '[PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel)
    is the base model class for specifying the base Transformer model and configuration
    to apply a PEFT method to. The base `PeftModel` contains methods for loading and
    saving models from the Hub.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel)是指定基础变换器模型和配置以应用PEFT方法的基础模型类。基础`PeftModel`包含从Hub加载和保存模型的方法。'
- en: PeftModel
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModel
- en: '### `class peft.PeftModel`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModel`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L88)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L88)'
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — The base transformer model used for Peft.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — 用于Peft的基础变换器模型。'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — The configuration of the Peft model.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft模型的配置。'
- en: '`adapter_name` (`str`, *optional*) — The name of the adapter, defaults to `"default"`.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, *可选*) — 适配器的名称，默认为`"default"`。'
- en: Base model encompassing various Peft methods.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 包含各种Peft方法的基础模型。
- en: '**Attributes**:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**属性**：'
- en: '`base_model` (`torch.nn.Module`) — The base transformer model used for Peft.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base_model` (`torch.nn.Module`) — 用于Peft的基础变换器模型。'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — The configuration of the Peft model.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft模型的配置。'
- en: '`modules_to_save` (`list` of `str`) — The list of sub-module names to save
    when saving the model.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modules_to_save` (`list` of `str`) — 保存模型时要保存的子模块名称的列表。'
- en: '`prompt_encoder` ([PromptEncoder](/docs/peft/v0.8.2/en/package_reference/p_tuning#peft.PromptEncoder))
    — The prompt encoder used for Peft if using [PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_encoder` ([PromptEncoder](/docs/peft/v0.8.2/en/package_reference/p_tuning#peft.PromptEncoder))
    — 如果使用[PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)，则用于Peft的提示编码器。'
- en: '`prompt_tokens` (`torch.Tensor`) — The virtual prompt tokens used for Peft
    if using [PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_tokens` (`torch.Tensor`) — 如果使用[PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)，则用于Peft的虚拟提示标记。'
- en: '`transformer_backbone_name` (`str`) — The name of the transformer backbone
    in the base model if using [PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer_backbone_name` (`str`) — 如果使用[PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)，则是基础模型中变换器主干的名称。'
- en: '`word_embeddings` (`torch.nn.Embedding`) — The word embeddings of the transformer
    backbone in the base model if using [PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`word_embeddings` (`torch.nn.Embedding`) — 如果使用[PromptLearningConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PromptLearningConfig)，则是基础模型中变换器主干的词嵌入。'
- en: '#### `add_adapter`'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `add_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L587)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L587)'
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`adapter_name` (`str`) — The name of the adapter to be added.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`) — 要添加的适配器的名称。'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — The configuration of the adapter to be added.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — 要添加的适配器的配置。'
- en: Add an adapter to the model based on the passed configuration.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 根据传递的配置向模型添加适配器。
- en: The name for the new adapter should be unique.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 新适配器的名称应该是唯一的。
- en: The new adapter is not automatically set as the active adapter. Use [PeftModel.set_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.set_adapter)
    to set the active adapter.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 新适配器不会自动设置为活动适配器。使用[PeftModel.set_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.set_adapter)来设置活动适配器。
- en: '#### `create_or_update_model_card`'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `create_or_update_model_card`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L777)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L777)'
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Updates or create model card to include information about peft:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 更新或创建模型卡以包含有关peft的信息：
- en: Adds `peft` library tag
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加`peft`库标签
- en: Adds peft version
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加peft版本
- en: Adds base model info
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加基础模型信息
- en: Adds quantization information if it was used
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果使用了量化信息，则添加量化信息
- en: '#### `disable_adapter`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L547)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L547)'
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Context manager that disables the adapter module. Use this to run inference
    on the base model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用适配器模块的上下文管理器。使用此功能在基础模型上运行推理。
- en: 'Example:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `forward`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L533)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L533)'
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Forward pass of the model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的前向传递。
- en: '#### `from_pretrained`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L283)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L283)'
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Parameters
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to be adapted. For 🤗 Transformers models,
    the model should be initialized with the [from_pretrained](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained).'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要适配的模型。对于🤗变换器模型，模型应该使用[from_pretrained](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)进行初始化。'
- en: '`model_id` (`str` or `os.PathLike`) — The name of the PEFT configuration to
    use. Can be either:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_id` (`str`或`os.PathLike`) — 要使用的PEFT配置的名称。可以是：'
- en: A string, the `model id` of a PEFT configuration hosted inside a model repo
    on the Hugging Face Hub.
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A path to a directory containing a PEFT configuration file saved using the `save_pretrained`
    method (`./my_peft_config_directory/`).
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`adapter_name` (`str`, *optional*, defaults to `"default"`) — The name of the
    adapter to be loaded. This is useful for loading multiple adapters.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_trainable` (`bool`, *optional*, defaults to `False`) — Whether the adapter
    should be trainable or not. If `False`, the adapter will be frozen and can only
    be used for inference.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig),
    *optional*) — The configuration object to use instead of an automatically loaded
    configuration. This configuration object is mutually exclusive with `model_id`
    and `kwargs`. This is useful when configuration is already loaded before calling
    `from_pretrained`. kwargs — (`optional`): Additional keyword arguments passed
    along to the specific PEFT configuration class.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate a PEFT model from a pretrained model and loaded PEFT weights.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Note that the passed `model` may be modified inplace.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_base_model`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L577)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Returns the base model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_nb_trainable_parameters`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L492)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Returns the number of trainable parameters and the number of all parameters
    in the model.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_prompt`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L446)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Returns the virtual prompts to use for Peft. Only applicable when using a prompt
    learning method.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '#### `get_prompt_embedding_to_save`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L427)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Returns the prompt embedding to save when saving the model. Only applicable
    when using a prompt learning method.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '#### `load_adapter`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L652)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '`adapter_name` (`str`) — The name of the adapter to be added.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — The configuration of the adapter to be added.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_trainable` (`bool`, *optional*, defaults to `False`) — Whether the adapter
    should be trainable or not. If `False`, the adapter will be frozen and can only
    be used for inference. kwargs — (`optional`): Additional arguments to modify the
    way the adapter is loaded, e.g. the token for Hugging Face Hub.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load a trained adapter into the model.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: The name for the new adapter should be unique.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: The new adapter is not automatically set as the active adapter. Use [PeftModel.set_adapter()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.set_adapter)
    to set the active adapter.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '#### `print_trainable_parameters`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L516)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Prints the number of trainable parameters in the model.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '#### `save_pretrained`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L161)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '`save_directory` (`str`) — Directory where the adapter model and configuration
    files will be saved (will be created if it does not exist).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safe_serialization` (`bool`, *optional*) — Whether to save the adapter files
    in safetensors format, defaults to `True`.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`selected_adapters` (`List[str]`, *optional*) — A list of adapters to be saved.
    If `None`, will default to all adapters.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`save_embedding_layers` (`Union[bool, str]`, *optional*, defaults to `"auto"`)
    — If `True`, save the embedding layers in addition to adapter weights. If `auto`,
    checks the common embedding layers `peft.utils.other.EMBEDDING_LAYER_NAMES` in
    config’s `target_modules` when available. and automatically sets the boolean flag.
    This only works for 🤗 transformers models.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_main_process` (`bool`, *optional*) — Whether the process calling this is
    the main process or not. Will default to `True`. Will not save the checkpoint
    if not on the main process, which is important for multi device setups (e.g. DDP).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_main_process` (`bool`, *可选*) — 调用此函数的进程是否为主进程。默认为 `True`。如果不是主进程，则不会保存检查点，这对于多设备设置（例如
    DDP）很重要。'
- en: '`kwargs` (additional keyword arguments, *optional*) — Additional keyword arguments
    passed along to the `push_to_hub` method.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kwargs`（额外的关键字参数，*可选*） — 传递给 `push_to_hub` 方法的额外关键字参数。'
- en: This function saves the adapter model and the adapter configuration files to
    a directory, so that it can be reloaded using the [PeftModel.from_pretrained()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.from_pretrained)
    class method, and also used by the `PeftModel.push_to_hub()` method.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将适配器模型和适配器配置文件保存到一个目录中，以便可以使用 [PeftModel.from_pretrained()](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel.from_pretrained)
    类方法重新加载，并且也可以被 `PeftModel.push_to_hub()` 方法使用。
- en: '#### `set_adapter`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L743)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L743)'
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Parameters
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`adapter_name` (`str`) — The name of the adapter to be set as active. The adapter
    must be loaded first.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`) — 要设置为活动的适配器的名称。必须先加载适配器。'
- en: Sets the active adapter.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 设置活动适配器。
- en: Only one adapter can be active at a time.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一次只能有一个适配器处于活动状态。
- en: Additionally, this function will set the specified adapter to trainable (i.e.,
    requires_grad=True). If this is not desired, use the following code.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，此函数将设置指定的适配器为可训练的（即，requires_grad=True）。如果不需要此功能，请使用以下代码。
- en: '[PRE15]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: PeftModelForSequenceClassification
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForSequenceClassification
- en: A `PeftModel` for sequence classification tasks.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 用于序列分类任务的 `PeftModel`。
- en: '### `class peft.PeftModelForSequenceClassification`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForSequenceClassification`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L830)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L830)'
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — Base transformer model.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — 基础变换器模型。'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft config.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft 配置。'
- en: Peft model for sequence classification tasks.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 用于序列分类任务的 Peft 模型。
- en: '**Attributes**:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**属性**:'
- en: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration object of the base model.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 基础模型的配置对象。'
- en: '`cls_layer_name` (`str`) — The name of the classification layer.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_layer_name` (`str`) — 分类层的名称。'
- en: 'Example:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: PeftModelForTokenClassification
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForTokenClassification
- en: A `PeftModel` for token classification tasks.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 用于标记分类任务的 `PeftModel`。
- en: '### `class peft.PeftModelForTokenClassification`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForTokenClassification`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1460)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1460)'
- en: '[PRE18]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — Base transformer model.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — 基础变换器模型。'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft config.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft 配置。'
- en: Peft model for token classification tasks.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 用于标记分类任务的 Peft 模型。
- en: '**Attributes**:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**属性**:'
- en: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration object of the base model.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 基础模型的配置对象。'
- en: '`cls_layer_name` (`str`) — The name of the classification layer.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_layer_name` (`str`) — 分类层的名称。'
- en: 'Example:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE19]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: PeftModelForCausalLM
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForCausalLM
- en: A `PeftModel` for causal language modeling.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 用于因果语言建模的 `PeftModel`。
- en: '### `class peft.PeftModelForCausalLM`'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForCausalLM`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1021)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1021)'
- en: '[PRE20]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — Base transformer model.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — 基础变换器模型。'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft config.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft 配置。'
- en: Peft model for causal language modeling.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 用于因果语言建模的 Peft 模型。
- en: 'Example:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: PeftModelForSeq2SeqLM
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForSeq2SeqLM
- en: A `PeftModel` for sequence-to-sequence language modeling.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 用于序列到序列语言建模的 `PeftModel`。
- en: '### `class peft.PeftModelForSeq2SeqLM`'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForSeq2SeqLM`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1211)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1211)'
- en: '[PRE22]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — Base transformer model.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — 基础变换器模型。'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft config.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft 配置。'
- en: Peft model for sequence-to-sequence language modeling.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 用于序列到序列语言建模的 Peft 模型。
- en: 'Example:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '示例:'
- en: '[PRE23]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: PeftModelForQuestionAnswering
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForQuestionAnswering
- en: A `PeftModel` for question answering.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 用于问答的 `PeftModel`。
- en: '### `class peft.PeftModelForQuestionAnswering`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForQuestionAnswering`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1635)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1635)'
- en: '[PRE24]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — Base transformer model.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — 基础变换器模型。'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft config.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft配置。'
- en: Peft model for extractive question answering.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 用于抽取式问答的Peft模型。
- en: '**Attributes**:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**属性**：'
- en: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration object of the base model.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 基础模型的配置对象。'
- en: '`cls_layer_name` (`str`) — The name of the classification layer.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cls_layer_name` (`str`) — 分类层的名称。'
- en: 'Example:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE25]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: PeftModelForFeatureExtraction
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftModelForFeatureExtraction
- en: A `PeftModel` for getting extracting features/embeddings from transformer models.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 用于从变换器模型中提取特征/嵌入的`PeftModel`。
- en: '### `class peft.PeftModelForFeatureExtraction`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftModelForFeatureExtraction`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1830)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/peft_model.py#L1830)'
- en: '[PRE26]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — Base transformer model.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — 基础变换器模型。'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft config.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Peft配置。'
- en: Peft model for extracting features/embeddings from transformer models
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 用于从变换器模型中提取特征/嵌入的Peft模型。
- en: '**Attributes**:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**属性**：'
- en: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — The configuration object of the base model.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/configuration#transformers.PretrainedConfig))
    — 基础模型的配置对象。'
- en: 'Example:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE27]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: PeftMixedModel
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PeftMixedModel
- en: A `PeftModel` for mixing different adapter types (e.g. LoRA and LoHa).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 用于混合不同适配器类型（例如LoRA和LoHa）的`PeftModel`。
- en: '### `class peft.PeftMixedModel`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class peft.PeftMixedModel`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L83)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L83)'
- en: '[PRE28]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to be tuned.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要调整的模型。'
- en: '`config` (`PeftConfig`) — The config of the model to be tuned. The adapter
    type must be compatible.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` (`PeftConfig`) — 要调整的模型的配置。适配器类型必须兼容。'
- en: '`adapter_name` (`str`, `optional`, defaults to `"default"`) — The name of the
    first adapter.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, `可选`, 默认为`"default"`) — 第一个适配器的名称。'
- en: PeftMixedModel for loading mixing different types of adapters for inference.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 用于加载不同类型适配器进行推断的PeftMixedModel。
- en: This class does not support loading/saving, and it shouldn’t usually be initialized
    directly. Instead, use `get_peft_model` with the argument `mixed=True`.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 此类不支持加载/保存，通常不应直接初始化。而是使用`get_peft_model`并使用参数`mixed=True`。
- en: Read the [Mixed adapter types](https://huggingface.co/docs/peft/en/developer_guides/mixed_models)
    guide to learn more about using different adapter types.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读[Mixed adapter types](https://huggingface.co/docs/peft/en/developer_guides/mixed_models)指南，了解更多关于使用不同适配器类型的信息。
- en: 'Example:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE29]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '#### `disable_adapter`'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `disable_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L203)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L203)'
- en: '[PRE30]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Disables the adapter module.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用适配器模块。
- en: '#### `forward`'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `forward`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L191)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L191)'
- en: '[PRE31]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Forward pass of the model.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的前向传递。
- en: '#### `from_pretrained`'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `from_pretrained`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L329)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L329)'
- en: '[PRE32]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Parameters
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`nn.Module`) — The model to be adapted.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`nn.Module`) — 要适应的模型。'
- en: '`model_id` (`str` or `os.PathLike`) — The name of the PEFT configuration to
    use. Can be either:'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_id` (`str`或`os.PathLike`) — 要使用的PEFT配置的名称。可以是：'
- en: A string, the `model id` of a PEFT configuration hosted inside a model repo
    on the Hugging Face Hub.
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个字符串，PEFT配置的`模型id`，托管在Hugging Face Hub上的模型存储库中。
- en: A path to a directory containing a PEFT configuration file saved using the `save_pretrained`
    method (`./my_peft_config_directory/`).
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含使用`save_pretrained`方法保存的PEFT配置文件的目录路径（`./my_peft_config_directory/`）。
- en: '`adapter_name` (`str`, *optional*, defaults to `"default"`) — The name of the
    adapter to be loaded. This is useful for loading multiple adapters.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, *可选*, 默认为`"default"`) — 要加载的适配器的名称。这对于加载多个适配器很有用。'
- en: '`is_trainable` (`bool`, *optional*, defaults to `False`) — Whether the adapter
    should be trainable or not. If `False`, the adapter will be frozen and use for
    inference'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_trainable` (`bool`, *可选*, 默认为`False`) — 适配器是否可训练。如果为`False`，适配器将被冻结并用于推断。'
- en: '`config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig),
    *optional*) — The configuration object to use instead of an automatically loaded
    configuration. This configuration object is mutually exclusive with `model_id`
    and `kwargs`. This is useful when configuration is already loaded before calling
    `from_pretrained`. kwargs — (`optional`): Additional keyword arguments passed
    along to the specific PEFT configuration class.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig),
    *可选*) — 要使用的配置对象，而不是自动加载的配置。此配置对象与`model_id`和`kwargs`互斥。在调用`from_pretrained`之前已加载配置时，这很有用。kwargs
    — (`可选`): 传递给特定PEFT配置类的其他关键字参数。'
- en: Instantiate a PEFT mixed model from a pretrained model and loaded PEFT weights.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 从预训练模型和加载的PEFT权重实例化一个PEFT混合模型。
- en: Note that the passed `model` may be modified inplace.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，传递的 `model` 可能会被原地修改。
- en: '#### `generate`'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `generate`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L197)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L197)'
- en: '[PRE33]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Generate output.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 生成输出。
- en: '#### `get_nb_trainable_parameters`'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_nb_trainable_parameters`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L146)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L146)'
- en: '[PRE34]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Returns the number of trainable parameters and number of all parameters in the
    model.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 返回模型中可训练参数的数量和所有参数的数量。
- en: '#### `merge_and_unload`'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `merge_and_unload`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L283)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L283)'
- en: '[PRE35]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`progressbar` (`bool`) — whether to show a progressbar indicating the unload
    and merge process'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`progressbar` (`bool`) — 是否显示指示卸载和合并过程的进度条'
- en: '`safe_merge` (`bool`) — whether to activate the safe merging check to check
    if there is any potential Nan in the adapter weights'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`safe_merge` (`bool`) — 是否激活安全合并检查以检查适配器权重中是否存在潜在的 NaN'
- en: '`adapter_names` (`List[str]`, *optional*) — The list of adapter names that
    should be merged. If None, all active adapters will be merged. Defaults to `None`.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_names` (`List[str]`, *optional*) — 应合并的适配器名称列表。如果为 None，则将合并所有活动适配器。默认为
    `None`。'
- en: This method merges the adapter layers into the base model. This is needed if
    someone wants to use the base model as a standalone model.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法将适配器层合并到基础模型中。如果有人想要将基础模型用作独立模型，则需要这样做。
- en: '#### `print_trainable_parameters`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `print_trainable_parameters`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L171)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L171)'
- en: '[PRE36]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Prints the number of trainable parameters in the model.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 打印模型中可训练参数的数量。
- en: '#### `set_adapter`'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `set_adapter`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L237)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L237)'
- en: '[PRE37]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Parameters
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`adapter_name` (`str` or `List[str]`) — The name of the adapter(s) to be activated.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str` 或 `List[str]`) — 要激活的适配器的名称。'
- en: Sets the active adapter(s) for the model.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 设置模型的活动适配器。
- en: Note that the order in which the adapters are applied during the forward pass
    may not be the same as the order in which they are passed to this function. Instead,
    the order during the forward pass is determined by the order in which the adapters
    were loaded into the model. The active adapters only determine which adapters
    are active during the forward pass, but not the order in which they are applied.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前向传递期间应用适配器的顺序可能与将适配器传递给此函数的顺序不同。相反，在前向传递期间的顺序由适配器加载到模型中的顺序确定。活动适配器仅确定在前向传递期间哪些适配器处于活动状态，但不确定它们被应用的顺序。
- en: Additionally, this function will set the specified adapters to trainable (i.e.,
    requires_grad=True). If this is not desired, use the following code.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，此函数将指定的适配器设置为可训练（即，requires_grad=True）。如果不需要这样做，请使用以下代码。
- en: '[PRE38]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '#### `unload`'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `unload`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L300)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mixed_model.py#L300)'
- en: '[PRE39]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Gets back the base model by removing all the adapter modules without merging.
    This gives back the original base model.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 通过删除所有适配器模块而不进行合并来获取基础模型。这将还原原始基础模型。
- en: Utilities
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实用工具
- en: '#### `peft.cast_mixed_precision_params`'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.cast_mixed_precision_params`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/other.py#L523)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/other.py#L523)'
- en: '[PRE40]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Parameters
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`torch.nn.Module`) — The model to cast the non-trainable parameters
    of.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`torch.nn.Module`) — 要转换不可训练参数的模型。'
- en: '`dtype` (`torch.dtype`) — The dtype to cast the non-trainable parameters to.
    The `dtype` can be `torch.float16` or'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dtype` (`torch.dtype`) — 要将不可训练参数转换为的 dtype。`dtype` 可以是 `torch.float16` 或'
- en: Cast all non-trainable parameters of the model to the given `dtype`. The `dtype`
    can be `torch.float16` or `torch.bfloat16` as per the mixed-precision training
    you are performing. The trainable parameters are cast to full precision. This
    is meant to reduce the GPU memory usage when using PEFT methods by using half-precision
    dtype for non-trainable parameters. Having the trainable parameters in full-precision
    preserves training stability when using automatic mixed-precision training.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型的所有不可训练参数转换为给定的 `dtype`。`dtype` 可以是 `torch.float16` 或 `torch.bfloat16`，根据您正在执行的混合精度训练而定。可训练参数转换为全精度。这旨在通过使用半精度
    dtype 减少使用 PEFT 方法时的 GPU 内存使用量。将可训练参数保留为全精度可在使用自动混合精度训练时保持训练稳定性。
- en: '`torch.bfloat16` as per the mixed-precision training you are performing.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.bfloat16` 根据您正在执行的混合精度训练。'
- en: '#### `peft.get_peft_model`'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.get_peft_model`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mapping.py#L106)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mapping.py#L106)'
- en: '[PRE41]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Parameters
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([transformers.PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — Model to be wrapped.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` ([transformers.PreTrainedModel](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/model#transformers.PreTrainedModel))
    — Model to be wrapped.'
- en: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — Configuration object containing the parameters of the Peft model.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config` ([PeftConfig](/docs/peft/v0.8.2/en/package_reference/config#peft.PeftConfig))
    — 包含 Peft 模型参数的配置对象。'
- en: '`adapter_name` (`str`, `optional`, defaults to `"default"`) — The name of the
    adapter to be injected, if not provided, the default adapter name is used (“default”).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name` (`str`, `optional`, 默认为 `"default"`) — 要注入的适配器的名称，如果未提供，则使用默认适配器名称（“default”）。'
- en: '`mixed` (`bool`, `optional`, defaults to `False`) — Whether to allow mixing
    different (compatible) adapter types.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mixed` (`bool`, `optional`, 默认为 `False`) — 是否允许混合不同（兼容的）适配器类型。'
- en: Returns a Peft model object from a model and a config.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 从模型和配置返回一个 Peft 模型对象。
- en: '#### `peft.inject_adapter_in_model`'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.inject_adapter_in_model`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mapping.py#L139)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/mapping.py#L139)'
- en: '[PRE42]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Parameters
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`peft_config` (`PeftConfig`) — Configuration object containing the parameters
    of the Peft model.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`peft_config`（`PeftConfig`）- 包含Peft模型参数的配置对象。'
- en: '`model` (`torch.nn.Module`) — The input model where the adapter will be injected.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`torch.nn.Module`）- 要注入适配器的输入模型。'
- en: '`adapter_name` (`str`, `optional`, defaults to `"default"`) — The name of the
    adapter to be injected, if not provided, the default adapter name is used (“default”).'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name`（`str`，`可选`，默认为`"default"`）- 要注入的适配器的名称，如果未提供，则使用默认的适配器名称（“default”）。'
- en: A simple API to create and inject adapter in-place into a model. Currently the
    API does not support prompt learning methods and adaption prompt. Make sure to
    have the correct `target_names` set in the `peft_config` object. The API calls
    `get_peft_model` under the hood but would be restricted only to non-prompt learning
    methods.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的API，用于在模型中创建并就地注入适配器。目前，该API不支持提示学习方法和适应提示。请确保在`peft_config`对象中设置了正确的`target_names`。API在底层调用`get_peft_model`，但仅限于非提示学习方法。
- en: '#### `peft.get_peft_model_state_dict`'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.get_peft_model_state_dict`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/save_and_load.py#L46)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/save_and_load.py#L46)'
- en: '[PRE43]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Parameters
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` ([PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel))
    — The Peft model. When using torch.nn.DistributedDataParallel, DeepSpeed or FSDP,
    the model should be the underlying model/unwrapped model (i.e. model.module).'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（[PeftModel](/docs/peft/v0.8.2/en/package_reference/peft_model#peft.PeftModel)）-
    Peft模型。在使用torch.nn.DistributedDataParallel、DeepSpeed或FSDP时，模型应为基础模型/取消包装模型（即model.module）。'
- en: '`state_dict` (`dict`, *optional*, defaults to `None`) — The state dict of the
    model. If not provided, the state dict of the passed model will be used.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state_dict`（`dict`，*可选*，默认为`None`）- 模型的状态字典。如果未提供，则将使用传递模型的状态字典。'
- en: '`adapter_name` (`str`, *optional*, defaults to `"default"`) — The name of the
    adapter whose state dict should be returned.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adapter_name`（`str`，*可选*，默认为`"default"`）- 应返回其状态字典的适配器的名称。'
- en: '`unwrap_compiled` (`bool`, *optional*, defaults to `False`) — Whether to unwrap
    the model if torch.compile was used.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unwrap_compiled`（`bool`，*可选*，默认为`False`）- 是否在使用torch.compile时取消包装模型。'
- en: '`save_embedding_layers` (`Union[bool, str]`, , *optional*, defaults to `auto`)
    — If `True`, save the embedding layers in addition to adapter weights. If `auto`,
    checks the common embedding layers `peft.utils.other.EMBEDDING_LAYER_NAMES` in
    config’s `target_modules` when available. Based on it sets the boolean flag. This
    only works for 🤗 transformers models.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_embedding_layers`（`Union[bool, str]`，*可选*，默认为`auto`）- 如果为`True`，则保存嵌入层以及适配器权重。如果为`auto`，则在配置的`target_modules`中检查常见的嵌入层`peft.utils.other.EMBEDDING_LAYER_NAMES`，并根据其设置布尔标志。这仅适用于🤗
    transformers模型。'
- en: Get the state dict of the Peft model.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 获取Peft模型的状态字典。
- en: '#### `peft.prepare_model_for_kbit_training`'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `peft.prepare_model_for_kbit_training`'
- en: '[< source >](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/other.py#L77)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/other.py#L77)'
- en: '[PRE44]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Parameters
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`transformers.PreTrainedModel`) — The loaded model from `transformers`'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`transformers.PreTrainedModel`）- 从`transformers`加载的模型'
- en: '`use_gradient_checkpointing` (`bool`, *optional*, defaults to `True`) — If
    True, use gradient checkpointing to save memory at the expense of slower backward
    pass.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_gradient_checkpointing`（`bool`，*可选*，默认为`True`）- 如果为True，则使用梯度检查点以节省内存，但会导致反向传播速度变慢。'
- en: '`gradient_checkpointing_kwargs` (`dict`, *optional*, defaults to `None`) —
    Keyword arguments to pass to the gradient checkpointing function, please refer
    to the documentation of `torch.utils.checkpoint.checkpoint` for more details about
    the arguments that you can pass to that method. Note this is only available in
    the latest transformers versions (> 4.34.1).'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gradient_checkpointing_kwargs`（`dict`，*可选*，默认为`None`）- 传递给梯度检查点函数的关键字参数，请参考`torch.utils.checkpoint.checkpoint`的文档，了解可以传递给该方法的参数的更多详细信息。请注意，这仅适用于最新的transformers版本（>
    4.34.1）。'
- en: Note this method only works for `transformers` models.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此方法仅适用于`transformers`模型。
- en: 'This method wraps the entire protocol for preparing a model before running
    a training. This includes: 1- Cast the layernorm in fp32 2- making output embedding
    layer require grads 3- Add the upcasting of the lm head to fp32'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法包装了准备模型在运行训练之前的整个协议。这包括：1- 将layernorm转换为fp32 2- 使输出嵌入层需要梯度 3- 将lm头的升级转换为fp32
