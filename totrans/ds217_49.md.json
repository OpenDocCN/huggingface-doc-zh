["```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 train.csv\n\u2514\u2500\u2500 test.csv\n```", "```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 data.csv\n\u2514\u2500\u2500 holdout.csv\n```", "```py\n---\nconfigs:\n- config_name: default\n  data_files:\n  - split: train\n    path: \"data.csv\"\n  - split: test\n    path: \"holdout.csv\"\n---\n```", "```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 abc.csv\n\u2502   \u2514\u2500\u2500 def.csv\n\u2514\u2500\u2500 holdout/\n    \u2514\u2500\u2500 ghi.csv\n```", "```py\n---\nconfigs:\n- config_name: default\n  data_files:\n  - split: train\n    path:\n    - \"data/abc.csv\"\n    - \"data/def.csv\"\n  - split: test\n    path: \"holdout/ghi.csv\"\n---\n```", "```py\n---\nconfigs:\n- config_name: default\n  data_files:\n  - split: train\n    path: \"data/*.csv\"\n  - split: test\n    path: \"holdout/*.csv\"\n---\n```", "```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 main_data.csv\n\u2514\u2500\u2500 additional_data.csv\n```", "```py\n---\nconfigs:\n- config_name: main_data\n  data_files: \"main_data.csv\"\n- config_name: additional_data\n  data_files: \"additional_data.csv\"\n---\n```", "```py\nfrom datasets import load_dataset\n\nmain_data = load_dataset(\"my_dataset_repository\", \"main_data\")\nadditional_data = load_dataset(\"my_dataset_repository\", \"additional_data\")\n```", "```py\n---\nconfigs:\n- config_name: tab\n  data_files: \"main_data.csv\"\n  sep: \"\\t\"\n- config_name: comma\n  data_files: \"additional_data.csv\"\n  sep: \",\"\n---\n```", "```py\n- config_name: main_data\n  data_files: \"main_data.csv\"\n  default: true\n```", "```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 train/\n    \u2502   \u2514\u2500\u2500 bees.csv\n    \u251c\u2500\u2500 test/\n    \u2502   \u2514\u2500\u2500 more_bees.csv\n    \u2514\u2500\u2500 validation/\n        \u2514\u2500\u2500 even_more_bees.csv\n```", "```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 train.csv\n    \u251c\u2500\u2500 test.csv\n    \u2514\u2500\u2500 validation.csv\n```", "```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 train-00000-of-00003.csv\n    \u251c\u2500\u2500 train-00001-of-00003.csv\n    \u251c\u2500\u2500 train-00002-of-00003.csv\n    \u251c\u2500\u2500 test-00000-of-00001.csv\n    \u251c\u2500\u2500 random-00000-of-00003.csv\n    \u251c\u2500\u2500 random-00001-of-00003.csv\n    \u2514\u2500\u2500 random-00002-of-00003.csv\n```", "```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 training.csv\n    \u251c\u2500\u2500 eval.csv\n    \u2514\u2500\u2500 valid.csv\n```", "```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 train_0.csv\n\u251c\u2500\u2500 train_1.csv\n\u251c\u2500\u2500 train_2.csv\n\u251c\u2500\u2500 train_3.csv\n\u251c\u2500\u2500 test_0.csv\n\u2514\u2500\u2500 test_1.csv\n```", "```py\nmy_dataset_repository/\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 train/\n    \u2502   \u251c\u2500\u2500 shard_0.csv\n    \u2502   \u251c\u2500\u2500 shard_1.csv\n    \u2502   \u251c\u2500\u2500 shard_2.csv\n    \u2502   \u2514\u2500\u2500 shard_3.csv\n    \u2514\u2500\u2500 test/\n        \u251c\u2500\u2500 shard_0.csv\n        \u2514\u2500\u2500 shard_1.csv\n```"]