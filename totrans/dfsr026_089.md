# é‡‘å±æ€§èƒ½ç€è‰²å™¨ï¼ˆMPSï¼‰

> åŸå§‹æ–‡æœ¬ï¼š[https://huggingface.co/docs/diffusers/optimization/mps](https://huggingface.co/docs/diffusers/optimization/mps)

ğŸ¤— Diffuserså…¼å®¹ä½¿ç”¨PyTorch [`mps`](https://pytorch.org/docs/stable/notes/mps.html)è®¾å¤‡çš„è‹¹æœç¡…ï¼ˆM1/M2èŠ¯ç‰‡ï¼‰ï¼Œè¯¥è®¾å¤‡ä½¿ç”¨Metalæ¡†æ¶æ¥åˆ©ç”¨MacOSè®¾å¤‡ä¸Šçš„GPUã€‚æ‚¨éœ€è¦ï¼š

+   å…·æœ‰è‹¹æœç¡…ï¼ˆM1/M2ï¼‰ç¡¬ä»¶çš„macOSè®¡ç®—æœº

+   macOS 12.6æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆå»ºè®®ä½¿ç”¨13.0æˆ–æ›´é«˜ç‰ˆæœ¬ï¼‰

+   Pythonçš„arm64ç‰ˆæœ¬

+   [PyTorch 2.0](https://pytorch.org/get-started/locally/)ï¼ˆå»ºè®®ï¼‰æˆ–1.13ï¼ˆ`mps`æ”¯æŒçš„æœ€ä½ç‰ˆæœ¬ï¼‰

`mps`åç«¯ä½¿ç”¨PyTorchçš„`.to()`æ¥å£å°†ç¨³å®šæ‰©æ•£ç®¡é“ç§»åŠ¨åˆ°æ‚¨çš„M1æˆ–M2è®¾å¤‡ä¸Šï¼š

```py
from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
pipe = pipe.to("mps")

# Recommended if your computer has < 64 GB of RAM
pipe.enable_attention_slicing()

prompt = "a photo of an astronaut riding a horse on mars"
image = pipe(prompt).images[0]
image
```

åœ¨æ‰¹å¤„ç†ä¸­ç”Ÿæˆå¤šä¸ªæç¤ºå¯èƒ½ä¼š[å´©æºƒ](https://github.com/huggingface/diffusers/issues/363)æˆ–æ— æ³•å¯é å·¥ä½œã€‚æˆ‘ä»¬è®¤ä¸ºè¿™ä¸PyTorchä¸­çš„[`mps`](https://github.com/pytorch/pytorch/issues/84039)åç«¯æœ‰å…³ã€‚åœ¨è°ƒæŸ¥æ­¤é—®é¢˜æ—¶ï¼Œæ‚¨åº”è¯¥è¿­ä»£è€Œä¸æ˜¯æ‰¹å¤„ç†ã€‚

å¦‚æœæ‚¨ä½¿ç”¨**PyTorch 1.13**ï¼Œæ‚¨éœ€è¦é€šè¿‡é¢å¤–çš„ä¸€æ¬¡é€šè¿‡â€œprimeâ€ç®¡é“ã€‚è¿™æ˜¯ä¸€ä¸ªä¸´æ—¶è§£å†³æ–¹æ³•ï¼Œç”¨äºè§£å†³ç¬¬ä¸€æ¬¡æ¨ç†é€šè¿‡äº§ç”Ÿä¸åç»­æ¨ç†é€šè¿‡ç•¥æœ‰ä¸åŒç»“æœçš„é—®é¢˜ã€‚æ‚¨åªéœ€è¦æ‰§è¡Œæ­¤æ­¥éª¤ä¸€æ¬¡ï¼Œä»…ç»è¿‡ä¸€æ¬¡æ¨ç†æ­¥éª¤åï¼Œæ‚¨å¯ä»¥ä¸¢å¼ƒç»“æœã€‚

```py
  from diffusers import DiffusionPipeline

  pipe = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5").to("mps")
  pipe.enable_attention_slicing()

  prompt = "a photo of an astronaut riding a horse on mars"
  # First-time "warmup" pass if PyTorch version is 1.13
+ _ = pipe(prompt, num_inference_steps=1)

  # Results match those from the CPU device after the warmup pass.
  image = pipe(prompt).images[0]
```

## æ•…éšœæ’é™¤

M1/M2çš„æ€§èƒ½å¯¹å†…å­˜å‹åŠ›éå¸¸æ•æ„Ÿã€‚å½“å‘ç”Ÿè¿™ç§æƒ…å†µæ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¿›è¡Œäº¤æ¢ï¼Œå¦‚æœéœ€è¦çš„è¯ï¼Œè¿™ä¼šæ˜¾è‘—é™ä½æ€§èƒ½ã€‚

ä¸ºé˜²æ­¢è¿™ç§æƒ…å†µå‘ç”Ÿï¼Œæˆ‘ä»¬å»ºè®®*æ³¨æ„åŠ›åˆ‡ç‰‡*ä»¥å‡å°‘æ¨ç†è¿‡ç¨‹ä¸­çš„å†…å­˜å‹åŠ›å¹¶é˜²æ­¢äº¤æ¢ã€‚å¦‚æœæ‚¨çš„è®¡ç®—æœºç³»ç»ŸRAMå°‘äº64GBï¼Œæˆ–è€…ç”Ÿæˆçš„å›¾åƒåˆ†è¾¨ç‡å¤§äº512Ã—512åƒç´ çš„éæ ‡å‡†åˆ†è¾¨ç‡ï¼Œåˆ™è¿™ä¸€ç‚¹å°¤ä¸ºé‡è¦ã€‚åœ¨æ‚¨çš„ç®¡é“ä¸Šè°ƒç”¨[enable_attention_slicing()](/docs/diffusers/v0.26.3/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline.enable_attention_slicing)å‡½æ•°ï¼š

```py
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True).to("mps")
pipeline.enable_attention_slicing()
```

æ³¨æ„åŠ›åˆ‡ç‰‡å°†æ˜‚è´µçš„æ³¨æ„åŠ›æ“ä½œåˆ†ä¸ºå¤šä¸ªæ­¥éª¤ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§å®Œæˆã€‚åœ¨æ²¡æœ‰é€šç”¨å†…å­˜çš„è®¡ç®—æœºä¸Šï¼Œè¿™é€šå¸¸å¯ä»¥æé«˜çº¦20%çš„æ€§èƒ½ï¼Œä½†æˆ‘ä»¬è§‚å¯Ÿåˆ°åœ¨å¤§å¤šæ•°è‹¹æœç¡…è®¡ç®—æœºä¸Šæœ‰æ›´å¥½çš„æ€§èƒ½ï¼Œé™¤éæ‚¨æœ‰64GBæˆ–æ›´å¤šçš„RAMã€‚
