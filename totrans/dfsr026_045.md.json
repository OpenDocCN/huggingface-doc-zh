["```py\ndef callback_dynamic_cfg(pipe, step_index, timestep, callback_kwargs):\n        # adjust the batch_size of prompt_embeds according to guidance_scale\n        if step_index == int(pipe.num_timestep * 0.4):\n                prompt_embeds = callback_kwargs[\"prompt_embeds\"]\n                prompt_embeds = prompt_embeds.chunk(2)[-1]\n\n        # update guidance_scale and prompt_embeds\n        pipe._guidance_scale = 0.0\n        callback_kwargs[\"prompt_embeds\"] = prompt_embeds\n        return callback_kwargs\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\npipe = pipe.to(\"cuda\")\n\nprompt = \"a photo of an astronaut riding a horse on mars\"\n\ngenerator = torch.Generator(device=\"cuda\").manual_seed(1)\nout = pipe(prompt, generator=generator, callback_on_step_end=callback_custom_cfg, callback_on_step_end_tensor_inputs=['prompt_embeds'])\n\nout.images[0].save(\"out_custom_cfg.png\")\n```", "```py\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\npipe.enable_model_cpu_offload()\nnum_inference_steps = 50\n\ndef interrupt_callback(pipe, i, t, callback_kwargs):\n    stop_idx = 10\n    if i == stop_idx:\n        pipe._interrupt = True\n\n    return callback_kwargs\n\npipe(\n    \"A photo of a cat\",\n    num_inference_steps=num_inference_steps,\n    callback_on_step_end=interrupt_callback,\n)\n```"]