- en: 'Class: HfInferenceEndpoint'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Original text: [https://huggingface.co/docs/huggingface.js/inference/classes/HfInferenceEndpoint](https://huggingface.co/docs/huggingface.js/inference/classes/HfInferenceEndpoint)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en:  
    
    
    
    
    
    
    
    
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`TaskWithNoAccessTokenNoModel`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ↳ **`HfInferenceEndpoint`**
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Constructors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: constructor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: • `new HfInferenceEndpoint`(`endpointUrl`, `accessToken?`, `defaultOptions?`)
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Name | Type | Default value |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `endpointUrl` | `string` | `undefined` |'
  prefs: []
  type: TYPE_TB
- en: '| `accessToken` | `string` | `""` |'
  prefs: []
  type: TYPE_TB
- en: '| `defaultOptions` | [`Options`](../interfaces/Options) | `{}` |'
  prefs: []
  type: TYPE_TB
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/HfInference.ts:48](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/HfInference.ts#L48)'
  prefs: []
  type: TYPE_NORMAL
- en: Properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: audioClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `audioClassification`: (`args`: { `data`: `Blob` | `ArrayBuffer` }, `options?`:
    [`Options`](../interfaces/Options)) => `Promise`<[`AudioClassificationReturn`](../modules#audioclassificationreturn)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`AudioClassificationReturn`](../modules#audioclassificationreturn)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.data` | `Blob` &#124; `ArrayBuffer` | Binary audio data |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`AudioClassificationReturn`](../modules#audioclassificationreturn)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/audio/audioClassification.ts:30](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/audio/audioClassification.ts#L30)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: audioToAudio
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `audioToAudio`: (`args`: { `data`: `Blob` | `ArrayBuffer` }, `options?`:
    [`Options`](../interfaces/Options)) => `Promise`<[`AudioToAudioReturn`](../modules#audiotoaudioreturn)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`AudioToAudioReturn`](../modules#audiotoaudioreturn)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.data` | `Blob` &#124; `ArrayBuffer` | Binary audio data |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`AudioToAudioReturn`](../modules#audiotoaudioreturn)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/audio/audioToAudio.ts:35](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/audio/audioToAudio.ts#L35)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: automaticSpeechRecognition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `automaticSpeechRecognition`: (`args`: { `data`: `Blob` | `ArrayBuffer`
    }, `options?`: [`Options`](../interfaces/Options)) => `Promise`<[`AutomaticSpeechRecognitionOutput`](../interfaces/AutomaticSpeechRecognitionOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`AutomaticSpeechRecognitionOutput`](../interfaces/AutomaticSpeechRecognitionOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.data` | `Blob` &#124; `ArrayBuffer` | Binary audio data |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`AutomaticSpeechRecognitionOutput`](../interfaces/AutomaticSpeechRecognitionOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/audio/automaticSpeechRecognition.ts:23](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/audio/automaticSpeechRecognition.ts#L23)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: conversational
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `conversational`: (`args`: { `inputs`: { `generated_responses?`: `string`[]
    ; `past_user_inputs?`: `string`[] ; `text`: `string` } ; `parameters?`: { `max_length?`:
    `number` ; `max_time?`: `number` ; `min_length?`: `number` ; `repetition_penalty?`:
    `number` ; `temperature?`: `number` ; `top_k?`: `number` ; `top_p?`: `number`
    } }, `options?`: [`Options`](../interfaces/Options)) => `Promise`<[`ConversationalOutput`](../interfaces/ConversationalOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`ConversationalOutput`](../interfaces/ConversationalOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.generated_responses?` | `string`[] | A list of strings corresponding
    to the earlier replies from the model. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.past_user_inputs?` | `string`[] | A list of strings corresponding
    to the earlier replies from the user. Should be of the same length of generated_responses.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.text` | `string` | The last input from the user in the conversation.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters?` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.max_length?` | `number` | (Default: None). Integer to define
    the maximum length in tokens of the output summary. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.max_time?` | `number` | (Default: None). Float (0-120.0).
    The amount of time in seconds that the query should take maximum. Network can
    cause some overhead so it will be a soft limit. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.min_length?` | `number` | (Default: None). Integer to define
    the minimum length in tokens of the output summary. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.repetition_penalty?` | `number` | (Default: None). Float
    (0.0-100.0). The more a token is used within generation the more it is penalized
    to not be picked in successive generation passes. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.temperature?` | `number` | (Default: 1.0). Float (0.0-100.0).
    The temperature of the sampling operation. 1 means regular sampling, 0 means always
    take the highest score, 100.0 is getting closer to uniform probability. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.top_k?` | `number` | (Default: None). Integer to define
    the top tokens considered within the sample operation to create new text. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.top_p?` | `number` | (Default: None). Float to define the
    tokens that are within the sample operation of text generation. Add tokens in
    the sample for more probable to least probable until the sum of the probabilities
    is greater than top_p. |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`ConversationalOutput`](../interfaces/ConversationalOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/conversational.ts:65](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/conversational.ts#L65)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: documentQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `documentQuestionAnswering`: (`args`: { `inputs`: { `image`: `Blob` | `ArrayBuffer`
    ; `question`: `string` } }, `options?`: [`Options`](../interfaces/Options)) =>
    `Promise`<[`DocumentQuestionAnsweringOutput`](../interfaces/DocumentQuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`DocumentQuestionAnsweringOutput`](../interfaces/DocumentQuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.image` | `Blob` &#124; `ArrayBuffer` | Raw image You can use
    native `File` in browsers, or `new Blob([buffer])` in node, or for a base64 image
    `new Blob([btoa(base64String)])`, or even `await (await fetch(''...)).blob()`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.question` | `string` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`DocumentQuestionAnsweringOutput`](../interfaces/DocumentQuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/multimodal/documentQuestionAnswering.ts:42](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/multimodal/documentQuestionAnswering.ts#L42)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: featureExtraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `featureExtraction`: (`args`: { `inputs`: `string` | `string`[] }, `options?`:
    [`Options`](../interfaces/Options)) => `Promise`<[`FeatureExtractionOutput`](../modules#featureextractionoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`FeatureExtractionOutput`](../modules#featureextractionoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` &#124; `string`[] | The inputs is a string or a
    list of strings to get the features from. inputs: “That is a happy person”, |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`FeatureExtractionOutput`](../modules#featureextractionoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/featureExtraction.ts:24](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/featureExtraction.ts#L24)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: fillMask
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `fillMask`: (`args`: { `inputs`: `string` }, `options?`: [`Options`](../interfaces/Options))
    => `Promise`<[`FillMaskOutput`](../modules#fillmaskoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`FillMaskOutput`](../modules#fillmaskoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`FillMaskOutput`](../modules#fillmaskoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/fillMask.ts:31](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/fillMask.ts#L31)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: imageClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `imageClassification`: (`args`: { `data`: `Blob` | `ArrayBuffer` }, `options?`:
    [`Options`](../interfaces/Options)) => `Promise`<[`ImageClassificationOutput`](../modules#imageclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`ImageClassificationOutput`](../modules#imageclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.data` | `Blob` &#124; `ArrayBuffer` | Binary image data |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`ImageClassificationOutput`](../modules#imageclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/cv/imageClassification.ts:29](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/cv/imageClassification.ts#L29)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: imageSegmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `imageSegmentation`: (`args`: { `data`: `Blob` | `ArrayBuffer` }, `options?`:
    [`Options`](../interfaces/Options)) => `Promise`<[`ImageSegmentationOutput`](../modules#imagesegmentationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`ImageSegmentationOutput`](../modules#imagesegmentationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.data` | `Blob` &#124; `ArrayBuffer` | Binary image data |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`ImageSegmentationOutput`](../modules#imagesegmentationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/cv/imageSegmentation.ts:33](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/cv/imageSegmentation.ts#L33)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: imageToImage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `imageToImage`: (`args`: { `inputs`: `Blob` | `ArrayBuffer` ; `parameters?`:
    { `guess_mode?`: `boolean` ; `guidance_scale?`: `number` ; `height?`: `number`
    ; `negative_prompt?`: `string` ; `num_inference_steps?`: `number` ; `prompt?`:
    `string` ; `strength?`: `number` ; `width?`: `number` } }, `options?`: [`Options`](../interfaces/Options))
    => `Promise`<`Blob`>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<`Blob`>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Blob` &#124; `ArrayBuffer` | The initial image condition
    |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters?` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.guess_mode?` | `boolean` | guess_mode only works for ControlNet
    models, defaults to False In this mode, the ControlNet encoder will try best to
    recognize the content of the input image even if you remove all prompts. The `guidance_scale`
    between 3.0 and 5.0 is recommended. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.guidance_scale?` | `number` | Guidance scale: Higher guidance
    scale encourages to generate images that are closely linked to the text `prompt`,
    usually at the expense of lower image quality. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.height?` | `number` | The height in pixels of the generated
    image |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.negative_prompt?` | `string` | An optional negative prompt
    for the image generation |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.num_inference_steps?` | `number` | The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.prompt?` | `string` | The text prompt to guide the image
    generation. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.strength?` | `number` | strengh param only works for SD
    img2img and alt diffusion img2img models Conceptually, indicates how much to transform
    the reference `image`. Must be between 0 and 1\. `image` will be used as a starting
    point, adding more noise to it the larger the `strength`. The number of denoising
    steps depends on the amount of noise initially added. When `strength` is 1, added
    noise will be maximum and the denoising process will run for the full number of
    iterations specified in `num_inference_steps`. A value of 1, therefore, essentially
    ignores `image`. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.width?` | `number` | The width in pixels of the generated
    image |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<`Blob`>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/cv/imageToImage.ts:61](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/cv/imageToImage.ts#L61)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: imageToText
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `imageToText`: (`args`: { `data`: `Blob` | `ArrayBuffer` }, `options?`:
    [`Options`](../interfaces/Options)) => `Promise`<[`ImageToTextOutput`](../interfaces/ImageToTextOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`ImageToTextOutput`](../interfaces/ImageToTextOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.data` | `Blob` &#124; `ArrayBuffer` | Binary image data |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`ImageToTextOutput`](../interfaces/ImageToTextOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/cv/imageToText.ts:22](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/cv/imageToText.ts#L22)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: objectDetection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `objectDetection`: (`args`: { `data`: `Blob` | `ArrayBuffer` }, `options?`:
    [`Options`](../interfaces/Options)) => `Promise`<[`ObjectDetectionOutput`](../modules#objectdetectionoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`ObjectDetectionOutput`](../modules#objectdetectionoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.data` | `Blob` &#124; `ArrayBuffer` | Binary image data |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`ObjectDetectionOutput`](../modules#objectdetectionoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/cv/objectDetection.ts:39](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/cv/objectDetection.ts#L39)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: questionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `questionAnswering`: (`args`: { `inputs`: { `context`: `string` ; `question`:
    `string` } }, `options?`: [`Options`](../interfaces/Options)) => `Promise`<[`QuestionAnsweringOutput`](../interfaces/QuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`QuestionAnsweringOutput`](../interfaces/QuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Object` |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.context` | `string` |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.question` | `string` |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`QuestionAnsweringOutput`](../interfaces/QuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/questionAnswering.ts:34](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/questionAnswering.ts#L34)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: request
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `request`: (`args`: { `data`: `Blob` | `ArrayBuffer` ; `parameters?`: `Record`<`string`,
    `unknown`> } | { `inputs`: `unknown` ; `parameters?`: `Record`<`string`, `unknown`>
    }, `options?`: [`Options`](../interfaces/Options) & { `task?`: `string` ; `taskHint?`:
    [`InferenceTask`](../modules#inferencetask) }) => `Promise`<`unknown`>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<`unknown`>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | { `data`: `Blob` &#124; `ArrayBuffer` ; `parameters?`: `Record`<`string`,
    `unknown`> } &#124; { `inputs`: `unknown` ; `parameters?`: `Record`<`string`,
    `unknown`> } |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) & { `task?`: `string` ; `taskHint?`:
    [`InferenceTask`](../modules#inferencetask) } |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<`unknown`>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/custom/request.ts:7](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/custom/request.ts#L7)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: sentenceSimilarity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `sentenceSimilarity`: (`args`: { `inputs`: `Record`<`string`, `unknown`>
    | `Record`<`string`, `unknown`>[] }, `options?`: [`Options`](../interfaces/Options))
    => `Promise`<[`SentenceSimilarityOutput`](../modules#sentencesimilarityoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`SentenceSimilarityOutput`](../modules#sentencesimilarityoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Record`<`string`, `unknown`> &#124; `Record`<`string`, `unknown`>[]
    | The inputs vary based on the model. For example when using sentence-transformers/paraphrase-xlm-r-multilingual-v1
    the inputs will have a `source_sentence` string and a `sentences` array of strings
    |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`SentenceSimilarityOutput`](../modules#sentencesimilarityoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/sentenceSimilarity.ts:24](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/sentenceSimilarity.ts#L24)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: streamingRequest
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `streamingRequest`: (`args`: { `data`: `Blob` | `ArrayBuffer` ; `parameters?`:
    `Record`<`string`, `unknown`> } | { `inputs`: `unknown` ; `parameters?`: `Record`<`string`,
    `unknown`> }, `options?`: [`Options`](../interfaces/Options) & { `task?`: `string`
    ; `taskHint?`: [`InferenceTask`](../modules#inferencetask) }) => `AsyncGenerator`<`unknown`,
    `any`, `unknown`>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `AsyncGenerator`<`unknown`, `any`, `unknown`>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | { `data`: `Blob` &#124; `ArrayBuffer` ; `parameters?`: `Record`<`string`,
    `unknown`> } &#124; { `inputs`: `unknown` ; `parameters?`: `Record`<`string`,
    `unknown`> } |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) & { `task?`: `string` ; `taskHint?`:
    [`InferenceTask`](../modules#inferencetask) } |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`AsyncGenerator`<`unknown`, `any`, `unknown`>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/custom/streamingRequest.ts:9](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/custom/streamingRequest.ts#L9)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: summarization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `summarization`: (`args`: { `inputs`: `string` ; `parameters?`: { `max_length?`:
    `number` ; `max_time?`: `number` ; `min_length?`: `number` ; `repetition_penalty?`:
    `number` ; `temperature?`: `number` ; `top_k?`: `number` ; `top_p?`: `number`
    } }, `options?`: [`Options`](../interfaces/Options)) => `Promise`<[`SummarizationOutput`](../interfaces/SummarizationOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`SummarizationOutput`](../interfaces/SummarizationOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` | A string to be summarized |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters?` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.max_length?` | `number` | (Default: None). Integer to define
    the maximum length in tokens of the output summary. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.max_time?` | `number` | (Default: None). Float (0-120.0).
    The amount of time in seconds that the query should take maximum. Network can
    cause some overhead so it will be a soft limit. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.min_length?` | `number` | (Default: None). Integer to define
    the minimum length in tokens of the output summary. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.repetition_penalty?` | `number` | (Default: None). Float
    (0.0-100.0). The more a token is used within generation the more it is penalized
    to not be picked in successive generation passes. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.temperature?` | `number` | (Default: 1.0). Float (0.0-100.0).
    The temperature of the sampling operation. 1 means regular sampling, 0 means always
    take the highest score, 100.0 is getting closer to uniform probability. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.top_k?` | `number` | (Default: None). Integer to define
    the top tokens considered within the sample operation to create new text. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.top_p?` | `number` | (Default: None). Float to define the
    tokens that are within the sample operation of text generation. Add tokens in
    the sample for more probable to least probable until the sum of the probabilities
    is greater than top_p. |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`SummarizationOutput`](../interfaces/SummarizationOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/summarization.ts:52](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/summarization.ts#L52)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: tableQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `tableQuestionAnswering`: (`args`: { `inputs`: { `query`: `string` ; `table`:
    `Record`<`string`, `string`[]> } }, `options?`: [`Options`](../interfaces/Options))
    => `Promise`<[`TableQuestionAnsweringOutput`](../interfaces/TableQuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`TableQuestionAnsweringOutput`](../interfaces/TableQuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.query` | `string` | The query in plain text that you want to
    ask the table |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.table` | `Record`<`string`, `string`[]> | A table of data represented
    as a dict of list where entries are headers and the lists are all the values,
    all lists must have the same size. |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`TableQuestionAnsweringOutput`](../interfaces/TableQuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/tableQuestionAnswering.ts:40](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/tableQuestionAnswering.ts#L40)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: tabularClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `tabularClassification`: (`args`: { `inputs`: { `data`: `Record`<`string`,
    `string`[]> } }, `options?`: [`Options`](../interfaces/Options)) => `Promise`<[`TabularClassificationOutput`](../modules#tabularclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`TabularClassificationOutput`](../modules#tabularclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.data` | `Record`<`string`, `string`[]> | A table of data represented
    as a dict of list where entries are headers and the lists are all the values,
    all lists must have the same size. |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`TabularClassificationOutput`](../modules#tabularclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/tabular/tabularClassification.ts:24](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/tabular/tabularClassification.ts#L24)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: tabularRegression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `tabularRegression`: (`args`: { `inputs`: { `data`: `Record`<`string`,
    `string`[]> } }, `options?`: [`Options`](../interfaces/Options)) => `Promise`<[`TabularRegressionOutput`](../modules#tabularregressionoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`TabularRegressionOutput`](../modules#tabularregressionoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.data` | `Record`<`string`, `string`[]> | A table of data represented
    as a dict of list where entries are headers and the lists are all the values,
    all lists must have the same size. |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`TabularRegressionOutput`](../modules#tabularregressionoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/tabular/tabularRegression.ts:24](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/tabular/tabularRegression.ts#L24)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: textClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `textClassification`: (`args`: { `inputs`: `string` }, `options?`: [`Options`](../interfaces/Options))
    => `Promise`<[`TextClassificationOutput`](../modules#textclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`TextClassificationOutput`](../modules#textclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` | A string to be classified |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`TextClassificationOutput`](../modules#textclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textClassification.ts:26](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textClassification.ts#L26)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: textGeneration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `textGeneration`: (`args`: { `inputs`: `string` ; `parameters?`: { `do_sample?`:
    `boolean` ; `max_new_tokens?`: `number` ; `max_time?`: `number` ; `num_return_sequences?`:
    `number` ; `repetition_penalty?`: `number` ; `return_full_text?`: `boolean` ;
    `stop_sequences?`: `string`[] ; `temperature?`: `number` ; `top_k?`: `number`
    ; `top_p?`: `number` ; `truncate?`: `number` } }, `options?`: [`Options`](../interfaces/Options))
    => `Promise`<[`TextGenerationOutput`](../interfaces/TextGenerationOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`TextGenerationOutput`](../interfaces/TextGenerationOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` | A string to be generated from |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters?` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.do_sample?` | `boolean` | (Optional: True). Bool. Whether
    or not to use sampling, use greedy decoding otherwise. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.max_new_tokens?` | `number` | (Default: None). Int (0-250).
    The amount of new tokens to be generated, this does not include the input length
    it is a estimate of the size of generated text you want. Each new tokens slows
    down the request, so look for balance between response times and length of text
    generated. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.max_time?` | `number` | (Default: None). Float (0-120.0).
    The amount of time in seconds that the query should take maximum. Network can
    cause some overhead so it will be a soft limit. Use that in combination with max_new_tokens
    for best results. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.num_return_sequences?` | `number` | (Default: 1). Integer.
    The number of proposition you want to be returned. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.repetition_penalty?` | `number` | (Default: None). Float
    (0.0-100.0). The more a token is used within generation the more it is penalized
    to not be picked in successive generation passes. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.return_full_text?` | `boolean` | (Default: True). Bool.
    If set to False, the return results will not contain the original query making
    it easier for prompting. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.stop_sequences?` | `string`[] | (Default: []) List of strings.
    The model will stop generating text when one of the strings in the list is generated.
    * |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.temperature?` | `number` | (Default: 1.0). Float (0.0-100.0).
    The temperature of the sampling operation. 1 means regular sampling, 0 means always
    take the highest score, 100.0 is getting closer to uniform probability. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.top_k?` | `number` | (Default: None). Integer to define
    the top tokens considered within the sample operation to create new text. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.top_p?` | `number` | (Default: None). Float to define the
    tokens that are within the sample operation of text generation. Add tokens in
    the sample for more probable to least probable until the sum of the probabilities
    is greater than top_p. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.truncate?` | `number` | (Default: None). Integer. The maximum
    number of tokens from the input. |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`TextGenerationOutput`](../interfaces/TextGenerationOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGeneration.ts:68](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGeneration.ts#L68)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: textGenerationStream
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `textGenerationStream`: (`args`: { `inputs`: `string` ; `parameters?`:
    { `do_sample?`: `boolean` ; `max_new_tokens?`: `number` ; `max_time?`: `number`
    ; `num_return_sequences?`: `number` ; `repetition_penalty?`: `number` ; `return_full_text?`:
    `boolean` ; `stop_sequences?`: `string`[] ; `temperature?`: `number` ; `top_k?`:
    `number` ; `top_p?`: `number` ; `truncate?`: `number` } }, `options?`: [`Options`](../interfaces/Options))
    => `AsyncGenerator`<[`TextGenerationStreamOutput`](../interfaces/TextGenerationStreamOutput),
    `any`, `unknown`>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `AsyncGenerator`<[`TextGenerationStreamOutput`](../interfaces/TextGenerationStreamOutput),
    `any`, `unknown`>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` | A string to be generated from |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters?` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.do_sample?` | `boolean` | (Optional: True). Bool. Whether
    or not to use sampling, use greedy decoding otherwise. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.max_new_tokens?` | `number` | (Default: None). Int (0-250).
    The amount of new tokens to be generated, this does not include the input length
    it is a estimate of the size of generated text you want. Each new tokens slows
    down the request, so look for balance between response times and length of text
    generated. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.max_time?` | `number` | (Default: None). Float (0-120.0).
    The amount of time in seconds that the query should take maximum. Network can
    cause some overhead so it will be a soft limit. Use that in combination with max_new_tokens
    for best results. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.num_return_sequences?` | `number` | (Default: 1). Integer.
    The number of proposition you want to be returned. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.repetition_penalty?` | `number` | (Default: None). Float
    (0.0-100.0). The more a token is used within generation the more it is penalized
    to not be picked in successive generation passes. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.return_full_text?` | `boolean` | (Default: True). Bool.
    If set to False, the return results will not contain the original query making
    it easier for prompting. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.stop_sequences?` | `string`[] | (Default: []) List of strings.
    The model will stop generating text when one of the strings in the list is generated.
    * |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.temperature?` | `number` | (Default: 1.0). Float (0.0-100.0).
    The temperature of the sampling operation. 1 means regular sampling, 0 means always
    take the highest score, 100.0 is getting closer to uniform probability. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.top_k?` | `number` | (Default: None). Integer to define
    the top tokens considered within the sample operation to create new text. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.top_p?` | `number` | (Default: None). Float to define the
    tokens that are within the sample operation of text generation. Add tokens in
    the sample for more probable to least probable until the sum of the probabilities
    is greater than top_p. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.truncate?` | `number` | (Default: None). Integer. The maximum
    number of tokens from the input. |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`AsyncGenerator`<[`TextGenerationStreamOutput`](../interfaces/TextGenerationStreamOutput),
    `any`, `unknown`>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/textGenerationStream.ts:87](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/textGenerationStream.ts#L87)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: textToImage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `textToImage`: (`args`: { `inputs`: `string` ; `parameters?`: { `guidance_scale?`:
    `number` ; `height?`: `number` ; `negative_prompt?`: `string` ; `num_inference_steps?`:
    `number` ; `width?`: `number` } }, `options?`: [`Options`](../interfaces/Options))
    => `Promise`<`Blob`>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<`Blob`>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` | The text to generate an image from |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters?` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.guidance_scale?` | `number` | Guidance scale: Higher guidance
    scale encourages to generate images that are closely linked to the text `prompt`,
    usually at the expense of lower image quality. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.height?` | `number` | The height in pixels of the generated
    image |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.negative_prompt?` | `string` | An optional negative prompt
    for the image generation |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.num_inference_steps?` | `number` | The number of denoising
    steps. More denoising steps usually lead to a higher quality image at the expense
    of slower inference. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.width?` | `number` | The width in pixels of the generated
    image |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<`Blob`>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/cv/textToImage.ts:41](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/cv/textToImage.ts#L41)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: textToSpeech
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `textToSpeech`: (`args`: { `inputs`: `string` }, `options?`: [`Options`](../interfaces/Options))
    => `Promise`<`Blob`>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<`Blob`>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` | The text to generate an audio from |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<`Blob`>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/audio/textToSpeech.ts:18](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/audio/textToSpeech.ts#L18)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: tokenClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `tokenClassification`: (`args`: { `inputs`: `string` ; `parameters?`: {
    `aggregation_strategy?`: `"none"` | `"simple"` | `"first"` | `"average"` | `"max"`
    } }, `options?`: [`Options`](../interfaces/Options)) => `Promise`<[`TokenClassificationOutput`](../modules#tokenclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`TokenClassificationOutput`](../modules#tokenclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` | A string to be classified |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters?` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.aggregation_strategy?` | `"none"` &#124; `"simple"` &#124;
    `"first"` &#124; `"average"` &#124; `"max"` | (Default: simple). There are several
    aggregation strategies: none: Every token gets classified without further aggregation.
    simple: Entities are grouped according to the default schema (B-, I- tags get
    merged when the tag is similar). first: Same as the simple strategy except words
    cannot end up with different tags. Words will use the tag of the first token when
    there is ambiguity. average: Same as the simple strategy except words cannot end
    up with different tags. Scores are averaged across tokens and then the maximum
    label is applied. max: Same as the simple strategy except words cannot end up
    with different tags. Word entity will be the token with the maximum score. |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`TokenClassificationOutput`](../modules#tokenclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/tokenClassification.ts:57](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/tokenClassification.ts#L57)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: translation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `translation`: (`args`: { `inputs`: `string` | `string`[] }, `options?`:
    [`Options`](../interfaces/Options)) => `Promise`<[`TranslationOutput`](../modules#translationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`TranslationOutput`](../modules#translationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` &#124; `string`[] | A string to be translated |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`TranslationOutput`](../modules#translationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/translation.ts:24](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/translation.ts#L24)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: visualQuestionAnswering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `visualQuestionAnswering`: (`args`: { `inputs`: { `image`: `Blob` | `ArrayBuffer`
    ; `question`: `string` } }, `options?`: [`Options`](../interfaces/Options)) =>
    `Promise`<[`VisualQuestionAnsweringOutput`](../interfaces/VisualQuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`VisualQuestionAnsweringOutput`](../interfaces/VisualQuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.image` | `Blob` &#124; `ArrayBuffer` | Raw image You can use
    native `File` in browsers, or `new Blob([buffer])` in node, or for a base64 image
    `new Blob([btoa(base64String)])`, or even `await (await fetch(''...)).blob()`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.question` | `string` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`VisualQuestionAnsweringOutput`](../interfaces/VisualQuestionAnsweringOutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/multimodal/visualQuestionAnswering.ts:32](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/multimodal/visualQuestionAnswering.ts#L32)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: zeroShotClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `zeroShotClassification`: (`args`: { `inputs`: `string` | `string`[] ;
    `parameters`: { `candidate_labels`: `string`[] ; `multi_label?`: `boolean` } },
    `options?`: [`Options`](../interfaces/Options)) => `Promise`<[`ZeroShotClassificationOutput`](../modules#zeroshotclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`ZeroShotClassificationOutput`](../modules#zeroshotclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `string` &#124; `string`[] | a string or list of strings
    |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.candidate_labels` | `string`[] | a list of strings that
    are potential classes for inputs. (max 10 candidate_labels, for more, simply run
    multiple requests, results are going to be misleading if using too many candidate_labels
    anyway. If you want to keep the exact same, you can simply run multi_label=True
    and do the scaling on your end. |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.multi_label?` | `boolean` | (Default: false) Boolean that
    is set to True if classes can overlap |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`ZeroShotClassificationOutput`](../modules#zeroshotclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/nlp/zeroShotClassification.ts:34](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/nlp/zeroShotClassification.ts#L34)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: zeroShotImageClassification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '• `zeroShotImageClassification`: (`args`: { `inputs`: { `image`: `Blob` |
    `ArrayBuffer` } ; `parameters`: { `candidate_labels`: `string`[] } }, `options?`:
    [`Options`](../interfaces/Options)) => `Promise`<[`ZeroShotImageClassificationOutput`](../modules#zeroshotimageclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Type declaration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '▸ (`args`, `options?`): `Promise`<[`ZeroShotImageClassificationOutput`](../modules#zeroshotimageclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| :-- | :-- | :-- |'
  prefs: []
  type: TYPE_TB
- en: '| `args` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.inputs.image` | `Blob` &#124; `ArrayBuffer` | Binary image data |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters` | `Object` | - |'
  prefs: []
  type: TYPE_TB
- en: '| `args.parameters.candidate_labels` | `string`[] | A list of strings that
    are potential classes for inputs. (max 10) |'
  prefs: []
  type: TYPE_TB
- en: '| `options?` | [`Options`](../interfaces/Options) | - |'
  prefs: []
  type: TYPE_TB
- en: Returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Promise`<[`ZeroShotImageClassificationOutput`](../modules#zeroshotimageclassificationoutput)>'
  prefs: []
  type: TYPE_NORMAL
- en: Defined in
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[inference/src/tasks/cv/zeroShotImageClassification.ts:33](https://github.com/huggingface/huggingface.js/blob/main/packages/inference/src/tasks/cv/zeroShotImageClassification.ts#L33)'
  prefs: []
  type: TYPE_NORMAL
