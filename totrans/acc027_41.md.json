["```py\n( dataloader: DataLoader device: Optional = None num_processes: Optional = None process_index: Optional = None split_batches: bool = False put_on_device: bool = False rng_types: Optional = None dispatch_batches: Optional = None even_batches: bool = True slice_fn_for_dispatch: Optional = None use_seedable_sampler: bool = False ) \u2192 export const metadata = 'undefined';torch.utils.data.dataloader.DataLoader\n```", "```py\n( dataloader num_batches = 0 )\n```", "```py\n( batch_sampler: BatchSampler num_processes: int = 1 process_index: int = 0 split_batches: bool = False even_batches: bool = True )\n```", "```py\n( dataset: IterableDataset batch_size: int = 1 drop_last: bool = False num_processes: int = 1 process_index: int = 0 split_batches: bool = False )\n```", "```py\n( dataset device = None rng_types = None synchronized_generator = None skip_batches = 0 _drop_last: bool = False **kwargs )\n```", "```py\n( dataset split_batches: bool = False skip_batches = 0 _drop_last: bool = False slice_fn = None **kwargs )\n```", "```py\n( optimizer device_placement = True scaler = None )\n```", "```py\n( scheduler optimizers step_with_optimizer: bool = True split_batches: bool = False )\n```"]