# Megatron-LM

> 原文链接：[https://huggingface.co/docs/accelerate/usage_guides/megatron_lm](https://huggingface.co/docs/accelerate/usage_guides/megatron_lm)

[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)使得可以在规模上训练大型transformer语言模型。它为预训练基于transformer的语言模型（如[GPT](https://arxiv.org/abs/2005.14165)（仅解码器）、[BERT](https://arxiv.org/pdf/1810.04805.pdf)（仅编码器）和[T5](https://arxiv.org/abs/1910.10683)（编码器-解码器））提供了高效的张量、管道和基于序列的模型并行性。有关详细信息以及幕后工作原理，请参考github[repo](https://github.com/NVIDIA/Megatron-LM)。

## 什么是集成的？

Accelerate集成了Megatron-LM的以下功能，以实现BERT（编码器）、GPT（解码器）或T5模型（编码器和解码器）的大规模预训练/微调：

a. **张量并行（TP）**：减少内部节点排名之间的通信，减少内存占用。每个张量被分割成多个块，每个块都驻留在不同的GPU上。在每一步中，相同的数据小批量由每个块独立并并行处理，然后通过所有GPU进行同步（`all-reduce`操作）。在简单的transformer层中，这导致前向路径中有2个`all-reduces`，后向路径中有2个`all-reduces`。有关更多详细信息，请参考研究论文[Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](https://arxiv.org/pdf/1909.08053.pdf)和🤗博客文章[BLOOM Training背后的技术](https://huggingface.co/blog/bloom-megatron-deepspeed#tensor-parallelism)的这一部分。

b. **管道并行（PP）**：通过节点间并行化减少内存占用并实现大规模训练。通过PipeDream-Flush调度/1F1B调度和交替1F1B调度减少了天真PP的气泡。层在PP阶段均匀分布。例如，如果一个模型有`24`层，我们有`4`个GPU用于管道并行，每个GPU将有`6`层（24/4）。有关减少PP空闲时间的调度的更多详细信息，请参考研究论文[Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/pdf/2104.04473.pdf)和🤗博客文章[BLOOM Training背后的技术](https://huggingface.co/blog/bloom-megatron-deepspeed#pipeline-parallelism)的这一部分。

c. **序列并行（SP）**：在不增加任何额外通信的情况下减少内存占用。仅在使用TP时适用。它减少了激活内存的需求，因为它通过在`all-reduce`后替换相同的副本到张量并行排名上来防止这种情况，通过`reduce-scatter`替换`no-op`操作，`all-reduce = reduce-scatter + all-gather`，这样可以节省大量激活内存而不增加通信成本。简单来说，它沿着序列维度分片每个transformer层的输出，例如，如果序列长度为`1024`，TP大小为`4`，每个GPU将有`256`个标记（1024/4）用于每个样本。这增加了支持训练的批量大小。有关更多详细信息，请参考研究论文[Reducing Activation Recomputation in Large Transformer Models](https://arxiv.org/pdf/2205.05198.pdf)。

d. **数据并行（DP）** 通过分布式优化器：通过在 DP 排名之间分片优化器状态和梯度来减少内存占用量（与传统方法在数据并行排名之间复制优化器状态相比）。例如，当使用混合精度训练的 Adam 优化器时，每个参数占用 12 字节的内存。这些内存均匀分布在 GPU 上，即如果有 4 个 GPU，则每个参数将占用 3 字节（12/4）。有关更多详细信息，请参阅研究论文 [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](https://arxiv.org/pdf/1910.02054.pdf) 和 🤗 博客 [BLOOM Training 背后的技术](https://huggingface.co/blog/bloom-megatron-deepspeed#zero-data-parallelism) 的以下部分。

e. **选择性激活重计算**：通过智能激活检查点减少激活的内存占用。它不会存储占用大量内存的激活，同时重新计算速度快，从而在内存和重新计算之间取得很好的折衷。例如，对于 GPT-3，这导致激活所需内存减少了 70%，而仅以 2.7% 的 FLOPs 开销重新计算激活。有关更多详细信息，请参阅研究论文 [Reducing Activation Recomputation in Large Transformer Models](https://arxiv.org/pdf/2205.05198.pdf)。

f. **融合内核**：融合 Softmax、混合精度融合层归一化和融合梯度累积以权重梯度计算线性层。PyTorch JIT 编译的融合 GeLU 和融合 Bias+Dropout+Residual addition。

g. **支持索引数据集**：用于大规模训练的数据集的高效二进制格式。支持 `mmap`、`cached` 索引文件和 `lazy` 加载器格式。

h. **检查点重塑和互操作性**：用于将变量张量和管道并行大小的 Megatron-LM 检查点重塑为备受喜爱的 🤗 Transformers 分片检查点的实用程序，因为它与众多工具（如 🤗 Accelerate Big Model Inference、Megatron-DeepSpeed Inference 等）具有良好的支持。还支持将 🤗 Transformers 分片检查点转换为变量张量和管道并行大小的 Megatron-LM 检查点，用于大规模训练。

## 先决条件

您需要安装最新的 pytorch、cuda、nccl 和 NVIDIA [APEX](https://github.com/NVIDIA/apex#quick-start) 版本以及 nltk 库。有关更多详细信息，请参阅[文档](https://github.com/NVIDIA/Megatron-LM#setup)。另一种设置环境的方法是拉取一个包含所有所需安装的 NVIDIA PyTorch 容器。

以下是设置 conda 环境的逐步方法：

1.  创建虚拟环境

```py
conda create --name ml
```

1.  假设机器已安装 CUDA 11.3，安装相应的 PyTorch GPU 版本

```py
conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch
```

1.  安装 Nvidia APEX

```py
git clone https://github.com/NVIDIA/apex
cd apex
pip install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./
cd ..
```

1.  安装 Megatron-LM

```py
pip install git+https://github.com/huggingface/Megatron-LM.git
```

## 加速 Megatron-LM 插件

重要功能通过 `accelerate config` 命令直接支持。下面显示了使用 Megatron-LM 功能的相应问题的示例：

```py
:~$ accelerate config --config_file "megatron_gpt_config.yaml"
In which compute environment are you running? ([0] This machine, [1] AWS (Amazon SageMaker)): 0
Which type of machine are you using? ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU): 2
How many different machines will you use (use more than 1 for multi-node training)? [1]: 
Do you want to use DeepSpeed? [yes/NO]: 
Do you want to use FullyShardedDataParallel? [yes/NO]: 
Do you want to use Megatron-LM ? [yes/NO]: yes
What is the Tensor Parallelism degree/size? [1]:2
Do you want to enable Sequence Parallelism? [YES/no]: 
What is the Pipeline Parallelism degree/size? [1]:2
What is the number of micro-batches? [1]:2
Do you want to enable selective activation recomputation? [YES/no]: 
Do you want to use distributed optimizer which shards optimizer state and gradients across data parallel ranks? [YES/no]: 
What is the gradient clipping value based on global L2 Norm (0 to disable)? [1.0]: 
How many GPU(s) should be used for distributed training? [1]:4
Do you wish to use FP16 or BF16 (mixed precision)? [NO/fp16/bf16]: bf16
```

结果配置如下所示：

```py
~$ cat megatron_gpt_config.yaml 
compute_environment: LOCAL_MACHINE
deepspeed_config: {}
distributed_type: MEGATRON_LM
downcast_bf16: 'no'
fsdp_config: {}
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
megatron_lm_config:
  megatron_lm_gradient_clipping: 1.0
  megatron_lm_num_micro_batches: 2
  megatron_lm_pp_degree: 2
  megatron_lm_recompute_activations: true
  megatron_lm_sequence_parallelism: true
  megatron_lm_tp_degree: 2
  megatron_lm_use_distributed_optimizer: true
mixed_precision: bf16
num_machines: 1
num_processes: 4
rdzv_backend: static
same_network: true
use_cpu: false
```

我们将以 GPT 预训练为例。要使用 Megatron-LM，对官方的 `run_clm_no_trainer.py` 进行的最小更改如下：

1.  由于 Megatron-LM 使用自己的优化器实现，因此需要使用与之兼容的相应调度器。因此，仅支持 Megatron-LM 的调度器。用户需要创建 `accelerate.utils.MegatronLMDummyScheduler`。示例如下：

```py
from accelerate.utils import MegatronLMDummyScheduler

if accelerator.distributed_type == DistributedType.MEGATRON_LM:
    lr_scheduler = MegatronLMDummyScheduler(
        optimizer=optimizer,
        total_num_steps=args.max_train_steps,
        warmup_num_steps=args.num_warmup_steps,
    )
else:
    lr_scheduler = get_scheduler(
        name=args.lr_scheduler_type,
        optimizer=optimizer,
        num_warmup_steps=args.num_warmup_steps * args.gradient_accumulation_steps,
        num_training_steps=args.max_train_steps * args.gradient_accumulation_steps,
    )
```

1.  现在需要了解总批量大小的细节，需要认知张量和管道并行大小。获取有效总批量大小的示例如下：

```py
if accelerator.distributed_type == DistributedType.MEGATRON_LM:
    total_batch_size = accelerator.state.megatron_lm_plugin.global_batch_size
else:
    total_batch_size = args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps
```

1.  在使用 Megatron-LM 时，损失已经在数据并行组中进行了平均

```py
if accelerator.distributed_type == DistributedType.MEGATRON_LM:
    losses.append(loss)
else:
    losses.append(accelerator.gather_for_metrics(loss.repeat(args.per_device_eval_batch_size)))

if accelerator.distributed_type == DistributedType.MEGATRON_LM:
    losses = torch.tensor(losses)
else:
    losses = torch.cat(losses)
```

1.  对于 Megatron-LM，我们需要使用 `accelerator.save_state` 来保存模型

```py
if accelerator.distributed_type == DistributedType.MEGATRON_LM:
    accelerator.save_state(args.output_dir)
else:
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(
        args.output_dir, is_main_process=accelerator.is_main_process, save_function=accelerator.save
    )
```

就这样了！我们准备好出发了🚀。请在路径`accelerate/examples/by_feature/megatron_lm_gpt_pretraining.py`的示例脚本中找到示例。让我们使用4个A100-80GB GPU来运行`gpt-large`模型架构。

```py
accelerate launch --config_file megatron_gpt_config.yaml \
examples/by_feature/megatron_lm_gpt_pretraining.py \
--config_name "gpt2-large" \
--tokenizer_name "gpt2-large" \
--dataset_name wikitext \
--dataset_config_name wikitext-2-raw-v1 \
--block_size 1024 \
--learning_rate 5e-5 \
--per_device_train_batch_size 24 \
--per_device_eval_batch_size 24 \
--num_train_epochs 5 \
--with_tracking \
--report_to "wandb" \
--output_dir "awesome_model"
```

以下是输出日志中的一些重要摘录：

```py
Loading extension module fused_dense_cuda...
>>> done with compiling and loading fused kernels. Compilation time: 3.569 seconds
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
Building gpt model in the pre-training mode.
The Megatron LM model weights are initialized at random in `accelerator.prepare`. Please use `accelerator.load_checkpoint` to load a pre-trained checkpoint matching the distributed setup.
Preparing dataloader
Preparing dataloader
Preparing model
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 210753280
 > number of parameters on (tensor, pipeline) model parallel rank (1, 1): 209445120
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 210753280
 > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 209445120
Preparing optimizer
Preparing scheduler
> learning rate decay style: linear
10/10/2022 22:57:22 - INFO - __main__ - ***** Running training *****
10/10/2022 22:57:22 - INFO - __main__ -   Num examples = 2318
10/10/2022 22:57:22 - INFO - __main__ -   Num Epochs = 5
10/10/2022 22:57:22 - INFO - __main__ -   Instantaneous batch size per device = 24
10/10/2022 22:57:22 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 48
10/10/2022 22:57:22 - INFO - __main__ -   Gradient Accumulation steps = 1
10/10/2022 22:57:22 - INFO - __main__ -   Total optimization steps = 245
 20%|████████████▍                                                 | 49/245 [01:04<04:09,  1.27s/it]
 10/10/2022 22:58:29 - INFO - __main__ - epoch 0: perplexity: 1222.1594275215962 eval_loss: 7.10837459564209
 40%|████████████████████████▊                                     | 98/245 [02:10<03:07,  1.28s/it]
 10/10/2022 22:59:35 - INFO - __main__ - epoch 1: perplexity: 894.5236583794557 eval_loss: 6.796291351318359
 60%|████████████████████████████████████▌                        | 147/245 [03:16<02:05,  1.28s/it]
 10/10/2022 23:00:40 - INFO - __main__ - epoch 2: perplexity: 702.8458788508042 eval_loss: 6.555137634277344
 80%|████████████████████████████████████████████████▊            | 196/245 [04:22<01:02,  1.28s/it]
 10/10/2022 23:01:46 - INFO - __main__ - epoch 3: perplexity: 600.3220028695281 eval_loss: 6.39746618270874
100%|█████████████████████████████████████████████████████████████| 245/245 [05:27<00:00,  1.28s/it]
```

还有许多其他选项/功能可以使用`accelerate.utils.MegatronLMPlugin`设置。

## 利用编写自定义训练步骤和Megatron-LM索引数据集的高级功能

要利用更多功能，请查看以下详细信息。

1.  以下是在使用Megatron-LM时自定义训练步骤所需的更改示例。您将实现`accelerate.utils.AbstractTrainStep`或继承自其相应的子类`accelerate.utils.GPTTrainStep`、`accelerate.utils.BertTrainStep`或`accelerate.utils.T5TrainStep`。

```py
from accelerate.utils import MegatronLMDummyScheduler, GPTTrainStep, avg_losses_across_data_parallel_group

# Custom loss function for the Megatron model
class GPTTrainStepWithCustomLoss(GPTTrainStep):
    def __init__(self, megatron_args, **kwargs):
        super().__init__(megatron_args)
        self.kwargs = kwargs

    def get_loss_func(self):
        def loss_func(inputs, loss_mask, output_tensor):
            batch_size, seq_length = output_tensor.shape
            losses = output_tensor.float()
            loss_mask = loss_mask.view(-1).float()
            loss = losses.view(-1) * loss_mask

            # Resize and average loss per sample
            loss_per_sample = loss.view(batch_size, seq_length).sum(axis=1)
            loss_mask_per_sample = loss_mask.view(batch_size, seq_length).sum(axis=1)
            loss_per_sample = loss_per_sample / loss_mask_per_sample

            # Calculate and scale weighting
            weights = torch.stack([(inputs == kt).float() for kt in self.kwargs["keytoken_ids"]]).sum(axis=[0, 2])
            weights = 1.0 + self.kwargs["alpha"] * weights
            # Calculate weighted average
            weighted_loss = (loss_per_sample * weights).mean()

            # Reduce loss across data parallel groups
            averaged_loss = avg_losses_across_data_parallel_group([weighted_loss])

            return weighted_loss, {"lm loss": averaged_loss[0]}

        return loss_func

    def get_forward_step_func(self):
        def forward_step(data_iterator, model):
            """Forward step."""
            # Get the batch.
            tokens, labels, loss_mask, attention_mask, position_ids = self.get_batch(data_iterator)
            output_tensor = model(tokens, position_ids, attention_mask, labels=labels)

            return output_tensor, partial(self.loss_func, tokens, loss_mask)

        return forward_step

def main():
    # Custom loss function for the Megatron model
    keytoken_ids = []
    keywords = ["plt", "pd", "sk", "fit", "predict", " plt", " pd", " sk", " fit", " predict"]
    for keyword in keywords:
        ids = tokenizer([keyword]).input_ids[0]
        if len(ids) == 1:
            keytoken_ids.append(ids[0])
    accelerator.print(f"Keytoken ids: {keytoken_ids}")
    accelerator.state.megatron_lm_plugin.custom_train_step_class = GPTTrainStepWithCustomLoss
    accelerator.state.megatron_lm_plugin.custom_train_step_kwargs = {
        "keytoken_ids": keytoken_ids,
        "alpha": 0.25,
    }
```

1.  要使用Megatron-LM数据集，需要进行一些更改。这些数据集的数据加载器仅在每个张量并行组的等级0上可用。因此，存在数据加载器不可用的等级，这需要对训练循环进行调整。能够做到这一点显示了🤗 Accelerate有多么灵活和可扩展。所需的更改如下。

a. 对于Megatron-LM索引数据集，我们需要使用`MegatronLMDummyDataLoader`并将所需的数据集参数传递给它，例如`data_path`、`seq_length`等。请参阅[此处](https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/arguments.py#L804)以获取可用参数的列表。

```py
from accelerate.utils import MegatronLMDummyDataLoader

megatron_dataloader_config = {
    "data_path": args.data_path,
    "splits_string": args.splits_string,
    "seq_length": args.block_size,
    "micro_batch_size": args.per_device_train_batch_size,
}
megatron_dataloader = MegatronLMDummyDataLoader(**megatron_dataloader_config)
accelerator.state.megatron_lm_plugin.megatron_dataset_flag = True
```

b. `megatron_dataloader`重复3次，以根据`args.splits_string`比例获取训练、验证和测试数据加载器。

```py
model, optimizer, lr_scheduler, train_dataloader, eval_dataloader, _ = accelerator.prepare(
    model, optimizer, lr_scheduler, megatron_dataloader, megatron_dataloader, megatron_dataloader
)
```

c. 由于数据加载器仅在张量并行等级0上可用，因此需要对训练和评估循环进行更改，因此我们只需要在数据加载器不是`None`时迭代，否则提供空字典。因此，我们使用`while`循环进行循环，并在`completed_steps`等于`args.max_train_steps`时中断。这类似于Megatron-LM设置，用户在使用Megaton-LM索引数据集时必须提供`max_train_steps`。这显示了🤗 Accelerate有多么灵活和可扩展。

```py
while completed_steps < args.max_train_steps:
    model.train()
    batch = next(train_dataloader) if train_dataloader is not None else {}
    outputs = model(**batch)
    loss = outputs.loss
    ...

    if completed_steps % eval_interval == 0:
        eval_completed_steps = 0
        losses = []
        while eval_completed_steps < eval_iters:
            model.eval()
            with torch.no_grad():
                batch = next(eval_dataloader) if eval_dataloader is not None else {}
                outputs = model(**batch)
```

## 用于检查点重塑和互操作性的实用程序

1.  这些脚本位于🤗 Transformers库中的相应模型下。目前，它适用于GPT模型[checkpoint_reshaping_and_interoperability.py](https://github.com/huggingface/transformers/blob/main/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py)

1.  以下是将检查点从Megatron-LM转换为通用🤗 Transformers分片检查点的示例。

```py
python checkpoint_reshaping_and_interoperability.py \
--convert_checkpoint_from_megatron_to_transformers \
--load_path "gpt/iter_0005000" \
--save_path "gpt/trfs_checkpoint" \
--max_shard_size "200MB" \
--tokenizer_name "gpt2" \
--print-checkpoint-structure
```

1.  将transformers的检查点转换为megatron，使用`tp_size=2`，`pp_size=2`和`dp_size=2`。

```py
python checkpoint_utils/megatgron_gpt2/checkpoint_reshaping_and_interoperability.py \
--load_path "gpt/trfs_checkpoint" \
--save_path "gpt/megatron_lm_checkpoint" \
--target_tensor_model_parallel_size 2 \
--target_pipeline_model_parallel_size 2 \
--target_data_parallel_size 2 \
--target_params_dtype "bf16" \
--make_vocab_size_divisible_by 128 \
--use_distributed_optimizer \
--print-checkpoint-structure
```

## Megatron-LM GPT模型支持返回对数和用于文本生成的megatron_generate函数

1.  返回对数需要在MegatronLMPlugin中设置`require_logits=True`，如下所示。这些将在管道的最后阶段可用。

```py
megatron_lm_plugin = MegatronLMPlugin(return_logits=True)
```

1.  Megatron-LM GPT模型的`megatron_generate`方法：当使用贪婪采样或不带top_k/top_p采样时，将使用张量和管道并行性来完成一批输入的生成，以及当使用波束搜索解码时，用于单个提示输入的生成。仅支持transformers generate的一部分功能。这将有助于通过张量和管道并行性使用大型模型进行生成（默认情况下已经进行了键值缓存并使用融合内核）。这需要将数据并行大小设置为1，禁用序列并行性和激活检查点。还需要指定分词器的词汇文件和合并文件的路径。下面的示例显示了如何配置和使用Megatron-LM GPT模型的`megatron_generate`方法。

```py
# specifying tokenizer's vocab and merges file
vocab_file = os.path.join(args.resume_from_checkpoint, "vocab.json")
merge_file = os.path.join(args.resume_from_checkpoint, "merges.txt")
other_megatron_args = {"vocab_file": vocab_file, "merge_file": merge_file}
megatron_lm_plugin = MegatronLMPlugin(other_megatron_args=other_megatron_args)

# inference using `megatron_generate` functionality
tokenizer.pad_token = tokenizer.eos_token
max_new_tokens = 64
batch_texts = [
    "Are you human?",
    "The purpose of life is",
    "The arsenal was constructed at the request of",
    "How are you doing these days?",
]
batch_encodings = tokenizer(batch_texts, return_tensors="pt", padding=True)

# top-p sampling
generated_tokens = model.megatron_generate(
    batch_encodings["input_ids"],
    batch_encodings["attention_mask"],
    max_new_tokens=max_new_tokens,
    top_p=0.8,
    top_p_decay=0.5,
    temperature=0.9,
)
decoded_preds = tokenizer.batch_decode(generated_tokens.cpu().numpy())
accelerator.print(decoded_preds)

# top-k sampling
generated_tokens = model.megatron_generate(
    batch_encodings["input_ids"],
    batch_encodings["attention_mask"],
    max_new_tokens=max_new_tokens,
    top_k=50,
    temperature=0.9,
)
decoded_preds = tokenizer.batch_decode(generated_tokens.cpu().numpy())
accelerator.print(decoded_preds)

# adding `bos` token at the start
generated_tokens = model.megatron_generate(
    batch_encodings["input_ids"], batch_encodings["attention_mask"], max_new_tokens=max_new_tokens, add_BOS=True
)
decoded_preds = tokenizer.batch_decode(generated_tokens.cpu().numpy())
accelerator.print(decoded_preds)

# beam search => only takes single prompt
batch_texts = ["The purpose of life is"]
batch_encodings = tokenizer(batch_texts, return_tensors="pt", padding=True)
generated_tokens = model.megatron_generate(
    batch_encodings["input_ids"],
    batch_encodings["attention_mask"],
    max_new_tokens=max_new_tokens,
    num_beams=20,
    length_penalty=1.5,
)
decoded_preds = tokenizer.batch_decode(generated_tokens.cpu().numpy())
accelerator.print(decoded_preds)
```

1.  有关在 Megatron-LM GPT 模型中使用 `megatron_generate` 方法的端到端示例，请参阅 [megatron_gpt2_generation.py](https://github.com/pacman100/accelerate-megatron-test/blob/main/src/inference/megatron_gpt2_generation.py)，配置文件为 [megatron_lm_gpt_generate_config.yaml](https://github.com/pacman100/accelerate-megatron-test/blob/main/src/Configs/megatron_lm_gpt_generate_config.yaml)。带有 accelerate launch 命令的 bash 脚本位于 [megatron_lm_gpt_generate.sh](https://github.com/pacman100/accelerate-megatron-test/blob/main/megatron_lm_gpt_generate.sh)。脚本的输出日志位于 [megatron_lm_gpt_generate.log](https://github.com/pacman100/accelerate-megatron-test/blob/main/output_logs/megatron_lm_gpt_generate.log)。

## 支持 ROPE 和 ALiBi 位置嵌入以及 Multi-Query Attention

1.  对于 ROPE/ALiBi 注意力，将 `position_embedding_type` 与 `("absolute" | "rotary" | "alibi")` 传递给 `MegatronLMPlugin`，如下所示。

```py
other_megatron_args = {"position_embedding_type": "alibi"}
megatron_lm_plugin = MegatronLMPlugin(other_megatron_args=other_megatron_args)
```

1.  对于 Multi-Query Attention，将 `attention_head_type` 与 `("multihead" | "multiquery")` 传递给 `MegatronLMPlugin`，如下所示。

```py
other_megatron_args = {"attention_head_type": "multiquery"}
megatron_lm_plugin = MegatronLMPlugin(other_megatron_args=other_megatron_args)
```

## 注意事项

1.  支持 Transformers GPT2、Megatron-BERT 和 T5 模型。这涵盖了仅解码器、仅编码器和编码器-解码器模型类。

1.  由于管道、张量和数据并行背后存在相当复杂的相互作用，因此仅从模型前向传递中返回损失。`model(**batch_data)` 调用返回跨数据并行等级平均的损失。这对于大多数情况是可以的，其中使用 Megatron-LM 功能运行预训练作业，并且可以轻松使用损失计算 `perplexity`。对于 GPT 模型，除了损失之外还支持返回 logits。这些 logits 不会在数据并行等级之间收集。使用 `accelerator.utils.gather_across_data_parallel_groups` 来收集跨数据并行等级的 logits。这些 logits 以及标签可用于计算各种性能指标。

1.  主进程是最后一个等级，因为损失/Logits 在管道的最后阶段可用。在使用 Megatron-LM 集成时，`accelerator.is_main_process` 和 `accelerator.is_local_main_process` 在最后一个等级返回 `True`。

1.  在 `accelerator.prepare` 调用中，将为给定的 Transformers 模型创建一个具有随机权重的 Megatron-LM 模型。请使用 `accelerator.load_state` 加载具有匹配 TP、PP 和 DP 分区的 Megatron-LM 检查点。

1.  目前，检查点重塑和互操作性支持仅适用于 GPT。很快将扩展到 BERT 和 T5。

1.  `gradient_accumulation_steps` 需要为 1。在使用 Megatron-LM 时，管道并行设置中的微批次等同于梯度累积。

1.  在使用 Megatron-LM 时，请使用 `accelerator.save_state` 和 `accelerator.load_state` 来保存和加载检查点。

1.  以下是从 Megatron-LM 模型架构到等效 🤗 transformers 模型架构的映射。仅支持这些 🤗 transformers 模型架构。

a. Megatron-LM [BertModel](https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/bert_model.py)：🤗 transformers 模型中配置为 `megatron-bert` 的模型类型，例如 [MegatronBERT](https://huggingface.co/docs/transformers/model_doc/megatron-bert)

b. Megatron-LM [GPTModel](https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/gpt_model.py)：🤗 transformers 模型中配置为 `gpt2` 的模型类型，例如 [OpenAI GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)

c. Megatron-LM [T5Model](https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/t5_model.py)：🤗 transformers 模型中配置为 `t5` 的模型类型，例如 [T5](https://huggingface.co/docs/transformers/model_doc/t5) 和 [MT5](https://huggingface.co/docs/transformers/model_doc/mt5)
