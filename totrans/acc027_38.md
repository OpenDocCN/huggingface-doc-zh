# 加速器

> 原始文本：[`huggingface.co/docs/accelerate/package_reference/accelerator`](https://huggingface.co/docs/accelerate/package_reference/accelerator)

Accelerator 是🤗 Accelerate 提供的主要类。它作为 API 的主要入口点。

## 代码的快速适应

将脚本快速适应任何类型的设置与🤗 Accelerate 一起工作只需：

1.  尽早在脚本中初始化一个 Accelerator 对象（我们将在本页中称之为`accelerator`）。

1.  将您的数据加载器、模型、优化器和调度器传递给 prepare()方法。

1.  从您的代码中删除所有`.cuda()`或`.to(device)`，让`accelerator`为您处理设备放置。

第三步是可选的，但被认为是最佳实践。

1.  在您的代码中用`accelerator.backward(loss)`替换`loss.backward()`

1.  在存储或使用预测和标签之前，使用 gather()来收集它们，以进行度量计算。

在进行分布式评估时，第五步是强制的

在大多数情况下，这就是所需的。下一节列出了一些更高级的用例和您应该搜索并替换为`accelerator`相应方法的一些不错的功能：

## 高级建议

### 打印

将`print`语句替换为 print()以每个进程打印一次：

```py
- print("My thing I want to print!")
+ accelerator.print("My thing I want to print!")
```

### 执行进程

#### 一次在单个服务器上

对于应在每台服务器上执行一次的语句，使用`is_local_main_process`：

```py
if accelerator.is_local_main_process:
    do_thing_once_per_server()
```

可以使用 on_local_main_process()函数来包装函数，以在函数执行时实现相同的行为：

```py
@accelerator.on_local_main_process
def do_my_thing():
    "Something done once per server"
    do_thing_once_per_server()
```

#### 在所有服务器上仅一次

对于应仅执行一次的语句，使用`is_main_process`：

```py
if accelerator.is_main_process:
    do_thing_once()
```

可以使用 on_main_process()函数来包装函数，以在函数执行时实现相同的行为：

```py
@accelerator.on_main_process
def do_my_thing():
    "Something done once per server"
    do_thing_once()
```

#### 在特定进程上

如果函数应在特定的整体或本地进程索引上运行，有类似的装饰器可实现此目的：

```py
@accelerator.on_local_process(local_process_idx=0)
def do_my_thing():
    "Something done on process index 0 on each server"
    do_thing_on_index_zero_on_each_server()
```

```py
@accelerator.on_process(process_index=0)
def do_my_thing():
    "Something done on process index 0"
    do_thing_on_index_zero()
```

### 同步控制

使用 wait_for_everyone()确保所有进程在继续之前加入该点。（例如，在保存模型之前很有用）。

### 保存和加载

```py
model = MyModel()
model = accelerator.prepare(model)
```

使用 save_model()代替`torch.save`来保存模型。它将删除在分布式过程中添加的所有模型包装器，获取模型的 state_dict 并保存它。state_dict 将与正在训练的模型具有相同的精度。

```py
- torch.save(state_dict, "my_state.pkl")
+ accelerator.save_model(model, save_directory)
```

save_model()还可以将模型保存为分片检查点或使用 safetensors 格式。这里是一个示例：

```py
accelerator.save_model(model, save_directory, max_shard_size="1GB", safe_serialization=True)
```

#### 🤗 Transformers 模型

如果您正在使用[🤗 Transformers](https://huggingface.co/docs/transformers/)库中的模型，可以使用`.save_pretrained()`方法。

```py
from transformers import AutoModel

model = AutoModel.from_pretrained("bert-base-cased")
model = accelerator.prepare(model)

# ...fine-tune with PyTorch...

unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(
    "path/to/my_model_directory",
    is_main_process=accelerator.is_main_process,
    save_function=accelerator.save,
)
```

这将确保您的模型与其他🤗 Transformers 功能保持兼容，如`.from_pretrained()`方法。

```py
from transformers import AutoModel

model = AutoModel.from_pretrained("path/to/my_model_directory")
```

### 操作

使用 clip*grad_norm*()代替`torch.nn.utils.clip_grad_norm_`，并使用 clip*grad_value*()代替`torch.nn.utils.clip_grad_value`

### 梯度累积

要执行梯度累积，请使用 accumulate()并指定 gradient_accumulation_steps。这也将自动确保在多设备训练时同步或异步梯度，检查是否实际执行步骤，并自动缩放损失：

```py
- accelerator = Accelerator()
+ accelerator = Accelerator(gradient_accumulation_steps=2)

  for (input, label) in training_dataloader:
+     with accelerator.accumulate(model):
          predictions = model(input)
          loss = loss_function(predictions, labels)
          accelerator.backward(loss)
          optimizer.step()
          scheduler.step()
          optimizer.zero_grad()
```

#### GradientAccumulationPlugin

### `class accelerate.utils.GradientAccumulationPlugin`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/utils/dataclasses.py#L505)

```py
( num_steps: int = None adjust_scheduler: bool = True sync_with_dataloader: bool = True )
```

一个用于配置梯度累积行为的插件。

不要传递`gradient_accumulation_steps`，您可以实例化一个 GradientAccumulationPlugin 并将其传递给 Accelerator 的`__init__`作为`gradient_accumulation_plugin`。您只能传递`gradient_accumulation_plugin`或`gradient_accumulation_steps`中的一个，传递两者将引发错误。

```py
from accelerate.utils import GradientAccumulationPlugin

gradient_accumulation_plugin = GradientAccumulationPlugin(num_steps=2)
- accelerator = Accelerator()
+ accelerator = Accelerator(gradient_accumulation_plugin=gradient_accumulation_plugin)
```

除了步数之外，这还让您配置是否调整学习率调度程序以考虑由于累积而导致的步骤变化。

## 总体 API 文档：

### `class accelerate.Accelerator`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L153)

```py
( device_placement: bool = True split_batches: bool = False mixed_precision: PrecisionType | str | None = None gradient_accumulation_steps: int = 1 cpu: bool = False deepspeed_plugin: DeepSpeedPlugin | None = None fsdp_plugin: FullyShardedDataParallelPlugin | None = None megatron_lm_plugin: MegatronLMPlugin | None = None rng_types: list[str | RNGType] | None = None log_with: str | LoggerType | GeneralTracker | list[str | LoggerType | GeneralTracker] | None = None project_dir: str | os.PathLike | None = None project_config: ProjectConfiguration | None = None gradient_accumulation_plugin: GradientAccumulationPlugin | None = None dispatch_batches: bool | None = None even_batches: bool = True use_seedable_sampler: bool = False step_scheduler_with_optimizer: bool = True kwargs_handlers: list[KwargsHandler] | None = None dynamo_backend: DynamoBackend | str | None = None )
```

参数

+   `device_placement` (`bool`, *optional*, 默认为`True`) — 加速器是否应该将对象放在设备上（数据加载器产生的张量，模型等）。

+   `split_batches` (`bool`, *optional*, 默认为`False`) — 加速器是否应该将数据加载器产生的批次分配到不同的设备上。如果为`True`，实际使用的批次大小将在任何类型的分布式进程上相同，但必须是您使用的`num_processes`的圆倍数。如果为`False`，实际使用的批次大小将是脚本中设置的批次大小乘以进程数。

+   `mixed_precision` (`str`, *optional*) — 是否使用混合精度训练。选择‘no’、‘fp16’、‘bf16’或‘fp8’。将默认为环境变量`ACCELERATE_MIXED_PRECISION`中的值，该值将使用当前系统的加速配置中的默认值或使用`accelerate.launch`命令传递的标志。‘fp8’需要安装 transformers-engine。

+   `gradient_accumulation_steps` (`int`, *optional*, default to 1) — 在梯度累积之前应该经过的步数。数字大于 1 应该与`Accelerator.accumulate`结合使用。如果未传递，则默认为环境变量`ACCELERATE_GRADIENT_ACCUMULATION_STEPS`中的值。也可以通过`GradientAccumulationPlugin`进行配置。

+   `cpu` (`bool`, *optional*) — 是否强制脚本在 CPU 上执行。如果设置为`True`，将忽略 GPU 的可用性，并强制在一个进程上执行。

+   `deepspeed_plugin` (`DeepSpeedPlugin`, *optional*) — 使用此参数调整您的 DeepSpeed 相关参数。此参数是可选的，可以直接使用*accelerate config*进行配置。

+   `fsdp_plugin` (`FullyShardedDataParallelPlugin`, *optional*) — 使用此参数调整您的 FSDP 相关参数。此参数是可选的，可以直接使用*accelerate config*进行配置。

+   `megatron_lm_plugin` (`MegatronLMPlugin`, *optional*) — 使用此参数调整您的 MegatronLM 相关参数。此参数是可选的，可以直接使用*accelerate config*进行配置。

+   `rng_types`（`str`列表或 RNGType）— 在准备好的数据加载器的每次迭代开始时要同步的随机数生成器列表。应该是以下之一或几个：

    +   `"torch"`：基本 torch 随机数生成器

    +   `"cuda"`：CUDA 随机数生成器（仅限 GPU）

    +   `"xla"`：XLA 随机数生成器（仅限 TPU）

    +   `"generator"`：采样器的`torch.Generator`（如果数据加载器中没有采样器，则为批次采样器）或可迭代数据集（如果存在）的生成器（如果基础数据集是该类型）。

    对于 PyTorch 版本<=1.5.1，默认为`["torch"]`，对于 PyTorch 版本>= 1.6，默认为`["generator"]`。

+   `log_with`（`str`列表，LoggerType 或 GeneralTracker，*可选*）— 要为实验跟踪设置的记录器列表。应该是以下之一或几个：

    +   `"all"`

    +   `"tensorboard"`

    +   `"wandb"`

    +   `"comet_ml"` 如果选择`"all"`，将捡起环境中所有可用的跟踪器并初始化它们。还可以接受`GeneralTracker`的自定义跟踪器的实现，并且可以与`"all"`组合使用。

+   `project_config`（`ProjectConfiguration`，*可选*）— 用于处理状态保存的配置。

+   `project_dir`（`str`，`os.PathLike`，*可选*）— 用于存储数据的目录路径，例如本地兼容日志记录器的日志和可能的保存检查点。

+   `dispatch_batches`（`bool`，*可选*）— 如果设置为`True`，则由加速器准备的数据加载器仅在主进程上进行迭代，然后将批次分割并广播到每个进程。对于其基础数据集为`IterableDataset`的`DataLoader`，默认为`True`，否则为`False`。

+   `even_batches`（`bool`，*可选*，默认为`True`）— 如果设置为`True`，在所有进程的总批次大小不能完全整除数据集的情况下，数据集开头的样本将被复制，以便批次可以在所有工作进程之间均匀分配。

+   `use_seedable_sampler`（`bool`，*可选*，默认为`False`）— 是否使用完全可种子的随机采样器（`SeedableRandomSampler`）。确保使用不同的采样技术时训练结果是完全可重现的。虽然种子到种子的结果可能不同，但平均而言，使用多个不同的种子进行比较时差异微不足道。每次都应该与 set_seed()一起运行以获得最佳结果。

+   `step_scheduler_with_optimizer`（`bool`，*可选*，默认为`True`）-- 如果学习率调度程序与优化器同时进行步进，则设置为`True`，如果仅在某些情况下进行（例如在每个时期结束时），则设置为`False`。

+   `kwargs_handlers`（`list[KwargHandler]`，*可选*）— 用于自定义与分布式训练或混合精度相关的对象如何创建的`KwargHandler`列表。有关更多信息，请参阅 kwargs。

+   `dynamo_backend`（`str`或`DynamoBackend`，*可选*，默认为`"no"`）— 设置为可能的 dynamo 后端之一，以优化使用 torch dynamo 进行训练。

+   `gradient_accumulation_plugin`（`GradientAccumulationPlugin`，*可选*）— 用于处理梯度累积的配置，如果需要比仅使用`gradient_accumulation_steps`更多的调整。

创建一个用于分布式训练（在多 GPU、TPU 上）或混合精度训练的加速器实例。

**可用属性：**

+   `device`（`torch.device`）— 要使用的设备。

+   `distributed_type`（DistributedType）— 分布式训练配置。

+   `local_process_index`（`int`）— 当前机器上的进程索引。

+   `mixed_precision`（`str`）-配置的混合精度模式。

+   `num_processes`（`int`）-用于训练的进程总数。

+   `optimizer_step_was_skipped`（`bool`）-是否跳过了优化器更新（因为在混合精度中梯度溢出），在这种情况下学习率不应该改变。

+   `process_index`（`int`）-当前进程在所有进程中的总体索引。

+   `state`（AcceleratorState）-分布式设置状态。

+   `sync_gradients`（`bool`）-当前是否正在跨所有进程同步梯度。

+   `use_distributed`（`bool`）-当前配置是否用于分布式训练。

#### `accumulate`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L967)

```py
( *models )
```

参数

+   `*models`（`torch.nn.Module`列表）-使用`Accelerator.prepare`准备的 PyTorch 模块。传递给`accumulate()`的模型将在分布式训练中的反向传递期间跳过梯度同步

一个上下文管理器，将轻松包装并自动执行梯度累积

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(gradient_accumulation_steps=1)
>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)

>>> for input, output in dataloader:
...     with accelerator.accumulate(model):
...         outputs = model(input)
...         loss = loss_func(outputs)
...         loss.backward()
...         optimizer.step()
...         scheduler.step()
...         optimizer.zero_grad()
```

#### `autocast`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3109)

```py
( cache_enabled: bool = False autocast_handler: AutocastKwargs = None )
```

如果启用，将在此上下文管理器内部的块中应用自动混合精度。否则不会发生任何不同。

可以传入不同的`autocast_handler`来覆盖`Accelerator`对象中设置的处理程序。这在`autocast`下的块中很有用，您想要恢复到 fp32。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(mixed_precision="fp16")
>>> with accelerator.autocast():
...     train()
```

#### `backward`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1938)

```py
( loss **kwargs )
```

根据`GradientAccumulationPlugin`缩放梯度，并根据配置调用正确的`backward()`。

应该用来代替`loss.backward()`。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(gradient_accumulation_steps=2)
>>> outputs = model(inputs)
>>> loss = loss_fn(outputs, labels)
>>> accelerator.backward(loss)
```

#### `check_trigger`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1994)

```py
( )
```

检查内部触发张量是否在任何进程中设置为 1。如果是，则将返回`True`并将触发张量重置为 0。

注意：不需要`wait_for_everyone()`

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume later in the training script
>>> # `should_do_breakpoint` is a custom function to monitor when to break,
>>> # e.g. when the loss is NaN
>>> if should_do_breakpoint(loss):
...     accelerator.set_trigger()
>>> # Assume later in the training script
>>> if accelerator.check_trigger():
...     break
```

#### `clear`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2973)

```py
( )
```

别名为`Accelerate.free_memory`，释放所有对存储的内部对象的引用并调用垃圾回收器。您应该在两个具有不同模型/优化器的训练之间调用此方法。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer, scheduler = ...
>>> model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)
>>> accelerator.free_memory()
>>> del model, optimizer, scheduler
```

#### `clip_grad_norm_`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2066)

```py
( parameters max_norm norm_type = 2 ) → export const metadata = 'undefined';torch.Tensor
```

返回

`torch.Tensor`

参数梯度的总范数（视为单个向量）。

应该用来代替`torch.nn.utils.clip_grad_norm_`。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(gradient_accumulation_steps=2)
>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)

>>> for input, target in dataloader:
...     optimizer.zero_grad()
...     output = model(input)
...     loss = loss_func(output, target)
...     accelerator.backward(loss)
...     if accelerator.sync_gradients:
...         accelerator.clip_grad_norm_(model.parameters(), max_grad_norm)
...     optimizer.step()
```

#### `clip_grad_value_`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2104)

```py
( parameters clip_value )
```

应该用来代替`torch.nn.utils.clip_grad_value_`。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(gradient_accumulation_steps=2)
>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)

>>> for input, target in dataloader:
...     optimizer.zero_grad()
...     output = model(input)
...     loss = loss_func(output, target)
...     accelerator.backward(loss)
...     if accelerator.sync_gradients:
...         accelerator.clip_grad_value_(model.parameters(), clip_value)
...     optimizer.step()
```

#### `free_memory`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2948)

```py
( )
```

将释放所有对存储的内部对象的引用并调用垃圾回收器。您应该在两个具有不同模型/优化器的训练之间调用此方法。还将`Accelerator.step`重置为 0。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer, scheduler = ...
>>> model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)
>>> accelerator.free_memory()
>>> del model, optimizer, scheduler
```

#### `gather`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2131)

```py
( tensor ) → export const metadata = 'undefined';torch.Tensor, or a nested tuple/list/dictionary of torch.Tensor
```

参数

+   `tensor`（`torch.Tensor`，或`torch.Tensor`的嵌套元组/列表/字典）-要在所有进程中收集的张量。

返回

`torch.Tensor`，或`torch.Tensor`的嵌套元组/列表/字典

收集的张量。请注意，结果的第一个维度是* num_processes *乘以输入张量的第一个维度。

收集*张量*在所有进程中的值，并在第一维上将它们连接起来。在进行评估时，有助于重新组合所有进程的预测。

注意：此收集在所有进程中发生。

示例:

```py
>>> # Assuming four processes
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> process_tensor = torch.tensor([accelerator.process_index])
>>> gathered_tensor = accelerator.gather(process_tensor)
>>> gathered_tensor
tensor([0, 1, 2, 3])
```

#### `gather_for_metrics`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2163)

```py
( input_data )
```

参数

+   `input` (`torch.Tensor`, `object`, `torch.Tensor`的嵌套元组/列表/字典，或`object`的嵌套元组/列表/字典) — 用于计算所有进程间指标的张量或对象

收集`input_data`并在分布式系统上可能删除最后一批中的重复项。应用于收集用于指标计算的输入和目标。

示例:

```py
>>> # Assuming two processes, with a batch size of 5 on a dataset with 9 samples
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> dataloader = torch.utils.data.DataLoader(range(9), batch_size=5)
>>> dataloader = accelerator.prepare(dataloader)
>>> batch = next(iter(dataloader))
>>> gathered_items = accelerator.gather_for_metrics(batch)
>>> len(gathered_items)
9
```

#### `get_state_dict`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3017)

```py
( model unwrap = True ) → export const metadata = 'undefined';dict
```

参数

+   `model` (`torch.nn.Module`) — 通过 Accelerator.prepare()发送的 PyTorch 模型

+   `unwrap` (`bool`, *可选*, 默认为`True`) — 是否返回`model`的原始底层`state_dict`或返回包装的`state_dict`

返回

`dict`

模型的状态字典，可能不是完全精确。

返回通过 Accelerator.prepare()发送的模型的状态字典，可能不是完全精确。

示例:

```py
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> net = torch.nn.Linear(2, 2)
>>> net = accelerator.prepare(net)
>>> state_dict = accelerator.get_state_dict(net)
```

#### `get_tracker`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2400)

```py
( name: str unwrap: bool = False ) → export const metadata = 'undefined';GeneralTracker
```

参数

+   `name` (`str`) — 一个跟踪器的名称，对应于`.name`属性。

+   `unwrap` (`bool`) — 是否返回内部跟踪机制或返回包装的跟踪器（推荐）。

返回

`GeneralTracker`

如果存在，则返回与`name`对应的跟踪器。

仅在主进程上基于`name`从`self.trackers`返回一个`tracker`。

示例:

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(log_with="tensorboard")
>>> accelerator.init_trackers("my_project")
>>> tensorboard_tracker = accelerator.get_tracker("tensorboard")
```

#### `join_uneven_inputs`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1001)

```py
( joinables even_batches = None )
```

参数

+   `joinables` (`list[torch.distributed.algorithms.Joinable]`) — 一个子类为`torch.distributed.algorithms.Joinable`的模型或优化器列表。最常见的是，使用`Accelerator.prepare`为分布式数据并行训练准备的 PyTorch 模块。

+   `even_batches` (`bool`, *可选*) — 如果设置，这将覆盖在`Accelerator`中设置的`even_batches`的值。如果未提供，则将使用默认的`Accelerator`值。

一个上下文管理器，用于在不均匀输入上进行分布式训练或评估，作为`torch.distributed.algorithms.join`周围的包装器。当总批量大小不能完全整除数据集的长度时，这是有用的。

`join_uneven_inputs`仅支持在多个 GPU 上进行分布式数据并行训练。对于任何其他配置，此方法将不起作用。

覆盖`even_batches`不会影响可迭代样式的数据加载器。

示例:

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator(even_batches=True)
>>> ddp_model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)

>>> with accelerator.join_uneven_inputs([ddp_model], even_batches=False):
...     for input, output in dataloader:
...         outputs = model(input)
...         loss = loss_func(outputs)
...         loss.backward()
...         optimizer.step()
...         optimizer.zero_grad()
```

#### `load_state`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2816)

```py
( input_dir: str = None **load_model_func_kwargs )
```

参数

+   `input_dir` (`str`或`os.PathLike`) — 所有相关权重和状态保存在的文件夹的名称。如果使用`automatic_checkpoint_naming`，则可以为`None`，并将从最新的检查点中获取。

+   `load_model_func_kwargs` (`dict`, *可选*) — 用于加载模型的附加关键字参数，可以传递给底层加载函数，例如 DeepSpeed 的`load_checkpoint`函数的可选参数或`map_location`以加载模型和优化器。

加载模型、优化器、缩放器、RNG 生成器和已注册对象的当前状态。

应该与 Accelerator.save_state() 结合使用。如果未注册用于检查点的文件，则如果存储在目录中，则不会加载。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer, lr_scheduler = ...
>>> model, optimizer, lr_scheduler = accelerator.prepare(model, optimizer, lr_scheduler)
>>> accelerator.load_state("my_checkpoint")
```

#### `local_main_process_first`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L830)

```py
( )
```

让本地主进程在 with 块内执行。

其他进程将在主进程退出后进入 with 块。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> with accelerator.local_main_process_first():
...     # This will be printed first by local process 0 then in a seemingly
...     # random order by the other processes.
...     print(f"This will be printed by process {accelerator.local_process_index}")
```

#### `main_process_first`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L808)

```py
( )
```

让主进程在 with 块内先执行。

其他进程将在主进程退出后进入 with 块。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> with accelerator.main_process_first():
...     # This will be printed first by process 0 then in a seemingly
...     # random order by the other processes.
...     print(f"This will be printed by process {accelerator.process_index}")
```

#### `no_sync`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L852)

```py
( model )
```

参数

+   `model` (`torch.nn.Module`) — 使用 `Accelerator.prepare` 准备的 PyTorch 模块。

一个上下文管理器，通过调用 `torch.nn.parallel.DistributedDataParallel.no_sync` 来禁用 DDP 进程之间的梯度同步。

如果 `model` 不在 DDP 中，则此上下文管理器不起作用

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> dataloader, model, optimizer = accelerator.prepare(dataloader, model, optimizer)
>>> input_a = next(iter(dataloader))
>>> input_b = next(iter(dataloader))

>>> with accelerator.no_sync():
...     outputs = model(input_a)
...     loss = loss_func(outputs)
...     accelerator.backward(loss)
...     # No synchronization across processes, only accumulate gradients
>>> outputs = model(input_b)
>>> accelerator.backward(loss)
>>> # Synchronization across all processes
>>> optimizer.step()
>>> optimizer.zero_grad()
```

#### `on_last_process`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L676)

```py
( function: Callable[..., Any] )
```

参数

+   `function` (`Callable`) — 要装饰的函数。

一个装饰器，只会在最后一个进程上运行装饰的函数。也可以使用 `PartialState` 类调用。

示例：

```py
# Assume we have 4 processes.
from accelerate import Accelerator

accelerator = Accelerator()

@accelerator.on_last_process
def print_something():
    print(f"Printed on process {accelerator.process_index}")

print_something()
"Printed on process 3"
```

#### `on_local_main_process`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L634)

```py
( function: Callable[..., Any] = None )
```

参数

+   `function` (`Callable`) — 要装饰的函数。

一个装饰器，只会在本地主进程上运行装饰的函数。也可以使用 `PartialState` 类调用。

示例：

```py
# Assume we have 2 servers with 4 processes each.
from accelerate import Accelerator

accelerator = Accelerator()

@accelerator.on_local_main_process
def print_something():
    print("This will be printed by process 0 only on each server.")

print_something()
# On server 1:
"This will be printed by process 0 only"
# On server 2:
"This will be printed by process 0 only"
```

#### `on_local_process`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L760)

```py
( function: Callable[..., Any] = None local_process_index: int = None )
```

参数

+   `function` (`Callable`, *可选*) — 要装饰的函数。

+   `local_process_index` (`int`, *可选*) — 要运行函数的本地进程的索引。

一个装饰器，只会在给定的本地进程索引上运行装饰的函数。也可以使用 `PartialState` 类调用。

示例：

```py
# Assume we have 2 servers with 4 processes each.
from accelerate import Accelerator

accelerator = Accelerator()

@accelerator.on_local_process(local_process_index=2)
def print_something():
    print(f"Printed on process {accelerator.local_process_index}")

print_something()
# On server 1:
"Printed on process 2"
# On server 2:
"Printed on process 2"
```

#### `on_main_process`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L595)

```py
( function: Callable[..., Any] = None )
```

参数

+   `function` (`Callable`) — 要装饰的函数。

一个装饰器，只会在主进程上运行装饰的函数。也可以使用 `PartialState` 类调用。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()

>>> @accelerator.on_main_process
... def print_something():
...     print("This will be printed by process 0 only.")

>>> print_something()
"This will be printed by process 0 only"
```

#### `on_process`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L715)

```py
( function: Callable[..., Any] = None process_index: int = None )
```

参数

+   `function` (`Callable`, `可选`) — 要装饰的函数。

+   `process_index` (`int`, `可选`) — 要运行函数的进程的索引。

一个装饰器，只会在给定的进程索引上运行装饰的函数。也可以使用 `PartialState` 类调用。

示例：

```py
# Assume we have 4 processes.
from accelerate import Accelerator

accelerator = Accelerator()

@accelerator.on_process(process_index=2)
def print_something():
    print(f"Printed on process {accelerator.process_index}")

print_something()
"Printed on process 2"
```

#### `pad_across_processes`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2261)

```py
( tensor dim = 0 pad_index = 0 pad_first = False ) → export const metadata = 'undefined';torch.Tensor, or a nested tuple/list/dictionary of torch.Tensor
```

参数

+   `tensor`（`torch.Tensor`的嵌套列表/元组/字典） — 要收集的数据。

+   `dim` (`int`, *可选*, 默认为 0) — 要填充的维度。

+   `pad_index` (`int`, *可选*, 默认为 0) — 用于填充的值。

+   `pad_first` (`bool`, *可选*, 默认为 `False`) — 是否在开头或结尾填充。

返回

`torch.Tensor`，或 `torch.Tensor` 的嵌套元组/列表/字典

填充后的张量。

递归填充嵌套列表/元组/张量字典中的张量，使它们可以安全地被收集到相同的大小。

示例：

```py
>>> # Assuming two processes, with the first processes having a tensor of size 1 and the second of size 2
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> process_tensor = torch.arange(accelerator.process_index + 1).to(accelerator.device)
>>> padded_tensor = accelerator.pad_across_processes(process_tensor)
>>> padded_tensor.shape
torch.Size([2])
```

#### `prepare`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1116)

```py
( *args device_placement = None )
```

参数

+   `*args`（对象列表） — 以下类型的任何对象：

    +   `torch.utils.data.DataLoader`: PyTorch 数据加载器

    +   `torch.nn.Module`: PyTorch 模块

    +   `torch.optim.Optimizer`: PyTorch 优化器

    +   `torch.optim.lr_scheduler.LRScheduler`: PyTorch LR 调度程序

+   `device_placement` (`list[bool]`, *可选*) — 用于自定义是否应为传递的每个对象执行自动设备放置。需要与 `args` 长度相同的列表。与 DeepSpeed 或 FSDP 不兼容。

准备传递的所有对象进行分布式训练和混合精度，然后以相同顺序返回它们。

如果仅用于推断而不涉及任何混合精度，则无需准备模型

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume a model, optimizer, data_loader and scheduler are defined
>>> model, optimizer, data_loader, scheduler = accelerator.prepare(model, optimizer, data_loader, scheduler)
```

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume a model, optimizer, data_loader and scheduler are defined
>>> device_placement = [True, True, False, False]
>>> # Will place the first to items passed in automatically to the right device but not the last two.
>>> model, optimizer, data_loader, scheduler = accelerator.prepare(
...     model, optimizer, data_loader, scheduler, device_placement=device_placement
... )
```

#### `prepare_data_loader`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1812)

```py
( data_loader: torch.utils.data.DataLoader device_placement = None slice_fn_for_dispatch = None )
```

参数

+   `data_loader` (`torch.utils.data.DataLoader`) — 一个普通的 PyTorch 数据加载器要准备

+   `device_placement` (`bool`, *可选*) — 是否将批次放置在准备好的数据加载器中的正确设备上。默认为 `self.device_placement`。

+   `slice_fn_for_dispatch` (`Callable`, *可选*`) -- 如果传递，将使用此函数在` num_processes`上切片张量。默认为 slice_tensors()。此参数仅在` dispatch_batches`设置为`True`时使用，否则将被忽略。

为在任何分布式设置中训练准备一个 PyTorch 数据加载器。建议使用 Accelerator.prepare()代替。

示例：

```py
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> data_loader = torch.utils.data.DataLoader(...)
>>> data_loader = accelerator.prepare_data_loader(data_loader, device_placement=True)
```

#### `prepare_model`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1252)

```py
( model: torch.nn.Module device_placement: bool = None evaluation_mode: bool = False )
```

参数

+   `model` (`torch.nn.Module`) — 一个要准备的 PyTorch 模型。如果仅用于推断而不涉及任何混合精度，则无需准备模型

+   `device_placement` (`bool`, *可选*) — 是否将模型放置在正确的设备上。默认为 `self.device_placement`。

+   `evaluation_mode` (`bool`, *可选*, 默认为 `False`) — 是否仅将模型设置为评估模式，只需应用混合精度和 `torch.compile`（如果在 `Accelerator` 对象中配置）。

为在任何分布式设置中训练准备一个 PyTorch 模型。建议使用 Accelerator.prepare()代替。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume a model is defined
>>> model = accelerator.prepare_model(model)
```

#### `prepare_optimizer`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1864)

```py
( optimizer: torch.optim.Optimizer device_placement = None )
```

参数

+   `optimizer` (`torch.optim.Optimizer`) — 一个普通的 PyTorch 优化器要准备

+   `device_placement` (`bool`, *可选*) — 是否将优化器放置在正确的设备上。默认为 `self.device_placement`。

为在任何分布式设置中训练准备一个 PyTorch 优化器。建议使用 Accelerator.prepare()代替。

示例：

```py
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> optimizer = torch.optim.Adam(...)
>>> optimizer = accelerator.prepare_optimizer(optimizer, device_placement=True)
```

#### `prepare_scheduler`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1897)

```py
( scheduler: LRScheduler )
```

参数

+   `scheduler` (`torch.optim.lr_scheduler.LRScheduler`) — 要准备的一个普通的 PyTorch 调度程序

为在任何分布式设置中训练准备一个 PyTorch 调度程序。建议使用 Accelerator.prepare()代替。

示例：

```py
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> optimizer = torch.optim.Adam(...)
>>> scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, ...)
>>> scheduler = accelerator.prepare_scheduler(scheduler)
```

#### `print`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1084)

```py
( *args **kwargs )
```

`print()`的替代方法，每个服务器只打印一次。

示例:

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> accelerator.print("Hello world!")
```

#### `reduce`

[< source >](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2225)

```py
( tensor reduction = 'sum' scale = 1.0 ) → export const metadata = 'undefined';torch.Tensor, or a nested tuple/list/dictionary of torch.Tensor
```

参数

+   `tensor`（`torch.Tensor`，或`torch.Tensor`的嵌套元组/列表/字典）— 要在所有进程中减少的张量。

+   `reduction`（`str`，*可选*，默认为“sum”）— 减少类型，可以是“sum”、“mean”或“none”中的一个。如果是“none”，则不执行任何操作。

+   `scale`（`float`，*可选*，默认为 1.0）— 在减少后应用的默认缩放值，仅在 XLA 上有效。

返回

`torch.Tensor`，或`torch.Tensor`的嵌套元组/列表/字典

减少的张量。

根据*reduction*在*张量*中减少所有进程中的值。

注意：所有进程都会得到减少的值。

示例：

```py
>>> # Assuming two processes
>>> import torch
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> process_tensor = torch.arange(accelerator.num_processes) + 1 + (2 * accelerator.process_index)
>>> process_tensor = process_tensor.to(accelerator.device)
>>> reduced_tensor = accelerator.reduce(process_tensor, reduction="sum")
>>> reduced_tensor
tensor([4, 6])
```

#### `register_for_checkpointing`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3073)

```py
( *objects )
```

注意`objects`并将在`save_state`或`load_state`期间保存或加载它们。

这些应该在相同脚本中加载或保存状态时使用。不应该在不同脚本中使用。

每个`object`必须有一个`load_state_dict`和`state_dict`函数以进行存储。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume `CustomObject` has a `state_dict` and `load_state_dict` function.
>>> obj = CustomObject()
>>> accelerator.register_for_checkpointing(obj)
>>> accelerator.save_state("checkpoint.pt")
```

#### `register_load_state_pre_hook`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2785)

```py
( hook: Callable[..., None] ) → export const metadata = 'undefined';torch.utils.hooks.RemovableHandle
```

参数

+   `hook`（`Callable`）— 在 Accelerator.load_state()之前调用的函数，用于`load_checkpoint`。

返回

`torch.utils.hooks.RemovableHandle`

一个句柄，可以通过调用`handle.remove()`来移除添加的钩子

注册一个预钩子，在 Accelerator.load_state()中调用`load_checkpoint`之前运行。

钩子应该具有以下签名:

`hook(models: list[torch.nn.Module], input_dir: str) -> None`

`models`参数是保存在加速器状态下的模型`accelerator._models`，`input_dir`参数是传递给 Accelerator.load_state()的`input_dir`参数。

应该只与 Accelerator.register_save_state_pre_hook()一起使用。可以用于加载配置以及模型权重。也可以用于使用自定义方法覆盖模型加载。在这种情况下，请确保从模型列表中删除已加载的模型。

#### `register_save_state_pre_hook`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2619)

```py
( hook: Callable[..., None] ) → export const metadata = 'undefined';torch.utils.hooks.RemovableHandle
```

参数

+   `hook`（`Callable`）— 在 Accelerator.save_state()之前调用的函数，用于`save_checkpoint`。

返回

`torch.utils.hooks.RemovableHandle`

一个句柄，可以通过调用`handle.remove()`来移除添加的钩子

注册一个预钩子，在 Accelerator.save_state()中调用`save_checkpoint`之前运行。

钩子应该具有以下签名：

`hook(models: list[torch.nn.Module], weights: list[dict[str, torch.Tensor]], input_dir: str) -> None`

`models`参数是保存在加速器状态下的模型`accelerator._models`，`weights`参数是`models`的状态字典，`input_dir`参数是传递给 Accelerator.load_state()的`input_dir`参数。

应仅与 Accelerator.register_load_state_pre_hook()一起使用。除了模型权重外，保存配置也很有用。也可以用于使用自定义方法覆盖模型保存。在这种情况下，请确保从权重列表中删除已加载的权重。

#### `save`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2482)

```py
( obj f safe_serialization = False )
```

参数

+   `obj`（`object`）— 要保存的对象。

+   `f`（`str`或`os.PathLike`）— 要保存`obj`内容的位置。

+   `safe_serialization`（`bool`，*可选*，默认为`False`）— 是否使用`safetensors`保存`obj`

将传递给磁盘的对象每台机器保存一次。用于替代`torch.save`。

注意：如果`save_on_each_node`作为`ProjectConfiguration`传入，则会在每个节点上保存对象一次，而不仅在主节点上保存一次。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> arr = [0, 1, 2, 3]
>>> accelerator.save(arr, "array.pkl")
```

#### `save_model`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2512)

```py
( model: torch.nn.Module save_directory: Union[str, os.PathLike] max_shard_size: Union[int, str] = '10GB' safe_serialization: bool = True )
```

参数

+   `save_directory`（`str`或`os.PathLike`）— 要保存到的目录。如果不存在，将会创建。

+   `max_shard_size`（`int`或`str`，*可选*，默认为`"10GB"`）— 在分片之前的检查点的最大大小。然后，检查点分片将每个大小都小于此大小。如果表示为字符串，则需要是数字后跟一个单位（如`"5MB"`）。

    如果模型的单个权重大于`max_shard_size`，则它将在自己的检查点分片中，该分片将大于`max_shard_size`。

+   `safe_serialization`（`bool`，*可选*，默认为`True`）— 是否使用`safetensors`或传统的 PyTorch 方式（使用`pickle`）保存模型。

保存模型，以便可以使用`load_checkpoint_in_model`重新加载

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model = ...
>>> accelerator.save_model(model, save_directory)
```

#### `save_state`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2651)

```py
( output_dir: str = None safe_serialization: bool = True **save_model_func_kwargs )
```

参数

+   `output_dir`（`str`或`os.PathLike`）— 保存所有相关权重和状态的文件夹的名称。

+   `safe_serialization`（`bool`，*可选*，默认为`True`）— 是否使用`safetensors`或传统的 PyTorch 方式（使用`pickle`）保存模型。

+   `save_model_func_kwargs`（`dict`，*可选*）— 用于保存模型的额外关键字参数，可以传递给底层保存函数，例如 DeepSpeed 的`save_checkpoint`函数的可选参数。

将模型、优化器、缩放器、RNG 生成器和已注册对象的当前状态保存到一个文件夹中。

如果将`ProjectConfiguration`传递给启用了`automatic_checkpoint_naming`的`Accelerator`对象，则检查点将保存在`self.project_dir/checkpoints`中。如果当前保存的数量大于`total_limit`，则将删除最旧的保存。每个检查点都保存在名为`checkpoint_<iteration>`的单独文件夹中。

否则它们只保存到`output_dir`。

仅在希望在训练期间保存检查点并在相同环境中恢复状态时使用。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer, lr_scheduler = ...
>>> model, optimizer, lr_scheduler = accelerator.prepare(model, optimizer, lr_scheduler)
>>> accelerator.save_state(output_dir="my_checkpoint")
```

#### `set_trigger`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L1968)

```py
( )
```

将当前进程的内部触发张量设置为 1。随后应该使用此检查，该检查将跨所有进程进行检查。

注意：不需要`wait_for_everyone()`

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> # Assume later in the training script
>>> # `should_do_breakpoint` is a custom function to monitor when to break,
>>> # e.g. when the loss is NaN
>>> if should_do_breakpoint(loss):
...     accelerator.set_trigger()
>>> # Assume later in the training script
>>> if accelerator.check_breakpoint():
...     break
```

#### `skip_first_batches`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3156)

```py
( dataloader num_batches: int = 0 )
```

参数

+   `dataloader`（`torch.utils.data.DataLoader`）— 要跳过批次的数据加载器。

+   `num_batches`（`int`，*可选*，默认为 0）— 要跳过的批次数

创建一个新的`torch.utils.data.DataLoader`，它将高效地跳过前`num_batches`。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)
>>> skipped_dataloader = accelerator.skip_first_batches(dataloader, num_batches=2)
>>> # for the first epoch only
>>> for input, target in skipped_dataloader:
...     optimizer.zero_grad()
...     output = model(input)
...     loss = loss_func(output, target)
...     accelerator.backward(loss)
...     optimizer.step()

>>> # subsequent epochs
>>> for input, target in dataloader:
...     optimizer.zero_grad()
...     ...
```

#### `split_between_processes`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L553)

```py
( inputs: list | tuple | dict | torch.Tensor apply_padding: bool = False )
```

参数

+   `inputs`（`list`，`tuple`，`torch.Tensor`或`dict`的`list`/`tuple`/`torch.Tensor`）— 在进程之间拆分的输入。

+   `apply_padding`（`bool`，`可选`，默认为`False`）— 是否通过重复输入的最后一个元素来应用填充，以便所有进程具有相同数量的元素。在尝试对输出执行`Accelerator.gather()`等操作或传入少于进程数的输入时很有用。如果是这样，请记得之后删除填充的元素。

快速将`input`在`self.num_processes`之间拆分，然后可以在该进程上使用。在进行分布式推理时很有用，例如使用不同的提示。

请注意，使用`dict`时，所有键都需要具有相同数量的元素。

示例：

```py
# Assume there are two processes
from accelerate import Accelerator

accelerator = Accelerator()
with accelerator.split_between_processes(["A", "B", "C"]) as inputs:
    print(inputs)
# Process 0
["A", "B"]
# Process 1
["C"]

with accelerator.split_between_processes(["A", "B", "C"], apply_padding=True) as inputs:
    print(inputs)
# Process 0
["A", "B"]
# Process 1
["C", "C"]
```

#### `trigger_sync_in_backward`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L893)

```py
( model )
```

参数

+   `model`（`torch.nn.Module`）— 要触发梯度同步的模型。

在`Accelerator.no_sync`下的多次前向传递后，触发模型在下一个反向传递中同步梯度（仅适用于多 GPU 场景）。

如果脚本未在分布式模式下启动，则此上下文管理器不起作用。

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> dataloader, model, optimizer = accelerator.prepare(dataloader, model, optimizer)

>>> with accelerator.no_sync():
...     loss_a = loss_func(model(input_a))  # first forward pass
...     loss_b = loss_func(model(input_b))  # second forward pass
>>> accelerator.backward(loss_a)  # No synchronization across processes, only accumulate gradients
>>> with accelerator.trigger_sync_in_backward(model):
...     accelerator.backward(loss_b)  # Synchronization across all processes
>>> optimizer.step()
>>> optimizer.zero_grad()
```

#### `unscale_gradients`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2027)

```py
( optimizer = None )
```

参数

+   `optimizer`（`torch.optim.Optimizer`或`list[torch.optim.Optimizer]`，*可选*）— 要对梯度进行不缩放的优化器。如果未设置，将对传递给 prepare()的所有优化器进行梯度不缩放。

在 AMP 混合精度训练中不缩放梯度。在所有其他设置中，这是一个空操作。

可能应该通过 Accelerator.clip*grad_norm*()或 Accelerator.clip*grad_value*()来调用

示例：

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model, optimizer = accelerator.prepare(model, optimizer)
>>> outputs = model(inputs)
>>> loss = loss_fn(outputs, labels)
>>> accelerator.backward(loss)
>>> accelerator.unscale_gradients(optimizer=optimizer)
```

#### `unwrap_model`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2296)

```py
( model keep_fp32_wrapper: bool = True ) → export const metadata = 'undefined';torch.nn.Module
```

参数

+   `model`（`torch.nn.Module`）— 要取消包装的模型。

+   `keep_fp32_wrapper`（`bool`，*可选*，默认为`True`）— 是否在添加时不删除混合精度钩子。

返回

`torch.nn.Module`

未包装的模型。

从 prepare()可能添加的额外层中取消包装`model`。在保存模型之前很有用。

示例：

```py
>>> # Assuming two GPU processes
>>> from torch.nn.parallel import DistributedDataParallel
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> model = accelerator.prepare(MyModel())
>>> print(model.__class__.__name__)
DistributedDataParallel

>>> model = accelerator.unwrap_model(model)
>>> print(model.__class__.__name__)
MyModel
```

#### `verify_device_map`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L3192)

```py
( model: torch.nn.Module )
```

验证`model`是否未准备好使用类似`auto`的设备映射进行大型模型推理。

#### `wait_for_everyone`

[<来源>](https://github.com/huggingface/accelerate/blob/v0.27.2/src/accelerate/accelerator.py#L2329)

```py
( )
```

将停止当前进程的执行，直到每个其他进程都达到该点（因此当脚本仅在一个进程中运行时，此操作无效）。在保存模型之前执行此操作很有用。

示例：

```py
>>> # Assuming two GPU processes
>>> import time
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
>>> if accelerator.is_main_process:
...     time.sleep(2)
>>> else:
...     print("I'm waiting for the main process to finish its sleep...")
>>> accelerator.wait_for_everyone()
>>> # Should print on every process at the same time
>>> print("Everyone is here")
```
