- en: Batch mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://huggingface.co/docs/datasets/about_map_batch](https://huggingface.co/docs/datasets/about_map_batch)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <link href="/docs/datasets/v2.17.0/en/_app/immutable/assets/0.e3b0c442.css"
    rel="modulepreload"> <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/entry/start.146395b0.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/scheduler.bdbef820.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/singletons.98dc5b8b.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/index.8a885b74.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/paths.a483fec8.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/entry/app.e612c4fb.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/index.c0aea24a.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/nodes/0.5e8dbda6.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/each.e59479a4.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/nodes/6.b4a84df2.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/CodeBlock.6ccca92e.js">
    <link rel="modulepreload" href="/docs/datasets/v2.17.0/en/_app/immutable/chunks/Heading.2eb892cb.js">
  prefs: []
  type: TYPE_NORMAL
- en: Combining the utility of [Dataset.map()](/docs/datasets/v2.17.0/en/package_reference/main_classes#datasets.Dataset.map)
    with batch mode is very powerful. It allows you to speed up processing, and freely
    control the size of the generated dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Need for speed
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The primary objective of batch mapping is to speed up processing. Often times,
    it is faster to work with batches of data instead of single examples. Naturally,
    batch mapping lends itself to tokenization. For example, the ðŸ¤— [Tokenizers](https://huggingface.co/docs/tokenizers/python/latest/)
    library works faster with batches because it parallelizes the tokenization of
    all the examples in a batch.
  prefs: []
  type: TYPE_NORMAL
- en: Input size != output size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The ability to control the size of the generated dataset can be leveraged for
    many interesting use-cases. In the How-to [map](#map) section, there are examples
    of using batch mapping to:'
  prefs: []
  type: TYPE_NORMAL
- en: Split long sentences into shorter chunks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Augment a dataset with additional tokens.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It is helpful to understand how this works, so you can come up with your own
    ways to use batch mapping. At this point, you may be wondering how you can control
    the size of the generated dataset. The answer is: **the mapped function does not
    have to return an output batch of the same size**.'
  prefs: []
  type: TYPE_NORMAL
- en: In other words, your mapped function input can be a batch of size `N` and return
    a batch of size `M`. The output `M` can be greater than or less than `N`. This
    means you can concatenate your examples, divide it up, and even add more examples!
  prefs: []
  type: TYPE_NORMAL
- en: However, remember that all values in the output dictionary must contain the
    **same number of elements** as the other fields in the output dictionary. Otherwise,
    it is not possible to define the number of examples in the output returned by
    the mapped function. The number can vary between successive batches processed
    by the mapped function. For a single batch though, all values of the output dictionary
    should have the same length (i.e., the number of elements).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, from a dataset of 1 column and 3 rows, if you use `map` to return
    a new column with twice as many rows, then you will have an error. In this case,
    you end up with one column with 3 rows, and one column with 6 rows. As you can
    see, the table will not be valid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To make it valid, you have to drop one of the columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
