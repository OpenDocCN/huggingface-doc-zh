# å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰ç®¡é“ï¼Ÿ

> åŸå§‹æ–‡æœ¬ï¼š[`huggingface.co/docs/transformers/v4.37.2/en/add_new_pipeline`](https://huggingface.co/docs/transformers/v4.37.2/en/add_new_pipeline)

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰ç®¡é“å¹¶åœ¨[Hub](https://hf.co/models)ä¸Šå…±äº«å®ƒæˆ–å°†å…¶æ·»åŠ åˆ°ğŸ¤— Transformers åº“ä¸­ã€‚

é¦–å…ˆï¼Œæ‚¨éœ€è¦å†³å®šç®¡é“å°†èƒ½å¤Ÿæ¥å—çš„åŸå§‹æ¡ç›®ã€‚å®ƒå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€åŸå§‹å­—èŠ‚ã€å­—å…¸æˆ–ä»»ä½•çœ‹èµ·æ¥æœ€æœ‰å¯èƒ½çš„æœŸæœ›è¾“å…¥ã€‚å°½é‡ä¿æŒè¿™äº›è¾“å…¥å°½å¯èƒ½çº¯ç²¹çš„ Pythonï¼Œå› ä¸ºè¿™æ ·å¯ä»¥ä½¿å…¼å®¹æ€§æ›´å®¹æ˜“ï¼ˆç”šè‡³é€šè¿‡ JSON é€šè¿‡å…¶ä»–è¯­è¨€ï¼‰ã€‚è¿™äº›å°†æ˜¯ç®¡é“çš„`inputs`ï¼ˆ`preprocess`ï¼‰ã€‚

ç„¶åå®šä¹‰`outputs`ã€‚ä¸`inputs`ç›¸åŒçš„ç­–ç•¥ã€‚è¶Šç®€å•è¶Šå¥½ã€‚è¿™äº›å°†æ˜¯`postprocess`æ–¹æ³•çš„è¾“å‡ºã€‚

é¦–å…ˆé€šè¿‡ç»§æ‰¿åŸºç±»`Pipeline`ï¼Œå…·æœ‰å®ç°`preprocess`ã€`_forward`ã€`postprocess`å’Œ`_sanitize_parameters`æ‰€éœ€çš„ 4 ä¸ªæ–¹æ³•ã€‚

```py
from transformers import Pipeline

class MyPipeline(Pipeline):
    def _sanitize_parameters(self, **kwargs):
        preprocess_kwargs = {}
        if "maybe_arg" in kwargs:
            preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]
        return preprocess_kwargs, {}, {}

    def preprocess(self, inputs, maybe_arg=2):
        model_input = Tensor(inputs["input_ids"])
        return {"model_input": model_input}

    def _forward(self, model_inputs):
        # model_inputs == {"model_input": model_input}
        outputs = self.model(**model_inputs)
        # Maybe {"logits": Tensor(...)}
        return outputs

    def postprocess(self, model_outputs):
        best_class = model_outputs["logits"].softmax(-1)
        return best_class
```

è¿™ç§åˆ†è§£çš„ç»“æ„æ”¯æŒç›¸å¯¹æ— ç¼åœ°æ”¯æŒ CPU/GPUï¼ŒåŒæ—¶æ”¯æŒåœ¨ä¸åŒçº¿ç¨‹ä¸Šåœ¨ CPU ä¸Šè¿›è¡Œé¢„å¤„ç†/åå¤„ç†

`preprocess`å°†è·å–æœ€åˆå®šä¹‰çš„è¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå¯ä¾›æ¨¡å‹ä½¿ç”¨çš„å†…å®¹ã€‚å®ƒå¯èƒ½åŒ…å«æ›´å¤šä¿¡æ¯ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ª`Dict`ã€‚

`_forward`æ˜¯å®ç°ç»†èŠ‚ï¼Œä¸åº”ç›´æ¥è°ƒç”¨ã€‚`forward`æ˜¯é¦–é€‰çš„è°ƒç”¨æ–¹æ³•ï¼Œå› ä¸ºå®ƒåŒ…å«äº†ç¡®ä¿ä¸€åˆ‡åœ¨é¢„æœŸè®¾å¤‡ä¸Šå·¥ä½œçš„ä¿éšœæªæ–½ã€‚å¦‚æœä»»ä½•å†…å®¹ä¸çœŸå®æ¨¡å‹ç›¸å…³ï¼Œåˆ™åº”è¯¥æ”¾åœ¨`_forward`æ–¹æ³•ä¸­ï¼Œå…¶ä»–å†…å®¹åº”è¯¥æ”¾åœ¨é¢„å¤„ç†/åå¤„ç†ä¸­ã€‚

`postprocess`æ–¹æ³•å°†è·å–`_forward`çš„è¾“å‡ºå¹¶å°†å…¶è½¬æ¢ä¸ºä¹‹å‰å†³å®šçš„æœ€ç»ˆè¾“å‡ºã€‚

`_sanitize_parameters`å­˜åœ¨æ˜¯ä¸ºäº†å…è®¸ç”¨æˆ·åœ¨ä»»ä½•æ—¶å€™ä¼ é€’ä»»ä½•å‚æ•°ï¼Œæ— è®ºæ˜¯åœ¨åˆå§‹åŒ–æ—¶`pipeline(...., maybe_arg=4)`è¿˜æ˜¯åœ¨è°ƒç”¨æ—¶`pipe = pipeline(...); output = pipe(...., maybe_arg=4)`ã€‚

`_sanitize_parameters`çš„è¿”å›å€¼æ˜¯å°†ç›´æ¥ä¼ é€’ç»™`preprocess`ã€`_forward`å’Œ`postprocess`çš„ 3 ä¸ª kwargs å­—å…¸ã€‚å¦‚æœè°ƒç”¨è€…æ²¡æœ‰ä½¿ç”¨ä»»ä½•é¢å¤–å‚æ•°ï¼Œåˆ™ä¸è¦å¡«å†™ä»»ä½•å†…å®¹ã€‚è¿™æ ·å¯ä»¥ä¿æŒå‡½æ•°å®šä¹‰ä¸­çš„é»˜è®¤å‚æ•°ï¼Œè¿™æ€»æ˜¯æ›´â€œè‡ªç„¶â€çš„ã€‚

ä¸€ä¸ªç»å…¸çš„ä¾‹å­æ˜¯åœ¨åˆ†ç±»ä»»åŠ¡çš„åå¤„ç†ä¸­æ·»åŠ ä¸€ä¸ª`top_k`å‚æ•°ã€‚

```py
>>> pipe = pipeline("my-new-task")
>>> pipe("This is a test")
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}, {"label": "3-star", "score": 0.05}
{"label": "4-star", "score": 0.025}, {"label": "5-star", "score": 0.025}]

>>> pipe("This is a test", top_k=2)
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}]
```

ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªé»˜è®¤å‚æ•°`5`æ¥æ›´æ–°æˆ‘ä»¬çš„`postprocess`æ–¹æ³•ï¼Œå¹¶ç¼–è¾‘`_sanitize_parameters`ä»¥å…è®¸è¿™ä¸ªæ–°å‚æ•°ã€‚

```py
def postprocess(self, model_outputs, top_k=5):
    best_class = model_outputs["logits"].softmax(-1)
    # Add logic to handle top_k
    return best_class

def _sanitize_parameters(self, **kwargs):
    preprocess_kwargs = {}
    if "maybe_arg" in kwargs:
        preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]

    postprocess_kwargs = {}
    if "top_k" in kwargs:
        postprocess_kwargs["top_k"] = kwargs["top_k"]
    return preprocess_kwargs, {}, postprocess_kwargs
```

å°½é‡ä¿æŒè¾“å…¥/è¾“å‡ºéå¸¸ç®€å•ï¼Œæœ€å¥½æ˜¯å¯ JSON åºåˆ—åŒ–çš„ï¼Œå› ä¸ºè¿™æ ·å¯ä»¥ä½¿ç®¡é“çš„ä½¿ç”¨éå¸¸ç®€å•ï¼Œè€Œä¸éœ€è¦ç”¨æˆ·ç†è§£æ–°ç±»å‹çš„å¯¹è±¡ã€‚é€šå¸¸ä¹Ÿæ”¯æŒè®¸å¤šä¸åŒç±»å‹çš„å‚æ•°ï¼Œä»¥ä¾¿äºä½¿ç”¨ï¼ˆä¾‹å¦‚éŸ³é¢‘æ–‡ä»¶ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶åã€URL æˆ–çº¯å­—èŠ‚ï¼‰

## å°†å…¶æ·»åŠ åˆ°æ”¯æŒä»»åŠ¡åˆ—è¡¨ä¸­

è¦å°†æ‚¨çš„`new-task`æ³¨å†Œåˆ°æ”¯æŒä»»åŠ¡åˆ—è¡¨ä¸­ï¼Œæ‚¨å¿…é¡»å°†å…¶æ·»åŠ åˆ°`PIPELINE_REGISTRY`ä¸­ï¼š

```py
from transformers.pipelines import PIPELINE_REGISTRY

PIPELINE_REGISTRY.register_pipeline(
    "new-task",
    pipeline_class=MyPipeline,
    pt_model=AutoModelForSequenceClassification,
)
```

å¦‚æœéœ€è¦ï¼Œæ‚¨å¯ä»¥æŒ‡å®šä¸€ä¸ªé»˜è®¤æ¨¡å‹ï¼Œæ­¤æ—¶åº”è¯¥é™„å¸¦ä¸€ä¸ªç‰¹å®šçš„ä¿®è®¢ç‰ˆï¼ˆå¯ä»¥æ˜¯åˆ†æ”¯åç§°æˆ–æäº¤å“ˆå¸Œï¼Œè¿™é‡Œæˆ‘ä»¬å–`"abcdef"`ï¼‰ä»¥åŠç±»å‹ï¼š

```py
PIPELINE_REGISTRY.register_pipeline(
    "new-task",
    pipeline_class=MyPipeline,
    pt_model=AutoModelForSequenceClassification,
    default={"pt": ("user/awesome_model", "abcdef")},
    type="text",  # current support type: text, audio, image, multimodal
)
```

## åœ¨ Hub ä¸Šå…±äº«æ‚¨çš„ç®¡é“

è¦åœ¨ Hub ä¸Šå…±äº«æ‚¨çš„è‡ªå®šä¹‰ç®¡é“ï¼Œåªéœ€å°†`Pipeline`å­ç±»çš„è‡ªå®šä¹‰ä»£ç ä¿å­˜åœ¨ä¸€ä¸ª python æ–‡ä»¶ä¸­ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æƒ³è¦åƒè¿™æ ·ä¸ºå¥å¯¹åˆ†ç±»ä½¿ç”¨è‡ªå®šä¹‰ç®¡é“ï¼š

```py
import numpy as np

from transformers import Pipeline

def softmax(outputs):
    maxes = np.max(outputs, axis=-1, keepdims=True)
    shifted_exp = np.exp(outputs - maxes)
    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)

class PairClassificationPipeline(Pipeline):
    def _sanitize_parameters(self, **kwargs):
        preprocess_kwargs = {}
        if "second_text" in kwargs:
            preprocess_kwargs["second_text"] = kwargs["second_text"]
        return preprocess_kwargs, {}, {}

    def preprocess(self, text, second_text=None):
        return self.tokenizer(text, text_pair=second_text, return_tensors=self.framework)

    def _forward(self, model_inputs):
        return self.model(**model_inputs)

    def postprocess(self, model_outputs):
        logits = model_outputs.logits[0].numpy()
        probabilities = softmax(logits)

        best_class = np.argmax(probabilities)
        label = self.model.config.id2label[best_class]
        score = probabilities[best_class].item()
        logits = logits.tolist()
        return {"label": label, "score": score, "logits": logits}
```

è¿™ä¸ªå®ç°æ˜¯ä¸æ¡†æ¶æ— å…³çš„ï¼Œå°†é€‚ç”¨äº PyTorch å’Œ TensorFlow æ¨¡å‹ã€‚å¦‚æœæˆ‘ä»¬å°†å…¶ä¿å­˜åœ¨ä¸€ä¸ªåä¸º`pair_classification.py`çš„æ–‡ä»¶ä¸­ï¼Œç„¶åå¯ä»¥åƒè¿™æ ·å¯¼å…¥å¹¶æ³¨å†Œå®ƒï¼š

```py
from pair_classification import PairClassificationPipeline
from transformers.pipelines import PIPELINE_REGISTRY
from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification

PIPELINE_REGISTRY.register_pipeline(
    "pair-classification",
    pipeline_class=PairClassificationPipeline,
    pt_model=AutoModelForSequenceClassification,
    tf_model=TFAutoModelForSequenceClassification,
)
```

å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ã€‚ä¾‹å¦‚`sgugger/finetuned-bert-mrpc`å·²åœ¨ MRPC æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¾®è°ƒï¼Œç”¨äºå°†å¥å­å¯¹åˆ†ç±»ä¸ºé‡Šä¹‰æˆ–éé‡Šä¹‰ã€‚

```py
from transformers import pipeline

classifier = pipeline("pair-classification", model="sgugger/finetuned-bert-mrpc")
```

ç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨`Repository`ä¸­ä½¿ç”¨`save_pretrained`æ–¹æ³•åœ¨ Hub ä¸Šå…±äº«å®ƒï¼š

```py
from huggingface_hub import Repository

repo = Repository("test-dynamic-pipeline", clone_from="{your_username}/test-dynamic-pipeline")
classifier.save_pretrained("test-dynamic-pipeline")
repo.push_to_hub()
```

è¿™å°†å¤åˆ¶æ‚¨åœ¨æ–‡ä»¶ä¸­å®šä¹‰`PairClassificationPipeline`çš„æ–‡ä»¶å¤¹`"test-dynamic-pipeline"`ä¸­ï¼ŒåŒæ—¶ä¿å­˜ç®¡é“çš„æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œç„¶åå°†æ‰€æœ‰å†…å®¹æ¨é€åˆ°å­˜å‚¨åº“`{your_username}/test-dynamic-pipeline`ä¸­ã€‚ä¹‹åï¼Œä»»ä½•äººåªè¦æä¾›é€‰é¡¹`trust_remote_code=True`å°±å¯ä»¥ä½¿ç”¨å®ƒï¼š

```py
from transformers import pipeline

classifier = pipeline(model="{your_username}/test-dynamic-pipeline", trust_remote_code=True)
```

## å°†ç®¡é“æ·»åŠ åˆ°ğŸ¤— Transformers

å¦‚æœæ‚¨æƒ³å°†æ‚¨çš„ç®¡é“è´¡çŒ®ç»™ğŸ¤— Transformersï¼Œæ‚¨éœ€è¦åœ¨`pipelines`å­æ¨¡å—ä¸­æ·»åŠ ä¸€ä¸ªæ–°æ¨¡å—ï¼Œå…¶ä¸­åŒ…å«æ‚¨çš„ç®¡é“çš„ä»£ç ï¼Œç„¶åå°†å…¶æ·»åŠ åˆ°`pipelines/__init__.py`ä¸­å®šä¹‰çš„ä»»åŠ¡åˆ—è¡¨ä¸­ã€‚

ç„¶åï¼Œæ‚¨éœ€è¦æ·»åŠ æµ‹è¯•ã€‚åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶`tests/test_pipelines_MY_PIPELINE.py`ï¼Œå…¶ä¸­åŒ…å«å…¶ä»–æµ‹è¯•çš„ç¤ºä¾‹ã€‚

`run_pipeline_test`å‡½æ•°å°†éå¸¸é€šç”¨ï¼Œå¹¶åœ¨ç”±`model_mapping`å’Œ`tf_model_mapping`å®šä¹‰çš„æ¯ç§å¯èƒ½çš„æ¶æ„ä¸Šè¿è¡Œå°å‹éšæœºæ¨¡å‹ã€‚

è¿™å¯¹äºæµ‹è¯•æœªæ¥çš„å…¼å®¹æ€§éå¸¸é‡è¦ï¼Œè¿™æ„å‘³ç€å¦‚æœæœ‰äººä¸º`XXXForQuestionAnswering`æ·»åŠ äº†ä¸€ä¸ªæ–°æ¨¡å‹ï¼Œé‚£ä¹ˆç®¡é“æµ‹è¯•å°†å°è¯•åœ¨å…¶ä¸Šè¿è¡Œã€‚ç”±äºæ¨¡å‹æ˜¯éšæœºçš„ï¼Œæ— æ³•æ£€æŸ¥å®é™…å€¼ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœ‰ä¸€ä¸ªè¾…åŠ©`ANY`ï¼Œå®ƒå°†ç®€å•åœ°å°è¯•åŒ¹é…ç®¡é“ç±»å‹çš„è¾“å‡ºã€‚

æ‚¨è¿˜*éœ€è¦*å®ç° 2ï¼ˆç†æƒ³æƒ…å†µä¸‹ 4ï¼‰ä¸ªæµ‹è¯•ã€‚

+   `test_small_model_pt`ï¼šä¸ºè¿™ä¸ªç®¡é“å®šä¹‰ä¸€ä¸ªå°æ¨¡å‹ï¼ˆç»“æœæ˜¯å¦æœ‰æ„ä¹‰å¹¶ä¸é‡è¦ï¼‰ï¼Œå¹¶æµ‹è¯•ç®¡é“çš„è¾“å‡ºã€‚ç»“æœåº”è¯¥ä¸`test_small_model_tf`ç›¸åŒã€‚

+   `test_small_model_tf`ï¼šä¸ºè¿™ä¸ªç®¡é“å®šä¹‰ä¸€ä¸ªå°æ¨¡å‹ï¼ˆç»“æœæ˜¯å¦æœ‰æ„ä¹‰å¹¶ä¸é‡è¦ï¼‰ï¼Œå¹¶æµ‹è¯•ç®¡é“çš„è¾“å‡ºã€‚ç»“æœåº”è¯¥ä¸`test_small_model_pt`ç›¸åŒã€‚

+   `test_large_model_pt` (`optional`): åœ¨ä¸€ä¸ªçœŸå®çš„ç®¡é“ä¸Šæµ‹è¯•ç®¡é“ï¼Œç»“æœåº”è¯¥æ˜¯æœ‰æ„ä¹‰çš„ã€‚è¿™äº›æµ‹è¯•å¾ˆæ…¢ï¼Œåº”è¯¥æ ‡è®°ä¸ºè¿™æ ·ã€‚è¿™é‡Œçš„ç›®æ ‡æ˜¯å±•ç¤ºç®¡é“ï¼Œå¹¶ç¡®ä¿å°†æ¥çš„å‘å¸ƒä¸­æ²¡æœ‰æ¼‚ç§»ã€‚

+   `test_large_model_tf` (`optional`): åœ¨ä¸€ä¸ªçœŸå®çš„ç®¡é“ä¸Šæµ‹è¯•ç®¡é“ï¼Œç»“æœåº”è¯¥æ˜¯æœ‰æ„ä¹‰çš„ã€‚è¿™äº›æµ‹è¯•å¾ˆæ…¢ï¼Œåº”è¯¥æ ‡è®°ä¸ºè¿™æ ·ã€‚è¿™é‡Œçš„ç›®æ ‡æ˜¯å±•ç¤ºç®¡é“ï¼Œå¹¶ç¡®ä¿å°†æ¥çš„å‘å¸ƒä¸­æ²¡æœ‰æ¼‚ç§»ã€‚
