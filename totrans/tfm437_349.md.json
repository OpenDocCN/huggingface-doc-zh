["```py\n>>> from transformers import (\n...     InstructBlipVisionConfig,\n...     InstructBlipQFormerConfig,\n...     OPTConfig,\n...     InstructBlipConfig,\n...     InstructBlipForConditionalGeneration,\n... )\n\n>>> # Initializing a InstructBlipConfig with Salesforce/instruct-blip-flan-t5 style configuration\n>>> configuration = InstructBlipConfig()\n\n>>> # Initializing a InstructBlipForConditionalGeneration (with random weights) from the Salesforce/instruct-blip-flan-t5 style configuration\n>>> model = InstructBlipForConditionalGeneration(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n\n>>> # We can also initialize a InstructBlipConfig from a InstructBlipVisionConfig, InstructBlipQFormerConfig and any PretrainedConfig\n\n>>> # Initializing InstructBLIP vision, InstructBLIP Q-Former and language model configurations\n>>> vision_config = InstructBlipVisionConfig()\n>>> qformer_config = InstructBlipQFormerConfig()\n>>> text_config = OPTConfig()\n\n>>> config = InstructBlipConfig.from_text_vision_configs(vision_config, qformer_config, text_config)\n```", "```py\n>>> from transformers import InstructBlipVisionConfig, InstructBlipVisionModel\n\n>>> # Initializing a InstructBlipVisionConfig with Salesforce/instruct-blip-flan-t5 style configuration\n>>> configuration = InstructBlipVisionConfig()\n\n>>> # Initializing a InstructBlipVisionModel (with random weights) from the Salesforce/instruct-blip-flan-t5 style configuration\n>>> model = InstructBlipVisionModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import InstructBlipQFormerConfig, InstructBlipQFormerModel\n\n>>> # Initializing a InstructBLIP Salesforce/instruct-blip-flan-t5 style configuration\n>>> configuration = InstructBlipQFormerConfig()\n\n>>> # Initializing a model (with random weights) from the Salesforce/instruct-blip-flan-t5 style configuration\n>>> model = InstructBlipQFormerModel(configuration)\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n>>> import torch\n>>> from PIL import Image\n>>> import requests\n\n>>> model = InstructBlipForConditionalGeneration.from_pretrained(\"Salesforce/instructblip-vicuna-7b\")\n>>> processor = InstructBlipProcessor.from_pretrained(\"Salesforce/instructblip-vicuna-7b\")\n\n>>> device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n>>> model.to(device)\n>>> url = \"https://raw.githubusercontent.com/salesforce/LAVIS/main/docs/_static/Confusing-Pictures.jpg\"\n>>> image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n>>> prompt = \"What is unusual about this image?\"\n>>> inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n\n>>> outputs = model.generate(\n...     **inputs,\n...     do_sample=False,\n...     num_beams=5,\n...     max_length=256,\n...     min_length=1,\n...     top_p=0.9,\n...     repetition_penalty=1.5,\n...     length_penalty=1.0,\n...     temperature=1,\n... )\n>>> generated_text = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n>>> print(generated_text)\nThe unusual aspect of this image is that a man is ironing clothes on the back of a yellow SUV, which is parked in the middle of a busy city street. This is an unconventional approach to ironing clothes, as it requires the man to balance himself and his ironing equipment on top of the vehicle while navigating through traffic. Additionally, the presence of taxis and other vehicles in the scene further emphasizes the unusual nature of this situation.\n```"]