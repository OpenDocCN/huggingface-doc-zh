- en: Inference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推断
- en: 'Original text: [https://huggingface.co/docs/huggingface_hub/package_reference/inference_client](https://huggingface.co/docs/huggingface_hub/package_reference/inference_client)'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始文本：[https://huggingface.co/docs/huggingface_hub/package_reference/inference_client](https://huggingface.co/docs/huggingface_hub/package_reference/inference_client)
- en: null
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Inference is the process of using a trained model to make predictions on new
    data. As this process can be compute-intensive, running on a dedicated server
    can be an interesting option. The `huggingface_hub` library provides an easy way
    to call a service that runs inference for hosted models. There are several services
    you can connect to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 推断是使用训练好的模型对新数据进行预测的过程。由于这个过程可能需要大量计算资源，运行在专用服务器上可能是一个有趣的选择。`huggingface_hub`库提供了一种简单的方法来调用一个运行托管模型推断的服务。您可以连接到几种服务：
- en: '[Inference API](https://huggingface.co/docs/api-inference/index): a service
    that allows you to run accelerated inference on Hugging Face’s infrastructure
    for free. This service is a fast way to get started, test different models, and
    prototype AI products.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[推断API](https://huggingface.co/docs/api-inference/index)：一个允许您在Hugging Face基础设施上加速推断的服务，免费使用。这项服务是一个快速开始、测试不同模型和原型化AI产品的方式。'
- en: '[Inference Endpoints](https://huggingface.co/inference-endpoints): a product
    to easily deploy models to production. Inference is run by Hugging Face in a dedicated,
    fully managed infrastructure on a cloud provider of your choice.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[推断端点](https://huggingface.co/inference-endpoints)：一个产品，可以轻松部署模型到生产环境。推断由Hugging
    Face在您选择的云提供商上的专用、完全托管的基础设施上运行。'
- en: These services can be called with the [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    object. Please refer to [this guide](../guides/inference) for more information
    on how to use it.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这些服务可以通过[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)对象调用。请参考[此指南](../guides/inference)获取更多关于如何使用它的信息。
- en: Inference Client
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推断客户端
- en: '### `class huggingface_hub.InferenceClient`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class huggingface_hub.InferenceClient`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L105)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L105)'
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Parameters
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`str`, `optional`) — The model to run inference with. Can be a model
    id hosted on the Hugging Face Hub, e.g. `bigcode/starcoder` or a URL to a deployed
    Inference Endpoint. Defaults to None, in which case a recommended model is automatically
    selected for the task.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, `可选`) — 用于进行推断的模型。可以是托管在Hugging Face Hub上的模型ID，例如`bigcode/starcoder`，也可以是指向部署的推断端点的URL。默认为None，此时将自动选择适合任务的推荐模型。'
- en: '`token` (`str`, *optional*) — Hugging Face token. Will default to the locally
    saved token. Pass `token=False` if you don’t want to send your token to the server.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`, *可选*) — Hugging Face token。默认为本地保存的token。如果不想将您的token发送到服务器，请传递`token=False`。'
- en: '`timeout` (`float`, `optional`) — The maximum number of seconds to wait for
    a response from the server. Loading a new model in Inference API can take up to
    several minutes. Defaults to None, meaning it will loop until the server is available.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeout` (`float`, `可选`) — 等待服务器响应的最大秒数。在推断API中加载新模型可能需要几分钟。默认为None，意味着会循环直到服务器可用。'
- en: '`headers` (`Dict[str, str]`, `optional`) — Additional headers to send to the
    server. By default only the authorization and user-agent headers are sent. Values
    in this dictionary will override the default values.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`headers` (`Dict[str, str]`, `可选`) — 要发送到服务器的额外标头。默认只发送授权和用户代理标头。此字典中的值将覆盖默认值。'
- en: '`cookies` (`Dict[str, str]`, `optional`) — Additional cookies to send to the
    server.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cookies` (`Dict[str, str]`, `可选`) — 要发送到服务器的额外cookie。'
- en: Initialize a new Inference Client.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化一个新的推断客户端。
- en: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    aims to provide a unified experience to perform inference. The client can be used
    seamlessly with either the (free) Inference API or self-hosted Inference Endpoints.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)旨在提供一个统一的体验来执行推断。该客户端可以无缝地与（免费的）推断API或自托管的推断端点一起使用。'
- en: '#### `audio_classification`'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `audio_classification`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L264)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L264)'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Parameters
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`audio` (Union[str, Path, bytes, BinaryIO]) — The audio content to classify.
    It can be raw audio bytes, a local audio file, or a URL pointing to an audio file.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio` (Union[str, Path, bytes, BinaryIO]) — 要分类的音频内容。可以是原始音频字节、本地音频文件或指向音频文件的URL。'
- en: '`model` (`str`, *optional*) — The model to use for audio classification. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended model for audio classification
    will be used.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于音频分类的模型。可以是托管在Hugging Face Hub上的模型ID或指向部署的推断端点的URL。如果未提供，默认将使用音频分类的推荐模型。'
- en: Returns
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: The classification output containing the predicted label and its confidence.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签及其置信度的分类输出。
- en: Raises
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，返回的HTTP错误状态码不是HTTP 503。'
- en: Perform audio classification on the provided audio content.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对提供的音频内容进行音频分类。
- en: 'Example:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#### `automatic_speech_recognition`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 自动语音识别
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L302)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L302)'
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Parameters
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`audio` (Union[str, Path, bytes, BinaryIO]) — The content to transcribe. It
    can be raw audio bytes, local audio file, or a URL to an audio file.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio`（Union[str, Path, bytes, BinaryIO）—要转录的内容。可以是原始音频字节、本地音频文件或音频文件的URL。'
- en: '`model` (`str`, *optional*) — The model to use for ASR. Can be a model ID hosted
    on the Hugging Face Hub or a URL to a deployed Inference Endpoint. If not provided,
    the default recommended model for ASR will be used.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`str`，*可选*）—用于ASR的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，默认推荐的ASR模型将被使用。'
- en: Returns
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: str
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: str
- en: The transcribed text.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 转录的文本。
- en: Raises
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    —如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` —如果请求失败，并且HTTP状态代码不是HTTP 503。'
- en: Perform automatic speech recognition (ASR or audio-to-text) on the given audio
    content.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对给定音频内容执行自动语音识别（ASR或音频转文本）。
- en: 'Example:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#### `conversational`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `对话`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L338)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L338)'
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Parameters
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — The last input from the user in the conversation.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`（`str`）—对话中用户的最后输入。'
- en: '`generated_responses` (`List[str]`, *optional*) — A list of strings corresponding
    to the earlier replies from the model. Defaults to None.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generated_responses`（`List[str]`，*可选*）—与模型先前回复对应的字符串列表。默认为None。'
- en: '`past_user_inputs` (`List[str]`, *optional*) — A list of strings corresponding
    to the earlier replies from the user. Should be the same length as `generated_responses`.
    Defaults to None.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_user_inputs`（`List[str]`，*可选*）—与用户先前回复对应的字符串列表。应与`generated_responses`的长度相同。默认为None。'
- en: '`parameters` (`Dict[str, Any]`, *optional*) — Additional parameters for the
    conversational task. Defaults to None. For more details about the available parameters,
    please refer to [this page](https://huggingface.co/docs/api-inference/detailed_parameters#conversational-task)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`parameters`（`Dict[str, Any]`，*可选*）—对话任务的附加参数。默认为None。有关可用参数的更多详细信息，请参考[此页面](https://huggingface.co/docs/api-inference/detailed_parameters#conversational-task)'
- en: '`model` (`str`, *optional*) — The model to use for the conversational task.
    Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended conversational model will be
    used. Defaults to None.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`str`，*可选*）—用于对话任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，默认推荐的对话模型将被使用。默认为None。'
- en: Returns
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict`'
- en: The generated conversational output.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的对话输出。
- en: Raises
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    —如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` —如果请求失败，并且HTTP状态代码不是HTTP 503。'
- en: Generate conversational responses based on the given input text (i.e. chat with
    the API).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 根据给定的输入文本生成对话响应（即与API聊天）。
- en: 'Example:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#### `document_question_answering`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `文档问答`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L443)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L443)'
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Parameters
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image for the context.
    It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`（`Union[str, Path, bytes, BinaryIO]`）—上下文的输入图像。可以是原始字节、图像文件或在线图像的URL。'
- en: '`question` (`str`) — Question to be answered.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question`（`str`）—要回答的问题。'
- en: '`model` (`str`, *optional*) — The model to use for the document question answering
    task. Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed
    Inference Endpoint. If not provided, the default recommended document question
    answering model will be used. Defaults to None.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`str`，*可选*）—用于文档问答任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，默认推荐的文档问答模型将被使用。默认为None。'
- en: Returns
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: a list of dictionaries containing the predicted label, associated probability,
    word ids, and page number.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签、相关概率、单词ID和页码的字典列表。
- en: Raises
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    —如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` —如果请求失败，并且HTTP状态代码不是HTTP 503。'
- en: Answer questions on document images.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 回答文档图像上的问题。
- en: 'Example:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#### `feature_extraction`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `特征提取`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L484)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L484)'
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Parameters
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — The text to embed.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 要嵌入的文本。'
- en: '`model` (`str`, *optional*) — The model to use for the conversational task.
    Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended conversational model will be
    used. Defaults to None.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`，*可选*) — 用于对话任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，默认推荐的对话模型将被使用。默认为None。'
- en: Returns
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`np.ndarray`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`np.ndarray`'
- en: The embedding representing the input text as a float32 numpy array.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入文本表示为float32 numpy数组的嵌入。
- en: Raises
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，状态码不是HTTP 503。'
- en: Generate embeddings for a given text.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为给定文本生成嵌入。
- en: 'Example:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#### `fill_mask`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `fill_mask`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L520)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L520)'
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parameters
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — a string to be filled from, must contain the [MASK] token
    (check model card for exact name of the mask).'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 要填充的字符串，必须包含[MASK]标记（检查模型卡片以获取掩码的确切名称）。'
- en: '`model` (`str`, *optional*) — The model to use for the fill mask task. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended fill mask model will be used.
    Defaults to None.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`，*可选*) — 用于填充掩码任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，默认推荐的填充掩码模型将被使用。默认为None。'
- en: Returns
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: a list of fill mask output dictionaries containing the predicted label, associated
    probability, token reference, and completed text.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签、相关概率、标记引用和完成文本的填充掩码输出字典列表。
- en: Raises
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，状态码不是HTTP 503。'
- en: Fill in a hole with a missing word (token to be precise).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 用缺失的单词（确切地说是标记）填充空白。
- en: 'Example:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE12]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#### `get_model_status`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_model_status`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1941)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1941)'
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Parameters
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`str`, *optional*) — Identifier of the model for witch the status
    gonna be checked. If model is not provided, the model associated with this instance
    of [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    will be used. Only InferenceAPI service can be checked so the identifier cannot
    be a URL.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`，*可选*) — 要检查状态的模型标识符。如果未提供模型，则将使用与此[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)实例关联的模型。只能检查InferenceAPI服务，因此标识符不能是URL。'
- en: Returns
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`ModelStatus`'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`ModelStatus`'
- en: 'An instance of ModelStatus dataclass, containing information, about the state
    of the model: load, state, compute type and framework.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 包含有关模型状态的ModelStatus数据类的实例：加载、状态、计算类型和框架的信息。
- en: Get the status of a model hosted on the Inference API.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 获取托管在推理API上的模型的状态。
- en: This endpoint is mostly useful when you already know which model you want to
    use and want to check its availability. If you want to discover already deployed
    models, you should rather use [list_deployed_models()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.list_deployed_models).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当您已经知道要使用哪个模型并想要检查其可用性时，此端点非常有用。如果要发现已部署的模型，您应该使用[list_deployed_models()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.list_deployed_models)。
- en: 'Example:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE14]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#### `get_recommended_model`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `get_recommended_model`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1917)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1917)'
- en: '[PRE15]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Parameters
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`task` (`str`) — The Hugging Face task to get which model Hugging Face recommends.
    All available tasks can be found [here](https://huggingface.co/tasks).'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task` (`str`) — 要获取Hugging Face推荐的模型的任务。所有可用任务可以在[这里](https://huggingface.co/tasks)找到。'
- en: Returns
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: Name of the model recommended for the input task.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐的输入任务模型的名称。
- en: Raises
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '`ValueError`'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`ValueError`'
- en: '`ValueError` — If Hugging Face has no recommendation for the input task.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ValueError` — 如果Hugging Face没有对输入任务的推荐。'
- en: Get the model Hugging Face recommends for the input task.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 获取Hugging Face推荐的输入任务模型。
- en: '#### `image_classification`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `image_classification`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L560)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L560)'
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Parameters
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The image to classify. It can
    be raw bytes, an image file, or a URL to an online image.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`Union[str, Path, bytes, BinaryIO]`) — 要分类的图像。可以是原始字节、图像文件或在线图像的 URL。'
- en: '`model` (`str`, *optional*) — The model to use for image classification. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended model for image classification
    will be used.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于图像分类的模型。可以是托管在 Hugging Face Hub 上的模型 ID，也可以是部署的推理端点的
    URL。如果未提供，则将使用默认推荐的图像分类模型。'
- en: Returns
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: a list of dictionaries containing the predicted label and associated probability.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签和相关概率的字典列表。
- en: Raises
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，返回的 HTTP 错误状态码不是 HTTP 503。'
- en: Perform image classification on the given image using the specified model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定模型对给定图像进行图像分类。
- en: 'Example:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE17]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#### `image_segmentation`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `image_segmentation`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L596)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L596)'
- en: '[PRE18]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Parameters
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The image to segment. It can
    be raw bytes, an image file, or a URL to an online image.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`Union[str, Path, bytes, BinaryIO]`) — 要分割的图像。可以是原始字节、图像文件或在线图像的 URL。'
- en: '`model` (`str`, *optional*) — The model to use for image segmentation. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended model for image segmentation
    will be used.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于图像分割的模型。可以是托管在 Hugging Face Hub 上的模型 ID，也可以是部署的推理端点的
    URL。如果未提供，则将使用默认推荐的图像分割模型。'
- en: Returns
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: A list of dictionaries containing the segmented masks and associated attributes.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 包含分割掩模和相关属性的字典列表。
- en: Raises
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，返回的 HTTP 错误状态码不是 HTTP 503。'
- en: Perform image segmentation on the given image using the specified model.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定模型对给定图像进行图像分割。
- en: You must have `PIL` installed if you want to work with images (`pip install
    Pillow`).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要处理图像，必须安装 `PIL` (`pip install Pillow`)。
- en: 'Example:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE19]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '#### `image_to_image`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `image_to_image`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L647)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L647)'
- en: '[PRE20]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Parameters
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image for translation.
    It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`Union[str, Path, bytes, BinaryIO]`) — 用于翻译的输入图像。可以是原始字节、图像文件或在线图像的
    URL。'
- en: '`prompt` (`str`, *optional*) — The text prompt to guide the image generation.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str`, *optional*) — 用于指导图像生成的文本提示。'
- en: '`negative_prompt` (`str`, *optional*) — A negative prompt to guide the translation
    process.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str`, *optional*) — 用于指导翻译过程的负面提示。'
- en: '`height` (`int`, *optional*) — The height in pixels of the generated image.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *optional*) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*) — The width in pixels of the generated image.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *optional*) — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*) — Higher guidance scale encourages to
    generate images that are closely linked to the text `prompt`, usually at the expense
    of lower image quality.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*) — 更高的引导比例鼓励生成与文本 `prompt` 密切相关的图像，通常以降低图像质量为代价。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于推理的模型。可以是托管在 Hugging Face Hub 上的模型 ID，也可以是部署的推理端点的
    URL。此参数会覆盖实例级别定义的模型。默认为 None。'
- en: Returns
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Image`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`Image`'
- en: The translated image.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译后的图像。
- en: Raises
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，返回的 HTTP 错误状态码不是 HTTP 503。'
- en: Perform image-to-image translation using a specified model.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定模型进行图像到图像的翻译。
- en: You must have `PIL` installed if you want to work with images (`pip install
    Pillow`).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要使用图像进行工作，则必须安装`PIL`（`pip install Pillow`）。
- en: 'Example:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE21]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '#### `image_to_text`'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `image_to_text`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L731)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L731)'
- en: '[PRE22]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Parameters
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image to caption.
    It can be raw bytes, an image file, or a URL to an online image..'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`（`Union[str，Path，bytes，BinaryIO]`）—要添加标题的输入图像。它可以是原始字节，图像文件或在线图像的URL。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`str`，*可选*）—用于推断的模型。可以是托管在Hugging Face Hub上的模型ID或部署的推断端点的URL。此参数将覆盖实例级别定义的模型。默认为None。'
- en: Returns
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The generated text.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的文本。
- en: Raises
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    —如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError`—如果请求失败，并且HTTP错误状态代码不是HTTP 503。'
- en: Takes an input image and return text.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 接受输入图像并返回文本。
- en: Models can have very different outputs depending on your use case (image captioning,
    optical character recognition (OCR), Pix2Struct, etc). Please have a look to the
    model card to learn more about a model’s specificities.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的用例（图像字幕，光学字符识别（OCR），Pix2Struct等），模型的输出可能会有很大的不同。请查看模型卡片以了解有关模型特定性的更多信息。
- en: 'Example:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE23]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '#### `list_deployed_models`'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `list_deployed_models`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L767)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L767)'
- en: '[PRE24]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Parameters
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`frameworks` (`Literal["all"]` or `List[str]` or `str`, *optional*) — The frameworks
    to filter on. By default only a subset of the available frameworks are tested.
    If set to “all”, all available frameworks will be tested. It is also possible
    to provide a single framework or a custom set of frameworks to check.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frameworks`（`Literal["all"]`或`List[str]`或`str`，*可选*）—要过滤的框架。默认情况下，仅测试可用框架的子集。如果设置为“all”，将测试所有可用的框架。还可以提供单个框架或一组自定义框架以进行检查。'
- en: Returns
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict[str, List[str]]`'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict[str，List[str]]`'
- en: A dictionary mapping task names to a sorted list of model IDs.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 将任务名称映射到模型ID的排序列表的字典。
- en: List models currently deployed on the Inference API service.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 列出当前部署在推断API服务上的模型。
- en: This helper checks deployed models framework by framework. By default, it will
    check the 4 main frameworks that are supported and account for 95% of the hosted
    models. However, if you want a complete list of models you can specify `frameworks="all"`
    as input. Alternatively, if you know before-hand which framework you are interested
    in, you can also restrict to search to this one (e.g. `frameworks="text-generation-inference"`).
    The more frameworks are checked, the more time it will take.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 此助手按框架检查部署的模型。默认情况下，它将检查支持的四个主要框架，并占托管模型的95％。但是，如果您想要完整的模型列表，可以指定`frameworks="all"`作为输入。或者，如果您事先知道您感兴趣的框架，也可以将搜索限制为该框架（例如`frameworks="text-generation-inference"`）。检查的框架越多，花费的时间就越多。
- en: This endpoint is mostly useful for discoverability. If you already know which
    model you want to use and want to check its availability, you can directly use
    [get_model_status()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.get_model_status).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 此端点主要用于可发现性。如果您已经知道要使用哪个模型并想要检查其可用性，则可以直接使用[get_model_status()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.get_model_status)。
- en: 'Example:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE25]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '#### `object_detection`'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `object_detection`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L842)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L842)'
- en: '[PRE26]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Parameters
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The image to detect objects
    on. It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`（`Union[str，Path，bytes，BinaryIO]`）—要在其上检测对象的图像。它可以是原始字节，图像文件或在线图像的URL。'
- en: '`model` (`str`, *optional*) — The model to use for object detection. Can be
    a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint.
    If not provided, the default recommended model for object detection (DETR) will
    be used.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`（`str`，*可选*）—用于对象检测的模型。可以是托管在Hugging Face Hub上的模型ID或部署的推断端点的URL。如果未提供，默认推荐的对象检测模型（DETR）将被使用。'
- en: Returns
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[ObjectDetectionOutput]`'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[ObjectDetectionOutput]`'
- en: A list of dictionaries containing the bounding boxes and associated attributes.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 包含边界框和相关属性的字典列表。
- en: Raises
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError` or `ValueError`'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`或`ValueError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    —如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError`—如果请求失败，并且HTTP错误状态代码不是HTTP 503。'
- en: '`ValueError` — If the request output is not a List.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ValueError`—如果请求输出不是列表。'
- en: Perform object detection on the given image using the specified model.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定模型对给定图像执行对象检测。
- en: You must have `PIL` installed if you want to work with images (`pip install
    Pillow`).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要处理图像，必须安装`PIL`（`pip install Pillow`）。
- en: 'Example:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE27]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '#### `post`'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `post`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L172)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L172)'
- en: '[PRE28]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Parameters
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Parameters
- en: '`json` (`Union[str, Dict, List]`, *optional*) — The JSON data to send in the
    request body, specific to each task. Defaults to None.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`json` (`Union[str, Dict, List]`, *optional*) — 要发送到请求体中的JSON数据，针对每个任务特定。默认为None。'
- en: '`data` (`Union[str, Path, bytes, BinaryIO]`, *optional*) — The content to send
    in the request body, specific to each task. It can be raw bytes, a pointer to
    an opened file, a local file path, or a URL to an online resource (image, audio
    file,…). If both `json` and `data` are passed, `data` will take precedence. At
    least `json` or `data` must be provided. Defaults to None.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data` (`Union[str, Path, bytes, BinaryIO]`, *optional*) — 要发送到请求体中的内容，针对每个任务特定。可以是原始字节、指向已打开文件的指针、本地文件路径或在线资源的URL（图像、音频文件等）。如果同时传递了`json`和`data`，则`data`将优先。必须提供至少`json`或`data`。默认为None。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. Will
    override the model defined at the instance level. Defaults to None.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于推理的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是指向部署的推理端点的URL。将覆盖实例级别定义的模型。默认为None。'
- en: '`task` (`str`, *optional*) — The task to perform on the inference. All available
    tasks can be found [here](https://huggingface.co/tasks). Used only to default
    to a recommended model if `model` is not provided. At least `model` or `task`
    must be provided. Defaults to None.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task` (`str`, *optional*) — 在推理上执行的任务。所有可用任务可以在[这里](https://huggingface.co/tasks)找到。仅在未提供`model`时才用于默认推荐模型。必须提供至少`model`或`task`。默认为None。'
- en: '`stream` (`bool`, *optional*) — Whether to iterate over streaming APIs.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stream` (`bool`, *optional*) — 是否迭代流式API。'
- en: Returns
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: Returns
- en: bytes
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: bytes
- en: The raw bytes returned by the server.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器返回的原始字节。
- en: Raises
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并且HTTP状态代码不是HTTP 503。'
- en: Make a POST request to the inference server.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 向推理服务器发出POST请求。
- en: '#### `question_answering`'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `question_answering`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L890)'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L890)'
- en: '[PRE29]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Parameters
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: Parameters
- en: '`question` (`str`) — Question to be answered.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question` (`str`) — 待回答的问题。'
- en: '`context` (`str`) — The context of the question.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`context` (`str`) — 问题的上下文。'
- en: '`model` (`str`) — The model to use for the question answering task. Can be
    a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`) — 用于问答任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是指向部署的推理端点的URL。'
- en: Returns
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Returns
- en: '`Dict`'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict`'
- en: a dictionary of question answering output containing the score, start index,
    end index, and answer.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 包含得分、起始索引、结束索引和答案的问答输出的字典。
- en: Raises
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并且HTTP状态代码不是HTTP 503。'
- en: Retrieve the answer to a question from a given text.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定文本中检索问题的答案。
- en: 'Example:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE30]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '#### `sentence_similarity`'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `sentence_similarity`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L931)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L931)'
- en: '[PRE31]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Parameters
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: Parameters
- en: '`sentence` (`str`) — The main sentence to compare to others.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sentence` (`str`) — 用于与其他句子进行比较的主要句子。'
- en: '`other_sentences` (`List[str]`) — The list of sentences to compare to.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`other_sentences` (`List[str]`) — 要进行比较的句子列表。'
- en: '`model` (`str`, *optional*) — The model to use for the conversational task.
    Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended conversational model will be
    used. Defaults to None.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于对话任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是指向部署的推理端点的URL。如果未提供，默认将使用推荐的对话模型。默认为None。'
- en: Returns
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Returns
- en: '`List[float]`'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[float]`'
- en: The embedding representing the input text.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 表示输入文本的嵌入。
- en: Raises
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并且HTTP状态代码不是HTTP 503。'
- en: Compute the semantic similarity between a sentence and a list of other sentences
    by comparing their embeddings.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 通过比较它们的嵌入来计算句子与其他句子列表之间的语义相似性。
- en: 'Example:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE32]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '#### `summarization`'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `summarization`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L978)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L978)'
- en: '[PRE33]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Parameters
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — The input text to summarize.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 要总结的输入文本。'
- en: '`parameters` (`Dict[str, Any]`, *optional*) — Additional parameters for summarization.
    Check out this [page](https://huggingface.co/docs/api-inference/detailed_parameters#summarization-task)
    for more details.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`parameters` (`Dict[str, Any]`, *optional*) — 用于总结的额外参数。查看此 [页面](https://huggingface.co/docs/api-inference/detailed_parameters#summarization-task)
    获取更多详细信息。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于推理的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。此参数会覆盖实例级别定义的模型。默认为None。'
- en: Returns
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`str`'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The generated summary text.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的摘要文本。
- en: Raises
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，返回的HTTP错误状态码不是HTTP 503。'
- en: Generate a summary of a given text using a specified model.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定的模型生成给定文本的摘要。
- en: 'Example:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE34]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '#### `table_question_answering`'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `table_question_answering`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1021)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1021)'
- en: '[PRE35]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Parameters
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`table` (`str`) — A table of data represented as a dict of lists where entries
    are headers and the lists are all the values, all lists must have the same size.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table` (`str`) — 以字典列表表示的数据表，其中条目是标题，列表是所有值，所有列表必须具有相同的大小。'
- en: '`query` (`str`) — The query in plain text that you want to ask the table.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query` (`str`) — 您想要询问表格的纯文本查询。'
- en: '`model` (`str`) — The model to use for the table-question-answering task. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`) — 用于表格问题回答任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。'
- en: Returns
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict`'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict`'
- en: a dictionary of table question answering output containing the answer, coordinates,
    cells and the aggregator used.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 包含答案、坐标、单元格和使用的聚合器的表格问题回答输出的字典。
- en: Raises
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，返回的HTTP错误状态码不是HTTP 503。'
- en: Retrieve the answer to a question from information given in a table.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 从表中给定的信息中检索问题的答案。
- en: 'Example:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE36]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '#### `tabular_classification`'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tabular_classification`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1066)'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1066)'
- en: '[PRE37]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Parameters
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`table` (`Dict[str, Any]`) — Set of attributes to classify.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table` (`Dict[str, Any]`) — 用于分类的属性集。'
- en: '`model` (`str`) — The model to use for the tabular-classification task. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`) — 用于表格分类任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。'
- en: Returns
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List`'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '`List`'
- en: a list of labels, one per row in the initial table.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 一个标签列表，每行一个标签在初始表中。
- en: Raises
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，返回的HTTP错误状态码不是HTTP 503。'
- en: Classifying a target category (a group) based on a set of attributes.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 基于一组属性对目标类别（一组）进行分类。
- en: 'Example:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE38]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '#### `tabular_regression`'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `tabular_regression`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1110)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1110)'
- en: '[PRE39]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Parameters
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`table` (`Dict[str, Any]`) — Set of attributes stored in a table. The attributes
    used to predict the target can be both numerical and categorical.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table` (`Dict[str, Any]`) — 存储在表中的属性集。用于预测目标的属性可以是数值和分类的。'
- en: '`model` (`str`) — The model to use for the tabular-regression task. Can be
    a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`) — 用于表格回归任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。'
- en: Returns
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List`'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '`List`'
- en: a list of predicted numerical target values.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 一个预测的数值目标值列表。
- en: Raises
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并返回除HTTP 503以外的HTTP错误状态码。'
- en: Predicting a numerical target value given a set of attributes/features in a
    table.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在表中给定一组属性/特征，预测数值目标值。
- en: 'Example:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE40]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '#### `text_classification`'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `text_classification`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1149)'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1149)'
- en: '[PRE41]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Parameters
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — A string to be classified.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 待分类的字符串。'
- en: '`model` (`str`, *optional*) — The model to use for the text classification
    task. Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed
    Inference Endpoint. If not provided, the default recommended text classification
    model will be used. Defaults to None.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于文本分类任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，则将使用默认推荐的文本分类模型。默认为None。'
- en: Returns
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: a list of dictionaries containing the predicted label and associated probability.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签和相关概率的字典列表。
- en: Raises
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并返回除HTTP 503以外的HTTP错误状态码。'
- en: Perform text classification (e.g. sentiment-analysis) on the given text.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 对给定文本执行文本分类（例如情感分析）。
- en: 'Example:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE42]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '#### `text_generation`'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `text_generation`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1277)'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1277)'
- en: '[PRE43]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Parameters
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str`) — Input text.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str`) — 输入文本。'
- en: '`details` (`bool`, *optional*) — By default, text_generation returns a string.
    Pass `details=True` if you want a detailed output (tokens, probabilities, seed,
    finish reason, etc.). Only available for models running on with the `text-generation-inference`
    backend.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`details` (`bool`, *可选*) — 默认情况下，text_generation返回一个字符串。如果要获取详细输出（token、概率、种子、完成原因等），请传递`details=True`。仅适用于在`text-generation-inference`后端上运行的模型。'
- en: '`stream` (`bool`, *optional*) — By default, text_generation returns the full
    generated text. Pass `stream=True` if you want a stream of tokens to be returned.
    Only available for models running on with the `text-generation-inference` backend.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stream` (`bool`, *可选*) — 默认情况下，text_generation返回完整生成的文本。如果要返回token流，请传递`stream=True`。仅适用于在`text-generation-inference`后端上运行的模型。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于推理的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。此参数会覆盖实例级别定义的模型。默认为None。'
- en: '`do_sample` (`bool`) — Activate logits sampling'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_sample` (`bool`) — 激活logits采样'
- en: '`max_new_tokens` (`int`) — Maximum number of generated tokens'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_new_tokens` (`int`) — 生成的token的最大数量'
- en: '`best_of` (`int`) — Generate best_of sequences and return the one if the highest
    token logprobs'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`best_of` (`int`) — 生成best_of序列并返回具有最高token对数概率的一个'
- en: '`repetition_penalty` (`float`) — The parameter for repetition penalty. 1.0
    means no penalty. See [this paper](https://arxiv.org/pdf/1909.05858.pdf) for more
    details.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repetition_penalty` (`float`) — 重复惩罚的参数。1.0表示没有惩罚。有关更多详细信息，请参阅[此论文](https://arxiv.org/pdf/1909.05858.pdf)。'
- en: '`return_full_text` (`bool`) — Whether to prepend the prompt to the generated
    text'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_full_text` (`bool`) — 是否将提示添加到生成的文本之前'
- en: '`seed` (`int`) — Random sampling seed'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seed` (`int`) — 随机采样种子'
- en: '`stop_sequences` (`List[str]`) — Stop generating tokens if a member of `stop_sequences`
    is generated'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stop_sequences` (`List[str]`) — 如果生成了`stop_sequences`中的成员，则停止生成token'
- en: '`temperature` (`float`) — The value used to module the logits distribution.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature` (`float`) — 用于调节logits分布的值。'
- en: '`top_k` (`int`) — The number of highest probability vocabulary tokens to keep
    for top-k-filtering.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_k` (`int`) — 保留最高概率词汇token的数量以进行top-k过滤。'
- en: '`top_p` (`float`) — If set to < 1, only the smallest set of most probable tokens
    with probabilities that add up to `top_p` or higher are kept for generation.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_p` (`float`) — 如果设置为 < 1，则仅保留概率相加达到 `top_p` 或更高的最可能token集合用于生成。'
- en: '`truncate` (`int`) — Truncate inputs tokens to the given size'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncate` (`int`) — 将输入token截断为给定大小'
- en: '`typical_p` (`float`) — Typical Decoding mass See [Typical Decoding for Natural
    Language Generation](https://arxiv.org/abs/2202.00666) for more information'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`typical_p` (`float`) — 典型解码质量。有关更多信息，请参阅[Typical Decoding for Natural Language
    Generation](https://arxiv.org/abs/2202.00666)。'
- en: '`watermark` (`bool`) — Watermarking with [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`watermark` (`bool`) — 使用[A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)进行水印处理'
- en: '`decoder_input_details` (`bool`) — Return the decoder input token logprobs
    and ids. You must set `details=True` as well for it to be taken into account.
    Defaults to `False`.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decoder_input_details` (`bool`) — 返回解码器输入token的对数概率和ID。您必须同时设置`details=True`才能考虑。默认为`False`。'
- en: Returns
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Union[str, TextGenerationResponse, Iterable[str], Iterable[TextGenerationStreamResponse]]`'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '`Union[str, TextGenerationResponse, Iterable[str], Iterable[TextGenerationStreamResponse]]`'
- en: 'Generated text returned from the server:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器返回的生成文本：
- en: if `stream=False` and `details=False`, the generated text is returned as a `str`
    (default)
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`stream=False`和`details=False`，生成的文本将作为`str`返回（默认）
- en: if `stream=True` and `details=False`, the generated text is returned token by
    token as a `Iterable[str]`
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`stream=True`和`details=False`，生成的文本将逐个标记返回，作为`Iterable[str]`。
- en: if `stream=False` and `details=True`, the generated text is returned with more
    details as a [TextGenerationResponse](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationResponse)
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`stream=False`和`details=True`，生成的文本将以更多细节的形式返回，作为[TextGenerationResponse](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationResponse)
- en: if `details=True` and `stream=True`, the generated text is returned token by
    token as a iterable of [TextGenerationStreamResponse](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationStreamResponse)
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`details=True`和`stream=True`，生成的文本将逐个标记返回，作为[TextGenerationStreamResponse](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationStreamResponse)的可迭代对象
- en: Raises
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '`ValidationError` or [InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '`ValidationError` 或 [InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '`ValidationError` — If input values are not valid. No HTTP call is made to
    the server.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ValidationError` — 如果输入值无效。不会向服务器发出HTTP调用。'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，返回的HTTP错误状态码不是HTTP 503。'
- en: Given a prompt, generate the following text.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 给定提示，生成以下文本。
- en: It is recommended to have Pydantic installed in order to get inputs validated.
    This is preferable as it allow early failures.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 建议安装Pydantic以验证输入。这样做更好，因为它可以提前失败。
- en: API endpoint is supposed to run with the `text-generation-inference` backend
    (TGI). This backend is the go-to solution to run large language models at scale.
    However, for some smaller models (e.g. “gpt2”) the default `transformers` + `api-inference`
    solution is still in use. Both approaches have very similar APIs, but not exactly
    the same. This method is compatible with both approaches but some parameters are
    only available for `text-generation-inference`. If some parameters are ignored,
    a warning message is triggered but the process continues correctly.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: API端点应该使用`text-generation-inference`后端（TGI）运行。这个后端是运行大型语言模型的首选解决方案。但是，对于一些较小的模型（例如“gpt2”），仍在使用默认的`transformers`
    + `api-inference`解决方案。这两种方法具有非常相似的API，但并非完全相同。此方法与两种方法兼容，但某些参数仅适用于`text-generation-inference`。如果忽略了某些参数，将触发警告消息，但进程将继续正确进行。
- en: To learn more about the TGI project, please refer to [https://github.com/huggingface/text-generation-inference](https://github.com/huggingface/text-generation-inference).
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关TGI项目的更多信息，请参阅[https://github.com/huggingface/text-generation-inference](https://github.com/huggingface/text-generation-inference)。
- en: 'Example:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE44]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '#### `text_to_image`'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `text_to_image`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1544)'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1544)'
- en: '[PRE45]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Parameters
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`prompt` (`str`) — The prompt to generate an image from.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str`) — 生成图像的提示。'
- en: '`negative_prompt` (`str`, *optional*) — An optional negative prompt for the
    image generation.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str`, *可选*) — 用于图像生成的可选负面提示。'
- en: '`height` (`float`, *optional*) — The height in pixels of the image to generate.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`float`, *可选*) — 要生成的图像的像素高度。'
- en: '`width` (`float`, *optional*) — The width in pixels of the image to generate.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`float`, *可选*) — 要生成的图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *可选*) — 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*) — Higher guidance scale encourages to
    generate images that are closely linked to the text `prompt`, usually at the expense
    of lower image quality.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *可选*) — 更高的引导比例鼓励生成与文本`prompt`密切相关的图像，通常以降低图像质量为代价。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于推理的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。此参数将覆盖实例级别定义的模型。默认为None。'
- en: Returns
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Image`'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '`Image`'
- en: The generated image.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图像。
- en: Raises
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，返回的HTTP错误状态码不是HTTP 503。'
- en: Generate an image based on a given text using a specified model.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 根据给定文本使用指定模型生成图像。
- en: You must have `PIL` installed if you want to work with images (`pip install
    Pillow`).
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要处理图像，必须安装`PIL`（`pip install Pillow`）。
- en: 'Example:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE46]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '#### `text_to_speech`'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `text_to_speech`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1624)'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1624)'
- en: '[PRE47]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Parameters
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: Parameters
- en: '`text` (`str`) — The text to synthesize.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 要合成的文本。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于推理的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。此参数将覆盖实例级别定义的模型。默认为None。'
- en: Returns
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: Returns
- en: '`bytes`'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '`bytes`'
- en: The generated audio.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的音频。
- en: Raises
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并且HTTP错误状态码不是HTTP 503。'
- en: Synthesize an audio of a voice pronouncing a given text.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 合成一个发音给定文本的声音的音频。
- en: 'Example:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE48]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '#### `token_classification`'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `token_classification`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1656)'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1656)'
- en: '[PRE49]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Parameters
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: Parameters
- en: '`text` (`str`) — A string to be classified.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 要分类的字符串。'
- en: '`model` (`str`, *optional*) — The model to use for the token classification
    task. Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed
    Inference Endpoint. If not provided, the default recommended token classification
    model will be used. Defaults to None.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于标记分类任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，则将使用默认推荐的标记分类模型。默认为None。'
- en: Returns
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: Returns
- en: '`List[Dict]`'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: List of token classification outputs containing the entity group, confidence
    score, word, start and end index.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 包含实体组、置信度分数、单词、起始和结束索引的标记分类输出列表。
- en: Raises
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并且HTTP错误状态码不是HTTP 503。'
- en: Perform token classification on the given text. Usually used for sentence parsing,
    either grammatical, or Named Entity Recognition (NER) to understand keywords contained
    within text.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 对给定文本执行标记分类。通常用于句子解析，无论是语法还是命名实体识别（NER），以理解文本中包含的关键字。
- en: 'Example:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE50]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '#### `translation`'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `translation`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1703)'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1703)'
- en: '[PRE51]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Parameters
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: Parameters
- en: '`text` (`str`) — A string to be translated.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 要翻译的字符串。'
- en: '`model` (`str`, *optional*) — The model to use for the translation task. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended translation model will be used.
    Defaults to None.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于翻译任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，则将使用默认推荐的翻译模型。默认为None。'
- en: '`src_lang` (`str`, *optional*) — Source language of the translation task, i.e.
    input language. Cannot be passed without `tgt_lang`.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`src_lang` (`str`, *optional*) — 翻译任务的源语言，即输入语言。不能在没有`tgt_lang`的情况下传递。'
- en: '`tgt_lang` (`str`, *optional*) — Target language of the translation task, i.e.
    output language. Cannot be passed without `src_lang`.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tgt_lang` (`str`, *optional*) — 翻译任务的目标语言，即输出语言。不能在没有`src_lang`的情况下传递。'
- en: Returns
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: Returns
- en: '`str`'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: '`str`'
- en: The generated translated text.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的翻译文本。
- en: Raises
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError` or `ValueError`'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `HTTPError` 或 `ValueError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并且HTTP错误状态码不是HTTP 503。'
- en: '`ValueError` — If only one of the `src_lang` and `tgt_lang` arguments are provided.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ValueError` — 如果只提供了`src_lang`和`tgt_lang`参数中的一个。'
- en: Convert text from one language to another.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 将文本从一种语言转换为另一种语言。
- en: Check out [https://huggingface.co/tasks/translation](https://huggingface.co/tasks/translation)
    for more information on how to choose the best model for your specific use case.
    Source and target languages usually depend on the model. However, it is possible
    to specify source and target languages for certain models. If you are working
    with one of these models, you can use `src_lang` and `tgt_lang` arguments to pass
    the relevant information. You can find this information in the model card.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[https://huggingface.co/tasks/translation](https://huggingface.co/tasks/translation)以获取有关如何为特定用例选择最佳模型的更多信息。源语言和目标语言通常取决于模型。但是，可以为某些模型指定源语言和目标语言。如果您正在使用这些模型之一，可以使用`src_lang`和`tgt_lang`参数传递相关信息。您可以在模型卡中找到这些信息。
- en: 'Example:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE52]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Specifying languages:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 指定语言：
- en: '[PRE53]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '#### `visual_question_answering`'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `visual_question_answering`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L399)'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L399)'
- en: '[PRE54]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Parameters
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image for the context.
    It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`Union[str, Path, bytes, BinaryIO]`) — 上下文的输入图像。可以是原始字节、图像文件或在线图像的URL。'
- en: '`question` (`str`) — Question to be answered.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question` (`str`) — 要回答的问题。'
- en: '`model` (`str`, *optional*) — The model to use for the visual question answering
    task. Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed
    Inference Endpoint. If not provided, the default recommended visual question answering
    model will be used. Defaults to None.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于视觉问答任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，默认推荐的视觉问答模型将被使用。默认为None。'
- en: Returns
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: a list of dictionaries containing the predicted label and associated probability.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签及其相关概率的字典列表。
- en: Raises
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '`InferenceTimeoutError` or `HTTPError`'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '`InferenceTimeoutError`或`HTTPError`'
- en: '`InferenceTimeoutError` — If the model is unavailable or the request times
    out.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`InferenceTimeoutError` — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并且HTTP状态代码不是HTTP 503。'
- en: Answering open-ended questions based on an image.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图像回答开放式问题。
- en: 'Example:'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE55]'
  id: totrans-512
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '#### `zero_shot_classification`'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `zero_shot_classification`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1768)'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1768)'
- en: '[PRE56]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Parameters
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — The input text to classify.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 要分类的输入文本。'
- en: '`labels` (`List[str]`) — List of string possible labels. There must be at least
    2 labels.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`List[str]`) — 字符串可能标签的列表。必须至少有2个标签。'
- en: '`multi_label` (`bool`) — Boolean that is set to True if classes can overlap.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multi_label` (`bool`) — 如果类别可以重叠，则设置为True。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于推理的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。此参数将覆盖实例级别定义的模型。默认为None。'
- en: Returns
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: List of classification outputs containing the predicted labels and their confidence.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签及其置信度的分类输出列表。
- en: Raises
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并且HTTP状态代码不是HTTP 503。'
- en: Provide as input a text and a set of candidate labels to classify the input
    text.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 提供一个文本和一组候选标签作为输入，对输入文本进行分类。
- en: 'Example:'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE57]'
  id: totrans-530
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '#### `zero_shot_image_classification`'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `zero_shot_image_classification`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1840)'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_client.py#L1840)'
- en: '[PRE58]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Parameters
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image to caption.
    It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`Union[str, Path, bytes, BinaryIO]`) — 输入图像以进行描述。可以是原始字节、图像文件或在线图像的URL。'
- en: '`labels` (`List[str]`) — List of string possible labels. There must be at least
    2 labels.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels` (`List[str]`) — 字符串可能标签的列表。必须至少有2个标签。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于推理的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。此参数将覆盖实例级别定义的模型。默认为None。'
- en: Returns
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: List of classification outputs containing the predicted labels and their confidence.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签及其置信度的分类输出列表。
- en: Raises
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `HTTPError`'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`HTTPError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`HTTPError` — If the request fails with an HTTP error status code other than
    HTTP 503.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPError` — 如果请求失败，并且HTTP状态代码不是HTTP 503。'
- en: Provide input image and text labels to predict text labels for the image.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 提供输入图像和文本标签以预测图像的文本标签。
- en: 'Example:'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE59]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Async Inference Client
  id: totrans-548
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异步推理客户端
- en: 'An async version of the client is also provided, based on `asyncio` and `aiohttp`.
    To use it, you can either install `aiohttp` directly or use the `[inference]`
    extra:'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 还提供了一个基于`asyncio`和`aiohttp`的异步版本的客户端。要使用它，可以直接安装`aiohttp`，或者使用`[inference]`额外选项：
- en: '[PRE60]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '### `class huggingface_hub.AsyncInferenceClient`'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '### `class huggingface_hub.AsyncInferenceClient`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L89)'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L89)'
- en: '[PRE61]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Parameters
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`model` (`str`, `optional`) — The model to run inference with. Can be a model
    id hosted on the Hugging Face Hub, e.g. `bigcode/starcoder` or a URL to a deployed
    Inference Endpoint. Defaults to None, in which case a recommended model is automatically
    selected for the task.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, `optional`) — 用于推理的模型。可以是托管在Hugging Face Hub上的模型ID，例如`bigcode/starcoder`，也可以是部署的推理端点的URL。默认为None，此时将自动选择任务的推荐模型。'
- en: '`token` (`str`, *optional*) — Hugging Face token. Will default to the locally
    saved token. Pass `token=False` if you don’t want to send your token to the server.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token` (`str`, *optional*) — Hugging Face令牌。将默认使用本地保存的令牌。如果不想将令牌发送到服务器，请传递`token=False`。'
- en: '`timeout` (`float`, `optional`) — The maximum number of seconds to wait for
    a response from the server. Loading a new model in Inference API can take up to
    several minutes. Defaults to None, meaning it will loop until the server is available.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeout` (`float`, `optional`) — 等待服务器响应的最大秒数。在推理API中加载新模型可能需要几分钟。默认为None，表示会循环直到服务器可用。'
- en: '`headers` (`Dict[str, str]`, `optional`) — Additional headers to send to the
    server. By default only the authorization and user-agent headers are sent. Values
    in this dictionary will override the default values.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`headers` (`Dict[str, str]`, `optional`) — 要发送到服务器的额外标头。默认情况下，只发送授权和用户代理标头。此字典中的值将覆盖默认值。'
- en: '`cookies` (`Dict[str, str]`, `optional`) — Additional cookies to send to the
    server.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cookies` (`Dict[str, str]`, `optional`) — 要发送到服务器的额外cookie。'
- en: Initialize a new Inference Client.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化一个新的推理客户端。
- en: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    aims to provide a unified experience to perform inference. The client can be used
    seamlessly with either the (free) Inference API or self-hosted Inference Endpoints.'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)旨在提供执行推理的统一体验。该客户端可以无缝地与（免费的）推理API或自托管的推理端点一起使用。'
- en: '#### `audio_classification`'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `audio_classification`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L259)'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L259)'
- en: '[PRE62]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Parameters
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`audio` (Union[str, Path, bytes, BinaryIO]) — The audio content to classify.
    It can be raw audio bytes, a local audio file, or a URL pointing to an audio file.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio` (Union[str, Path, bytes, BinaryIO]) — 要分类的音频内容。可以是原始音频字节、本地音频文件或指向音频文件的URL。'
- en: '`model` (`str`, *optional*) — The model to use for audio classification. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended model for audio classification
    will be used.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于音频分类的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，则将使用默认推荐的音频分类模型。'
- en: Returns
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: The classification output containing the predicted label and its confidence.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签及其置信度的分类输出。
- en: Raises
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`aiohttp.ClientResponseError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aiohttp.ClientResponseError` — 如果请求失败，并且HTTP错误状态代码不是HTTP 503。'
- en: Perform audio classification on the provided audio content.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 对提供的音频内容执行音频分类。
- en: 'Example:'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE63]'
  id: totrans-577
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '#### `automatic_speech_recognition`'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `automatic_speech_recognition`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L298)'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '[<来源>](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L298)'
- en: '[PRE64]'
  id: totrans-580
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Parameters
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`audio` (Union[str, Path, bytes, BinaryIO]) — The content to transcribe. It
    can be raw audio bytes, local audio file, or a URL to an audio file.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audio` (Union[str, Path, bytes, BinaryIO]) — 要转录的内容。可以是原始音频字节、本地音频文件或音频文件的URL。'
- en: '`model` (`str`, *optional*) — The model to use for ASR. Can be a model ID hosted
    on the Hugging Face Hub or a URL to a deployed Inference Endpoint. If not provided,
    the default recommended model for ASR will be used.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于ASR的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，则将使用默认推荐的ASR模型。'
- en: Returns
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: str
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: str
- en: The transcribed text.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 转录的文本。
- en: Raises
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: Raises
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)或`aiohttp.ClientResponseError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aiohttp.ClientResponseError` — 如果请求失败，返回的HTTP错误状态码不是HTTP 503。'
- en: Perform automatic speech recognition (ASR or audio-to-text) on the given audio
    content.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 对给定音频内容执行自动语音识别（ASR或音频转文本）。
- en: 'Example:'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE65]'
  id: totrans-593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '#### `conversational`'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `conversational`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L335)'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L335)'
- en: '[PRE66]'
  id: totrans-596
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Parameters
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — The last input from the user in the conversation.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 用户在对话中的最后输入。'
- en: '`generated_responses` (`List[str]`, *optional*) — A list of strings corresponding
    to the earlier replies from the model. Defaults to None.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generated_responses` (`List[str]`, *可选*) — 与模型先前回复对应的字符串列表。默认为None。'
- en: '`past_user_inputs` (`List[str]`, *optional*) — A list of strings corresponding
    to the earlier replies from the user. Should be the same length as `generated_responses`.
    Defaults to None.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`past_user_inputs` (`List[str]`, *可选*) — 与用户先前回复对应的字符串列表。应与`generated_responses`长度相同。默认为None。'
- en: '`parameters` (`Dict[str, Any]`, *optional*) — Additional parameters for the
    conversational task. Defaults to None. For more details about the available parameters,
    please refer to [this page](https://huggingface.co/docs/api-inference/detailed_parameters#conversational-task)'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`parameters` (`Dict[str, Any]`, *可选*) — 对话任务的其他参数。默认为None。有关可用参数的更多详细信息，请参考[此页面](https://huggingface.co/docs/api-inference/detailed_parameters#conversational-task)'
- en: '`model` (`str`, *optional*) — The model to use for the conversational task.
    Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended conversational model will be
    used. Defaults to None.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于对话任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，默认推荐的对话模型将被使用。默认为None。'
- en: Returns
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Dict`'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dict`'
- en: The generated conversational output.
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的对话输出。
- en: Raises
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `aiohttp.ClientResponseError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aiohttp.ClientResponseError` — 如果请求失败，返回的HTTP错误状态码不是HTTP 503。'
- en: Generate conversational responses based on the given input text (i.e. chat with
    the API).
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 根据给定的输入文本生成对话响应（即与API聊天）。
- en: 'Example:'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE67]'
  id: totrans-612
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '#### `document_question_answering`'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `document_question_answering`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L442)'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L442)'
- en: '[PRE68]'
  id: totrans-615
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Parameters
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image for the context.
    It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`Union[str, Path, bytes, BinaryIO]`) — 上下文的输入图像。可以是原始字节、图像文件或在线图像的URL。'
- en: '`question` (`str`) — Question to be answered.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`question` (`str`) — 要回答的问题。'
- en: '`model` (`str`, *optional*) — The model to use for the document question answering
    task. Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed
    Inference Endpoint. If not provided, the default recommended document question
    answering model will be used. Defaults to None.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于文档问答任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，默认推荐的文档问答模型将被使用。默认为None。'
- en: Returns
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: a list of dictionaries containing the predicted label, associated probability,
    word ids, and page number.
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 包含预测标签、相关概率、单词ID和页码的字典列表。
- en: Raises
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `aiohttp.ClientResponseError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aiohttp.ClientResponseError` — 如果请求失败，返回的HTTP错误状态码不是HTTP 503。'
- en: Answer questions on document images.
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 回答文档图像上的问题。
- en: 'Example:'
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE69]'
  id: totrans-629
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '#### `feature_extraction`'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `feature_extraction`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L484)'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L484)'
- en: '[PRE70]'
  id: totrans-632
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Parameters
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`text` (`str`) — The text to embed.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text` (`str`) — 要嵌入的文本。'
- en: '`model` (`str`, *optional*) — The model to use for the conversational task.
    Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended conversational model will be
    used. Defaults to None.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *可选*) — 用于对话任务的模型。可以是托管在Hugging Face Hub上的模型ID，也可以是部署的推理端点的URL。如果未提供，默认推荐的对话模型将被使用。默认为None。'
- en: Returns
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`np.ndarray`'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: '`np.ndarray`'
- en: The embedding representing the input text as a float32 numpy array.
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入文本表示为float32 numpy数组的嵌入。
- en: Raises
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `aiohttp.ClientResponseError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate embeddings for a given text.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-645
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '#### `fill_mask`'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L521)'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-648
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Parameters
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
- en: '`text` (`str`) — a string to be filled from, must contain the [MASK] token
    (check model card for exact name of the mask).'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for the fill mask task. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended fill mask model will be used.
    Defaults to None.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
- en: '`List[Dict]`'
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
- en: a list of fill mask output dictionaries containing the predicted label, associated
    probability, token reference, and completed text.
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fill in a hole with a missing word (token to be precise).
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  id: totrans-661
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '#### `get_model_status`'
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1969)'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-664
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Parameters
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — Identifier of the model for witch the status
    gonna be checked. If model is not provided, the model associated with this instance
    of [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    will be used. Only InferenceAPI service can be checked so the identifier cannot
    be a URL.'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
- en: '`ModelStatus`'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
- en: 'An instance of ModelStatus dataclass, containing information, about the state
    of the model: load, state, compute type and framework.'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
- en: Get the status of a model hosted on the Inference API.
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
- en: This endpoint is mostly useful when you already know which model you want to
    use and want to check its availability. If you want to discover already deployed
    models, you should rather use [list_deployed_models()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.list_deployed_models).
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-673
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '#### `get_recommended_model`'
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1945)'
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-676
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Parameters
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
- en: '`task` (`str`) — The Hugging Face task to get which model Hugging Face recommends.
    All available tasks can be found [here](https://huggingface.co/tasks).'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
- en: '`str`'
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
- en: Name of the model recommended for the input task.
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
- en: '`ValueError`'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
- en: '`ValueError` — If Hugging Face has no recommendation for the input task.'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get the model Hugging Face recommends for the input task.
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
- en: '#### `image_classification`'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L562)'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-688
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Parameters
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The image to classify. It can
    be raw bytes, an image file, or a URL to an online image.'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for image classification. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended model for image classification
    will be used.'
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
- en: '`List[Dict]`'
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
- en: a list of dictionaries containing the predicted label and associated probability.
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `aiohttp.ClientResponseError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aiohttp.ClientResponseError` — 如果请求失败，HTTP 状态码不是 HTTP 503。'
- en: Perform image classification on the given image using the specified model.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定模型对给定图像执行图像分类。
- en: 'Example:'
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE78]'
  id: totrans-701
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '#### `image_segmentation`'
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `image_segmentation`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L599)'
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L599)'
- en: '[PRE79]'
  id: totrans-704
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Parameters
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The image to segment. It can
    be raw bytes, an image file, or a URL to an online image.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`Union[str, Path, bytes, BinaryIO]`) — 要分割的图像。可以是原始字节、图像文件或在线图像的 URL。'
- en: '`model` (`str`, *optional*) — The model to use for image segmentation. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended model for image segmentation
    will be used.'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于图像分割的模型。可以是托管在 Hugging Face Hub 上的模型 ID，也可以是部署的推理端点的
    URL。如果未提供，默认推荐的图像分割模型将被使用。'
- en: Returns
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`List[Dict]`'
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: '`List[Dict]`'
- en: A list of dictionaries containing the segmented masks and associated attributes.
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 包含分割掩模和相关属性的字典列表。
- en: Raises
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `aiohttp.ClientResponseError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aiohttp.ClientResponseError` — 如果请求失败，HTTP 状态码不是 HTTP 503。'
- en: Perform image segmentation on the given image using the specified model.
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定模型对给定图像执行图像分割。
- en: You must have `PIL` installed if you want to work with images (`pip install
    Pillow`).
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要处理图像，必须安装 `PIL` (`pip install Pillow`)。
- en: 'Example:'
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE80]'
  id: totrans-718
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '#### `image_to_image`'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `image_to_image`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L651)'
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L651)'
- en: '[PRE81]'
  id: totrans-721
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Parameters
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image for translation.
    It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` (`Union[str, Path, bytes, BinaryIO]`) — 用于翻译的输入图像。可以是原始字节、图像文件或在线图像的
    URL。'
- en: '`prompt` (`str`, *optional*) — The text prompt to guide the image generation.'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt` (`str`, *optional*) — 用于引导图像生成的文本提示。'
- en: '`negative_prompt` (`str`, *optional*) — A negative prompt to guide the translation
    process.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`negative_prompt` (`str`, *optional*) — 用于引导翻译过程的负面提示。'
- en: '`height` (`int`, *optional*) — The height in pixels of the generated image.'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height` (`int`, *optional*) — 生成图像的像素高度。'
- en: '`width` (`int`, *optional*) — The width in pixels of the generated image.'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width` (`int`, *optional*) — 生成图像的像素宽度。'
- en: '`num_inference_steps` (`int`, *optional*) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference.'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inference_steps` (`int`, *optional*) — 降噪步骤的数量。更多的降噪步骤通常会导致更高质量的图像，但会降低推理速度。'
- en: '`guidance_scale` (`float`, *optional*) — Higher guidance scale encourages to
    generate images that are closely linked to the text `prompt`, usually at the expense
    of lower image quality.'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guidance_scale` (`float`, *optional*) — 更高的引导比例鼓励生成与文本提示紧密相关的图像，通常会降低图像质量。'
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` (`str`, *optional*) — 用于推理的模型。可以是托管在 Hugging Face Hub 上的模型 ID，也可以是部署的推理端点的
    URL。此参数会覆盖实例级别定义的模型。默认为 None。'
- en: Returns
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '`Image`'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: '`Image`'
- en: The translated image.
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译后的图像。
- en: Raises
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 引发
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    或 `aiohttp.ClientResponseError`'
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — 如果模型不可用或请求超时。'
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aiohttp.ClientResponseError` — 如果请求失败，HTTP 状态码不是 HTTP 503。'
- en: Perform image-to-image translation using a specified model.
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定模型执行图像到图像的翻译。
- en: You must have `PIL` installed if you want to work with images (`pip install
    Pillow`).
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要处理图像，必须安装 `PIL` (`pip install Pillow`)。
- en: 'Example:'
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE82]'
  id: totrans-741
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '#### `image_to_text`'
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: '#### `image_to_text`'
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L736)'
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L736)'
- en: '[PRE83]'
  id: totrans-744
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Parameters
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image to caption.
    It can be raw bytes, an image file, or a URL to an online image..'
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
- en: '`str`'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
- en: The generated text.
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Takes an input image and return text.
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
- en: Models can have very different outputs depending on your use case (image captioning,
    optical character recognition (OCR), Pix2Struct, etc). Please have a look to the
    model card to learn more about a model’s specificities.
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  id: totrans-758
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '#### `list_deployed_models`'
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L773)'
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  id: totrans-761
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Parameters
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
- en: '`frameworks` (`Literal["all"]` or `List[str]` or `str`, *optional*) — The frameworks
    to filter on. By default only a subset of the available frameworks are tested.
    If set to “all”, all available frameworks will be tested. It is also possible
    to provide a single framework or a custom set of frameworks to check.'
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict[str, List[str]]`'
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
- en: A dictionary mapping task names to a sorted list of model IDs.
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
- en: List models currently deployed on the Inference API service.
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
- en: This helper checks deployed models framework by framework. By default, it will
    check the 4 main frameworks that are supported and account for 95% of the hosted
    models. However, if you want a complete list of models you can specify `frameworks="all"`
    as input. Alternatively, if you know before-hand which framework you are interested
    in, you can also restrict to search to this one (e.g. `frameworks="text-generation-inference"`).
    The more frameworks are checked, the more time it will take.
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
- en: This endpoint is mostly useful for discoverability. If you already know which
    model you want to use and want to check its availability, you can directly use
    [get_model_status()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.get_model_status).
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  id: totrans-771
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '#### `object_detection`'
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L854)'
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  id: totrans-774
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Parameters
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The image to detect objects
    on. It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for object detection. Can be
    a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint.
    If not provided, the default recommended model for object detection (DETR) will
    be used.'
  id: totrans-777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
- en: '`List[ObjectDetectionOutput]`'
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
- en: A list of dictionaries containing the bounding boxes and associated attributes.
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError` or `ValueError`'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ValueError` — If the request output is not a List.'
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform object detection on the given image using the specified model.
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
- en: You must have `PIL` installed if you want to work with images (`pip install
    Pillow`).
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  id: totrans-789
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '#### `post`'
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L156)'
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  id: totrans-792
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Parameters
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
- en: '`json` (`Union[str, Dict, List]`, *optional*) — The JSON data to send in the
    request body, specific to each task. Defaults to None.'
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data` (`Union[str, Path, bytes, BinaryIO]`, *optional*) — The content to send
    in the request body, specific to each task. It can be raw bytes, a pointer to
    an opened file, a local file path, or a URL to an online resource (image, audio
    file,…). If both `json` and `data` are passed, `data` will take precedence. At
    least `json` or `data` must be provided. Defaults to None.'
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. Will
    override the model defined at the instance level. Defaults to None.'
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`task` (`str`, *optional*) — The task to perform on the inference. All available
    tasks can be found [here](https://huggingface.co/tasks). Used only to default
    to a recommended model if `model` is not provided. At least `model` or `task`
    must be provided. Defaults to None.'
  id: totrans-797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stream` (`bool`, *optional*) — Whether to iterate over streaming APIs.'
  id: totrans-798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
- en: bytes
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
- en: The raw bytes returned by the server.
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make a POST request to the inference server.
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
- en: '#### `question_answering`'
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L903)'
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  id: totrans-809
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Parameters
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
- en: '`question` (`str`) — Question to be answered.'
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`context` (`str`) — The context of the question.'
  id: totrans-812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`) — The model to use for the question answering task. Can be
    a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint.'
  id: totrans-813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict`'
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
- en: a dictionary of question answering output containing the score, start index,
    end index, and answer.
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieve the answer to a question from a given text.
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  id: totrans-823
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '#### `sentence_similarity`'
  id: totrans-824
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L945)'
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  id: totrans-826
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: Parameters
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
- en: '`sentence` (`str`) — The main sentence to compare to others.'
  id: totrans-828
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`other_sentences` (`List[str]`) — The list of sentences to compare to.'
  id: totrans-829
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for the conversational task.
    Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended conversational model will be
    used. Defaults to None.'
  id: totrans-830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
- en: '`List[float]`'
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
- en: The embedding representing the input text.
  id: totrans-833
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute the semantic similarity between a sentence and a list of other sentences
    by comparing their embeddings.
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  id: totrans-840
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '#### `summarization`'
  id: totrans-841
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L993)'
  id: totrans-842
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  id: totrans-843
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Parameters
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
- en: '`text` (`str`) — The input text to summarize.'
  id: totrans-845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`parameters` (`Dict[str, Any]`, *optional*) — Additional parameters for summarization.
    Check out this [page](https://huggingface.co/docs/api-inference/detailed_parameters#summarization-task)
    for more details.'
  id: totrans-846
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
- en: '`str`'
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
- en: The generated summary text.
  id: totrans-850
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate a summary of a given text using a specified model.
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  id: totrans-857
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '#### `table_question_answering`'
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1037)'
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  id: totrans-860
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Parameters
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
- en: '`table` (`str`) — A table of data represented as a dict of lists where entries
    are headers and the lists are all the values, all lists must have the same size.'
  id: totrans-862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`query` (`str`) — The query in plain text that you want to ask the table.'
  id: totrans-863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`) — The model to use for the table-question-answering task. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint.'
  id: totrans-864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
- en: '`Dict`'
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
- en: a dictionary of table question answering output containing the answer, coordinates,
    cells and the aggregator used.
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-870
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieve the answer to a question from information given in a table.
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-873
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  id: totrans-874
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '#### `tabular_classification`'
  id: totrans-875
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1083)'
  id: totrans-876
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  id: totrans-877
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: Parameters
  id: totrans-878
  prefs: []
  type: TYPE_NORMAL
- en: '`table` (`Dict[str, Any]`) — Set of attributes to classify.'
  id: totrans-879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`) — The model to use for the tabular-classification task. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint.'
  id: totrans-880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
- en: '`List`'
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
- en: a list of labels, one per row in the initial table.
  id: totrans-883
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-884
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-885
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-886
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-887
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifying a target category (a group) based on a set of attributes.
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-889
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  id: totrans-890
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '#### `tabular_regression`'
  id: totrans-891
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1128)'
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  id: totrans-893
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Parameters
  id: totrans-894
  prefs: []
  type: TYPE_NORMAL
- en: '`table` (`Dict[str, Any]`) — Set of attributes stored in a table. The attributes
    used to predict the target can be both numerical and categorical.'
  id: totrans-895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`) — The model to use for the tabular-regression task. Can be
    a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint.'
  id: totrans-896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-897
  prefs: []
  type: TYPE_NORMAL
- en: '`List`'
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
- en: a list of predicted numerical target values.
  id: totrans-899
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-902
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-903
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting a numerical target value given a set of attributes/features in a
    table.
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-905
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  id: totrans-906
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '#### `text_classification`'
  id: totrans-907
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1168)'
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  id: totrans-909
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: Parameters
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
- en: '`text` (`str`) — A string to be classified.'
  id: totrans-911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for the text classification
    task. Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed
    Inference Endpoint. If not provided, the default recommended text classification
    model will be used. Defaults to None.'
  id: totrans-912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
- en: '`List[Dict]`'
  id: totrans-914
  prefs: []
  type: TYPE_NORMAL
- en: a list of dictionaries containing the predicted label and associated probability.
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-916
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-919
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform text classification (e.g. sentiment-analysis) on the given text.
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-921
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  id: totrans-922
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '#### `text_generation`'
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1297)'
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  id: totrans-925
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: Parameters
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str`) — Input text.'
  id: totrans-927
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`details` (`bool`, *optional*) — By default, text_generation returns a string.
    Pass `details=True` if you want a detailed output (tokens, probabilities, seed,
    finish reason, etc.). Only available for models running on with the `text-generation-inference`
    backend.'
  id: totrans-928
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stream` (`bool`, *optional*) — By default, text_generation returns the full
    generated text. Pass `stream=True` if you want a stream of tokens to be returned.
    Only available for models running on with the `text-generation-inference` backend.'
  id: totrans-929
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-930
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`do_sample` (`bool`) — Activate logits sampling'
  id: totrans-931
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_new_tokens` (`int`) — Maximum number of generated tokens'
  id: totrans-932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`best_of` (`int`) — Generate best_of sequences and return the one if the highest
    token logprobs'
  id: totrans-933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`repetition_penalty` (`float`) — The parameter for repetition penalty. 1.0
    means no penalty. See [this paper](https://arxiv.org/pdf/1909.05858.pdf) for more
    details.'
  id: totrans-934
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_full_text` (`bool`) — Whether to prepend the prompt to the generated
    text'
  id: totrans-935
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`seed` (`int`) — Random sampling seed'
  id: totrans-936
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stop_sequences` (`List[str]`) — Stop generating tokens if a member of `stop_sequences`
    is generated'
  id: totrans-937
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`temperature` (`float`) — The value used to module the logits distribution.'
  id: totrans-938
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_k` (`int`) — The number of highest probability vocabulary tokens to keep
    for top-k-filtering.'
  id: totrans-939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_p` (`float`) — If set to < 1, only the smallest set of most probable tokens
    with probabilities that add up to `top_p` or higher are kept for generation.'
  id: totrans-940
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`truncate` (`int`) — Truncate inputs tokens to the given size'
  id: totrans-941
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`typical_p` (`float`) — Typical Decoding mass See [Typical Decoding for Natural
    Language Generation](https://arxiv.org/abs/2202.00666) for more information'
  id: totrans-942
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`watermark` (`bool`) — Watermarking with [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)'
  id: totrans-943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_input_details` (`bool`) — Return the decoder input token logprobs
    and ids. You must set `details=True` as well for it to be taken into account.
    Defaults to `False`.'
  id: totrans-944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-945
  prefs: []
  type: TYPE_NORMAL
- en: '`Union[str, TextGenerationResponse, Iterable[str], Iterable[TextGenerationStreamResponse]]`'
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
- en: 'Generated text returned from the server:'
  id: totrans-947
  prefs: []
  type: TYPE_NORMAL
- en: if `stream=False` and `details=False`, the generated text is returned as a `str`
    (default)
  id: totrans-948
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if `stream=True` and `details=False`, the generated text is returned token by
    token as a `Iterable[str]`
  id: totrans-949
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if `stream=False` and `details=True`, the generated text is returned with more
    details as a [TextGenerationResponse](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationResponse)
  id: totrans-950
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if `details=True` and `stream=True`, the generated text is returned token by
    token as a iterable of [TextGenerationStreamResponse](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationStreamResponse)
  id: totrans-951
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raises
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
- en: '`ValidationError` or [InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-953
  prefs: []
  type: TYPE_NORMAL
- en: '`ValidationError` — If input values are not valid. No HTTP call is made to
    the server.'
  id: totrans-954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-955
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-956
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given a prompt, generate the following text.
  id: totrans-957
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended to have Pydantic installed in order to get inputs validated.
    This is preferable as it allow early failures.
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
- en: API endpoint is supposed to run with the `text-generation-inference` backend
    (TGI). This backend is the go-to solution to run large language models at scale.
    However, for some smaller models (e.g. “gpt2”) the default `transformers` + `api-inference`
    solution is still in use. Both approaches have very similar APIs, but not exactly
    the same. This method is compatible with both approaches but some parameters are
    only available for `text-generation-inference`. If some parameters are ignored,
    a warning message is triggered but the process continues correctly.
  id: totrans-959
  prefs: []
  type: TYPE_NORMAL
- en: To learn more about the TGI project, please refer to [https://github.com/huggingface/text-generation-inference](https://github.com/huggingface/text-generation-inference).
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  id: totrans-962
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '#### `text_to_image`'
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1566)'
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  id: totrans-965
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: Parameters
  id: totrans-966
  prefs: []
  type: TYPE_NORMAL
- en: '`prompt` (`str`) — The prompt to generate an image from.'
  id: totrans-967
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`negative_prompt` (`str`, *optional*) — An optional negative prompt for the
    image generation.'
  id: totrans-968
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height` (`float`, *optional*) — The height in pixels of the image to generate.'
  id: totrans-969
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width` (`float`, *optional*) — The width in pixels of the image to generate.'
  id: totrans-970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_inference_steps` (`int`, *optional*) — The number of denoising steps.
    More denoising steps usually lead to a higher quality image at the expense of
    slower inference.'
  id: totrans-971
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`guidance_scale` (`float`, *optional*) — Higher guidance scale encourages to
    generate images that are closely linked to the text `prompt`, usually at the expense
    of lower image quality.'
  id: totrans-972
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-973
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-974
  prefs: []
  type: TYPE_NORMAL
- en: '`Image`'
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
- en: The generated image.
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-977
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-978
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-979
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate an image based on a given text using a specified model.
  id: totrans-981
  prefs: []
  type: TYPE_NORMAL
- en: You must have `PIL` installed if you want to work with images (`pip install
    Pillow`).
  id: totrans-982
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-983
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  id: totrans-984
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '#### `text_to_speech`'
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1647)'
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  id: totrans-987
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: Parameters
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
- en: '`text` (`str`) — The text to synthesize.'
  id: totrans-989
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-990
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
- en: '`bytes`'
  id: totrans-992
  prefs: []
  type: TYPE_NORMAL
- en: The generated audio.
  id: totrans-993
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-995
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-996
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-997
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthesize an audio of a voice pronouncing a given text.
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-999
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  id: totrans-1000
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '#### `token_classification`'
  id: totrans-1001
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1680)'
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  id: totrans-1003
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: Parameters
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
- en: '`text` (`str`) — A string to be classified.'
  id: totrans-1005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for the token classification
    task. Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed
    Inference Endpoint. If not provided, the default recommended token classification
    model will be used. Defaults to None.'
  id: totrans-1006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1007
  prefs: []
  type: TYPE_NORMAL
- en: '`List[Dict]`'
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
- en: List of token classification outputs containing the entity group, confidence
    score, word, start and end index.
  id: totrans-1009
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-1011
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-1012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-1013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform token classification on the given text. Usually used for sentence parsing,
    either grammatical, or Named Entity Recognition (NER) to understand keywords contained
    within text.
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1015
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  id: totrans-1016
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '#### `translation`'
  id: totrans-1017
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1728)'
  id: totrans-1018
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  id: totrans-1019
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: Parameters
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
- en: '`text` (`str`) — A string to be translated.'
  id: totrans-1021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for the translation task. Can
    be a model ID hosted on the Hugging Face Hub or a URL to a deployed Inference
    Endpoint. If not provided, the default recommended translation model will be used.
    Defaults to None.'
  id: totrans-1022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src_lang` (`str`, *optional*) — Source language of the translation task, i.e.
    input language. Cannot be passed without `tgt_lang`.'
  id: totrans-1023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tgt_lang` (`str`, *optional*) — Target language of the translation task, i.e.
    output language. Cannot be passed without `src_lang`.'
  id: totrans-1024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1025
  prefs: []
  type: TYPE_NORMAL
- en: '`str`'
  id: totrans-1026
  prefs: []
  type: TYPE_NORMAL
- en: The generated translated text.
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError` or `ValueError`'
  id: totrans-1029
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-1030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-1031
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ValueError` — If only one of the `src_lang` and `tgt_lang` arguments are provided.'
  id: totrans-1032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert text from one language to another.
  id: totrans-1033
  prefs: []
  type: TYPE_NORMAL
- en: Check out [https://huggingface.co/tasks/translation](https://huggingface.co/tasks/translation)
    for more information on how to choose the best model for your specific use case.
    Source and target languages usually depend on the model. However, it is possible
    to specify source and target languages for certain models. If you are working
    with one of these models, you can use `src_lang` and `tgt_lang` arguments to pass
    the relevant information. You can find this information in the model card.
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  id: totrans-1036
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Specifying languages:'
  id: totrans-1037
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  id: totrans-1038
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '#### `visual_question_answering`'
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L397)'
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  id: totrans-1041
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: Parameters
  id: totrans-1042
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image for the context.
    It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-1043
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`question` (`str`) — Question to be answered.'
  id: totrans-1044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for the visual question answering
    task. Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed
    Inference Endpoint. If not provided, the default recommended visual question answering
    model will be used. Defaults to None.'
  id: totrans-1045
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
- en: '`List[Dict]`'
  id: totrans-1047
  prefs: []
  type: TYPE_NORMAL
- en: a list of dictionaries containing the predicted label and associated probability.
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-1049
  prefs: []
  type: TYPE_NORMAL
- en: '`InferenceTimeoutError` or `aiohttp.ClientResponseError`'
  id: totrans-1050
  prefs: []
  type: TYPE_NORMAL
- en: '`InferenceTimeoutError` — If the model is unavailable or the request times
    out.'
  id: totrans-1051
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-1052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answering open-ended questions based on an image.
  id: totrans-1053
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1054
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  id: totrans-1055
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '#### `zero_shot_classification`'
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1794)'
  id: totrans-1057
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  id: totrans-1058
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: Parameters
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
- en: '`text` (`str`) — The input text to classify.'
  id: totrans-1060
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`List[str]`) — List of string possible labels. There must be at least
    2 labels.'
  id: totrans-1061
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`multi_label` (`bool`) — Boolean that is set to True if classes can overlap.'
  id: totrans-1062
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-1063
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
- en: '`List[Dict]`'
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
- en: List of classification outputs containing the predicted labels and their confidence.
  id: totrans-1066
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-1067
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-1068
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-1069
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-1070
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide as input a text and a set of candidate labels to classify the input
    text.
  id: totrans-1071
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  id: totrans-1073
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '#### `zero_shot_image_classification`'
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_generated/_async_client.py#L1867)'
  id: totrans-1075
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  id: totrans-1076
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: Parameters
  id: totrans-1077
  prefs: []
  type: TYPE_NORMAL
- en: '`image` (`Union[str, Path, bytes, BinaryIO]`) — The input image to caption.
    It can be raw bytes, an image file, or a URL to an online image.'
  id: totrans-1078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels` (`List[str]`) — List of string possible labels. There must be at least
    2 labels.'
  id: totrans-1079
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model` (`str`, *optional*) — The model to use for inference. Can be a model
    ID hosted on the Hugging Face Hub or a URL to a deployed Inference Endpoint. This
    parameter overrides the model defined at the instance level. Defaults to None.'
  id: totrans-1080
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns
  id: totrans-1081
  prefs: []
  type: TYPE_NORMAL
- en: '`List[Dict]`'
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
- en: List of classification outputs containing the predicted labels and their confidence.
  id: totrans-1083
  prefs: []
  type: TYPE_NORMAL
- en: Raises
  id: totrans-1084
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    or `aiohttp.ClientResponseError`'
  id: totrans-1085
  prefs: []
  type: TYPE_NORMAL
- en: '[InferenceTimeoutError](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceTimeoutError)
    — If the model is unavailable or the request times out.'
  id: totrans-1086
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aiohttp.ClientResponseError` — If the request fails with an HTTP error status
    code other than HTTP 503.'
  id: totrans-1087
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide input image and text labels to predict text labels for the image.
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1089
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  id: totrans-1090
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: InferenceTimeoutError
  id: totrans-1091
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.InferenceTimeoutError`'
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_common.py#L100)'
  id: totrans-1093
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  id: totrans-1094
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: Error raised when a model is unavailable or the request times out.
  id: totrans-1095
  prefs: []
  type: TYPE_NORMAL
- en: Return types
  id: totrans-1096
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For most tasks, the return value has a built-in type (string, list, image…).
    Here is a list for the more complex types.
  id: totrans-1097
  prefs: []
  type: TYPE_NORMAL
- en: ClassificationOutput
  id: totrans-1098
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._types.ClassificationOutput`'
  id: totrans-1099
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_types.py#L22)'
  id: totrans-1100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  id: totrans-1101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: Parameters
  id: totrans-1102
  prefs: []
  type: TYPE_NORMAL
- en: '`label` (`str`) — The label predicted by the model.'
  id: totrans-1103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` (`float`) — The score of the label predicted by the model.'
  id: totrans-1104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionary containing the output of a [audio_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.audio_classification)
    and [image_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_classification)
    task.
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
- en: ConversationalOutputConversation
  id: totrans-1106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._types.ConversationalOutputConversation`'
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_types.py#L36)'
  id: totrans-1108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  id: totrans-1109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: Parameters
  id: totrans-1110
  prefs: []
  type: TYPE_NORMAL
- en: '`generated_responses` (`List[str]`) — A list of the responses from the model.'
  id: totrans-1111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`past_user_inputs` (`List[str]`) — A list of the inputs from the user. Must
    be the same length as `generated_responses`.'
  id: totrans-1112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionary containing the “conversation” part of a [conversational()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.conversational)
    task.
  id: totrans-1113
  prefs: []
  type: TYPE_NORMAL
- en: ConversationalOutput
  id: totrans-1114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._types.ConversationalOutput`'
  id: totrans-1115
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_types.py#L50)'
  id: totrans-1116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  id: totrans-1117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: Parameters
  id: totrans-1118
  prefs: []
  type: TYPE_NORMAL
- en: '`generated_text` (`str`) — The last response from the model.'
  id: totrans-1119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`conversation` (`ConversationalOutputConversation`) — The past conversation.'
  id: totrans-1120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`warnings` (`List[str]`) — A list of warnings associated with the process.'
  id: totrans-1121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionary containing the output of a [conversational()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.conversational)
    task.
  id: totrans-1122
  prefs: []
  type: TYPE_NORMAL
- en: ImageSegmentationOutput
  id: totrans-1123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._types.ImageSegmentationOutput`'
  id: totrans-1124
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_types.py#L87)'
  id: totrans-1125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  id: totrans-1126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: Parameters
  id: totrans-1127
  prefs: []
  type: TYPE_NORMAL
- en: '`label` (`str`) — The label corresponding to the mask.'
  id: totrans-1128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mask` (`Image`) — An Image object representing the mask predicted by the model.'
  id: totrans-1129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` (`float`) — The score associated with the label for this mask.'
  id: totrans-1130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionary containing information about a [image_segmentation()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.image_segmentation)
    task. In practice, image segmentation returns a list of `ImageSegmentationOutput`
    with 1 item per mask.
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
- en: ModelStatus
  id: totrans-1132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._common.ModelStatus`'
  id: totrans-1133
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_common.py#L71)'
  id: totrans-1134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  id: totrans-1135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: Parameters
  id: totrans-1136
  prefs: []
  type: TYPE_NORMAL
- en: '`loaded` (`bool`) — If the model is currently loaded into Hugging Face’s InferenceAPI.
    Models are loaded on-demand, leading to the user’s first request taking longer.
    If a model is loaded, you can be assured that it is in a healthy state.'
  id: totrans-1137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`state` (`str`) — The current state of the model. This can be ‘Loaded’, ‘Loadable’,
    ‘TooBig’. If a model’s state is ‘Loadable’, it’s not too big and has a supported
    backend. Loadable models are automatically loaded when the user first requests
    inference on the endpoint. This means it is transparent for the user to load a
    model, except that the first call takes longer to complete.'
  id: totrans-1138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`compute_type` (`str`) — The type of compute resource the model is using or
    will use, such as ‘gpu’ or ‘cpu’.'
  id: totrans-1139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`framework` (`str`) — The name of the framework that the model was built with,
    such as ‘transformers’ or ‘text-generation-inference’.'
  id: totrans-1140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This Dataclass represents the the model status in the Hugging Face Inference
    API.
  id: totrans-1141
  prefs: []
  type: TYPE_NORMAL
- en: TokenClassificationOutput
  id: totrans-1142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._types.TokenClassificationOutput`'
  id: totrans-1143
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_types.py#L163)'
  id: totrans-1144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  id: totrans-1145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: Parameters
  id: totrans-1146
  prefs: []
  type: TYPE_NORMAL
- en: '`entity_group` (`str`) — The type for the entity being recognized (model specific).'
  id: totrans-1147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score` (`float`) — The score of the label predicted by the model.'
  id: totrans-1148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`word` (`str`) — The string that was captured.'
  id: totrans-1149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start` (`int`) — The offset stringwise where the answer is located. Useful
    to disambiguate if word occurs multiple times.'
  id: totrans-1150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end` (`int`) — The offset stringwise where the answer is located. Useful to
    disambiguate if word occurs multiple times.'
  id: totrans-1151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionary containing the output of a [token_classification()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.token_classification)
    task.
  id: totrans-1152
  prefs: []
  type: TYPE_NORMAL
- en: Text generation types
  id: totrans-1153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[text_generation()](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient.text_generation)
    task has a greater support than other tasks in `InferenceClient`. In particular,
    user inputs and server outputs are validated using [Pydantic](https://docs.pydantic.dev/latest/)
    if this package is installed. Therefore, we recommend installing it (`pip install
    pydantic`) for a better user experience.'
  id: totrans-1154
  prefs: []
  type: TYPE_NORMAL
- en: You can find below the dataclasses used to validate data and in particular [TextGenerationParameters](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationParameters)
    (input), [TextGenerationResponse](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationResponse)
    (output) and [TextGenerationStreamResponse](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationStreamResponse)
    (streaming output).
  id: totrans-1155
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._text_generation.TextGenerationParameters`'
  id: totrans-1156
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_text_generation.py#L59)'
  id: totrans-1157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  id: totrans-1158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: Parameters
  id: totrans-1159
  prefs: []
  type: TYPE_NORMAL
- en: '`do_sample` (`bool`, *optional*) — Activate logits sampling. Defaults to False.'
  id: totrans-1160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_new_tokens` (`int`, *optional*) — Maximum number of generated tokens.
    Defaults to 20.'
  id: totrans-1161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`repetition_penalty` (`Optional[float]`, *optional*) — The parameter for repetition
    penalty. A value of 1.0 means no penalty. See [this paper](https://arxiv.org/pdf/1909.05858.pdf)
    for more details. Defaults to None.'
  id: totrans-1162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`return_full_text` (`bool`, *optional*) — Whether to prepend the prompt to
    the generated text. Defaults to False.'
  id: totrans-1163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stop` (`List[str]`, *optional*) — Stop generating tokens if a member of `stop_sequences`
    is generated. Defaults to an empty list.'
  id: totrans-1164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`seed` (`Optional[int]`, *optional*) — Random sampling seed. Defaults to None.'
  id: totrans-1165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`temperature` (`Optional[float]`, *optional*) — The value used to modulate
    the logits distribution. Defaults to None.'
  id: totrans-1166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_k` (`Optional[int]`, *optional*) — The number of highest probability vocabulary
    tokens to keep for top-k-filtering. Defaults to None.'
  id: totrans-1167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_p` (`Optional[float]`, *optional*) — If set to a value less than 1, only
    the smallest set of most probable tokens with probabilities that add up to `top_p`
    or higher are kept for generation. Defaults to None.'
  id: totrans-1168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`truncate` (`Optional[int]`, *optional*) — Truncate input tokens to the given
    size. Defaults to None.'
  id: totrans-1169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`typical_p` (`Optional[float]`, *optional*) — Typical Decoding mass. See [Typical
    Decoding for Natural Language Generation](https://arxiv.org/abs/2202.00666) for
    more information. Defaults to None.'
  id: totrans-1170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`best_of` (`Optional[int]`, *optional*) — Generate `best_of` sequences and
    return the one with the highest token logprobs. Defaults to None.'
  id: totrans-1171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`watermark` (`bool`, *optional*) — Watermarking with [A Watermark for Large
    Language Models](https://arxiv.org/abs/2301.10226). Defaults to False.'
  id: totrans-1172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`details` (`bool`, *optional*) — Get generation details. Defaults to False.'
  id: totrans-1173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoder_input_details` (`bool`, *optional*) — Get decoder input token logprobs
    and ids. Defaults to False.'
  id: totrans-1174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parameters for text generation.
  id: totrans-1175
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._text_generation.TextGenerationResponse`'
  id: totrans-1176
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_text_generation.py#L394)'
  id: totrans-1177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  id: totrans-1178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: Parameters
  id: totrans-1179
  prefs: []
  type: TYPE_NORMAL
- en: '`generated_text` (`str`) — The generated text.'
  id: totrans-1180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`details` (`Optional[Details]`) — Generation details. Returned only if `details=True`
    is sent to the server.'
  id: totrans-1181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Represents a response for text generation.
  id: totrans-1182
  prefs: []
  type: TYPE_NORMAL
- en: Only returned when `details=True`, otherwise a string is returned.
  id: totrans-1183
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._text_generation.TextGenerationStreamResponse`'
  id: totrans-1184
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_text_generation.py#L444)'
  id: totrans-1185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  id: totrans-1186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: Parameters
  id: totrans-1187
  prefs: []
  type: TYPE_NORMAL
- en: '`token` (`Token`) — The generated token.'
  id: totrans-1188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generated_text` (`Optional[str]`, *optional*) — The complete generated text.
    Only available when the generation is finished.'
  id: totrans-1189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`details` (`Optional[StreamDetails]`, *optional*) — Generation details. Only
    available when the generation is finished.'
  id: totrans-1190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Represents a response for streaming text generation.
  id: totrans-1191
  prefs: []
  type: TYPE_NORMAL
- en: Only returned when `details=True` and `stream=True`.
  id: totrans-1192
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._text_generation.InputToken`'
  id: totrans-1193
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_text_generation.py#L238)'
  id: totrans-1194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE131]'
  id: totrans-1195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: Parameters
  id: totrans-1196
  prefs: []
  type: TYPE_NORMAL
- en: '`id` (`int`) — Token ID from the model tokenizer.'
  id: totrans-1197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text` (`str`) — Token text.'
  id: totrans-1198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logprob` (`float` or `None`) — Log probability of the token. Optional since
    the logprob of the first token cannot be computed.'
  id: totrans-1199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Represents an input token.
  id: totrans-1200
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._text_generation.Token`'
  id: totrans-1201
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_text_generation.py#L262)'
  id: totrans-1202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  id: totrans-1203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: Parameters
  id: totrans-1204
  prefs: []
  type: TYPE_NORMAL
- en: '`id` (`int`) — Token ID from the model tokenizer.'
  id: totrans-1205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text` (`str`) — Token text.'
  id: totrans-1206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logprob` (`float`) — Log probability of the token.'
  id: totrans-1207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`special` (`bool`) — Indicates whether the token is a special token. It can
    be used to ignore tokens when concatenating.'
  id: totrans-1208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Represents a token.
  id: totrans-1209
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._text_generation.FinishReason`'
  id: totrans-1210
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_text_generation.py#L291)'
  id: totrans-1211
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  id: totrans-1212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: An enumeration.
  id: totrans-1213
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._text_generation.BestOfSequence`'
  id: totrans-1214
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_text_generation.py#L301)'
  id: totrans-1215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  id: totrans-1216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: Parameters
  id: totrans-1217
  prefs: []
  type: TYPE_NORMAL
- en: '`generated_text` (`str`) — The generated text.'
  id: totrans-1218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`finish_reason` (`FinishReason`) — The reason for the generation to finish,
    represented by a `FinishReason` value.'
  id: totrans-1219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generated_tokens` (`int`) — The number of generated tokens in the sequence.'
  id: totrans-1220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`seed` (`Optional[int]`) — The sampling seed if sampling was activated.'
  id: totrans-1221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prefill` (`List[InputToken]`) — The decoder input tokens. Empty if `decoder_input_details`
    is False. Defaults to an empty list.'
  id: totrans-1222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokens` (`List[Token]`) — The generated tokens. Defaults to an empty list.'
  id: totrans-1223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Represents a best-of sequence generated during text generation.
  id: totrans-1224
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._text_generation.Details`'
  id: totrans-1225
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_text_generation.py#L345)'
  id: totrans-1226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  id: totrans-1227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: Parameters
  id: totrans-1228
  prefs: []
  type: TYPE_NORMAL
- en: '`finish_reason` (`FinishReason`) — The reason for the generation to finish,
    represented by a `FinishReason` value.'
  id: totrans-1229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generated_tokens` (`int`) — The number of generated tokens.'
  id: totrans-1230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`seed` (`Optional[int]`) — The sampling seed if sampling was activated.'
  id: totrans-1231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prefill` (`List[InputToken]`, *optional*) — The decoder input tokens. Empty
    if `decoder_input_details` is False. Defaults to an empty list.'
  id: totrans-1232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokens` (`List[Token]`) — The generated tokens. Defaults to an empty list.'
  id: totrans-1233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`best_of_sequences` (`Optional[List[BestOfSequence]]`) — Additional sequences
    when using the `best_of` parameter.'
  id: totrans-1234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Represents details of a text generation.
  id: totrans-1235
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.inference._text_generation.StreamDetails`'
  id: totrans-1236
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference/_text_generation.py#L421)'
  id: totrans-1237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  id: totrans-1238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: Parameters
  id: totrans-1239
  prefs: []
  type: TYPE_NORMAL
- en: '`finish_reason` (`FinishReason`) — The reason for the generation to finish,
    represented by a `FinishReason` value.'
  id: totrans-1240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generated_tokens` (`int`) — The number of generated tokens.'
  id: totrans-1241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`seed` (`Optional[int]`) — The sampling seed if sampling was activated.'
  id: totrans-1242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Represents details of a text generation stream.
  id: totrans-1243
  prefs: []
  type: TYPE_NORMAL
- en: InferenceAPI
  id: totrans-1244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`InferenceAPI` is the legacy way to call the Inference API. The interface is
    more simplistic and requires knowing the input parameters and output format for
    each task. It also lacks the ability to connect to other services like Inference
    Endpoints or AWS SageMaker. `InferenceAPI` will soon be deprecated so we recommend
    using [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    whenever possible. Check out [this guide](../guides/inference#legacy-inferenceapi-client)
    to learn how to switch from `InferenceAPI` to [InferenceClient](/docs/huggingface_hub/v0.20.3/en/package_reference/inference_client#huggingface_hub.InferenceClient)
    in your scripts.'
  id: totrans-1245
  prefs: []
  type: TYPE_NORMAL
- en: '### `class huggingface_hub.InferenceApi`'
  id: totrans-1246
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference_api.py#L46)'
  id: totrans-1247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE137]'
  id: totrans-1248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: Client to configure requests and make calls to the HuggingFace Inference API.
  id: totrans-1249
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-1250
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  id: totrans-1251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: '#### `__init__`'
  id: totrans-1252
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference_api.py#L93)'
  id: totrans-1253
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE139]'
  id: totrans-1254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: Parameters
  id: totrans-1255
  prefs: []
  type: TYPE_NORMAL
- en: '`repo_id` (`str`) — Id of repository (e.g. *user/bert-base-uncased*).'
  id: totrans-1256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`task` (`str`, *optional*, defaults `None`) — Whether to force a task instead
    of using task specified in the repository.'
  id: totrans-1257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token` (*str*, *optional*) — The API token to use as HTTP bearer authorization.
    This is not the authentication token. You can find the token in [https://huggingface.co/settings/token](https://huggingface.co/settings/token).
    Alternatively, you can find both your organizations and personal API tokens using
    *HfApi().whoami(token)*.'
  id: totrans-1258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gpu` (*bool*, *optional*, defaults *False*) — Whether to use GPU instead of
    CPU for inference(requires Startup plan at least).'
  id: totrans-1259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inits headers and API call information.
  id: totrans-1260
  prefs: []
  type: TYPE_NORMAL
- en: '#### `__call__`'
  id: totrans-1261
  prefs: []
  type: TYPE_NORMAL
- en: '[< source >](https://github.com/huggingface/huggingface_hub/blob/v0.20.3/src/huggingface_hub/inference_api.py#L158)'
  id: totrans-1262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE140]'
  id: totrans-1263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: Parameters
  id: totrans-1264
  prefs: []
  type: TYPE_NORMAL
- en: '`inputs` (`str` or `Dict` or `List[str]` or `List[List[str]]`, *optional*)
    — Inputs for the prediction.'
  id: totrans-1265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`params` (`Dict`, *optional*) — Additional parameters for the models. Will
    be sent as `parameters` in the payload.'
  id: totrans-1266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data` (`bytes`, *optional*) — Bytes content of the request. In this case,
    leave `inputs` and `params` empty.'
  id: totrans-1267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`raw_response` (`bool`, defaults to `False`) — If `True`, the raw `Response`
    object is returned. You can parse its content as preferred. By default, the content
    is parsed into a more practical format (json dictionary or PIL Image for example).'
  id: totrans-1268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make a call to the Inference API.
  id: totrans-1269
  prefs: []
  type: TYPE_NORMAL
