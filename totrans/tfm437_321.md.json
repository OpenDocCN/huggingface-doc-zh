["```py\nimport torch\nfrom scipy.io.wavfile import write\nfrom datasets import Audio, load_dataset\n\nfrom transformers import UnivNetFeatureExtractor, UnivNetModel\n\nmodel_id_or_path = \"dg845/univnet-dev\"\nmodel = UnivNetModel.from_pretrained(model_id_or_path)\nfeature_extractor = UnivNetFeatureExtractor.from_pretrained(model_id_or_path)\n\nds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n# Resample the audio to the model and feature extractor's sampling rate.\nds = ds.cast_column(\"audio\", Audio(sampling_rate=feature_extractor.sampling_rate))\n# Pad the end of the converted waveforms to reduce artifacts at the end of the output audio samples.\ninputs = feature_extractor(\n    ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], pad_end=True, return_tensors=\"pt\"\n)\n\nwith torch.no_grad():\n    audio = model(**inputs)\n\n# Remove the extra padding at the end of the output.\naudio = feature_extractor.batch_decode(**audio)[0]\n# Convert to wav file\nwrite(\"sample_audio.wav\", feature_extractor.sampling_rate, audio)\n```", "```py\n>>> from transformers import UnivNetModel, UnivNetConfig\n\n>>> # Initializing a Tortoise TTS style configuration\n>>> configuration = UnivNetConfig()\n\n>>> # Initializing a model (with random weights) from the Tortoise TTS style configuration\n>>> model = UnivNetModel(configuration)\n\n>>> # Accessing the model configuration\n>>> configuration = model.config\n```", "```py\n>>> from transformers import UnivNetFeatureExtractor, UnivNetModel\n>>> from datasets import load_dataset, Audio\n\n>>> model = UnivNetModel.from_pretrained(\"dg845/univnet-dev\")\n>>> feature_extractor = UnivNetFeatureExtractor.from_pretrained(\"dg845/univnet-dev\")\n\n>>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n>>> # Resample the audio to the feature extractor's sampling rate.\n>>> ds = ds.cast_column(\"audio\", Audio(sampling_rate=feature_extractor.sampling_rate))\n>>> inputs = feature_extractor(\n...     ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\"\n... )\n>>> audio = model(**inputs).waveforms\n>>> list(audio.shape)\n[1, 140288]\n```"]