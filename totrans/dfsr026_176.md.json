["```py\nimport torch\nfrom diffusers import UnCLIPScheduler, DDPMScheduler, StableUnCLIPPipeline\nfrom diffusers.models import PriorTransformer\nfrom transformers import CLIPTokenizer, CLIPTextModelWithProjection\n\nprior_model_id = \"kakaobrain/karlo-v1-alpha\"\ndata_type = torch.float16\nprior = PriorTransformer.from_pretrained(prior_model_id, subfolder=\"prior\", torch_dtype=data_type)\n\nprior_text_model_id = \"openai/clip-vit-large-patch14\"\nprior_tokenizer = CLIPTokenizer.from_pretrained(prior_text_model_id)\nprior_text_model = CLIPTextModelWithProjection.from_pretrained(prior_text_model_id, torch_dtype=data_type)\nprior_scheduler = UnCLIPScheduler.from_pretrained(prior_model_id, subfolder=\"prior_scheduler\")\nprior_scheduler = DDPMScheduler.from_config(prior_scheduler.config)\n\nstable_unclip_model_id = \"stabilityai/stable-diffusion-2-1-unclip-small\"\n\npipe = StableUnCLIPPipeline.from_pretrained(\n    stable_unclip_model_id,\n    torch_dtype=data_type,\n    variant=\"fp16\",\n    prior_tokenizer=prior_tokenizer,\n    prior_text_encoder=prior_text_model,\n    prior=prior,\n    prior_scheduler=prior_scheduler,\n)\n\npipe = pipe.to(\"cuda\")\nwave_prompt = \"dramatic wave, the Oceans roar, Strong wave spiral across the oceans as the waves unfurl into roaring crests; perfect wave form; perfect wave shape; dramatic wave shape; wave shape unbelievable; wave; wave shape spectacular\"\n\nimage = pipe(prompt=wave_prompt).images[0]\nimage\n```", "```py\nfrom diffusers import StableUnCLIPImg2ImgPipeline\nfrom diffusers.utils import load_image\nimport torch\n\npipe = StableUnCLIPImg2ImgPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-2-1-unclip\", torch_dtype=torch.float16, variation=\"fp16\"\n)\npipe = pipe.to(\"cuda\")\n\nurl = \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/stable_unclip/tarsila_do_amaral.png\"\ninit_image = load_image(url)\n\nimages = pipe(init_image).images\nimages[0].save(\"variation_image.png\")\n```", "```py\nprompt = \"A fantasy landscape, trending on artstation\"\n\nimage = pipe(init_image, prompt=prompt).images[0]\nimage\n```", "```py\n>>> import torch\n>>> from diffusers import StableUnCLIPPipeline\n\n>>> pipe = StableUnCLIPPipeline.from_pretrained(\n...     \"fusing/stable-unclip-2-1-l\", torch_dtype=torch.float16\n... )  # TODO update model path\n>>> pipe = pipe.to(\"cuda\")\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> images = pipe(prompt).images\n>>> images[0].save(\"astronaut_horse.png\")\n```", "```py\n>>> import torch\n>>> from diffusers import StableDiffusionPipeline\n\n>>> pipe = StableDiffusionPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\",\n...     torch_dtype=torch.float16,\n...     use_safetensors=True,\n... )\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> pipe.enable_attention_slicing()\n>>> image = pipe(prompt).images[0]\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```", "```py\n>>> import requests\n>>> import torch\n>>> from PIL import Image\n>>> from io import BytesIO\n\n>>> from diffusers import StableUnCLIPImg2ImgPipeline\n\n>>> pipe = StableUnCLIPImg2ImgPipeline.from_pretrained(\n...     \"fusing/stable-unclip-2-1-l-img2img\", torch_dtype=torch.float16\n... )  # TODO update model path\n>>> pipe = pipe.to(\"cuda\")\n\n>>> url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n\n>>> response = requests.get(url)\n>>> init_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n>>> init_image = init_image.resize((768, 512))\n\n>>> prompt = \"A fantasy landscape, trending on artstation\"\n\n>>> images = pipe(prompt, init_image).images\n>>> images[0].save(\"fantasy_landscape.png\")\n```", "```py\n>>> import torch\n>>> from diffusers import StableDiffusionPipeline\n\n>>> pipe = StableDiffusionPipeline.from_pretrained(\n...     \"runwayml/stable-diffusion-v1-5\",\n...     torch_dtype=torch.float16,\n...     use_safetensors=True,\n... )\n\n>>> prompt = \"a photo of an astronaut riding a horse on mars\"\n>>> pipe.enable_attention_slicing()\n>>> image = pipe(prompt).images[0]\n```", "```py\n>>> import torch\n>>> from diffusers import DiffusionPipeline\n>>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n\n>>> pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n>>> pipe = pipe.to(\"cuda\")\n>>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n>>> # Workaround for not accepting attention shape using VAE for Flash Attention\n>>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)\n```"]