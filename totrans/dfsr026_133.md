# AutoPipeline

> 原文链接: [`huggingface.co/docs/diffusers/api/pipelines/auto_pipeline`](https://huggingface.co/docs/diffusers/api/pipelines/auto_pipeline)

`AutoPipeline` 的设计目的是:

1.  使您能够加载任务的检查点，而无需知道要使用的特定管道类

1.  在工作流中使用多个管道

基于任务，`AutoPipeline` 类会根据预训练权重的名称或路径自动检索相关管道，使用 `from_pretrained()` 方法。

为了在不重新分配额外内存的情况下无缝切换任务，使用 `from_pipe()` 方法将组件从原始管道传输到新管道。

```py
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

image = pipeline(prompt, num_inference_steps=25).images[0]
```

查看 AutoPipeline 教程，了解如何使用此 API！

`AutoPipeline` 支持以下扩散模型的文本到图像、图像到图像和修补功能：

+   稳定扩散

+   ControlNet

+   稳定扩散 XL (SDXL)

+   DeepFloyd IF

+   Kandinsky 2.1

+   Kandinsky 2.2

## AutoPipelineForText2Image

### `class diffusers.AutoPipelineForText2Image`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/auto_pipeline.py#L175)

```py
( *args **kwargs )
```

AutoPipelineForText2Image 是一个通用的管道类，实例化一个文本到图像的管道类。具体的底层管道类会自动从 from_pretrained() 或 from_pipe() 方法中选择。

这个类不能使用 `__init__()` 实例化（会抛出错误）。

类属性:

+   `config_name` (`str`) — 存储所有扩散管道组件类和模块名称的配置文件名。

#### `from_pretrained`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/auto_pipeline.py#L200)

```py
( pretrained_model_or_path **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`, *可选*) — 可以是:

    +   一个字符串，预训练管道的 *repo id*（例如 `CompVis/ldm-text2im-large-256`）。

    +   一个*目录*路径（例如 `./my_pipeline_directory/`），其中包含使用 save_pretrained() 保存的管道权重。

+   `torch_dtype` (`str` 或 `torch.dtype`, *可选*) — 覆盖默认的 `torch.dtype` 并使用另一种 dtype 加载模型。如果传递“auto”，dtype 将自动从模型的权重中派生。

+   `force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `cache_dir` (`Union[str, os.PathLike]`, *可选*) — 下载预训练模型配置的缓存路径，如果不使用标准缓存。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否恢复下载模型权重和配置文件。如果设置为 `False`，则删除任何未完全下载的文件。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个代理服务器字典，按协议或端点使用，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。这些代理会在每个请求中使用。

+   `output_loading_info(bool,` *可选*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only` (`bool`, *optional*, defaults to `False`) — 是否仅加载本地模型权重和配置文件。如果设置为`True`，则不会从 Hub 下载模型。

+   `token` (`str` or *bool*, *optional*) — 用作远程文件的 HTTP 令牌。如果为`True`，则使用从`diffusers-cli login`生成的令牌（存储在`~/.huggingface`中）。

+   `revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。可以是分支名称、标签名称、提交 ID 或 Git 允许的任何标识符。

+   `custom_revision` (`str`, *optional*, defaults to `"main"`) — 要使用的特定模型版本。当从 Hub 加载自定义管道时，可以是分支名称、标签名称或提交 ID。当从 GitHub 加载自定义管道时，可以是🤗 Diffusers 版本，否则在从 Hub 加载时默认为`"main"`。

+   `mirror` (`str`, *optional*) — 镜像源以解决在中国下载模型时的可访问性问题。我们不保证源的及时性或安全性，您应参考镜像站点获取更多信息。

+   `device_map` (`str` or `Dict[str, Union[int, str, torch.device]]`, *optional*) — 指定每个子模块应该放在哪里的映射。不需要为每个参数/缓冲区名称定义它；一旦给定模块名称在内部，它的每个子模块都将发送到相同的设备。

    设置`device_map="auto"`以使🤗 Accelerate 自动计算最优化的`device_map`。有关每个选项的更多信息，请参阅[设计设备映射](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map)。

+   `max_memory` (`Dict`, *optional*) — 用于最大内存的字典设备标识符。如果未设置，将默认为每个 GPU 和可用 CPU RAM 的最大内存。

+   `offload_folder` (`str` or `os.PathLike`, *optional*) — 如果`device_map`包含值`"disk"`，则为卸载权重的路径。

+   `offload_state_dict` (`bool`, *optional*) — 如果为`True`，则临时将 CPU 状态字典卸载到硬盘，以避免 CPU RAM 不足，如果 CPU 状态字典的权重+检查点的最大分片不适合。当存在一些磁盘卸载时，默认为`True`。

+   `low_cpu_mem_usage` (`bool`, *optional*, defaults to `True` if torch version >= 1.9.0 else `False`) — 仅加载预训练权重而不初始化权重以加快模型加载速度。在加载模型时，尝试不使用超过 1 倍模型大小的 CPU 内存（包括峰值内存）。仅支持 PyTorch >= 1.9.0。如果您使用较旧版本的 PyTorch，将此参数设置为`True`将引发错误。

+   `use_safetensors` (`bool`, *optional*, defaults to `None`) — 如果设置为`None`，则在可用时下载 safetensors 权重 **并且** 如果已安装 safetensors 库。如果设置为`True`，则强制从 safetensors 权重加载模型。如果设置为`False`，则不加载 safetensors 权重。

+   `kwargs`（剩余的关键字参数字典，*可选*） — 可用于覆盖加载和可保存变量（特定管道类的管道组件）。被覆盖的组件直接传递给管道的`__init__`方法。有关更多信息，请参阅下面的示例。

+   `variant` (`str`, *optional*) — 从指定的变体文件名（如`"fp16"`或`"ema"`）加载权重。在加载`from_flax`时会被忽略。

从预训练管道权重实例化一个文本到图像的 Pytorch 扩散管道。

from_pretrained()方法负责通过以下方式返回正确的管道类实例：

1.  根据其配置对象的 _class_name 属性检测预训练模型或路径的管道类

1.  通过对管道类名称进行模式匹配，找到与管道类相关联的文本到图像管道。

如果传递了一个 `controlnet` 参数，它将实例化一个 StableDiffusionControlNetPipeline 对象。

默认情况下，管道设置为评估模式 (`model.eval()`)。

如果收到以下错误消息，则需要为下游任务微调权重:

```py
Some weights of UNet2DConditionModel were not initialized from the model checkpoint at runwayml/stable-diffusion-v1-5 and are newly initialized because the shapes did not match:
- conv_in.weight: found shape torch.Size([320, 4, 3, 3]) in the checkpoint and torch.Size([320, 9, 3, 3]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
```

要使用私有或[门控](https://huggingface.co/docs/hub/models-gated#gated-models)模型，请使用 `huggingface-cli login` 登录。

示例:

```py
>>> from diffusers import AutoPipelineForText2Image

>>> pipeline = AutoPipelineForText2Image.from_pretrained("runwayml/stable-diffusion-v1-5")
>>> image = pipeline(prompt).images[0]
```

#### `from_pipe`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/auto_pipeline.py#L346)

```py
( pipeline **kwargs )
```

参数

+   `pipeline` (`DiffusionPipeline`) — 一个实例化的 `DiffusionPipeline` 对象

从另一个实例化的扩散管道类实例化一个文本到图像 Pytorch 扩散管道。

from_pipe() 方法负责通过在管道类名称上进行模式匹配找到与管道类链接的文本到图像管道的正确管道类实例。

管道包含的所有模块将用于初始化新管道，而不重新分配额外的内存。

默认情况下，管道设置为评估模式 (`model.eval()`)。

```py
>>> from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image

>>> pipe_i2i = AutoPipelineForImage2Image.from_pretrained(
...     "runwayml/stable-diffusion-v1-5", requires_safety_checker=False
... )

>>> pipe_t2i = AutoPipelineForText2Image.from_pipe(pipe_i2i)
>>> image = pipe_t2i(prompt).images[0]
```

## AutoPipelineForImage2Image

### `class diffusers.AutoPipelineForImage2Image`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/auto_pipeline.py#L447)

```py
( *args **kwargs )
```

AutoPipelineForImage2Image 是一个通用管道类，实例化一个图像到图像管道类。具体的底层管道类会自动从 from_pretrained() 或 from_pipe() 方法中选择。

此类不能使用 `__init__()` 实例化（会抛出错误）。

类属性:

+   `config_name` (`str`) — 存储所有扩散管道组件的类和模块名称的配置文件名。

#### `from_pretrained`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/auto_pipeline.py#L472)

```py
( pretrained_model_or_path **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` 或 `os.PathLike`, *可选*) — 可以是:

    +   一个字符串，预训练管道的 *repo id*（例如 `CompVis/ldm-text2im-large-256`），托管在 Hub 上。

    +   一个 *目录* 路径（例如 `./my_pipeline_directory/`），其中包含使用 save_pretrained() 保存的管道权重。

+   `torch_dtype` (`str` 或 `torch.dtype`, *可选*) — 覆盖默认的 `torch.dtype` 并使用另一种 dtype 加载模型。如果传递“auto”，dtype 将从模型的权重自动推导。

+   `force_download` (`bool`, *可选*, 默认为 `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `cache_dir` (`Union[str, os.PathLike]`, *可选*) — 下载的预训练模型配置缓存在标准缓存未使用时的目录路径。

+   `resume_download` (`bool`, *可选*, 默认为 `False`) — 是否恢复下载模型权重和配置文件。如果设置为 `False`，则删除任何未完全下载的文件。

+   `proxies` (`Dict[str, str]`, *可选*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理在每个请求上使用。

+   `output_loading_info(bool,` *可选*, 默认为 `False`) — 是否返回一个包含缺失键、意外键和错误消息的字典。

+   `local_files_only`（`bool`，*可选*，默认为`False`）— 是否仅加载本地模型权重和配置文件。如果设置为`True`，则不会从 Hub 下载模型。

+   `token`（`str`或*bool*，*可选*）— 用作远程文件的 HTTP bearer 授权的令牌。如果为`True`，则使用从`diffusers-cli login`生成的令牌（存储在`~/.huggingface`中）。

+   `revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。可以是分支名称、标签名称、提交 ID 或 Git 允许的任何标识符。

+   `custom_revision`（`str`，*可选*，默认为`"main"`）— 要使用的特定模型版本。可以是分支名称、标签名称或提交 ID，类似于从 Hub 加载自定义管道时的`revision`。在从 GitHub 加载自定义管道时可以是🤗 Diffusers 版本，否则在从 Hub 加载时默认为`"main"`。

+   `mirror`（`str`，*可选*）— 镜像源以解决在中国下载模型时的可访问性问题。我们不保证源的及时性或安全性，您应参考镜像站点获取更多信息。

+   `device_map`（`str`或`Dict[str，Union[int，str，torch.device]]`，*可选*）— 指定每个子模块应放置在何处的映射。不需要为每个参数/缓冲区名称定义它；一旦给定模块名称在内部，它的每个子模块都将发送到相同的设备。

    设置`device_map="auto"`以使🤗 Accelerate 自动计算最优化的`device_map`。有关每个选项的更多信息，请参见[设计设备映射](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map)。

+   `max_memory`（`Dict`，*可选*）— 用于最大内存的字典设备标识符。如果未设置，将默认为每个 GPU 和可用 CPU RAM 的最大内存。

+   `offload_folder`（`str`或`os.PathLike`，*可选*）— 如果`device_map`包含值`"disk"`，则为卸载权重的路径。

+   `offload_state_dict`（`bool`，*可选*）— 如果为`True`，则临时将 CPU 状态字典卸载到硬盘，以避免 CPU RAM 的权重 + 检查点的最大分片不适合的情况。当存在一些磁盘卸载时，默认为`True`。

+   `low_cpu_mem_usage`（`bool`，*可选*，如果 torch 版本 >= 1.9.0 则默认为`True`，否则为`False`）— 加快模型加载，仅加载预训练权重而不初始化权重。在加载模型时，还尝试不使用超过 CPU 内存中的 1 倍模型大小（包括峰值内存）。仅支持 PyTorch >= 1.9.0。如果您使用较旧版本的 PyTorch，将此参数设置为`True`将引发错误。

+   `use_safetensors`（`bool`，*可选*，默认为`None`）— 如果设置为`None`，则在可用时下载 safetensors 权重 **并且** 如果已安装 safetensors 库。如果设置为`True`，则模型将强制从 safetensors 权重加载。如果设置为`False`，则不加载 safetensors 权重。

+   `kwargs`（剩余的关键字参数字典，*可选*）— 可用于覆盖加载和保存变量（特定管道类的管道组件）。被覆盖的组件直接传递给管道的`__init__`方法。有关更多信息，请参见下面的示例。

+   `variant`（`str`，*可选*）— 从指定的变体文件名（例如`"fp16"`或`"ema"`）加载权重。在加载`from_flax`时会忽略此选项。

从预训练管道权重实例化一个图像到图像的 Pytorch 扩散管道。

`from_pretrained()`方法负责通过以下方式返回正确的管道类实例：

1.  根据其配置对象的 _class_name 属性检测预训练模型或路径的管道类

1.  通过在管道类名称上进行模式匹配，找到与管道类相关联的图像到图像管道。

如果传递了 `controlnet` 参数，它将实例化一个 StableDiffusionControlNetImg2ImgPipeline 对象。

默认情况下，管道设置为评估模式（`model.eval()`）。

如果您收到以下错误消息，则需要为下游任务微调权重：

```py
Some weights of UNet2DConditionModel were not initialized from the model checkpoint at runwayml/stable-diffusion-v1-5 and are newly initialized because the shapes did not match:
- conv_in.weight: found shape torch.Size([320, 4, 3, 3]) in the checkpoint and torch.Size([320, 9, 3, 3]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
```

要使用私有或[门控](https://huggingface.co/docs/hub/models-gated#gated-models)模型，请使用 `huggingface-cli login` 登录。

示例：

```py
>>> from diffusers import AutoPipelineForImage2Image

>>> pipeline = AutoPipelineForImage2Image.from_pretrained("runwayml/stable-diffusion-v1-5")
>>> image = pipeline(prompt, image).images[0]
```

#### `from_pipe`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/auto_pipeline.py#L619)

```py
( pipeline **kwargs )
```

参数

+   `pipeline` (`DiffusionPipeline`) — 一个实例化的 `DiffusionPipeline` 对象

从另一个已实例化的扩散管道类实例化一个图像到图像的 Pytorch 扩散管道。

from_pipe() 方法负责通过在管道类名称上进行模式匹配找到与管道类链接的图像到图像管道的正确管道类实例。

管道包含的所有模块将用于初始化新管道，而无需重新分配额外的内存。

默认情况下，管道设置为评估模式（`model.eval()`）。

示例：

```py
>>> from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image

>>> pipe_t2i = AutoPipelineForText2Image.from_pretrained(
...     "runwayml/stable-diffusion-v1-5", requires_safety_checker=False
... )

>>> pipe_i2i = AutoPipelineForImage2Image.from_pipe(pipe_t2i)
>>> image = pipe_i2i(prompt, image).images[0]
```

## AutoPipelineForInpainting

### `class diffusers.AutoPipelineForInpainting`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/auto_pipeline.py#L724)

```py
( *args **kwargs )
```

AutoPipelineForInpainting 是一个通用管道类，实例化一个修复管道类。具体的底层管道类会自动从 from_pretrained() 或 from_pipe() 方法中选择。

此类不能使用 `__init__()` 实例化（会抛出错误）。

类属性：

+   `config_name` (`str`) — 存储所有扩散管道组件类和模块名称的配置文件名。

#### `from_pretrained`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/auto_pipeline.py#L749)

```py
( pretrained_model_or_path **kwargs )
```

参数

+   `pretrained_model_name_or_path` (`str` or `os.PathLike`, *optional*) — 可以是：

    +   一个字符串，预训练管道的*repo id*（例如 `CompVis/ldm-text2im-large-256`）。

    +   一个*目录*的路径（例如 `./my_pipeline_directory/`），其中包含使用 save_pretrained() 保存的管道权重。

+   `torch_dtype` (`str` or `torch.dtype`, *optional*) — 覆盖默认的 `torch.dtype` 并使用另一种数据类型加载模型。如果传递“auto”，数据类型将自动从模型的权重中派生。

+   `force_download` (`bool`, *optional*, defaults to `False`) — 是否强制（重新）下载模型权重和配置文件，覆盖缓存版本（如果存在）。

+   `cache_dir` (`Union[str, os.PathLike]`, *optional*) — 下载预训练模型配置的缓存路径，如果不使用标准缓存。

+   `resume_download` (`bool`, *optional*, defaults to `False`) — 是否恢复下载模型权重和配置文件。如果设置为 `False`，则删除任何未完全下载的文件。

+   `proxies` (`Dict[str, str]`, *optional*) — 一个按协议或端点使用的代理服务器字典，例如，`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`。代理服务器在每个请求上使用。

+   `output_loading_info(bool,` *optional*, defaults to `False`) — 是否返回包含缺失键、意外键和错误消息的字典。

+   `local_files_only` (`bool`, *optional*, 默认为 `False`) — 是否仅加载本地模型权重和配置文件。如果设置为 `True`，模型将不会从 Hub 下载。

+   `token` (`str` 或 *bool*, *optional*) — 用作远程文件的 HTTP bearer 授权的令牌。如果为 `True`，则使用从 `diffusers-cli login` 生成的令牌（存储在 `~/.huggingface` 中）。

+   `revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称、提交 ID 或 Git 允许的任何标识符。

+   `custom_revision` (`str`, *optional*, 默认为 `"main"`) — 要使用的特定模型版本。它可以是分支名称、标签名称或提交 ID，类似于从 Hub 加载自定义管道时的 `revision`。当从 GitHub 加载自定义管道时，它可以是一个 🤗 Diffusers 版本，否则在从 Hub 加载时默认为 `"main"`。

+   `mirror` (`str`, *optional*) — 镜像源以解决在中国下载模型时的可访问性问题。我们不保证源的及时性或安全性，您应参考镜像站点获取更多信息。

+   `device_map` (`str` 或 `Dict[str, Union[int, str, torch.device]]`, *optional*) — 指定每个子模块应该去的映射。不需要为每个参数/缓冲器名称定义；一旦给定模块名称在内部，它的每个子模块都将发送到相同的设备。

    设置 `device_map="auto"` 以使 🤗 Accelerate 自动计算最优化的 `device_map`。有关每个选项的更多信息，请参见[设计设备映射](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map)。

+   `max_memory` (`Dict`, *optional*) — 用于最大内存的字典设备标识符。如果未设置，将默认为每个 GPU 可用的最大内存和可用的 CPU RAM。

+   `offload_folder` (`str` 或 `os.PathLike`, *optional*) — 如果 device_map 包含值 `"disk"`，则是卸载权重的路径。

+   `offload_state_dict` (`bool`, *optional*) — 如果为 `True`，则临时将 CPU 状态字典转移到硬盘，以避免 CPU RAM 不足，如果 CPU 状态字典的权重 + 检查点的最大分片的权重不适合。当存在一些磁盘卸载时，默认为 `True`。

+   `low_cpu_mem_usage` (`bool`, *optional*, 如果 torch 版本 >= 1.9.0 则默认为 `True`，否则为 `False`) — 加速模型加载，仅加载预训练权重而不初始化权重。这也尝试在加载模型时不使用超过 CPU 内存中的 1x 模型大小（包括峰值内存）。仅支持 PyTorch >= 1.9.0。如果您使用较旧版本的 PyTorch，将此参数设置为 `True` 将引发错误。

+   `use_safetensors` (`bool`, *optional*, 默认为 `None`) — 如果设置为 `None`，则在可用时下载 safetensors 权重 **并且** 如果已安装 safetensors 库。如果设置为 `True`，则强制从 safetensors 权重加载模型。如果设置为 `False`，则不加载 safetensors 权重。

+   `kwargs`（剩余的关键字参数字典，*optional*） — 可用于覆盖加载和可保存变量（特定管道类的管道组件）。被覆盖的组件将直接传递给管道的 `__init__` 方法。有关更多信息，请参见下面的示例。

+   `variant` (`str`, *optional*) — 从指定的变体文件名（如 `"fp16"` 或 `"ema"`）加载权重。在加载 `from_flax` 时会忽略此选项。

从预训练管道权重实例化一个修复 Pytorch 扩散管道。

from_pretrained() 方法负责通过返回正确的管道类实例：

1.  基于其配置对象的 _class_name 属性，检测 pretrained_model_or_path 的管道类。

1.  使用管道类名称上的模式匹配找到与管道类相关联的修复管道。

如果传递了 `controlnet` 参数，它将实例化一个 StableDiffusionControlNetInpaintPipeline 对象。

默认情况下，管道被设置为评估模式 (`model.eval()`)。

如果您收到下面的错误消息，则需要微调权重以适应您的下游任务：

```py
Some weights of UNet2DConditionModel were not initialized from the model checkpoint at runwayml/stable-diffusion-v1-5 and are newly initialized because the shapes did not match:
- conv_in.weight: found shape torch.Size([320, 4, 3, 3]) in the checkpoint and torch.Size([320, 9, 3, 3]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
```

要使用私有或 [门控](https://huggingface.co/docs/hub/models-gated#gated-models) 模型，请使用 `huggingface-cli login` 登录。

示例：

```py
>>> from diffusers import AutoPipelineForInpainting

>>> pipeline = AutoPipelineForInpainting.from_pretrained("runwayml/stable-diffusion-v1-5")
>>> image = pipeline(prompt, image=init_image, mask_image=mask_image).images[0]
```

#### `from_pipe`

[< source >](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/pipelines/auto_pipeline.py#L895)

```py
( pipeline **kwargs )
```

参数

+   `pipeline` (`DiffusionPipeline`) — 一个实例化的 `DiffusionPipeline` 对象

从另一个实例化的扩散管道类实例化一个修补 Pytorch 扩散管道。

from_pipe() 方法负责通过在管道类名称上进行模式匹配，找到与管道类相关联的修补管道，从而返回正确的管道类实例。

管道类包含的所有模块将用于初始化新管道，而不需要重新分配额外的内存。

默认情况下，管道被设置为评估模式 (`model.eval()`)。

示例：

```py
>>> from diffusers import AutoPipelineForText2Image, AutoPipelineForInpainting

>>> pipe_t2i = AutoPipelineForText2Image.from_pretrained(
...     "DeepFloyd/IF-I-XL-v1.0", requires_safety_checker=False
... )

>>> pipe_inpaint = AutoPipelineForInpainting.from_pipe(pipe_t2i)
>>> image = pipe_inpaint(prompt, image=init_image, mask_image=mask_image).images[0]
```
