# AutoencoderKL

> [`huggingface.co/docs/diffusers/api/models/autoencoderkl`](https://huggingface.co/docs/diffusers/api/models/autoencoderkl)

变分自动编码器（VAE）模型与 KL 损失在[Diederik P. Kingma 和 Max Welling 的《自动编码变分贝叶斯》](https://arxiv.org/abs/1312.6114v11)中引入。该模型用于将图像编码为潜在变量，并将潜在表示解码为图像。

论文摘要如下：

*我们如何在连续潜在变量具有难以处理的后验分布和大型数据集的情况下，在有向概率模型中执行高效的推断和学习？我们引入了一种随机变分推断和学习算法，可扩展到大型数据集，并且在一些温和的可微条件下，甚至在难以处理的情况下也能工作。我们的贡献有两个方面。首先，我们表明变分下界的重新参数化产生了一个下界估计器，可以通过标准随机梯度方法直接优化。其次，我们表明对于具有连续潜在变量的 i.i.d.数据集，通过使用提出的下界估计器将近似推断模型（也称为识别模型）拟合到难以处理的后验，可以使后验推断特别高效。理论优势在实验结果中得到体现。*

## 从原始格式加载

默认情况下，应使用 from_pretrained()加载 AutoencoderKL，但也可以使用`FromOriginalVAEMixin.from_single_file`从原始格式加载，如下所示：

```py
from diffusers import AutoencoderKL

url = "https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.safetensors"  # can also be a local file
model = AutoencoderKL.from_single_file(url)
```

## AutoencoderKL

### `class diffusers.AutoencoderKL`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L35)

```py
( in_channels: int = 3 out_channels: int = 3 down_block_types: Tuple = ('DownEncoderBlock2D',) up_block_types: Tuple = ('UpDecoderBlock2D',) block_out_channels: Tuple = (64,) layers_per_block: int = 1 act_fn: str = 'silu' latent_channels: int = 4 norm_num_groups: int = 32 sample_size: int = 32 scaling_factor: float = 0.18215 force_upcast: float = True )
```

参数

+   `in_channels`（int，*可选*，默认为 3）— 输入图像中的通道数。

+   `out_channels`（int，*可选*，默认为 3）— 输出中的通道数。

+   `down_block_types`（`Tuple[str]`，*可选*，默认为`("DownEncoderBlock2D",)`）— 下采样块类型的元组。

+   `up_block_types`（`Tuple[str]`，*可选*，默认为`("UpDecoderBlock2D",)`）— 上采样块类型的元组。

+   `block_out_channels`（`Tuple[int]`，*可选*，默认为`(64,)`）— 块输出通道的元组。

+   `act_fn`（`str`，*可选*，默认为`"silu"`）— 要使用的激活函数。

+   `latent_channels`（`int`，*可选*，默认为 4）— 潜在空间中的通道数。

+   `sample_size`（`int`，*可选*，默认为`32`）— 样本输入大小。

+   `scaling_factor`（`float`，*可选*，默认为 0.18215）— 使用训练集的第一批计算出的训练潜在空间的分量标准差。在训练扩散模型时，用于将潜在空间缩放为单位方差。在传递给扩散模型之前，潜在变量使用公式`z = z * scaling_factor`进行缩放。解码时，潜在变量使用公式进行缩放回原始比例：`z = 1 / scaling_factor * z`。有关更多详细信息，请参阅[具有潜在扩散模型的高分辨率图像合成](https://arxiv.org/abs/2112.10752)论文的 4.3.2 和 D.1 节。

+   `force_upcast`（`bool`，*可选*，默认为`True`）— 如果启用，它将强制 VAE 在高分辨率图像管道（如 SD-XL）中以 float32 运行。 VAE 可以微调/训练到较低范围而不会失去太多精度，在这种情况下，`force_upcast`可以设置为`False` - 参见：[`huggingface.co/madebyollin/sdxl-vae-fp16-fix`](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)

具有 KL 损失的 VAE 模型，用于将图像编码为潜在变量，并将潜在表示解码为图像。

此模型继承自 ModelMixin。查看超类文档以了解为所有模型实现的通用方法（例如下载或保存）。

#### `wrapper`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/accelerate_utils.py#L43)

```py
( *args **kwargs )
```

#### `wrapper`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/utils/accelerate_utils.py#L43)

```py
( *args **kwargs )
```

#### `disable_slicing`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L152)

```py
( )
```

禁用切片 VAE 解码。如果之前启用了`enable_slicing`，则此方法将返回到一步计算解码。

#### `disable_tiling`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L138)

```py
( )
```

禁用平铺 VAE 解码。如果之前启用了`enable_tiling`，则此方法将返回到一步计算解码。

#### `enable_slicing`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L145)

```py
( )
```

启用切片 VAE 解码。当启用此选项时，VAE 将将输入张量分割成切片，以便在多个步骤中计算解码。这对于节省一些内存并允许更大的批量大小非常有用。

#### `enable_tiling`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L130)

```py
( use_tiling: bool = True )
```

启用平铺 VAE 解码。当启用此选项时，VAE 将将输入张量分割成瓦片，以便在多个步骤中计算解码和编码。这对于节省大量内存并允许处理更大的图像非常有用。

#### `forward`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L423)

```py
( sample: FloatTensor sample_posterior: bool = False return_dict: bool = True generator: Optional = None )
```

参数

+   `sample`（`torch.FloatTensor`）— 输入样本。

+   `sample_posterior`（`bool`，*可选*，默认为`False`）— 是否从后验中抽样。

+   `return_dict`（`bool`，*可选*，默认为`True`）— 是否返回`DecoderOutput`而不是普通元组。

#### `fuse_qkv_projections`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L452)

```py
( )
```

启用融合 QKV 投影。对于自注意力模块，所有投影矩阵（即查询、键、值）都被融合。对于交叉注意力模块，键和值投影矩阵被融合。

此 API 为🧪实验性质。

#### `set_attn_processor`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L185)

```py
( processor: Union )
```

参数

+   `processor`（`dict`或仅`AttentionProcessor`）— 实例化的处理器类或将设置为**所有**`Attention`层的处理器类字典。

    如果`processor`是一个字典，则键需要定义相应交叉注意力处理器的路径。在设置可训练的注意力处理器时，强烈建议这样做。

设置用于计算注意力的注意力处理器。

#### `set_default_attn_processor`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L220)

```py
( )
```

禁用自定义注意力处理器并设置默认的注意力实现。

#### `tiled_decode`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L375)

```py
( z: FloatTensor return_dict: bool = True ) → export const metadata = 'undefined';~models.vae.DecoderOutput or tuple
```

参数

+   `z`（`torch.FloatTensor`）— 潜在向量的输入批次。

+   `return_dict`（`bool`，*可选*，默认为`True`）— 是否返回`~models.vae.DecoderOutput`而不是普通的元组。

返回

`~models.vae.DecoderOutput`或`tuple`

如果`return_dict`为 True，则返回`~models.vae.DecoderOutput`，否则返回普通的`tuple`。

使用平铺解码器解码一批图像。

#### `tiled_encode`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L321)

```py
( x: FloatTensor return_dict: bool = True ) → export const metadata = 'undefined';~models.autoencoder_kl.AutoencoderKLOutput or tuple
```

参数

+   `x`（`torch.FloatTensor`）-图像的输入批次。

+   `return_dict`（`bool`，*可选*，默认为`True`）-是否返回`~models.autoencoder_kl.AutoencoderKLOutput`而不是普通的元组。

返回

`~models.autoencoder_kl.AutoencoderKLOutput`或`tuple`

如果 return_dict 为 True，则返回`~models.autoencoder_kl.AutoencoderKLOutput`，否则返回普通的`tuple`。

使用瓦片编码批量图像。

启用此选项时，VAE 将输入张量分割成瓦片以在几个步骤中计算编码。这对于保持内存使用量恒定而不受图像大小影响很有用。瓦片编码的最终结果与非瓦片编码不同，因为每个瓦片使用不同的编码器。为了避免瓦片伪影，瓦片重叠并混合在一起以形成平滑的输出。您仍然可能看到输出中的瓦片大小变化，但它们应该不太明显。

#### `unfuse_qkv_projections`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/autoencoder_kl.py#L476)

```py
( )
```

如果启用，禁用融合的 QKV 投影。

此 API 为🧪实验性质。

## 自动编码器 KL 输出

### `class diffusers.models.modeling_outputs.AutoencoderKLOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/modeling_outputs.py#L6)

```py
( latent_dist: DiagonalGaussianDistribution )
```

参数

+   `latent_dist`（`DiagonalGaussianDistribution`）-`Encoder`的编码输出表示为`DiagonalGaussianDistribution`的均值和 logvar。`DiagonalGaussianDistribution`允许从分布中采样潜在变量。

AutoencoderKL 编码方法的输出。

## DecoderOutput

### `class diffusers.models.autoencoders.vae.DecoderOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/autoencoders/vae.py#L33)

```py
( sample: FloatTensor )
```

参数

+   `sample`（形状为`(batch_size, num_channels, height, width)`的`torch.FloatTensor`）-模型最后一层的解码输出样本。

解码方法的输出。

## FlaxAutoencoderKL

### `class diffusers.FlaxAutoencoderKL`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/vae_flax.py#L726)

```py
( in_channels: int = 3 out_channels: int = 3 down_block_types: Tuple = ('DownEncoderBlock2D',) up_block_types: Tuple = ('UpDecoderBlock2D',) block_out_channels: Tuple = (64,) layers_per_block: int = 1 act_fn: str = 'silu' latent_channels: int = 4 norm_num_groups: int = 32 sample_size: int = 32 scaling_factor: float = 0.18215 dtype: dtype = <class 'jax.numpy.float32'> parent: Union = <flax.linen.module._Sentinel object at 0x7fbd557629e0> name: Optional = None )
```

参数

+   `in_channels`（`int`，*可选*，默认为 3）-输入图像中的通道数。

+   `out_channels`（`int`，*可选*，默认为 3）-输出中的通道数。

+   `down_block_types`（`Tuple[str]`，*可选*，默认为`(DownEncoderBlock2D)`）-下采样块类型的元组。

+   `up_block_types`（`Tuple[str]`，*可选*，默认为`(UpDecoderBlock2D)`）-上采样块类型的元组。

+   `block_out_channels`（`Tuple[str]`，*可选*，默认为`(64,)`）-块输出通道的元组。

+   `layers_per_block`（`int`，*可选*，默认为`2`）-每个块的 ResNet 层数。

+   `act_fn`（`str`，*可选*，默认为`silu`）-要使用的激活函数。

+   `latent_channels`（`int`，*可选*，默认为`4`）-潜在空间中的通道数。

+   `norm_num_groups`（`int`，*可选*，默认为`32`）-规范化的组数。

+   `sample_size`（`int`，*可选*，默认为 32）-样本输入大小。

+   `scaling_factor`（`float`，*可选*，默认为 0.18215）-使用训练集的第一批计算的训练潜在空间的分量标准差。这用于在训练扩散模型时将潜在空间缩放为单位方差。在传递给扩散模型之前，潜在空间使用公式`z = z * scaling_factor`进行缩放。解码时，潜在变量使用公式缩放回原始比例：`z = 1 / scaling_factor * z`。有关更多详细信息，请参阅[具有潜在扩散模型的高分辨率图像合成](https://arxiv.org/abs/2112.10752)论文的 4.3.2 和 D.1 节。

+   `dtype` (`jnp.dtype`, *可选*, 默认为 `jnp.float32`) — 参数的`dtype`。

带有 KL 损失的解码潜在表示的 Flax VAE 模型的实现。

这个模型继承自 FlaxModelMixin。查看超类文档以了解为所有模型实现的通用方法（如下载或保存）。

这个模型是一个 Flax Linen [flax.linen.Module](https://flax.readthedocs.io/en/latest/flax.linen.html#module)子类。将其用作常规的 Flax Linen 模块，并参考 Flax 文档以了解与其一般使用和行为相关的所有事项。

支持以下 JAX 特性：

+   [即时编译（JIT）](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)

+   [自动微分](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)

+   [矢量化](https://jax.readthedocs.io/en/latest/jax.html#vectorization-vmap)

+   [并行化](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)

## FlaxAutoencoderKLOutput

### `class diffusers.models.vae_flax.FlaxAutoencoderKLOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/vae_flax.py#L47)

```py
( latent_dist: FlaxDiagonalGaussianDistribution )
```

参数

+   `latent_dist` (`FlaxDiagonalGaussianDistribution`) — `Encoder`的编码输出，表示为`FlaxDiagonalGaussianDistribution`的均值和 logvar。`FlaxDiagonalGaussianDistribution`允许从分布中采样潜在变量。

AutoencoderKL 编码方法的输出。

#### `replace`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。

## FlaxDecoderOutput

### `class diffusers.models.vae_flax.FlaxDecoderOutput`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/diffusers/models/vae_flax.py#L32)

```py
( sample: Array )
```

参数

+   `样本` (`形状为`(batch_size, num_channels, height, width)`的`jnp.ndarray`) — 模型最后一层的解码输出样本。

+   `dtype` (`jnp.dtype`, *可选*, 默认为 `jnp.float32`) — 参数的`dtype`。

解码方法的输出。

#### `replace`

[<来源>](https://github.com/huggingface/diffusers/blob/v0.26.3/src/flax/struct.py#L111)

```py
( **updates )
```

“返回一个用新值替换指定字段的新对象。
