["```py\npip install -q bitsandbytes sentencepiece accelerate transformers\n```", "```py\n>>> checkpoint = \"HuggingFaceM4/idefics-9b\"\n```", "```py\n>>> import torch\n\n>>> from transformers import IdeficsForVisionText2Text, AutoProcessor\n\n>>> processor = AutoProcessor.from_pretrained(checkpoint)\n\n>>> model = IdeficsForVisionText2Text.from_pretrained(checkpoint, torch_dtype=torch.bfloat16, device_map=\"auto\")\n```", "```py\n>>> import torch\n>>> from transformers import IdeficsForVisionText2Text, AutoProcessor, BitsAndBytesConfig\n\n>>> quantization_config = BitsAndBytesConfig(\n...     load_in_4bit=True,\n...     bnb_4bit_compute_dtype=torch.float16,\n... )\n\n>>> processor = AutoProcessor.from_pretrained(checkpoint)\n\n>>> model = IdeficsForVisionText2Text.from_pretrained(\n...     checkpoint,\n...     quantization_config=quantization_config,\n...     device_map=\"auto\"\n... )\n```", "```py\n>>> prompt = [\n...     \"https://images.unsplash.com/photo-1583160247711-2191776b4b91?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3542&q=80\",\n... ]\n\n>>> inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda\")\n>>> bad_words_ids = processor.tokenizer([\"<image>\", \"<fake_token_around_image>\"], add_special_tokens=False).input_ids\n\n>>> generated_ids = model.generate(**inputs, max_new_tokens=10, bad_words_ids=bad_words_ids)\n>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> print(generated_text[0])\nA puppy in a flower bed\n```", "```py\n>>> prompt = [\n...     \"https://images.unsplash.com/photo-1543349689-9a4d426bee8e?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3501&q=80\",\n...     \"This is an image of \",\n... ]\n\n>>> inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda\")\n>>> bad_words_ids = processor.tokenizer([\"<image>\", \"<fake_token_around_image>\"], add_special_tokens=False).input_ids\n\n>>> generated_ids = model.generate(**inputs, max_new_tokens=10, bad_words_ids=bad_words_ids)\n>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> print(generated_text[0])\nThis is an image of the Eiffel Tower in Paris, France.\n```", "```py\n>>> prompt = [\"User:\",\n...            \"https://images.unsplash.com/photo-1543349689-9a4d426bee8e?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3501&q=80\",\n...            \"Describe this image.\\nAssistant: An image of the Eiffel Tower at night. Fun fact: the Eiffel Tower is the same height as an 81-storey building.\\n\",\n...            \"User:\",\n...            \"https://images.unsplash.com/photo-1524099163253-32b7f0256868?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3387&q=80\",\n...            \"Describe this image.\\nAssistant:\"\n...            ]\n\n>>> inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda\")\n>>> bad_words_ids = processor.tokenizer([\"<image>\", \"<fake_token_around_image>\"], add_special_tokens=False).input_ids\n\n>>> generated_ids = model.generate(**inputs, max_new_tokens=30, bad_words_ids=bad_words_ids)\n>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> print(generated_text[0])\nUser: Describe this image.\nAssistant: An image of the Eiffel Tower at night. Fun fact: the Eiffel Tower is the same height as an 81-storey building. \nUser: Describe this image.\nAssistant: An image of the Statue of Liberty. Fun fact: the Statue of Liberty is 151 feet tall.\n```", "```py\n>>> prompt = [\n...     \"Instruction: Provide an answer to the question. Use the image to answer.\\n\",\n...     \"https://images.unsplash.com/photo-1623944889288-cd147dbb517c?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3540&q=80\",\n...     \"Question: Where are these people and what's the weather like? Answer:\"\n... ]\n\n>>> inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda\")\n>>> bad_words_ids = processor.tokenizer([\"<image>\", \"<fake_token_around_image>\"], add_special_tokens=False).input_ids\n\n>>> generated_ids = model.generate(**inputs, max_new_tokens=20, bad_words_ids=bad_words_ids)\n>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> print(generated_text[0])\nInstruction: Provide an answer to the question. Use the image to answer.\n Question: Where are these people and what's the weather like? Answer: They're in a park in New York City, and it's a beautiful day.\n```", "```py\n>>> categories = ['animals','vegetables', 'city landscape', 'cars', 'office']\n>>> prompt = [f\"Instruction: Classify the following image into a single category from the following list: {categories}.\\n\",\n...     \"https://images.unsplash.com/photo-1471193945509-9ad0617afabf?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3540&q=80\",    \n...     \"Category: \"\n... ]\n\n>>> inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda\")\n>>> bad_words_ids = processor.tokenizer([\"<image>\", \"<fake_token_around_image>\"], add_special_tokens=False).input_ids\n\n>>> generated_ids = model.generate(**inputs, max_new_tokens=6, bad_words_ids=bad_words_ids)\n>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> print(generated_text[0])\nInstruction: Classify the following image into a single category from the following list: ['animals', 'vegetables', 'city landscape', 'cars', 'office'].\nCategory: Vegetables\n```", "```py\n>>> prompt = [\"Instruction: Use the image to write a story. \\n\",\n...     \"https://images.unsplash.com/photo-1517086822157-2b0358e7684a?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2203&q=80\",\n...     \"Story: \\n\"]\n\n>>> inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda\")\n>>> bad_words_ids = processor.tokenizer([\"<image>\", \"<fake_token_around_image>\"], add_special_tokens=False).input_ids\n\n>>> generated_ids = model.generate(**inputs, num_beams=2, max_new_tokens=200, bad_words_ids=bad_words_ids)\n>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> print(generated_text[0]) \nInstruction: Use the image to write a story. \n Story: \nOnce upon a time, there was a little girl who lived in a house with a red door.  She loved her red door.  It was the prettiest door in the whole world.\n\nOne day, the little girl was playing in her yard when she noticed a man standing on her doorstep.  He was wearing a long black coat and a top hat.\n\nThe little girl ran inside and told her mother about the man.\n\nHer mother said, \u201cDon\u2019t worry, honey.  He\u2019s just a friendly ghost.\u201d\n\nThe little girl wasn\u2019t sure if she believed her mother, but she went outside anyway.\n\nWhen she got to the door, the man was gone.\n\nThe next day, the little girl was playing in her yard again when she noticed the man standing on her doorstep.\n\nHe was wearing a long black coat and a top hat.\n\nThe little girl ran\n```", "```py\n>>> prompts = [\n...     [   \"https://images.unsplash.com/photo-1543349689-9a4d426bee8e?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3501&q=80\",\n...         \"This is an image of \",\n...     ],\n...     [   \"https://images.unsplash.com/photo-1623944889288-cd147dbb517c?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3540&q=80\",\n...         \"This is an image of \",\n...     ],\n...     [   \"https://images.unsplash.com/photo-1471193945509-9ad0617afabf?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3540&q=80\",\n...         \"This is an image of \",\n...     ],\n... ]\n\n>>> inputs = processor(prompts, return_tensors=\"pt\").to(\"cuda\")\n>>> bad_words_ids = processor.tokenizer([\"<image>\", \"<fake_token_around_image>\"], add_special_tokens=False).input_ids\n\n>>> generated_ids = model.generate(**inputs, max_new_tokens=10, bad_words_ids=bad_words_ids)\n>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> for i,t in enumerate(generated_text):\n...     print(f\"{i}:\\n{t}\\n\") \n0:\nThis is an image of the Eiffel Tower in Paris, France.\n\n1:\nThis is an image of a couple on a picnic blanket.\n\n2:\nThis is an image of a vegetable stand.\n```", "```py\n>>> import torch\n>>> from transformers import IdeficsForVisionText2Text, AutoProcessor\n\n>>> device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n>>> checkpoint = \"HuggingFaceM4/idefics-9b-instruct\"\n>>> model = IdeficsForVisionText2Text.from_pretrained(checkpoint, torch_dtype=torch.bfloat16).to(device)\n>>> processor = AutoProcessor.from_pretrained(checkpoint)\n\n>>> prompts = [\n...     [\n...         \"User: What is in this image?\",\n...         \"https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPG\",\n...         \"<end_of_utterance>\",\n\n...         \"\\nAssistant: This picture depicts Idefix, the dog of Obelix in Asterix and Obelix. Idefix is running on the ground.<end_of_utterance>\",\n\n...         \"\\nUser:\",\n...         \"https://static.wikia.nocookie.net/asterix/images/2/25/R22b.gif/revision/latest?cb=20110815073052\",\n...         \"And who is that?<end_of_utterance>\",\n\n...         \"\\nAssistant:\",\n...     ],\n... ]\n\n>>> # --batched mode\n>>> inputs = processor(prompts, add_end_of_utterance_token=False, return_tensors=\"pt\").to(device)\n>>> # --single sample mode\n>>> # inputs = processor(prompts[0], return_tensors=\"pt\").to(device)\n\n>>> # Generation args\n>>> exit_condition = processor.tokenizer(\"<end_of_utterance>\", add_special_tokens=False).input_ids\n>>> bad_words_ids = processor.tokenizer([\"<image>\", \"<fake_token_around_image>\"], add_special_tokens=False).input_ids\n\n>>> generated_ids = model.generate(**inputs, eos_token_id=exit_condition, bad_words_ids=bad_words_ids, max_length=100)\n>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n>>> for i, t in enumerate(generated_text):\n...     print(f\"{i}:\\n{t}\\n\")\n```"]