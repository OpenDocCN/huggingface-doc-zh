["```py\n!pip install -q -U diffusers transformers accelerate \n```", "```py\nimport torch\n\nfrom diffusers import StableVideoDiffusionPipeline\nfrom diffusers.utils import load_image, export_to_video\n\npipe = StableVideoDiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-video-diffusion-img2vid-xt\", torch_dtype=torch.float16, variant=\"fp16\"\n)\npipe.enable_model_cpu_offload()\n\n# Load the conditioning image\nimage = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/svd/rocket.png\")\nimage = image.resize((1024, 576))\n\ngenerator = torch.manual_seed(42)\nframes = pipe(image, decode_chunk_size=8, generator=generator).frames[0]\n\nexport_to_video(frames, \"generated.mp4\", fps=7)\n```", "```py\n- pipe.enable_model_cpu_offload()\n+ pipe.to(\"cuda\")\n+ pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)\n```", "```py\n- pipe.enable_model_cpu_offload()\n- frames = pipe(image, decode_chunk_size=8, generator=generator).frames[0]\n+ pipe.enable_model_cpu_offload()\n+ pipe.unet.enable_forward_chunking()\n+ frames = pipe(image, decode_chunk_size=2, generator=generator, num_frames=25).frames[0]\n```", "```py\nimport torch\n\nfrom diffusers import StableVideoDiffusionPipeline\nfrom diffusers.utils import load_image, export_to_video\n\npipe = StableVideoDiffusionPipeline.from_pretrained(\n  \"stabilityai/stable-video-diffusion-img2vid-xt\", torch_dtype=torch.float16, variant=\"fp16\"\n)\npipe.enable_model_cpu_offload()\n\n# Load the conditioning image\nimage = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/svd/rocket.png\")\nimage = image.resize((1024, 576))\n\ngenerator = torch.manual_seed(42)\nframes = pipe(image, decode_chunk_size=8, generator=generator, motion_bucket_id=180, noise_aug_strength=0.1).frames[0]\nexport_to_video(frames, \"generated.mp4\", fps=7)\n```"]