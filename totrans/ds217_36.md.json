["```py\nfolder/train/dog/golden_retriever.png\nfolder/train/dog/german_shepherd.png\nfolder/train/dog/chihuahua.png\n\nfolder/train/cat/maine_coon.png\nfolder/train/cat/bengal.png\nfolder/train/cat/birman.png\n```", "```py\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"imagefolder\", data_dir=\"/path/to/folder\")\n```", "```py\nfolder/train/dog/golden_retriever.png\nfolder/train/cat/maine_coon.png\nfolder/test/dog/german_shepherd.png\nfolder/test/cat/bengal.png\n```", "```py\nfolder/train/metadata.csv\nfolder/train/0001.png\nfolder/train/0002.png\nfolder/train/0003.png\n```", "```py\nfolder/metadata.csv\nfolder/train.zip\nfolder/test.zip\nfolder/valid.zip\n```", "```py\nfile_name,additional_feature\n0001.png,This is a first value of a text feature you added to your images\n0002.png,This is a second value of a text feature you added to your images\n0003.png,This is a third value of a text feature you added to your images\n```", "```py\n{\"file_name\": \"0001.png\", \"additional_feature\": \"This is a first value of a text feature you added to your images\"}\n{\"file_name\": \"0002.png\", \"additional_feature\": \"This is a second value of a text feature you added to your images\"}\n{\"file_name\": \"0003.png\", \"additional_feature\": \"This is a third value of a text feature you added to your images\"}\n```", "```py\nfile_name,text\n0001.png,This is a golden retriever playing with a ball\n0002.png,A german shepherd\n0003.png,One chihuahua\n```", "```py\n>>> dataset = load_dataset(\"imagefolder\", data_dir=\"/path/to/folder\", split=\"train\")\n>>> dataset[0][\"text\"]\n\"This is a golden retriever playing with a ball\"\n```", "```py\n{\"file_name\": \"0001.png\", \"objects\": {\"bbox\": [[302.0, 109.0, 73.0, 52.0]], \"categories\": [0]}}\n{\"file_name\": \"0002.png\", \"objects\": {\"bbox\": [[810.0, 100.0, 57.0, 28.0]], \"categories\": [1]}}\n{\"file_name\": \"0003.png\", \"objects\": {\"bbox\": [[160.0, 31.0, 248.0, 616.0], [741.0, 68.0, 202.0, 401.0]], \"categories\": [2, 2]}}\n```", "```py\n>>> dataset = load_dataset(\"imagefolder\", data_dir=\"/path/to/folder\", split=\"train\")\n>>> dataset[0][\"objects\"]\n{\"bbox\": [[302.0, 109.0, 73.0, 52.0]], \"categories\": [0]}\n```", "```py\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"imagefolder\", data_dir=\"/path/to/folder\", split=\"train\")\n>>> dataset.push_to_hub(\"stevhliu/my-image-captioning-dataset\")\n```", "```py\nfolder/train/00000.tar\nfolder/train/00001.tar\nfolder/train/00002.tar\n...\n```", "```py\ne39871fd9fd74f55.jpg e39871fd9fd74f55.json f18b91585c4d3f3e.jpg f18b91585c4d3f3e.json ede6e66b2fb59aab.jpg ede6e66b2fb59aab.json ed600d57fcee4f94.jpg ed600d57fcee4f94.json ...\n```", "```py\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"webdataset\", data_dir=\"/path/to/folder\", split=\"train\")\n>>> dataset[0][\"json\"]\n{\"bbox\": [[302.0, 109.0, 73.0, 52.0]], \"categories\": [0]}\n```", "```py\nmy_dataset/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 my_dataset.py\n\u2514\u2500\u2500 data/  # optional, may contain your images or TAR archives\n```", "```py\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"path/to/my_dataset\")\n```", "```py\nclass Food101(datasets.GeneratorBasedBuilder):\n    \"\"\"Food-101 Images dataset\"\"\"\n\n    def _info(self):\n\n    def _split_generators(self, dl_manager):\n\n    def _generate_examples(self, images, metadata_path):\n```", "```py\nclass Food101Config(datasets.BuilderConfig):\n    \"\"\"Builder Config for Food-101\"\"\"\n\n    def __init__(self, data_url, metadata_urls, **kwargs):\n        \"\"\"BuilderConfig for Food-101.\n        Args:\n          data_url: `string`, url to download the zip file from.\n          metadata_urls: dictionary with keys 'train' and 'validation' containing the archive metadata URLs\n          **kwargs: keyword arguments forwarded to super.\n        \"\"\"\n        super(Food101Config, self).__init__(version=datasets.Version(\"1.0.0\"), **kwargs)\n        self.data_url = data_url\n        self.metadata_urls = metadata_urls\n```", "```py\nclass Food101(datasets.GeneratorBasedBuilder):\n    \"\"\"Food-101 Images dataset\"\"\"\n\n    BUILDER_CONFIGS = [\n        Food101Config(\n            name=\"breakfast\",\n            description=\"Food types commonly eaten during breakfast.\",\n            data_url=\"https://link-to-breakfast-foods.zip\",\n            metadata_urls={\n                \"train\": \"https://link-to-breakfast-foods-train.txt\", \n                \"validation\": \"https://link-to-breakfast-foods-validation.txt\"\n            },\n        ,\n        Food101Config(\n            name=\"dinner\",\n            description=\"Food types commonly eaten during dinner.\",\n            data_url=\"https://link-to-dinner-foods.zip\",\n            metadata_urls={\n                \"train\": \"https://link-to-dinner-foods-train.txt\", \n                \"validation\": \"https://link-to-dinner-foods-validation.txt\"\n            },\n        )...\n    ]\n```", "```py\n>>> from datasets import load_dataset\n>>> ds = load_dataset(\"food101\", \"breakfast\", split=\"train\")\n```", "```py\n>>> from datasets import load_dataset_builder\n>>> ds_builder = load_dataset_builder(\"food101\")\n>>> ds_builder.info\n```", "```py\ndef _info(self):\n    return datasets.DatasetInfo(\n        description=_DESCRIPTION,\n        features=datasets.Features(\n            {\n                \"image\": datasets.Image(),\n                \"label\": datasets.ClassLabel(names=_NAMES),\n            }\n        ),\n        supervised_keys=(\"image\", \"label\"),\n        homepage=_HOMEPAGE,\n        citation=_CITATION,\n        license=_LICENSE,\n        task_templates=[ImageClassification(image_column=\"image\", label_column=\"label\")],\n    )\n```", "```py\ndef _split_generators(self, dl_manager):\n    archive_path = dl_manager.download(_BASE_URL)\n    split_metadata_paths = dl_manager.download(_METADATA_URLS)\n    return [\n        datasets.SplitGenerator(\n            name=datasets.Split.TRAIN,\n            gen_kwargs={\n                \"images\": dl_manager.iter_archive(archive_path),\n                \"metadata_path\": split_metadata_paths[\"train\"],\n            },\n        ),\n        datasets.SplitGenerator(\n            name=datasets.Split.VALIDATION,\n            gen_kwargs={\n                \"images\": dl_manager.iter_archive(archive_path),\n                \"metadata_path\": split_metadata_paths[\"test\"],\n            },\n        ),\n    ]\n```", "```py\ndef _generate_examples(self, images, metadata_path):\n    \"\"\"Generate images and labels for splits.\"\"\"\n    with open(metadata_path, encoding=\"utf-8\") as f:\n        files_to_keep = set(f.read().split(\"\\n\"))\n    for file_path, file_obj in images:\n        if file_path.startswith(_IMAGES_DIR):\n            if file_path[len(_IMAGES_DIR) : -len(\".jpg\")] in files_to_keep:\n                label = file_path.split(\"/\")[2]\n                yield file_path, {\n                    \"image\": {\"path\": file_path, \"bytes\": file_obj.read()},\n                    \"label\": label,\n                }\n```", "```py\ndatasets-cli test path/to/<your-dataset-loading-script> --save_info --all_configs\n```", "```py\n>>> from datasets import load_dataset\n>>> load_dataset(\"<username>/my_dataset\")\n```"]